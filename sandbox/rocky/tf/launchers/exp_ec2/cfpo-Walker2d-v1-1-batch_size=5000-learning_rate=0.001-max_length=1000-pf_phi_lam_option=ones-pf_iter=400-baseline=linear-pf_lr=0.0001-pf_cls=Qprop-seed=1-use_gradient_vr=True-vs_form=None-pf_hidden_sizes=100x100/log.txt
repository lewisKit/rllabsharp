output_formats ['stdout', 'log', 'json', 'tensorboard']
Logging to exp_ec2/cfpo-Walker2d-v1-1-batch_size=5000-learning_rate=0.001-max_length=1000-pf_phi_lam_option=ones-pf_iter=400-baseline=linear-pf_lr=0.0001-pf_cls=Qprop-seed=1-use_gradient_vr=True-vs_form=None-pf_hidden_sizes=100x100
Setting seed to 1
Setting seed to 2
Setting seed to 3
Setting seed to 4
observation space: Box(17,)
action space: Box(6,)
use_gradient_vr is True
pf_learning_rate is 0.0001
observation space: Box(17,)
action space: Box(6,)
observation space: Box(17,)
action space: Box(6,)
observation space: Box(17,)
action space: Box(6,)
observation space: Box(17,)
action space: Box(6,)
observation space: Box(17,)
action space: Box(6,)
qf is None
using gradient as variance reduction
parameter of phi Phinet/obs_h0/W:0, shape=(17, 100)
parameter of phi Phinet/obs_h0/b:0, shape=(100,)
parameter of phi Phinet/act_h0/W:0, shape=(6, 100)
parameter of phi Phinet/act_h0/b:0, shape=(100,)
parameter of phi Phinet/h1/W:0, shape=(100, 100)
parameter of phi Phinet/h1/b:0, shape=(100,)
parameter of phi Phinet/output/W:0, shape=(100, 1)
parameter of phi Phinet/output/b:0, shape=(1,)
No checkpoint exp_ec2/cfpo-Walker2d-v1-1-batch_size=5000-learning_rate=0.001-max_length=1000-pf_phi_lam_option=ones-pf_iter=400-baseline=linear-pf_lr=0.0001-pf_cls=Qprop-seed=1-use_gradient_vr=True-vs_form=None-pf_hidden_sizes=100x100/params.chk
itr #0 | 
Mem: 271.339844
Obtaining samples...
Obtaining samples for iteration 0...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5000, #subsample_inputs: 5000
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.745      |
| AbsLearnSignalNew       | 0.745      |
| AbsLearningOld          | 0.744      |
| AverageDiscountedReturn | -3.02      |
| AveragePhiLoss          | 8.46495    |
| AveragePolicyStd        | 1.0        |
| AverageReturn           | -4.25      |
| Entropy                 | 8.51363    |
| EnvExecTime             | 2.51       |
| ExplainedVariance       | 2.83e-10   |
| Iteration               | 0          |
| ItrTime                 | 12         |
| LossAfter               | -0.448542  |
| LossBefore              | -0.394873  |
| MaxReturn               | 47.1       |
| MeanKL                  | 0.00650104 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -17.5      |
| NumTrajs                | 210        |
| Perplexity              | 4982.22    |
| PolicyExecTime          | 0.592      |
| ProcessExecTime         | 0.0938     |
| StdReturn               | 6.56       |
| Time                    | 12         |
| dLoss                   | 0.0536694  |
----------------------------------------
itr #1 | 
Mem: 613.921875
Obtaining samples...
Obtaining samples for iteration 1...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5031, #subsample_inputs: 5031
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.781      |
| AbsLearnSignalNew       | 0.781      |
| AbsLearningOld          | 0.782      |
| AverageDiscountedReturn | -2.11      |
| AveragePhiLoss          | 7.96366    |
| AveragePolicyStd        | 1.00046    |
| AverageReturn           | -3.3       |
| Entropy                 | 8.51636    |
| EnvExecTime             | 2.27       |
| ExplainedVariance       | 0.355      |
| Iteration               | 1          |
| ItrTime                 | 10.5       |
| LossAfter               | -1.26184   |
| LossBefore              | -1.20032   |
| MaxReturn               | 13.4       |
| MeanKL                  | 0.00653921 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -16.8      |
| NumTrajs                | 205        |
| Perplexity              | 4995.83    |
| PolicyExecTime          | 0.494      |
| ProcessExecTime         | 0.0788     |
| StdReturn               | 5.83       |
| Time                    | 22.6       |
| dLoss                   | 0.0615171  |
----------------------------------------
itr #2 | 
Mem: 633.183594
Obtaining samples...
Obtaining samples for iteration 2...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5008, #subsample_inputs: 5008
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.728      |
| AbsLearnSignalNew       | 0.728      |
| AbsLearningOld          | 0.73       |
| AverageDiscountedReturn | -0.859     |
| AveragePhiLoss          | 8.16252    |
| AveragePolicyStd        | 1.00045    |
| AverageReturn           | -1.85      |
| Entropy                 | 8.51627    |
| EnvExecTime             | 2.47       |
| ExplainedVariance       | 0.204      |
| Iteration               | 2          |
| ItrTime                 | 10.6       |
| LossAfter               | -1.17884   |
| LossBefore              | -1.11726   |
| MaxReturn               | 58.3       |
| MeanKL                  | 0.00643273 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -14.9      |
| NumTrajs                | 203        |
| Perplexity              | 4995.37    |
| PolicyExecTime          | 0.555      |
| ProcessExecTime         | 0.0956     |
| StdReturn               | 7.12       |
| Time                    | 33.4       |
| dLoss                   | 0.0615731  |
----------------------------------------
itr #3 | 
Mem: 644.496094
Obtaining samples...
Obtaining samples for iteration 3...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5009, #subsample_inputs: 5009
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.691      |
| AbsLearnSignalNew       | 0.691      |
| AbsLearningOld          | 0.693      |
| AverageDiscountedReturn | -0.251     |
| AveragePhiLoss          | 7.8191     |
| AveragePolicyStd        | 1.00079    |
| AverageReturn           | -1.21      |
| Entropy                 | 8.51831    |
| EnvExecTime             | 2.25       |
| ExplainedVariance       | 0.313      |
| Iteration               | 3          |
| ItrTime                 | 11.4       |
| LossAfter               | -0.309522  |
| LossBefore              | -0.257131  |
| MaxReturn               | 62.1       |
| MeanKL                  | 0.00641545 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -15        |
| NumTrajs                | 193        |
| Perplexity              | 5005.58    |
| PolicyExecTime          | 0.52       |
| ProcessExecTime         | 0.0791     |
| StdReturn               | 7.29       |
| Time                    | 44.9       |
| dLoss                   | 0.0523904  |
----------------------------------------
itr #4 | 
Mem: 661.464844
Obtaining samples...
Obtaining samples for iteration 4...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5029, #subsample_inputs: 5029
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.759      |
| AbsLearnSignalNew       | 0.759      |
| AbsLearningOld          | 0.76       |
| AverageDiscountedReturn | 1.65       |
| AveragePhiLoss          | 8.00799    |
| AveragePolicyStd        | 1.00046    |
| AverageReturn           | 0.958      |
| Entropy                 | 8.5163     |
| EnvExecTime             | 2.42       |
| ExplainedVariance       | 0.29       |
| Iteration               | 4          |
| ItrTime                 | 10.1       |
| LossAfter               | -1.61767   |
| LossBefore              | -1.5608    |
| MaxReturn               | 45         |
| MeanKL                  | 0.00649815 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -14.5      |
| NumTrajs                | 188        |
| Perplexity              | 4995.56    |
| PolicyExecTime          | 0.544      |
| ProcessExecTime         | 0.0934     |
| StdReturn               | 7.41       |
| Time                    | 55.1       |
| dLoss                   | 0.0568682  |
----------------------------------------
itr #5 | 
Mem: 664.035156
Obtaining samples...
Obtaining samples for iteration 5...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5018, #subsample_inputs: 5018
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.709      |
| AbsLearnSignalNew       | 0.709      |
| AbsLearningOld          | 0.709      |
| AverageDiscountedReturn | 2.59       |
| AveragePhiLoss          | 7.75932    |
| AveragePolicyStd        | 0.999312   |
| AverageReturn           | 2.06       |
| Entropy                 | 8.50946    |
| EnvExecTime             | 2.49       |
| ExplainedVariance       | 0.247      |
| Iteration               | 5          |
| ItrTime                 | 11.6       |
| LossAfter               | -0.17862   |
| LossBefore              | -0.109689  |
| MaxReturn               | 80.9       |
| MeanKL                  | 0.00986404 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -14.7      |
| NumTrajs                | 179        |
| Perplexity              | 4961.48    |
| PolicyExecTime          | 0.576      |
| ProcessExecTime         | 0.0935     |
| StdReturn               | 8.85       |
| Time                    | 66.8       |
| dLoss                   | 0.0689309  |
----------------------------------------
itr #6 | 
Mem: 664.546875
Obtaining samples...
Obtaining samples for iteration 6...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5031, #subsample_inputs: 5031
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.738      |
| AbsLearnSignalNew       | 0.738      |
| AbsLearningOld          | 0.739      |
| AverageDiscountedReturn | 4.14       |
| AveragePhiLoss          | 8.18361    |
| AveragePolicyStd        | 0.99945    |
| AverageReturn           | 3.64       |
| Entropy                 | 8.51023    |
| EnvExecTime             | 2.06       |
| ExplainedVariance       | 0.156      |
| Iteration               | 6          |
| ItrTime                 | 11.1       |
| LossAfter               | 0.040124   |
| LossBefore              | 0.104253   |
| MaxReturn               | 27.9       |
| MeanKL                  | 0.00988412 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -16.3      |
| NumTrajs                | 174        |
| Perplexity              | 4965.31    |
| PolicyExecTime          | 0.433      |
| ProcessExecTime         | 0.0682     |
| StdReturn               | 7.17       |
| Time                    | 78         |
| dLoss                   | 0.0641294  |
----------------------------------------
itr #7 | 
Mem: 665.316406
Obtaining samples...
Obtaining samples for iteration 7...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5014, #subsample_inputs: 5014
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.737      |
| AbsLearnSignalNew       | 0.737      |
| AbsLearningOld          | 0.737      |
| AverageDiscountedReturn | 6.53       |
| AveragePhiLoss          | 8.40628    |
| AveragePolicyStd        | 0.995048   |
| AverageReturn           | 6.65       |
| Entropy                 | 8.48366    |
| EnvExecTime             | 2.44       |
| ExplainedVariance       | 0.254      |
| Iteration               | 7          |
| ItrTime                 | 10.1       |
| LossAfter               | 0.418629   |
| LossBefore              | 0.475862   |
| MaxReturn               | 65.9       |
| MeanKL                  | 0.00649266 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -16.3      |
| NumTrajs                | 152        |
| Perplexity              | 4835.14    |
| PolicyExecTime          | 0.561      |
| ProcessExecTime         | 0.0903     |
| StdReturn               | 10.7       |
| Time                    | 88.2       |
| dLoss                   | 0.0572325  |
----------------------------------------
itr #8 | 
Mem: 665.316406
Obtaining samples...
Obtaining samples for iteration 8...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5018, #subsample_inputs: 5018
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.763      |
| AbsLearnSignalNew       | 0.763      |
| AbsLearningOld          | 0.764      |
| AverageDiscountedReturn | 6.25       |
| AveragePhiLoss          | 8.44029    |
| AveragePolicyStd        | 0.993178   |
| AverageReturn           | 6.26       |
| Entropy                 | 8.4723     |
| EnvExecTime             | 2.45       |
| ExplainedVariance       | 0.296      |
| Iteration               | 8          |
| ItrTime                 | 11.5       |
| LossAfter               | 1.54092    |
| LossBefore              | 1.59563    |
| MaxReturn               | 56.4       |
| MeanKL                  | 0.00654119 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -14.7      |
| NumTrajs                | 154        |
| Perplexity              | 4780.51    |
| PolicyExecTime          | 0.57       |
| ProcessExecTime         | 0.091      |
| StdReturn               | 9.59       |
| Time                    | 99.9       |
| dLoss                   | 0.0547118  |
----------------------------------------
itr #9 | 
Mem: 670.468750
Obtaining samples...
Obtaining samples for iteration 9...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5028, #subsample_inputs: 5028
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.773      |
| AbsLearnSignalNew       | 0.773      |
| AbsLearningOld          | 0.773      |
| AverageDiscountedReturn | 10.2       |
| AveragePhiLoss          | 8.38099    |
| AveragePolicyStd        | 0.99228    |
| AverageReturn           | 11.1       |
| Entropy                 | 8.4669     |
| EnvExecTime             | 2.24       |
| ExplainedVariance       | 0.267      |
| Iteration               | 9          |
| ItrTime                 | 10.2       |
| LossAfter               | 0.301018   |
| LossBefore              | 0.364753   |
| MaxReturn               | 55.3       |
| MeanKL                  | 0.00984877 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -5.39      |
| NumTrajs                | 128        |
| Perplexity              | 4754.75    |
| PolicyExecTime          | 0.504      |
| ProcessExecTime         | 0.0792     |
| StdReturn               | 12.1       |
| Time                    | 110        |
| dLoss                   | 0.0637347  |
----------------------------------------
itr #10 | 
Mem: 672.785156
Obtaining samples...
Obtaining samples for iteration 10...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5019, #subsample_inputs: 5019
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.687      |
| AbsLearnSignalNew       | 0.687      |
| AbsLearningOld          | 0.687      |
| AverageDiscountedReturn | 13         |
| AveragePhiLoss          | 7.91603    |
| AveragePolicyStd        | 0.992494   |
| AverageReturn           | 15.4       |
| Entropy                 | 8.46817    |
| EnvExecTime             | 2.47       |
| ExplainedVariance       | 0.179      |
| Iteration               | 10         |
| ItrTime                 | 11.3       |
| LossAfter               | -0.123338  |
| LossBefore              | -0.0717887 |
| MaxReturn               | 157        |
| MeanKL                  | 0.00643099 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -7.27      |
| NumTrajs                | 120        |
| Perplexity              | 4760.79    |
| PolicyExecTime          | 0.569      |
| ProcessExecTime         | 0.0906     |
| StdReturn               | 21.8       |
| Time                    | 122        |
| dLoss                   | 0.0515492  |
----------------------------------------
itr #11 | 
Mem: 676.652344
Obtaining samples...
Obtaining samples for iteration 11...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5030, #subsample_inputs: 5030
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
-----------------------------------------
| AbsLearnSignal          | 0.727       |
| AbsLearnSignalNew       | 0.727       |
| AbsLearningOld          | 0.727       |
| AverageDiscountedReturn | 13.9        |
| AveragePhiLoss          | 8.78657     |
| AveragePolicyStd        | 0.990027    |
| AverageReturn           | 17.1        |
| Entropy                 | 8.45326     |
| EnvExecTime             | 2.12        |
| ExplainedVariance       | 0.182       |
| Iteration               | 11          |
| ItrTime                 | 10.8        |
| LossAfter               | -0.00654776 |
| LossBefore              | 0.0609675   |
| MaxReturn               | 255         |
| MeanKL                  | 0.00979078  |
| MeanKLBefore            | 0.0         |
| MinReturn               | -5.05       |
| NumTrajs                | 115         |
| Perplexity              | 4690.32     |
| PolicyExecTime          | 0.456       |
| ProcessExecTime         | 0.0676      |
| StdReturn               | 27.6        |
| Time                    | 133         |
| dLoss                   | 0.0675153   |
-----------------------------------------
itr #12 | 
Mem: 679.230469
Obtaining samples...
Obtaining samples for iteration 12...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5024, #subsample_inputs: 5024
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.71       |
| AbsLearnSignalNew       | 0.71       |
| AbsLearningOld          | 0.71       |
| AverageDiscountedReturn | 15.5       |
| AveragePhiLoss          | 8.55175    |
| AveragePolicyStd        | 0.990541   |
| AverageReturn           | 21.3       |
| Entropy                 | 8.45633    |
| EnvExecTime             | 2.42       |
| ExplainedVariance       | 0.286      |
| Iteration               | 12         |
| ItrTime                 | 10.1       |
| LossAfter               | -0.0573823 |
| LossBefore              | 0.00992008 |
| MaxReturn               | 291        |
| MeanKL                  | 0.00999502 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -18.2      |
| NumTrajs                | 107        |
| Perplexity              | 4704.77    |
| PolicyExecTime          | 0.573      |
| ProcessExecTime         | 0.0869     |
| StdReturn               | 40.9       |
| Time                    | 143        |
| dLoss                   | 0.0673024  |
----------------------------------------
itr #13 | 
Mem: 679.746094
Obtaining samples...
Obtaining samples for iteration 13...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5027, #subsample_inputs: 5027
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.764      |
| AbsLearnSignalNew       | 0.764      |
| AbsLearningOld          | 0.764      |
| AverageDiscountedReturn | 12.6       |
| AveragePhiLoss          | 8.52339    |
| AveragePolicyStd        | 0.988387   |
| AverageReturn           | 13.6       |
| Entropy                 | 8.44339    |
| EnvExecTime             | 2.52       |
| ExplainedVariance       | -0.162     |
| Iteration               | 13         |
| ItrTime                 | 11.7       |
| LossAfter               | 0.101577   |
| LossBefore              | 0.167559   |
| MaxReturn               | 116        |
| MeanKL                  | 0.00999347 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -6.44      |
| NumTrajs                | 101        |
| Perplexity              | 4644.27    |
| PolicyExecTime          | 0.57       |
| ProcessExecTime         | 0.086      |
| StdReturn               | 16         |
| Time                    | 155        |
| dLoss                   | 0.0659818  |
----------------------------------------
itr #14 | 
Mem: 685.652344
Obtaining samples...
Obtaining samples for iteration 14...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5020, #subsample_inputs: 5020
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.684      |
| AbsLearnSignalNew       | 0.684      |
| AbsLearningOld          | 0.684      |
| AverageDiscountedReturn | 14.9       |
| AveragePhiLoss          | 8.41986    |
| AveragePolicyStd        | 0.988689   |
| AverageReturn           | 17.5       |
| Entropy                 | 8.4452     |
| EnvExecTime             | 2.19       |
| ExplainedVariance       | 0.273      |
| Iteration               | 14         |
| ItrTime                 | 10.1       |
| LossAfter               | 0.377651   |
| LossBefore              | 0.440789   |
| MaxReturn               | 194        |
| MeanKL                  | 0.00976672 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -18.7      |
| NumTrajs                | 89         |
| Perplexity              | 4652.7     |
| PolicyExecTime          | 0.502      |
| ProcessExecTime         | 0.0764     |
| StdReturn               | 26.8       |
| Time                    | 165        |
| dLoss                   | 0.0631382  |
----------------------------------------
itr #15 | 
Mem: 685.652344
Obtaining samples...
Obtaining samples for iteration 15...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5015, #subsample_inputs: 5015
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.769      |
| AbsLearnSignalNew       | 0.769      |
| AbsLearningOld          | 0.769      |
| AverageDiscountedReturn | 22.5       |
| AveragePhiLoss          | 8.4517     |
| AveragePolicyStd        | 0.986692   |
| AverageReturn           | 33.3       |
| Entropy                 | 8.4331     |
| EnvExecTime             | 2.45       |
| ExplainedVariance       | 0.262      |
| Iteration               | 15         |
| ItrTime                 | 10.8       |
| LossAfter               | -0.233866  |
| LossBefore              | -0.167438  |
| MaxReturn               | 260        |
| MeanKL                  | 0.00992424 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -4.67      |
| NumTrajs                | 86         |
| Perplexity              | 4596.71    |
| PolicyExecTime          | 0.571      |
| ProcessExecTime         | 0.0853     |
| StdReturn               | 49.5       |
| Time                    | 176        |
| dLoss                   | 0.0664286  |
----------------------------------------
itr #16 | 
Mem: 687.707031
Obtaining samples...
Obtaining samples for iteration 16...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5022, #subsample_inputs: 5022
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.811      |
| AbsLearnSignalNew       | 0.811      |
| AbsLearningOld          | 0.811      |
| AverageDiscountedReturn | 29.5       |
| AveragePhiLoss          | 8.22832    |
| AveragePolicyStd        | 0.985182   |
| AverageReturn           | 49.2       |
| Entropy                 | 8.42383    |
| EnvExecTime             | 2.24       |
| ExplainedVariance       | 0.235      |
| Iteration               | 16         |
| ItrTime                 | 11.4       |
| LossAfter               | 0.112843   |
| LossBefore              | 0.162052   |
| MaxReturn               | 303        |
| MeanKL                  | 0.00655426 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -13.3      |
| NumTrajs                | 67         |
| Perplexity              | 4554.29    |
| PolicyExecTime          | 0.518      |
| ProcessExecTime         | 0.0727     |
| StdReturn               | 70.1       |
| Time                    | 187        |
| dLoss                   | 0.0492084  |
----------------------------------------
itr #17 | 
Mem: 689.246094
Obtaining samples...
Obtaining samples for iteration 17...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5009, #subsample_inputs: 5009
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.738      |
| AbsLearnSignalNew       | 0.738      |
| AbsLearningOld          | 0.738      |
| AverageDiscountedReturn | 24.7       |
| AveragePhiLoss          | 8.76805    |
| AveragePolicyStd        | 0.981504   |
| AverageReturn           | 37.4       |
| Entropy                 | 8.40141    |
| EnvExecTime             | 2.42       |
| ExplainedVariance       | 0.132      |
| Iteration               | 17         |
| ItrTime                 | 9.82       |
| LossAfter               | 0.0147985  |
| LossBefore              | 0.064813   |
| MaxReturn               | 307        |
| MeanKL                  | 0.00641957 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -10.4      |
| NumTrajs                | 75         |
| Perplexity              | 4453.35    |
| PolicyExecTime          | 0.562      |
| ProcessExecTime         | 0.0853     |
| StdReturn               | 54.5       |
| Time                    | 197        |
| dLoss                   | 0.0500145  |
----------------------------------------
itr #18 | 
Mem: 689.246094
Obtaining samples...
Obtaining samples for iteration 18...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5033, #subsample_inputs: 5033
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
-----------------------------------------
| AbsLearnSignal          | 0.709       |
| AbsLearnSignalNew       | 0.709       |
| AbsLearningOld          | 0.709       |
| AverageDiscountedReturn | 26.1        |
| AveragePhiLoss          | 8.86217     |
| AveragePolicyStd        | 0.979554    |
| AverageReturn           | 38          |
| Entropy                 | 8.3894      |
| EnvExecTime             | 2.45        |
| ExplainedVariance       | 0.211       |
| Iteration               | 18          |
| ItrTime                 | 11.5        |
| LossAfter               | -0.00912549 |
| LossBefore              | 0.0418906   |
| MaxReturn               | 274         |
| MeanKL                  | 0.0064165   |
| MeanKLBefore            | 0.0         |
| MinReturn               | -10.2       |
| NumTrajs                | 72          |
| Perplexity              | 4400.16     |
| PolicyExecTime          | 0.572       |
| ProcessExecTime         | 0.0857      |
| StdReturn               | 51.7        |
| Time                    | 209         |
| dLoss                   | 0.051016    |
-----------------------------------------
itr #19 | 
Mem: 690.273438
Obtaining samples...
Obtaining samples for iteration 19...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5007, #subsample_inputs: 5007
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.777      |
| AbsLearnSignalNew       | 0.777      |
| AbsLearningOld          | 0.777      |
| AverageDiscountedReturn | 26.5       |
| AveragePhiLoss          | 8.5061     |
| AveragePolicyStd        | 0.979311   |
| AverageReturn           | 40.8       |
| Entropy                 | 8.3878     |
| EnvExecTime             | 2.18       |
| ExplainedVariance       | 0.306      |
| Iteration               | 19         |
| ItrTime                 | 10.4       |
| LossAfter               | -0.107083  |
| LossBefore              | -0.0499194 |
| MaxReturn               | 327        |
| MeanKL                  | 0.00996176 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -7.87      |
| NumTrajs                | 66         |
| Perplexity              | 4393.13    |
| PolicyExecTime          | 0.496      |
| ProcessExecTime         | 0.071      |
| StdReturn               | 62.4       |
| Time                    | 219        |
| dLoss                   | 0.0571636  |
----------------------------------------
itr #20 | 
Mem: 690.273438
Obtaining samples...
Obtaining samples for iteration 20...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5047, #subsample_inputs: 5047
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.782      |
| AbsLearnSignalNew       | 0.782      |
| AbsLearningOld          | 0.782      |
| AverageDiscountedReturn | 33.4       |
| AveragePhiLoss          | 9.07388    |
| AveragePolicyStd        | 0.976932   |
| AverageReturn           | 54.8       |
| Entropy                 | 8.37321    |
| EnvExecTime             | 2.52       |
| ExplainedVariance       | 0.274      |
| Iteration               | 20         |
| ItrTime                 | 10.8       |
| LossAfter               | 0.15012    |
| LossBefore              | 0.197069   |
| MaxReturn               | 300        |
| MeanKL                  | 0.00645304 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -12.1      |
| NumTrajs                | 59         |
| Perplexity              | 4329.5     |
| PolicyExecTime          | 0.585      |
| ProcessExecTime         | 0.0839     |
| StdReturn               | 71.3       |
| Time                    | 230        |
| dLoss                   | 0.0469489  |
----------------------------------------
itr #21 | 
Mem: 694.652344
Obtaining samples...
Obtaining samples for iteration 21...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5017, #subsample_inputs: 5017
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.75       |
| AbsLearnSignalNew       | 0.75       |
| AbsLearningOld          | 0.75       |
| AverageDiscountedReturn | 33.7       |
| AveragePhiLoss          | 9.06248    |
| AveragePolicyStd        | 0.975249   |
| AverageReturn           | 52.2       |
| Entropy                 | 8.36281    |
| EnvExecTime             | 2.11       |
| ExplainedVariance       | 0.242      |
| Iteration               | 21         |
| ItrTime                 | 11.1       |
| LossAfter               | -0.492672  |
| LossBefore              | -0.440046  |
| MaxReturn               | 268        |
| MeanKL                  | 0.00641963 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -12        |
| NumTrajs                | 55         |
| Perplexity              | 4284.7     |
| PolicyExecTime          | 0.475      |
| ProcessExecTime         | 0.0666     |
| StdReturn               | 61.1       |
| Time                    | 241        |
| dLoss                   | 0.0526261  |
----------------------------------------
itr #22 | 
Mem: 709.925781
Obtaining samples...
Obtaining samples for iteration 22...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5128, #subsample_inputs: 5128
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.796      |
| AbsLearnSignalNew       | 0.796      |
| AbsLearningOld          | 0.796      |
| AverageDiscountedReturn | 43         |
| AveragePhiLoss          | 8.95652    |
| AveragePolicyStd        | 0.973615   |
| AverageReturn           | 88.1       |
| Entropy                 | 8.35275    |
| EnvExecTime             | 2.5        |
| ExplainedVariance       | 0.286      |
| Iteration               | 22         |
| ItrTime                 | 10.2       |
| LossAfter               | -0.368462  |
| LossBefore              | -0.320537  |
| MaxReturn               | 371        |
| MeanKL                  | 0.00646199 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -8.24      |
| NumTrajs                | 48         |
| Perplexity              | 4241.85    |
| PolicyExecTime          | 0.581      |
| ProcessExecTime         | 0.0865     |
| StdReturn               | 106        |
| Time                    | 252        |
| dLoss                   | 0.0479247  |
----------------------------------------
itr #23 | 
Mem: 710.183594
Obtaining samples...
Obtaining samples for iteration 23...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5120, #subsample_inputs: 5120
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.741      |
| AbsLearnSignalNew       | 0.741      |
| AbsLearningOld          | 0.741      |
| AverageDiscountedReturn | 41.1       |
| AveragePhiLoss          | 9.0572     |
| AveragePolicyStd        | 0.972478   |
| AverageReturn           | 78.2       |
| Entropy                 | 8.34566    |
| EnvExecTime             | 2.54       |
| ExplainedVariance       | 0.142      |
| Iteration               | 23         |
| ItrTime                 | 11.8       |
| LossAfter               | 0.156919   |
| LossBefore              | 0.223721   |
| MaxReturn               | 324        |
| MeanKL                  | 0.00980482 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -19.7      |
| NumTrajs                | 45         |
| Perplexity              | 4211.85    |
| PolicyExecTime          | 0.588      |
| ProcessExecTime         | 0.088      |
| StdReturn               | 92.2       |
| Time                    | 264        |
| dLoss                   | 0.0668017  |
----------------------------------------
itr #24 | 
Mem: 715.074219
Obtaining samples...
Obtaining samples for iteration 24...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5014, #subsample_inputs: 5014
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.781      |
| AbsLearnSignalNew       | 0.781      |
| AbsLearningOld          | 0.781      |
| AverageDiscountedReturn | 35.1       |
| AveragePhiLoss          | 9.06521    |
| AveragePolicyStd        | 0.973164   |
| AverageReturn           | 57.6       |
| Entropy                 | 8.34987    |
| EnvExecTime             | 2.1        |
| ExplainedVariance       | 0.277      |
| Iteration               | 24         |
| ItrTime                 | 10.5       |
| LossAfter               | 0.90629    |
| LossBefore              | 0.96637    |
| MaxReturn               | 299        |
| MeanKL                  | 0.00994085 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -16.8      |
| NumTrajs                | 55         |
| Perplexity              | 4229.63    |
| PolicyExecTime          | 0.454      |
| ProcessExecTime         | 0.0642     |
| StdReturn               | 71.5       |
| Time                    | 274        |
| dLoss                   | 0.0600796  |
----------------------------------------
itr #25 | 
Mem: 715.074219
Obtaining samples...
Obtaining samples for iteration 25...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5144, #subsample_inputs: 5144
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.77       |
| AbsLearnSignalNew       | 0.77       |
| AbsLearningOld          | 0.77       |
| AverageDiscountedReturn | 54.2       |
| AveragePhiLoss          | 8.91013    |
| AveragePolicyStd        | 0.972179   |
| AverageReturn           | 116        |
| Entropy                 | 8.34376    |
| EnvExecTime             | 2.43       |
| ExplainedVariance       | 0.252      |
| Iteration               | 25         |
| ItrTime                 | 10.4       |
| LossAfter               | 0.330024   |
| LossBefore              | 0.390469   |
| MaxReturn               | 405        |
| MeanKL                  | 0.00996032 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -9.28      |
| NumTrajs                | 35         |
| Perplexity              | 4203.86    |
| PolicyExecTime          | 0.57       |
| ProcessExecTime         | 0.0841     |
| StdReturn               | 111        |
| Time                    | 285        |
| dLoss                   | 0.0604444  |
----------------------------------------
itr #26 | 
Mem: 716.105469
Obtaining samples...
Obtaining samples for iteration 26...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5074, #subsample_inputs: 5074
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.579      |
| AbsLearnSignalNew       | 0.579      |
| AbsLearningOld          | 0.579      |
| AverageDiscountedReturn | 48.6       |
| AveragePhiLoss          | 8.91392    |
| AveragePolicyStd        | 0.972298   |
| AverageReturn           | 96.6       |
| Entropy                 | 8.34434    |
| EnvExecTime             | 2.44       |
| ExplainedVariance       | -1.12      |
| Iteration               | 26         |
| ItrTime                 | 11.7       |
| LossAfter               | 1.45838    |
| LossBefore              | 1.51541    |
| MaxReturn               | 482        |
| MeanKL                  | 0.00656857 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -0.257     |
| NumTrajs                | 40         |
| Perplexity              | 4206.29    |
| PolicyExecTime          | 0.573      |
| ProcessExecTime         | 0.0807     |
| StdReturn               | 108        |
| Time                    | 297        |
| dLoss                   | 0.0570304  |
----------------------------------------
itr #27 | 
Mem: 716.105469
Obtaining samples...
Obtaining samples for iteration 27...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5086, #subsample_inputs: 5086
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.757      |
| AbsLearnSignalNew       | 0.757      |
| AbsLearningOld          | 0.757      |
| AverageDiscountedReturn | 35.6       |
| AveragePhiLoss          | 9.24372    |
| AveragePolicyStd        | 0.970392   |
| AverageReturn           | 57.9       |
| Entropy                 | 8.33243    |
| EnvExecTime             | 2.37       |
| ExplainedVariance       | 0.318      |
| Iteration               | 27         |
| ItrTime                 | 9.84       |
| LossAfter               | 0.371893   |
| LossBefore              | 0.431677   |
| MaxReturn               | 332        |
| MeanKL                  | 0.00977746 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -15.1      |
| NumTrajs                | 46         |
| Perplexity              | 4156.49    |
| PolicyExecTime          | 0.548      |
| ProcessExecTime         | 0.0787     |
| StdReturn               | 71.3       |
| Time                    | 307        |
| dLoss                   | 0.0597831  |
----------------------------------------
itr #28 | 
Mem: 716.105469
Obtaining samples...
Obtaining samples for iteration 28...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5021, #subsample_inputs: 5021
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.723      |
| AbsLearnSignalNew       | 0.723      |
| AbsLearningOld          | 0.723      |
| AverageDiscountedReturn | 49.5       |
| AveragePhiLoss          | 8.89758    |
| AveragePolicyStd        | 0.973115   |
| AverageReturn           | 98.9       |
| Entropy                 | 8.34921    |
| EnvExecTime             | 2.51       |
| ExplainedVariance       | 0.0932     |
| Iteration               | 28         |
| ItrTime                 | 11.6       |
| LossAfter               | -0.0763111 |
| LossBefore              | -0.0253835 |
| MaxReturn               | 394        |
| MeanKL                  | 0.00641046 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 2.4        |
| NumTrajs                | 41         |
| Perplexity              | 4226.85    |
| PolicyExecTime          | 0.602      |
| ProcessExecTime         | 0.0839     |
| StdReturn               | 104        |
| Time                    | 318        |
| dLoss                   | 0.0509277  |
----------------------------------------
itr #29 | 
Mem: 721.507812
Obtaining samples...
Obtaining samples for iteration 29...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5062, #subsample_inputs: 5062
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.802      |
| AbsLearnSignalNew       | 0.802      |
| AbsLearningOld          | 0.802      |
| AverageDiscountedReturn | 52.8       |
| AveragePhiLoss          | 8.9805     |
| AveragePolicyStd        | 0.971693   |
| AverageReturn           | 121        |
| Entropy                 | 8.34037    |
| EnvExecTime             | 2.23       |
| ExplainedVariance       | 0.362      |
| Iteration               | 29         |
| ItrTime                 | 10.7       |
| LossAfter               | 0.975007   |
| LossBefore              | 1.02094    |
| MaxReturn               | 438        |
| MeanKL                  | 0.00644774 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -16.4      |
| NumTrajs                | 37         |
| Perplexity              | 4189.64    |
| PolicyExecTime          | 0.504      |
| ProcessExecTime         | 0.071      |
| StdReturn               | 129        |
| Time                    | 329        |
| dLoss                   | 0.0459347  |
----------------------------------------
itr #30 | 
Mem: 721.507812
Obtaining samples...
Obtaining samples for iteration 30...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5114, #subsample_inputs: 5114
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.796      |
| AbsLearnSignalNew       | 0.796      |
| AbsLearningOld          | 0.797      |
| AverageDiscountedReturn | 54.4       |
| AveragePhiLoss          | 8.90386    |
| AveragePolicyStd        | 0.968483   |
| AverageReturn           | 109        |
| Entropy                 | 8.3208     |
| EnvExecTime             | 2.59       |
| ExplainedVariance       | 0.29       |
| Iteration               | 30         |
| ItrTime                 | 10.6       |
| LossAfter               | 0.0577726  |
| LossBefore              | 0.103682   |
| MaxReturn               | 349        |
| MeanKL                  | 0.00646074 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 18.7       |
| NumTrajs                | 35         |
| Perplexity              | 4108.46    |
| PolicyExecTime          | 0.592      |
| ProcessExecTime         | 0.082      |
| StdReturn               | 92.7       |
| Time                    | 340        |
| dLoss                   | 0.0459096  |
----------------------------------------
itr #31 | 
Mem: 722.847656
Obtaining samples...
Obtaining samples for iteration 31...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5058, #subsample_inputs: 5058
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.775      |
| AbsLearnSignalNew       | 0.775      |
| AbsLearningOld          | 0.775      |
| AverageDiscountedReturn | 63.9       |
| AveragePhiLoss          | 9.24152    |
| AveragePolicyStd        | 0.967379   |
| AverageReturn           | 139        |
| Entropy                 | 8.31392    |
| EnvExecTime             | 2.64       |
| ExplainedVariance       | 0.327      |
| Iteration               | 31         |
| ItrTime                 | 11.7       |
| LossAfter               | -0.18169   |
| LossBefore              | -0.123981  |
| MaxReturn               | 315        |
| MeanKL                  | 0.00993107 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -5.61      |
| NumTrajs                | 30         |
| Perplexity              | 4080.27    |
| PolicyExecTime          | 0.623      |
| ProcessExecTime         | 0.0823     |
| StdReturn               | 103        |
| Time                    | 351        |
| dLoss                   | 0.0577092  |
----------------------------------------
itr #32 | 
Mem: 724.136719
Obtaining samples...
Obtaining samples for iteration 32...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5140, #subsample_inputs: 5140
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.766      |
| AbsLearnSignalNew       | 0.766      |
| AbsLearningOld          | 0.766      |
| AverageDiscountedReturn | 63.9       |
| AveragePhiLoss          | 8.74229    |
| AveragePolicyStd        | 0.967313   |
| AverageReturn           | 145        |
| Entropy                 | 8.31348    |
| EnvExecTime             | 2.38       |
| ExplainedVariance       | 0.209      |
| Iteration               | 32         |
| ItrTime                 | 10.7       |
| LossAfter               | -0.22954   |
| LossBefore              | -0.174615  |
| MaxReturn               | 391        |
| MeanKL                  | 0.00980775 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 0.197      |
| NumTrajs                | 31         |
| Perplexity              | 4078.47    |
| PolicyExecTime          | 0.516      |
| ProcessExecTime         | 0.075      |
| StdReturn               | 119        |
| Time                    | 362        |
| dLoss                   | 0.0549248  |
----------------------------------------
itr #33 | 
Mem: 726.707031
Obtaining samples...
Obtaining samples for iteration 33...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5103, #subsample_inputs: 5103
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.784      |
| AbsLearnSignalNew       | 0.784      |
| AbsLearningOld          | 0.784      |
| AverageDiscountedReturn | 71.3       |
| AveragePhiLoss          | 9.05272    |
| AveragePolicyStd        | 0.968678   |
| AverageReturn           | 176        |
| Entropy                 | 8.32178    |
| EnvExecTime             | 2.67       |
| ExplainedVariance       | 0.364      |
| Iteration               | 33         |
| ItrTime                 | 10.9       |
| LossAfter               | 0.0615477  |
| LossBefore              | 0.123312   |
| MaxReturn               | 653        |
| MeanKL                  | 0.00995627 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 44.5       |
| NumTrajs                | 24         |
| Perplexity              | 4112.49    |
| PolicyExecTime          | 0.611      |
| ProcessExecTime         | 0.0873     |
| StdReturn               | 139        |
| Time                    | 373        |
| dLoss                   | 0.0617646  |
----------------------------------------
itr #34 | 
Mem: 726.960938
Obtaining samples...
Obtaining samples for iteration 34...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5017, #subsample_inputs: 5017
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.794      |
| AbsLearnSignalNew       | 0.794      |
| AbsLearningOld          | 0.794      |
| AverageDiscountedReturn | 73.5       |
| AveragePhiLoss          | 8.87386    |
| AveragePolicyStd        | 0.965894   |
| AverageReturn           | 179        |
| Entropy                 | 8.30439    |
| EnvExecTime             | 2.45       |
| ExplainedVariance       | 0.436      |
| Iteration               | 34         |
| ItrTime                 | 11.4       |
| LossAfter               | -0.371452  |
| LossBefore              | -0.31336   |
| MaxReturn               | 433        |
| MeanKL                  | 0.00991908 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 24.5       |
| NumTrajs                | 28         |
| Perplexity              | 4041.58    |
| PolicyExecTime          | 0.566      |
| ProcessExecTime         | 0.0786     |
| StdReturn               | 127        |
| Time                    | 385        |
| dLoss                   | 0.0580926  |
----------------------------------------
itr #35 | 
Mem: 726.960938
Obtaining samples...
Obtaining samples for iteration 35...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5043, #subsample_inputs: 5043
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.764      |
| AbsLearnSignalNew       | 0.764      |
| AbsLearningOld          | 0.765      |
| AverageDiscountedReturn | 80.3       |
| AveragePhiLoss          | 9.19298    |
| AveragePolicyStd        | 0.963062   |
| AverageReturn           | 197        |
| Entropy                 | 8.28643    |
| EnvExecTime             | 2.48       |
| ExplainedVariance       | 0.315      |
| Iteration               | 35         |
| ItrTime                 | 10.2       |
| LossAfter               | 0.0969181  |
| LossBefore              | 0.157385   |
| MaxReturn               | 397        |
| MeanKL                  | 0.00984468 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 13.5       |
| NumTrajs                | 27         |
| Perplexity              | 3969.65    |
| PolicyExecTime          | 0.564      |
| ProcessExecTime         | 0.0775     |
| StdReturn               | 107        |
| Time                    | 395        |
| dLoss                   | 0.0604666  |
----------------------------------------
itr #36 | 
Mem: 726.960938
Obtaining samples...
Obtaining samples for iteration 36...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5326, #subsample_inputs: 5326
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.762      |
| AbsLearnSignalNew       | 0.762      |
| AbsLearningOld          | 0.762      |
| AverageDiscountedReturn | 67.3       |
| AveragePhiLoss          | 9.17193    |
| AveragePolicyStd        | 0.96232    |
| AverageReturn           | 166        |
| Entropy                 | 8.28191    |
| EnvExecTime             | 2.86       |
| ExplainedVariance       | 0.318      |
| Iteration               | 36         |
| ItrTime                 | 12.1       |
| LossAfter               | -0.320443  |
| LossBefore              | -0.263788  |
| MaxReturn               | 548        |
| MeanKL                  | 0.00996362 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 7.25       |
| NumTrajs                | 27         |
| Perplexity              | 3951.72    |
| PolicyExecTime          | 0.671      |
| ProcessExecTime         | 0.0915     |
| StdReturn               | 146        |
| Time                    | 408        |
| dLoss                   | 0.0566548  |
----------------------------------------
itr #37 | 
Mem: 727.218750
Obtaining samples...
Obtaining samples for iteration 37...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5024, #subsample_inputs: 5024
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.801      |
| AbsLearnSignalNew       | 0.801      |
| AbsLearningOld          | 0.801      |
| AverageDiscountedReturn | 80         |
| AveragePhiLoss          | 9.26582    |
| AveragePolicyStd        | 0.959604   |
| AverageReturn           | 195        |
| Entropy                 | 8.26508    |
| EnvExecTime             | 2.16       |
| ExplainedVariance       | 0.376      |
| Iteration               | 37         |
| ItrTime                 | 11.1       |
| LossAfter               | -0.242037  |
| LossBefore              | -0.183935  |
| MaxReturn               | 412        |
| MeanKL                  | 0.00992908 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 16.9       |
| NumTrajs                | 28         |
| Perplexity              | 3885.78    |
| PolicyExecTime          | 0.467      |
| ProcessExecTime         | 0.0637     |
| StdReturn               | 127        |
| Time                    | 419        |
| dLoss                   | 0.0581016  |
----------------------------------------
itr #38 | 
Mem: 727.218750
Obtaining samples...
Obtaining samples for iteration 38...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5149, #subsample_inputs: 5149
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.559      |
| AbsLearnSignalNew       | 0.559      |
| AbsLearningOld          | 0.559      |
| AverageDiscountedReturn | 82.5       |
| AveragePhiLoss          | 9.50095    |
| AveragePolicyStd        | 0.957462   |
| AverageReturn           | 275        |
| Entropy                 | 8.25144    |
| EnvExecTime             | 2.68       |
| ExplainedVariance       | -1.65      |
| Iteration               | 38         |
| ItrTime                 | 10.5       |
| LossAfter               | -0.520651  |
| LossBefore              | -0.465971  |
| MaxReturn               | 588        |
| MeanKL                  | 0.00979341 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 27         |
| NumTrajs                | 21         |
| Perplexity              | 3833.16    |
| PolicyExecTime          | 0.61       |
| ProcessExecTime         | 0.0859     |
| StdReturn               | 149        |
| Time                    | 429        |
| dLoss                   | 0.0546799  |
----------------------------------------
itr #39 | 
Mem: 727.593750
Obtaining samples...
Obtaining samples for iteration 39...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5011, #subsample_inputs: 5011
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.765      |
| AbsLearnSignalNew       | 0.765      |
| AbsLearningOld          | 0.765      |
| AverageDiscountedReturn | 93.8       |
| AveragePhiLoss          | 9.22522    |
| AveragePolicyStd        | 0.954687   |
| AverageReturn           | 250        |
| Entropy                 | 8.23444    |
| EnvExecTime             | 2.64       |
| ExplainedVariance       | 0.375      |
| Iteration               | 39         |
| ItrTime                 | 11.8       |
| LossAfter               | -0.685857  |
| LossBefore              | -0.630915  |
| MaxReturn               | 418        |
| MeanKL                  | 0.00977836 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 31.7       |
| NumTrajs                | 23         |
| Perplexity              | 3768.52    |
| PolicyExecTime          | 0.614      |
| ProcessExecTime         | 0.086      |
| StdReturn               | 110        |
| Time                    | 441        |
| dLoss                   | 0.0549412  |
----------------------------------------
itr #40 | 
Mem: 727.593750
Obtaining samples...
Obtaining samples for iteration 40...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5095, #subsample_inputs: 5095
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.762      |
| AbsLearnSignalNew       | 0.762      |
| AbsLearningOld          | 0.762      |
| AverageDiscountedReturn | 93.9       |
| AveragePhiLoss          | 9.4523     |
| AveragePolicyStd        | 0.956499   |
| AverageReturn           | 237        |
| Entropy                 | 8.24593    |
| EnvExecTime             | 2.24       |
| ExplainedVariance       | 0.434      |
| Iteration               | 40         |
| ItrTime                 | 10.8       |
| LossAfter               | -1.14546   |
| LossBefore              | -1.10018   |
| MaxReturn               | 420        |
| MeanKL                  | 0.00645354 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 22.1       |
| NumTrajs                | 28         |
| Perplexity              | 3812.09    |
| PolicyExecTime          | 0.479      |
| ProcessExecTime         | 0.0651     |
| StdReturn               | 105        |
| Time                    | 452        |
| dLoss                   | 0.0452819  |
----------------------------------------
itr #41 | 
Mem: 728.109375
Obtaining samples...
Obtaining samples for iteration 41...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5284, #subsample_inputs: 5284
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.744      |
| AbsLearnSignalNew       | 0.744      |
| AbsLearningOld          | 0.744      |
| AverageDiscountedReturn | 85.1       |
| AveragePhiLoss          | 9.47113    |
| AveragePolicyStd        | 0.951793   |
| AverageReturn           | 230        |
| Entropy                 | 8.21657    |
| EnvExecTime             | 3.03       |
| ExplainedVariance       | 0.374      |
| Iteration               | 41         |
| ItrTime                 | 11         |
| LossAfter               | -0.388975  |
| LossBefore              | -0.342451  |
| MaxReturn               | 513        |
| MeanKL                  | 0.00652305 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 26.8       |
| NumTrajs                | 26         |
| Perplexity              | 3701.78    |
| PolicyExecTime          | 0.68       |
| ProcessExecTime         | 0.0911     |
| StdReturn               | 136        |
| Time                    | 463        |
| dLoss                   | 0.046524   |
----------------------------------------
itr #42 | 
Mem: 728.882812
Obtaining samples...
Obtaining samples for iteration 42...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5089, #subsample_inputs: 5089
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.763      |
| AbsLearnSignalNew       | 0.763      |
| AbsLearningOld          | 0.763      |
| AverageDiscountedReturn | 77.7       |
| AveragePhiLoss          | 9.81615    |
| AveragePolicyStd        | 0.95123    |
| AverageReturn           | 205        |
| Entropy                 | 8.21276    |
| EnvExecTime             | 2.77       |
| ExplainedVariance       | 0.18       |
| Iteration               | 42         |
| ItrTime                 | 11.9       |
| LossAfter               | 0.160433   |
| LossBefore              | 0.205873   |
| MaxReturn               | 617        |
| MeanKL                  | 0.00645127 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 8.27       |
| NumTrajs                | 24         |
| Perplexity              | 3687.71    |
| PolicyExecTime          | 0.636      |
| ProcessExecTime         | 0.0883     |
| StdReturn               | 154        |
| Time                    | 475        |
| dLoss                   | 0.0454401  |
----------------------------------------
itr #43 | 
Mem: 729.136719
Obtaining samples...
Obtaining samples for iteration 43...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5105, #subsample_inputs: 5105
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.8       |
| AbsLearnSignalNew       | 0.8       |
| AbsLearningOld          | 0.8       |
| AverageDiscountedReturn | 96.3      |
| AveragePhiLoss          | 9.71144   |
| AveragePolicyStd        | 0.95038   |
| AverageReturn           | 230       |
| Entropy                 | 8.20709   |
| EnvExecTime             | 2.26      |
| ExplainedVariance       | 0.471     |
| Iteration               | 43        |
| ItrTime                 | 10.8      |
| LossAfter               | -0.289496 |
| LossBefore              | -0.242191 |
| MaxReturn               | 442       |
| MeanKL                  | 0.0064202 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 21.5      |
| NumTrajs                | 28        |
| Perplexity              | 3666.87   |
| PolicyExecTime          | 0.487     |
| ProcessExecTime         | 0.0683    |
| StdReturn               | 104       |
| Time                    | 486       |
| dLoss                   | 0.0473045 |
---------------------------------------
itr #44 | 
Mem: 729.136719
Obtaining samples...
Obtaining samples for iteration 44...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5058, #subsample_inputs: 5058
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.541      |
| AbsLearnSignalNew       | 0.541      |
| AbsLearningOld          | 0.541      |
| AverageDiscountedReturn | 91.2       |
| AveragePhiLoss          | 8.51451    |
| AveragePolicyStd        | 0.948531   |
| AverageReturn           | 261        |
| Entropy                 | 8.19537    |
| EnvExecTime             | 2.61       |
| ExplainedVariance       | -0.91      |
| Iteration               | 44         |
| ItrTime                 | 10.5       |
| LossAfter               | 0.455211   |
| LossBefore              | 0.504635   |
| MaxReturn               | 505        |
| MeanKL                  | 0.00993684 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 26.9       |
| NumTrajs                | 24         |
| Perplexity              | 3624.15    |
| PolicyExecTime          | 0.611      |
| ProcessExecTime         | 0.085      |
| StdReturn               | 133        |
| Time                    | 497        |
| dLoss                   | 0.0494232  |
----------------------------------------
itr #45 | 
Mem: 729.136719
Obtaining samples...
Obtaining samples for iteration 45...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5134, #subsample_inputs: 5134
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.705      |
| AbsLearnSignalNew       | 0.705      |
| AbsLearningOld          | 0.705      |
| AverageDiscountedReturn | 99.3       |
| AveragePhiLoss          | 9.44696    |
| AveragePolicyStd        | 0.952074   |
| AverageReturn           | 278        |
| Entropy                 | 8.21746    |
| EnvExecTime             | 2.5        |
| ExplainedVariance       | 0.438      |
| Iteration               | 45         |
| ItrTime                 | 11.8       |
| LossAfter               | 0.290618   |
| LossBefore              | 0.336033   |
| MaxReturn               | 409        |
| MeanKL                  | 0.00651667 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 61.8       |
| NumTrajs                | 23         |
| Perplexity              | 3705.08    |
| PolicyExecTime          | 0.587      |
| ProcessExecTime         | 0.0809     |
| StdReturn               | 96.1       |
| Time                    | 509        |
| dLoss                   | 0.0454149  |
----------------------------------------
itr #46 | 
Mem: 729.136719
Obtaining samples...
Obtaining samples for iteration 46...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5066, #subsample_inputs: 5066
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.719      |
| AbsLearnSignalNew       | 0.719      |
| AbsLearningOld          | 0.719      |
| AverageDiscountedReturn | 92.7       |
| AveragePhiLoss          | 9.54346    |
| AveragePolicyStd        | 0.949704   |
| AverageReturn           | 268        |
| Entropy                 | 8.20238    |
| EnvExecTime             | 2.37       |
| ExplainedVariance       | 0.172      |
| Iteration               | 46         |
| ItrTime                 | 10.4       |
| LossAfter               | 0.3614     |
| LossBefore              | 0.418744   |
| MaxReturn               | 741        |
| MeanKL                  | 0.00995987 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 34.6       |
| NumTrajs                | 23         |
| Perplexity              | 3649.61    |
| PolicyExecTime          | 0.527      |
| ProcessExecTime         | 0.0726     |
| StdReturn               | 151        |
| Time                    | 519        |
| dLoss                   | 0.057344   |
----------------------------------------
itr #47 | 
Mem: 729.136719
Obtaining samples...
Obtaining samples for iteration 47...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5166, #subsample_inputs: 5166
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.742      |
| AbsLearnSignalNew       | 0.742      |
| AbsLearningOld          | 0.742      |
| AverageDiscountedReturn | 89.9       |
| AveragePhiLoss          | 10.1393    |
| AveragePolicyStd        | 0.944684   |
| AverageReturn           | 214        |
| Entropy                 | 8.1702     |
| EnvExecTime             | 2.75       |
| ExplainedVariance       | 0.487      |
| Iteration               | 47         |
| ItrTime                 | 11.3       |
| LossAfter               | 0.686952   |
| LossBefore              | 0.736428   |
| MaxReturn               | 447        |
| MeanKL                  | 0.00647819 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 21.6       |
| NumTrajs                | 29         |
| Perplexity              | 3534.05    |
| PolicyExecTime          | 0.63       |
| ProcessExecTime         | 0.0886     |
| StdReturn               | 99.8       |
| Time                    | 531        |
| dLoss                   | 0.0494766  |
----------------------------------------
itr #48 | 
Mem: 729.433594
Obtaining samples...
Obtaining samples for iteration 48...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5050, #subsample_inputs: 5050
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.77       |
| AbsLearnSignalNew       | 0.77       |
| AbsLearningOld          | 0.77       |
| AverageDiscountedReturn | 97.7       |
| AveragePhiLoss          | 9.79803    |
| AveragePolicyStd        | 0.944389   |
| AverageReturn           | 252        |
| Entropy                 | 8.16798    |
| EnvExecTime             | 2.34       |
| ExplainedVariance       | 0.448      |
| Iteration               | 48         |
| ItrTime                 | 11.6       |
| LossAfter               | 0.239467   |
| LossBefore              | 0.295058   |
| MaxReturn               | 417        |
| MeanKL                  | 0.00991399 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 38.9       |
| NumTrajs                | 26         |
| Perplexity              | 3526.23    |
| PolicyExecTime          | 0.551      |
| ProcessExecTime         | 0.075      |
| StdReturn               | 96.6       |
| Time                    | 542        |
| dLoss                   | 0.0555906  |
----------------------------------------
itr #49 | 
Mem: 729.433594
Obtaining samples...
Obtaining samples for iteration 49...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5130, #subsample_inputs: 5130
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.764      |
| AbsLearnSignalNew       | 0.764      |
| AbsLearningOld          | 0.764      |
| AverageDiscountedReturn | 88.2       |
| AveragePhiLoss          | 10.1967    |
| AveragePolicyStd        | 0.941792   |
| AverageReturn           | 191        |
| Entropy                 | 8.15062    |
| EnvExecTime             | 2.64       |
| ExplainedVariance       | 0.517      |
| Iteration               | 49         |
| ItrTime                 | 10.6       |
| LossAfter               | 0.0107414  |
| LossBefore              | 0.0703863  |
| MaxReturn               | 391        |
| MeanKL                  | 0.00986222 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 31         |
| NumTrajs                | 31         |
| Perplexity              | 3465.54    |
| PolicyExecTime          | 0.598      |
| ProcessExecTime         | 0.0835     |
| StdReturn               | 91.7       |
| Time                    | 553        |
| dLoss                   | 0.0596448  |
----------------------------------------
itr #50 | 
Mem: 729.433594
Obtaining samples...
Obtaining samples for iteration 50...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5091, #subsample_inputs: 5091
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.697      |
| AbsLearnSignalNew       | 0.697      |
| AbsLearningOld          | 0.697      |
| AverageDiscountedReturn | 94.5       |
| AveragePhiLoss          | 9.39489    |
| AveragePolicyStd        | 0.941731   |
| AverageReturn           | 246        |
| Entropy                 | 8.14964    |
| EnvExecTime             | 2.64       |
| ExplainedVariance       | 0.291      |
| Iteration               | 50         |
| ItrTime                 | 11         |
| LossAfter               | 0.0993506  |
| LossBefore              | 0.143136   |
| MaxReturn               | 544        |
| MeanKL                  | 0.00649012 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 39.1       |
| NumTrajs                | 26         |
| Perplexity              | 3462.12    |
| PolicyExecTime          | 0.589      |
| ProcessExecTime         | 0.0828     |
| StdReturn               | 121        |
| Time                    | 564        |
| dLoss                   | 0.0437849  |
----------------------------------------
itr #51 | 
Mem: 729.433594
Obtaining samples...
Obtaining samples for iteration 51...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5009, #subsample_inputs: 5009
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.753      |
| AbsLearnSignalNew       | 0.753      |
| AbsLearningOld          | 0.753      |
| AverageDiscountedReturn | 92         |
| AveragePhiLoss          | 9.8792     |
| AveragePolicyStd        | 0.941367   |
| AverageReturn           | 255        |
| Entropy                 | 8.14764    |
| EnvExecTime             | 2.23       |
| ExplainedVariance       | 0.416      |
| Iteration               | 51         |
| ItrTime                 | 11.3       |
| LossAfter               | 0.0631163  |
| LossBefore              | 0.111443   |
| MaxReturn               | 647        |
| MeanKL                  | 0.00641599 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 48.3       |
| NumTrajs                | 24         |
| Perplexity              | 3455.21    |
| PolicyExecTime          | 0.493      |
| ProcessExecTime         | 0.0681     |
| StdReturn               | 141        |
| Time                    | 576        |
| dLoss                   | 0.0483264  |
----------------------------------------
itr #52 | 
Mem: 729.433594
Obtaining samples...
Obtaining samples for iteration 52...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5104, #subsample_inputs: 5104
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.747      |
| AbsLearnSignalNew       | 0.747      |
| AbsLearningOld          | 0.747      |
| AverageDiscountedReturn | 86.3       |
| AveragePhiLoss          | 9.88405    |
| AveragePolicyStd        | 0.940704   |
| AverageReturn           | 214        |
| Entropy                 | 8.14353    |
| EnvExecTime             | 2.59       |
| ExplainedVariance       | 0.44       |
| Iteration               | 52         |
| ItrTime                 | 10.1       |
| LossAfter               | 0.578452   |
| LossBefore              | 0.636413   |
| MaxReturn               | 475        |
| MeanKL                  | 0.00998988 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 2.16       |
| NumTrajs                | 28         |
| Perplexity              | 3441.05    |
| PolicyExecTime          | 0.588      |
| ProcessExecTime         | 0.0845     |
| StdReturn               | 124        |
| Time                    | 586        |
| dLoss                   | 0.057961   |
----------------------------------------
itr #53 | 
Mem: 729.433594
Obtaining samples...
Obtaining samples for iteration 53...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5045, #subsample_inputs: 5045
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.788     |
| AbsLearnSignalNew       | 0.788     |
| AbsLearningOld          | 0.788     |
| AverageDiscountedReturn | 91.3      |
| AveragePhiLoss          | 10.1567   |
| AveragePolicyStd        | 0.936755  |
| AverageReturn           | 246       |
| Entropy                 | 8.11837   |
| EnvExecTime             | 2.66      |
| ExplainedVariance       | 0.446     |
| Iteration               | 53        |
| ItrTime                 | 11.8      |
| LossAfter               | 0.748463  |
| LossBefore              | 0.804322  |
| MaxReturn               | 455       |
| MeanKL                  | 0.0099272 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 24.3      |
| NumTrajs                | 26        |
| Perplexity              | 3355.56   |
| PolicyExecTime          | 0.616     |
| ProcessExecTime         | 0.0833    |
| StdReturn               | 137       |
| Time                    | 598       |
| dLoss                   | 0.0558595 |
---------------------------------------
itr #54 | 
Mem: 729.433594
Obtaining samples...
Obtaining samples for iteration 54...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5206, #subsample_inputs: 5206
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.697      |
| AbsLearnSignalNew       | 0.697      |
| AbsLearningOld          | 0.697      |
| AverageDiscountedReturn | 103        |
| AveragePhiLoss          | 10.2153    |
| AveragePolicyStd        | 0.933066   |
| AverageReturn           | 294        |
| Entropy                 | 8.09476    |
| EnvExecTime             | 2.4        |
| ExplainedVariance       | 0.439      |
| Iteration               | 54         |
| ItrTime                 | 11.2       |
| LossAfter               | 0.575292   |
| LossBefore              | 0.640981   |
| MaxReturn               | 489        |
| MeanKL                  | 0.00990665 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 104        |
| NumTrajs                | 22         |
| Perplexity              | 3277.26    |
| PolicyExecTime          | 0.521      |
| ProcessExecTime         | 0.0703     |
| StdReturn               | 95.3       |
| Time                    | 609        |
| dLoss                   | 0.0656889  |
----------------------------------------
itr #55 | 
Mem: 729.433594
Obtaining samples...
Obtaining samples for iteration 55...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5017, #subsample_inputs: 5017
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.739      |
| AbsLearnSignalNew       | 0.739      |
| AbsLearningOld          | 0.739      |
| AverageDiscountedReturn | 96.1       |
| AveragePhiLoss          | 9.96055    |
| AveragePolicyStd        | 0.93491    |
| AverageReturn           | 260        |
| Entropy                 | 8.1068     |
| EnvExecTime             | 2.84       |
| ExplainedVariance       | 0.474      |
| Iteration               | 55         |
| ItrTime                 | 11         |
| LossAfter               | -0.12483   |
| LossBefore              | -0.0675635 |
| MaxReturn               | 425        |
| MeanKL                  | 0.0099433  |
| MeanKLBefore            | 0.0        |
| MinReturn               | 36.7       |
| NumTrajs                | 25         |
| Perplexity              | 3316.94    |
| PolicyExecTime          | 0.657      |
| ProcessExecTime         | 0.088      |
| StdReturn               | 104        |
| Time                    | 620        |
| dLoss                   | 0.0572667  |
----------------------------------------
itr #56 | 
Mem: 729.433594
Obtaining samples...
Obtaining samples for iteration 56...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5083, #subsample_inputs: 5083
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.748      |
| AbsLearnSignalNew       | 0.748      |
| AbsLearningOld          | 0.748      |
| AverageDiscountedReturn | 91.1       |
| AveragePhiLoss          | 9.91643    |
| AveragePolicyStd        | 0.937086   |
| AverageReturn           | 237        |
| Entropy                 | 8.12038    |
| EnvExecTime             | 2.59       |
| ExplainedVariance       | 0.432      |
| Iteration               | 56         |
| ItrTime                 | 11.7       |
| LossAfter               | 0.408056   |
| LossBefore              | 0.465741   |
| MaxReturn               | 613        |
| MeanKL                  | 0.00986722 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 33.7       |
| NumTrajs                | 27         |
| Perplexity              | 3362.31    |
| PolicyExecTime          | 0.591      |
| ProcessExecTime         | 0.0791     |
| StdReturn               | 137        |
| Time                    | 632        |
| dLoss                   | 0.0576852  |
----------------------------------------
itr #57 | 
Mem: 730.203125
Obtaining samples...
Obtaining samples for iteration 57...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5063, #subsample_inputs: 5063
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.742      |
| AbsLearnSignalNew       | 0.742      |
| AbsLearningOld          | 0.742      |
| AverageDiscountedReturn | 95.4       |
| AveragePhiLoss          | 10.061     |
| AveragePolicyStd        | 0.935039   |
| AverageReturn           | 264        |
| Entropy                 | 8.10664    |
| EnvExecTime             | 2.64       |
| ExplainedVariance       | 0.459      |
| Iteration               | 57         |
| ItrTime                 | 11.1       |
| LossAfter               | 0.0890614  |
| LossBefore              | 0.137333   |
| MaxReturn               | 457        |
| MeanKL                  | 0.00650193 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 15         |
| NumTrajs                | 24         |
| Perplexity              | 3316.43    |
| PolicyExecTime          | 0.567      |
| ProcessExecTime         | 0.0766     |
| StdReturn               | 114        |
| Time                    | 643        |
| dLoss                   | 0.0482717  |
----------------------------------------
itr #58 | 
Mem: 730.203125
Obtaining samples...
Obtaining samples for iteration 58...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5023, #subsample_inputs: 5023
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.651      |
| AbsLearnSignalNew       | 0.651      |
| AbsLearningOld          | 0.651      |
| AverageDiscountedReturn | 101        |
| AveragePhiLoss          | 9.99188    |
| AveragePolicyStd        | 0.932121   |
| AverageReturn           | 295        |
| Entropy                 | 8.08791    |
| EnvExecTime             | 2.66       |
| ExplainedVariance       | 0.0134     |
| Iteration               | 58         |
| ItrTime                 | 10.9       |
| LossAfter               | 0.324154   |
| LossBefore              | 0.382805   |
| MaxReturn               | 682        |
| MeanKL                  | 0.00978685 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 38.3       |
| NumTrajs                | 23         |
| Perplexity              | 3254.88    |
| PolicyExecTime          | 0.616      |
| ProcessExecTime         | 0.0874     |
| StdReturn               | 132        |
| Time                    | 654        |
| dLoss                   | 0.0586509  |
----------------------------------------
itr #59 | 
Mem: 730.203125
Obtaining samples...
Obtaining samples for iteration 59...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5263, #subsample_inputs: 5263
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.724      |
| AbsLearnSignalNew       | 0.724      |
| AbsLearningOld          | 0.723      |
| AverageDiscountedReturn | 103        |
| AveragePhiLoss          | 10.7392    |
| AveragePolicyStd        | 0.934875   |
| AverageReturn           | 275        |
| Entropy                 | 8.10546    |
| EnvExecTime             | 2.6        |
| ExplainedVariance       | 0.48       |
| Iteration               | 59         |
| ItrTime                 | 11.9       |
| LossAfter               | -0.124043  |
| LossBefore              | -0.0753501 |
| MaxReturn               | 424        |
| MeanKL                  | 0.00644901 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 51.3       |
| NumTrajs                | 26         |
| Perplexity              | 3312.51    |
| PolicyExecTime          | 0.575      |
| ProcessExecTime         | 0.0807     |
| StdReturn               | 90.7       |
| Time                    | 666        |
| dLoss                   | 0.0486927  |
----------------------------------------
itr #60 | 
Mem: 730.976562
Obtaining samples...
Obtaining samples for iteration 60...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5056, #subsample_inputs: 5056
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.711      |
| AbsLearnSignalNew       | 0.711      |
| AbsLearningOld          | 0.711      |
| AverageDiscountedReturn | 101        |
| AveragePhiLoss          | 9.98898    |
| AveragePolicyStd        | 0.934403   |
| AverageReturn           | 269        |
| Entropy                 | 8.10209    |
| EnvExecTime             | 2.43       |
| ExplainedVariance       | 0.592      |
| Iteration               | 60         |
| ItrTime                 | 10.7       |
| LossAfter               | 0.078463   |
| LossBefore              | 0.125269   |
| MaxReturn               | 421        |
| MeanKL                  | 0.00645698 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 9.49       |
| NumTrajs                | 24         |
| Perplexity              | 3301.35    |
| PolicyExecTime          | 0.531      |
| ProcessExecTime         | 0.0729     |
| StdReturn               | 94         |
| Time                    | 677        |
| dLoss                   | 0.0468065  |
----------------------------------------
itr #61 | 
Mem: 730.976562
Obtaining samples...
Obtaining samples for iteration 61...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5061, #subsample_inputs: 5061
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.745     |
| AbsLearnSignalNew       | 0.745     |
| AbsLearningOld          | 0.745     |
| AverageDiscountedReturn | 103       |
| AveragePhiLoss          | 10.5759   |
| AveragePolicyStd        | 0.932622  |
| AverageReturn           | 304       |
| Entropy                 | 8.09122   |
| EnvExecTime             | 2.6       |
| ExplainedVariance       | 0.385     |
| Iteration               | 61        |
| ItrTime                 | 10.9      |
| LossAfter               | 0.0959398 |
| LossBefore              | 0.14403   |
| MaxReturn               | 526       |
| MeanKL                  | 0.0064531 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 52.2      |
| NumTrajs                | 23        |
| Perplexity              | 3265.68   |
| PolicyExecTime          | 0.573     |
| ProcessExecTime         | 0.0827    |
| StdReturn               | 119       |
| Time                    | 688       |
| dLoss                   | 0.0480905 |
---------------------------------------
itr #62 | 
Mem: 730.976562
Obtaining samples...
Obtaining samples for iteration 62...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5151, #subsample_inputs: 5151
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.752      |
| AbsLearnSignalNew       | 0.752      |
| AbsLearningOld          | 0.752      |
| AverageDiscountedReturn | 108        |
| AveragePhiLoss          | 10.3946    |
| AveragePolicyStd        | 0.93275    |
| AverageReturn           | 294        |
| Entropy                 | 8.09256    |
| EnvExecTime             | 2.45       |
| ExplainedVariance       | 0.426      |
| Iteration               | 62         |
| ItrTime                 | 11.6       |
| LossAfter               | 0.328778   |
| LossBefore              | 0.384839   |
| MaxReturn               | 567        |
| MeanKL                  | 0.00978607 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 83.3       |
| NumTrajs                | 25         |
| Perplexity              | 3270.04    |
| PolicyExecTime          | 0.539      |
| ProcessExecTime         | 0.0745     |
| StdReturn               | 84         |
| Time                    | 700        |
| dLoss                   | 0.0560611  |
----------------------------------------
itr #63 | 
Mem: 731.500000
Obtaining samples...
Obtaining samples for iteration 63...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5082, #subsample_inputs: 5082
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.73       |
| AbsLearnSignalNew       | 0.73       |
| AbsLearningOld          | 0.73       |
| AverageDiscountedReturn | 104        |
| AveragePhiLoss          | 10.5547    |
| AveragePolicyStd        | 0.934924   |
| AverageReturn           | 321        |
| Entropy                 | 8.10684    |
| EnvExecTime             | 2.89       |
| ExplainedVariance       | 0.381      |
| Iteration               | 63         |
| ItrTime                 | 11.3       |
| LossAfter               | -0.0540197 |
| LossBefore              | 0.00451417 |
| MaxReturn               | 611        |
| MeanKL                  | 0.00998326 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 73.2       |
| NumTrajs                | 23         |
| Perplexity              | 3317.06    |
| PolicyExecTime          | 0.643      |
| ProcessExecTime         | 0.0827     |
| StdReturn               | 130        |
| Time                    | 711        |
| dLoss                   | 0.0585339  |
----------------------------------------
itr #64 | 
Mem: 732.316406
Obtaining samples...
Obtaining samples for iteration 64...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5057, #subsample_inputs: 5057
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.666      |
| AbsLearnSignalNew       | 0.666      |
| AbsLearningOld          | 0.666      |
| AverageDiscountedReturn | 106        |
| AveragePhiLoss          | 10.4402    |
| AveragePolicyStd        | 0.936083   |
| AverageReturn           | 308        |
| Entropy                 | 8.11494    |
| EnvExecTime             | 2.69       |
| ExplainedVariance       | 0.281      |
| Iteration               | 64         |
| ItrTime                 | 11         |
| LossAfter               | 0.224155   |
| LossBefore              | 0.268123   |
| MaxReturn               | 581        |
| MeanKL                  | 0.00643978 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 126        |
| NumTrajs                | 22         |
| Perplexity              | 3344.05    |
| PolicyExecTime          | 0.591      |
| ProcessExecTime         | 0.0843     |
| StdReturn               | 121        |
| Time                    | 722        |
| dLoss                   | 0.0439682  |
----------------------------------------
itr #65 | 
Mem: 732.574219
Obtaining samples...
Obtaining samples for iteration 65...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5157, #subsample_inputs: 5157
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.753      |
| AbsLearnSignalNew       | 0.753      |
| AbsLearningOld          | 0.753      |
| AverageDiscountedReturn | 104        |
| AveragePhiLoss          | 10.3989    |
| AveragePolicyStd        | 0.934205   |
| AverageReturn           | 317        |
| Entropy                 | 8.10255    |
| EnvExecTime             | 2.58       |
| ExplainedVariance       | 0.546      |
| Iteration               | 65         |
| ItrTime                 | 11.7       |
| LossAfter               | 0.321575   |
| LossBefore              | 0.377018   |
| MaxReturn               | 616        |
| MeanKL                  | 0.00988905 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 63.2       |
| NumTrajs                | 22         |
| Perplexity              | 3302.89    |
| PolicyExecTime          | 0.572      |
| ProcessExecTime         | 0.0797     |
| StdReturn               | 113        |
| Time                    | 734        |
| dLoss                   | 0.0554429  |
----------------------------------------
itr #66 | 
Mem: 732.574219
Obtaining samples...
Obtaining samples for iteration 66...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5140, #subsample_inputs: 5140
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.749      |
| AbsLearnSignalNew       | 0.749      |
| AbsLearningOld          | 0.749      |
| AverageDiscountedReturn | 96.2       |
| AveragePhiLoss          | 10.4865    |
| AveragePolicyStd        | 0.932306   |
| AverageReturn           | 250        |
| Entropy                 | 8.08944    |
| EnvExecTime             | 2.51       |
| ExplainedVariance       | 0.402      |
| Iteration               | 66         |
| ItrTime                 | 10.8       |
| LossAfter               | 0.515279   |
| LossBefore              | 0.569063   |
| MaxReturn               | 625        |
| MeanKL                  | 0.00994612 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 51.8       |
| NumTrajs                | 26         |
| Perplexity              | 3259.86    |
| PolicyExecTime          | 0.558      |
| ProcessExecTime         | 0.0748     |
| StdReturn               | 132        |
| Time                    | 745        |
| dLoss                   | 0.0537835  |
----------------------------------------
itr #67 | 
Mem: 732.574219
Obtaining samples...
Obtaining samples for iteration 67...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5020, #subsample_inputs: 5020
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.769      |
| AbsLearnSignalNew       | 0.769      |
| AbsLearningOld          | 0.769      |
| AverageDiscountedReturn | 109        |
| AveragePhiLoss          | 10.3404    |
| AveragePolicyStd        | 0.928705   |
| AverageReturn           | 326        |
| Entropy                 | 8.06621    |
| EnvExecTime             | 2.73       |
| ExplainedVariance       | 0.478      |
| Iteration               | 67         |
| ItrTime                 | 11.2       |
| LossAfter               | 0.206642   |
| LossBefore              | 0.264587   |
| MaxReturn               | 577        |
| MeanKL                  | 0.00989903 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 116        |
| NumTrajs                | 22         |
| Perplexity              | 3185.01    |
| PolicyExecTime          | 0.601      |
| ProcessExecTime         | 0.084      |
| StdReturn               | 119        |
| Time                    | 756        |
| dLoss                   | 0.0579448  |
----------------------------------------
itr #68 | 
Mem: 732.574219
Obtaining samples...
Obtaining samples for iteration 68...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5037, #subsample_inputs: 5037
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.712      |
| AbsLearnSignalNew       | 0.712      |
| AbsLearningOld          | 0.712      |
| AverageDiscountedReturn | 109        |
| AveragePhiLoss          | 10.0171    |
| AveragePolicyStd        | 0.930519   |
| AverageReturn           | 325        |
| Entropy                 | 8.07781    |
| EnvExecTime             | 2.35       |
| ExplainedVariance       | 0.485      |
| Iteration               | 68         |
| ItrTime                 | 11.4       |
| LossAfter               | 0.95402    |
| LossBefore              | 0.999686   |
| MaxReturn               | 541        |
| MeanKL                  | 0.00651668 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 110        |
| NumTrajs                | 22         |
| Perplexity              | 3222.18    |
| PolicyExecTime          | 0.503      |
| ProcessExecTime         | 0.0697     |
| StdReturn               | 82.2       |
| Time                    | 768        |
| dLoss                   | 0.0456662  |
----------------------------------------
itr #69 | 
Mem: 732.574219
Obtaining samples...
Obtaining samples for iteration 69...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5059, #subsample_inputs: 5059
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.741      |
| AbsLearnSignalNew       | 0.741      |
| AbsLearningOld          | 0.741      |
| AverageDiscountedReturn | 106        |
| AveragePhiLoss          | 10.7515    |
| AveragePolicyStd        | 0.928585   |
| AverageReturn           | 281        |
| Entropy                 | 8.0655     |
| EnvExecTime             | 2.78       |
| ExplainedVariance       | 0.474      |
| Iteration               | 69         |
| ItrTime                 | 10.5       |
| LossAfter               | -0.0238067 |
| LossBefore              | 0.0228058  |
| MaxReturn               | 564        |
| MeanKL                  | 0.00649387 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 79.9       |
| NumTrajs                | 25         |
| Perplexity              | 3182.76    |
| PolicyExecTime          | 0.628      |
| ProcessExecTime         | 0.0861     |
| StdReturn               | 112        |
| Time                    | 778        |
| dLoss                   | 0.0466124  |
----------------------------------------
itr #70 | 
Mem: 732.574219
Obtaining samples...
Obtaining samples for iteration 70...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5116, #subsample_inputs: 5116
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.747      |
| AbsLearnSignalNew       | 0.747      |
| AbsLearningOld          | 0.747      |
| AverageDiscountedReturn | 106        |
| AveragePhiLoss          | 10.9007    |
| AveragePolicyStd        | 0.925818   |
| AverageReturn           | 322        |
| Entropy                 | 8.04765    |
| EnvExecTime             | 2.87       |
| ExplainedVariance       | 0.413      |
| Iteration               | 70         |
| ItrTime                 | 11.9       |
| LossAfter               | 0.475284   |
| LossBefore              | 0.523636   |
| MaxReturn               | 550        |
| MeanKL                  | 0.00642956 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 47.7       |
| NumTrajs                | 23         |
| Perplexity              | 3126.43    |
| PolicyExecTime          | 0.637      |
| ProcessExecTime         | 0.088      |
| StdReturn               | 105        |
| Time                    | 790        |
| dLoss                   | 0.0483528  |
----------------------------------------
itr #71 | 
Mem: 732.574219
Obtaining samples...
Obtaining samples for iteration 71...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5150, #subsample_inputs: 5150
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.734      |
| AbsLearnSignalNew       | 0.734      |
| AbsLearningOld          | 0.734      |
| AverageDiscountedReturn | 103        |
| AveragePhiLoss          | 10.1668    |
| AveragePolicyStd        | 0.924159   |
| AverageReturn           | 340        |
| Entropy                 | 8.03727    |
| EnvExecTime             | 2.33       |
| ExplainedVariance       | 0.564      |
| Iteration               | 71         |
| ItrTime                 | 11.4       |
| LossAfter               | -0.11802   |
| LossBefore              | -0.0623077 |
| MaxReturn               | 660        |
| MeanKL                  | 0.00963536 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 44.7       |
| NumTrajs                | 21         |
| Perplexity              | 3094.15    |
| PolicyExecTime          | 0.486      |
| ProcessExecTime         | 0.0675     |
| StdReturn               | 140        |
| Time                    | 802        |
| dLoss                   | 0.0557127  |
----------------------------------------
itr #72 | 
Mem: 732.574219
Obtaining samples...
Obtaining samples for iteration 72...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5611, #subsample_inputs: 5611
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.698     |
| AbsLearnSignalNew       | 0.698     |
| AbsLearningOld          | 0.698     |
| AverageDiscountedReturn | 103       |
| AveragePhiLoss          | 10.1446   |
| AveragePolicyStd        | 0.924959  |
| AverageReturn           | 317       |
| Entropy                 | 8.04243   |
| EnvExecTime             | 2.97      |
| ExplainedVariance       | 0.533     |
| Iteration               | 72        |
| ItrTime                 | 11.2      |
| LossAfter               | -0.187126 |
| LossBefore              | -0.142033 |
| MaxReturn               | 742       |
| MeanKL                  | 0.006451  |
| MeanKLBefore            | 0.0       |
| MinReturn               | 57.7      |
| NumTrajs                | 24        |
| Perplexity              | 3110.15   |
| PolicyExecTime          | 0.661     |
| ProcessExecTime         | 0.0914    |
| StdReturn               | 144       |
| Time                    | 813       |
| dLoss                   | 0.0450933 |
---------------------------------------
itr #73 | 
Mem: 733.343750
Obtaining samples...
Obtaining samples for iteration 73...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5133, #subsample_inputs: 5133
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.735      |
| AbsLearnSignalNew       | 0.735      |
| AbsLearningOld          | 0.735      |
| AverageDiscountedReturn | 97.8       |
| AveragePhiLoss          | 10.6096    |
| AveragePolicyStd        | 0.923178   |
| AverageReturn           | 341        |
| Entropy                 | 8.03096    |
| EnvExecTime             | 2.8        |
| ExplainedVariance       | 0.497      |
| Iteration               | 73         |
| ItrTime                 | 12         |
| LossAfter               | -0.398381  |
| LossBefore              | -0.35483   |
| MaxReturn               | 847        |
| MeanKL                  | 0.00644368 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 70.3       |
| NumTrajs                | 19         |
| Perplexity              | 3074.69    |
| PolicyExecTime          | 0.62       |
| ProcessExecTime         | 0.0861     |
| StdReturn               | 215        |
| Time                    | 825        |
| dLoss                   | 0.0435507  |
----------------------------------------
itr #74 | 
Mem: 733.632812
Obtaining samples...
Obtaining samples for iteration 74...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5029, #subsample_inputs: 5029
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.763      |
| AbsLearnSignalNew       | 0.763      |
| AbsLearningOld          | 0.763      |
| AverageDiscountedReturn | 116        |
| AveragePhiLoss          | 10.722     |
| AveragePolicyStd        | 0.921277   |
| AverageReturn           | 336        |
| Entropy                 | 8.01831    |
| EnvExecTime             | 2.34       |
| ExplainedVariance       | 0.58       |
| Iteration               | 74         |
| ItrTime                 | 11.3       |
| LossAfter               | -0.33382   |
| LossBefore              | -0.289298  |
| MaxReturn               | 663        |
| MeanKL                  | 0.00645295 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 196        |
| NumTrajs                | 24         |
| Perplexity              | 3036.04    |
| PolicyExecTime          | 0.476      |
| ProcessExecTime         | 0.0674     |
| StdReturn               | 110        |
| Time                    | 837        |
| dLoss                   | 0.044522   |
----------------------------------------
itr #75 | 
Mem: 733.632812
Obtaining samples...
Obtaining samples for iteration 75...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5056, #subsample_inputs: 5056
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.64       |
| AbsLearnSignalNew       | 0.64       |
| AbsLearningOld          | 0.64       |
| AverageDiscountedReturn | 109        |
| AveragePhiLoss          | 10.4172    |
| AveragePolicyStd        | 0.920223   |
| AverageReturn           | 331        |
| Entropy                 | 8.01192    |
| EnvExecTime             | 2.65       |
| ExplainedVariance       | 0.319      |
| Iteration               | 75         |
| ItrTime                 | 10.6       |
| LossAfter               | 0.0288275  |
| LossBefore              | 0.0792901  |
| MaxReturn               | 678        |
| MeanKL                  | 0.00993598 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 139        |
| NumTrajs                | 22         |
| Perplexity              | 3016.69    |
| PolicyExecTime          | 0.6        |
| ProcessExecTime         | 0.0845     |
| StdReturn               | 109        |
| Time                    | 848        |
| dLoss                   | 0.0504627  |
----------------------------------------
itr #76 | 
Mem: 733.632812
Obtaining samples...
Obtaining samples for iteration 76...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5164, #subsample_inputs: 5164
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.729      |
| AbsLearnSignalNew       | 0.729      |
| AbsLearningOld          | 0.729      |
| AverageDiscountedReturn | 112        |
| AveragePhiLoss          | 10.8007    |
| AveragePolicyStd        | 0.918908   |
| AverageReturn           | 338        |
| Entropy                 | 8.00291    |
| EnvExecTime             | 2.91       |
| ExplainedVariance       | 0.482      |
| Iteration               | 76         |
| ItrTime                 | 12.3       |
| LossAfter               | 0.00294822 |
| LossBefore              | 0.0503581  |
| MaxReturn               | 506        |
| MeanKL                  | 0.00647669 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 71.8       |
| NumTrajs                | 24         |
| Perplexity              | 2989.66    |
| PolicyExecTime          | 0.67       |
| ProcessExecTime         | 0.0877     |
| StdReturn               | 104        |
| Time                    | 860        |
| dLoss                   | 0.0474099  |
----------------------------------------
itr #77 | 
Mem: 733.632812
Obtaining samples...
Obtaining samples for iteration 77...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5100, #subsample_inputs: 5100
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.687      |
| AbsLearnSignalNew       | 0.687      |
| AbsLearningOld          | 0.687      |
| AverageDiscountedReturn | 111        |
| AveragePhiLoss          | 10.8093    |
| AveragePolicyStd        | 0.919574   |
| AverageReturn           | 340        |
| Entropy                 | 8.00771    |
| EnvExecTime             | 2.39       |
| ExplainedVariance       | 0.626      |
| Iteration               | 77         |
| ItrTime                 | 10.8       |
| LossAfter               | -0.335068  |
| LossBefore              | -0.291711  |
| MaxReturn               | 550        |
| MeanKL                  | 0.00644943 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 67.6       |
| NumTrajs                | 23         |
| Perplexity              | 3004.02    |
| PolicyExecTime          | 0.499      |
| ProcessExecTime         | 0.0695     |
| StdReturn               | 88.2       |
| Time                    | 871        |
| dLoss                   | 0.0433576  |
----------------------------------------
itr #78 | 
Mem: 733.632812
Obtaining samples...
Obtaining samples for iteration 78...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5004, #subsample_inputs: 5004
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.697      |
| AbsLearnSignalNew       | 0.697      |
| AbsLearningOld          | 0.697      |
| AverageDiscountedReturn | 107        |
| AveragePhiLoss          | 10.4842    |
| AveragePolicyStd        | 0.916974   |
| AverageReturn           | 340        |
| Entropy                 | 7.99118    |
| EnvExecTime             | 2.69       |
| ExplainedVariance       | 0.516      |
| Iteration               | 78         |
| ItrTime                 | 10.6       |
| LossAfter               | -0.362083  |
| LossBefore              | -0.318208  |
| MaxReturn               | 695        |
| MeanKL                  | 0.00641381 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 67         |
| NumTrajs                | 21         |
| Perplexity              | 2954.79    |
| PolicyExecTime          | 0.596      |
| ProcessExecTime         | 0.0861     |
| StdReturn               | 134        |
| Time                    | 882        |
| dLoss                   | 0.0438754  |
----------------------------------------
itr #79 | 
Mem: 733.632812
Obtaining samples...
Obtaining samples for iteration 79...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5105, #subsample_inputs: 5105
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.754      |
| AbsLearnSignalNew       | 0.754      |
| AbsLearningOld          | 0.754      |
| AverageDiscountedReturn | 111        |
| AveragePhiLoss          | 10.6686    |
| AveragePolicyStd        | 0.917411   |
| AverageReturn           | 296        |
| Entropy                 | 7.99457    |
| EnvExecTime             | 2.72       |
| ExplainedVariance       | 0.61       |
| Iteration               | 79         |
| ItrTime                 | 12.1       |
| LossAfter               | 0.827796   |
| LossBefore              | 0.886008   |
| MaxReturn               | 502        |
| MeanKL                  | 0.00991011 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 93.5       |
| NumTrajs                | 27         |
| Perplexity              | 2964.82    |
| PolicyExecTime          | 0.636      |
| ProcessExecTime         | 0.0853     |
| StdReturn               | 83.3       |
| Time                    | 894        |
| dLoss                   | 0.0582119  |
----------------------------------------
itr #80 | 
Mem: 733.632812
Obtaining samples...
Obtaining samples for iteration 80...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5283, #subsample_inputs: 5283
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.747      |
| AbsLearnSignalNew       | 0.747      |
| AbsLearningOld          | 0.747      |
| AverageDiscountedReturn | 109        |
| AveragePhiLoss          | 10.3307    |
| AveragePolicyStd        | 0.919257   |
| AverageReturn           | 311        |
| Entropy                 | 8.00694    |
| EnvExecTime             | 2.71       |
| ExplainedVariance       | 0.557      |
| Iteration               | 80         |
| ItrTime                 | 11.3       |
| LossAfter               | 0.708421   |
| LossBefore              | 0.760665   |
| MaxReturn               | 437        |
| MeanKL                  | 0.00991529 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 94.1       |
| NumTrajs                | 25         |
| Perplexity              | 3001.72    |
| PolicyExecTime          | 0.581      |
| ProcessExecTime         | 0.0797     |
| StdReturn               | 88.1       |
| Time                    | 905        |
| dLoss                   | 0.0522436  |
----------------------------------------
itr #81 | 
Mem: 735.183594
Obtaining samples...
Obtaining samples for iteration 81...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5106, #subsample_inputs: 5106
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.276      |
| AbsLearnSignalNew       | 0.276      |
| AbsLearningOld          | 0.276      |
| AverageDiscountedReturn | 118        |
| AveragePhiLoss          | 11.3256    |
| AveragePolicyStd        | 0.918124   |
| AverageReturn           | 353        |
| Entropy                 | 7.99951    |
| EnvExecTime             | 2.82       |
| ExplainedVariance       | -31        |
| Iteration               | 81         |
| ItrTime                 | 10.9       |
| LossAfter               | 0.0112966  |
| LossBefore              | 0.0560612  |
| MaxReturn               | 809        |
| MeanKL                  | 0.00997621 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 250        |
| NumTrajs                | 23         |
| Perplexity              | 2979.49    |
| PolicyExecTime          | 0.621      |
| ProcessExecTime         | 0.0862     |
| StdReturn               | 108        |
| Time                    | 916        |
| dLoss                   | 0.0447647  |
----------------------------------------
itr #82 | 
Mem: 735.183594
Obtaining samples...
Obtaining samples for iteration 82...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5414, #subsample_inputs: 5414
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.672      |
| AbsLearnSignalNew       | 0.672      |
| AbsLearningOld          | 0.672      |
| AverageDiscountedReturn | 114        |
| AveragePhiLoss          | 11.2356    |
| AveragePolicyStd        | 0.916249   |
| AverageReturn           | 338        |
| Entropy                 | 7.98691    |
| EnvExecTime             | 2.7        |
| ExplainedVariance       | 0.479      |
| Iteration               | 82         |
| ItrTime                 | 12.4       |
| LossAfter               | 0.0243999  |
| LossBefore              | 0.0643429  |
| MaxReturn               | 677        |
| MeanKL                  | 0.00649643 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 184        |
| NumTrajs                | 23         |
| Perplexity              | 2942.19    |
| PolicyExecTime          | 0.62       |
| ProcessExecTime         | 0.0813     |
| StdReturn               | 104        |
| Time                    | 929        |
| dLoss                   | 0.039943   |
----------------------------------------
itr #83 | 
Mem: 736.730469
Obtaining samples...
Obtaining samples for iteration 83...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5171, #subsample_inputs: 5171
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.772      |
| AbsLearnSignalNew       | 0.772      |
| AbsLearningOld          | 0.772      |
| AverageDiscountedReturn | 114        |
| AveragePhiLoss          | 10.6775    |
| AveragePolicyStd        | 0.91338    |
| AverageReturn           | 342        |
| Entropy                 | 7.96781    |
| EnvExecTime             | 2.84       |
| ExplainedVariance       | 0.553      |
| Iteration               | 83         |
| ItrTime                 | 11         |
| LossAfter               | -0.0188634 |
| LossBefore              | 0.0241475  |
| MaxReturn               | 555        |
| MeanKL                  | 0.0064142  |
| MeanKLBefore            | 0.0        |
| MinReturn               | 215        |
| NumTrajs                | 23         |
| Perplexity              | 2886.53    |
| PolicyExecTime          | 0.61       |
| ProcessExecTime         | 0.083      |
| StdReturn               | 87.3       |
| Time                    | 940        |
| dLoss                   | 0.0430108  |
----------------------------------------
itr #84 | 
Mem: 736.730469
Obtaining samples...
Obtaining samples for iteration 84...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5212, #subsample_inputs: 5212
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.737      |
| AbsLearnSignalNew       | 0.737      |
| AbsLearningOld          | 0.737      |
| AverageDiscountedReturn | 104        |
| AveragePhiLoss          | 11.1646    |
| AveragePolicyStd        | 0.913277   |
| AverageReturn           | 323        |
| Entropy                 | 7.96691    |
| EnvExecTime             | 2.9        |
| ExplainedVariance       | 0.485      |
| Iteration               | 84         |
| ItrTime                 | 11.5       |
| LossAfter               | -0.493809  |
| LossBefore              | -0.450348  |
| MaxReturn               | 569        |
| MeanKL                  | 0.00649259 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 2.94       |
| NumTrajs                | 23         |
| Perplexity              | 2883.93    |
| PolicyExecTime          | 0.64       |
| ProcessExecTime         | 0.0881     |
| StdReturn               | 129        |
| Time                    | 952        |
| dLoss                   | 0.0434613  |
----------------------------------------
itr #85 | 
Mem: 737.246094
Obtaining samples...
Obtaining samples for iteration 85...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5021, #subsample_inputs: 5021
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.794      |
| AbsLearnSignalNew       | 0.794      |
| AbsLearningOld          | 0.794      |
| AverageDiscountedReturn | 116        |
| AveragePhiLoss          | 10.8438    |
| AveragePolicyStd        | 0.908767   |
| AverageReturn           | 386        |
| Entropy                 | 7.93697    |
| EnvExecTime             | 2.57       |
| ExplainedVariance       | 0.713      |
| Iteration               | 85         |
| ItrTime                 | 11.8       |
| LossAfter               | -0.231399  |
| LossBefore              | -0.186365  |
| MaxReturn               | 693        |
| MeanKL                  | 0.00644015 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 257        |
| NumTrajs                | 20         |
| Perplexity              | 2798.88    |
| PolicyExecTime          | 0.561      |
| ProcessExecTime         | 0.077      |
| StdReturn               | 105        |
| Time                    | 963        |
| dLoss                   | 0.0450339  |
----------------------------------------
itr #86 | 
Mem: 737.246094
Obtaining samples...
Obtaining samples for iteration 86...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5253, #subsample_inputs: 5253
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.755     |
| AbsLearnSignalNew       | 0.755     |
| AbsLearningOld          | 0.755     |
| AverageDiscountedReturn | 121       |
| AveragePhiLoss          | 11.3018   |
| AveragePolicyStd        | 0.908164  |
| AverageReturn           | 357       |
| Entropy                 | 7.93357   |
| EnvExecTime             | 2.77      |
| ExplainedVariance       | 0.813     |
| Iteration               | 86        |
| ItrTime                 | 10.9      |
| LossAfter               | 0.0376611 |
| LossBefore              | 0.0917516 |
| MaxReturn               | 492       |
| MeanKL                  | 0.0097806 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 171       |
| NumTrajs                | 25        |
| Perplexity              | 2789.36   |
| PolicyExecTime          | 0.613     |
| ProcessExecTime         | 0.0855    |
| StdReturn               | 73.9      |
| Time                    | 975       |
| dLoss                   | 0.0540904 |
---------------------------------------
itr #87 | 
Mem: 737.246094
Obtaining samples...
Obtaining samples for iteration 87...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5047, #subsample_inputs: 5047
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.577      |
| AbsLearnSignalNew       | 0.577      |
| AbsLearningOld          | 0.577      |
| AverageDiscountedReturn | 116        |
| AveragePhiLoss          | 11.0105    |
| AveragePolicyStd        | 0.908088   |
| AverageReturn           | 343        |
| Entropy                 | 7.93316    |
| EnvExecTime             | 2.62       |
| ExplainedVariance       | 0.549      |
| Iteration               | 87         |
| ItrTime                 | 11.5       |
| LossAfter               | -0.0324216 |
| LossBefore              | 0.0170493  |
| MaxReturn               | 566        |
| MeanKL                  | 0.0099026  |
| MeanKLBefore            | 0.0        |
| MinReturn               | 53.6       |
| NumTrajs                | 24         |
| Perplexity              | 2788.22    |
| PolicyExecTime          | 0.584      |
| ProcessExecTime         | 0.0846     |
| StdReturn               | 97.3       |
| Time                    | 986        |
| dLoss                   | 0.0494708  |
----------------------------------------
itr #88 | 
Mem: 737.246094
Obtaining samples...
Obtaining samples for iteration 88...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5008, #subsample_inputs: 5008
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.723      |
| AbsLearnSignalNew       | 0.723      |
| AbsLearningOld          | 0.723      |
| AverageDiscountedReturn | 117        |
| AveragePhiLoss          | 11.4793    |
| AveragePolicyStd        | 0.90773    |
| AverageReturn           | 383        |
| Entropy                 | 7.9311     |
| EnvExecTime             | 2.35       |
| ExplainedVariance       | 0.62       |
| Iteration               | 88         |
| ItrTime                 | 11.7       |
| LossAfter               | -0.718809  |
| LossBefore              | -0.663795  |
| MaxReturn               | 670        |
| MeanKL                  | 0.00993514 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 223        |
| NumTrajs                | 20         |
| Perplexity              | 2782.48    |
| PolicyExecTime          | 0.479      |
| ProcessExecTime         | 0.066      |
| StdReturn               | 97.4       |
| Time                    | 998        |
| dLoss                   | 0.0550145  |
----------------------------------------
itr #89 | 
Mem: 738.796875
Obtaining samples...
Obtaining samples for iteration 89...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5041, #subsample_inputs: 5041
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.756      |
| AbsLearnSignalNew       | 0.756      |
| AbsLearningOld          | 0.756      |
| AverageDiscountedReturn | 115        |
| AveragePhiLoss          | 10.8162    |
| AveragePolicyStd        | 0.905069   |
| AverageReturn           | 359        |
| Entropy                 | 7.91337    |
| EnvExecTime             | 2.8        |
| ExplainedVariance       | 0.623      |
| Iteration               | 89         |
| ItrTime                 | 10.7       |
| LossAfter               | -0.667272  |
| LossBefore              | -0.621419  |
| MaxReturn               | 614        |
| MeanKL                  | 0.00646929 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 87.2       |
| NumTrajs                | 22         |
| Perplexity              | 2733.58    |
| PolicyExecTime          | 0.628      |
| ProcessExecTime         | 0.0873     |
| StdReturn               | 115        |
| Time                    | 1.01e+03   |
| dLoss                   | 0.0458536  |
----------------------------------------
itr #90 | 
Mem: 738.796875
Obtaining samples...
Obtaining samples for iteration 90...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5106, #subsample_inputs: 5106
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.683      |
| AbsLearnSignalNew       | 0.683      |
| AbsLearningOld          | 0.683      |
| AverageDiscountedReturn | 117        |
| AveragePhiLoss          | 10.5575    |
| AveragePolicyStd        | 0.9074     |
| AverageReturn           | 393        |
| Entropy                 | 7.92903    |
| EnvExecTime             | 2.76       |
| ExplainedVariance       | 0.589      |
| Iteration               | 90         |
| ItrTime                 | 12.2       |
| LossAfter               | 0.252422   |
| LossBefore              | 0.307273   |
| MaxReturn               | 829        |
| MeanKL                  | 0.00996463 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 137        |
| NumTrajs                | 20         |
| Perplexity              | 2776.74    |
| PolicyExecTime          | 0.608      |
| ProcessExecTime         | 0.0841     |
| StdReturn               | 145        |
| Time                    | 1.02e+03   |
| dLoss                   | 0.0548502  |
----------------------------------------
itr #91 | 
Mem: 738.796875
Obtaining samples...
Obtaining samples for iteration 91...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5204, #subsample_inputs: 5204
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.704      |
| AbsLearnSignalNew       | 0.704      |
| AbsLearningOld          | 0.704      |
| AverageDiscountedReturn | 114        |
| AveragePhiLoss          | 11.6338    |
| AveragePolicyStd        | 0.905621   |
| AverageReturn           | 356        |
| Entropy                 | 7.91736    |
| EnvExecTime             | 2.53       |
| ExplainedVariance       | 0.63       |
| Iteration               | 91         |
| ItrTime                 | 12.1       |
| LossAfter               | -0.0815347 |
| LossBefore              | -0.01359   |
| MaxReturn               | 594        |
| MeanKL                  | 0.00990788 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 77         |
| NumTrajs                | 23         |
| Perplexity              | 2744.5     |
| PolicyExecTime          | 0.518      |
| ProcessExecTime         | 0.072      |
| StdReturn               | 107        |
| Time                    | 1.03e+03   |
| dLoss                   | 0.0679447  |
----------------------------------------
itr #92 | 
Mem: 738.796875
Obtaining samples...
Obtaining samples for iteration 92...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5091, #subsample_inputs: 5091
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.71       |
| AbsLearnSignalNew       | 0.71       |
| AbsLearningOld          | 0.71       |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 10.6055    |
| AveragePolicyStd        | 0.904943   |
| AverageReturn           | 382        |
| Entropy                 | 7.91263    |
| EnvExecTime             | 2.71       |
| ExplainedVariance       | 0.695      |
| Iteration               | 92         |
| ItrTime                 | 10.5       |
| LossAfter               | 0.432051   |
| LossBefore              | 0.485502   |
| MaxReturn               | 850        |
| MeanKL                  | 0.00980322 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 223        |
| NumTrajs                | 22         |
| Perplexity              | 2731.56    |
| PolicyExecTime          | 0.594      |
| ProcessExecTime         | 0.0832     |
| StdReturn               | 130        |
| Time                    | 1.04e+03   |
| dLoss                   | 0.0534514  |
----------------------------------------
itr #93 | 
Mem: 738.796875
Obtaining samples...
Obtaining samples for iteration 93...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5042, #subsample_inputs: 5042
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.654      |
| AbsLearnSignalNew       | 0.654      |
| AbsLearningOld          | 0.654      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 9.82243    |
| AveragePolicyStd        | 0.90388    |
| AverageReturn           | 348        |
| Entropy                 | 7.90594    |
| EnvExecTime             | 2.63       |
| ExplainedVariance       | 0.545      |
| Iteration               | 93         |
| ItrTime                 | 11.7       |
| LossAfter               | -0.13322   |
| LossBefore              | -0.0842823 |
| MaxReturn               | 453        |
| MeanKL                  | 0.00985019 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 139        |
| NumTrajs                | 24         |
| Perplexity              | 2713.34    |
| PolicyExecTime          | 0.584      |
| ProcessExecTime         | 0.0824     |
| StdReturn               | 67.2       |
| Time                    | 1.06e+03   |
| dLoss                   | 0.0489378  |
----------------------------------------
itr #94 | 
Mem: 738.796875
Obtaining samples...
Obtaining samples for iteration 94...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5608, #subsample_inputs: 5608
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.373      |
| AbsLearnSignalNew       | 0.373      |
| AbsLearningOld          | 0.373      |
| AverageDiscountedReturn | 117        |
| AveragePhiLoss          | 11.0239    |
| AveragePolicyStd        | 0.907911   |
| AverageReturn           | 386        |
| Entropy                 | 7.93252    |
| EnvExecTime             | 2.56       |
| ExplainedVariance       | -2.16      |
| Iteration               | 94         |
| ItrTime                 | 12.1       |
| LossAfter               | -0.465508  |
| LossBefore              | -0.42215   |
| MaxReturn               | 815        |
| MeanKL                  | 0.00978449 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 253        |
| NumTrajs                | 23         |
| Perplexity              | 2786.44    |
| PolicyExecTime          | 0.526      |
| ProcessExecTime         | 0.0727     |
| StdReturn               | 118        |
| Time                    | 1.07e+03   |
| dLoss                   | 0.0433586  |
----------------------------------------
itr #95 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 95...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5145, #subsample_inputs: 5145
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.645      |
| AbsLearnSignalNew       | 0.645      |
| AbsLearningOld          | 0.646      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 10.7441    |
| AveragePolicyStd        | 0.909166   |
| AverageReturn           | 333        |
| Entropy                 | 7.94073    |
| EnvExecTime             | 3.02       |
| ExplainedVariance       | 0.557      |
| Iteration               | 95         |
| ItrTime                 | 10.8       |
| LossAfter               | -0.282243  |
| LossBefore              | -0.240678  |
| MaxReturn               | 517        |
| MeanKL                  | 0.00640346 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 53.1       |
| NumTrajs                | 26         |
| Perplexity              | 2809.4     |
| PolicyExecTime          | 0.664      |
| ProcessExecTime         | 0.091      |
| StdReturn               | 91.4       |
| Time                    | 1.08e+03   |
| dLoss                   | 0.0415655  |
----------------------------------------
itr #96 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 96...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5146, #subsample_inputs: 5146
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.683      |
| AbsLearnSignalNew       | 0.683      |
| AbsLearningOld          | 0.683      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 11.3604    |
| AveragePolicyStd        | 0.90752    |
| AverageReturn           | 365        |
| Entropy                 | 7.92973    |
| EnvExecTime             | 2.83       |
| ExplainedVariance       | 0.673      |
| Iteration               | 96         |
| ItrTime                 | 12         |
| LossAfter               | -0.650112  |
| LossBefore              | -0.592022  |
| MaxReturn               | 595        |
| MeanKL                  | 0.00991208 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 72.1       |
| NumTrajs                | 23         |
| Perplexity              | 2778.67    |
| PolicyExecTime          | 0.622      |
| ProcessExecTime         | 0.0881     |
| StdReturn               | 109        |
| Time                    | 1.09e+03   |
| dLoss                   | 0.05809    |
----------------------------------------
itr #97 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 97...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5203, #subsample_inputs: 5203
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.667      |
| AbsLearnSignalNew       | 0.667      |
| AbsLearningOld          | 0.667      |
| AverageDiscountedReturn | 119        |
| AveragePhiLoss          | 10.9562    |
| AveragePolicyStd        | 0.906995   |
| AverageReturn           | 339        |
| Entropy                 | 7.92567    |
| EnvExecTime             | 2.46       |
| ExplainedVariance       | 0.596      |
| Iteration               | 97         |
| ItrTime                 | 11.7       |
| LossAfter               | -0.0410264 |
| LossBefore              | 0.00378402 |
| MaxReturn               | 541        |
| MeanKL                  | 0.00641442 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 87.3       |
| NumTrajs                | 25         |
| Perplexity              | 2767.41    |
| PolicyExecTime          | 0.493      |
| ProcessExecTime         | 0.071      |
| StdReturn               | 90.9       |
| Time                    | 1.1e+03    |
| dLoss                   | 0.0448104  |
----------------------------------------
itr #98 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 98...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5142, #subsample_inputs: 5142
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.756      |
| AbsLearnSignalNew       | 0.756      |
| AbsLearningOld          | 0.756      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 11.3206    |
| AveragePolicyStd        | 0.906043   |
| AverageReturn           | 368        |
| Entropy                 | 7.91933    |
| EnvExecTime             | 2.68       |
| ExplainedVariance       | 0.597      |
| Iteration               | 98         |
| ItrTime                 | 10.5       |
| LossAfter               | -0.330614  |
| LossBefore              | -0.275099  |
| MaxReturn               | 511        |
| MeanKL                  | 0.00994473 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 128        |
| NumTrajs                | 23         |
| Perplexity              | 2749.94    |
| PolicyExecTime          | 0.603      |
| ProcessExecTime         | 0.0822     |
| StdReturn               | 81.6       |
| Time                    | 1.11e+03   |
| dLoss                   | 0.0555157  |
----------------------------------------
itr #99 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 99...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5122, #subsample_inputs: 5122
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.69       |
| AbsLearnSignalNew       | 0.69       |
| AbsLearningOld          | 0.69       |
| AverageDiscountedReturn | 115        |
| AveragePhiLoss          | 12.3583    |
| AveragePolicyStd        | 0.903491   |
| AverageReturn           | 344        |
| Entropy                 | 7.90184    |
| EnvExecTime             | 2.84       |
| ExplainedVariance       | 0.67       |
| Iteration               | 99         |
| ItrTime                 | 12         |
| LossAfter               | -0.0831751 |
| LossBefore              | -0.0242737 |
| MaxReturn               | 464        |
| MeanKL                  | 0.00997425 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 31.7       |
| NumTrajs                | 24         |
| Perplexity              | 2702.25    |
| PolicyExecTime          | 0.619      |
| ProcessExecTime         | 0.0873     |
| StdReturn               | 89.1       |
| Time                    | 1.13e+03   |
| dLoss                   | 0.0589014  |
----------------------------------------
itr #100 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 100...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5110, #subsample_inputs: 5110
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.673      |
| AbsLearnSignalNew       | 0.673      |
| AbsLearningOld          | 0.673      |
| AverageDiscountedReturn | 124        |
| AveragePhiLoss          | 11.0311    |
| AveragePolicyStd        | 0.900383   |
| AverageReturn           | 383        |
| Entropy                 | 7.88132    |
| EnvExecTime             | 2.41       |
| ExplainedVariance       | 0.75       |
| Iteration               | 100        |
| ItrTime                 | 11         |
| LossAfter               | 0.535203   |
| LossBefore              | 0.595538   |
| MaxReturn               | 547        |
| MeanKL                  | 0.00990844 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 220        |
| NumTrajs                | 23         |
| Perplexity              | 2647.38    |
| PolicyExecTime          | 0.501      |
| ProcessExecTime         | 0.0712     |
| StdReturn               | 85.7       |
| Time                    | 1.14e+03   |
| dLoss                   | 0.060335   |
----------------------------------------
itr #101 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 101...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5025, #subsample_inputs: 5025
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.662      |
| AbsLearnSignalNew       | 0.662      |
| AbsLearningOld          | 0.662      |
| AverageDiscountedReturn | 124        |
| AveragePhiLoss          | 11.5962    |
| AveragePolicyStd        | 0.900068   |
| AverageReturn           | 384        |
| Entropy                 | 7.87814    |
| EnvExecTime             | 2.72       |
| ExplainedVariance       | 0.467      |
| Iteration               | 101        |
| ItrTime                 | 10.8       |
| LossAfter               | 0.801994   |
| LossBefore              | 0.86943    |
| MaxReturn               | 664        |
| MeanKL                  | 0.00986647 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 213        |
| NumTrajs                | 22         |
| Perplexity              | 2638.95    |
| PolicyExecTime          | 0.596      |
| ProcessExecTime         | 0.0859     |
| StdReturn               | 99         |
| Time                    | 1.15e+03   |
| dLoss                   | 0.0674357  |
----------------------------------------
itr #102 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 102...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5029, #subsample_inputs: 5029
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.757      |
| AbsLearnSignalNew       | 0.757      |
| AbsLearningOld          | 0.757      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 11.3424    |
| AveragePolicyStd        | 0.897413   |
| AverageReturn           | 398        |
| Entropy                 | 7.86027    |
| EnvExecTime             | 2.7        |
| ExplainedVariance       | 0.741      |
| Iteration               | 102        |
| ItrTime                 | 11.7       |
| LossAfter               | 0.341836   |
| LossBefore              | 0.388151   |
| MaxReturn               | 575        |
| MeanKL                  | 0.00652069 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 237        |
| NumTrajs                | 22         |
| Perplexity              | 2592.23    |
| PolicyExecTime          | 0.598      |
| ProcessExecTime         | 0.0789     |
| StdReturn               | 80         |
| Time                    | 1.16e+03   |
| dLoss                   | 0.0463144  |
----------------------------------------
itr #103 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 103...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5198, #subsample_inputs: 5198
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.707      |
| AbsLearnSignalNew       | 0.707      |
| AbsLearningOld          | 0.707      |
| AverageDiscountedReturn | 123        |
| AveragePhiLoss          | 11.3593    |
| AveragePolicyStd        | 0.894271   |
| AverageReturn           | 394        |
| Entropy                 | 7.83938    |
| EnvExecTime             | 2.54       |
| ExplainedVariance       | 0.726      |
| Iteration               | 103        |
| ItrTime                 | 10.6       |
| LossAfter               | -0.110868  |
| LossBefore              | -0.0499082 |
| MaxReturn               | 558        |
| MeanKL                  | 0.00990997 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 242        |
| NumTrajs                | 22         |
| Perplexity              | 2538.63    |
| PolicyExecTime          | 0.545      |
| ProcessExecTime         | 0.0763     |
| StdReturn               | 80.2       |
| Time                    | 1.17e+03   |
| dLoss                   | 0.0609596  |
----------------------------------------
itr #104 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 104...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5061, #subsample_inputs: 5061
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.73       |
| AbsLearnSignalNew       | 0.73       |
| AbsLearningOld          | 0.73       |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 11.7721    |
| AveragePolicyStd        | 0.891056   |
| AverageReturn           | 382        |
| Entropy                 | 7.81737    |
| EnvExecTime             | 2.85       |
| ExplainedVariance       | 0.785      |
| Iteration               | 104        |
| ItrTime                 | 11.7       |
| LossAfter               | 0.506045   |
| LossBefore              | 0.567775   |
| MaxReturn               | 577        |
| MeanKL                  | 0.00997505 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 268        |
| NumTrajs                | 23         |
| Perplexity              | 2483.38    |
| PolicyExecTime          | 0.626      |
| ProcessExecTime         | 0.0869     |
| StdReturn               | 81.5       |
| Time                    | 1.18e+03   |
| dLoss                   | 0.0617307  |
----------------------------------------
itr #105 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 105...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5206, #subsample_inputs: 5206
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.757      |
| AbsLearnSignalNew       | 0.757      |
| AbsLearningOld          | 0.757      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 11.2993    |
| AveragePolicyStd        | 0.888332   |
| AverageReturn           | 394        |
| Entropy                 | 7.79969    |
| EnvExecTime             | 2.38       |
| ExplainedVariance       | 0.828      |
| Iteration               | 105        |
| ItrTime                 | 11.4       |
| LossAfter               | 0.224726   |
| LossBefore              | 0.283551   |
| MaxReturn               | 548        |
| MeanKL                  | 0.00993932 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 307        |
| NumTrajs                | 23         |
| Perplexity              | 2439.85    |
| PolicyExecTime          | 0.481      |
| ProcessExecTime         | 0.0655     |
| StdReturn               | 60.9       |
| Time                    | 1.19e+03   |
| dLoss                   | 0.0588244  |
----------------------------------------
itr #106 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 106...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5224, #subsample_inputs: 5224
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.604      |
| AbsLearnSignalNew       | 0.604      |
| AbsLearningOld          | 0.604      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 11.5878    |
| AveragePolicyStd        | 0.887905   |
| AverageReturn           | 394        |
| Entropy                 | 7.79695    |
| EnvExecTime             | 2.89       |
| ExplainedVariance       | 0.477      |
| Iteration               | 106        |
| ItrTime                 | 10.6       |
| LossAfter               | 0.127181   |
| LossBefore              | 0.169306   |
| MaxReturn               | 620        |
| MeanKL                  | 0.00643842 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 70.1       |
| NumTrajs                | 22         |
| Perplexity              | 2433.17    |
| PolicyExecTime          | 0.644      |
| ProcessExecTime         | 0.0876     |
| StdReturn               | 118        |
| Time                    | 1.2e+03    |
| dLoss                   | 0.0421251  |
----------------------------------------
itr #107 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 107...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5023, #subsample_inputs: 5023
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.724     |
| AbsLearnSignalNew       | 0.724     |
| AbsLearningOld          | 0.724     |
| AverageDiscountedReturn | 127       |
| AveragePhiLoss          | 11.5242   |
| AveragePolicyStd        | 0.888124  |
| AverageReturn           | 385       |
| Entropy                 | 7.79852   |
| EnvExecTime             | 2.72      |
| ExplainedVariance       | 0.805     |
| Iteration               | 107       |
| ItrTime                 | 12        |
| LossAfter               | 0.0751303 |
| LossBefore              | 0.122068  |
| MaxReturn               | 616       |
| MeanKL                  | 0.0064324 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 258       |
| NumTrajs                | 23        |
| Perplexity              | 2436.99   |
| PolicyExecTime          | 0.615     |
| ProcessExecTime         | 0.0816    |
| StdReturn               | 75.2      |
| Time                    | 1.22e+03  |
| dLoss                   | 0.0469376 |
---------------------------------------
itr #108 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 108...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5253, #subsample_inputs: 5253
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.625      |
| AbsLearnSignalNew       | 0.625      |
| AbsLearningOld          | 0.625      |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 12.8441    |
| AveragePolicyStd        | 0.884573   |
| AverageReturn           | 359        |
| Entropy                 | 7.77479    |
| EnvExecTime             | 2.56       |
| ExplainedVariance       | 0.434      |
| Iteration               | 108        |
| ItrTime                 | 11.5       |
| LossAfter               | -0.0101244 |
| LossBefore              | 0.0312145  |
| MaxReturn               | 518        |
| MeanKL                  | 0.00641682 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 109        |
| NumTrajs                | 24         |
| Perplexity              | 2379.85    |
| PolicyExecTime          | 0.533      |
| ProcessExecTime         | 0.0721     |
| StdReturn               | 82.1       |
| Time                    | 1.23e+03   |
| dLoss                   | 0.041339   |
----------------------------------------
itr #109 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 109...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5020, #subsample_inputs: 5020
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.718      |
| AbsLearnSignalNew       | 0.718      |
| AbsLearningOld          | 0.718      |
| AverageDiscountedReturn | 124        |
| AveragePhiLoss          | 12.3789    |
| AveragePolicyStd        | 0.879645   |
| AverageReturn           | 409        |
| Entropy                 | 7.74126    |
| EnvExecTime             | 2.66       |
| ExplainedVariance       | 0.642      |
| Iteration               | 109        |
| ItrTime                 | 10.3       |
| LossAfter               | -0.339585  |
| LossBefore              | -0.285264  |
| MaxReturn               | 517        |
| MeanKL                  | 0.00984959 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 280        |
| NumTrajs                | 21         |
| Perplexity              | 2301.37    |
| PolicyExecTime          | 0.572      |
| ProcessExecTime         | 0.0809     |
| StdReturn               | 57.2       |
| Time                    | 1.24e+03   |
| dLoss                   | 0.0543209  |
----------------------------------------
itr #110 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 110...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5008, #subsample_inputs: 5008
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.651      |
| AbsLearnSignalNew       | 0.651      |
| AbsLearningOld          | 0.651      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 12.286     |
| AveragePolicyStd        | 0.877097   |
| AverageReturn           | 363        |
| Entropy                 | 7.72436    |
| EnvExecTime             | 2.98       |
| ExplainedVariance       | 0.416      |
| Iteration               | 110        |
| ItrTime                 | 12.2       |
| LossAfter               | -0.191726  |
| LossBefore              | -0.144233  |
| MaxReturn               | 532        |
| MeanKL                  | 0.00999504 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 68.1       |
| NumTrajs                | 22         |
| Perplexity              | 2262.81    |
| PolicyExecTime          | 0.623      |
| ProcessExecTime         | 0.088      |
| StdReturn               | 106        |
| Time                    | 1.25e+03   |
| dLoss                   | 0.0474928  |
----------------------------------------
itr #111 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 111...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5160, #subsample_inputs: 5160
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.728      |
| AbsLearnSignalNew       | 0.728      |
| AbsLearningOld          | 0.728      |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 11.7211    |
| AveragePolicyStd        | 0.876472   |
| AverageReturn           | 412        |
| Entropy                 | 7.72029    |
| EnvExecTime             | 2.39       |
| ExplainedVariance       | 0.565      |
| Iteration               | 111        |
| ItrTime                 | 10.8       |
| LossAfter               | -0.622962  |
| LossBefore              | -0.575835  |
| MaxReturn               | 567        |
| MeanKL                  | 0.00646113 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 102        |
| NumTrajs                | 21         |
| Perplexity              | 2253.61    |
| PolicyExecTime          | 0.495      |
| ProcessExecTime         | 0.0725     |
| StdReturn               | 88.1       |
| Time                    | 1.26e+03   |
| dLoss                   | 0.0471268  |
----------------------------------------
itr #112 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 112...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5124, #subsample_inputs: 5124
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.672      |
| AbsLearnSignalNew       | 0.672      |
| AbsLearningOld          | 0.672      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 13.0894    |
| AveragePolicyStd        | 0.872917   |
| AverageReturn           | 385        |
| Entropy                 | 7.69589    |
| EnvExecTime             | 2.76       |
| ExplainedVariance       | 0.618      |
| Iteration               | 112        |
| ItrTime                 | 10.6       |
| LossAfter               | -0.15254   |
| LossBefore              | -0.0949287 |
| MaxReturn               | 594        |
| MeanKL                  | 0.00991893 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 81.7       |
| NumTrajs                | 22         |
| Perplexity              | 2199.29    |
| PolicyExecTime          | 0.593      |
| ProcessExecTime         | 0.0835     |
| StdReturn               | 118        |
| Time                    | 1.27e+03   |
| dLoss                   | 0.0576115  |
----------------------------------------
itr #113 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 113...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5213, #subsample_inputs: 5213
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.708      |
| AbsLearnSignalNew       | 0.708      |
| AbsLearningOld          | 0.708      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 12.153     |
| AveragePolicyStd        | 0.876054   |
| AverageReturn           | 384        |
| Entropy                 | 7.71787    |
| EnvExecTime             | 2.78       |
| ExplainedVariance       | 0.651      |
| Iteration               | 113        |
| ItrTime                 | 12.1       |
| LossAfter               | -0.235712  |
| LossBefore              | -0.182565  |
| MaxReturn               | 562        |
| MeanKL                  | 0.00997914 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 107        |
| NumTrajs                | 23         |
| Perplexity              | 2248.17    |
| PolicyExecTime          | 0.583      |
| ProcessExecTime         | 0.0837     |
| StdReturn               | 101        |
| Time                    | 1.28e+03   |
| dLoss                   | 0.0531477  |
----------------------------------------
itr #114 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 114...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5057, #subsample_inputs: 5057
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.694      |
| AbsLearnSignalNew       | 0.694      |
| AbsLearningOld          | 0.694      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 12.7602    |
| AveragePolicyStd        | 0.879398   |
| AverageReturn           | 384        |
| Entropy                 | 7.74072    |
| EnvExecTime             | 2.47       |
| ExplainedVariance       | 0.702      |
| Iteration               | 114        |
| ItrTime                 | 10.9       |
| LossAfter               | 0.511754   |
| LossBefore              | 0.559704   |
| MaxReturn               | 516        |
| MeanKL                  | 0.00645312 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 66.9       |
| NumTrajs                | 23         |
| Perplexity              | 2300.13    |
| PolicyExecTime          | 0.497      |
| ProcessExecTime         | 0.0695     |
| StdReturn               | 86.6       |
| Time                    | 1.3e+03    |
| dLoss                   | 0.04795    |
----------------------------------------
itr #115 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 115...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5037, #subsample_inputs: 5037
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.646      |
| AbsLearnSignalNew       | 0.646      |
| AbsLearningOld          | 0.646      |
| AverageDiscountedReturn | 123        |
| AveragePhiLoss          | 12.0898    |
| AveragePolicyStd        | 0.876608   |
| AverageReturn           | 393        |
| Entropy                 | 7.72209    |
| EnvExecTime             | 2.92       |
| ExplainedVariance       | 0.594      |
| Iteration               | 115        |
| ItrTime                 | 10.7       |
| LossAfter               | 0.216609   |
| LossBefore              | 0.260076   |
| MaxReturn               | 518        |
| MeanKL                  | 0.00640651 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 115        |
| NumTrajs                | 21         |
| Perplexity              | 2257.67    |
| PolicyExecTime          | 0.624      |
| ProcessExecTime         | 0.0851     |
| StdReturn               | 96.6       |
| Time                    | 1.31e+03   |
| dLoss                   | 0.0434668  |
----------------------------------------
itr #116 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 116...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5219, #subsample_inputs: 5219
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.614      |
| AbsLearnSignalNew       | 0.614      |
| AbsLearningOld          | 0.614      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 11.8555    |
| AveragePolicyStd        | 0.876351   |
| AverageReturn           | 405        |
| Entropy                 | 7.72034    |
| EnvExecTime             | 3.03       |
| ExplainedVariance       | 0.465      |
| Iteration               | 116        |
| ItrTime                 | 12.5       |
| LossAfter               | 0.567587   |
| LossBefore              | 0.620746   |
| MaxReturn               | 649        |
| MeanKL                  | 0.00990193 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 153        |
| NumTrajs                | 21         |
| Perplexity              | 2253.73    |
| PolicyExecTime          | 0.661      |
| ProcessExecTime         | 0.0924     |
| StdReturn               | 92.9       |
| Time                    | 1.32e+03   |
| dLoss                   | 0.0531591  |
----------------------------------------
itr #117 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 117...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5070, #subsample_inputs: 5070
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.673      |
| AbsLearnSignalNew       | 0.673      |
| AbsLearningOld          | 0.673      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 12.3635    |
| AveragePolicyStd        | 0.873936   |
| AverageReturn           | 374        |
| Entropy                 | 7.70344    |
| EnvExecTime             | 2.48       |
| ExplainedVariance       | 0.702      |
| Iteration               | 117        |
| ItrTime                 | 11         |
| LossAfter               | 0.0101369  |
| LossBefore              | 0.0638213  |
| MaxReturn               | 563        |
| MeanKL                  | 0.00983168 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 52.5       |
| NumTrajs                | 23         |
| Perplexity              | 2215.96    |
| PolicyExecTime          | 0.495      |
| ProcessExecTime         | 0.0667     |
| StdReturn               | 98.3       |
| Time                    | 1.33e+03   |
| dLoss                   | 0.0536844  |
----------------------------------------
itr #118 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 118...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5015, #subsample_inputs: 5015
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.697      |
| AbsLearnSignalNew       | 0.697      |
| AbsLearningOld          | 0.697      |
| AverageDiscountedReturn | 130        |
| AveragePhiLoss          | 11.3619    |
| AveragePolicyStd        | 0.874759   |
| AverageReturn           | 411        |
| Entropy                 | 7.71       |
| EnvExecTime             | 2.95       |
| ExplainedVariance       | 0.758      |
| Iteration               | 118        |
| ItrTime                 | 10.5       |
| LossAfter               | -0.195758  |
| LossBefore              | -0.133631  |
| MaxReturn               | 542        |
| MeanKL                  | 0.00997889 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 306        |
| NumTrajs                | 22         |
| Perplexity              | 2230.55    |
| PolicyExecTime          | 0.63       |
| ProcessExecTime         | 0.0866     |
| StdReturn               | 68.7       |
| Time                    | 1.34e+03   |
| dLoss                   | 0.0621269  |
----------------------------------------
itr #119 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 119...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5215, #subsample_inputs: 5215
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.616      |
| AbsLearnSignalNew       | 0.616      |
| AbsLearningOld          | 0.616      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 12.3564    |
| AveragePolicyStd        | 0.874572   |
| AverageReturn           | 378        |
| Entropy                 | 7.70806    |
| EnvExecTime             | 3.1        |
| ExplainedVariance       | 0.441      |
| Iteration               | 119        |
| ItrTime                 | 12.6       |
| LossAfter               | -0.069483  |
| LossBefore              | -0.0187859 |
| MaxReturn               | 508        |
| MeanKL                  | 0.00991567 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 95.4       |
| NumTrajs                | 23         |
| Perplexity              | 2226.22    |
| PolicyExecTime          | 0.709      |
| ProcessExecTime         | 0.0907     |
| StdReturn               | 105        |
| Time                    | 1.35e+03   |
| dLoss                   | 0.0506972  |
----------------------------------------
itr #120 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 120...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5098, #subsample_inputs: 5098
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.693     |
| AbsLearnSignalNew       | 0.693     |
| AbsLearningOld          | 0.694     |
| AverageDiscountedReturn | 124       |
| AveragePhiLoss          | 12.1387   |
| AveragePolicyStd        | 0.874783  |
| AverageReturn           | 380       |
| Entropy                 | 7.70935   |
| EnvExecTime             | 2.34      |
| ExplainedVariance       | 0.63      |
| Iteration               | 120       |
| ItrTime                 | 10.8      |
| LossAfter               | -0.204235 |
| LossBefore              | -0.159805 |
| MaxReturn               | 727       |
| MeanKL                  | 0.0064817 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 147       |
| NumTrajs                | 22        |
| Perplexity              | 2229.1    |
| PolicyExecTime          | 0.468     |
| ProcessExecTime         | 0.0654    |
| StdReturn               | 113       |
| Time                    | 1.36e+03  |
| dLoss                   | 0.0444303 |
---------------------------------------
itr #121 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 121...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5260, #subsample_inputs: 5260
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.707      |
| AbsLearnSignalNew       | 0.707      |
| AbsLearningOld          | 0.707      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 12.7279    |
| AveragePolicyStd        | 0.872027   |
| AverageReturn           | 382        |
| Entropy                 | 7.6901     |
| EnvExecTime             | 2.96       |
| ExplainedVariance       | 0.613      |
| Iteration               | 121        |
| ItrTime                 | 11.2       |
| LossAfter               | -0.0511142 |
| LossBefore              | -0.0064013 |
| MaxReturn               | 600        |
| MeanKL                  | 0.00646999 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 57.3       |
| NumTrajs                | 23         |
| Perplexity              | 2186.59    |
| PolicyExecTime          | 0.657      |
| ProcessExecTime         | 0.0892     |
| StdReturn               | 118        |
| Time                    | 1.38e+03   |
| dLoss                   | 0.0447129  |
----------------------------------------
itr #122 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 122...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5011, #subsample_inputs: 5011
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.676     |
| AbsLearnSignalNew       | 0.676     |
| AbsLearningOld          | 0.676     |
| AverageDiscountedReturn | 119       |
| AveragePhiLoss          | 13.824    |
| AveragePolicyStd        | 0.870846  |
| AverageReturn           | 371       |
| Entropy                 | 7.68163   |
| EnvExecTime             | 2.84      |
| ExplainedVariance       | 0.559     |
| Iteration               | 122       |
| ItrTime                 | 12.1      |
| LossAfter               | 0.20681   |
| LossBefore              | 0.260586  |
| MaxReturn               | 519       |
| MeanKL                  | 0.0098122 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 84.7      |
| NumTrajs                | 22        |
| Perplexity              | 2168.16   |
| PolicyExecTime          | 0.597     |
| ProcessExecTime         | 0.084     |
| StdReturn               | 119       |
| Time                    | 1.39e+03  |
| dLoss                   | 0.0537755 |
---------------------------------------
itr #123 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 123...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5000, #subsample_inputs: 5000
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.681      |
| AbsLearnSignalNew       | 0.681      |
| AbsLearningOld          | 0.681      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 12.0163    |
| AveragePolicyStd        | 0.873278   |
| AverageReturn           | 377        |
| Entropy                 | 7.69878    |
| EnvExecTime             | 2.63       |
| ExplainedVariance       | 0.474      |
| Iteration               | 123        |
| ItrTime                 | 10.5       |
| LossAfter               | 0.705054   |
| LossBefore              | 0.751287   |
| MaxReturn               | 503        |
| MeanKL                  | 0.00648004 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 235        |
| NumTrajs                | 23         |
| Perplexity              | 2205.65    |
| PolicyExecTime          | 0.557      |
| ProcessExecTime         | 0.076      |
| StdReturn               | 62.9       |
| Time                    | 1.4e+03    |
| dLoss                   | 0.0462326  |
----------------------------------------
itr #124 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 124...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5142, #subsample_inputs: 5142
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.73       |
| AbsLearnSignalNew       | 0.73       |
| AbsLearningOld          | 0.731      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 12.2208    |
| AveragePolicyStd        | 0.871728   |
| AverageReturn           | 376        |
| Entropy                 | 7.68759    |
| EnvExecTime             | 2.9        |
| ExplainedVariance       | 0.804      |
| Iteration               | 124        |
| ItrTime                 | 11.4       |
| LossAfter               | -0.121321  |
| LossBefore              | -0.0754677 |
| MaxReturn               | 507        |
| MeanKL                  | 0.00644053 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 277        |
| NumTrajs                | 24         |
| Perplexity              | 2181.11    |
| PolicyExecTime          | 0.619      |
| ProcessExecTime         | 0.0859     |
| StdReturn               | 55.2       |
| Time                    | 1.41e+03   |
| dLoss                   | 0.0458538  |
----------------------------------------
itr #125 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 125...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5123, #subsample_inputs: 5123
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.635      |
| AbsLearnSignalNew       | 0.635      |
| AbsLearningOld          | 0.635      |
| AverageDiscountedReturn | 123        |
| AveragePhiLoss          | 12.5609    |
| AveragePolicyStd        | 0.868791   |
| AverageReturn           | 376        |
| Entropy                 | 7.6664     |
| EnvExecTime             | 2.71       |
| ExplainedVariance       | 0.612      |
| Iteration               | 125        |
| ItrTime                 | 12.1       |
| LossAfter               | -0.0237551 |
| LossBefore              | 0.0161753  |
| MaxReturn               | 500        |
| MeanKL                  | 0.00648805 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 66.1       |
| NumTrajs                | 23         |
| Perplexity              | 2135.37    |
| PolicyExecTime          | 0.579      |
| ProcessExecTime         | 0.0785     |
| StdReturn               | 91.3       |
| Time                    | 1.42e+03   |
| dLoss                   | 0.0399304  |
----------------------------------------
itr #126 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 126...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5082, #subsample_inputs: 5082
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.665      |
| AbsLearnSignalNew       | 0.665      |
| AbsLearningOld          | 0.665      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 12.2342    |
| AveragePolicyStd        | 0.866243   |
| AverageReturn           | 378        |
| Entropy                 | 7.64883    |
| EnvExecTime             | 2.74       |
| ExplainedVariance       | 0.624      |
| Iteration               | 126        |
| ItrTime                 | 10.7       |
| LossAfter               | -0.116783  |
| LossBefore              | -0.0752642 |
| MaxReturn               | 473        |
| MeanKL                  | 0.00643533 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 73.3       |
| NumTrajs                | 23         |
| Perplexity              | 2098.2     |
| PolicyExecTime          | 0.578      |
| ProcessExecTime         | 0.0809     |
| StdReturn               | 78.8       |
| Time                    | 1.43e+03   |
| dLoss                   | 0.041519   |
----------------------------------------
itr #127 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 127...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5230, #subsample_inputs: 5230
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.716      |
| AbsLearnSignalNew       | 0.716      |
| AbsLearningOld          | 0.716      |
| AverageDiscountedReturn | 113        |
| AveragePhiLoss          | 12.5771    |
| AveragePolicyStd        | 0.86608    |
| AverageReturn           | 371        |
| Entropy                 | 7.64778    |
| EnvExecTime             | 2.94       |
| ExplainedVariance       | 0.287      |
| Iteration               | 127        |
| ItrTime                 | 11.7       |
| LossAfter               | -0.493997  |
| LossBefore              | -0.43458   |
| MaxReturn               | 608        |
| MeanKL                  | 0.00995129 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 66.8       |
| NumTrajs                | 22         |
| Perplexity              | 2095.99    |
| PolicyExecTime          | 0.625      |
| ProcessExecTime         | 0.0908     |
| StdReturn               | 160        |
| Time                    | 1.45e+03   |
| dLoss                   | 0.0594172  |
----------------------------------------
itr #128 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 128...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5014, #subsample_inputs: 5014
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.743      |
| AbsLearnSignalNew       | 0.743      |
| AbsLearningOld          | 0.743      |
| AverageDiscountedReturn | 127        |
| AveragePhiLoss          | 12.1441    |
| AveragePolicyStd        | 0.866773   |
| AverageReturn           | 400        |
| Entropy                 | 7.65172    |
| EnvExecTime             | 2.76       |
| ExplainedVariance       | 0.646      |
| Iteration               | 128        |
| ItrTime                 | 11.9       |
| LossAfter               | -0.627319  |
| LossBefore              | -0.570455  |
| MaxReturn               | 525        |
| MeanKL                  | 0.00998204 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 284        |
| NumTrajs                | 22         |
| Perplexity              | 2104.26    |
| PolicyExecTime          | 0.581      |
| ProcessExecTime         | 0.0768     |
| StdReturn               | 57         |
| Time                    | 1.46e+03   |
| dLoss                   | 0.0568638  |
----------------------------------------
itr #129 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 129...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5162, #subsample_inputs: 5162
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.626      |
| AbsLearnSignalNew       | 0.626      |
| AbsLearningOld          | 0.625      |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 12.3506    |
| AveragePolicyStd        | 0.865913   |
| AverageReturn           | 395        |
| Entropy                 | 7.64606    |
| EnvExecTime             | 2.7        |
| ExplainedVariance       | 0.413      |
| Iteration               | 129        |
| ItrTime                 | 10.7       |
| LossAfter               | 0.126094   |
| LossBefore              | 0.164577   |
| MaxReturn               | 548        |
| MeanKL                  | 0.00643004 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 210        |
| NumTrajs                | 21         |
| Perplexity              | 2092.39    |
| PolicyExecTime          | 0.562      |
| ProcessExecTime         | 0.079      |
| StdReturn               | 84.4       |
| Time                    | 1.47e+03   |
| dLoss                   | 0.0384824  |
----------------------------------------
itr #130 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 130...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5229, #subsample_inputs: 5229
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.687      |
| AbsLearnSignalNew       | 0.687      |
| AbsLearningOld          | 0.687      |
| AverageDiscountedReturn | 123        |
| AveragePhiLoss          | 11.56      |
| AveragePolicyStd        | 0.867289   |
| AverageReturn           | 376        |
| Entropy                 | 7.65512    |
| EnvExecTime             | 2.97       |
| ExplainedVariance       | 0.61       |
| Iteration               | 130        |
| ItrTime                 | 11.3       |
| LossAfter               | -0.627861  |
| LossBefore              | -0.575008  |
| MaxReturn               | 601        |
| MeanKL                  | 0.00984789 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 51.4       |
| NumTrajs                | 24         |
| Perplexity              | 2111.44    |
| PolicyExecTime          | 0.636      |
| ProcessExecTime         | 0.0887     |
| StdReturn               | 98.8       |
| Time                    | 1.48e+03   |
| dLoss                   | 0.0528534  |
----------------------------------------
itr #131 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 131...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5054, #subsample_inputs: 5054
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.701      |
| AbsLearnSignalNew       | 0.701      |
| AbsLearningOld          | 0.701      |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 12.4909    |
| AveragePolicyStd        | 0.865431   |
| AverageReturn           | 394        |
| Entropy                 | 7.64251    |
| EnvExecTime             | 2.65       |
| ExplainedVariance       | 0.744      |
| Iteration               | 131        |
| ItrTime                 | 12         |
| LossAfter               | 0.210224   |
| LossBefore              | 0.25482    |
| MaxReturn               | 543        |
| MeanKL                  | 0.00641527 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 245        |
| NumTrajs                | 23         |
| Perplexity              | 2084.97    |
| PolicyExecTime          | 0.582      |
| ProcessExecTime         | 0.0807     |
| StdReturn               | 73.9       |
| Time                    | 1.49e+03   |
| dLoss                   | 0.0445956  |
----------------------------------------
itr #132 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 132...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5056, #subsample_inputs: 5056
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.723      |
| AbsLearnSignalNew       | 0.723      |
| AbsLearningOld          | 0.722      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 12.6368    |
| AveragePolicyStd        | 0.86347    |
| AverageReturn           | 421        |
| Entropy                 | 7.62926    |
| EnvExecTime             | 2.61       |
| ExplainedVariance       | 0.853      |
| Iteration               | 132        |
| ItrTime                 | 10.5       |
| LossAfter               | 0.0381726  |
| LossBefore              | 0.0877341  |
| MaxReturn               | 532        |
| MeanKL                  | 0.00644901 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 309        |
| NumTrajs                | 21         |
| Perplexity              | 2057.54    |
| PolicyExecTime          | 0.559      |
| ProcessExecTime         | 0.0775     |
| StdReturn               | 60.5       |
| Time                    | 1.5e+03    |
| dLoss                   | 0.0495615  |
----------------------------------------
itr #133 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 133...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5020, #subsample_inputs: 5020
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.614      |
| AbsLearnSignalNew       | 0.614      |
| AbsLearningOld          | 0.614      |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 12.654     |
| AveragePolicyStd        | 0.866816   |
| AverageReturn           | 386        |
| Entropy                 | 7.65197    |
| EnvExecTime             | 2.78       |
| ExplainedVariance       | 0.512      |
| Iteration               | 133        |
| ItrTime                 | 11.4       |
| LossAfter               | -0.433202  |
| LossBefore              | -0.391419  |
| MaxReturn               | 484        |
| MeanKL                  | 0.00642188 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 126        |
| NumTrajs                | 23         |
| Perplexity              | 2104.79    |
| PolicyExecTime          | 0.591      |
| ProcessExecTime         | 0.0839     |
| StdReturn               | 73.4       |
| Time                    | 1.51e+03   |
| dLoss                   | 0.0417835  |
----------------------------------------
itr #134 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 134...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5137, #subsample_inputs: 5137
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.673      |
| AbsLearnSignalNew       | 0.673      |
| AbsLearningOld          | 0.673      |
| AverageDiscountedReturn | 127        |
| AveragePhiLoss          | 12.9442    |
| AveragePolicyStd        | 0.867329   |
| AverageReturn           | 393        |
| Entropy                 | 7.65622    |
| EnvExecTime             | 2.63       |
| ExplainedVariance       | 0.677      |
| Iteration               | 134        |
| ItrTime                 | 12         |
| LossAfter               | 0.144269   |
| LossBefore              | 0.19989    |
| MaxReturn               | 522        |
| MeanKL                  | 0.00995641 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 58.8       |
| NumTrajs                | 23         |
| Perplexity              | 2113.75    |
| PolicyExecTime          | 0.53       |
| ProcessExecTime         | 0.0718     |
| StdReturn               | 92.6       |
| Time                    | 1.53e+03   |
| dLoss                   | 0.0556215  |
----------------------------------------
itr #135 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 135...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5124, #subsample_inputs: 5124
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.67       |
| AbsLearnSignalNew       | 0.67       |
| AbsLearningOld          | 0.67       |
| AverageDiscountedReturn | 127        |
| AveragePhiLoss          | 13.513     |
| AveragePolicyStd        | 0.86529    |
| AverageReturn           | 395        |
| Entropy                 | 7.6416     |
| EnvExecTime             | 2.86       |
| ExplainedVariance       | 0.719      |
| Iteration               | 135        |
| ItrTime                 | 10.8       |
| LossAfter               | -0.37258   |
| LossBefore              | -0.32113   |
| MaxReturn               | 532        |
| MeanKL                  | 0.00646386 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 48.1       |
| NumTrajs                | 23         |
| Perplexity              | 2083.08    |
| PolicyExecTime          | 0.622      |
| ProcessExecTime         | 0.0873     |
| StdReturn               | 97.2       |
| Time                    | 1.54e+03   |
| dLoss                   | 0.0514494  |
----------------------------------------
itr #136 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 136...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5081, #subsample_inputs: 5081
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.729      |
| AbsLearnSignalNew       | 0.729      |
| AbsLearningOld          | 0.729      |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 12.398     |
| AveragePolicyStd        | 0.865146   |
| AverageReturn           | 419        |
| Entropy                 | 7.64047    |
| EnvExecTime             | 2.83       |
| ExplainedVariance       | 0.812      |
| Iteration               | 136        |
| ItrTime                 | 11.7       |
| LossAfter               | -0.216889  |
| LossBefore              | -0.16144   |
| MaxReturn               | 639        |
| MeanKL                  | 0.00997761 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 291        |
| NumTrajs                | 21         |
| Perplexity              | 2080.71    |
| PolicyExecTime          | 0.606      |
| ProcessExecTime         | 0.0844     |
| StdReturn               | 70.5       |
| Time                    | 1.55e+03   |
| dLoss                   | 0.0554486  |
----------------------------------------
itr #137 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 137...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5161, #subsample_inputs: 5161
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.63       |
| AbsLearnSignalNew       | 0.63       |
| AbsLearningOld          | 0.63       |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 14.5824    |
| AveragePolicyStd        | 0.862322   |
| AverageReturn           | 395        |
| Entropy                 | 7.6214     |
| EnvExecTime             | 2.45       |
| ExplainedVariance       | 0.643      |
| Iteration               | 137        |
| ItrTime                 | 11.9       |
| LossAfter               | 0.358856   |
| LossBefore              | 0.399777   |
| MaxReturn               | 559        |
| MeanKL                  | 0.00642449 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 109        |
| NumTrajs                | 23         |
| Perplexity              | 2041.43    |
| PolicyExecTime          | 0.487      |
| ProcessExecTime         | 0.0664     |
| StdReturn               | 92.4       |
| Time                    | 1.56e+03   |
| dLoss                   | 0.0409206  |
----------------------------------------
itr #138 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 138...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5118, #subsample_inputs: 5118
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.65       |
| AbsLearnSignalNew       | 0.65       |
| AbsLearningOld          | 0.65       |
| AverageDiscountedReturn | 123        |
| AveragePhiLoss          | 12.86      |
| AveragePolicyStd        | 0.859231   |
| AverageReturn           | 385        |
| Entropy                 | 7.5998     |
| EnvExecTime             | 2.92       |
| ExplainedVariance       | 0.58       |
| Iteration               | 138        |
| ItrTime                 | 10.4       |
| LossAfter               | -0.124446  |
| LossBefore              | -0.0828219 |
| MaxReturn               | 511        |
| MeanKL                  | 0.0064253  |
| MeanKLBefore            | 0.0        |
| MinReturn               | 123        |
| NumTrajs                | 22         |
| Perplexity              | 1997.79    |
| PolicyExecTime          | 0.62       |
| ProcessExecTime         | 0.0859     |
| StdReturn               | 102        |
| Time                    | 1.57e+03   |
| dLoss                   | 0.0416237  |
----------------------------------------
itr #139 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 139...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5011, #subsample_inputs: 5011
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.707      |
| AbsLearnSignalNew       | 0.707      |
| AbsLearningOld          | 0.707      |
| AverageDiscountedReturn | 124        |
| AveragePhiLoss          | 12.8411    |
| AveragePolicyStd        | 0.860283   |
| AverageReturn           | 387        |
| Entropy                 | 7.60671    |
| EnvExecTime             | 2.78       |
| ExplainedVariance       | 0.648      |
| Iteration               | 139        |
| ItrTime                 | 11.8       |
| LossAfter               | 0.0123414  |
| LossBefore              | 0.0689784  |
| MaxReturn               | 522        |
| MeanKL                  | 0.00997823 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 95.2       |
| NumTrajs                | 22         |
| Perplexity              | 2011.65    |
| PolicyExecTime          | 0.606      |
| ProcessExecTime         | 0.0877     |
| StdReturn               | 102        |
| Time                    | 1.58e+03   |
| dLoss                   | 0.056637   |
----------------------------------------
itr #140 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 140...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5070, #subsample_inputs: 5070
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.694      |
| AbsLearnSignalNew       | 0.694      |
| AbsLearningOld          | 0.693      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 13.0788    |
| AveragePolicyStd        | 0.860304   |
| AverageReturn           | 370        |
| Entropy                 | 7.60653    |
| EnvExecTime             | 2.56       |
| ExplainedVariance       | 0.62       |
| Iteration               | 140        |
| ItrTime                 | 11.4       |
| LossAfter               | 0.677351   |
| LossBefore              | 0.717907   |
| MaxReturn               | 581        |
| MeanKL                  | 0.00640998 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 51.5       |
| NumTrajs                | 23         |
| Perplexity              | 2011.29    |
| PolicyExecTime          | 0.496      |
| ProcessExecTime         | 0.0696     |
| StdReturn               | 129        |
| Time                    | 1.59e+03   |
| dLoss                   | 0.0405561  |
----------------------------------------
itr #141 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 141...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5244, #subsample_inputs: 5244
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.72       |
| AbsLearnSignalNew       | 0.72       |
| AbsLearningOld          | 0.72       |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 13.2411    |
| AveragePolicyStd        | 0.860323   |
| AverageReturn           | 379        |
| Entropy                 | 7.60616    |
| EnvExecTime             | 3.02       |
| ExplainedVariance       | 0.617      |
| Iteration               | 141        |
| ItrTime                 | 11         |
| LossAfter               | 0.0469953  |
| LossBefore              | 0.102042   |
| MaxReturn               | 534        |
| MeanKL                  | 0.00986717 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 78.5       |
| NumTrajs                | 23         |
| Perplexity              | 2010.54    |
| PolicyExecTime          | 0.649      |
| ProcessExecTime         | 0.0898     |
| StdReturn               | 125        |
| Time                    | 1.61e+03   |
| dLoss                   | 0.0550463  |
----------------------------------------
itr #142 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 142...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5043, #subsample_inputs: 5043
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.734      |
| AbsLearnSignalNew       | 0.734      |
| AbsLearningOld          | 0.734      |
| AverageDiscountedReturn | 129        |
| AveragePhiLoss          | 12.4106    |
| AveragePolicyStd        | 0.859404   |
| AverageReturn           | 411        |
| Entropy                 | 7.59936    |
| EnvExecTime             | 2.74       |
| ExplainedVariance       | 0.642      |
| Iteration               | 142        |
| ItrTime                 | 11.7       |
| LossAfter               | 0.0192509  |
| LossBefore              | 0.07836    |
| MaxReturn               | 677        |
| MeanKL                  | 0.00990442 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 98.4       |
| NumTrajs                | 22         |
| Perplexity              | 1996.91    |
| PolicyExecTime          | 0.587      |
| ProcessExecTime         | 0.0774     |
| StdReturn               | 103        |
| Time                    | 1.62e+03   |
| dLoss                   | 0.0591091  |
----------------------------------------
itr #143 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 143...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5079, #subsample_inputs: 5079
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.721      |
| AbsLearnSignalNew       | 0.721      |
| AbsLearningOld          | 0.721      |
| AverageDiscountedReturn | 130        |
| AveragePhiLoss          | 13.1265    |
| AveragePolicyStd        | 0.85981    |
| AverageReturn           | 423        |
| Entropy                 | 7.60212    |
| EnvExecTime             | 2.71       |
| ExplainedVariance       | 0.706      |
| Iteration               | 143        |
| ItrTime                 | 11.2       |
| LossAfter               | -0.267692  |
| LossBefore              | -0.210129  |
| MaxReturn               | 614        |
| MeanKL                  | 0.00990076 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 292        |
| NumTrajs                | 22         |
| Perplexity              | 2002.44    |
| PolicyExecTime          | 0.552      |
| ProcessExecTime         | 0.0759     |
| StdReturn               | 74.3       |
| Time                    | 1.63e+03   |
| dLoss                   | 0.0575625  |
----------------------------------------
itr #144 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 144...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5178, #subsample_inputs: 5178
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.634     |
| AbsLearnSignalNew       | 0.634     |
| AbsLearningOld          | 0.634     |
| AverageDiscountedReturn | 127       |
| AveragePhiLoss          | 12.2108   |
| AveragePolicyStd        | 0.862682  |
| AverageReturn           | 372       |
| Entropy                 | 7.62163   |
| EnvExecTime             | 2.87      |
| ExplainedVariance       | 0.586     |
| Iteration               | 144       |
| ItrTime                 | 11.2      |
| LossAfter               | -0.417401 |
| LossBefore              | -0.370116 |
| MaxReturn               | 493       |
| MeanKL                  | 0.0099877 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 131       |
| NumTrajs                | 24        |
| Perplexity              | 2041.9    |
| PolicyExecTime          | 0.634     |
| ProcessExecTime         | 0.0863    |
| StdReturn               | 87.6      |
| Time                    | 1.64e+03  |
| dLoss                   | 0.047285  |
---------------------------------------
itr #145 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 145...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5129, #subsample_inputs: 5129
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.544      |
| AbsLearnSignalNew       | 0.544      |
| AbsLearningOld          | 0.544      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 14.0907    |
| AveragePolicyStd        | 0.861832   |
| AverageReturn           | 419        |
| Entropy                 | 7.61497    |
| EnvExecTime             | 2.75       |
| ExplainedVariance       | 0.00356    |
| Iteration               | 145        |
| ItrTime                 | 11.9       |
| LossAfter               | -0.879321  |
| LossBefore              | -0.834973  |
| MaxReturn               | 698        |
| MeanKL                  | 0.00650349 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 116        |
| NumTrajs                | 20         |
| Perplexity              | 2028.33    |
| PolicyExecTime          | 0.576      |
| ProcessExecTime         | 0.0784     |
| StdReturn               | 125        |
| Time                    | 1.65e+03   |
| dLoss                   | 0.0443488  |
----------------------------------------
itr #146 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 146...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5081, #subsample_inputs: 5081
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.727     |
| AbsLearnSignalNew       | 0.727     |
| AbsLearningOld          | 0.726     |
| AverageDiscountedReturn | 115       |
| AveragePhiLoss          | 13.5153   |
| AveragePolicyStd        | 0.859808  |
| AverageReturn           | 346       |
| Entropy                 | 7.59959   |
| EnvExecTime             | 2.74      |
| ExplainedVariance       | 0.541     |
| Iteration               | 146       |
| ItrTime                 | 11.2      |
| LossAfter               | -0.836678 |
| LossBefore              | -0.794558 |
| MaxReturn               | 531       |
| MeanKL                  | 0.0064079 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 76.4      |
| NumTrajs                | 22        |
| Perplexity              | 1997.38   |
| PolicyExecTime          | 0.551     |
| ProcessExecTime         | 0.0758    |
| StdReturn               | 131       |
| Time                    | 1.66e+03  |
| dLoss                   | 0.0421202 |
---------------------------------------
itr #147 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 147...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5139, #subsample_inputs: 5139
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.763      |
| AbsLearnSignalNew       | 0.763      |
| AbsLearningOld          | 0.763      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 12.7034    |
| AveragePolicyStd        | 0.859014   |
| AverageReturn           | 373        |
| Entropy                 | 7.5934     |
| EnvExecTime             | 2.95       |
| ExplainedVariance       | 0.595      |
| Iteration               | 147        |
| ItrTime                 | 11.4       |
| LossAfter               | -0.0406433 |
| LossBefore              | 0.0144244  |
| MaxReturn               | 614        |
| MeanKL                  | 0.00999106 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 59.7       |
| NumTrajs                | 23         |
| Perplexity              | 1985.05    |
| PolicyExecTime          | 0.629      |
| ProcessExecTime         | 0.0873     |
| StdReturn               | 135        |
| Time                    | 1.68e+03   |
| dLoss                   | 0.0550677  |
----------------------------------------
itr #148 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 148...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5186, #subsample_inputs: 5186
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
-----------------------------------------
| AbsLearnSignal          | 0.74        |
| AbsLearnSignalNew       | 0.74        |
| AbsLearningOld          | 0.74        |
| AverageDiscountedReturn | 119         |
| AveragePhiLoss          | 12.8906     |
| AveragePolicyStd        | 0.859479    |
| AverageReturn           | 385         |
| Entropy                 | 7.59725     |
| EnvExecTime             | 2.72        |
| ExplainedVariance       | 0.509       |
| Iteration               | 148         |
| ItrTime                 | 11.9        |
| LossAfter               | -0.00776205 |
| LossBefore              | 0.0452966   |
| MaxReturn               | 586         |
| MeanKL                  | 0.00973022  |
| MeanKLBefore            | 0.0         |
| MinReturn               | 76.9        |
| NumTrajs                | 22          |
| Perplexity              | 1992.71     |
| PolicyExecTime          | 0.556       |
| ProcessExecTime         | 0.0774      |
| StdReturn               | 128         |
| Time                    | 1.69e+03    |
| dLoss                   | 0.0530586   |
-----------------------------------------
itr #149 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 149...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5073, #subsample_inputs: 5073
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.718      |
| AbsLearnSignalNew       | 0.718      |
| AbsLearningOld          | 0.718      |
| AverageDiscountedReturn | 124        |
| AveragePhiLoss          | 12.5025    |
| AveragePolicyStd        | 0.861946   |
| AverageReturn           | 375        |
| Entropy                 | 7.61458    |
| EnvExecTime             | 2.71       |
| ExplainedVariance       | 0.598      |
| Iteration               | 149        |
| ItrTime                 | 11.3       |
| LossAfter               | 0.452249   |
| LossBefore              | 0.492501   |
| MaxReturn               | 573        |
| MeanKL                  | 0.00647934 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 102        |
| NumTrajs                | 23         |
| Perplexity              | 2027.54    |
| PolicyExecTime          | 0.544      |
| ProcessExecTime         | 0.0761     |
| StdReturn               | 115        |
| Time                    | 1.7e+03    |
| dLoss                   | 0.0402514  |
----------------------------------------
itr #150 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 150...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5050, #subsample_inputs: 5050
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.744      |
| AbsLearnSignalNew       | 0.744      |
| AbsLearningOld          | 0.743      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 12.7706    |
| AveragePolicyStd        | 0.859402   |
| AverageReturn           | 403        |
| Entropy                 | 7.59719    |
| EnvExecTime             | 2.79       |
| ExplainedVariance       | 0.469      |
| Iteration               | 150        |
| ItrTime                 | 11.1       |
| LossAfter               | 0.147619   |
| LossBefore              | 0.192146   |
| MaxReturn               | 524        |
| MeanKL                  | 0.00642897 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 102        |
| NumTrajs                | 22         |
| Perplexity              | 1992.59    |
| PolicyExecTime          | 0.596      |
| ProcessExecTime         | 0.0847     |
| StdReturn               | 95         |
| Time                    | 1.71e+03   |
| dLoss                   | 0.0445274  |
----------------------------------------
itr #151 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 151...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5135, #subsample_inputs: 5135
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.716      |
| AbsLearnSignalNew       | 0.716      |
| AbsLearningOld          | 0.716      |
| AverageDiscountedReturn | 133        |
| AveragePhiLoss          | 12.9059    |
| AveragePolicyStd        | 0.857731   |
| AverageReturn           | 418        |
| Entropy                 | 7.58464    |
| EnvExecTime             | 2.46       |
| ExplainedVariance       | 0.76       |
| Iteration               | 151        |
| ItrTime                 | 11.6       |
| LossAfter               | 0.117254   |
| LossBefore              | 0.173994   |
| MaxReturn               | 543        |
| MeanKL                  | 0.00988407 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 287        |
| NumTrajs                | 23         |
| Perplexity              | 1967.73    |
| PolicyExecTime          | 0.537      |
| ProcessExecTime         | 0.0737     |
| StdReturn               | 61         |
| Time                    | 1.72e+03   |
| dLoss                   | 0.0567401  |
----------------------------------------
itr #152 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 152...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5057, #subsample_inputs: 5057
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
-----------------------------------------
| AbsLearnSignal          | 0.744       |
| AbsLearnSignalNew       | 0.744       |
| AbsLearningOld          | 0.744       |
| AverageDiscountedReturn | 131         |
| AveragePhiLoss          | 12.8071     |
| AveragePolicyStd        | 0.85799     |
| AverageReturn           | 444         |
| Entropy                 | 7.58663     |
| EnvExecTime             | 2.89        |
| ExplainedVariance       | 0.751       |
| Iteration               | 152         |
| ItrTime                 | 10.7        |
| LossAfter               | -0.00273963 |
| LossBefore              | 0.0523382   |
| MaxReturn               | 642         |
| MeanKL                  | 0.00982903  |
| MeanKLBefore            | 0.0         |
| MinReturn               | 322         |
| NumTrajs                | 21          |
| Perplexity              | 1971.65     |
| PolicyExecTime          | 0.607       |
| ProcessExecTime         | 0.0845      |
| StdReturn               | 78.1        |
| Time                    | 1.73e+03    |
| dLoss                   | 0.0550779   |
-----------------------------------------
itr #153 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 153...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5164, #subsample_inputs: 5164
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.649      |
| AbsLearnSignalNew       | 0.649      |
| AbsLearningOld          | 0.648      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 12.6681    |
| AveragePolicyStd        | 0.854995   |
| AverageReturn           | 405        |
| Entropy                 | 7.56596    |
| EnvExecTime             | 3.02       |
| ExplainedVariance       | 0.43       |
| Iteration               | 153        |
| ItrTime                 | 12         |
| LossAfter               | 0.618334   |
| LossBefore              | 0.667407   |
| MaxReturn               | 677        |
| MeanKL                  | 0.00988599 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 61.7       |
| NumTrajs                | 23         |
| Perplexity              | 1931.33    |
| PolicyExecTime          | 0.661      |
| ProcessExecTime         | 0.0895     |
| StdReturn               | 153        |
| Time                    | 1.74e+03   |
| dLoss                   | 0.0490735  |
----------------------------------------
itr #154 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 154...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5143, #subsample_inputs: 5143
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.723      |
| AbsLearnSignalNew       | 0.723      |
| AbsLearningOld          | 0.723      |
| AverageDiscountedReturn | 116        |
| AveragePhiLoss          | 13.7311    |
| AveragePolicyStd        | 0.858056   |
| AverageReturn           | 361        |
| Entropy                 | 7.5871     |
| EnvExecTime             | 2.68       |
| ExplainedVariance       | 0.502      |
| Iteration               | 154        |
| ItrTime                 | 11.8       |
| LossAfter               | 0.0512131  |
| LossBefore              | 0.0998804  |
| MaxReturn               | 538        |
| MeanKL                  | 0.00985937 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 57.2       |
| NumTrajs                | 22         |
| Perplexity              | 1972.59    |
| PolicyExecTime          | 0.541      |
| ProcessExecTime         | 0.0747     |
| StdReturn               | 132        |
| Time                    | 1.76e+03   |
| dLoss                   | 0.0486673  |
----------------------------------------
itr #155 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 155...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5370, #subsample_inputs: 5370
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.712      |
| AbsLearnSignalNew       | 0.712      |
| AbsLearningOld          | 0.712      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 12.2652    |
| AveragePolicyStd        | 0.862453   |
| AverageReturn           | 378        |
| Entropy                 | 7.61745    |
| EnvExecTime             | 2.91       |
| ExplainedVariance       | 0.533      |
| Iteration               | 155        |
| ItrTime                 | 11         |
| LossAfter               | -0.169879  |
| LossBefore              | -0.117194  |
| MaxReturn               | 598        |
| MeanKL                  | 0.00988754 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 57         |
| NumTrajs                | 25         |
| Perplexity              | 2033.38    |
| PolicyExecTime          | 0.616      |
| ProcessExecTime         | 0.0887     |
| StdReturn               | 130        |
| Time                    | 1.77e+03   |
| dLoss                   | 0.0526842  |
----------------------------------------
itr #156 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 156...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5104, #subsample_inputs: 5104
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.733      |
| AbsLearnSignalNew       | 0.733      |
| AbsLearningOld          | 0.733      |
| AverageDiscountedReturn | 123        |
| AveragePhiLoss          | 12.7292    |
| AveragePolicyStd        | 0.863242   |
| AverageReturn           | 409        |
| Entropy                 | 7.62324    |
| EnvExecTime             | 3.17       |
| ExplainedVariance       | 0.566      |
| Iteration               | 156        |
| ItrTime                 | 12         |
| LossAfter               | 0.622195   |
| LossBefore              | 0.674145   |
| MaxReturn               | 595        |
| MeanKL                  | 0.00994196 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 130        |
| NumTrajs                | 21         |
| Perplexity              | 2045.17    |
| PolicyExecTime          | 0.664      |
| ProcessExecTime         | 0.09       |
| StdReturn               | 103        |
| Time                    | 1.78e+03   |
| dLoss                   | 0.0519504  |
----------------------------------------
itr #157 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 157...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5167, #subsample_inputs: 5167
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.675      |
| AbsLearnSignalNew       | 0.675      |
| AbsLearningOld          | 0.675      |
| AverageDiscountedReturn | 133        |
| AveragePhiLoss          | 12.4154    |
| AveragePolicyStd        | 0.865765   |
| AverageReturn           | 444        |
| Entropy                 | 7.64008    |
| EnvExecTime             | 2.71       |
| ExplainedVariance       | 0.6        |
| Iteration               | 157        |
| ItrTime                 | 11.8       |
| LossAfter               | 0.368492   |
| LossBefore              | 0.412993   |
| MaxReturn               | 621        |
| MeanKL                  | 0.00640527 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 82.5       |
| NumTrajs                | 22         |
| Perplexity              | 2079.92    |
| PolicyExecTime          | 0.569      |
| ProcessExecTime         | 0.0758     |
| StdReturn               | 111        |
| Time                    | 1.79e+03   |
| dLoss                   | 0.0445009  |
----------------------------------------
itr #158 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 158...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5045, #subsample_inputs: 5045
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.692      |
| AbsLearnSignalNew       | 0.692      |
| AbsLearningOld          | 0.692      |
| AverageDiscountedReturn | 130        |
| AveragePhiLoss          | 12.1915    |
| AveragePolicyStd        | 0.865925   |
| AverageReturn           | 425        |
| Entropy                 | 7.64057    |
| EnvExecTime             | 2.76       |
| ExplainedVariance       | 0.679      |
| Iteration               | 158        |
| ItrTime                 | 10.8       |
| LossAfter               | -0.535737  |
| LossBefore              | -0.49236   |
| MaxReturn               | 536        |
| MeanKL                  | 0.00642663 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 69         |
| NumTrajs                | 22         |
| Perplexity              | 2080.93    |
| PolicyExecTime          | 0.576      |
| ProcessExecTime         | 0.0809     |
| StdReturn               | 93.6       |
| Time                    | 1.8e+03    |
| dLoss                   | 0.0433767  |
----------------------------------------
itr #159 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 159...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5044, #subsample_inputs: 5044
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.716      |
| AbsLearnSignalNew       | 0.716      |
| AbsLearningOld          | 0.716      |
| AverageDiscountedReturn | 130        |
| AveragePhiLoss          | 12.5875    |
| AveragePolicyStd        | 0.865048   |
| AverageReturn           | 472        |
| Entropy                 | 7.63398    |
| EnvExecTime             | 2.83       |
| ExplainedVariance       | 0.611      |
| Iteration               | 159        |
| ItrTime                 | 11.1       |
| LossAfter               | -0.765198  |
| LossBefore              | -0.708708  |
| MaxReturn               | 725        |
| MeanKL                  | 0.00989395 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 346        |
| NumTrajs                | 20         |
| Perplexity              | 2067.26    |
| PolicyExecTime          | 0.596      |
| ProcessExecTime         | 0.083      |
| StdReturn               | 91         |
| Time                    | 1.81e+03   |
| dLoss                   | 0.0564892  |
----------------------------------------
itr #160 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 160...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5170, #subsample_inputs: 5170
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.654      |
| AbsLearnSignalNew       | 0.654      |
| AbsLearningOld          | 0.654      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 12.666     |
| AveragePolicyStd        | 0.866351   |
| AverageReturn           | 414        |
| Entropy                 | 7.64198    |
| EnvExecTime             | 2.66       |
| ExplainedVariance       | 0.497      |
| Iteration               | 160        |
| ItrTime                 | 11.8       |
| LossAfter               | -0.734777  |
| LossBefore              | -0.692721  |
| MaxReturn               | 676        |
| MeanKL                  | 0.00644323 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 118        |
| NumTrajs                | 22         |
| Perplexity              | 2083.87    |
| PolicyExecTime          | 0.558      |
| ProcessExecTime         | 0.0766     |
| StdReturn               | 130        |
| Time                    | 1.83e+03   |
| dLoss                   | 0.0420557  |
----------------------------------------
itr #161 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 161...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5193, #subsample_inputs: 5193
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.698      |
| AbsLearnSignalNew       | 0.698      |
| AbsLearningOld          | 0.698      |
| AverageDiscountedReturn | 129        |
| AveragePhiLoss          | 13.1471    |
| AveragePolicyStd        | 0.863657   |
| AverageReturn           | 431        |
| Entropy                 | 7.62164    |
| EnvExecTime             | 2.75       |
| ExplainedVariance       | 0.589      |
| Iteration               | 161        |
| ItrTime                 | 11.3       |
| LossAfter               | -0.252345  |
| LossBefore              | -0.204802  |
| MaxReturn               | 608        |
| MeanKL                  | 0.00653139 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 33.2       |
| NumTrajs                | 22         |
| Perplexity              | 2041.91    |
| PolicyExecTime          | 0.549      |
| ProcessExecTime         | 0.075      |
| StdReturn               | 125        |
| Time                    | 1.84e+03   |
| dLoss                   | 0.047543   |
----------------------------------------
itr #162 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 162...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5013, #subsample_inputs: 5013
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.723      |
| AbsLearnSignalNew       | 0.723      |
| AbsLearningOld          | 0.723      |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 13.0555    |
| AveragePolicyStd        | 0.857525   |
| AverageReturn           | 414        |
| Entropy                 | 7.57785    |
| EnvExecTime             | 2.92       |
| ExplainedVariance       | 0.473      |
| Iteration               | 162        |
| ItrTime                 | 11.2       |
| LossAfter               | 0.112713   |
| LossBefore              | 0.168908   |
| MaxReturn               | 633        |
| MeanKL                  | 0.00996859 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 69.9       |
| NumTrajs                | 21         |
| Perplexity              | 1954.42    |
| PolicyExecTime          | 0.622      |
| ProcessExecTime         | 0.0875     |
| StdReturn               | 143        |
| Time                    | 1.85e+03   |
| dLoss                   | 0.0561956  |
----------------------------------------
itr #163 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 163...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5001, #subsample_inputs: 5001
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.687      |
| AbsLearnSignalNew       | 0.687      |
| AbsLearningOld          | 0.687      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 14.168     |
| AveragePolicyStd        | 0.857834   |
| AverageReturn           | 476        |
| Entropy                 | 7.58064    |
| EnvExecTime             | 2.49       |
| ExplainedVariance       | 0.548      |
| Iteration               | 163        |
| ItrTime                 | 11.5       |
| LossAfter               | -0.305745  |
| LossBefore              | -0.248008  |
| MaxReturn               | 727        |
| MeanKL                  | 0.00640555 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 69.8       |
| NumTrajs                | 19         |
| Perplexity              | 1959.87    |
| PolicyExecTime          | 0.508      |
| ProcessExecTime         | 0.0727     |
| StdReturn               | 149        |
| Time                    | 1.86e+03   |
| dLoss                   | 0.0577364  |
----------------------------------------
itr #164 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 164...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5056, #subsample_inputs: 5056
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.674      |
| AbsLearnSignalNew       | 0.674      |
| AbsLearningOld          | 0.674      |
| AverageDiscountedReturn | 124        |
| AveragePhiLoss          | 13.0359    |
| AveragePolicyStd        | 0.856555   |
| AverageReturn           | 401        |
| Entropy                 | 7.57084    |
| EnvExecTime             | 2.85       |
| ExplainedVariance       | 0.48       |
| Iteration               | 164        |
| ItrTime                 | 10.6       |
| LossAfter               | -0.676784  |
| LossBefore              | -0.637181  |
| MaxReturn               | 674        |
| MeanKL                  | 0.00641532 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 88.9       |
| NumTrajs                | 22         |
| Perplexity              | 1940.77    |
| PolicyExecTime          | 0.605      |
| ProcessExecTime         | 0.0865     |
| StdReturn               | 156        |
| Time                    | 1.87e+03   |
| dLoss                   | 0.0396035  |
----------------------------------------
itr #165 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 165...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5204, #subsample_inputs: 5204
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.726      |
| AbsLearnSignalNew       | 0.726      |
| AbsLearningOld          | 0.726      |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 13.0291    |
| AveragePolicyStd        | 0.853006   |
| AverageReturn           | 432        |
| Entropy                 | 7.54614    |
| EnvExecTime             | 2.88       |
| ExplainedVariance       | 0.559      |
| Iteration               | 165        |
| ItrTime                 | 11.9       |
| LossAfter               | 0.407222   |
| LossBefore              | 0.461169   |
| MaxReturn               | 655        |
| MeanKL                  | 0.00992777 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 74.5       |
| NumTrajs                | 22         |
| Perplexity              | 1893.42    |
| PolicyExecTime          | 0.59       |
| ProcessExecTime         | 0.0866     |
| StdReturn               | 140        |
| Time                    | 1.88e+03   |
| dLoss                   | 0.0539465  |
----------------------------------------
itr #166 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 166...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5055, #subsample_inputs: 5055
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.71       |
| AbsLearnSignalNew       | 0.71       |
| AbsLearningOld          | 0.71       |
| AverageDiscountedReturn | 131        |
| AveragePhiLoss          | 13.2158    |
| AveragePolicyStd        | 0.854333   |
| AverageReturn           | 493        |
| Entropy                 | 7.55527    |
| EnvExecTime             | 2.59       |
| ExplainedVariance       | 0.528      |
| Iteration               | 166        |
| ItrTime                 | 11.6       |
| LossAfter               | 1.01926    |
| LossBefore              | 1.07151    |
| MaxReturn               | 672        |
| MeanKL                  | 0.00990383 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 125        |
| NumTrajs                | 19         |
| Perplexity              | 1910.79    |
| PolicyExecTime          | 0.513      |
| ProcessExecTime         | 0.0687     |
| StdReturn               | 123        |
| Time                    | 1.89e+03   |
| dLoss                   | 0.0522499  |
----------------------------------------
itr #167 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 167...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5084, #subsample_inputs: 5084
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.662      |
| AbsLearnSignalNew       | 0.662      |
| AbsLearningOld          | 0.662      |
| AverageDiscountedReturn | 129        |
| AveragePhiLoss          | 13.6193    |
| AveragePolicyStd        | 0.85306    |
| AverageReturn           | 512        |
| Entropy                 | 7.54598    |
| EnvExecTime             | 3.13       |
| ExplainedVariance       | 0.584      |
| Iteration               | 167        |
| ItrTime                 | 10.9       |
| LossAfter               | -0.0166882 |
| LossBefore              | 0.029887   |
| MaxReturn               | 943        |
| MeanKL                  | 0.00643729 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 76.3       |
| NumTrajs                | 19         |
| Perplexity              | 1893.11    |
| PolicyExecTime          | 0.68       |
| ProcessExecTime         | 0.0897     |
| StdReturn               | 170        |
| Time                    | 1.91e+03   |
| dLoss                   | 0.0465752  |
----------------------------------------
itr #168 | 
Mem: 741.886719
Obtaining samples...
Obtaining samples for iteration 168...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5089, #subsample_inputs: 5089
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.676      |
| AbsLearnSignalNew       | 0.676      |
| AbsLearningOld          | 0.676      |
| AverageDiscountedReturn | 117        |
| AveragePhiLoss          | 13.6161    |
| AveragePolicyStd        | 0.850078   |
| AverageReturn           | 433        |
| Entropy                 | 7.52384    |
| EnvExecTime             | 2.91       |
| ExplainedVariance       | 0.46       |
| Iteration               | 168        |
| ItrTime                 | 11.9       |
| LossAfter               | -0.142706  |
| LossBefore              | -0.0874989 |
| MaxReturn               | 742        |
| MeanKL                  | 0.00998993 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 78         |
| NumTrajs                | 20         |
| Perplexity              | 1851.67    |
| PolicyExecTime          | 0.599      |
| ProcessExecTime         | 0.0858     |
| StdReturn               | 199        |
| Time                    | 1.92e+03   |
| dLoss                   | 0.0552075  |
----------------------------------------
itr #169 | 
Mem: 743.167969
Obtaining samples...
Obtaining samples for iteration 169...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5098, #subsample_inputs: 5098
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.765      |
| AbsLearnSignalNew       | 0.765      |
| AbsLearningOld          | 0.766      |
| AverageDiscountedReturn | 133        |
| AveragePhiLoss          | 13.3961    |
| AveragePolicyStd        | 0.847565   |
| AverageReturn           | 473        |
| Entropy                 | 7.50619    |
| EnvExecTime             | 2.57       |
| ExplainedVariance       | 0.504      |
| Iteration               | 169        |
| ItrTime                 | 11.5       |
| LossAfter               | 0.364031   |
| LossBefore              | 0.418539   |
| MaxReturn               | 716        |
| MeanKL                  | 0.00999386 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 66         |
| NumTrajs                | 21         |
| Perplexity              | 1819.26    |
| PolicyExecTime          | 0.506      |
| ProcessExecTime         | 0.0674     |
| StdReturn               | 166        |
| Time                    | 1.93e+03   |
| dLoss                   | 0.0545084  |
----------------------------------------
itr #170 | 
Mem: 743.167969
Obtaining samples...
Obtaining samples for iteration 170...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5212, #subsample_inputs: 5212
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.688      |
| AbsLearnSignalNew       | 0.688      |
| AbsLearningOld          | 0.688      |
| AverageDiscountedReturn | 133        |
| AveragePhiLoss          | 14.475     |
| AveragePolicyStd        | 0.845428   |
| AverageReturn           | 473        |
| Entropy                 | 7.49322    |
| EnvExecTime             | 2.94       |
| ExplainedVariance       | 0.533      |
| Iteration               | 170        |
| ItrTime                 | 10.9       |
| LossAfter               | -0.0944144 |
| LossBefore              | -0.0500356 |
| MaxReturn               | 852        |
| MeanKL                  | 0.00640915 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 91.4       |
| NumTrajs                | 21         |
| Perplexity              | 1795.83    |
| PolicyExecTime          | 0.618      |
| ProcessExecTime         | 0.0868     |
| StdReturn               | 170        |
| Time                    | 1.94e+03   |
| dLoss                   | 0.0443788  |
----------------------------------------
itr #171 | 
Mem: 743.167969
Obtaining samples...
Obtaining samples for iteration 171...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5110, #subsample_inputs: 5110
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.729     |
| AbsLearnSignalNew       | 0.729     |
| AbsLearningOld          | 0.728     |
| AverageDiscountedReturn | 134       |
| AveragePhiLoss          | 13.7488   |
| AveragePolicyStd        | 0.842417  |
| AverageReturn           | 478       |
| Entropy                 | 7.47105   |
| EnvExecTime             | 3.11      |
| ExplainedVariance       | 0.562     |
| Iteration               | 171       |
| ItrTime                 | 12        |
| LossAfter               | -0.663568 |
| LossBefore              | -0.60699  |
| MaxReturn               | 715       |
| MeanKL                  | 0.0099989 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 135       |
| NumTrajs                | 20        |
| Perplexity              | 1756.46   |
| PolicyExecTime          | 0.652     |
| ProcessExecTime         | 0.0896    |
| StdReturn               | 139       |
| Time                    | 1.95e+03  |
| dLoss                   | 0.056578  |
---------------------------------------
itr #172 | 
Mem: 743.167969
Obtaining samples...
Obtaining samples for iteration 172...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5020, #subsample_inputs: 5020
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.719      |
| AbsLearnSignalNew       | 0.719      |
| AbsLearningOld          | 0.719      |
| AverageDiscountedReturn | 132        |
| AveragePhiLoss          | 14.0222    |
| AveragePolicyStd        | 0.840339   |
| AverageReturn           | 544        |
| Entropy                 | 7.45447    |
| EnvExecTime             | 2.76       |
| ExplainedVariance       | 0.421      |
| Iteration               | 172        |
| ItrTime                 | 11.8       |
| LossAfter               | -1.38064   |
| LossBefore              | -1.32353   |
| MaxReturn               | 785        |
| MeanKL                  | 0.00990166 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 82.5       |
| NumTrajs                | 18         |
| Perplexity              | 1727.57    |
| PolicyExecTime          | 0.575      |
| ProcessExecTime         | 0.0712     |
| StdReturn               | 170        |
| Time                    | 1.96e+03   |
| dLoss                   | 0.0571097  |
----------------------------------------
itr #173 | 
Mem: 743.679688
Obtaining samples...
Obtaining samples for iteration 173...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5103, #subsample_inputs: 5103
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.694      |
| AbsLearnSignalNew       | 0.694      |
| AbsLearningOld          | 0.694      |
| AverageDiscountedReturn | 118        |
| AveragePhiLoss          | 14.4106    |
| AveragePolicyStd        | 0.842591   |
| AverageReturn           | 405        |
| Entropy                 | 7.47047    |
| EnvExecTime             | 3.12       |
| ExplainedVariance       | 0.508      |
| Iteration               | 173        |
| ItrTime                 | 11         |
| LossAfter               | -0.272374  |
| LossBefore              | -0.234264  |
| MaxReturn               | 965        |
| MeanKL                  | 0.00647844 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 60.4       |
| NumTrajs                | 21         |
| Perplexity              | 1755.44    |
| PolicyExecTime          | 0.658      |
| ProcessExecTime         | 0.0892     |
| StdReturn               | 208        |
| Time                    | 1.98e+03   |
| dLoss                   | 0.0381106  |
----------------------------------------
itr #174 | 
Mem: 745.160156
Obtaining samples...
Obtaining samples for iteration 174...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5078, #subsample_inputs: 5078
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.617      |
| AbsLearnSignalNew       | 0.617      |
| AbsLearningOld          | 0.617      |
| AverageDiscountedReturn | 133        |
| AveragePhiLoss          | 14.0744    |
| AveragePolicyStd        | 0.840402   |
| AverageReturn           | 510        |
| Entropy                 | 7.45631    |
| EnvExecTime             | 2.91       |
| ExplainedVariance       | -0.192     |
| Iteration               | 174        |
| ItrTime                 | 11.9       |
| LossAfter               | -0.604831  |
| LossBefore              | -0.557854  |
| MaxReturn               | 760        |
| MeanKL                  | 0.00646044 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 329        |
| NumTrajs                | 19         |
| Perplexity              | 1730.74    |
| PolicyExecTime          | 0.624      |
| ProcessExecTime         | 0.0892     |
| StdReturn               | 110        |
| Time                    | 1.99e+03   |
| dLoss                   | 0.0469767  |
----------------------------------------
itr #175 | 
Mem: 745.160156
Obtaining samples...
Obtaining samples for iteration 175...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5175, #subsample_inputs: 5175
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.712      |
| AbsLearnSignalNew       | 0.712      |
| AbsLearningOld          | 0.712      |
| AverageDiscountedReturn | 135        |
| AveragePhiLoss          | 14.2219    |
| AveragePolicyStd        | 0.838602   |
| AverageReturn           | 539        |
| Entropy                 | 7.44264    |
| EnvExecTime             | 2.62       |
| ExplainedVariance       | 0.578      |
| Iteration               | 175        |
| ItrTime                 | 11.8       |
| LossAfter               | -0.60084   |
| LossBefore              | -0.55338   |
| MaxReturn               | 870        |
| MeanKL                  | 0.00644687 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 182        |
| NumTrajs                | 19         |
| Perplexity              | 1707.24    |
| PolicyExecTime          | 0.518      |
| ProcessExecTime         | 0.0689     |
| StdReturn               | 160        |
| Time                    | 2e+03      |
| dLoss                   | 0.0474598  |
----------------------------------------
itr #176 | 
Mem: 745.160156
Obtaining samples...
Obtaining samples for iteration 176...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5271, #subsample_inputs: 5271
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.696      |
| AbsLearnSignalNew       | 0.696      |
| AbsLearningOld          | 0.696      |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 13.987     |
| AveragePolicyStd        | 0.838752   |
| AverageReturn           | 588        |
| Entropy                 | 7.44395    |
| EnvExecTime             | 2.95       |
| ExplainedVariance       | 0.509      |
| Iteration               | 176        |
| ItrTime                 | 10.6       |
| LossAfter               | -0.510244  |
| LossBefore              | -0.466828  |
| MaxReturn               | 974        |
| MeanKL                  | 0.00640305 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 149        |
| NumTrajs                | 17         |
| Perplexity              | 1709.5     |
| PolicyExecTime          | 0.614      |
| ProcessExecTime         | 0.0856     |
| StdReturn               | 200        |
| Time                    | 2.01e+03   |
| dLoss                   | 0.0434153  |
----------------------------------------
itr #177 | 
Mem: 747.378906
Obtaining samples...
Obtaining samples for iteration 177...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5117, #subsample_inputs: 5117
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.701      |
| AbsLearnSignalNew       | 0.701      |
| AbsLearningOld          | 0.701      |
| AverageDiscountedReturn | 132        |
| AveragePhiLoss          | 14.902     |
| AveragePolicyStd        | 0.839971   |
| AverageReturn           | 556        |
| Entropy                 | 7.45158    |
| EnvExecTime             | 3.22       |
| ExplainedVariance       | 0.577      |
| Iteration               | 177        |
| ItrTime                 | 12.4       |
| LossAfter               | -0.976405  |
| LossBefore              | -0.929994  |
| MaxReturn               | 958        |
| MeanKL                  | 0.00641948 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 93.8       |
| NumTrajs                | 18         |
| Perplexity              | 1722.58    |
| PolicyExecTime          | 0.689      |
| ProcessExecTime         | 0.0912     |
| StdReturn               | 191        |
| Time                    | 2.02e+03   |
| dLoss                   | 0.046411   |
----------------------------------------
itr #178 | 
Mem: 748.007812
Obtaining samples...
Obtaining samples for iteration 178...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5021, #subsample_inputs: 5021
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.691      |
| AbsLearnSignalNew       | 0.691      |
| AbsLearningOld          | 0.691      |
| AverageDiscountedReturn | 127        |
| AveragePhiLoss          | 13.9618    |
| AveragePolicyStd        | 0.83791    |
| AverageReturn           | 483        |
| Entropy                 | 7.43637    |
| EnvExecTime             | 2.51       |
| ExplainedVariance       | 0.47       |
| Iteration               | 178        |
| ItrTime                 | 11.4       |
| LossAfter               | -0.951908  |
| LossBefore              | -0.897765  |
| MaxReturn               | 762        |
| MeanKL                  | 0.00990812 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 90         |
| NumTrajs                | 19         |
| Perplexity              | 1696.59    |
| PolicyExecTime          | 0.461      |
| ProcessExecTime         | 0.0641     |
| StdReturn               | 176        |
| Time                    | 2.03e+03   |
| dLoss                   | 0.0541431  |
----------------------------------------
itr #179 | 
Mem: 748.007812
Obtaining samples...
Obtaining samples for iteration 179...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5214, #subsample_inputs: 5214
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.702      |
| AbsLearnSignalNew       | 0.702      |
| AbsLearningOld          | 0.702      |
| AverageDiscountedReturn | 136        |
| AveragePhiLoss          | 14.0837    |
| AveragePolicyStd        | 0.836391   |
| AverageReturn           | 625        |
| Entropy                 | 7.42335    |
| EnvExecTime             | 3.24       |
| ExplainedVariance       | 0.464      |
| Iteration               | 179        |
| ItrTime                 | 11         |
| LossAfter               | -0.342361  |
| LossBefore              | -0.296833  |
| MaxReturn               | 940        |
| MeanKL                  | 0.00642255 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 342        |
| NumTrajs                | 17         |
| Perplexity              | 1674.64    |
| PolicyExecTime          | 0.683      |
| ProcessExecTime         | 0.088      |
| StdReturn               | 179        |
| Time                    | 2.04e+03   |
| dLoss                   | 0.0455281  |
----------------------------------------
itr #180 | 
Mem: 748.007812
Obtaining samples...
Obtaining samples for iteration 180...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5225, #subsample_inputs: 5225
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.611      |
| AbsLearnSignalNew       | 0.611      |
| AbsLearningOld          | 0.611      |
| AverageDiscountedReturn | 123        |
| AveragePhiLoss          | 13.7748    |
| AveragePolicyStd        | 0.836623   |
| AverageReturn           | 449        |
| Entropy                 | 7.4245     |
| EnvExecTime             | 3.16       |
| ExplainedVariance       | 0.429      |
| Iteration               | 180        |
| ItrTime                 | 12.4       |
| LossAfter               | -0.976234  |
| LossBefore              | -0.93754   |
| MaxReturn               | 897        |
| MeanKL                  | 0.00640559 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 65.5       |
| NumTrajs                | 21         |
| Perplexity              | 1676.56    |
| PolicyExecTime          | 0.659      |
| ProcessExecTime         | 0.0885     |
| StdReturn               | 204        |
| Time                    | 2.06e+03   |
| dLoss                   | 0.0386944  |
----------------------------------------
itr #181 | 
Mem: 748.007812
Obtaining samples...
Obtaining samples for iteration 181...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5053, #subsample_inputs: 5053
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.725      |
| AbsLearnSignalNew       | 0.725      |
| AbsLearningOld          | 0.725      |
| AverageDiscountedReturn | 133        |
| AveragePhiLoss          | 13.2118    |
| AveragePolicyStd        | 0.836208   |
| AverageReturn           | 563        |
| Entropy                 | 7.42218    |
| EnvExecTime             | 2.59       |
| ExplainedVariance       | 0.486      |
| Iteration               | 181        |
| ItrTime                 | 11.5       |
| LossAfter               | -0.387444  |
| LossBefore              | -0.336031  |
| MaxReturn               | 1.11e+03   |
| MeanKL                  | 0.00983844 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 81.8       |
| NumTrajs                | 18         |
| Perplexity              | 1672.67    |
| PolicyExecTime          | 0.515      |
| ProcessExecTime         | 0.0644     |
| StdReturn               | 280        |
| Time                    | 2.07e+03   |
| dLoss                   | 0.0514131  |
----------------------------------------
itr #182 | 
Mem: 748.007812
Obtaining samples...
Obtaining samples for iteration 182...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5018, #subsample_inputs: 5018
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.721      |
| AbsLearnSignalNew       | 0.721      |
| AbsLearningOld          | 0.721      |
| AverageDiscountedReturn | 127        |
| AveragePhiLoss          | 14.184     |
| AveragePolicyStd        | 0.835262   |
| AverageReturn           | 563        |
| Entropy                 | 7.41495    |
| EnvExecTime             | 2.96       |
| ExplainedVariance       | 0.464      |
| Iteration               | 182        |
| ItrTime                 | 10.6       |
| LossAfter               | -0.679056  |
| LossBefore              | -0.630571  |
| MaxReturn               | 1.22e+03   |
| MeanKL                  | 0.00642553 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 87         |
| NumTrajs                | 17         |
| Perplexity              | 1660.62    |
| PolicyExecTime          | 0.617      |
| ProcessExecTime         | 0.0812     |
| StdReturn               | 271        |
| Time                    | 2.08e+03   |
| dLoss                   | 0.0484851  |
----------------------------------------
itr #183 | 
Mem: 748.007812
Obtaining samples...
Obtaining samples for iteration 183...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5106, #subsample_inputs: 5106
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.728      |
| AbsLearnSignalNew       | 0.728      |
| AbsLearningOld          | 0.728      |
| AverageDiscountedReturn | 131        |
| AveragePhiLoss          | 14.125     |
| AveragePolicyStd        | 0.835754   |
| AverageReturn           | 467        |
| Entropy                 | 7.41829    |
| EnvExecTime             | 3.13       |
| ExplainedVariance       | 0.453      |
| Iteration               | 183        |
| ItrTime                 | 12.5       |
| LossAfter               | -0.563303  |
| LossBefore              | -0.507374  |
| MaxReturn               | 921        |
| MeanKL                  | 0.00984852 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 71.7       |
| NumTrajs                | 21         |
| Perplexity              | 1666.18    |
| PolicyExecTime          | 0.654      |
| ProcessExecTime         | 0.0931     |
| StdReturn               | 198        |
| Time                    | 2.09e+03   |
| dLoss                   | 0.0559291  |
----------------------------------------
itr #184 | 
Mem: 748.007812
Obtaining samples...
Obtaining samples for iteration 184...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5074, #subsample_inputs: 5074
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.715     |
| AbsLearnSignalNew       | 0.715     |
| AbsLearningOld          | 0.715     |
| AverageDiscountedReturn | 127       |
| AveragePhiLoss          | 14.8404   |
| AveragePolicyStd        | 0.834352  |
| AverageReturn           | 583       |
| Entropy                 | 7.40771   |
| EnvExecTime             | 2.49      |
| ExplainedVariance       | 0.377     |
| Iteration               | 184       |
| ItrTime                 | 11.1      |
| LossAfter               | -0.825021 |
| LossBefore              | -0.777898 |
| MaxReturn               | 1.66e+03  |
| MeanKL                  | 0.0064916 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 94        |
| NumTrajs                | 17        |
| Perplexity              | 1648.65   |
| PolicyExecTime          | 0.475     |
| ProcessExecTime         | 0.0634    |
| StdReturn               | 307       |
| Time                    | 2.1e+03   |
| dLoss                   | 0.0471231 |
---------------------------------------
itr #185 | 
Mem: 748.007812
Obtaining samples...
Obtaining samples for iteration 185...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5199, #subsample_inputs: 5199
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.73       |
| AbsLearnSignalNew       | 0.73       |
| AbsLearningOld          | 0.73       |
| AverageDiscountedReturn | 139        |
| AveragePhiLoss          | 14.7474    |
| AveragePolicyStd        | 0.832287   |
| AverageReturn           | 611        |
| Entropy                 | 7.3931     |
| EnvExecTime             | 3.07       |
| ExplainedVariance       | 0.554      |
| Iteration               | 185        |
| ItrTime                 | 10.9       |
| LossAfter               | -0.0837678 |
| LossBefore              | -0.0289911 |
| MaxReturn               | 1.24e+03   |
| MeanKL                  | 0.00986181 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 93.5       |
| NumTrajs                | 18         |
| Perplexity              | 1624.73    |
| PolicyExecTime          | 0.648      |
| ProcessExecTime         | 0.0867     |
| StdReturn               | 270        |
| Time                    | 2.11e+03   |
| dLoss                   | 0.0547767  |
----------------------------------------
itr #186 | 
Mem: 748.007812
Obtaining samples...
Obtaining samples for iteration 186...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5150, #subsample_inputs: 5150
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.693      |
| AbsLearnSignalNew       | 0.693      |
| AbsLearningOld          | 0.693      |
| AverageDiscountedReturn | 134        |
| AveragePhiLoss          | 14.4197    |
| AveragePolicyStd        | 0.831507   |
| AverageReturn           | 578        |
| Entropy                 | 7.38631    |
| EnvExecTime             | 2.93       |
| ExplainedVariance       | 0.456      |
| Iteration               | 186        |
| ItrTime                 | 12.4       |
| LossAfter               | -0.625915  |
| LossBefore              | -0.580238  |
| MaxReturn               | 1.3e+03    |
| MeanKL                  | 0.00640428 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 73.3       |
| NumTrajs                | 18         |
| Perplexity              | 1613.74    |
| PolicyExecTime          | 0.639      |
| ProcessExecTime         | 0.0867     |
| StdReturn               | 263        |
| Time                    | 2.13e+03   |
| dLoss                   | 0.0456774  |
----------------------------------------
itr #187 | 
Mem: 748.007812
Obtaining samples...
Obtaining samples for iteration 187...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5509, #subsample_inputs: 5509
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.642     |
| AbsLearnSignalNew       | 0.642     |
| AbsLearningOld          | 0.642     |
| AverageDiscountedReturn | 119       |
| AveragePhiLoss          | 14.42     |
| AveragePolicyStd        | 0.828995  |
| AverageReturn           | 535       |
| Entropy                 | 7.3685    |
| EnvExecTime             | 2.89      |
| ExplainedVariance       | 0.466     |
| Iteration               | 187       |
| ItrTime                 | 12        |
| LossAfter               | 0.479194  |
| LossBefore              | 0.516271  |
| MaxReturn               | 1.45e+03  |
| MeanKL                  | 0.0064962 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 51        |
| NumTrajs                | 19        |
| Perplexity              | 1585.26   |
| PolicyExecTime          | 0.547     |
| ProcessExecTime         | 0.0747    |
| StdReturn               | 360       |
| Time                    | 2.14e+03  |
| dLoss                   | 0.0370768 |
---------------------------------------
itr #188 | 
Mem: 749.246094
Obtaining samples...
Obtaining samples for iteration 188...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5763, #subsample_inputs: 5763
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.58       |
| AbsLearnSignalNew       | 0.58       |
| AbsLearningOld          | 0.58       |
| AverageDiscountedReturn | 135        |
| AveragePhiLoss          | 17.0315    |
| AveragePolicyStd        | 0.827405   |
| AverageReturn           | 827        |
| Entropy                 | 7.35752    |
| EnvExecTime             | 3.24       |
| ExplainedVariance       | -0.395     |
| Iteration               | 188        |
| ItrTime                 | 11.9       |
| LossAfter               | -0.502133  |
| LossBefore              | -0.452716  |
| MaxReturn               | 2.39e+03   |
| MeanKL                  | 0.00994977 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 139        |
| NumTrajs                | 15         |
| Perplexity              | 1567.95    |
| PolicyExecTime          | 0.689      |
| ProcessExecTime         | 0.0902     |
| StdReturn               | 557        |
| Time                    | 2.15e+03   |
| dLoss                   | 0.0494176  |
----------------------------------------
itr #189 | 
Mem: 750.015625
Obtaining samples...
Obtaining samples for iteration 189...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5144, #subsample_inputs: 5144
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.697      |
| AbsLearnSignalNew       | 0.697      |
| AbsLearningOld          | 0.697      |
| AverageDiscountedReturn | 146        |
| AveragePhiLoss          | 15.0057    |
| AveragePolicyStd        | 0.824007   |
| AverageReturn           | 824        |
| Entropy                 | 7.33521    |
| EnvExecTime             | 3.43       |
| ExplainedVariance       | 0.444      |
| Iteration               | 189        |
| ItrTime                 | 12.8       |
| LossAfter               | -0.417861  |
| LossBefore              | -0.37387   |
| MaxReturn               | 1.39e+03   |
| MeanKL                  | 0.00641609 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 390        |
| NumTrajs                | 14         |
| Perplexity              | 1533.35    |
| PolicyExecTime          | 0.726      |
| ProcessExecTime         | 0.0921     |
| StdReturn               | 308        |
| Time                    | 2.16e+03   |
| dLoss                   | 0.0439911  |
----------------------------------------
itr #190 | 
Mem: 750.265625
Obtaining samples...
Obtaining samples for iteration 190...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5167, #subsample_inputs: 5167
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.672      |
| AbsLearnSignalNew       | 0.672      |
| AbsLearningOld          | 0.672      |
| AverageDiscountedReturn | 135        |
| AveragePhiLoss          | 14.7326    |
| AveragePolicyStd        | 0.822905   |
| AverageReturn           | 666        |
| Entropy                 | 7.32798    |
| EnvExecTime             | 2.55       |
| ExplainedVariance       | 0.346      |
| Iteration               | 190        |
| ItrTime                 | 12         |
| LossAfter               | 0.0810053  |
| LossBefore              | 0.136143   |
| MaxReturn               | 1.41e+03   |
| MeanKL                  | 0.00996611 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 92         |
| NumTrajs                | 16         |
| Perplexity              | 1522.3     |
| PolicyExecTime          | 0.481      |
| ProcessExecTime         | 0.0675     |
| StdReturn               | 357        |
| Time                    | 2.18e+03   |
| dLoss                   | 0.0551373  |
----------------------------------------
itr #191 | 
Mem: 750.265625
Obtaining samples...
Obtaining samples for iteration 191...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5226, #subsample_inputs: 5226
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.712      |
| AbsLearnSignalNew       | 0.712      |
| AbsLearningOld          | 0.712      |
| AverageDiscountedReturn | 130        |
| AveragePhiLoss          | 15.4928    |
| AveragePolicyStd        | 0.818228   |
| AverageReturn           | 602        |
| Entropy                 | 7.29484    |
| EnvExecTime             | 2.95       |
| ExplainedVariance       | 0.515      |
| Iteration               | 191        |
| ItrTime                 | 10.9       |
| LossAfter               | 0.364607   |
| LossBefore              | 0.420628   |
| MaxReturn               | 1.07e+03   |
| MeanKL                  | 0.00982686 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 88.3       |
| NumTrajs                | 17         |
| Perplexity              | 1472.68    |
| PolicyExecTime          | 0.626      |
| ProcessExecTime         | 0.0847     |
| StdReturn               | 237        |
| Time                    | 2.19e+03   |
| dLoss                   | 0.0560217  |
----------------------------------------
itr #192 | 
Mem: 750.265625
Obtaining samples...
Obtaining samples for iteration 192...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5134, #subsample_inputs: 5134
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.663      |
| AbsLearnSignalNew       | 0.663      |
| AbsLearningOld          | 0.664      |
| AverageDiscountedReturn | 131        |
| AveragePhiLoss          | 14.9167    |
| AveragePolicyStd        | 0.821513   |
| AverageReturn           | 646        |
| Entropy                 | 7.3186     |
| EnvExecTime             | 3.14       |
| ExplainedVariance       | 0.453      |
| Iteration               | 192        |
| ItrTime                 | 12.4       |
| LossAfter               | -0.0422086 |
| LossBefore              | 0.0022593  |
| MaxReturn               | 1.21e+03   |
| MeanKL                  | 0.00643279 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 78         |
| NumTrajs                | 16         |
| Perplexity              | 1508.09    |
| PolicyExecTime          | 0.665      |
| ProcessExecTime         | 0.0886     |
| StdReturn               | 265        |
| Time                    | 2.2e+03    |
| dLoss                   | 0.0444679  |
----------------------------------------
itr #193 | 
Mem: 750.312500
Obtaining samples...
Obtaining samples for iteration 193...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5104, #subsample_inputs: 5104
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.672      |
| AbsLearnSignalNew       | 0.672      |
| AbsLearningOld          | 0.671      |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 15.4257    |
| AveragePolicyStd        | 0.820713   |
| AverageReturn           | 548        |
| Entropy                 | 7.31467    |
| EnvExecTime             | 2.65       |
| ExplainedVariance       | 0.41       |
| Iteration               | 193        |
| ItrTime                 | 11.5       |
| LossAfter               | 0.0620912  |
| LossBefore              | 0.118945   |
| MaxReturn               | 1.13e+03   |
| MeanKL                  | 0.00993759 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 89.3       |
| NumTrajs                | 18         |
| Perplexity              | 1502.18    |
| PolicyExecTime          | 0.509      |
| ProcessExecTime         | 0.0669     |
| StdReturn               | 279        |
| Time                    | 2.21e+03   |
| dLoss                   | 0.0568541  |
----------------------------------------
itr #194 | 
Mem: 750.312500
Obtaining samples...
Obtaining samples for iteration 194...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5182, #subsample_inputs: 5182
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.719      |
| AbsLearnSignalNew       | 0.719      |
| AbsLearningOld          | 0.719      |
| AverageDiscountedReturn | 134        |
| AveragePhiLoss          | 15.0578    |
| AveragePolicyStd        | 0.816829   |
| AverageReturn           | 629        |
| Entropy                 | 7.28693    |
| EnvExecTime             | 2.99       |
| ExplainedVariance       | 0.497      |
| Iteration               | 194        |
| ItrTime                 | 10.7       |
| LossAfter               | -0.734094  |
| LossBefore              | -0.681272  |
| MaxReturn               | 1.16e+03   |
| MeanKL                  | 0.00997892 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 107        |
| NumTrajs                | 17         |
| Perplexity              | 1461.08    |
| PolicyExecTime          | 0.63       |
| ProcessExecTime         | 0.086      |
| StdReturn               | 278        |
| Time                    | 2.22e+03   |
| dLoss                   | 0.0528224  |
----------------------------------------
itr #195 | 
Mem: 750.312500
Obtaining samples...
Obtaining samples for iteration 195...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5508, #subsample_inputs: 5508
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.701      |
| AbsLearnSignalNew       | 0.701      |
| AbsLearningOld          | 0.701      |
| AverageDiscountedReturn | 129        |
| AveragePhiLoss          | 15.0882    |
| AveragePolicyStd        | 0.815873   |
| AverageReturn           | 651        |
| Entropy                 | 7.27844    |
| EnvExecTime             | 3.57       |
| ExplainedVariance       | 0.52       |
| Iteration               | 195        |
| ItrTime                 | 13.2       |
| LossAfter               | 0.19056    |
| LossBefore              | 0.249968   |
| MaxReturn               | 1.34e+03   |
| MeanKL                  | 0.00986589 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 82.7       |
| NumTrajs                | 17         |
| Perplexity              | 1448.73    |
| PolicyExecTime          | 0.752      |
| ProcessExecTime         | 0.0956     |
| StdReturn               | 375        |
| Time                    | 2.24e+03   |
| dLoss                   | 0.059408   |
----------------------------------------
itr #196 | 
Mem: 750.316406
Obtaining samples...
Obtaining samples for iteration 196...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5035, #subsample_inputs: 5035
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.706      |
| AbsLearnSignalNew       | 0.706      |
| AbsLearningOld          | 0.706      |
| AverageDiscountedReturn | 133        |
| AveragePhiLoss          | 14.6401    |
| AveragePolicyStd        | 0.816253   |
| AverageReturn           | 659        |
| Entropy                 | 7.28133    |
| EnvExecTime             | 2.8        |
| ExplainedVariance       | 0.514      |
| Iteration               | 196        |
| ItrTime                 | 11.8       |
| LossAfter               | -0.281133  |
| LossBefore              | -0.223065  |
| MaxReturn               | 1.48e+03   |
| MeanKL                  | 0.00995668 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 81.4       |
| NumTrajs                | 16         |
| Perplexity              | 1452.91    |
| PolicyExecTime          | 0.523      |
| ProcessExecTime         | 0.0708     |
| StdReturn               | 319        |
| Time                    | 2.25e+03   |
| dLoss                   | 0.0580685  |
----------------------------------------
itr #197 | 
Mem: 750.316406
Obtaining samples...
Obtaining samples for iteration 197...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5402, #subsample_inputs: 5402
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.668      |
| AbsLearnSignalNew       | 0.668      |
| AbsLearningOld          | 0.667      |
| AverageDiscountedReturn | 110        |
| AveragePhiLoss          | 14.0604    |
| AveragePolicyStd        | 0.815694   |
| AverageReturn           | 467        |
| Entropy                 | 7.27712    |
| EnvExecTime             | 3.15       |
| ExplainedVariance       | 0.497      |
| Iteration               | 197        |
| ItrTime                 | 11.2       |
| LossAfter               | 0.372113   |
| LossBefore              | 0.416572   |
| MaxReturn               | 1.05e+03   |
| MeanKL                  | 0.00982565 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 46.6       |
| NumTrajs                | 20         |
| Perplexity              | 1446.82    |
| PolicyExecTime          | 0.627      |
| ProcessExecTime         | 0.0844     |
| StdReturn               | 358        |
| Time                    | 2.26e+03   |
| dLoss                   | 0.0444595  |
----------------------------------------
itr #198 | 
Mem: 750.316406
Obtaining samples...
Obtaining samples for iteration 198...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5042, #subsample_inputs: 5042
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.565      |
| AbsLearnSignalNew       | 0.565      |
| AbsLearningOld          | 0.565      |
| AverageDiscountedReturn | 124        |
| AveragePhiLoss          | 16.2705    |
| AveragePolicyStd        | 0.818302   |
| AverageReturn           | 599        |
| Entropy                 | 7.29581    |
| EnvExecTime             | 2.88       |
| ExplainedVariance       | -1.11      |
| Iteration               | 198        |
| ItrTime                 | 11.9       |
| LossAfter               | 0.162565   |
| LossBefore              | 0.233617   |
| MaxReturn               | 1.69e+03   |
| MeanKL                  | 0.00983256 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 26.2       |
| NumTrajs                | 16         |
| Perplexity              | 1474.12    |
| PolicyExecTime          | 0.598      |
| ProcessExecTime         | 0.0805     |
| StdReturn               | 436        |
| Time                    | 2.27e+03   |
| dLoss                   | 0.0710516  |
----------------------------------------
itr #199 | 
Mem: 750.316406
Obtaining samples...
Obtaining samples for iteration 199...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5472, #subsample_inputs: 5472
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.756      |
| AbsLearnSignalNew       | 0.756      |
| AbsLearningOld          | 0.756      |
| AverageDiscountedReturn | 133        |
| AveragePhiLoss          | 15.5903    |
| AveragePolicyStd        | 0.822129   |
| AverageReturn           | 835        |
| Entropy                 | 7.3245     |
| EnvExecTime             | 2.95       |
| ExplainedVariance       | 0.55       |
| Iteration               | 199        |
| ItrTime                 | 12.6       |
| LossAfter               | 0.273867   |
| LossBefore              | 0.316415   |
| MaxReturn               | 2.12e+03   |
| MeanKL                  | 0.00642409 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 122        |
| NumTrajs                | 14         |
| Perplexity              | 1517.02    |
| PolicyExecTime          | 0.604      |
| ProcessExecTime         | 0.0742     |
| StdReturn               | 561        |
| Time                    | 2.28e+03   |
| dLoss                   | 0.0425474  |
----------------------------------------
itr #200 | 
Mem: 750.562500
Obtaining samples...
Obtaining samples for iteration 200...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5197, #subsample_inputs: 5197
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.654      |
| AbsLearnSignalNew       | 0.654      |
| AbsLearningOld          | 0.654      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 15.8899    |
| AveragePolicyStd        | 0.82235    |
| AverageReturn           | 523        |
| Entropy                 | 7.3259     |
| EnvExecTime             | 3.45       |
| ExplainedVariance       | 0.504      |
| Iteration               | 200        |
| ItrTime                 | 11.7       |
| LossAfter               | 0.072677   |
| LossBefore              | 0.117259   |
| MaxReturn               | 1.22e+03   |
| MeanKL                  | 0.00641859 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 79.8       |
| NumTrajs                | 18         |
| Perplexity              | 1519.14    |
| PolicyExecTime          | 0.696      |
| ProcessExecTime         | 0.087      |
| StdReturn               | 333        |
| Time                    | 2.3e+03    |
| dLoss                   | 0.0445817  |
----------------------------------------
itr #201 | 
Mem: 750.562500
Obtaining samples...
Obtaining samples for iteration 201...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5230, #subsample_inputs: 5230
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.748      |
| AbsLearnSignalNew       | 0.748      |
| AbsLearningOld          | 0.748      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 15.2138    |
| AveragePolicyStd        | 0.819849   |
| AverageReturn           | 513        |
| Entropy                 | 7.30807    |
| EnvExecTime             | 3.17       |
| ExplainedVariance       | 0.56       |
| Iteration               | 201        |
| ItrTime                 | 11.8       |
| LossAfter               | 0.10727    |
| LossBefore              | 0.160644   |
| MaxReturn               | 1.37e+03   |
| MeanKL                  | 0.00986399 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 76.3       |
| NumTrajs                | 19         |
| Perplexity              | 1492.3     |
| PolicyExecTime          | 0.636      |
| ProcessExecTime         | 0.0846     |
| StdReturn               | 375        |
| Time                    | 2.31e+03   |
| dLoss                   | 0.0533736  |
----------------------------------------
itr #202 | 
Mem: 750.562500
Obtaining samples...
Obtaining samples for iteration 202...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5053, #subsample_inputs: 5053
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.769      |
| AbsLearnSignalNew       | 0.769      |
| AbsLearningOld          | 0.769      |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 14.9022    |
| AveragePolicyStd        | 0.81854    |
| AverageReturn           | 637        |
| Entropy                 | 7.2979     |
| EnvExecTime             | 3          |
| ExplainedVariance       | 0.606      |
| Iteration               | 202        |
| ItrTime                 | 12         |
| LossAfter               | -0.0264412 |
| LossBefore              | 0.0294461  |
| MaxReturn               | 1.61e+03   |
| MeanKL                  | 0.00999191 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 70.6       |
| NumTrajs                | 16         |
| Perplexity              | 1477.19    |
| PolicyExecTime          | 0.625      |
| ProcessExecTime         | 0.0765     |
| StdReturn               | 534        |
| Time                    | 2.32e+03   |
| dLoss                   | 0.0558873  |
----------------------------------------
itr #203 | 
Mem: 750.562500
Obtaining samples...
Obtaining samples for iteration 203...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5323, #subsample_inputs: 5323
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.736      |
| AbsLearnSignalNew       | 0.736      |
| AbsLearningOld          | 0.736      |
| AverageDiscountedReturn | 127        |
| AveragePhiLoss          | 15.293     |
| AveragePolicyStd        | 0.819277   |
| AverageReturn           | 557        |
| Entropy                 | 7.30195    |
| EnvExecTime             | 2.93       |
| ExplainedVariance       | 0.441      |
| Iteration               | 203        |
| ItrTime                 | 11.6       |
| LossAfter               | 0.730951   |
| LossBefore              | 0.788718   |
| MaxReturn               | 1.12e+03   |
| MeanKL                  | 0.00986338 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 59.6       |
| NumTrajs                | 19         |
| Perplexity              | 1483.19    |
| PolicyExecTime          | 0.591      |
| ProcessExecTime         | 0.079      |
| StdReturn               | 282        |
| Time                    | 2.33e+03   |
| dLoss                   | 0.0577667  |
----------------------------------------
itr #204 | 
Mem: 750.562500
Obtaining samples...
Obtaining samples for iteration 204...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5288, #subsample_inputs: 5288
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.694      |
| AbsLearnSignalNew       | 0.694      |
| AbsLearningOld          | 0.694      |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 15.2374    |
| AveragePolicyStd        | 0.821477   |
| AverageReturn           | 791        |
| Entropy                 | 7.31749    |
| EnvExecTime             | 3.16       |
| ExplainedVariance       | 0.491      |
| Iteration               | 204        |
| ItrTime                 | 11.6       |
| LossAfter               | 0.809818   |
| LossBefore              | 0.86469    |
| MaxReturn               | 1.83e+03   |
| MeanKL                  | 0.00995656 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 83.5       |
| NumTrajs                | 14         |
| Perplexity              | 1506.41    |
| PolicyExecTime          | 0.677      |
| ProcessExecTime         | 0.0914     |
| StdReturn               | 465        |
| Time                    | 2.34e+03   |
| dLoss                   | 0.0548722  |
----------------------------------------
itr #205 | 
Mem: 750.562500
Obtaining samples...
Obtaining samples for iteration 205...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5167, #subsample_inputs: 5167
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.696      |
| AbsLearnSignalNew       | 0.696      |
| AbsLearningOld          | 0.696      |
| AverageDiscountedReturn | 127        |
| AveragePhiLoss          | 14.4854    |
| AveragePolicyStd        | 0.817118   |
| AverageReturn           | 824        |
| Entropy                 | 7.2854     |
| EnvExecTime             | 2.86       |
| ExplainedVariance       | 0.572      |
| Iteration               | 205        |
| ItrTime                 | 12.1       |
| LossAfter               | 0.83867    |
| LossBefore              | 0.87733    |
| MaxReturn               | 2.07e+03   |
| MeanKL                  | 0.00641307 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 111        |
| NumTrajs                | 13         |
| Perplexity              | 1458.84    |
| PolicyExecTime          | 0.593      |
| ProcessExecTime         | 0.0798     |
| StdReturn               | 555        |
| Time                    | 2.36e+03   |
| dLoss                   | 0.0386602  |
----------------------------------------
itr #206 | 
Mem: 750.562500
Obtaining samples...
Obtaining samples for iteration 206...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5112, #subsample_inputs: 5112
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.714      |
| AbsLearnSignalNew       | 0.714      |
| AbsLearningOld          | 0.714      |
| AverageDiscountedReturn | 134        |
| AveragePhiLoss          | 15.5346    |
| AveragePolicyStd        | 0.814919   |
| AverageReturn           | 722        |
| Entropy                 | 7.26817    |
| EnvExecTime             | 2.74       |
| ExplainedVariance       | 0.459      |
| Iteration               | 206        |
| ItrTime                 | 10.9       |
| LossAfter               | 0.315281   |
| LossBefore              | 0.362044   |
| MaxReturn               | 1.43e+03   |
| MeanKL                  | 0.00640913 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 269        |
| NumTrajs                | 15         |
| Perplexity              | 1433.93    |
| PolicyExecTime          | 0.557      |
| ProcessExecTime         | 0.0712     |
| StdReturn               | 327        |
| Time                    | 2.37e+03   |
| dLoss                   | 0.0467634  |
----------------------------------------
itr #207 | 
Mem: 750.562500
Obtaining samples...
Obtaining samples for iteration 207...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5067, #subsample_inputs: 5067
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.641      |
| AbsLearnSignalNew       | 0.641      |
| AbsLearningOld          | 0.641      |
| AverageDiscountedReturn | 130        |
| AveragePhiLoss          | 15.4004    |
| AveragePolicyStd        | 0.815707   |
| AverageReturn           | 722        |
| Entropy                 | 7.27379    |
| EnvExecTime             | 3.15       |
| ExplainedVariance       | 0.574      |
| Iteration               | 207        |
| ItrTime                 | 11.7       |
| LossAfter               | 0.404707   |
| LossBefore              | 0.462753   |
| MaxReturn               | 1.53e+03   |
| MeanKL                  | 0.00992545 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 88.5       |
| NumTrajs                | 15         |
| Perplexity              | 1442.0     |
| PolicyExecTime          | 0.653      |
| ProcessExecTime         | 0.0867     |
| StdReturn               | 401        |
| Time                    | 2.38e+03   |
| dLoss                   | 0.0580459  |
----------------------------------------
itr #208 | 
Mem: 750.562500
Obtaining samples...
Obtaining samples for iteration 208...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5091, #subsample_inputs: 5091
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.727      |
| AbsLearnSignalNew       | 0.727      |
| AbsLearningOld          | 0.727      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 14.898     |
| AveragePolicyStd        | 0.814964   |
| AverageReturn           | 574        |
| Entropy                 | 7.26864    |
| EnvExecTime             | 2.75       |
| ExplainedVariance       | 0.528      |
| Iteration               | 208        |
| ItrTime                 | 11.8       |
| LossAfter               | 0.372558   |
| LossBefore              | 0.424524   |
| MaxReturn               | 1.32e+03   |
| MeanKL                  | 0.00993356 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 87.4       |
| NumTrajs                | 16         |
| Perplexity              | 1434.6     |
| PolicyExecTime          | 0.546      |
| ProcessExecTime         | 0.072      |
| StdReturn               | 328        |
| Time                    | 2.39e+03   |
| dLoss                   | 0.0519661  |
----------------------------------------
itr #209 | 
Mem: 750.562500
Obtaining samples...
Obtaining samples for iteration 209...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5088, #subsample_inputs: 5088
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.689     |
| AbsLearnSignalNew       | 0.689     |
| AbsLearningOld          | 0.689     |
| AverageDiscountedReturn | 112       |
| AveragePhiLoss          | 14.5896   |
| AveragePolicyStd        | 0.813694  |
| AverageReturn           | 576       |
| Entropy                 | 7.25954   |
| EnvExecTime             | 2.91      |
| ExplainedVariance       | 0.557     |
| Iteration               | 209       |
| ItrTime                 | 11        |
| LossAfter               | 0.0649441 |
| LossBefore              | 0.110159  |
| MaxReturn               | 1.61e+03  |
| MeanKL                  | 0.0064087 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 60.7      |
| NumTrajs                | 17        |
| Perplexity              | 1421.6    |
| PolicyExecTime          | 0.586     |
| ProcessExecTime         | 0.0811    |
| StdReturn               | 462       |
| Time                    | 2.4e+03   |
| dLoss                   | 0.0452144 |
---------------------------------------
itr #210 | 
Mem: 750.562500
Obtaining samples...
Obtaining samples for iteration 210...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5087, #subsample_inputs: 5087
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.716      |
| AbsLearnSignalNew       | 0.716      |
| AbsLearningOld          | 0.716      |
| AverageDiscountedReturn | 127        |
| AveragePhiLoss          | 16.3703    |
| AveragePolicyStd        | 0.81176    |
| AverageReturn           | 570        |
| Entropy                 | 7.24456    |
| EnvExecTime             | 3.04       |
| ExplainedVariance       | 0.553      |
| Iteration               | 210        |
| ItrTime                 | 11.3       |
| LossAfter               | 0.546001   |
| LossBefore              | 0.598647   |
| MaxReturn               | 1.62e+03   |
| MeanKL                  | 0.00996555 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 73.9       |
| NumTrajs                | 18         |
| Perplexity              | 1400.47    |
| PolicyExecTime          | 0.637      |
| ProcessExecTime         | 0.0826     |
| StdReturn               | 386        |
| Time                    | 2.41e+03   |
| dLoss                   | 0.0526457  |
----------------------------------------
itr #211 | 
Mem: 750.562500
Obtaining samples...
Obtaining samples for iteration 211...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5371, #subsample_inputs: 5371
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
-----------------------------------------
| AbsLearnSignal          | 0.757       |
| AbsLearnSignalNew       | 0.757       |
| AbsLearningOld          | 0.757       |
| AverageDiscountedReturn | 141         |
| AveragePhiLoss          | 15.5172     |
| AveragePolicyStd        | 0.810614    |
| AverageReturn           | 728         |
| Entropy                 | 7.23454     |
| EnvExecTime             | 2.99        |
| ExplainedVariance       | 0.456       |
| Iteration               | 211         |
| ItrTime                 | 12.4        |
| LossAfter               | -0.00434349 |
| LossBefore              | 0.0394163   |
| MaxReturn               | 1.26e+03    |
| MeanKL                  | 0.00644265  |
| MeanKLBefore            | 0.0         |
| MinReturn               | 96.5        |
| NumTrajs                | 16          |
| Perplexity              | 1386.5      |
| PolicyExecTime          | 0.617       |
| ProcessExecTime         | 0.0786      |
| StdReturn               | 331         |
| Time                    | 2.42e+03    |
| dLoss                   | 0.0437598   |
-----------------------------------------
itr #212 | 
Mem: 752.285156
Obtaining samples...
Obtaining samples for iteration 212...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5453, #subsample_inputs: 5453
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.675      |
| AbsLearnSignalNew       | 0.675      |
| AbsLearningOld          | 0.675      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 15.8797    |
| AveragePolicyStd        | 0.809844   |
| AverageReturn           | 751        |
| Entropy                 | 7.22908    |
| EnvExecTime             | 2.82       |
| ExplainedVariance       | 0.294      |
| Iteration               | 212        |
| ItrTime                 | 11.6       |
| LossAfter               | -0.524784  |
| LossBefore              | -0.473835  |
| MaxReturn               | 2.21e+03   |
| MeanKL                  | 0.00989903 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 68.7       |
| NumTrajs                | 15         |
| Perplexity              | 1378.95    |
| PolicyExecTime          | 0.564      |
| ProcessExecTime         | 0.0761     |
| StdReturn               | 630        |
| Time                    | 2.44e+03   |
| dLoss                   | 0.0509483  |
----------------------------------------
itr #213 | 
Mem: 752.285156
Obtaining samples...
Obtaining samples for iteration 213...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5208, #subsample_inputs: 5208
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.717      |
| AbsLearnSignalNew       | 0.717      |
| AbsLearningOld          | 0.717      |
| AverageDiscountedReturn | 132        |
| AveragePhiLoss          | 15.1092    |
| AveragePolicyStd        | 0.809477   |
| AverageReturn           | 622        |
| Entropy                 | 7.22521    |
| EnvExecTime             | 3.14       |
| ExplainedVariance       | 0.559      |
| Iteration               | 213        |
| ItrTime                 | 11.2       |
| LossAfter               | 0.526708   |
| LossBefore              | 0.577548   |
| MaxReturn               | 1.61e+03   |
| MeanKL                  | 0.00982134 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 87.4       |
| NumTrajs                | 18         |
| Perplexity              | 1373.63    |
| PolicyExecTime          | 0.664      |
| ProcessExecTime         | 0.0898     |
| StdReturn               | 452        |
| Time                    | 2.45e+03   |
| dLoss                   | 0.0508398  |
----------------------------------------
itr #214 | 
Mem: 752.285156
Obtaining samples...
Obtaining samples for iteration 214...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5129, #subsample_inputs: 5129
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.751      |
| AbsLearnSignalNew       | 0.751      |
| AbsLearningOld          | 0.751      |
| AverageDiscountedReturn | 134        |
| AveragePhiLoss          | 15.916     |
| AveragePolicyStd        | 0.809845   |
| AverageReturn           | 760        |
| Entropy                 | 7.22866    |
| EnvExecTime             | 2.94       |
| ExplainedVariance       | 0.476      |
| Iteration               | 214        |
| ItrTime                 | 12.2       |
| LossAfter               | 0.300781   |
| LossBefore              | 0.35708    |
| MaxReturn               | 1.63e+03   |
| MeanKL                  | 0.00989132 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 64.4       |
| NumTrajs                | 15         |
| Perplexity              | 1378.38    |
| PolicyExecTime          | 0.632      |
| ProcessExecTime         | 0.0824     |
| StdReturn               | 440        |
| Time                    | 2.46e+03   |
| dLoss                   | 0.0562993  |
----------------------------------------
itr #215 | 
Mem: 752.285156
Obtaining samples...
Obtaining samples for iteration 215...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5090, #subsample_inputs: 5090
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.667      |
| AbsLearnSignalNew       | 0.667      |
| AbsLearningOld          | 0.667      |
| AverageDiscountedReturn | 123        |
| AveragePhiLoss          | 15.1616    |
| AveragePolicyStd        | 0.81336    |
| AverageReturn           | 533        |
| Entropy                 | 7.25328    |
| EnvExecTime             | 2.89       |
| ExplainedVariance       | 0.499      |
| Iteration               | 215        |
| ItrTime                 | 11.4       |
| LossAfter               | -0.432231  |
| LossBefore              | -0.389814  |
| MaxReturn               | 1.29e+03   |
| MeanKL                  | 0.00645739 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 48         |
| NumTrajs                | 18         |
| Perplexity              | 1412.73    |
| PolicyExecTime          | 0.563      |
| ProcessExecTime         | 0.0739     |
| StdReturn               | 303        |
| Time                    | 2.47e+03   |
| dLoss                   | 0.0424169  |
----------------------------------------
itr #216 | 
Mem: 752.285156
Obtaining samples...
Obtaining samples for iteration 216...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5414, #subsample_inputs: 5414
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.725      |
| AbsLearnSignalNew       | 0.725      |
| AbsLearningOld          | 0.725      |
| AverageDiscountedReturn | 137        |
| AveragePhiLoss          | 15.6601    |
| AveragePolicyStd        | 0.811438   |
| AverageReturn           | 813        |
| Entropy                 | 7.2389     |
| EnvExecTime             | 3.13       |
| ExplainedVariance       | 0.484      |
| Iteration               | 216        |
| ItrTime                 | 11.6       |
| LossAfter               | -0.117524  |
| LossBefore              | -0.0631772 |
| MaxReturn               | 1.54e+03   |
| MeanKL                  | 0.00970363 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 374        |
| NumTrajs                | 15         |
| Perplexity              | 1392.56    |
| PolicyExecTime          | 0.653      |
| ProcessExecTime         | 0.0903     |
| StdReturn               | 298        |
| Time                    | 2.48e+03   |
| dLoss                   | 0.0543464  |
----------------------------------------
itr #217 | 
Mem: 752.285156
Obtaining samples...
Obtaining samples for iteration 217...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5176, #subsample_inputs: 5176
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.627      |
| AbsLearnSignalNew       | 0.627      |
| AbsLearningOld          | 0.626      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 15.425     |
| AveragePolicyStd        | 0.814147   |
| AverageReturn           | 561        |
| Entropy                 | 7.2567     |
| EnvExecTime             | 2.93       |
| ExplainedVariance       | 0.352      |
| Iteration               | 217        |
| ItrTime                 | 12.2       |
| LossAfter               | -0.470458  |
| LossBefore              | -0.430987  |
| MaxReturn               | 1.08e+03   |
| MeanKL                  | 0.00646019 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 51.1       |
| NumTrajs                | 18         |
| Perplexity              | 1417.57    |
| PolicyExecTime          | 0.617      |
| ProcessExecTime         | 0.0772     |
| StdReturn               | 297        |
| Time                    | 2.5e+03    |
| dLoss                   | 0.0394707  |
----------------------------------------
itr #218 | 
Mem: 752.285156
Obtaining samples...
Obtaining samples for iteration 218...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5144, #subsample_inputs: 5144
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.7        |
| AbsLearnSignalNew       | 0.7        |
| AbsLearningOld          | 0.7        |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 15.4217    |
| AveragePolicyStd        | 0.814154   |
| AverageReturn           | 707        |
| Entropy                 | 7.25601    |
| EnvExecTime             | 2.89       |
| ExplainedVariance       | 0.522      |
| Iteration               | 218        |
| ItrTime                 | 11.3       |
| LossAfter               | -0.4492    |
| LossBefore              | -0.393791  |
| MaxReturn               | 1.49e+03   |
| MeanKL                  | 0.00994194 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 71.7       |
| NumTrajs                | 15         |
| Perplexity              | 1416.59    |
| PolicyExecTime          | 0.582      |
| ProcessExecTime         | 0.0775     |
| StdReturn               | 444        |
| Time                    | 2.51e+03   |
| dLoss                   | 0.0554088  |
----------------------------------------
itr #219 | 
Mem: 752.285156
Obtaining samples...
Obtaining samples for iteration 219...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5087, #subsample_inputs: 5087
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.722      |
| AbsLearnSignalNew       | 0.722      |
| AbsLearningOld          | 0.722      |
| AverageDiscountedReturn | 127        |
| AveragePhiLoss          | 15.9442    |
| AveragePolicyStd        | 0.814466   |
| AverageReturn           | 671        |
| Entropy                 | 7.25796    |
| EnvExecTime             | 2.97       |
| ExplainedVariance       | 0.487      |
| Iteration               | 219        |
| ItrTime                 | 11.1       |
| LossAfter               | -0.672684  |
| LossBefore              | -0.618336  |
| MaxReturn               | 1.46e+03   |
| MeanKL                  | 0.00993386 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 83.3       |
| NumTrajs                | 15         |
| Perplexity              | 1419.36    |
| PolicyExecTime          | 0.632      |
| ProcessExecTime         | 0.0855     |
| StdReturn               | 419        |
| Time                    | 2.52e+03   |
| dLoss                   | 0.0543473  |
----------------------------------------
itr #220 | 
Mem: 752.285156
Obtaining samples...
Obtaining samples for iteration 220...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5155, #subsample_inputs: 5155
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.739      |
| AbsLearnSignalNew       | 0.739      |
| AbsLearningOld          | 0.739      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 15.2513    |
| AveragePolicyStd        | 0.815784   |
| AverageReturn           | 598        |
| Entropy                 | 7.26709    |
| EnvExecTime             | 2.86       |
| ExplainedVariance       | 0.534      |
| Iteration               | 220        |
| ItrTime                 | 12.1       |
| LossAfter               | -0.439114  |
| LossBefore              | -0.383671  |
| MaxReturn               | 1.73e+03   |
| MeanKL                  | 0.00986382 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 59.4       |
| NumTrajs                | 17         |
| Perplexity              | 1432.38    |
| PolicyExecTime          | 0.592      |
| ProcessExecTime         | 0.0793     |
| StdReturn               | 451        |
| Time                    | 2.53e+03   |
| dLoss                   | 0.0554434  |
----------------------------------------
itr #221 | 
Mem: 752.285156
Obtaining samples...
Obtaining samples for iteration 221...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5149, #subsample_inputs: 5149
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.714      |
| AbsLearnSignalNew       | 0.714      |
| AbsLearningOld          | 0.714      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 16.0444    |
| AveragePolicyStd        | 0.816235   |
| AverageReturn           | 762        |
| Entropy                 | 7.26869    |
| EnvExecTime             | 2.8        |
| ExplainedVariance       | 0.448      |
| Iteration               | 221        |
| ItrTime                 | 11.2       |
| LossAfter               | -0.67647   |
| LossBefore              | -0.634237  |
| MaxReturn               | 2.51e+03   |
| MeanKL                  | 0.00643377 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 68.5       |
| NumTrajs                | 14         |
| Perplexity              | 1434.67    |
| PolicyExecTime          | 0.568      |
| ProcessExecTime         | 0.0752     |
| StdReturn               | 611        |
| Time                    | 2.54e+03   |
| dLoss                   | 0.0422325  |
----------------------------------------
itr #222 | 
Mem: 752.285156
Obtaining samples...
Obtaining samples for iteration 222...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5191, #subsample_inputs: 5191
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.695      |
| AbsLearnSignalNew       | 0.695      |
| AbsLearningOld          | 0.695      |
| AverageDiscountedReturn | 127        |
| AveragePhiLoss          | 15.1711    |
| AveragePolicyStd        | 0.815502   |
| AverageReturn           | 528        |
| Entropy                 | 7.26106    |
| EnvExecTime             | 3.35       |
| ExplainedVariance       | 0.37       |
| Iteration               | 222        |
| ItrTime                 | 11.7       |
| LossAfter               | -0.962842  |
| LossBefore              | -0.921232  |
| MaxReturn               | 1.11e+03   |
| MeanKL                  | 0.00649002 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 50.1       |
| NumTrajs                | 19         |
| Perplexity              | 1423.76    |
| PolicyExecTime          | 0.702      |
| ProcessExecTime         | 0.0889     |
| StdReturn               | 279        |
| Time                    | 2.55e+03   |
| dLoss                   | 0.0416099  |
----------------------------------------
itr #223 | 
Mem: 752.285156
Obtaining samples...
Obtaining samples for iteration 223...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5235, #subsample_inputs: 5235
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.714      |
| AbsLearnSignalNew       | 0.714      |
| AbsLearningOld          | 0.714      |
| AverageDiscountedReturn | 129        |
| AveragePhiLoss          | 16.5655    |
| AveragePolicyStd        | 0.812647   |
| AverageReturn           | 630        |
| Entropy                 | 7.24028    |
| EnvExecTime             | 3          |
| ExplainedVariance       | 0.526      |
| Iteration               | 223        |
| ItrTime                 | 12.3       |
| LossAfter               | 0.0872654  |
| LossBefore              | 0.139319   |
| MaxReturn               | 1.17e+03   |
| MeanKL                  | 0.00996561 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 83.3       |
| NumTrajs                | 17         |
| Perplexity              | 1394.48    |
| PolicyExecTime          | 0.614      |
| ProcessExecTime         | 0.0827     |
| StdReturn               | 309        |
| Time                    | 2.57e+03   |
| dLoss                   | 0.052054   |
----------------------------------------
itr #224 | 
Mem: 752.285156
Obtaining samples...
Obtaining samples for iteration 224...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5103, #subsample_inputs: 5103
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.704      |
| AbsLearnSignalNew       | 0.704      |
| AbsLearningOld          | 0.704      |
| AverageDiscountedReturn | 135        |
| AveragePhiLoss          | 15.6453    |
| AveragePolicyStd        | 0.811381   |
| AverageReturn           | 599        |
| Entropy                 | 7.23109    |
| EnvExecTime             | 2.76       |
| ExplainedVariance       | 0.373      |
| Iteration               | 224        |
| ItrTime                 | 11         |
| LossAfter               | 0.0881702  |
| LossBefore              | 0.134763   |
| MaxReturn               | 1.39e+03   |
| MeanKL                  | 0.00643647 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 188        |
| NumTrajs                | 17         |
| Perplexity              | 1381.72    |
| PolicyExecTime          | 0.553      |
| ProcessExecTime         | 0.076      |
| StdReturn               | 286        |
| Time                    | 2.58e+03   |
| dLoss                   | 0.046593   |
----------------------------------------
itr #225 | 
Mem: 752.285156
Obtaining samples...
Obtaining samples for iteration 225...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5310, #subsample_inputs: 5310
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.715      |
| AbsLearnSignalNew       | 0.715      |
| AbsLearningOld          | 0.715      |
| AverageDiscountedReturn | 132        |
| AveragePhiLoss          | 15.6772    |
| AveragePolicyStd        | 0.810025   |
| AverageReturn           | 653        |
| Entropy                 | 7.2211     |
| EnvExecTime             | 2.93       |
| ExplainedVariance       | 0.503      |
| Iteration               | 225        |
| ItrTime                 | 11.5       |
| LossAfter               | 0.169819   |
| LossBefore              | 0.220557   |
| MaxReturn               | 1.35e+03   |
| MeanKL                  | 0.00987188 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 106        |
| NumTrajs                | 17         |
| Perplexity              | 1367.99    |
| PolicyExecTime          | 0.6        |
| ProcessExecTime         | 0.0864     |
| StdReturn               | 343        |
| Time                    | 2.59e+03   |
| dLoss                   | 0.0507376  |
----------------------------------------
itr #226 | 
Mem: 752.285156
Obtaining samples...
Obtaining samples for iteration 226...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5290, #subsample_inputs: 5290
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.608      |
| AbsLearnSignalNew       | 0.608      |
| AbsLearningOld          | 0.608      |
| AverageDiscountedReturn | 139        |
| AveragePhiLoss          | 14.3295    |
| AveragePolicyStd        | 0.810453   |
| AverageReturn           | 853        |
| Entropy                 | 7.22324    |
| EnvExecTime             | 2.89       |
| ExplainedVariance       | 0.228      |
| Iteration               | 226        |
| ItrTime                 | 12.2       |
| LossAfter               | 0.174295   |
| LossBefore              | 0.218184   |
| MaxReturn               | 2.12e+03   |
| MeanKL                  | 0.00640802 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 151        |
| NumTrajs                | 14         |
| Perplexity              | 1370.93    |
| PolicyExecTime          | 0.608      |
| ProcessExecTime         | 0.0811     |
| StdReturn               | 528        |
| Time                    | 2.6e+03    |
| dLoss                   | 0.0438889  |
----------------------------------------
itr #227 | 
Mem: 752.285156
Obtaining samples...
Obtaining samples for iteration 227...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5363, #subsample_inputs: 5363
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.693      |
| AbsLearnSignalNew       | 0.693      |
| AbsLearningOld          | 0.694      |
| AverageDiscountedReturn | 127        |
| AveragePhiLoss          | 15.8814    |
| AveragePolicyStd        | 0.811481   |
| AverageReturn           | 560        |
| Entropy                 | 7.23131    |
| EnvExecTime             | 2.96       |
| ExplainedVariance       | 0.498      |
| Iteration               | 227        |
| ItrTime                 | 12.1       |
| LossAfter               | -1.07406   |
| LossBefore              | -1.02007   |
| MaxReturn               | 1.16e+03   |
| MeanKL                  | 0.00975034 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 50.1       |
| NumTrajs                | 19         |
| Perplexity              | 1382.03    |
| PolicyExecTime          | 0.578      |
| ProcessExecTime         | 0.0758     |
| StdReturn               | 313        |
| Time                    | 2.61e+03   |
| dLoss                   | 0.053992   |
----------------------------------------
itr #228 | 
Mem: 752.285156
Obtaining samples...
Obtaining samples for iteration 228...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5066, #subsample_inputs: 5066
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.468      |
| AbsLearnSignalNew       | 0.468      |
| AbsLearningOld          | 0.468      |
| AverageDiscountedReturn | 144        |
| AveragePhiLoss          | 18.1575    |
| AveragePolicyStd        | 0.814119   |
| AverageReturn           | 778        |
| Entropy                 | 7.25197    |
| EnvExecTime             | 2.74       |
| ExplainedVariance       | -1.53      |
| Iteration               | 228        |
| ItrTime                 | 10.6       |
| LossAfter               | -1.15438   |
| LossBefore              | -1.09962   |
| MaxReturn               | 1.92e+03   |
| MeanKL                  | 0.00989425 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 385        |
| NumTrajs                | 15         |
| Perplexity              | 1410.88    |
| PolicyExecTime          | 0.566      |
| ProcessExecTime         | 0.0797     |
| StdReturn               | 435        |
| Time                    | 2.62e+03   |
| dLoss                   | 0.0547549  |
----------------------------------------
itr #229 | 
Mem: 752.792969
Obtaining samples...
Obtaining samples for iteration 229...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5185, #subsample_inputs: 5185
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.648      |
| AbsLearnSignalNew       | 0.648      |
| AbsLearningOld          | 0.648      |
| AverageDiscountedReturn | 134        |
| AveragePhiLoss          | 16.1584    |
| AveragePolicyStd        | 0.812909   |
| AverageReturn           | 652        |
| Entropy                 | 7.24315    |
| EnvExecTime             | 2.8        |
| ExplainedVariance       | 0.388      |
| Iteration               | 229        |
| ItrTime                 | 12         |
| LossAfter               | -0.874255  |
| LossBefore              | -0.822656  |
| MaxReturn               | 1.7e+03    |
| MeanKL                  | 0.00989411 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 70         |
| NumTrajs                | 16         |
| Perplexity              | 1398.49    |
| PolicyExecTime          | 0.585      |
| ProcessExecTime         | 0.0778     |
| StdReturn               | 355        |
| Time                    | 2.64e+03   |
| dLoss                   | 0.0515993  |
----------------------------------------
itr #230 | 
Mem: 752.792969
Obtaining samples...
Obtaining samples for iteration 230...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5133, #subsample_inputs: 5133
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.705      |
| AbsLearnSignalNew       | 0.705      |
| AbsLearningOld          | 0.705      |
| AverageDiscountedReturn | 134        |
| AveragePhiLoss          | 15.5       |
| AveragePolicyStd        | 0.814256   |
| AverageReturn           | 607        |
| Entropy                 | 7.25127    |
| EnvExecTime             | 2.68       |
| ExplainedVariance       | 0.52       |
| Iteration               | 230        |
| ItrTime                 | 11.5       |
| LossAfter               | -0.797605  |
| LossBefore              | -0.74599   |
| MaxReturn               | 1.2e+03    |
| MeanKL                  | 0.00998687 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 94.7       |
| NumTrajs                | 17         |
| Perplexity              | 1409.89    |
| PolicyExecTime          | 0.521      |
| ProcessExecTime         | 0.0709     |
| StdReturn               | 301        |
| Time                    | 2.65e+03   |
| dLoss                   | 0.051615   |
----------------------------------------
itr #231 | 
Mem: 752.792969
Obtaining samples...
Obtaining samples for iteration 231...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5142, #subsample_inputs: 5142
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.695      |
| AbsLearnSignalNew       | 0.695      |
| AbsLearningOld          | 0.695      |
| AverageDiscountedReturn | 137        |
| AveragePhiLoss          | 15.6374    |
| AveragePolicyStd        | 0.812508   |
| AverageReturn           | 650        |
| Entropy                 | 7.238      |
| EnvExecTime             | 3.06       |
| ExplainedVariance       | 0.466      |
| Iteration               | 231        |
| ItrTime                 | 10.8       |
| LossAfter               | -0.999902  |
| LossBefore              | -0.946013  |
| MaxReturn               | 1.06e+03   |
| MeanKL                  | 0.00999145 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 86.7       |
| NumTrajs                | 17         |
| Perplexity              | 1391.31    |
| PolicyExecTime          | 0.638      |
| ProcessExecTime         | 0.0855     |
| StdReturn               | 238        |
| Time                    | 2.66e+03   |
| dLoss                   | 0.0538892  |
----------------------------------------
itr #232 | 
Mem: 752.792969
Obtaining samples...
Obtaining samples for iteration 232...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5165, #subsample_inputs: 5165
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.742      |
| AbsLearnSignalNew       | 0.742      |
| AbsLearningOld          | 0.742      |
| AverageDiscountedReturn | 158        |
| AveragePhiLoss          | 15.873     |
| AveragePolicyStd        | 0.809073   |
| AverageReturn           | 994        |
| Entropy                 | 7.21251    |
| EnvExecTime             | 2.85       |
| ExplainedVariance       | 0.563      |
| Iteration               | 232        |
| ItrTime                 | 11.9       |
| LossAfter               | -0.118982  |
| LossBefore              | -0.0622339 |
| MaxReturn               | 2.2e+03    |
| MeanKL                  | 0.00995224 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 496        |
| NumTrajs                | 13         |
| Perplexity              | 1356.29    |
| PolicyExecTime          | 0.608      |
| ProcessExecTime         | 0.0808     |
| StdReturn               | 449        |
| Time                    | 2.67e+03   |
| dLoss                   | 0.056748   |
----------------------------------------
itr #233 | 
Mem: 752.792969
Obtaining samples...
Obtaining samples for iteration 233...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5048, #subsample_inputs: 5048
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.529      |
| AbsLearnSignalNew       | 0.529      |
| AbsLearningOld          | 0.529      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 14.3666    |
| AveragePolicyStd        | 0.812246   |
| AverageReturn           | 560        |
| Entropy                 | 7.23531    |
| EnvExecTime             | 2.55       |
| ExplainedVariance       | 0.295      |
| Iteration               | 233        |
| ItrTime                 | 11.4       |
| LossAfter               | -0.208166  |
| LossBefore              | -0.174579  |
| MaxReturn               | 1.42e+03   |
| MeanKL                  | 0.00651308 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 83.9       |
| NumTrajs                | 17         |
| Perplexity              | 1387.57    |
| PolicyExecTime          | 0.48       |
| ProcessExecTime         | 0.065      |
| StdReturn               | 381        |
| Time                    | 2.68e+03   |
| dLoss                   | 0.033587   |
----------------------------------------
itr #234 | 
Mem: 752.792969
Obtaining samples...
Obtaining samples for iteration 234...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5107, #subsample_inputs: 5107
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.712      |
| AbsLearnSignalNew       | 0.712      |
| AbsLearningOld          | 0.712      |
| AverageDiscountedReturn | 138        |
| AveragePhiLoss          | 15.516     |
| AveragePolicyStd        | 0.81266    |
| AverageReturn           | 767        |
| Entropy                 | 7.23843    |
| EnvExecTime             | 3          |
| ExplainedVariance       | 0.307      |
| Iteration               | 234        |
| ItrTime                 | 10.7       |
| LossAfter               | -0.060554  |
| LossBefore              | -0.0101454 |
| MaxReturn               | 2.1e+03    |
| MeanKL                  | 0.00643182 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 72.7       |
| NumTrajs                | 15         |
| Perplexity              | 1391.91    |
| PolicyExecTime          | 0.629      |
| ProcessExecTime         | 0.0839     |
| StdReturn               | 534        |
| Time                    | 2.69e+03   |
| dLoss                   | 0.0504086  |
----------------------------------------
itr #235 | 
Mem: 752.792969
Obtaining samples...
Obtaining samples for iteration 235...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5094, #subsample_inputs: 5094
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.732      |
| AbsLearnSignalNew       | 0.732      |
| AbsLearningOld          | 0.732      |
| AverageDiscountedReturn | 138        |
| AveragePhiLoss          | 15.8509    |
| AveragePolicyStd        | 0.812146   |
| AverageReturn           | 623        |
| Entropy                 | 7.23495    |
| EnvExecTime             | 2.85       |
| ExplainedVariance       | 0.413      |
| Iteration               | 235        |
| ItrTime                 | 11.8       |
| LossAfter               | -0.051745  |
| LossBefore              | 0.00228753 |
| MaxReturn               | 1.59e+03   |
| MeanKL                  | 0.0098815  |
| MeanKLBefore            | 0.0        |
| MinReturn               | 56         |
| NumTrajs                | 18         |
| Perplexity              | 1387.07    |
| PolicyExecTime          | 0.6        |
| ProcessExecTime         | 0.0813     |
| StdReturn               | 388        |
| Time                    | 2.7e+03    |
| dLoss                   | 0.0540325  |
----------------------------------------
itr #236 | 
Mem: 752.792969
Obtaining samples...
Obtaining samples for iteration 236...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5218, #subsample_inputs: 5218
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.688      |
| AbsLearnSignalNew       | 0.688      |
| AbsLearningOld          | 0.688      |
| AverageDiscountedReturn | 132        |
| AveragePhiLoss          | 16.4697    |
| AveragePolicyStd        | 0.813154   |
| AverageReturn           | 676        |
| Entropy                 | 7.24324    |
| EnvExecTime             | 2.52       |
| ExplainedVariance       | 0.488      |
| Iteration               | 236        |
| ItrTime                 | 11.6       |
| LossAfter               | 0.0819544  |
| LossBefore              | 0.143554   |
| MaxReturn               | 1.46e+03   |
| MeanKL                  | 0.00994404 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 35.4       |
| NumTrajs                | 17         |
| Perplexity              | 1398.62    |
| PolicyExecTime          | 0.496      |
| ProcessExecTime         | 0.0683     |
| StdReturn               | 423        |
| Time                    | 2.72e+03   |
| dLoss                   | 0.0615999  |
----------------------------------------
itr #237 | 
Mem: 752.792969
Obtaining samples...
Obtaining samples for iteration 237...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5648, #subsample_inputs: 5648
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.702      |
| AbsLearnSignalNew       | 0.702      |
| AbsLearningOld          | 0.701      |
| AverageDiscountedReturn | 138        |
| AveragePhiLoss          | 15.9858    |
| AveragePolicyStd        | 0.812524   |
| AverageReturn           | 938        |
| Entropy                 | 7.23914    |
| EnvExecTime             | 2.97       |
| ExplainedVariance       | 0.621      |
| Iteration               | 237        |
| ItrTime                 | 11.8       |
| LossAfter               | -0.766275  |
| LossBefore              | -0.707135  |
| MaxReturn               | 1.99e+03   |
| MeanKL                  | 0.00987157 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 57.8       |
| NumTrajs                | 14         |
| Perplexity              | 1392.9     |
| PolicyExecTime          | 0.646      |
| ProcessExecTime         | 0.0865     |
| StdReturn               | 556        |
| Time                    | 2.73e+03   |
| dLoss                   | 0.0591398  |
----------------------------------------
itr #238 | 
Mem: 753.042969
Obtaining samples...
Obtaining samples for iteration 238...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5646, #subsample_inputs: 5646
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.688      |
| AbsLearnSignalNew       | 0.688      |
| AbsLearningOld          | 0.687      |
| AverageDiscountedReturn | 138        |
| AveragePhiLoss          | 16.2665    |
| AveragePolicyStd        | 0.81131    |
| AverageReturn           | 674        |
| Entropy                 | 7.22978    |
| EnvExecTime             | 3.17       |
| ExplainedVariance       | 0.457      |
| Iteration               | 238        |
| ItrTime                 | 11.8       |
| LossAfter               | -0.574664  |
| LossBefore              | -0.51849   |
| MaxReturn               | 1.59e+03   |
| MeanKL                  | 0.00992913 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 84.5       |
| NumTrajs                | 18         |
| Perplexity              | 1379.91    |
| PolicyExecTime          | 0.671      |
| ProcessExecTime         | 0.0895     |
| StdReturn               | 335        |
| Time                    | 2.74e+03   |
| dLoss                   | 0.0561737  |
----------------------------------------
itr #239 | 
Mem: 753.042969
Obtaining samples...
Obtaining samples for iteration 239...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5277, #subsample_inputs: 5277
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.648      |
| AbsLearnSignalNew       | 0.648      |
| AbsLearningOld          | 0.648      |
| AverageDiscountedReturn | 133        |
| AveragePhiLoss          | 15.1779    |
| AveragePolicyStd        | 0.811556   |
| AverageReturn           | 736        |
| Entropy                 | 7.23328    |
| EnvExecTime             | 3.13       |
| ExplainedVariance       | 0.358      |
| Iteration               | 239        |
| ItrTime                 | 12.4       |
| LossAfter               | -0.0377086 |
| LossBefore              | 0.0178953  |
| MaxReturn               | 1.82e+03   |
| MeanKL                  | 0.00973978 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 196        |
| NumTrajs                | 15         |
| Perplexity              | 1384.75    |
| PolicyExecTime          | 0.647      |
| ProcessExecTime         | 0.0864     |
| StdReturn               | 411        |
| Time                    | 2.75e+03   |
| dLoss                   | 0.0556039  |
----------------------------------------
itr #240 | 
Mem: 753.042969
Obtaining samples...
Obtaining samples for iteration 240...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5105, #subsample_inputs: 5105
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.715      |
| AbsLearnSignalNew       | 0.715      |
| AbsLearningOld          | 0.714      |
| AverageDiscountedReturn | 144        |
| AveragePhiLoss          | 16.0325    |
| AveragePolicyStd        | 0.812285   |
| AverageReturn           | 806        |
| Entropy                 | 7.23622    |
| EnvExecTime             | 2.63       |
| ExplainedVariance       | 0.319      |
| Iteration               | 240        |
| ItrTime                 | 11         |
| LossAfter               | -0.193977  |
| LossBefore              | -0.150873  |
| MaxReturn               | 2.21e+03   |
| MeanKL                  | 0.00645089 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 408        |
| NumTrajs                | 14         |
| Perplexity              | 1388.84    |
| PolicyExecTime          | 0.539      |
| ProcessExecTime         | 0.0681     |
| StdReturn               | 457        |
| Time                    | 2.76e+03   |
| dLoss                   | 0.0431038  |
----------------------------------------
itr #241 | 
Mem: 753.292969
Obtaining samples...
Obtaining samples for iteration 241...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5159, #subsample_inputs: 5159
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.634      |
| AbsLearnSignalNew       | 0.634      |
| AbsLearningOld          | 0.634      |
| AverageDiscountedReturn | 137        |
| AveragePhiLoss          | 16.6837    |
| AveragePolicyStd        | 0.809448   |
| AverageReturn           | 691        |
| Entropy                 | 7.21528    |
| EnvExecTime             | 3.03       |
| ExplainedVariance       | 0.515      |
| Iteration               | 241        |
| ItrTime                 | 11.2       |
| LossAfter               | -0.918356  |
| LossBefore              | -0.872861  |
| MaxReturn               | 1.57e+03   |
| MeanKL                  | 0.00643126 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 78         |
| NumTrajs                | 16         |
| Perplexity              | 1360.06    |
| PolicyExecTime          | 0.652      |
| ProcessExecTime         | 0.0848     |
| StdReturn               | 431        |
| Time                    | 2.78e+03   |
| dLoss                   | 0.0454948  |
----------------------------------------
itr #242 | 
Mem: 753.292969
Obtaining samples...
Obtaining samples for iteration 242...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5570, #subsample_inputs: 5570
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.653      |
| AbsLearnSignalNew       | 0.653      |
| AbsLearningOld          | 0.653      |
| AverageDiscountedReturn | 123        |
| AveragePhiLoss          | 16.4284    |
| AveragePolicyStd        | 0.809152   |
| AverageReturn           | 672        |
| Entropy                 | 7.21309    |
| EnvExecTime             | 3.35       |
| ExplainedVariance       | 0.517      |
| Iteration               | 242        |
| ItrTime                 | 13.2       |
| LossAfter               | -1.25476   |
| LossBefore              | -1.2043    |
| MaxReturn               | 2e+03      |
| MeanKL                  | 0.00646409 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 62.7       |
| NumTrajs                | 17         |
| Perplexity              | 1357.08    |
| PolicyExecTime          | 0.687      |
| ProcessExecTime         | 0.096      |
| StdReturn               | 459        |
| Time                    | 2.79e+03   |
| dLoss                   | 0.0504568  |
----------------------------------------
itr #243 | 
Mem: 753.292969
Obtaining samples...
Obtaining samples for iteration 243...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5321, #subsample_inputs: 5321
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.707     |
| AbsLearnSignalNew       | 0.707     |
| AbsLearningOld          | 0.707     |
| AverageDiscountedReturn | 137       |
| AveragePhiLoss          | 16.9113   |
| AveragePolicyStd        | 0.80727   |
| AverageReturn           | 699       |
| Entropy                 | 7.19939   |
| EnvExecTime             | 3.14      |
| ExplainedVariance       | 0.473     |
| Iteration               | 243       |
| ItrTime                 | 12.5      |
| LossAfter               | -0.673092 |
| LossBefore              | -0.61918  |
| MaxReturn               | 1.82e+03  |
| MeanKL                  | 0.0099127 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 79.5      |
| NumTrajs                | 16        |
| Perplexity              | 1338.61   |
| PolicyExecTime          | 0.624     |
| ProcessExecTime         | 0.0804    |
| StdReturn               | 432       |
| Time                    | 2.8e+03   |
| dLoss                   | 0.0539123 |
---------------------------------------
itr #244 | 
Mem: 754.574219
Obtaining samples...
Obtaining samples for iteration 244...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5458, #subsample_inputs: 5458
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.705      |
| AbsLearnSignalNew       | 0.705      |
| AbsLearningOld          | 0.705      |
| AverageDiscountedReturn | 115        |
| AveragePhiLoss          | 16.6329    |
| AveragePolicyStd        | 0.806961   |
| AverageReturn           | 596        |
| Entropy                 | 7.19541    |
| EnvExecTime             | 3.46       |
| ExplainedVariance       | 0.486      |
| Iteration               | 244        |
| ItrTime                 | 11.6       |
| LossAfter               | -0.84283   |
| LossBefore              | -0.783392  |
| MaxReturn               | 2.51e+03   |
| MeanKL                  | 0.00994239 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 74.1       |
| NumTrajs                | 17         |
| Perplexity              | 1333.3     |
| PolicyExecTime          | 0.729      |
| ProcessExecTime         | 0.0921     |
| StdReturn               | 613        |
| Time                    | 2.81e+03   |
| dLoss                   | 0.059438   |
----------------------------------------
itr #245 | 
Mem: 754.574219
Obtaining samples...
Obtaining samples for iteration 245...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5373, #subsample_inputs: 5373
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.766      |
| AbsLearnSignalNew       | 0.766      |
| AbsLearningOld          | 0.767      |
| AverageDiscountedReturn | 131        |
| AveragePhiLoss          | 16.1542    |
| AveragePolicyStd        | 0.806323   |
| AverageReturn           | 656        |
| Entropy                 | 7.19151    |
| EnvExecTime             | 3.64       |
| ExplainedVariance       | 0.599      |
| Iteration               | 245        |
| ItrTime                 | 12.9       |
| LossAfter               | -0.61965   |
| LossBefore              | -0.563864  |
| MaxReturn               | 1.41e+03   |
| MeanKL                  | 0.00990084 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 65.9       |
| NumTrajs                | 17         |
| Perplexity              | 1328.1     |
| PolicyExecTime          | 0.763      |
| ProcessExecTime         | 0.0949     |
| StdReturn               | 393        |
| Time                    | 2.83e+03   |
| dLoss                   | 0.0557866  |
----------------------------------------
itr #246 | 
Mem: 754.574219
Obtaining samples...
Obtaining samples for iteration 246...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5313, #subsample_inputs: 5313
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.529      |
| AbsLearnSignalNew       | 0.529      |
| AbsLearningOld          | 0.529      |
| AverageDiscountedReturn | 138        |
| AveragePhiLoss          | 16.4946    |
| AveragePolicyStd        | 0.80493    |
| AverageReturn           | 966        |
| Entropy                 | 7.17984    |
| EnvExecTime             | 2.87       |
| ExplainedVariance       | -1.46      |
| Iteration               | 246        |
| ItrTime                 | 12.4       |
| LossAfter               | -0.331461  |
| LossBefore              | -0.288241  |
| MaxReturn               | 2.38e+03   |
| MeanKL                  | 0.00643313 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 70.3       |
| NumTrajs                | 12         |
| Perplexity              | 1312.7     |
| PolicyExecTime          | 0.592      |
| ProcessExecTime         | 0.0715     |
| StdReturn               | 623        |
| Time                    | 2.84e+03   |
| dLoss                   | 0.0432197  |
----------------------------------------
itr #247 | 
Mem: 754.574219
Obtaining samples...
Obtaining samples for iteration 247...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5442, #subsample_inputs: 5442
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.671      |
| AbsLearnSignalNew       | 0.671      |
| AbsLearningOld          | 0.671      |
| AverageDiscountedReturn | 133        |
| AveragePhiLoss          | 16.6693    |
| AveragePolicyStd        | 0.803654   |
| AverageReturn           | 741        |
| Entropy                 | 7.17157    |
| EnvExecTime             | 3.23       |
| ExplainedVariance       | 0.582      |
| Iteration               | 247        |
| ItrTime                 | 11.5       |
| LossAfter               | -1.32717   |
| LossBefore              | -1.26997   |
| MaxReturn               | 2.01e+03   |
| MeanKL                  | 0.00994845 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 112        |
| NumTrajs                | 16         |
| Perplexity              | 1301.89    |
| PolicyExecTime          | 0.683      |
| ProcessExecTime         | 0.0894     |
| StdReturn               | 556        |
| Time                    | 2.85e+03   |
| dLoss                   | 0.0572003  |
----------------------------------------
itr #248 | 
Mem: 754.574219
Obtaining samples...
Obtaining samples for iteration 248...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5361, #subsample_inputs: 5361
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.696      |
| AbsLearnSignalNew       | 0.696      |
| AbsLearningOld          | 0.696      |
| AverageDiscountedReturn | 139        |
| AveragePhiLoss          | 17.6961    |
| AveragePolicyStd        | 0.805187   |
| AverageReturn           | 897        |
| Entropy                 | 7.18401    |
| EnvExecTime             | 3.28       |
| ExplainedVariance       | 0.465      |
| Iteration               | 248        |
| ItrTime                 | 12.2       |
| LossAfter               | -0.720754  |
| LossBefore              | -0.674924  |
| MaxReturn               | 1.79e+03   |
| MeanKL                  | 0.00646343 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 370        |
| NumTrajs                | 13         |
| Perplexity              | 1318.19    |
| PolicyExecTime          | 0.714      |
| ProcessExecTime         | 0.088      |
| StdReturn               | 451        |
| Time                    | 2.86e+03   |
| dLoss                   | 0.0458294  |
----------------------------------------
itr #249 | 
Mem: 755.371094
Obtaining samples...
Obtaining samples for iteration 249...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5049, #subsample_inputs: 5049
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.683      |
| AbsLearnSignalNew       | 0.683      |
| AbsLearningOld          | 0.683      |
| AverageDiscountedReturn | 136        |
| AveragePhiLoss          | 16.8109    |
| AveragePolicyStd        | 0.803972   |
| AverageReturn           | 869        |
| Entropy                 | 7.17621    |
| EnvExecTime             | 2.78       |
| ExplainedVariance       | 0.405      |
| Iteration               | 249        |
| ItrTime                 | 12.1       |
| LossAfter               | -0.426312  |
| LossBefore              | -0.38257   |
| MaxReturn               | 2.17e+03   |
| MeanKL                  | 0.00645194 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 82         |
| NumTrajs                | 13         |
| Perplexity              | 1307.94    |
| PolicyExecTime          | 0.588      |
| ProcessExecTime         | 0.0776     |
| StdReturn               | 573        |
| Time                    | 2.87e+03   |
| dLoss                   | 0.0437424  |
----------------------------------------
itr #250 | 
Mem: 755.371094
Obtaining samples...
Obtaining samples for iteration 250...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5196, #subsample_inputs: 5196
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.677      |
| AbsLearnSignalNew       | 0.677      |
| AbsLearningOld          | 0.677      |
| AverageDiscountedReturn | 110        |
| AveragePhiLoss          | 17.4425    |
| AveragePolicyStd        | 0.804281   |
| AverageReturn           | 562        |
| Entropy                 | 7.17753    |
| EnvExecTime             | 3.18       |
| ExplainedVariance       | 0.469      |
| Iteration               | 250        |
| ItrTime                 | 10.9       |
| LossAfter               | -0.600411  |
| LossBefore              | -0.559762  |
| MaxReturn               | 2.19e+03   |
| MeanKL                  | 0.00649033 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 20.1       |
| NumTrajs                | 17         |
| Perplexity              | 1309.66    |
| PolicyExecTime          | 0.667      |
| ProcessExecTime         | 0.0868     |
| StdReturn               | 523        |
| Time                    | 2.89e+03   |
| dLoss                   | 0.0406485  |
----------------------------------------
itr #251 | 
Mem: 755.371094
Obtaining samples...
Obtaining samples for iteration 251...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5117, #subsample_inputs: 5117
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.739      |
| AbsLearnSignalNew       | 0.739      |
| AbsLearningOld          | 0.739      |
| AverageDiscountedReturn | 131        |
| AveragePhiLoss          | 15.9452    |
| AveragePolicyStd        | 0.800972   |
| AverageReturn           | 662        |
| Entropy                 | 7.15163    |
| EnvExecTime             | 3.24       |
| ExplainedVariance       | 0.521      |
| Iteration               | 251        |
| ItrTime                 | 12.5       |
| LossAfter               | -0.0731747 |
| LossBefore              | -0.0322682 |
| MaxReturn               | 2.02e+03   |
| MeanKL                  | 0.00640635 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 45.5       |
| NumTrajs                | 16         |
| Perplexity              | 1276.18    |
| PolicyExecTime          | 0.682      |
| ProcessExecTime         | 0.0895     |
| StdReturn               | 460        |
| Time                    | 2.9e+03    |
| dLoss                   | 0.0409065  |
----------------------------------------
itr #252 | 
Mem: 755.371094
Obtaining samples...
Obtaining samples for iteration 252...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5100, #subsample_inputs: 5100
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.736      |
| AbsLearnSignalNew       | 0.736      |
| AbsLearningOld          | 0.736      |
| AverageDiscountedReturn | 131        |
| AveragePhiLoss          | 16.6368    |
| AveragePolicyStd        | 0.80003    |
| AverageReturn           | 743        |
| Entropy                 | 7.14454    |
| EnvExecTime             | 3.03       |
| ExplainedVariance       | 0.482      |
| Iteration               | 252        |
| ItrTime                 | 12.2       |
| LossAfter               | -0.213692  |
| LossBefore              | -0.170973  |
| MaxReturn               | 1.49e+03   |
| MeanKL                  | 0.00649713 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 97.3       |
| NumTrajs                | 14         |
| Perplexity              | 1267.17    |
| PolicyExecTime          | 0.588      |
| ProcessExecTime         | 0.0746     |
| StdReturn               | 438        |
| Time                    | 2.91e+03   |
| dLoss                   | 0.042719   |
----------------------------------------
itr #253 | 
Mem: 755.371094
Obtaining samples...
Obtaining samples for iteration 253...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5261, #subsample_inputs: 5261
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.72       |
| AbsLearnSignalNew       | 0.72       |
| AbsLearningOld          | 0.72       |
| AverageDiscountedReturn | 141        |
| AveragePhiLoss          | 16.1007    |
| AveragePolicyStd        | 0.797469   |
| AverageReturn           | 1.04e+03   |
| Entropy                 | 7.12497    |
| EnvExecTime             | 3.04       |
| ExplainedVariance       | 0.55       |
| Iteration               | 253        |
| ItrTime                 | 10.8       |
| LossAfter               | 0.168553   |
| LossBefore              | 0.209587   |
| MaxReturn               | 2.43e+03   |
| MeanKL                  | 0.00641951 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 110        |
| NumTrajs                | 11         |
| Perplexity              | 1242.61    |
| PolicyExecTime          | 0.636      |
| ProcessExecTime         | 0.0846     |
| StdReturn               | 586        |
| Time                    | 2.92e+03   |
| dLoss                   | 0.0410333  |
----------------------------------------
itr #254 | 
Mem: 755.621094
Obtaining samples...
Obtaining samples for iteration 254...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5158, #subsample_inputs: 5158
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.699     |
| AbsLearnSignalNew       | 0.699     |
| AbsLearningOld          | 0.699     |
| AverageDiscountedReturn | 128       |
| AveragePhiLoss          | 16.6876   |
| AveragePolicyStd        | 0.796084  |
| AverageReturn           | 627       |
| Entropy                 | 7.11231   |
| EnvExecTime             | 3.32      |
| ExplainedVariance       | 0.574     |
| Iteration               | 254       |
| ItrTime                 | 12.3      |
| LossAfter               | 0.730662  |
| LossBefore              | 0.773598  |
| MaxReturn               | 1.35e+03  |
| MeanKL                  | 0.0064757 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 61.9      |
| NumTrajs                | 17        |
| Perplexity              | 1226.98   |
| PolicyExecTime          | 0.678     |
| ProcessExecTime         | 0.0876    |
| StdReturn               | 381       |
| Time                    | 2.93e+03  |
| dLoss                   | 0.042936  |
---------------------------------------
itr #255 | 
Mem: 755.621094
Obtaining samples...
Obtaining samples for iteration 255...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5201, #subsample_inputs: 5201
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.732      |
| AbsLearnSignalNew       | 0.732      |
| AbsLearningOld          | 0.732      |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 17.7701    |
| AveragePolicyStd        | 0.7958     |
| AverageReturn           | 716        |
| Entropy                 | 7.11014    |
| EnvExecTime             | 3.41       |
| ExplainedVariance       | 0.452      |
| Iteration               | 255        |
| ItrTime                 | 12.8       |
| LossAfter               | -0.0340858 |
| LossBefore              | 0.0222587  |
| MaxReturn               | 1.97e+03   |
| MeanKL                  | 0.00992332 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 84.7       |
| NumTrajs                | 15         |
| Perplexity              | 1224.32    |
| PolicyExecTime          | 0.681      |
| ProcessExecTime         | 0.0828     |
| StdReturn               | 598        |
| Time                    | 2.95e+03   |
| dLoss                   | 0.0563444  |
----------------------------------------
itr #256 | 
Mem: 755.621094
Obtaining samples...
Obtaining samples for iteration 256...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5007, #subsample_inputs: 5007
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.696      |
| AbsLearnSignalNew       | 0.696      |
| AbsLearningOld          | 0.696      |
| AverageDiscountedReturn | 119        |
| AveragePhiLoss          | 16.6539    |
| AveragePolicyStd        | 0.795822   |
| AverageReturn           | 854        |
| Entropy                 | 7.11005    |
| EnvExecTime             | 3.07       |
| ExplainedVariance       | 0.333      |
| Iteration               | 256        |
| ItrTime                 | 10.7       |
| LossAfter               | 0.0988472  |
| LossBefore              | 0.155956   |
| MaxReturn               | 2.11e+03   |
| MeanKL                  | 0.00986202 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 64.1       |
| NumTrajs                | 12         |
| Perplexity              | 1224.21    |
| PolicyExecTime          | 0.657      |
| ProcessExecTime         | 0.0816     |
| StdReturn               | 670        |
| Time                    | 2.96e+03   |
| dLoss                   | 0.057109   |
----------------------------------------
itr #257 | 
Mem: 755.621094
Obtaining samples...
Obtaining samples for iteration 257...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5525, #subsample_inputs: 5525
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.722     |
| AbsLearnSignalNew       | 0.722     |
| AbsLearningOld          | 0.722     |
| AverageDiscountedReturn | 134       |
| AveragePhiLoss          | 17.0864   |
| AveragePolicyStd        | 0.795346  |
| AverageReturn           | 830       |
| Entropy                 | 7.10784   |
| EnvExecTime             | 3.56      |
| ExplainedVariance       | 0.524     |
| Iteration               | 257       |
| ItrTime                 | 12.6      |
| LossAfter               | 0.488903  |
| LossBefore              | 0.543076  |
| MaxReturn               | 2.03e+03  |
| MeanKL                  | 0.0098423 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 74.9      |
| NumTrajs                | 14        |
| Perplexity              | 1221.51   |
| PolicyExecTime          | 0.755     |
| ProcessExecTime         | 0.0942    |
| StdReturn               | 522       |
| Time                    | 2.97e+03  |
| dLoss                   | 0.0541734 |
---------------------------------------
itr #258 | 
Mem: 757.167969
Obtaining samples...
Obtaining samples for iteration 258...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5177, #subsample_inputs: 5177
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.697      |
| AbsLearnSignalNew       | 0.697      |
| AbsLearningOld          | 0.697      |
| AverageDiscountedReturn | 129        |
| AveragePhiLoss          | 16.8771    |
| AveragePolicyStd        | 0.794703   |
| AverageReturn           | 743        |
| Entropy                 | 7.10337    |
| EnvExecTime             | 2.94       |
| ExplainedVariance       | 0.573      |
| Iteration               | 258        |
| ItrTime                 | 12.4       |
| LossAfter               | 0.739634   |
| LossBefore              | 0.788996   |
| MaxReturn               | 1.78e+03   |
| MeanKL                  | 0.00993639 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 69.1       |
| NumTrajs                | 14         |
| Perplexity              | 1216.06    |
| PolicyExecTime          | 0.631      |
| ProcessExecTime         | 0.0796     |
| StdReturn               | 523        |
| Time                    | 2.98e+03   |
| dLoss                   | 0.0493621  |
----------------------------------------
itr #259 | 
Mem: 757.933594
Obtaining samples...
Obtaining samples for iteration 259...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5375, #subsample_inputs: 5375
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.681      |
| AbsLearnSignalNew       | 0.681      |
| AbsLearningOld          | 0.681      |
| AverageDiscountedReturn | 132        |
| AveragePhiLoss          | 17.517     |
| AveragePolicyStd        | 0.796051   |
| AverageReturn           | 691        |
| Entropy                 | 7.11372    |
| EnvExecTime             | 3.15       |
| ExplainedVariance       | 0.513      |
| Iteration               | 259        |
| ItrTime                 | 11.7       |
| LossAfter               | 0.373449   |
| LossBefore              | 0.413757   |
| MaxReturn               | 1.51e+03   |
| MeanKL                  | 0.00650563 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 77.5       |
| NumTrajs                | 16         |
| Perplexity              | 1228.71    |
| PolicyExecTime          | 0.646      |
| ProcessExecTime         | 0.0809     |
| StdReturn               | 358        |
| Time                    | 2.99e+03   |
| dLoss                   | 0.0403077  |
----------------------------------------
itr #260 | 
Mem: 757.933594
Obtaining samples...
Obtaining samples for iteration 260...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5579, #subsample_inputs: 5579
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.685      |
| AbsLearnSignalNew       | 0.685      |
| AbsLearningOld          | 0.685      |
| AverageDiscountedReturn | 132        |
| AveragePhiLoss          | 17.5726    |
| AveragePolicyStd        | 0.795854   |
| AverageReturn           | 767        |
| Entropy                 | 7.1106     |
| EnvExecTime             | 3.47       |
| ExplainedVariance       | 0.555      |
| Iteration               | 260        |
| ItrTime                 | 11.9       |
| LossAfter               | 0.615806   |
| LossBefore              | 0.663812   |
| MaxReturn               | 1.8e+03    |
| MeanKL                  | 0.00995877 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 93.6       |
| NumTrajs                | 15         |
| Perplexity              | 1224.88    |
| PolicyExecTime          | 0.734      |
| ProcessExecTime         | 0.0947     |
| StdReturn               | 458        |
| Time                    | 3.01e+03   |
| dLoss                   | 0.0480055  |
----------------------------------------
itr #261 | 
Mem: 757.933594
Obtaining samples...
Obtaining samples for iteration 261...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5426, #subsample_inputs: 5426
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.691      |
| AbsLearnSignalNew       | 0.691      |
| AbsLearningOld          | 0.691      |
| AverageDiscountedReturn | 134        |
| AveragePhiLoss          | 17.6318    |
| AveragePolicyStd        | 0.795128   |
| AverageReturn           | 924        |
| Entropy                 | 7.10234    |
| EnvExecTime             | 3.36       |
| ExplainedVariance       | 0.606      |
| Iteration               | 261        |
| ItrTime                 | 13.1       |
| LossAfter               | -0.261984  |
| LossBefore              | -0.21806   |
| MaxReturn               | 1.99e+03   |
| MeanKL                  | 0.00645304 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 78.6       |
| NumTrajs                | 13         |
| Perplexity              | 1214.8     |
| PolicyExecTime          | 0.711      |
| ProcessExecTime         | 0.0923     |
| StdReturn               | 584        |
| Time                    | 3.02e+03   |
| dLoss                   | 0.0439242  |
----------------------------------------
itr #262 | 
Mem: 757.933594
Obtaining samples...
Obtaining samples for iteration 262...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5151, #subsample_inputs: 5151
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.676      |
| AbsLearnSignalNew       | 0.676      |
| AbsLearningOld          | 0.676      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 16.9413    |
| AveragePolicyStd        | 0.793275   |
| AverageReturn           | 626        |
| Entropy                 | 7.08875    |
| EnvExecTime             | 2.67       |
| ExplainedVariance       | 0.575      |
| Iteration               | 262        |
| ItrTime                 | 11.3       |
| LossAfter               | -0.309712  |
| LossBefore              | -0.268312  |
| MaxReturn               | 1.54e+03   |
| MeanKL                  | 0.00641182 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 79.5       |
| NumTrajs                | 16         |
| Perplexity              | 1198.41    |
| PolicyExecTime          | 0.518      |
| ProcessExecTime         | 0.0693     |
| StdReturn               | 435        |
| Time                    | 3.03e+03   |
| dLoss                   | 0.0414     |
----------------------------------------
itr #263 | 
Mem: 757.933594
Obtaining samples...
Obtaining samples for iteration 263...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5666, #subsample_inputs: 5666
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.7        |
| AbsLearnSignalNew       | 0.7        |
| AbsLearningOld          | 0.7        |
| AverageDiscountedReturn | 145        |
| AveragePhiLoss          | 17.3714    |
| AveragePolicyStd        | 0.792359   |
| AverageReturn           | 953        |
| Entropy                 | 7.08144    |
| EnvExecTime             | 3.38       |
| ExplainedVariance       | 0.294      |
| Iteration               | 263        |
| ItrTime                 | 12.3       |
| LossAfter               | -0.658963  |
| LossBefore              | -0.604427  |
| MaxReturn               | 2.03e+03   |
| MeanKL                  | 0.00992018 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 374        |
| NumTrajs                | 13         |
| Perplexity              | 1189.68    |
| PolicyExecTime          | 0.739      |
| ProcessExecTime         | 0.0988     |
| StdReturn               | 404        |
| Time                    | 3.04e+03   |
| dLoss                   | 0.0545364  |
----------------------------------------
itr #264 | 
Mem: 757.933594
Obtaining samples...
Obtaining samples for iteration 264...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5253, #subsample_inputs: 5253
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.687      |
| AbsLearnSignalNew       | 0.687      |
| AbsLearningOld          | 0.687      |
| AverageDiscountedReturn | 138        |
| AveragePhiLoss          | 17.7251    |
| AveragePolicyStd        | 0.791658   |
| AverageReturn           | 731        |
| Entropy                 | 7.07673    |
| EnvExecTime             | 2.99       |
| ExplainedVariance       | 0.475      |
| Iteration               | 264        |
| ItrTime                 | 12.4       |
| LossAfter               | 0.46941    |
| LossBefore              | 0.522689   |
| MaxReturn               | 1.66e+03   |
| MeanKL                  | 0.00997113 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 49.1       |
| NumTrajs                | 16         |
| Perplexity              | 1184.08    |
| PolicyExecTime          | 0.628      |
| ProcessExecTime         | 0.0843     |
| StdReturn               | 377        |
| Time                    | 3.06e+03   |
| dLoss                   | 0.0532788  |
----------------------------------------
itr #265 | 
Mem: 757.933594
Obtaining samples...
Obtaining samples for iteration 265...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5291, #subsample_inputs: 5291
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.676      |
| AbsLearnSignalNew       | 0.676      |
| AbsLearningOld          | 0.676      |
| AverageDiscountedReturn | 139        |
| AveragePhiLoss          | 17.1896    |
| AveragePolicyStd        | 0.792605   |
| AverageReturn           | 752        |
| Entropy                 | 7.08368    |
| EnvExecTime             | 2.93       |
| ExplainedVariance       | 0.526      |
| Iteration               | 265        |
| ItrTime                 | 11.6       |
| LossAfter               | 0.234286   |
| LossBefore              | 0.273582   |
| MaxReturn               | 1.38e+03   |
| MeanKL                  | 0.00645098 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 37         |
| NumTrajs                | 15         |
| Perplexity              | 1192.34    |
| PolicyExecTime          | 0.587      |
| ProcessExecTime         | 0.0728     |
| StdReturn               | 346        |
| Time                    | 3.07e+03   |
| dLoss                   | 0.0392962  |
----------------------------------------
itr #266 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 266...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5096, #subsample_inputs: 5096
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.657      |
| AbsLearnSignalNew       | 0.657      |
| AbsLearningOld          | 0.656      |
| AverageDiscountedReturn | 140        |
| AveragePhiLoss          | 16.6472    |
| AveragePolicyStd        | 0.791784   |
| AverageReturn           | 880        |
| Entropy                 | 7.07734    |
| EnvExecTime             | 3.49       |
| ExplainedVariance       | 0.417      |
| Iteration               | 266        |
| ItrTime                 | 11.2       |
| LossAfter               | -0.112054  |
| LossBefore              | -0.0647393 |
| MaxReturn               | 1.91e+03   |
| MeanKL                  | 0.00646752 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 322        |
| NumTrajs                | 12         |
| Perplexity              | 1184.81    |
| PolicyExecTime          | 0.74       |
| ProcessExecTime         | 0.09       |
| StdReturn               | 407        |
| Time                    | 3.08e+03   |
| dLoss                   | 0.0473146  |
----------------------------------------
itr #267 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 267...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5174, #subsample_inputs: 5174
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
-----------------------------------------
| AbsLearnSignal          | 0.417       |
| AbsLearnSignalNew       | 0.417       |
| AbsLearningOld          | 0.417       |
| AverageDiscountedReturn | 133         |
| AveragePhiLoss          | 16.2273     |
| AveragePolicyStd        | 0.790389    |
| AverageReturn           | 1e+03       |
| Entropy                 | 7.06571     |
| EnvExecTime             | 3.43        |
| ExplainedVariance       | -0.457      |
| Iteration               | 267         |
| ItrTime                 | 12.9        |
| LossAfter               | -0.00615707 |
| LossBefore              | 0.0432278   |
| MaxReturn               | 2.14e+03    |
| MeanKL                  | 0.00985781  |
| MeanKLBefore            | 0.0         |
| MinReturn               | 58.3        |
| NumTrajs                | 11          |
| Perplexity              | 1171.11     |
| PolicyExecTime          | 0.73        |
| ProcessExecTime         | 0.0973      |
| StdReturn               | 635         |
| Time                    | 3.09e+03    |
| dLoss                   | 0.0493849   |
-----------------------------------------
itr #268 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 268...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5670, #subsample_inputs: 5670
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.645      |
| AbsLearnSignalNew       | 0.645      |
| AbsLearningOld          | 0.645      |
| AverageDiscountedReturn | 134        |
| AveragePhiLoss          | 17.0784    |
| AveragePolicyStd        | 0.79027    |
| AverageReturn           | 788        |
| Entropy                 | 7.0639     |
| EnvExecTime             | 2.89       |
| ExplainedVariance       | 0.528      |
| Iteration               | 268        |
| ItrTime                 | 12.3       |
| LossAfter               | -0.710079  |
| LossBefore              | -0.659004  |
| MaxReturn               | 2.01e+03   |
| MeanKL                  | 0.00973588 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 53.3       |
| NumTrajs                | 15         |
| Perplexity              | 1169.0     |
| PolicyExecTime          | 0.567      |
| ProcessExecTime         | 0.0763     |
| StdReturn               | 545        |
| Time                    | 3.1e+03    |
| dLoss                   | 0.0510757  |
----------------------------------------
itr #269 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 269...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5328, #subsample_inputs: 5328
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.666      |
| AbsLearnSignalNew       | 0.666      |
| AbsLearningOld          | 0.666      |
| AverageDiscountedReturn | 118        |
| AveragePhiLoss          | 16.8507    |
| AveragePolicyStd        | 0.792756   |
| AverageReturn           | 763        |
| Entropy                 | 7.08318    |
| EnvExecTime             | 3.48       |
| ExplainedVariance       | 0.48       |
| Iteration               | 269        |
| ItrTime                 | 11.5       |
| LossAfter               | -0.778461  |
| LossBefore              | -0.7377    |
| MaxReturn               | 2.09e+03   |
| MeanKL                  | 0.00642683 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 61.5       |
| NumTrajs                | 14         |
| Perplexity              | 1191.76    |
| PolicyExecTime          | 0.708      |
| ProcessExecTime         | 0.0903     |
| StdReturn               | 653        |
| Time                    | 3.12e+03   |
| dLoss                   | 0.0407618  |
----------------------------------------
itr #270 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 270...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5058, #subsample_inputs: 5058
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.641      |
| AbsLearnSignalNew       | 0.641      |
| AbsLearningOld          | 0.641      |
| AverageDiscountedReturn | 140        |
| AveragePhiLoss          | 18.1502    |
| AveragePolicyStd        | 0.792841   |
| AverageReturn           | 904        |
| Entropy                 | 7.08385    |
| EnvExecTime             | 3.35       |
| ExplainedVariance       | -0.629     |
| Iteration               | 270        |
| ItrTime                 | 12.3       |
| LossAfter               | -0.559119  |
| LossBefore              | -0.510666  |
| MaxReturn               | 1.99e+03   |
| MeanKL                  | 0.00644938 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 443        |
| NumTrajs                | 12         |
| Perplexity              | 1192.55    |
| PolicyExecTime          | 0.718      |
| ProcessExecTime         | 0.0902     |
| StdReturn               | 470        |
| Time                    | 3.13e+03   |
| dLoss                   | 0.0484536  |
----------------------------------------
itr #271 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 271...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5204, #subsample_inputs: 5204
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.65      |
| AbsLearnSignalNew       | 0.65      |
| AbsLearningOld          | 0.65      |
| AverageDiscountedReturn | 111       |
| AveragePhiLoss          | 17.4419   |
| AveragePolicyStd        | 0.793548  |
| AverageReturn           | 922       |
| Entropy                 | 7.08939   |
| EnvExecTime             | 2.82      |
| ExplainedVariance       | 0.449     |
| Iteration               | 271       |
| ItrTime                 | 12.1      |
| LossAfter               | 0.631116  |
| LossBefore              | 0.667918  |
| MaxReturn               | 2.38e+03  |
| MeanKL                  | 0.00645   |
| MeanKLBefore            | 0.0       |
| MinReturn               | 85.1      |
| NumTrajs                | 10        |
| Perplexity              | 1199.17   |
| PolicyExecTime          | 0.556     |
| ProcessExecTime         | 0.0732    |
| StdReturn               | 838       |
| Time                    | 3.14e+03  |
| dLoss                   | 0.0368018 |
---------------------------------------
itr #272 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 272...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5846, #subsample_inputs: 5846
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.567      |
| AbsLearnSignalNew       | 0.567      |
| AbsLearningOld          | 0.567      |
| AverageDiscountedReturn | 151        |
| AveragePhiLoss          | 18.3571    |
| AveragePolicyStd        | 0.791315   |
| AverageReturn           | 1.12e+03   |
| Entropy                 | 7.07397    |
| EnvExecTime             | 3.28       |
| ExplainedVariance       | -0.21      |
| Iteration               | 272        |
| ItrTime                 | 12.2       |
| LossAfter               | -0.239471  |
| LossBefore              | -0.182356  |
| MaxReturn               | 2.27e+03   |
| MeanKL                  | 0.00991896 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 416        |
| NumTrajs                | 12         |
| Perplexity              | 1180.82    |
| PolicyExecTime          | 0.697      |
| ProcessExecTime         | 0.0913     |
| StdReturn               | 570        |
| Time                    | 3.15e+03   |
| dLoss                   | 0.0571148  |
----------------------------------------
itr #273 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 273...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5226, #subsample_inputs: 5226
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.634      |
| AbsLearnSignalNew       | 0.634      |
| AbsLearningOld          | 0.634      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 17.3222    |
| AveragePolicyStd        | 0.791123   |
| AverageReturn           | 636        |
| Entropy                 | 7.06937    |
| EnvExecTime             | 3.26       |
| ExplainedVariance       | 0.437      |
| Iteration               | 273        |
| ItrTime                 | 11.7       |
| LossAfter               | -0.0375064 |
| LossBefore              | 0.00659679 |
| MaxReturn               | 1.29e+03   |
| MeanKL                  | 0.00645871 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 66.7       |
| NumTrajs                | 16         |
| Perplexity              | 1175.41    |
| PolicyExecTime          | 0.69       |
| ProcessExecTime         | 0.0872     |
| StdReturn               | 381        |
| Time                    | 3.17e+03   |
| dLoss                   | 0.0441032  |
----------------------------------------
itr #274 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 274...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5006, #subsample_inputs: 5006
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.624      |
| AbsLearnSignalNew       | 0.624      |
| AbsLearningOld          | 0.624      |
| AverageDiscountedReturn | 132        |
| AveragePhiLoss          | 20.0456    |
| AveragePolicyStd        | 0.787809   |
| AverageReturn           | 876        |
| Entropy                 | 7.04196    |
| EnvExecTime             | 2.69       |
| ExplainedVariance       | 0.401      |
| Iteration               | 274        |
| ItrTime                 | 11.8       |
| LossAfter               | 1.01588    |
| LossBefore              | 1.06559    |
| MaxReturn               | 2.26e+03   |
| MeanKL                  | 0.00996567 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 106        |
| NumTrajs                | 12         |
| Perplexity              | 1143.63    |
| PolicyExecTime          | 0.58       |
| ProcessExecTime         | 0.0733     |
| StdReturn               | 584        |
| Time                    | 3.18e+03   |
| dLoss                   | 0.0497111  |
----------------------------------------
itr #275 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 275...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5349, #subsample_inputs: 5349
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.662      |
| AbsLearnSignalNew       | 0.662      |
| AbsLearningOld          | 0.662      |
| AverageDiscountedReturn | 156        |
| AveragePhiLoss          | 18.7247    |
| AveragePolicyStd        | 0.783377   |
| AverageReturn           | 1.29e+03   |
| Entropy                 | 7.00855    |
| EnvExecTime             | 3.17       |
| ExplainedVariance       | -0.133     |
| Iteration               | 275        |
| ItrTime                 | 11.7       |
| LossAfter               | 0.731538   |
| LossBefore              | 0.785076   |
| MaxReturn               | 2.2e+03    |
| MeanKL                  | 0.00987627 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 659        |
| NumTrajs                | 9          |
| Perplexity              | 1106.05    |
| PolicyExecTime          | 0.675      |
| ProcessExecTime         | 0.0876     |
| StdReturn               | 497        |
| Time                    | 3.19e+03   |
| dLoss                   | 0.0535386  |
----------------------------------------
itr #276 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 276...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5027, #subsample_inputs: 5027
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.669      |
| AbsLearnSignalNew       | 0.669      |
| AbsLearningOld          | 0.669      |
| AverageDiscountedReturn | 115        |
| AveragePhiLoss          | 18.9846    |
| AveragePolicyStd        | 0.784209   |
| AverageReturn           | 739        |
| Entropy                 | 7.01569    |
| EnvExecTime             | 3.39       |
| ExplainedVariance       | 0.461      |
| Iteration               | 276        |
| ItrTime                 | 11.7       |
| LossAfter               | 0.865691   |
| LossBefore              | 0.918395   |
| MaxReturn               | 2.03e+03   |
| MeanKL                  | 0.00990861 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 46.9       |
| NumTrajs                | 13         |
| Perplexity              | 1113.98    |
| PolicyExecTime          | 0.703      |
| ProcessExecTime         | 0.0892     |
| StdReturn               | 673        |
| Time                    | 3.2e+03    |
| dLoss                   | 0.0527036  |
----------------------------------------
itr #277 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 277...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5062, #subsample_inputs: 5062
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.715      |
| AbsLearnSignalNew       | 0.715      |
| AbsLearningOld          | 0.715      |
| AverageDiscountedReturn | 108        |
| AveragePhiLoss          | 17.6429    |
| AveragePolicyStd        | 0.782465   |
| AverageReturn           | 759        |
| Entropy                 | 7.00435    |
| EnvExecTime             | 3.22       |
| ExplainedVariance       | 0.534      |
| Iteration               | 277        |
| ItrTime                 | 12.5       |
| LossAfter               | 0.234819   |
| LossBefore              | 0.288387   |
| MaxReturn               | 2.33e+03   |
| MeanKL                  | 0.00989174 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 58.3       |
| NumTrajs                | 13         |
| Perplexity              | 1101.41    |
| PolicyExecTime          | 0.655      |
| ProcessExecTime         | 0.0827     |
| StdReturn               | 703        |
| Time                    | 3.21e+03   |
| dLoss                   | 0.0535687  |
----------------------------------------
itr #278 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 278...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5199, #subsample_inputs: 5199
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.718      |
| AbsLearnSignalNew       | 0.718      |
| AbsLearningOld          | 0.718      |
| AverageDiscountedReturn | 130        |
| AveragePhiLoss          | 18.645     |
| AveragePolicyStd        | 0.781926   |
| AverageReturn           | 837        |
| Entropy                 | 6.99882    |
| EnvExecTime             | 3.26       |
| ExplainedVariance       | 0.457      |
| Iteration               | 278        |
| ItrTime                 | 11.3       |
| LossAfter               | 0.0402586  |
| LossBefore              | 0.0804523  |
| MaxReturn               | 2.09e+03   |
| MeanKL                  | 0.00647392 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 120        |
| NumTrajs                | 12         |
| Perplexity              | 1095.34    |
| PolicyExecTime          | 0.693      |
| ProcessExecTime         | 0.084      |
| StdReturn               | 680        |
| Time                    | 3.23e+03   |
| dLoss                   | 0.0401937  |
----------------------------------------
itr #279 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 279...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5558, #subsample_inputs: 5558
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.608      |
| AbsLearnSignalNew       | 0.608      |
| AbsLearningOld          | 0.608      |
| AverageDiscountedReturn | 109        |
| AveragePhiLoss          | 19.2564    |
| AveragePolicyStd        | 0.78046    |
| AverageReturn           | 617        |
| Entropy                 | 6.98748    |
| EnvExecTime             | 3.57       |
| ExplainedVariance       | 0.444      |
| Iteration               | 279        |
| ItrTime                 | 12.8       |
| LossAfter               | -0.314686  |
| LossBefore              | -0.264277  |
| MaxReturn               | 1.81e+03   |
| MeanKL                  | 0.00642625 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 64.8       |
| NumTrajs                | 16         |
| Perplexity              | 1082.99    |
| PolicyExecTime          | 0.746      |
| ProcessExecTime         | 0.0941     |
| StdReturn               | 540        |
| Time                    | 3.24e+03   |
| dLoss                   | 0.0504096  |
----------------------------------------
itr #280 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 280...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5884, #subsample_inputs: 5884
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.707      |
| AbsLearnSignalNew       | 0.707      |
| AbsLearningOld          | 0.707      |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 18.8433    |
| AveragePolicyStd        | 0.779875   |
| AverageReturn           | 1e+03      |
| Entropy                 | 6.98415    |
| EnvExecTime             | 2.88       |
| ExplainedVariance       | 0.387      |
| Iteration               | 280        |
| ItrTime                 | 13         |
| LossAfter               | -0.0355144 |
| LossBefore              | 0.0132399  |
| MaxReturn               | 2.14e+03   |
| MeanKL                  | 0.00995437 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 92.8       |
| NumTrajs                | 12         |
| Perplexity              | 1079.39    |
| PolicyExecTime          | 0.595      |
| ProcessExecTime         | 0.0786     |
| StdReturn               | 653        |
| Time                    | 3.25e+03   |
| dLoss                   | 0.0487543  |
----------------------------------------
itr #281 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 281...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5204, #subsample_inputs: 5204
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.703      |
| AbsLearnSignalNew       | 0.703      |
| AbsLearningOld          | 0.703      |
| AverageDiscountedReturn | 140        |
| AveragePhiLoss          | 17.8651    |
| AveragePolicyStd        | 0.777508   |
| AverageReturn           | 972        |
| Entropy                 | 6.96523    |
| EnvExecTime             | 2.9        |
| ExplainedVariance       | 0.492      |
| Iteration               | 281        |
| ItrTime                 | 11.3       |
| LossAfter               | 0.82157    |
| LossBefore              | 0.87513    |
| MaxReturn               | 2.37e+03   |
| MeanKL                  | 0.00998819 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 94.3       |
| NumTrajs                | 12         |
| Perplexity              | 1059.15    |
| PolicyExecTime          | 0.598      |
| ProcessExecTime         | 0.0765     |
| StdReturn               | 597        |
| Time                    | 3.26e+03   |
| dLoss                   | 0.0535598  |
----------------------------------------
itr #282 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 282...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5023, #subsample_inputs: 5023
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.691      |
| AbsLearnSignalNew       | 0.691      |
| AbsLearningOld          | 0.691      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 17.7278    |
| AveragePolicyStd        | 0.777051   |
| AverageReturn           | 632        |
| Entropy                 | 6.96233    |
| EnvExecTime             | 3.3        |
| ExplainedVariance       | 0.559      |
| Iteration               | 282        |
| ItrTime                 | 11.5       |
| LossAfter               | 0.51337    |
| LossBefore              | 0.557696   |
| MaxReturn               | 1.98e+03   |
| MeanKL                  | 0.00640662 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 42.1       |
| NumTrajs                | 15         |
| Perplexity              | 1056.09    |
| PolicyExecTime          | 0.682      |
| ProcessExecTime         | 0.0852     |
| StdReturn               | 519        |
| Time                    | 3.27e+03   |
| dLoss                   | 0.0443261  |
----------------------------------------
itr #283 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 283...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5190, #subsample_inputs: 5190
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.58       |
| AbsLearnSignalNew       | 0.58       |
| AbsLearningOld          | 0.58       |
| AverageDiscountedReturn | 146        |
| AveragePhiLoss          | 17.4963    |
| AveragePolicyStd        | 0.776248   |
| AverageReturn           | 1.08e+03   |
| Entropy                 | 6.95518    |
| EnvExecTime             | 3.03       |
| ExplainedVariance       | 0.0743     |
| Iteration               | 283        |
| ItrTime                 | 12.6       |
| LossAfter               | 0.474498   |
| LossBefore              | 0.521663   |
| MaxReturn               | 2.09e+03   |
| MeanKL                  | 0.00640072 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 350        |
| NumTrajs                | 11         |
| Perplexity              | 1048.57    |
| PolicyExecTime          | 0.659      |
| ProcessExecTime         | 0.0827     |
| StdReturn               | 476        |
| Time                    | 3.29e+03   |
| dLoss                   | 0.0471651  |
----------------------------------------
itr #284 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 284...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5307, #subsample_inputs: 5307
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.632      |
| AbsLearnSignalNew       | 0.632      |
| AbsLearningOld          | 0.632      |
| AverageDiscountedReturn | 132        |
| AveragePhiLoss          | 17.893     |
| AveragePolicyStd        | 0.77504    |
| AverageReturn           | 982        |
| Entropy                 | 6.94428    |
| EnvExecTime             | 2.79       |
| ExplainedVariance       | 0.527      |
| Iteration               | 284        |
| ItrTime                 | 11.7       |
| LossAfter               | -0.213041  |
| LossBefore              | -0.17051   |
| MaxReturn               | 2.1e+03    |
| MeanKL                  | 0.00642726 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 69.6       |
| NumTrajs                | 11         |
| Perplexity              | 1037.2     |
| PolicyExecTime          | 0.551      |
| ProcessExecTime         | 0.0726     |
| StdReturn               | 594        |
| Time                    | 3.3e+03    |
| dLoss                   | 0.0425313  |
----------------------------------------
itr #285 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 285...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5226, #subsample_inputs: 5226
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.665      |
| AbsLearnSignalNew       | 0.665      |
| AbsLearningOld          | 0.664      |
| AverageDiscountedReturn | 132        |
| AveragePhiLoss          | 18.3391    |
| AveragePolicyStd        | 0.775098   |
| AverageReturn           | 838        |
| Entropy                 | 6.94125    |
| EnvExecTime             | 3.84       |
| ExplainedVariance       | 0.492      |
| Iteration               | 285        |
| ItrTime                 | 12.2       |
| LossAfter               | 0.352807   |
| LossBefore              | 0.395403   |
| MaxReturn               | 2.05e+03   |
| MeanKL                  | 0.00640281 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 96.8       |
| NumTrajs                | 13         |
| Perplexity              | 1034.06    |
| PolicyExecTime          | 0.801      |
| ProcessExecTime         | 0.0992     |
| StdReturn               | 583        |
| Time                    | 3.31e+03   |
| dLoss                   | 0.0425962  |
----------------------------------------
itr #286 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 286...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5604, #subsample_inputs: 5604
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.624      |
| AbsLearnSignalNew       | 0.624      |
| AbsLearningOld          | 0.624      |
| AverageDiscountedReturn | 146        |
| AveragePhiLoss          | 17.3907    |
| AveragePolicyStd        | 0.777476   |
| AverageReturn           | 1.37e+03   |
| Entropy                 | 6.95821    |
| EnvExecTime             | 3.08       |
| ExplainedVariance       | 0.53       |
| Iteration               | 286        |
| ItrTime                 | 12.8       |
| LossAfter               | 0.550319   |
| LossBefore              | 0.58828    |
| MaxReturn               | 2.24e+03   |
| MeanKL                  | 0.00644946 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 512        |
| NumTrajs                | 9          |
| Perplexity              | 1051.75    |
| PolicyExecTime          | 0.647      |
| ProcessExecTime         | 0.0864     |
| StdReturn               | 693        |
| Time                    | 3.32e+03   |
| dLoss                   | 0.0379618  |
----------------------------------------
itr #287 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 287...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5496, #subsample_inputs: 5496
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.65       |
| AbsLearnSignalNew       | 0.65       |
| AbsLearningOld          | 0.65       |
| AverageDiscountedReturn | 133        |
| AveragePhiLoss          | 19.1598    |
| AveragePolicyStd        | 0.774622   |
| AverageReturn           | 880        |
| Entropy                 | 6.93617    |
| EnvExecTime             | 2.8        |
| ExplainedVariance       | 0.428      |
| Iteration               | 287        |
| ItrTime                 | 12.5       |
| LossAfter               | -0.130183  |
| LossBefore              | -0.0809389 |
| MaxReturn               | 2.29e+03   |
| MeanKL                  | 0.00993005 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 71.8       |
| NumTrajs                | 13         |
| Perplexity              | 1028.82    |
| PolicyExecTime          | 0.548      |
| ProcessExecTime         | 0.0741     |
| StdReturn               | 589        |
| Time                    | 3.34e+03   |
| dLoss                   | 0.0492446  |
----------------------------------------
itr #288 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 288...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5504, #subsample_inputs: 5504
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.634      |
| AbsLearnSignalNew       | 0.634      |
| AbsLearningOld          | 0.634      |
| AverageDiscountedReturn | 148        |
| AveragePhiLoss          | 19.0627    |
| AveragePolicyStd        | 0.77436    |
| AverageReturn           | 1.1e+03    |
| Entropy                 | 6.93416    |
| EnvExecTime             | 3.21       |
| ExplainedVariance       | 0.324      |
| Iteration               | 288        |
| ItrTime                 | 11.5       |
| LossAfter               | 0.757274   |
| LossBefore              | 0.806322   |
| MaxReturn               | 2.47e+03   |
| MeanKL                  | 0.00648369 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 397        |
| NumTrajs                | 12         |
| Perplexity              | 1026.76    |
| PolicyExecTime          | 0.677      |
| ProcessExecTime         | 0.0881     |
| StdReturn               | 568        |
| Time                    | 3.35e+03   |
| dLoss                   | 0.0490485  |
----------------------------------------
itr #289 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 289...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5023, #subsample_inputs: 5023
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.577      |
| AbsLearnSignalNew       | 0.577      |
| AbsLearningOld          | 0.577      |
| AverageDiscountedReturn | 117        |
| AveragePhiLoss          | 17.2111    |
| AveragePolicyStd        | 0.774981   |
| AverageReturn           | 784        |
| Entropy                 | 6.93806    |
| EnvExecTime             | 2.93       |
| ExplainedVariance       | 0.419      |
| Iteration               | 289        |
| ItrTime                 | 11.6       |
| LossAfter               | 0.5751     |
| LossBefore              | 0.61551    |
| MaxReturn               | 2.25e+03   |
| MeanKL                  | 0.00644354 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 68.3       |
| NumTrajs                | 12         |
| Perplexity              | 1030.77    |
| PolicyExecTime          | 0.609      |
| ProcessExecTime         | 0.0809     |
| StdReturn               | 676        |
| Time                    | 3.36e+03   |
| dLoss                   | 0.0404095  |
----------------------------------------
itr #290 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 290...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5496, #subsample_inputs: 5496
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.607      |
| AbsLearnSignalNew       | 0.607      |
| AbsLearningOld          | 0.607      |
| AverageDiscountedReturn | 130        |
| AveragePhiLoss          | 18.4381    |
| AveragePolicyStd        | 0.772194   |
| AverageReturn           | 944        |
| Entropy                 | 6.91704    |
| EnvExecTime             | 3.12       |
| ExplainedVariance       | 0.332      |
| Iteration               | 290        |
| ItrTime                 | 12.9       |
| LossAfter               | -0.0902597 |
| LossBefore              | -0.0428185 |
| MaxReturn               | 2.25e+03   |
| MeanKL                  | 0.00647809 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 73.8       |
| NumTrajs                | 12         |
| Perplexity              | 1009.33    |
| PolicyExecTime          | 0.632      |
| ProcessExecTime         | 0.0807     |
| StdReturn               | 593        |
| Time                    | 3.37e+03   |
| dLoss                   | 0.0474412  |
----------------------------------------
itr #291 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 291...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5323, #subsample_inputs: 5323
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.675      |
| AbsLearnSignalNew       | 0.675      |
| AbsLearningOld          | 0.675      |
| AverageDiscountedReturn | 140        |
| AveragePhiLoss          | 19.2684    |
| AveragePolicyStd        | 0.770236   |
| AverageReturn           | 816        |
| Entropy                 | 6.90258    |
| EnvExecTime             | 3.33       |
| ExplainedVariance       | 0.469      |
| Iteration               | 291        |
| ItrTime                 | 11.9       |
| LossAfter               | -0.0870954 |
| LossBefore              | -0.0306132 |
| MaxReturn               | 1.27e+03   |
| MeanKL                  | 0.00999595 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 123        |
| NumTrajs                | 14         |
| Perplexity              | 994.835    |
| PolicyExecTime          | 0.684      |
| ProcessExecTime         | 0.0859     |
| StdReturn               | 316        |
| Time                    | 3.38e+03   |
| dLoss                   | 0.0564821  |
----------------------------------------
itr #292 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 292...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5920, #subsample_inputs: 5920
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.598      |
| AbsLearnSignalNew       | 0.598      |
| AbsLearningOld          | 0.598      |
| AverageDiscountedReturn | 130        |
| AveragePhiLoss          | 19.0127    |
| AveragePolicyStd        | 0.770253   |
| AverageReturn           | 732        |
| Entropy                 | 6.90344    |
| EnvExecTime             | 3.79       |
| ExplainedVariance       | 0.273      |
| Iteration               | 292        |
| ItrTime                 | 12.8       |
| LossAfter               | 0.661261   |
| LossBefore              | 0.714831   |
| MaxReturn               | 2.25e+03   |
| MeanKL                  | 0.00986326 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 81.2       |
| NumTrajs                | 15         |
| Perplexity              | 995.691    |
| PolicyExecTime          | 0.797      |
| ProcessExecTime         | 0.101      |
| StdReturn               | 557        |
| Time                    | 3.4e+03    |
| dLoss                   | 0.0535702  |
----------------------------------------
itr #293 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 293...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5073, #subsample_inputs: 5073
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.686      |
| AbsLearnSignalNew       | 0.686      |
| AbsLearningOld          | 0.686      |
| AverageDiscountedReturn | 127        |
| AveragePhiLoss          | 19.6175    |
| AveragePolicyStd        | 0.777004   |
| AverageReturn           | 699        |
| Entropy                 | 6.95342    |
| EnvExecTime             | 3.28       |
| ExplainedVariance       | 0.42       |
| Iteration               | 293        |
| ItrTime                 | 12.6       |
| LossAfter               | -0.269621  |
| LossBefore              | -0.213377  |
| MaxReturn               | 1.83e+03   |
| MeanKL                  | 0.00985268 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 36.4       |
| NumTrajs                | 15         |
| Perplexity              | 1046.72    |
| PolicyExecTime          | 0.662      |
| ProcessExecTime         | 0.0861     |
| StdReturn               | 447        |
| Time                    | 3.41e+03   |
| dLoss                   | 0.0562439  |
----------------------------------------
itr #294 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 294...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5343, #subsample_inputs: 5343
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.493     |
| AbsLearnSignalNew       | 0.493     |
| AbsLearningOld          | 0.493     |
| AverageDiscountedReturn | 148       |
| AveragePhiLoss          | 19.6959   |
| AveragePolicyStd        | 0.775184  |
| AverageReturn           | 1.34e+03  |
| Entropy                 | 6.93901   |
| EnvExecTime             | 2.85      |
| ExplainedVariance       | -1.43     |
| Iteration               | 294       |
| ItrTime                 | 12.2      |
| LossAfter               | 0.0568385 |
| LossBefore              | 0.0962665 |
| MaxReturn               | 2.3e+03   |
| MeanKL                  | 0.006411  |
| MeanKLBefore            | 0.0       |
| MinReturn               | 594       |
| NumTrajs                | 9         |
| Perplexity              | 1031.75   |
| PolicyExecTime          | 0.565     |
| ProcessExecTime         | 0.0743    |
| StdReturn               | 603       |
| Time                    | 3.42e+03  |
| dLoss                   | 0.0394281 |
---------------------------------------
itr #295 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 295...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5078, #subsample_inputs: 5078
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.592      |
| AbsLearnSignalNew       | 0.592      |
| AbsLearningOld          | 0.592      |
| AverageDiscountedReturn | 139        |
| AveragePhiLoss          | 18.7936    |
| AveragePolicyStd        | 0.774347   |
| AverageReturn           | 855        |
| Entropy                 | 6.93196    |
| EnvExecTime             | 3.01       |
| ExplainedVariance       | 0.384      |
| Iteration               | 295        |
| ItrTime                 | 10.5       |
| LossAfter               | 0.118699   |
| LossBefore              | 0.186263   |
| MaxReturn               | 1.59e+03   |
| MeanKL                  | 0.00978998 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 65.5       |
| NumTrajs                | 13         |
| Perplexity              | 1024.5     |
| PolicyExecTime          | 0.632      |
| ProcessExecTime         | 0.0833     |
| StdReturn               | 414        |
| Time                    | 3.43e+03   |
| dLoss                   | 0.0675639  |
----------------------------------------
itr #296 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 296...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5129, #subsample_inputs: 5129
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.58       |
| AbsLearnSignalNew       | 0.58       |
| AbsLearningOld          | 0.58       |
| AverageDiscountedReturn | 135        |
| AveragePhiLoss          | 17.9439    |
| AveragePolicyStd        | 0.77578    |
| AverageReturn           | 1.22e+03   |
| Entropy                 | 6.94486    |
| EnvExecTime             | 3.61       |
| ExplainedVariance       | -2.17      |
| Iteration               | 296        |
| ItrTime                 | 12.7       |
| LossAfter               | -0.0810136 |
| LossBefore              | -0.0289883 |
| MaxReturn               | 2.29e+03   |
| MeanKL                  | 0.00646523 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 138        |
| NumTrajs                | 9          |
| Perplexity              | 1037.81    |
| PolicyExecTime          | 0.751      |
| ProcessExecTime         | 0.0936     |
| StdReturn               | 723        |
| Time                    | 3.45e+03   |
| dLoss                   | 0.0520253  |
----------------------------------------
itr #297 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 297...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5233, #subsample_inputs: 5233
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.66       |
| AbsLearnSignalNew       | 0.66       |
| AbsLearningOld          | 0.66       |
| AverageDiscountedReturn | 129        |
| AveragePhiLoss          | 18.3625    |
| AveragePolicyStd        | 0.774968   |
| AverageReturn           | 1e+03      |
| Entropy                 | 6.93551    |
| EnvExecTime             | 3.31       |
| ExplainedVariance       | 0.529      |
| Iteration               | 297        |
| ItrTime                 | 12.7       |
| LossAfter               | 0.245985   |
| LossBefore              | 0.297673   |
| MaxReturn               | 2.47e+03   |
| MeanKL                  | 0.00996803 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 109        |
| NumTrajs                | 11         |
| Perplexity              | 1028.14    |
| PolicyExecTime          | 0.683      |
| ProcessExecTime         | 0.0793     |
| StdReturn               | 739        |
| Time                    | 3.46e+03   |
| dLoss                   | 0.0516875  |
----------------------------------------
itr #298 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 298...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5209, #subsample_inputs: 5209
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.67       |
| AbsLearnSignalNew       | 0.67       |
| AbsLearningOld          | 0.67       |
| AverageDiscountedReturn | 144        |
| AveragePhiLoss          | 19.226     |
| AveragePolicyStd        | 0.775594   |
| AverageReturn           | 932        |
| Entropy                 | 6.93835    |
| EnvExecTime             | 3.29       |
| ExplainedVariance       | 0.409      |
| Iteration               | 298        |
| ItrTime                 | 11.6       |
| LossAfter               | -1.00672   |
| LossBefore              | -0.952598  |
| MaxReturn               | 2.15e+03   |
| MeanKL                  | 0.00987535 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 471        |
| NumTrajs                | 12         |
| Perplexity              | 1031.06    |
| PolicyExecTime          | 0.699      |
| ProcessExecTime         | 0.0885     |
| StdReturn               | 444        |
| Time                    | 3.47e+03   |
| dLoss                   | 0.0541182  |
----------------------------------------
itr #299 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 299...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5035, #subsample_inputs: 5035
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.682      |
| AbsLearnSignalNew       | 0.682      |
| AbsLearningOld          | 0.682      |
| AverageDiscountedReturn | 118        |
| AveragePhiLoss          | 17.9448    |
| AveragePolicyStd        | 0.776946   |
| AverageReturn           | 936        |
| Entropy                 | 6.9504     |
| EnvExecTime             | 3.31       |
| ExplainedVariance       | 0.531      |
| Iteration               | 299        |
| ItrTime                 | 11.5       |
| LossAfter               | -1.34775   |
| LossBefore              | -1.30723   |
| MaxReturn               | 2e+03      |
| MeanKL                  | 0.00644581 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 52.5       |
| NumTrajs                | 11         |
| Perplexity              | 1043.56    |
| PolicyExecTime          | 0.671      |
| ProcessExecTime         | 0.0881     |
| StdReturn               | 673        |
| Time                    | 3.48e+03   |
| dLoss                   | 0.0405246  |
----------------------------------------
itr #300 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 300...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5287, #subsample_inputs: 5287
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.692      |
| AbsLearnSignalNew       | 0.692      |
| AbsLearningOld          | 0.691      |
| AverageDiscountedReturn | 145        |
| AveragePhiLoss          | 20.4184    |
| AveragePolicyStd        | 0.776584   |
| AverageReturn           | 871        |
| Entropy                 | 6.94818    |
| EnvExecTime             | 3.18       |
| ExplainedVariance       | 0.421      |
| Iteration               | 300        |
| ItrTime                 | 12.6       |
| LossAfter               | -1.29538   |
| LossBefore              | -1.25339   |
| MaxReturn               | 1.78e+03   |
| MeanKL                  | 0.00641332 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 40         |
| NumTrajs                | 13         |
| Perplexity              | 1041.25    |
| PolicyExecTime          | 0.663      |
| ProcessExecTime         | 0.0816     |
| StdReturn               | 466        |
| Time                    | 3.5e+03    |
| dLoss                   | 0.0419908  |
----------------------------------------
itr #301 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 301...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5323, #subsample_inputs: 5323
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.695      |
| AbsLearnSignalNew       | 0.695      |
| AbsLearningOld          | 0.695      |
| AverageDiscountedReturn | 153        |
| AveragePhiLoss          | 17.5892    |
| AveragePolicyStd        | 0.777528   |
| AverageReturn           | 920        |
| Entropy                 | 6.95635    |
| EnvExecTime             | 2.76       |
| ExplainedVariance       | 0.522      |
| Iteration               | 301        |
| ItrTime                 | 11.4       |
| LossAfter               | -1.08654   |
| LossBefore              | -1.04355   |
| MaxReturn               | 1.8e+03    |
| MeanKL                  | 0.00642233 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 110        |
| NumTrajs                | 14         |
| Perplexity              | 1049.79    |
| PolicyExecTime          | 0.561      |
| ProcessExecTime         | 0.0739     |
| StdReturn               | 435        |
| Time                    | 3.51e+03   |
| dLoss                   | 0.0429829  |
----------------------------------------
itr #302 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 302...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5291, #subsample_inputs: 5291
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.638     |
| AbsLearnSignalNew       | 0.638     |
| AbsLearningOld          | 0.638     |
| AverageDiscountedReturn | 130       |
| AveragePhiLoss          | 18.374    |
| AveragePolicyStd        | 0.778997  |
| AverageReturn           | 980       |
| Entropy                 | 6.96635   |
| EnvExecTime             | 3.1       |
| ExplainedVariance       | 0.506     |
| Iteration               | 302       |
| ItrTime                 | 11.4      |
| LossAfter               | -1.02691  |
| LossBefore              | -0.971812 |
| MaxReturn               | 1.96e+03  |
| MeanKL                  | 0.009791  |
| MeanKLBefore            | 0.0       |
| MinReturn               | 172       |
| NumTrajs                | 11        |
| Perplexity              | 1060.34   |
| PolicyExecTime          | 0.651     |
| ProcessExecTime         | 0.0883    |
| StdReturn               | 622       |
| Time                    | 3.52e+03  |
| dLoss                   | 0.0551022 |
---------------------------------------
itr #303 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 303...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5345, #subsample_inputs: 5345
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.659      |
| AbsLearnSignalNew       | 0.659      |
| AbsLearningOld          | 0.659      |
| AverageDiscountedReturn | 154        |
| AveragePhiLoss          | 18.3506    |
| AveragePolicyStd        | 0.7825     |
| AverageReturn           | 957        |
| Entropy                 | 6.99233    |
| EnvExecTime             | 3.25       |
| ExplainedVariance       | 0.301      |
| Iteration               | 303        |
| ItrTime                 | 12.8       |
| LossAfter               | -0.714646  |
| LossBefore              | -0.669396  |
| MaxReturn               | 2.12e+03   |
| MeanKL                  | 0.00640504 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 377        |
| NumTrajs                | 13         |
| Perplexity              | 1088.26    |
| PolicyExecTime          | 0.687      |
| ProcessExecTime         | 0.0877     |
| StdReturn               | 533        |
| Time                    | 3.53e+03   |
| dLoss                   | 0.0452503  |
----------------------------------------
itr #304 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 304...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5012, #subsample_inputs: 5012
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.594      |
| AbsLearnSignalNew       | 0.594      |
| AbsLearningOld          | 0.594      |
| AverageDiscountedReturn | 136        |
| AveragePhiLoss          | 17.7667    |
| AveragePolicyStd        | 0.782028   |
| AverageReturn           | 889        |
| Entropy                 | 6.98908    |
| EnvExecTime             | 2.36       |
| ExplainedVariance       | 0.456      |
| Iteration               | 304        |
| ItrTime                 | 10.4       |
| LossAfter               | -0.878279  |
| LossBefore              | -0.820177  |
| MaxReturn               | 2.18e+03   |
| MeanKL                  | 0.00988512 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 40.1       |
| NumTrajs                | 12         |
| Perplexity              | 1084.72    |
| PolicyExecTime          | 0.472      |
| ProcessExecTime         | 0.0641     |
| StdReturn               | 597        |
| Time                    | 3.54e+03   |
| dLoss                   | 0.0581017  |
----------------------------------------
itr #305 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 305...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5200, #subsample_inputs: 5200
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.676      |
| AbsLearnSignalNew       | 0.676      |
| AbsLearningOld          | 0.676      |
| AverageDiscountedReturn | 148        |
| AveragePhiLoss          | 18.9968    |
| AveragePolicyStd        | 0.782543   |
| AverageReturn           | 1.08e+03   |
| Entropy                 | 6.99231    |
| EnvExecTime             | 3.84       |
| ExplainedVariance       | 0.227      |
| Iteration               | 305        |
| ItrTime                 | 12         |
| LossAfter               | -0.634917  |
| LossBefore              | -0.578979  |
| MaxReturn               | 2.1e+03    |
| MeanKL                  | 0.00999068 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 436        |
| NumTrajs                | 11         |
| Perplexity              | 1088.24    |
| PolicyExecTime          | 0.814      |
| ProcessExecTime         | 0.102      |
| StdReturn               | 494        |
| Time                    | 3.55e+03   |
| dLoss                   | 0.055938   |
----------------------------------------
itr #306 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 306...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5034, #subsample_inputs: 5034
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.682      |
| AbsLearnSignalNew       | 0.682      |
| AbsLearningOld          | 0.682      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 19.9599    |
| AveragePolicyStd        | 0.780663   |
| AverageReturn           | 596        |
| Entropy                 | 6.97712    |
| EnvExecTime             | 2.98       |
| ExplainedVariance       | 0.449      |
| Iteration               | 306        |
| ItrTime                 | 12         |
| LossAfter               | -0.774401  |
| LossBefore              | -0.719428  |
| MaxReturn               | 1.23e+03   |
| MeanKL                  | 0.00994011 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 44.3       |
| NumTrajs                | 17         |
| Perplexity              | 1071.83    |
| PolicyExecTime          | 0.609      |
| ProcessExecTime         | 0.0808     |
| StdReturn               | 400        |
| Time                    | 3.57e+03   |
| dLoss                   | 0.0549729  |
----------------------------------------
itr #307 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 307...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5054, #subsample_inputs: 5054
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.563      |
| AbsLearnSignalNew       | 0.563      |
| AbsLearningOld          | 0.563      |
| AverageDiscountedReturn | 145        |
| AveragePhiLoss          | 19.3888    |
| AveragePolicyStd        | 0.779695   |
| AverageReturn           | 1.18e+03   |
| Entropy                 | 6.97121    |
| EnvExecTime             | 2.52       |
| ExplainedVariance       | -1.96      |
| Iteration               | 307        |
| ItrTime                 | 10.8       |
| LossAfter               | -0.951802  |
| LossBefore              | -0.887759  |
| MaxReturn               | 2.58e+03   |
| MeanKL                  | 0.00998876 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 202        |
| NumTrajs                | 10         |
| Perplexity              | 1065.51    |
| PolicyExecTime          | 0.501      |
| ProcessExecTime         | 0.0654     |
| StdReturn               | 651        |
| Time                    | 3.58e+03   |
| dLoss                   | 0.0640434  |
----------------------------------------
itr #308 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 308...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5214, #subsample_inputs: 5214
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.674      |
| AbsLearnSignalNew       | 0.674      |
| AbsLearningOld          | 0.674      |
| AverageDiscountedReturn | 150        |
| AveragePhiLoss          | 19.9458    |
| AveragePolicyStd        | 0.779429   |
| AverageReturn           | 831        |
| Entropy                 | 6.96845    |
| EnvExecTime             | 2.99       |
| ExplainedVariance       | 0.357      |
| Iteration               | 308        |
| ItrTime                 | 11.5       |
| LossAfter               | -0.594108  |
| LossBefore              | -0.545171  |
| MaxReturn               | 1.63e+03   |
| MeanKL                  | 0.00642565 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 285        |
| NumTrajs                | 14         |
| Perplexity              | 1062.58    |
| PolicyExecTime          | 0.627      |
| ProcessExecTime         | 0.0848     |
| StdReturn               | 367        |
| Time                    | 3.59e+03   |
| dLoss                   | 0.0489362  |
----------------------------------------
itr #309 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 309...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5198, #subsample_inputs: 5198
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.493      |
| AbsLearnSignalNew       | 0.493      |
| AbsLearningOld          | 0.493      |
| AverageDiscountedReturn | 141        |
| AveragePhiLoss          | 20.082     |
| AveragePolicyStd        | 0.779755   |
| AverageReturn           | 737        |
| Entropy                 | 6.97109    |
| EnvExecTime             | 2.56       |
| ExplainedVariance       | 0.309      |
| Iteration               | 309        |
| ItrTime                 | 11.7       |
| LossAfter               | -0.668918  |
| LossBefore              | -0.597544  |
| MaxReturn               | 1.43e+03   |
| MeanKL                  | 0.00996097 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 79.2       |
| NumTrajs                | 16         |
| Perplexity              | 1065.38    |
| PolicyExecTime          | 0.56       |
| ProcessExecTime         | 0.0731     |
| StdReturn               | 360        |
| Time                    | 3.6e+03    |
| dLoss                   | 0.0713744  |
----------------------------------------
itr #310 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 310...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5501, #subsample_inputs: 5501
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.569      |
| AbsLearnSignalNew       | 0.569      |
| AbsLearningOld          | 0.569      |
| AverageDiscountedReturn | 148        |
| AveragePhiLoss          | 20.6937    |
| AveragePolicyStd        | 0.781672   |
| AverageReturn           | 940        |
| Entropy                 | 6.98741    |
| EnvExecTime             | 3.26       |
| ExplainedVariance       | -0.46      |
| Iteration               | 310        |
| ItrTime                 | 12.5       |
| LossAfter               | -0.911341  |
| LossBefore              | -0.812919  |
| MaxReturn               | 2.25e+03   |
| MeanKL                  | 0.00993624 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 39.3       |
| NumTrajs                | 14         |
| Perplexity              | 1082.92    |
| PolicyExecTime          | 0.683      |
| ProcessExecTime         | 0.0855     |
| StdReturn               | 545        |
| Time                    | 3.61e+03   |
| dLoss                   | 0.0984223  |
----------------------------------------
itr #311 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 311...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5160, #subsample_inputs: 5160
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.643      |
| AbsLearnSignalNew       | 0.643      |
| AbsLearningOld          | 0.644      |
| AverageDiscountedReturn | 115        |
| AveragePhiLoss          | 18.5032    |
| AveragePolicyStd        | 0.785081   |
| AverageReturn           | 629        |
| Entropy                 | 7.01072    |
| EnvExecTime             | 3.39       |
| ExplainedVariance       | 0.501      |
| Iteration               | 311        |
| ItrTime                 | 11.2       |
| LossAfter               | -0.552816  |
| LossBefore              | -0.502572  |
| MaxReturn               | 1.79e+03   |
| MeanKL                  | 0.00994336 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 47.2       |
| NumTrajs                | 15         |
| Perplexity              | 1108.46    |
| PolicyExecTime          | 0.689      |
| ProcessExecTime         | 0.0885     |
| StdReturn               | 447        |
| Time                    | 3.62e+03   |
| dLoss                   | 0.0502444  |
----------------------------------------
itr #312 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 312...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5156, #subsample_inputs: 5156
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.425      |
| AbsLearnSignalNew       | 0.425      |
| AbsLearningOld          | 0.425      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 20.1875    |
| AveragePolicyStd        | 0.783088   |
| AverageReturn           | 606        |
| Entropy                 | 6.99824    |
| EnvExecTime             | 3.16       |
| ExplainedVariance       | -0.0304    |
| Iteration               | 312        |
| ItrTime                 | 12.3       |
| LossAfter               | -0.398675  |
| LossBefore              | -0.352667  |
| MaxReturn               | 1.63e+03   |
| MeanKL                  | 0.00649288 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 52.8       |
| NumTrajs                | 16         |
| Perplexity              | 1094.7     |
| PolicyExecTime          | 0.662      |
| ProcessExecTime         | 0.0854     |
| StdReturn               | 414        |
| Time                    | 3.64e+03   |
| dLoss                   | 0.0460085  |
----------------------------------------
itr #313 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 313...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5213, #subsample_inputs: 5213
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.733      |
| AbsLearnSignalNew       | 0.733      |
| AbsLearningOld          | 0.733      |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 18.2003    |
| AveragePolicyStd        | 0.784247   |
| AverageReturn           | 802        |
| Entropy                 | 7.00736    |
| EnvExecTime             | 2.56       |
| ExplainedVariance       | 0.331      |
| Iteration               | 313        |
| ItrTime                 | 11.7       |
| LossAfter               | -0.0480396 |
| LossBefore              | 0.00705064 |
| MaxReturn               | 1.45e+03   |
| MeanKL                  | 0.00985257 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 43.8       |
| NumTrajs                | 14         |
| Perplexity              | 1104.74    |
| PolicyExecTime          | 0.499      |
| ProcessExecTime         | 0.066      |
| StdReturn               | 428        |
| Time                    | 3.65e+03   |
| dLoss                   | 0.0550903  |
----------------------------------------
itr #314 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 314...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5265, #subsample_inputs: 5265
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.683      |
| AbsLearnSignalNew       | 0.683      |
| AbsLearningOld          | 0.683      |
| AverageDiscountedReturn | 136        |
| AveragePhiLoss          | 17.8253    |
| AveragePolicyStd        | 0.786323   |
| AverageReturn           | 798        |
| Entropy                 | 7.01858    |
| EnvExecTime             | 2.93       |
| ExplainedVariance       | 0.459      |
| Iteration               | 314        |
| ItrTime                 | 11         |
| LossAfter               | -0.01204   |
| LossBefore              | 0.045195   |
| MaxReturn               | 2.03e+03   |
| MeanKL                  | 0.00986789 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 61.6       |
| NumTrajs                | 14         |
| Perplexity              | 1117.2     |
| PolicyExecTime          | 0.618      |
| ProcessExecTime         | 0.0858     |
| StdReturn               | 564        |
| Time                    | 3.66e+03   |
| dLoss                   | 0.057235   |
----------------------------------------
itr #315 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 315...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5166, #subsample_inputs: 5166
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.682      |
| AbsLearnSignalNew       | 0.682      |
| AbsLearningOld          | 0.682      |
| AverageDiscountedReturn | 131        |
| AveragePhiLoss          | 17.3781    |
| AveragePolicyStd        | 0.785399   |
| AverageReturn           | 713        |
| Entropy                 | 7.00911    |
| EnvExecTime             | 3.31       |
| ExplainedVariance       | 0.408      |
| Iteration               | 315        |
| ItrTime                 | 12.3       |
| LossAfter               | -0.359018  |
| LossBefore              | -0.306451  |
| MaxReturn               | 1.25e+03   |
| MeanKL                  | 0.00986967 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 52.1       |
| NumTrajs                | 15         |
| Perplexity              | 1106.67    |
| PolicyExecTime          | 0.707      |
| ProcessExecTime         | 0.0878     |
| StdReturn               | 316        |
| Time                    | 3.67e+03   |
| dLoss                   | 0.0525669  |
----------------------------------------
itr #316 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 316...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5183, #subsample_inputs: 5183
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.675      |
| AbsLearnSignalNew       | 0.675      |
| AbsLearningOld          | 0.675      |
| AverageDiscountedReturn | 129        |
| AveragePhiLoss          | 18.1965    |
| AveragePolicyStd        | 0.784022   |
| AverageReturn           | 711        |
| Entropy                 | 6.99972    |
| EnvExecTime             | 2.73       |
| ExplainedVariance       | 0.499      |
| Iteration               | 316        |
| ItrTime                 | 12         |
| LossAfter               | 0.369813   |
| LossBefore              | 0.414145   |
| MaxReturn               | 1.46e+03   |
| MeanKL                  | 0.00644208 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 119        |
| NumTrajs                | 15         |
| Perplexity              | 1096.32    |
| PolicyExecTime          | 0.523      |
| ProcessExecTime         | 0.0674     |
| StdReturn               | 392        |
| Time                    | 3.68e+03   |
| dLoss                   | 0.0443326  |
----------------------------------------
itr #317 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 317...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5373, #subsample_inputs: 5373
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.729      |
| AbsLearnSignalNew       | 0.729      |
| AbsLearningOld          | 0.729      |
| AverageDiscountedReturn | 149        |
| AveragePhiLoss          | 18.9272    |
| AveragePolicyStd        | 0.782098   |
| AverageReturn           | 1.06e+03   |
| Entropy                 | 6.98469    |
| EnvExecTime             | 3.08       |
| ExplainedVariance       | 0.35       |
| Iteration               | 317        |
| ItrTime                 | 11.2       |
| LossAfter               | -1.5317    |
| LossBefore              | -1.48549   |
| MaxReturn               | 2.73e+03   |
| MeanKL                  | 0.00643127 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 104        |
| NumTrajs                | 12         |
| Perplexity              | 1079.97    |
| PolicyExecTime          | 0.648      |
| ProcessExecTime         | 0.0854     |
| StdReturn               | 696        |
| Time                    | 3.7e+03    |
| dLoss                   | 0.0462073  |
----------------------------------------
itr #318 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 318...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 6052, #subsample_inputs: 6052
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.655      |
| AbsLearnSignalNew       | 0.655      |
| AbsLearningOld          | 0.655      |
| AverageDiscountedReturn | 131        |
| AveragePhiLoss          | 18.9615    |
| AveragePolicyStd        | 0.782242   |
| AverageReturn           | 937        |
| Entropy                 | 6.9829     |
| EnvExecTime             | 3.59       |
| ExplainedVariance       | 0.56       |
| Iteration               | 318        |
| ItrTime                 | 13.2       |
| LossAfter               | 0.360003   |
| LossBefore              | 0.407816   |
| MaxReturn               | 1.94e+03   |
| MeanKL                  | 0.00647161 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 91.1       |
| NumTrajs                | 14         |
| Perplexity              | 1078.04    |
| PolicyExecTime          | 0.769      |
| ProcessExecTime         | 0.101      |
| StdReturn               | 510        |
| Time                    | 3.71e+03   |
| dLoss                   | 0.0478121  |
----------------------------------------
itr #319 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 319...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5237, #subsample_inputs: 5237
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.685      |
| AbsLearnSignalNew       | 0.685      |
| AbsLearningOld          | 0.685      |
| AverageDiscountedReturn | 137        |
| AveragePhiLoss          | 18.5849    |
| AveragePolicyStd        | 0.780804   |
| AverageReturn           | 751        |
| Entropy                 | 6.97298    |
| EnvExecTime             | 3.07       |
| ExplainedVariance       | 0.568      |
| Iteration               | 319        |
| ItrTime                 | 12.5       |
| LossAfter               | -0.402586  |
| LossBefore              | -0.354835  |
| MaxReturn               | 1.4e+03    |
| MeanKL                  | 0.00645154 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 44.9       |
| NumTrajs                | 15         |
| Perplexity              | 1067.4     |
| PolicyExecTime          | 0.641      |
| ProcessExecTime         | 0.082      |
| StdReturn               | 370        |
| Time                    | 3.72e+03   |
| dLoss                   | 0.0477502  |
----------------------------------------
itr #320 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 320...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5168, #subsample_inputs: 5168
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.688      |
| AbsLearnSignalNew       | 0.688      |
| AbsLearningOld          | 0.688      |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 20.031     |
| AveragePolicyStd        | 0.781267   |
| AverageReturn           | 598        |
| Entropy                 | 6.97659    |
| EnvExecTime             | 2.91       |
| ExplainedVariance       | 0.532      |
| Iteration               | 320        |
| ItrTime                 | 10.9       |
| LossAfter               | 0.463941   |
| LossBefore              | 0.508611   |
| MaxReturn               | 1.94e+03   |
| MeanKL                  | 0.00642765 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 23.3       |
| NumTrajs                | 18         |
| Perplexity              | 1071.26    |
| PolicyExecTime          | 0.593      |
| ProcessExecTime         | 0.0805     |
| StdReturn               | 470        |
| Time                    | 3.73e+03   |
| dLoss                   | 0.0446698  |
----------------------------------------
itr #321 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 321...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5054, #subsample_inputs: 5054
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.742      |
| AbsLearnSignalNew       | 0.742      |
| AbsLearningOld          | 0.742      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 18.6925    |
| AveragePolicyStd        | 0.780754   |
| AverageReturn           | 682        |
| Entropy                 | 6.97141    |
| EnvExecTime             | 3.13       |
| ExplainedVariance       | 0.525      |
| Iteration               | 321        |
| ItrTime                 | 11.4       |
| LossAfter               | 0.672239   |
| LossBefore              | 0.717452   |
| MaxReturn               | 1.86e+03   |
| MeanKL                  | 0.00641539 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 40.3       |
| NumTrajs                | 15         |
| Perplexity              | 1065.73    |
| PolicyExecTime          | 0.641      |
| ProcessExecTime         | 0.0858     |
| StdReturn               | 547        |
| Time                    | 3.74e+03   |
| dLoss                   | 0.045213   |
----------------------------------------
itr #322 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 322...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5017, #subsample_inputs: 5017
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.742      |
| AbsLearnSignalNew       | 0.742      |
| AbsLearningOld          | 0.742      |
| AverageDiscountedReturn | 141        |
| AveragePhiLoss          | 18.3231    |
| AveragePolicyStd        | 0.778001   |
| AverageReturn           | 787        |
| Entropy                 | 6.94973    |
| EnvExecTime             | 3.18       |
| ExplainedVariance       | 0.41       |
| Iteration               | 322        |
| ItrTime                 | 12.3       |
| LossAfter               | 0.0258053  |
| LossBefore              | 0.0821729  |
| MaxReturn               | 1.94e+03   |
| MeanKL                  | 0.00986797 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 76.6       |
| NumTrajs                | 14         |
| Perplexity              | 1042.86    |
| PolicyExecTime          | 0.661      |
| ProcessExecTime         | 0.0811     |
| StdReturn               | 466        |
| Time                    | 3.76e+03   |
| dLoss                   | 0.0563676  |
----------------------------------------
itr #323 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 323...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5018, #subsample_inputs: 5018
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.611      |
| AbsLearnSignalNew       | 0.611      |
| AbsLearningOld          | 0.611      |
| AverageDiscountedReturn | 129        |
| AveragePhiLoss          | 18.077     |
| AveragePolicyStd        | 0.778622   |
| AverageReturn           | 707        |
| Entropy                 | 6.9549     |
| EnvExecTime             | 2.93       |
| ExplainedVariance       | 0.486      |
| Iteration               | 323        |
| ItrTime                 | 11.1       |
| LossAfter               | -0.485435  |
| LossBefore              | -0.433303  |
| MaxReturn               | 1.48e+03   |
| MeanKL                  | 0.00650791 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 87.8       |
| NumTrajs                | 15         |
| Perplexity              | 1048.28    |
| PolicyExecTime          | 0.58       |
| ProcessExecTime         | 0.0771     |
| StdReturn               | 313        |
| Time                    | 3.77e+03   |
| dLoss                   | 0.0521323  |
----------------------------------------
itr #324 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 324...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5220, #subsample_inputs: 5220
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.687      |
| AbsLearnSignalNew       | 0.687      |
| AbsLearningOld          | 0.687      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 20.1055    |
| AveragePolicyStd        | 0.775181   |
| AverageReturn           | 529        |
| Entropy                 | 6.92861    |
| EnvExecTime             | 3.31       |
| ExplainedVariance       | 0.46       |
| Iteration               | 324        |
| ItrTime                 | 11.7       |
| LossAfter               | -0.331238  |
| LossBefore              | -0.285586  |
| MaxReturn               | 1.31e+03   |
| MeanKL                  | 0.00641916 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 68.7       |
| NumTrajs                | 18         |
| Perplexity              | 1021.08    |
| PolicyExecTime          | 0.699      |
| ProcessExecTime         | 0.0864     |
| StdReturn               | 330        |
| Time                    | 3.78e+03   |
| dLoss                   | 0.0456522  |
----------------------------------------
itr #325 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 325...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5528, #subsample_inputs: 5528
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.667      |
| AbsLearnSignalNew       | 0.667      |
| AbsLearningOld          | 0.667      |
| AverageDiscountedReturn | 141        |
| AveragePhiLoss          | 19.0575    |
| AveragePolicyStd        | 0.774663   |
| AverageReturn           | 750        |
| Entropy                 | 6.92349    |
| EnvExecTime             | 2.86       |
| ExplainedVariance       | 0.412      |
| Iteration               | 325        |
| ItrTime                 | 12.6       |
| LossAfter               | 0.0396158  |
| LossBefore              | 0.103896   |
| MaxReturn               | 1.68e+03   |
| MeanKL                  | 0.00991672 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 105        |
| NumTrajs                | 16         |
| Perplexity              | 1015.85    |
| PolicyExecTime          | 0.616      |
| ProcessExecTime         | 0.0829     |
| StdReturn               | 416        |
| Time                    | 3.79e+03   |
| dLoss                   | 0.0642802  |
----------------------------------------
itr #326 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 326...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5140, #subsample_inputs: 5140
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.657      |
| AbsLearnSignalNew       | 0.657      |
| AbsLearningOld          | 0.657      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 20.2492    |
| AveragePolicyStd        | 0.771833   |
| AverageReturn           | 553        |
| Entropy                 | 6.90271    |
| EnvExecTime             | 3          |
| ExplainedVariance       | 0.52       |
| Iteration               | 326        |
| ItrTime                 | 11.4       |
| LossAfter               | -0.402364  |
| LossBefore              | -0.344095  |
| MaxReturn               | 1.11e+03   |
| MeanKL                  | 0.00998444 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 48.9       |
| NumTrajs                | 18         |
| Perplexity              | 994.967    |
| PolicyExecTime          | 0.602      |
| ProcessExecTime         | 0.0795     |
| StdReturn               | 310        |
| Time                    | 3.8e+03    |
| dLoss                   | 0.0582682  |
----------------------------------------
itr #327 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 327...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5064, #subsample_inputs: 5064
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.627      |
| AbsLearnSignalNew       | 0.627      |
| AbsLearningOld          | 0.627      |
| AverageDiscountedReturn | 135        |
| AveragePhiLoss          | 19.4134    |
| AveragePolicyStd        | 0.772204   |
| AverageReturn           | 773        |
| Entropy                 | 6.90151    |
| EnvExecTime             | 2.93       |
| ExplainedVariance       | -0.612     |
| Iteration               | 327        |
| ItrTime                 | 10.9       |
| LossAfter               | -0.681178  |
| LossBefore              | -0.625606  |
| MaxReturn               | 1.8e+03    |
| MeanKL                  | 0.00986418 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 64.7       |
| NumTrajs                | 14         |
| Perplexity              | 993.773    |
| PolicyExecTime          | 0.615      |
| ProcessExecTime         | 0.0816     |
| StdReturn               | 466        |
| Time                    | 3.81e+03   |
| dLoss                   | 0.0555723  |
----------------------------------------
itr #328 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 328...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5411, #subsample_inputs: 5411
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.716      |
| AbsLearnSignalNew       | 0.716      |
| AbsLearningOld          | 0.716      |
| AverageDiscountedReturn | 150        |
| AveragePhiLoss          | 19.2796    |
| AveragePolicyStd        | 0.771719   |
| AverageReturn           | 897        |
| Entropy                 | 6.89611    |
| EnvExecTime             | 2.74       |
| ExplainedVariance       | 0.577      |
| Iteration               | 328        |
| ItrTime                 | 12.5       |
| LossAfter               | -0.0584076 |
| LossBefore              | -0.0124152 |
| MaxReturn               | 1.46e+03   |
| MeanKL                  | 0.00646983 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 425        |
| NumTrajs                | 14         |
| Perplexity              | 988.418    |
| PolicyExecTime          | 0.609      |
| ProcessExecTime         | 0.079      |
| StdReturn               | 365        |
| Time                    | 3.83e+03   |
| dLoss                   | 0.0459924  |
----------------------------------------
itr #329 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 329...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5328, #subsample_inputs: 5328
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.61       |
| AbsLearnSignalNew       | 0.61       |
| AbsLearningOld          | 0.61       |
| AverageDiscountedReturn | 137        |
| AveragePhiLoss          | 18.5974    |
| AveragePolicyStd        | 0.769825   |
| AverageReturn           | 776        |
| Entropy                 | 6.87976    |
| EnvExecTime             | 2.81       |
| ExplainedVariance       | 0.511      |
| Iteration               | 329        |
| ItrTime                 | 11.3       |
| LossAfter               | 0.196465   |
| LossBefore              | 0.246269   |
| MaxReturn               | 1.61e+03   |
| MeanKL                  | 0.00998937 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 65.7       |
| NumTrajs                | 15         |
| Perplexity              | 972.393    |
| PolicyExecTime          | 0.591      |
| ProcessExecTime         | 0.0746     |
| StdReturn               | 480        |
| Time                    | 3.84e+03   |
| dLoss                   | 0.0498035  |
----------------------------------------
itr #330 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 330...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5059, #subsample_inputs: 5059
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.682      |
| AbsLearnSignalNew       | 0.682      |
| AbsLearningOld          | 0.682      |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 20.8563    |
| AveragePolicyStd        | 0.767884   |
| AverageReturn           | 623        |
| Entropy                 | 6.86517    |
| EnvExecTime             | 2.82       |
| ExplainedVariance       | 0.509      |
| Iteration               | 330        |
| ItrTime                 | 10.9       |
| LossAfter               | -0.990417  |
| LossBefore              | -0.941703  |
| MaxReturn               | 1.33e+03   |
| MeanKL                  | 0.00646829 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 38.6       |
| NumTrajs                | 17         |
| Perplexity              | 958.311    |
| PolicyExecTime          | 0.592      |
| ProcessExecTime         | 0.0791     |
| StdReturn               | 341        |
| Time                    | 3.85e+03   |
| dLoss                   | 0.0487135  |
----------------------------------------
itr #331 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 331...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5233, #subsample_inputs: 5233
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.686      |
| AbsLearnSignalNew       | 0.686      |
| AbsLearningOld          | 0.686      |
| AverageDiscountedReturn | 140        |
| AveragePhiLoss          | 20.4889    |
| AveragePolicyStd        | 0.768208   |
| AverageReturn           | 595        |
| Entropy                 | 6.86554    |
| EnvExecTime             | 2.67       |
| ExplainedVariance       | 0.185      |
| Iteration               | 331        |
| ItrTime                 | 12         |
| LossAfter               | 0.132379   |
| LossBefore              | 0.189597   |
| MaxReturn               | 951        |
| MeanKL                  | 0.00999633 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 319        |
| NumTrajs                | 18         |
| Perplexity              | 958.667    |
| PolicyExecTime          | 0.562      |
| ProcessExecTime         | 0.0717     |
| StdReturn               | 178        |
| Time                    | 3.86e+03   |
| dLoss                   | 0.057218   |
----------------------------------------
itr #332 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 332...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5105, #subsample_inputs: 5105
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.672      |
| AbsLearnSignalNew       | 0.672      |
| AbsLearningOld          | 0.672      |
| AverageDiscountedReturn | 146        |
| AveragePhiLoss          | 18.5578    |
| AveragePolicyStd        | 0.765623   |
| AverageReturn           | 862        |
| Entropy                 | 6.84773    |
| EnvExecTime             | 2.94       |
| ExplainedVariance       | 0.369      |
| Iteration               | 332        |
| ItrTime                 | 10.9       |
| LossAfter               | 0.448567   |
| LossBefore              | 0.505779   |
| MaxReturn               | 1.31e+03   |
| MeanKL                  | 0.00988483 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 128        |
| NumTrajs                | 14         |
| Perplexity              | 941.743    |
| PolicyExecTime          | 0.62       |
| ProcessExecTime         | 0.0785     |
| StdReturn               | 283        |
| Time                    | 3.87e+03   |
| dLoss                   | 0.057212   |
----------------------------------------
itr #333 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 333...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5211, #subsample_inputs: 5211
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.678      |
| AbsLearnSignalNew       | 0.678      |
| AbsLearningOld          | 0.678      |
| AverageDiscountedReturn | 140        |
| AveragePhiLoss          | 19.5199    |
| AveragePolicyStd        | 0.764896   |
| AverageReturn           | 696        |
| Entropy                 | 6.84361    |
| EnvExecTime             | 3.22       |
| ExplainedVariance       | 0.5        |
| Iteration               | 333        |
| ItrTime                 | 11.9       |
| LossAfter               | -0.76371   |
| LossBefore              | -0.715419  |
| MaxReturn               | 1.07e+03   |
| MeanKL                  | 0.00641152 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 40.1       |
| NumTrajs                | 17         |
| Perplexity              | 937.871    |
| PolicyExecTime          | 0.693      |
| ProcessExecTime         | 0.0919     |
| StdReturn               | 270        |
| Time                    | 3.88e+03   |
| dLoss                   | 0.0482908  |
----------------------------------------
itr #334 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 334...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5270, #subsample_inputs: 5270
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.523      |
| AbsLearnSignalNew       | 0.523      |
| AbsLearningOld          | 0.523      |
| AverageDiscountedReturn | 143        |
| AveragePhiLoss          | 22.3065    |
| AveragePolicyStd        | 0.764903   |
| AverageReturn           | 886        |
| Entropy                 | 6.84417    |
| EnvExecTime             | 3.28       |
| ExplainedVariance       | -0.614     |
| Iteration               | 334        |
| ItrTime                 | 12.8       |
| LossAfter               | 0.00420054 |
| LossBefore              | 0.103504   |
| MaxReturn               | 2.07e+03   |
| MeanKL                  | 0.00991526 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 367        |
| NumTrajs                | 14         |
| Perplexity              | 938.396    |
| PolicyExecTime          | 0.684      |
| ProcessExecTime         | 0.0859     |
| StdReturn               | 460        |
| Time                    | 3.9e+03    |
| dLoss                   | 0.099303   |
----------------------------------------
itr #335 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 335...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5023, #subsample_inputs: 5023
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.737      |
| AbsLearnSignalNew       | 0.737      |
| AbsLearningOld          | 0.737      |
| AverageDiscountedReturn | 144        |
| AveragePhiLoss          | 19.6156    |
| AveragePolicyStd        | 0.767111   |
| AverageReturn           | 772        |
| Entropy                 | 6.86288    |
| EnvExecTime             | 2.63       |
| ExplainedVariance       | 0.581      |
| Iteration               | 335        |
| ItrTime                 | 10.9       |
| LossAfter               | 0.201618   |
| LossBefore              | 0.243544   |
| MaxReturn               | 1.64e+03   |
| MeanKL                  | 0.00641092 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 307        |
| NumTrajs                | 15         |
| Perplexity              | 956.117    |
| PolicyExecTime          | 0.55       |
| ProcessExecTime         | 0.0717     |
| StdReturn               | 423        |
| Time                    | 3.91e+03   |
| dLoss                   | 0.0419261  |
----------------------------------------
itr #336 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 336...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5253, #subsample_inputs: 5253
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.577      |
| AbsLearnSignalNew       | 0.577      |
| AbsLearningOld          | 0.577      |
| AverageDiscountedReturn | 147        |
| AveragePhiLoss          | 19.6526    |
| AveragePolicyStd        | 0.767307   |
| AverageReturn           | 872        |
| Entropy                 | 6.86114    |
| EnvExecTime             | 3.39       |
| ExplainedVariance       | 0.422      |
| Iteration               | 336        |
| ItrTime                 | 11.5       |
| LossAfter               | -0.204305  |
| LossBefore              | -0.157574  |
| MaxReturn               | 1.55e+03   |
| MeanKL                  | 0.00642201 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 98.5       |
| NumTrajs                | 14         |
| Perplexity              | 954.451    |
| PolicyExecTime          | 0.734      |
| ProcessExecTime         | 0.09       |
| StdReturn               | 380        |
| Time                    | 3.92e+03   |
| dLoss                   | 0.046732   |
----------------------------------------
itr #337 | 
Mem: 758.515625
Obtaining samples...
Obtaining samples for iteration 337...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5147, #subsample_inputs: 5147
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.623     |
| AbsLearnSignalNew       | 0.623     |
| AbsLearningOld          | 0.623     |
| AverageDiscountedReturn | 132       |
| AveragePhiLoss          | 19.2406   |
| AveragePolicyStd        | 0.765895  |
| AverageReturn           | 700       |
| Entropy                 | 6.85119   |
| EnvExecTime             | 3.23      |
| ExplainedVariance       | 0.467     |
| Iteration               | 337       |
| ItrTime                 | 12.5      |
| LossAfter               | -0.454618 |
| LossBefore              | -0.399365 |
| MaxReturn               | 1.97e+03  |
| MeanKL                  | 0.0099948 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 68.1      |
| NumTrajs                | 15        |
| Perplexity              | 945.003   |
| PolicyExecTime          | 0.709     |
| ProcessExecTime         | 0.0865    |
| StdReturn               | 487       |
| Time                    | 3.93e+03  |
| dLoss                   | 0.0552539 |
---------------------------------------
itr #338 | 
Mem: 759.085938
Obtaining samples...
Obtaining samples for iteration 338...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5195, #subsample_inputs: 5195
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.713      |
| AbsLearnSignalNew       | 0.713      |
| AbsLearningOld          | 0.713      |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 20.3116    |
| AveragePolicyStd        | 0.763122   |
| AverageReturn           | 939        |
| Entropy                 | 6.83065    |
| EnvExecTime             | 2.78       |
| ExplainedVariance       | 0.577      |
| Iteration               | 338        |
| ItrTime                 | 11.4       |
| LossAfter               | -0.164789  |
| LossBefore              | -0.102444  |
| MaxReturn               | 2.12e+03   |
| MeanKL                  | 0.00999505 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 76.1       |
| NumTrajs                | 12         |
| Perplexity              | 925.796    |
| PolicyExecTime          | 0.566      |
| ProcessExecTime         | 0.0702     |
| StdReturn               | 608        |
| Time                    | 3.94e+03   |
| dLoss                   | 0.0623452  |
----------------------------------------
itr #339 | 
Mem: 759.382812
Obtaining samples...
Obtaining samples for iteration 339...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5162, #subsample_inputs: 5162
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.605      |
| AbsLearnSignalNew       | 0.605      |
| AbsLearningOld          | 0.605      |
| AverageDiscountedReturn | 112        |
| AveragePhiLoss          | 21.0615    |
| AveragePolicyStd        | 0.760737   |
| AverageReturn           | 504        |
| Entropy                 | 6.81181    |
| EnvExecTime             | 3.44       |
| ExplainedVariance       | 0.371      |
| Iteration               | 339        |
| ItrTime                 | 11.7       |
| LossAfter               | 0.644285   |
| LossBefore              | 0.701589   |
| MaxReturn               | 1.38e+03   |
| MeanKL                  | 0.00650484 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 49.6       |
| NumTrajs                | 18         |
| Perplexity              | 908.512    |
| PolicyExecTime          | 0.725      |
| ProcessExecTime         | 0.0911     |
| StdReturn               | 367        |
| Time                    | 3.96e+03   |
| dLoss                   | 0.0573039  |
----------------------------------------
itr #340 | 
Mem: 759.382812
Obtaining samples...
Obtaining samples for iteration 340...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5205, #subsample_inputs: 5205
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.704      |
| AbsLearnSignalNew       | 0.704      |
| AbsLearningOld          | 0.704      |
| AverageDiscountedReturn | 139        |
| AveragePhiLoss          | 21.2567    |
| AveragePolicyStd        | 0.758422   |
| AverageReturn           | 720        |
| Entropy                 | 6.79591    |
| EnvExecTime             | 2.96       |
| ExplainedVariance       | 0.214      |
| Iteration               | 340        |
| ItrTime                 | 12.3       |
| LossAfter               | 0.226103   |
| LossBefore              | 0.28891    |
| MaxReturn               | 1.85e+03   |
| MeanKL                  | 0.00994618 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 50.3       |
| NumTrajs                | 16         |
| Perplexity              | 894.179    |
| PolicyExecTime          | 0.622      |
| ProcessExecTime         | 0.0802     |
| StdReturn               | 387        |
| Time                    | 3.97e+03   |
| dLoss                   | 0.062807   |
----------------------------------------
itr #341 | 
Mem: 759.382812
Obtaining samples...
Obtaining samples for iteration 341...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5191, #subsample_inputs: 5191
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.699      |
| AbsLearnSignalNew       | 0.699      |
| AbsLearningOld          | 0.7        |
| AverageDiscountedReturn | 148        |
| AveragePhiLoss          | 20.8873    |
| AveragePolicyStd        | 0.759847   |
| AverageReturn           | 789        |
| Entropy                 | 6.80722    |
| EnvExecTime             | 2.93       |
| ExplainedVariance       | 0.487      |
| Iteration               | 341        |
| ItrTime                 | 11.7       |
| LossAfter               | 0.0950581  |
| LossBefore              | 0.147713   |
| MaxReturn               | 1.47e+03   |
| MeanKL                  | 0.00988335 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 91.5       |
| NumTrajs                | 15         |
| Perplexity              | 904.357    |
| PolicyExecTime          | 0.59       |
| ProcessExecTime         | 0.074      |
| StdReturn               | 321        |
| Time                    | 3.98e+03   |
| dLoss                   | 0.0526548  |
----------------------------------------
itr #342 | 
Mem: 759.382812
Obtaining samples...
Obtaining samples for iteration 342...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5103, #subsample_inputs: 5103
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.644      |
| AbsLearnSignalNew       | 0.644      |
| AbsLearningOld          | 0.644      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 21.496     |
| AveragePolicyStd        | 0.758044   |
| AverageReturn           | 669        |
| Entropy                 | 6.79519    |
| EnvExecTime             | 3.23       |
| ExplainedVariance       | 0.541      |
| Iteration               | 342        |
| ItrTime                 | 11         |
| LossAfter               | 0.0423087  |
| LossBefore              | 0.100378   |
| MaxReturn               | 1.59e+03   |
| MeanKL                  | 0.00994786 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 42.2       |
| NumTrajs                | 16         |
| Perplexity              | 893.543    |
| PolicyExecTime          | 0.682      |
| ProcessExecTime         | 0.0875     |
| StdReturn               | 454        |
| Time                    | 3.99e+03   |
| dLoss                   | 0.0580697  |
----------------------------------------
itr #343 | 
Mem: 759.382812
Obtaining samples...
Obtaining samples for iteration 343...
