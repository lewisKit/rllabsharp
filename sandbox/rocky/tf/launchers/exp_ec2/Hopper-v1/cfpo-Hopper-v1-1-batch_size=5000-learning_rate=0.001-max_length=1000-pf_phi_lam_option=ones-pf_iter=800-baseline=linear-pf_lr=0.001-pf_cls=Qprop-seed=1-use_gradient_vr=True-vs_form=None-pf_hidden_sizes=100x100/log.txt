output_formats ['stdout', 'log', 'json', 'tensorboard']
Logging to exp_ec2/cfpo-Hopper-v1-1-batch_size=5000-learning_rate=0.001-max_length=1000-pf_phi_lam_option=ones-pf_iter=800-baseline=linear-pf_lr=0.001-pf_cls=Qprop-seed=1-use_gradient_vr=True-vs_form=None-pf_hidden_sizes=100x100
Setting seed to 1
Setting seed to 2
Setting seed to 3
Setting seed to 4
observation space: Box(11,)
action space: Box(3,)
use_gradient_vr is True
pf_learning_rate is 0.001
observation space: Box(11,)
action space: Box(3,)
observation space: Box(11,)
action space: Box(3,)
observation space: Box(11,)
action space: Box(3,)
observation space: Box(11,)
action space: Box(3,)
observation space: Box(11,)
action space: Box(3,)
qf is None
using gradient as variance reduction
parameter of phi Phinet/obs_h0/W:0, shape=(11, 100)
parameter of phi Phinet/obs_h0/b:0, shape=(100,)
parameter of phi Phinet/act_h0/W:0, shape=(3, 100)
parameter of phi Phinet/act_h0/b:0, shape=(100,)
parameter of phi Phinet/h1/W:0, shape=(100, 100)
parameter of phi Phinet/h1/b:0, shape=(100,)
parameter of phi Phinet/output/W:0, shape=(100, 1)
parameter of phi Phinet/output/b:0, shape=(1,)
No checkpoint exp_ec2/cfpo-Hopper-v1-1-batch_size=5000-learning_rate=0.001-max_length=1000-pf_phi_lam_option=ones-pf_iter=800-baseline=linear-pf_lr=0.001-pf_cls=Qprop-seed=1-use_gradient_vr=True-vs_form=None-pf_hidden_sizes=100x100/params.chk
itr #0 | 
Mem: 268.812500
Obtaining samples...
Obtaining samples for iteration 0...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5052, #subsample_inputs: 5052
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.852      |
| AbsLearnSignalNew       | 0.852      |
| AbsLearningOld          | 0.852      |
| AverageDiscountedReturn | 12         |
| AveragePhiLoss          | 3.96342    |
| AveragePolicyStd        | 1.0        |
| AverageReturn           | 13.5       |
| Entropy                 | 4.25682    |
| EnvExecTime             | 1.77       |
| ExplainedVariance       | 4.06e-11   |
| Iteration               | 0          |
| ItrTime                 | 12.8       |
| LossAfter               | -0.513677  |
| LossBefore              | -0.46237   |
| MaxReturn               | 72.8       |
| MeanKL                  | 0.00956395 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.79       |
| NumTrajs                | 351        |
| Perplexity              | 70.5849    |
| PolicyExecTime          | 0.419      |
| ProcessExecTime         | 0.063      |
| StdReturn               | 18.5       |
| Time                    | 12.8       |
| dLoss                   | 0.0513072  |
----------------------------------------
itr #1 | 
Mem: 594.570312
Obtaining samples...
Obtaining samples for iteration 1...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5019, #subsample_inputs: 5019
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.746      |
| AbsLearnSignalNew       | 0.746      |
| AbsLearningOld          | 0.746      |
| AverageDiscountedReturn | 19         |
| AveragePhiLoss          | 3.53192    |
| AveragePolicyStd        | 1.00125    |
| AverageReturn           | 21.9       |
| Entropy                 | 4.26051    |
| EnvExecTime             | 1.78       |
| ExplainedVariance       | 0.56       |
| Iteration               | 1          |
| ItrTime                 | 12.5       |
| LossAfter               | -0.652071  |
| LossBefore              | -0.571968  |
| MaxReturn               | 75.9       |
| MeanKL                  | 0.00996807 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.94       |
| NumTrajs                | 273        |
| Perplexity              | 70.8462    |
| PolicyExecTime          | 0.421      |
| ProcessExecTime         | 0.062      |
| StdReturn               | 23         |
| Time                    | 25.4       |
| dLoss                   | 0.0801035  |
----------------------------------------
itr #2 | 
Mem: 612.207031
Obtaining samples...
Obtaining samples for iteration 2...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5028, #subsample_inputs: 5028
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.765      |
| AbsLearnSignalNew       | 0.765      |
| AbsLearningOld          | 0.765      |
| AverageDiscountedReturn | 29.8       |
| AveragePhiLoss          | 3.82714    |
| AveragePolicyStd        | 0.999254   |
| AverageReturn           | 34.9       |
| Entropy                 | 4.25449    |
| EnvExecTime             | 1.81       |
| ExplainedVariance       | 0.515      |
| Iteration               | 2          |
| ItrTime                 | 12.5       |
| LossAfter               | 0.0706078  |
| LossBefore              | 0.145943   |
| MaxReturn               | 119        |
| MeanKL                  | 0.00988878 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 2.21       |
| NumTrajs                | 209        |
| Perplexity              | 70.4206    |
| PolicyExecTime          | 0.429      |
| ProcessExecTime         | 0.0614     |
| StdReturn               | 24.5       |
| Time                    | 38         |
| dLoss                   | 0.075335   |
----------------------------------------
itr #3 | 
Mem: 617.113281
Obtaining samples...
Obtaining samples for iteration 3...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5003, #subsample_inputs: 5003
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.745     |
| AbsLearnSignalNew       | 0.745     |
| AbsLearningOld          | 0.744     |
| AverageDiscountedReturn | 38.1      |
| AveragePhiLoss          | 3.87096   |
| AveragePolicyStd        | 0.999161  |
| AverageReturn           | 45.1      |
| Entropy                 | 4.25416   |
| EnvExecTime             | 1.7       |
| ExplainedVariance       | 0.595     |
| Iteration               | 3         |
| ItrTime                 | 12.4      |
| LossAfter               | 0.620601  |
| LossBefore              | 0.667251  |
| MaxReturn               | 133       |
| MeanKL                  | 0.0064312 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 2.57      |
| NumTrajs                | 174       |
| Perplexity              | 70.3975   |
| PolicyExecTime          | 0.414     |
| ProcessExecTime         | 0.0573    |
| StdReturn               | 22.3      |
| Time                    | 50.5      |
| dLoss                   | 0.0466505 |
---------------------------------------
itr #4 | 
Mem: 618.917969
Obtaining samples...
Obtaining samples for iteration 4...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5002, #subsample_inputs: 5002
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.724      |
| AbsLearnSignalNew       | 0.724      |
| AbsLearningOld          | 0.724      |
| AverageDiscountedReturn | 44.2       |
| AveragePhiLoss          | 4.18553    |
| AveragePolicyStd        | 0.99738    |
| AverageReturn           | 52.4       |
| Entropy                 | 4.24881    |
| EnvExecTime             | 1.8        |
| ExplainedVariance       | 0.717      |
| Iteration               | 4          |
| ItrTime                 | 12.5       |
| LossAfter               | 0.583827   |
| LossBefore              | 0.624411   |
| MaxReturn               | 109        |
| MeanKL                  | 0.00681188 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 3.41       |
| NumTrajs                | 156        |
| Perplexity              | 70.0223    |
| PolicyExecTime          | 0.428      |
| ProcessExecTime         | 0.06       |
| StdReturn               | 15.3       |
| Time                    | 63.1       |
| dLoss                   | 0.0405839  |
----------------------------------------
itr #5 | 
Mem: 618.917969
Obtaining samples...
Obtaining samples for iteration 5...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5003, #subsample_inputs: 5003
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.681      |
| AbsLearnSignalNew       | 0.681      |
| AbsLearningOld          | 0.681      |
| AverageDiscountedReturn | 47.2       |
| AveragePhiLoss          | 4.00544    |
| AveragePolicyStd        | 0.992094   |
| AverageReturn           | 56.5       |
| Entropy                 | 4.23284    |
| EnvExecTime             | 1.71       |
| ExplainedVariance       | 0.646      |
| Iteration               | 5          |
| ItrTime                 | 12.4       |
| LossAfter               | 0.0686772  |
| LossBefore              | 0.10913    |
| MaxReturn               | 126        |
| MeanKL                  | 0.00652568 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 4          |
| NumTrajs                | 147        |
| Perplexity              | 68.9129    |
| PolicyExecTime          | 0.416      |
| ProcessExecTime         | 0.0571     |
| StdReturn               | 16.5       |
| Time                    | 75.6       |
| dLoss                   | 0.040453   |
----------------------------------------
itr #6 | 
Mem: 622.265625
Obtaining samples...
Obtaining samples for iteration 6...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5002, #subsample_inputs: 5002
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.731      |
| AbsLearnSignalNew       | 0.731      |
| AbsLearningOld          | 0.731      |
| AverageDiscountedReturn | 53         |
| AveragePhiLoss          | 4.01135    |
| AveragePolicyStd        | 0.991827   |
| AverageReturn           | 65.2       |
| Entropy                 | 4.23202    |
| EnvExecTime             | 1.67       |
| ExplainedVariance       | 0.472      |
| Iteration               | 6          |
| ItrTime                 | 12.4       |
| LossAfter               | 0.738363   |
| LossBefore              | 0.781475   |
| MaxReturn               | 185        |
| MeanKL                  | 0.00663719 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 6.24       |
| NumTrajs                | 130        |
| Perplexity              | 68.856     |
| PolicyExecTime          | 0.412      |
| ProcessExecTime         | 0.0558     |
| StdReturn               | 22.2       |
| Time                    | 88.1       |
| dLoss                   | 0.0431119  |
----------------------------------------
itr #7 | 
Mem: 629.984375
Obtaining samples...
Obtaining samples for iteration 7...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5018, #subsample_inputs: 5018
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.785      |
| AbsLearnSignalNew       | 0.785      |
| AbsLearningOld          | 0.785      |
| AverageDiscountedReturn | 57.4       |
| AveragePhiLoss          | 3.90509    |
| AveragePolicyStd        | 0.988371   |
| AverageReturn           | 72.4       |
| Entropy                 | 4.22153    |
| EnvExecTime             | 1.66       |
| ExplainedVariance       | 0.389      |
| Iteration               | 7          |
| ItrTime                 | 12.4       |
| LossAfter               | 0.854924   |
| LossBefore              | 0.891099   |
| MaxReturn               | 181        |
| MeanKL                  | 0.00655749 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 42.8       |
| NumTrajs                | 120        |
| Perplexity              | 68.1376    |
| PolicyExecTime          | 0.416      |
| ProcessExecTime         | 0.0549     |
| StdReturn               | 29.4       |
| Time                    | 101        |
| dLoss                   | 0.0361746  |
----------------------------------------
itr #8 | 
Mem: 629.984375
Obtaining samples...
Obtaining samples for iteration 8...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5047, #subsample_inputs: 5047
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.844      |
| AbsLearnSignalNew       | 0.844      |
| AbsLearningOld          | 0.844      |
| AverageDiscountedReturn | 69.8       |
| AveragePhiLoss          | 4.15136    |
| AveragePolicyStd        | 0.984845   |
| AverageReturn           | 93         |
| Entropy                 | 4.21086    |
| EnvExecTime             | 1.72       |
| ExplainedVariance       | 0.361      |
| Iteration               | 8          |
| ItrTime                 | 12.5       |
| LossAfter               | -0.320185  |
| LossBefore              | -0.283385  |
| MaxReturn               | 181        |
| MeanKL                  | 0.00644379 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 41.8       |
| NumTrajs                | 98         |
| Perplexity              | 67.4144    |
| PolicyExecTime          | 0.425      |
| ProcessExecTime         | 0.0564     |
| StdReturn               | 37.1       |
| Time                    | 113        |
| dLoss                   | 0.0367995  |
----------------------------------------
itr #9 | 
Mem: 634.109375
Obtaining samples...
Obtaining samples for iteration 9...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5021, #subsample_inputs: 5021
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.834      |
| AbsLearnSignalNew       | 0.834      |
| AbsLearningOld          | 0.834      |
| AverageDiscountedReturn | 74.9       |
| AveragePhiLoss          | 4.3067     |
| AveragePolicyStd        | 0.983093   |
| AverageReturn           | 102        |
| Entropy                 | 4.20556    |
| EnvExecTime             | 1.74       |
| ExplainedVariance       | 0.395      |
| Iteration               | 9          |
| ItrTime                 | 12.5       |
| LossAfter               | -0.665144  |
| LossBefore              | -0.626674  |
| MaxReturn               | 187        |
| MeanKL                  | 0.00996066 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 42.6       |
| NumTrajs                | 90         |
| Perplexity              | 67.0585    |
| PolicyExecTime          | 0.434      |
| ProcessExecTime         | 0.0571     |
| StdReturn               | 40.5       |
| Time                    | 126        |
| dLoss                   | 0.0384705  |
----------------------------------------
itr #10 | 
Mem: 635.906250
Obtaining samples...
Obtaining samples for iteration 10...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5016, #subsample_inputs: 5016
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.815      |
| AbsLearnSignalNew       | 0.815      |
| AbsLearningOld          | 0.815      |
| AverageDiscountedReturn | 88.1       |
| AveragePhiLoss          | 4.39496    |
| AveragePolicyStd        | 0.977196   |
| AverageReturn           | 127        |
| Entropy                 | 4.18754    |
| EnvExecTime             | 1.66       |
| ExplainedVariance       | 0.483      |
| Iteration               | 10         |
| ItrTime                 | 12.4       |
| LossAfter               | -0.0365607 |
| LossBefore              | 0.00334896 |
| MaxReturn               | 188        |
| MeanKL                  | 0.00978351 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 46         |
| NumTrajs                | 75         |
| Perplexity              | 65.8607    |
| PolicyExecTime          | 0.417      |
| ProcessExecTime         | 0.0535     |
| StdReturn               | 43.1       |
| Time                    | 138        |
| dLoss                   | 0.0399097  |
----------------------------------------
itr #11 | 
Mem: 637.968750
Obtaining samples...
Obtaining samples for iteration 11...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5049, #subsample_inputs: 5049
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.712      |
| AbsLearnSignalNew       | 0.712      |
| AbsLearningOld          | 0.712      |
| AverageDiscountedReturn | 101        |
| AveragePhiLoss          | 5.05683    |
| AveragePolicyStd        | 0.970126   |
| AverageReturn           | 151        |
| Entropy                 | 4.16572    |
| EnvExecTime             | 1.86       |
| ExplainedVariance       | 0.728      |
| Iteration               | 11         |
| ItrTime                 | 12.6       |
| LossAfter               | 0.459542   |
| LossBefore              | 0.48952    |
| MaxReturn               | 182        |
| MeanKL                  | 0.00694317 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 56         |
| NumTrajs                | 65         |
| Perplexity              | 64.4392    |
| PolicyExecTime          | 0.45       |
| ProcessExecTime         | 0.0593     |
| StdReturn               | 29.9       |
| Time                    | 151        |
| dLoss                   | 0.0299777  |
----------------------------------------
itr #12 | 
Mem: 642.859375
Obtaining samples...
Obtaining samples for iteration 12...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5075, #subsample_inputs: 5075
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.65       |
| AbsLearnSignalNew       | 0.65       |
| AbsLearningOld          | 0.65       |
| AverageDiscountedReturn | 99.3       |
| AveragePhiLoss          | 5.02243    |
| AveragePolicyStd        | 0.964394   |
| AverageReturn           | 147        |
| Entropy                 | 4.14779    |
| EnvExecTime             | 1.76       |
| ExplainedVariance       | 0.721      |
| Iteration               | 12         |
| ItrTime                 | 12.5       |
| LossAfter               | -0.0947012 |
| LossBefore              | -0.0658787 |
| MaxReturn               | 177        |
| MeanKL                  | 0.00660806 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 41.9       |
| NumTrajs                | 66         |
| Perplexity              | 63.2942    |
| PolicyExecTime          | 0.432      |
| ProcessExecTime         | 0.0558     |
| StdReturn               | 29.6       |
| Time                    | 164        |
| dLoss                   | 0.0288224  |
----------------------------------------
itr #13 | 
Mem: 643.117188
Obtaining samples...
Obtaining samples for iteration 13...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5003, #subsample_inputs: 5003
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.647      |
| AbsLearnSignalNew       | 0.647      |
| AbsLearningOld          | 0.647      |
| AverageDiscountedReturn | 104        |
| AveragePhiLoss          | 5.21295    |
| AveragePolicyStd        | 0.959      |
| AverageReturn           | 157        |
| Entropy                 | 4.13118    |
| EnvExecTime             | 1.68       |
| ExplainedVariance       | 0.848      |
| Iteration               | 13         |
| ItrTime                 | 12.4       |
| LossAfter               | 1.64946    |
| LossBefore              | 1.67779    |
| MaxReturn               | 189        |
| MeanKL                  | 0.00669404 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 42.5       |
| NumTrajs                | 62         |
| Perplexity              | 62.2514    |
| PolicyExecTime          | 0.419      |
| ProcessExecTime         | 0.0528     |
| StdReturn               | 23.1       |
| Time                    | 176        |
| dLoss                   | 0.0283388  |
----------------------------------------
itr #14 | 
Mem: 644.921875
Obtaining samples...
Obtaining samples for iteration 14...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5038, #subsample_inputs: 5038
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.548      |
| AbsLearnSignalNew       | 0.548      |
| AbsLearningOld          | 0.548      |
| AverageDiscountedReturn | 103        |
| AveragePhiLoss          | 5.85699    |
| AveragePolicyStd        | 0.952893   |
| AverageReturn           | 156        |
| Entropy                 | 4.11188    |
| EnvExecTime             | 1.75       |
| ExplainedVariance       | 0.805      |
| Iteration               | 14         |
| ItrTime                 | 12.5       |
| LossAfter               | 0.682759   |
| LossBefore              | 0.715187   |
| MaxReturn               | 184        |
| MeanKL                  | 0.00664789 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 49.7       |
| NumTrajs                | 63         |
| Perplexity              | 61.0616    |
| PolicyExecTime          | 0.431      |
| ProcessExecTime         | 0.055      |
| StdReturn               | 26.7       |
| Time                    | 189        |
| dLoss                   | 0.0324276  |
----------------------------------------
itr #15 | 
Mem: 644.921875
Obtaining samples...
Obtaining samples for iteration 15...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5034, #subsample_inputs: 5034
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.639      |
| AbsLearnSignalNew       | 0.639      |
| AbsLearningOld          | 0.64       |
| AverageDiscountedReturn | 108        |
| AveragePhiLoss          | 4.75291    |
| AveragePolicyStd        | 0.946197   |
| AverageReturn           | 165        |
| Entropy                 | 4.0908     |
| EnvExecTime             | 1.84       |
| ExplainedVariance       | 0.91       |
| Iteration               | 15         |
| ItrTime                 | 12.6       |
| LossAfter               | 1.09595    |
| LossBefore              | 1.11771    |
| MaxReturn               | 184        |
| MeanKL                  | 0.00654903 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 86.4       |
| NumTrajs                | 60         |
| Perplexity              | 59.7878    |
| PolicyExecTime          | 0.444      |
| ProcessExecTime         | 0.058      |
| StdReturn               | 15.7       |
| Time                    | 201        |
| dLoss                   | 0.0217645  |
----------------------------------------
itr #16 | 
Mem: 645.179688
Obtaining samples...
Obtaining samples for iteration 16...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5006, #subsample_inputs: 5006
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.583      |
| AbsLearnSignalNew       | 0.583      |
| AbsLearningOld          | 0.583      |
| AverageDiscountedReturn | 108        |
| AveragePhiLoss          | 5.4592     |
| AveragePolicyStd        | 0.934826   |
| AverageReturn           | 165        |
| Entropy                 | 4.0545     |
| EnvExecTime             | 1.69       |
| ExplainedVariance       | 0.927      |
| Iteration               | 16         |
| ItrTime                 | 12.4       |
| LossAfter               | 0.399358   |
| LossBefore              | 0.424142   |
| MaxReturn               | 187        |
| MeanKL                  | 0.00966582 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 105        |
| NumTrajs                | 60         |
| Perplexity              | 57.6564    |
| PolicyExecTime          | 0.419      |
| ProcessExecTime         | 0.0529     |
| StdReturn               | 16.2       |
| Time                    | 214        |
| dLoss                   | 0.0247844  |
----------------------------------------
itr #17 | 
Mem: 645.179688
Obtaining samples...
Obtaining samples for iteration 17...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5018, #subsample_inputs: 5018
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.497      |
| AbsLearnSignalNew       | 0.497      |
| AbsLearningOld          | 0.497      |
| AverageDiscountedReturn | 110        |
| AveragePhiLoss          | 6.06589    |
| AveragePolicyStd        | 0.928369   |
| AverageReturn           | 169        |
| Entropy                 | 4.0331     |
| EnvExecTime             | 1.66       |
| ExplainedVariance       | 0.925      |
| Iteration               | 17         |
| ItrTime                 | 12.4       |
| LossAfter               | 0.731744   |
| LossBefore              | 0.767729   |
| MaxReturn               | 195        |
| MeanKL                  | 0.00985593 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 43.3       |
| NumTrajs                | 59         |
| Perplexity              | 56.4356    |
| PolicyExecTime          | 0.417      |
| ProcessExecTime         | 0.0527     |
| StdReturn               | 20.4       |
| Time                    | 226        |
| dLoss                   | 0.0359848  |
----------------------------------------
itr #18 | 
Mem: 646.210938
Obtaining samples...
Obtaining samples for iteration 18...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5036, #subsample_inputs: 5036
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.75       |
| AbsLearnSignalNew       | 0.75       |
| AbsLearningOld          | 0.749      |
| AverageDiscountedReturn | 112        |
| AveragePhiLoss          | 5.22032    |
| AveragePolicyStd        | 0.925909   |
| AverageReturn           | 173        |
| Entropy                 | 4.02516    |
| EnvExecTime             | 1.83       |
| ExplainedVariance       | 0.985      |
| Iteration               | 18         |
| ItrTime                 | 12.6       |
| LossAfter               | -0.0240009 |
| LossBefore              | 0.0142378  |
| MaxReturn               | 189        |
| MeanKL                  | 0.00978595 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 155        |
| NumTrajs                | 58         |
| Perplexity              | 55.9894    |
| PolicyExecTime          | 0.445      |
| ProcessExecTime         | 0.0584     |
| StdReturn               | 7.84       |
| Time                    | 239        |
| dLoss                   | 0.0382388  |
----------------------------------------
itr #19 | 
Mem: 648.269531
Obtaining samples...
Obtaining samples for iteration 19...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5033, #subsample_inputs: 5033
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.754      |
| AbsLearnSignalNew       | 0.754      |
| AbsLearningOld          | 0.753      |
| AverageDiscountedReturn | 115        |
| AveragePhiLoss          | 5.05014    |
| AveragePolicyStd        | 0.922364   |
| AverageReturn           | 180        |
| Entropy                 | 4.0136     |
| EnvExecTime             | 1.75       |
| ExplainedVariance       | 0.982      |
| Iteration               | 19         |
| ItrTime                 | 12.5       |
| LossAfter               | 0.181426   |
| LossBefore              | 0.210557   |
| MaxReturn               | 196        |
| MeanKL                  | 0.00668866 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 156        |
| NumTrajs                | 57         |
| Perplexity              | 55.3457    |
| PolicyExecTime          | 0.435      |
| ProcessExecTime         | 0.0541     |
| StdReturn               | 8.36       |
| Time                    | 252        |
| dLoss                   | 0.029131   |
----------------------------------------
itr #20 | 
Mem: 648.269531
Obtaining samples...
Obtaining samples for iteration 20...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5060, #subsample_inputs: 5060
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.618      |
| AbsLearnSignalNew       | 0.618      |
| AbsLearningOld          | 0.618      |
| AverageDiscountedReturn | 116        |
| AveragePhiLoss          | 5.28502    |
| AveragePolicyStd        | 0.917835   |
| AverageReturn           | 182        |
| Entropy                 | 3.99889    |
| EnvExecTime             | 1.96       |
| ExplainedVariance       | 0.967      |
| Iteration               | 20         |
| ItrTime                 | 12.8       |
| LossAfter               | 0.43357    |
| LossBefore              | 0.45978    |
| MaxReturn               | 208        |
| MeanKL                  | 0.00656479 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 129        |
| NumTrajs                | 57         |
| Perplexity              | 54.5378    |
| PolicyExecTime          | 0.469      |
| ProcessExecTime         | 0.0606     |
| StdReturn               | 11.6       |
| Time                    | 265        |
| dLoss                   | 0.0262106  |
----------------------------------------
itr #21 | 
Mem: 648.269531
Obtaining samples...
Obtaining samples for iteration 21...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5016, #subsample_inputs: 5016
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.566      |
| AbsLearnSignalNew       | 0.566      |
| AbsLearningOld          | 0.566      |
| AverageDiscountedReturn | 117        |
| AveragePhiLoss          | 6.2976     |
| AveragePolicyStd        | 0.921144   |
| AverageReturn           | 186        |
| Entropy                 | 4.00906    |
| EnvExecTime             | 1.83       |
| ExplainedVariance       | 0.925      |
| Iteration               | 21         |
| ItrTime                 | 12.6       |
| LossAfter               | 0.2326     |
| LossBefore              | 0.264018   |
| MaxReturn               | 220        |
| MeanKL                  | 0.00995962 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 111        |
| NumTrajs                | 56         |
| Perplexity              | 55.0953    |
| PolicyExecTime          | 0.446      |
| ProcessExecTime         | 0.0565     |
| StdReturn               | 16         |
| Time                    | 277        |
| dLoss                   | 0.031418   |
----------------------------------------
itr #22 | 
Mem: 648.269531
Obtaining samples...
Obtaining samples for iteration 22...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5082, #subsample_inputs: 5082
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.699      |
| AbsLearnSignalNew       | 0.699      |
| AbsLearningOld          | 0.699      |
| AverageDiscountedReturn | 119        |
| AveragePhiLoss          | 5.09025    |
| AveragePolicyStd        | 0.91476    |
| AverageReturn           | 190        |
| Entropy                 | 3.98781    |
| EnvExecTime             | 1.85       |
| ExplainedVariance       | 0.963      |
| Iteration               | 22         |
| ItrTime                 | 12.7       |
| LossAfter               | 0.0929493  |
| LossBefore              | 0.137247   |
| MaxReturn               | 219        |
| MeanKL                  | 0.00999537 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 170        |
| NumTrajs                | 56         |
| Perplexity              | 53.9366    |
| PolicyExecTime          | 0.453      |
| ProcessExecTime         | 0.0569     |
| StdReturn               | 10.6       |
| Time                    | 290        |
| dLoss                   | 0.0442973  |
----------------------------------------
itr #23 | 
Mem: 648.269531
Obtaining samples...
Obtaining samples for iteration 23...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5009, #subsample_inputs: 5009
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.714      |
| AbsLearnSignalNew       | 0.714      |
| AbsLearningOld          | 0.713      |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 5.29034    |
| AveragePolicyStd        | 0.915808   |
| AverageReturn           | 197        |
| Entropy                 | 3.99076    |
| EnvExecTime             | 1.67       |
| ExplainedVariance       | 0.966      |
| Iteration               | 23         |
| ItrTime                 | 12.4       |
| LossAfter               | -0.152218  |
| LossBefore              | -0.111148  |
| MaxReturn               | 236        |
| MeanKL                  | 0.00952046 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 169        |
| NumTrajs                | 54         |
| Perplexity              | 54.096     |
| PolicyExecTime          | 0.418      |
| ProcessExecTime         | 0.0528     |
| StdReturn               | 11.6       |
| Time                    | 303        |
| dLoss                   | 0.0410694  |
----------------------------------------
itr #24 | 
Mem: 648.785156
Obtaining samples...
Obtaining samples for iteration 24...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5087, #subsample_inputs: 5087
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.595      |
| AbsLearnSignalNew       | 0.595      |
| AbsLearningOld          | 0.595      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 5.34097    |
| AveragePolicyStd        | 0.917093   |
| AverageReturn           | 206        |
| Entropy                 | 3.99481    |
| EnvExecTime             | 1.77       |
| ExplainedVariance       | 0.929      |
| Iteration               | 24         |
| ItrTime                 | 12.7       |
| LossAfter               | -0.0746215 |
| LossBefore              | -0.050277  |
| MaxReturn               | 230        |
| MeanKL                  | 0.00644032 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 127        |
| NumTrajs                | 54         |
| Perplexity              | 54.3156    |
| PolicyExecTime          | 0.434      |
| ProcessExecTime         | 0.0549     |
| StdReturn               | 16.6       |
| Time                    | 315        |
| dLoss                   | 0.0243445  |
----------------------------------------
itr #25 | 
Mem: 649.816406
Obtaining samples...
Obtaining samples for iteration 25...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5053, #subsample_inputs: 5053
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.653      |
| AbsLearnSignalNew       | 0.653      |
| AbsLearningOld          | 0.653      |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 5.62542    |
| AveragePolicyStd        | 0.91452    |
| AverageReturn           | 211        |
| Entropy                 | 3.98664    |
| EnvExecTime             | 2.03       |
| ExplainedVariance       | 0.932      |
| Iteration               | 25         |
| ItrTime                 | 12.9       |
| LossAfter               | 0.418709   |
| LossBefore              | 0.443231   |
| MaxReturn               | 252        |
| MeanKL                  | 0.00645788 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 137        |
| NumTrajs                | 53         |
| Perplexity              | 53.8734    |
| PolicyExecTime          | 0.484      |
| ProcessExecTime         | 0.0646     |
| StdReturn               | 18         |
| Time                    | 328        |
| dLoss                   | 0.0245218  |
----------------------------------------
itr #26 | 
Mem: 649.816406
Obtaining samples...
Obtaining samples for iteration 26...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5047, #subsample_inputs: 5047
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.696      |
| AbsLearnSignalNew       | 0.696      |
| AbsLearningOld          | 0.696      |
| AverageDiscountedReturn | 130        |
| AveragePhiLoss          | 6.057      |
| AveragePolicyStd        | 0.912768   |
| AverageReturn           | 217        |
| Entropy                 | 3.98008    |
| EnvExecTime             | 1.78       |
| ExplainedVariance       | 0.956      |
| Iteration               | 26         |
| ItrTime                 | 12.5       |
| LossAfter               | -0.485588  |
| LossBefore              | -0.453913  |
| MaxReturn               | 257        |
| MeanKL                  | 0.00660266 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 181        |
| NumTrajs                | 52         |
| Perplexity              | 53.5211    |
| PolicyExecTime          | 0.438      |
| ProcessExecTime         | 0.0557     |
| StdReturn               | 15.6       |
| Time                    | 341        |
| dLoss                   | 0.0316755  |
----------------------------------------
itr #27 | 
Mem: 649.816406
Obtaining samples...
Obtaining samples for iteration 27...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5021, #subsample_inputs: 5021
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.591      |
| AbsLearnSignalNew       | 0.591      |
| AbsLearningOld          | 0.591      |
| AverageDiscountedReturn | 132        |
| AveragePhiLoss          | 5.50031    |
| AveragePolicyStd        | 0.907509   |
| AverageReturn           | 224        |
| Entropy                 | 3.96246    |
| EnvExecTime             | 1.93       |
| ExplainedVariance       | 0.902      |
| Iteration               | 27         |
| ItrTime                 | 12.7       |
| LossAfter               | -0.13057   |
| LossBefore              | -0.10007   |
| MaxReturn               | 271        |
| MeanKL                  | 0.00972627 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 133        |
| NumTrajs                | 51         |
| Perplexity              | 52.5866    |
| PolicyExecTime          | 0.466      |
| ProcessExecTime         | 0.0591     |
| StdReturn               | 25.1       |
| Time                    | 354        |
| dLoss                   | 0.0305001  |
----------------------------------------
itr #28 | 
Mem: 649.816406
Obtaining samples...
Obtaining samples for iteration 28...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5043, #subsample_inputs: 5043
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.664      |
| AbsLearnSignalNew       | 0.664      |
| AbsLearningOld          | 0.664      |
| AverageDiscountedReturn | 135        |
| AveragePhiLoss          | 5.70048    |
| AveragePolicyStd        | 0.904067   |
| AverageReturn           | 232        |
| Entropy                 | 3.95054    |
| EnvExecTime             | 1.76       |
| ExplainedVariance       | 0.897      |
| Iteration               | 28         |
| ItrTime                 | 12.5       |
| LossAfter               | -0.579981  |
| LossBefore              | -0.542086  |
| MaxReturn               | 280        |
| MeanKL                  | 0.00652385 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 129        |
| NumTrajs                | 50         |
| Perplexity              | 51.9633    |
| PolicyExecTime          | 0.431      |
| ProcessExecTime         | 0.0552     |
| StdReturn               | 28.7       |
| Time                    | 366        |
| dLoss                   | 0.037895   |
----------------------------------------
itr #29 | 
Mem: 650.589844
Obtaining samples...
Obtaining samples for iteration 29...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5017, #subsample_inputs: 5017
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.515      |
| AbsLearnSignalNew       | 0.515      |
| AbsLearningOld          | 0.516      |
| AverageDiscountedReturn | 141        |
| AveragePhiLoss          | 6.0873     |
| AveragePolicyStd        | 0.902685   |
| AverageReturn           | 250        |
| Entropy                 | 3.94591    |
| EnvExecTime             | 1.77       |
| ExplainedVariance       | 0.914      |
| Iteration               | 29         |
| ItrTime                 | 12.4       |
| LossAfter               | -1.04793   |
| LossBefore              | -1.02126   |
| MaxReturn               | 300        |
| MeanKL                  | 0.00663444 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 48.5       |
| NumTrajs                | 47         |
| Perplexity              | 51.7233    |
| PolicyExecTime          | 0.435      |
| ProcessExecTime         | 0.0551     |
| StdReturn               | 38.5       |
| Time                    | 379        |
| dLoss                   | 0.0266732  |
----------------------------------------
itr #30 | 
Mem: 650.589844
Obtaining samples...
Obtaining samples for iteration 30...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5140, #subsample_inputs: 5140
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.658      |
| AbsLearnSignalNew       | 0.658      |
| AbsLearningOld          | 0.659      |
| AverageDiscountedReturn | 144        |
| AveragePhiLoss          | 5.36522    |
| AveragePolicyStd        | 0.89515    |
| AverageReturn           | 258        |
| Entropy                 | 3.92045    |
| EnvExecTime             | 1.73       |
| ExplainedVariance       | 0.954      |
| Iteration               | 30         |
| ItrTime                 | 12.6       |
| LossAfter               | -0.210482  |
| LossBefore              | -0.165267  |
| MaxReturn               | 311        |
| MeanKL                  | 0.00982543 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 187        |
| NumTrajs                | 47         |
| Perplexity              | 50.4233    |
| PolicyExecTime          | 0.429      |
| ProcessExecTime         | 0.0541     |
| StdReturn               | 24.8       |
| Time                    | 392        |
| dLoss                   | 0.0452153  |
----------------------------------------
itr #31 | 
Mem: 650.847656
Obtaining samples...
Obtaining samples for iteration 31...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5069, #subsample_inputs: 5069
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.751      |
| AbsLearnSignalNew       | 0.751      |
| AbsLearningOld          | 0.75       |
| AverageDiscountedReturn | 150        |
| AveragePhiLoss          | 5.67946    |
| AveragePolicyStd        | 0.897533   |
| AverageReturn           | 276        |
| Entropy                 | 3.92831    |
| EnvExecTime             | 1.76       |
| ExplainedVariance       | 0.975      |
| Iteration               | 31         |
| ItrTime                 | 12.5       |
| LossAfter               | -0.249545  |
| LossBefore              | -0.215161  |
| MaxReturn               | 314        |
| MeanKL                  | 0.00642725 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 234        |
| NumTrajs                | 44         |
| Perplexity              | 50.8208    |
| PolicyExecTime          | 0.433      |
| ProcessExecTime         | 0.0552     |
| StdReturn               | 17.1       |
| Time                    | 404        |
| dLoss                   | 0.0343834  |
----------------------------------------
itr #32 | 
Mem: 651.359375
Obtaining samples...
Obtaining samples for iteration 32...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5093, #subsample_inputs: 5093
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.408      |
| AbsLearnSignalNew       | 0.408      |
| AbsLearningOld          | 0.409      |
| AverageDiscountedReturn | 151        |
| AveragePhiLoss          | 5.47238    |
| AveragePolicyStd        | 0.887522   |
| AverageReturn           | 283        |
| Entropy                 | 3.89483    |
| EnvExecTime             | 1.74       |
| ExplainedVariance       | 0.924      |
| Iteration               | 32         |
| ItrTime                 | 12.5       |
| LossAfter               | -0.598297  |
| LossBefore              | -0.579333  |
| MaxReturn               | 309        |
| MeanKL                  | 0.00654119 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 67         |
| NumTrajs                | 43         |
| Perplexity              | 49.1479    |
| PolicyExecTime          | 0.427      |
| ProcessExecTime         | 0.0528     |
| StdReturn               | 35.8       |
| Time                    | 417        |
| dLoss                   | 0.0189639  |
----------------------------------------
itr #33 | 
Mem: 653.929688
Obtaining samples...
Obtaining samples for iteration 33...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5098, #subsample_inputs: 5098
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.434      |
| AbsLearnSignalNew       | 0.434      |
| AbsLearningOld          | 0.434      |
| AverageDiscountedReturn | 151        |
| AveragePhiLoss          | 5.75149    |
| AveragePolicyStd        | 0.884648   |
| AverageReturn           | 285        |
| Entropy                 | 3.88704    |
| EnvExecTime             | 1.77       |
| ExplainedVariance       | 0.927      |
| Iteration               | 33         |
| ItrTime                 | 12.6       |
| LossAfter               | 0.0845082  |
| LossBefore              | 0.105841   |
| MaxReturn               | 327        |
| MeanKL                  | 0.00679357 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 55.8       |
| NumTrajs                | 43         |
| Perplexity              | 48.7665    |
| PolicyExecTime          | 0.438      |
| ProcessExecTime         | 0.0539     |
| StdReturn               | 39.8       |
| Time                    | 430        |
| dLoss                   | 0.0213324  |
----------------------------------------
itr #34 | 
Mem: 654.183594
Obtaining samples...
Obtaining samples for iteration 34...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5050, #subsample_inputs: 5050
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.389      |
| AbsLearnSignalNew       | 0.389      |
| AbsLearningOld          | 0.389      |
| AverageDiscountedReturn | 153        |
| AveragePhiLoss          | 6.00151    |
| AveragePolicyStd        | 0.879549   |
| AverageReturn           | 289        |
| Entropy                 | 3.86977    |
| EnvExecTime             | 1.8        |
| ExplainedVariance       | 0.938      |
| Iteration               | 34         |
| ItrTime                 | 12.7       |
| LossAfter               | 0.112363   |
| LossBefore              | 0.13327    |
| MaxReturn               | 326        |
| MeanKL                  | 0.00684719 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 52.2       |
| NumTrajs                | 42         |
| Perplexity              | 47.9311    |
| PolicyExecTime          | 0.445      |
| ProcessExecTime         | 0.0547     |
| StdReturn               | 39.4       |
| Time                    | 443        |
| dLoss                   | 0.0209077  |
----------------------------------------
itr #35 | 
Mem: 654.183594
Obtaining samples...
Obtaining samples for iteration 35...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5031, #subsample_inputs: 5031
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.769      |
| AbsLearnSignalNew       | 0.769      |
| AbsLearningOld          | 0.769      |
| AverageDiscountedReturn | 157        |
| AveragePhiLoss          | 5.94611    |
| AveragePolicyStd        | 0.876372   |
| AverageReturn           | 304        |
| Entropy                 | 3.85895    |
| EnvExecTime             | 1.83       |
| ExplainedVariance       | 0.986      |
| Iteration               | 35         |
| ItrTime                 | 12.6       |
| LossAfter               | 0.104619   |
| LossBefore              | 0.128623   |
| MaxReturn               | 329        |
| MeanKL                  | 0.00642417 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 280        |
| NumTrajs                | 40         |
| Perplexity              | 47.4155    |
| PolicyExecTime          | 0.44       |
| ProcessExecTime         | 0.0573     |
| StdReturn               | 11.7       |
| Time                    | 455        |
| dLoss                   | 0.0240041  |
----------------------------------------
itr #36 | 
Mem: 654.183594
Obtaining samples...
Obtaining samples for iteration 36...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5120, #subsample_inputs: 5120
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.731      |
| AbsLearnSignalNew       | 0.731      |
| AbsLearningOld          | 0.73       |
| AverageDiscountedReturn | 158        |
| AveragePhiLoss          | 6.29926    |
| AveragePolicyStd        | 0.872588   |
| AverageReturn           | 303        |
| Entropy                 | 3.84606    |
| EnvExecTime             | 1.82       |
| ExplainedVariance       | 0.991      |
| Iteration               | 36         |
| ItrTime                 | 12.7       |
| LossAfter               | 0.0858169  |
| LossBefore              | 0.115312   |
| MaxReturn               | 325        |
| MeanKL                  | 0.00645557 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 267        |
| NumTrajs                | 41         |
| Perplexity              | 46.8082    |
| PolicyExecTime          | 0.45       |
| ProcessExecTime         | 0.0553     |
| StdReturn               | 12.2       |
| Time                    | 468        |
| dLoss                   | 0.0294949  |
----------------------------------------
itr #37 | 
Mem: 654.183594
Obtaining samples...
Obtaining samples for iteration 37...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5112, #subsample_inputs: 5112
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.693      |
| AbsLearnSignalNew       | 0.693      |
| AbsLearningOld          | 0.692      |
| AverageDiscountedReturn | 159        |
| AveragePhiLoss          | 6.43456    |
| AveragePolicyStd        | 0.867679   |
| AverageReturn           | 310        |
| Entropy                 | 3.83012    |
| EnvExecTime             | 1.7        |
| ExplainedVariance       | 0.992      |
| Iteration               | 37         |
| ItrTime                 | 12.6       |
| LossAfter               | -0.011194  |
| LossBefore              | 0.0145871  |
| MaxReturn               | 331        |
| MeanKL                  | 0.00643496 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 289        |
| NumTrajs                | 40         |
| Perplexity              | 46.0681    |
| PolicyExecTime          | 0.418      |
| ProcessExecTime         | 0.0529     |
| StdReturn               | 11.3       |
| Time                    | 481        |
| dLoss                   | 0.0257811  |
----------------------------------------
itr #38 | 
Mem: 654.441406
Obtaining samples...
Obtaining samples for iteration 38...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5037, #subsample_inputs: 5037
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.712      |
| AbsLearnSignalNew       | 0.712      |
| AbsLearningOld          | 0.712      |
| AverageDiscountedReturn | 160        |
| AveragePhiLoss          | 6.59968    |
| AveragePolicyStd        | 0.858872   |
| AverageReturn           | 314        |
| Entropy                 | 3.80004    |
| EnvExecTime             | 1.87       |
| ExplainedVariance       | 0.994      |
| Iteration               | 38         |
| ItrTime                 | 12.6       |
| LossAfter               | -0.218967  |
| LossBefore              | -0.200342  |
| MaxReturn               | 334        |
| MeanKL                  | 0.00647223 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 299        |
| NumTrajs                | 39         |
| Perplexity              | 44.7028    |
| PolicyExecTime          | 0.448      |
| ProcessExecTime         | 0.0601     |
| StdReturn               | 9.47       |
| Time                    | 493        |
| dLoss                   | 0.0186257  |
----------------------------------------
itr #39 | 
Mem: 654.441406
Obtaining samples...
Obtaining samples for iteration 39...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5075, #subsample_inputs: 5075
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.717      |
| AbsLearnSignalNew       | 0.717      |
| AbsLearningOld          | 0.716      |
| AverageDiscountedReturn | 161        |
| AveragePhiLoss          | 6.3837     |
| AveragePolicyStd        | 0.859472   |
| AverageReturn           | 317        |
| Entropy                 | 3.80188    |
| EnvExecTime             | 1.87       |
| ExplainedVariance       | 0.992      |
| Iteration               | 39         |
| ItrTime                 | 12.8       |
| LossAfter               | 0.012858   |
| LossBefore              | 0.0460046  |
| MaxReturn               | 336        |
| MeanKL                  | 0.00999747 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 298        |
| NumTrajs                | 39         |
| Perplexity              | 44.7851    |
| PolicyExecTime          | 0.448      |
| ProcessExecTime         | 0.0582     |
| StdReturn               | 9.6        |
| Time                    | 506        |
| dLoss                   | 0.0331465  |
----------------------------------------
itr #40 | 
Mem: 654.441406
Obtaining samples...
Obtaining samples for iteration 40...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5008, #subsample_inputs: 5008
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.669     |
| AbsLearnSignalNew       | 0.669     |
| AbsLearningOld          | 0.668     |
| AverageDiscountedReturn | 162       |
| AveragePhiLoss          | 7.21486   |
| AveragePolicyStd        | 0.851981  |
| AverageReturn           | 322       |
| Entropy                 | 3.77579   |
| EnvExecTime             | 1.87      |
| ExplainedVariance       | 0.992     |
| Iteration               | 40        |
| ItrTime                 | 12.6      |
| LossAfter               | -0.434479 |
| LossBefore              | -0.415209 |
| MaxReturn               | 346       |
| MeanKL                  | 0.0067664 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 294       |
| NumTrajs                | 38        |
| Perplexity              | 43.632    |
| PolicyExecTime          | 0.449     |
| ProcessExecTime         | 0.0563    |
| StdReturn               | 10.1      |
| Time                    | 519       |
| dLoss                   | 0.0192706 |
---------------------------------------
itr #41 | 
Mem: 654.441406
Obtaining samples...
Obtaining samples for iteration 41...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5002, #subsample_inputs: 5002
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.698      |
| AbsLearnSignalNew       | 0.698      |
| AbsLearningOld          | 0.698      |
| AverageDiscountedReturn | 162        |
| AveragePhiLoss          | 6.79924    |
| AveragePolicyStd        | 0.84089    |
| AverageReturn           | 321        |
| Entropy                 | 3.73568    |
| EnvExecTime             | 1.75       |
| ExplainedVariance       | 0.993      |
| Iteration               | 41         |
| ItrTime                 | 12.4       |
| LossAfter               | -0.407738  |
| LossBefore              | -0.380391  |
| MaxReturn               | 334        |
| MeanKL                  | 0.00974718 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 294        |
| NumTrajs                | 38         |
| Perplexity              | 41.9165    |
| PolicyExecTime          | 0.425      |
| ProcessExecTime         | 0.0528     |
| StdReturn               | 9.34       |
| Time                    | 532        |
| dLoss                   | 0.0273474  |
----------------------------------------
itr #42 | 
Mem: 656.246094
Obtaining samples...
Obtaining samples for iteration 42...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5031, #subsample_inputs: 5031
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.647      |
| AbsLearnSignalNew       | 0.647      |
| AbsLearningOld          | 0.646      |
| AverageDiscountedReturn | 162        |
| AveragePhiLoss          | 7.25874    |
| AveragePolicyStd        | 0.829287   |
| AverageReturn           | 323        |
| Entropy                 | 3.69292    |
| EnvExecTime             | 1.76       |
| ExplainedVariance       | 0.993      |
| Iteration               | 42         |
| ItrTime                 | 12.5       |
| LossAfter               | -0.29568   |
| LossBefore              | -0.273752  |
| MaxReturn               | 343        |
| MeanKL                  | 0.00660177 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 304        |
| NumTrajs                | 38         |
| Perplexity              | 40.1618    |
| PolicyExecTime          | 0.428      |
| ProcessExecTime         | 0.0536     |
| StdReturn               | 8.61       |
| Time                    | 544        |
| dLoss                   | 0.0219285  |
----------------------------------------
itr #43 | 
Mem: 656.246094
Obtaining samples...
Obtaining samples for iteration 43...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5067, #subsample_inputs: 5067
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.652      |
| AbsLearnSignalNew       | 0.652      |
| AbsLearningOld          | 0.651      |
| AverageDiscountedReturn | 163        |
| AveragePhiLoss          | 7.27619    |
| AveragePolicyStd        | 0.823587   |
| AverageReturn           | 327        |
| Entropy                 | 3.67251    |
| EnvExecTime             | 1.88       |
| ExplainedVariance       | 0.986      |
| Iteration               | 43         |
| ItrTime                 | 12.7       |
| LossAfter               | 0.0642033  |
| LossBefore              | 0.0818565  |
| MaxReturn               | 363        |
| MeanKL                  | 0.00647515 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 297        |
| NumTrajs                | 38         |
| Perplexity              | 39.3505    |
| PolicyExecTime          | 0.453      |
| ProcessExecTime         | 0.0565     |
| StdReturn               | 12         |
| Time                    | 557        |
| dLoss                   | 0.0176533  |
----------------------------------------
itr #44 | 
Mem: 656.246094
Obtaining samples...
Obtaining samples for iteration 44...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5111, #subsample_inputs: 5111
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.673      |
| AbsLearnSignalNew       | 0.673      |
| AbsLearningOld          | 0.672      |
| AverageDiscountedReturn | 163        |
| AveragePhiLoss          | 6.86889    |
| AveragePolicyStd        | 0.819952   |
| AverageReturn           | 329        |
| Entropy                 | 3.66017    |
| EnvExecTime             | 1.93       |
| ExplainedVariance       | 0.989      |
| Iteration               | 44         |
| ItrTime                 | 12.8       |
| LossAfter               | -0.287122  |
| LossBefore              | -0.265275  |
| MaxReturn               | 353        |
| MeanKL                  | 0.00653504 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 309        |
| NumTrajs                | 38         |
| Perplexity              | 38.868     |
| PolicyExecTime          | 0.462      |
| ProcessExecTime         | 0.0573     |
| StdReturn               | 10.3       |
| Time                    | 570        |
| dLoss                   | 0.0218471  |
----------------------------------------
itr #45 | 
Mem: 656.503906
Obtaining samples...
Obtaining samples for iteration 45...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5142, #subsample_inputs: 5142
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.626      |
| AbsLearnSignalNew       | 0.626      |
| AbsLearningOld          | 0.625      |
| AverageDiscountedReturn | 165        |
| AveragePhiLoss          | 7.18194    |
| AveragePolicyStd        | 0.814603   |
| AverageReturn           | 334        |
| Entropy                 | 3.64096    |
| EnvExecTime             | 2.07       |
| ExplainedVariance       | 0.986      |
| Iteration               | 45         |
| ItrTime                 | 13         |
| LossAfter               | -0.386806  |
| LossBefore              | -0.353978  |
| MaxReturn               | 364        |
| MeanKL                  | 0.00979707 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 309        |
| NumTrajs                | 38         |
| Perplexity              | 38.1283    |
| PolicyExecTime          | 0.488      |
| ProcessExecTime         | 0.0644     |
| StdReturn               | 12.4       |
| Time                    | 583        |
| dLoss                   | 0.032828   |
----------------------------------------
itr #46 | 
Mem: 656.503906
Obtaining samples...
Obtaining samples for iteration 46...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5054, #subsample_inputs: 5054
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.671      |
| AbsLearnSignalNew       | 0.671      |
| AbsLearningOld          | 0.669      |
| AverageDiscountedReturn | 165        |
| AveragePhiLoss          | 7.3769     |
| AveragePolicyStd        | 0.818167   |
| AverageReturn           | 337        |
| Entropy                 | 3.65442    |
| EnvExecTime             | 1.94       |
| ExplainedVariance       | 0.985      |
| Iteration               | 46         |
| ItrTime                 | 12.7       |
| LossAfter               | -0.182676  |
| LossBefore              | -0.161373  |
| MaxReturn               | 367        |
| MeanKL                  | 0.00648779 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 316        |
| NumTrajs                | 37         |
| Perplexity              | 38.6451    |
| PolicyExecTime          | 0.46       |
| ProcessExecTime         | 0.0578     |
| StdReturn               | 10.9       |
| Time                    | 596        |
| dLoss                   | 0.0213038  |
----------------------------------------
itr #47 | 
Mem: 656.503906
Obtaining samples...
Obtaining samples for iteration 47...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5001, #subsample_inputs: 5001
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.656      |
| AbsLearnSignalNew       | 0.656      |
| AbsLearningOld          | 0.655      |
| AverageDiscountedReturn | 164        |
| AveragePhiLoss          | 7.2911     |
| AveragePolicyStd        | 0.817206   |
| AverageReturn           | 333        |
| Entropy                 | 3.65112    |
| EnvExecTime             | 1.8        |
| ExplainedVariance       | 0.976      |
| Iteration               | 47         |
| ItrTime                 | 12.5       |
| LossAfter               | 0.169351   |
| LossBefore              | 0.189122   |
| MaxReturn               | 369        |
| MeanKL                  | 0.00658079 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 300        |
| NumTrajs                | 37         |
| Perplexity              | 38.5176    |
| PolicyExecTime          | 0.442      |
| ProcessExecTime         | 0.055      |
| StdReturn               | 15.6       |
| Time                    | 608        |
| dLoss                   | 0.0197708  |
----------------------------------------
itr #48 | 
Mem: 656.503906
Obtaining samples...
Obtaining samples for iteration 48...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5025, #subsample_inputs: 5025
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.58       |
| AbsLearnSignalNew       | 0.58       |
| AbsLearningOld          | 0.58       |
| AverageDiscountedReturn | 165        |
| AveragePhiLoss          | 8.4332     |
| AveragePolicyStd        | 0.82075    |
| AverageReturn           | 338        |
| Entropy                 | 3.6641     |
| EnvExecTime             | 1.96       |
| ExplainedVariance       | 0.933      |
| Iteration               | 48         |
| ItrTime                 | 12.7       |
| LossAfter               | 0.0588114  |
| LossBefore              | 0.0788293  |
| MaxReturn               | 389        |
| MeanKL                  | 0.00643919 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 228        |
| NumTrajs                | 37         |
| Perplexity              | 39.021     |
| PolicyExecTime          | 0.47       |
| ProcessExecTime         | 0.0583     |
| StdReturn               | 28.1       |
| Time                    | 621        |
| dLoss                   | 0.0200178  |
----------------------------------------
itr #49 | 
Mem: 656.503906
Obtaining samples...
Obtaining samples for iteration 49...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5040, #subsample_inputs: 5040
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.678      |
| AbsLearnSignalNew       | 0.678      |
| AbsLearningOld          | 0.678      |
| AverageDiscountedReturn | 166        |
| AveragePhiLoss          | 7.28077    |
| AveragePolicyStd        | 0.820548   |
| AverageReturn           | 339        |
| Entropy                 | 3.66323    |
| EnvExecTime             | 1.91       |
| ExplainedVariance       | 0.975      |
| Iteration               | 49         |
| ItrTime                 | 12.7       |
| LossAfter               | 0.0459061  |
| LossBefore              | 0.0776689  |
| MaxReturn               | 377        |
| MeanKL                  | 0.00995335 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 309        |
| NumTrajs                | 37         |
| Perplexity              | 38.9872    |
| PolicyExecTime          | 0.458      |
| ProcessExecTime         | 0.057      |
| StdReturn               | 16         |
| Time                    | 634        |
| dLoss                   | 0.0317628  |
----------------------------------------
itr #50 | 
Mem: 656.503906
Obtaining samples...
Obtaining samples for iteration 50...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5092, #subsample_inputs: 5092
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.676     |
| AbsLearnSignalNew       | 0.676     |
| AbsLearningOld          | 0.676     |
| AverageDiscountedReturn | 168       |
| AveragePhiLoss          | 7.11354   |
| AveragePolicyStd        | 0.815535  |
| AverageReturn           | 347       |
| Entropy                 | 3.64491   |
| EnvExecTime             | 1.93      |
| ExplainedVariance       | 0.972     |
| Iteration               | 50        |
| ItrTime                 | 12.8      |
| LossAfter               | -0.584913 |
| LossBefore              | -0.561045 |
| MaxReturn               | 387       |
| MeanKL                  | 0.0099636 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 303       |
| NumTrajs                | 37        |
| Perplexity              | 38.2793   |
| PolicyExecTime          | 0.467     |
| ProcessExecTime         | 0.0578    |
| StdReturn               | 17.6      |
| Time                    | 647       |
| dLoss                   | 0.0238674 |
---------------------------------------
itr #51 | 
Mem: 657.015625
Obtaining samples...
Obtaining samples for iteration 51...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5047, #subsample_inputs: 5047
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.679     |
| AbsLearnSignalNew       | 0.679     |
| AbsLearningOld          | 0.679     |
| AverageDiscountedReturn | 171       |
| AveragePhiLoss          | 7.82273   |
| AveragePolicyStd        | 0.807561  |
| AverageReturn           | 357       |
| Entropy                 | 3.6155    |
| EnvExecTime             | 1.93      |
| ExplainedVariance       | 0.972     |
| Iteration               | 51        |
| ItrTime                 | 12.7      |
| LossAfter               | -0.386636 |
| LossBefore              | -0.351813 |
| MaxReturn               | 401       |
| MeanKL                  | 0.0098428 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 322       |
| NumTrajs                | 36        |
| Perplexity              | 37.17     |
| PolicyExecTime          | 0.466     |
| ProcessExecTime         | 0.0584    |
| StdReturn               | 18.8      |
| Time                    | 660       |
| dLoss                   | 0.0348226 |
---------------------------------------
itr #52 | 
Mem: 657.015625
Obtaining samples...
Obtaining samples for iteration 52...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5115, #subsample_inputs: 5115
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.685      |
| AbsLearnSignalNew       | 0.685      |
| AbsLearningOld          | 0.686      |
| AverageDiscountedReturn | 172        |
| AveragePhiLoss          | 8.494      |
| AveragePolicyStd        | 0.811672   |
| AverageReturn           | 363        |
| Entropy                 | 3.6307     |
| EnvExecTime             | 1.93       |
| ExplainedVariance       | 0.969      |
| Iteration               | 52         |
| ItrTime                 | 12.9       |
| LossAfter               | -0.313655  |
| LossBefore              | -0.291221  |
| MaxReturn               | 397        |
| MeanKL                  | 0.00666161 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 315        |
| NumTrajs                | 36         |
| Perplexity              | 37.7394    |
| PolicyExecTime          | 0.468      |
| ProcessExecTime         | 0.0577     |
| StdReturn               | 17.1       |
| Time                    | 673        |
| dLoss                   | 0.0224336  |
----------------------------------------
itr #53 | 
Mem: 657.531250
Obtaining samples...
Obtaining samples for iteration 53...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5063, #subsample_inputs: 5063
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.66       |
| AbsLearnSignalNew       | 0.66       |
| AbsLearningOld          | 0.659      |
| AverageDiscountedReturn | 171        |
| AveragePhiLoss          | 7.76615    |
| AveragePolicyStd        | 0.803947   |
| AverageReturn           | 358        |
| Entropy                 | 3.60154    |
| EnvExecTime             | 1.94       |
| ExplainedVariance       | 0.949      |
| Iteration               | 53         |
| ItrTime                 | 12.7       |
| LossAfter               | -0.336211  |
| LossBefore              | -0.304174  |
| MaxReturn               | 441        |
| MeanKL                  | 0.00982042 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 311        |
| NumTrajs                | 36         |
| Perplexity              | 36.6545    |
| PolicyExecTime          | 0.468      |
| ProcessExecTime         | 0.0576     |
| StdReturn               | 26         |
| Time                    | 686        |
| dLoss                   | 0.032037   |
----------------------------------------
itr #54 | 
Mem: 657.531250
Obtaining samples...
Obtaining samples for iteration 54...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5125, #subsample_inputs: 5125
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.601      |
| AbsLearnSignalNew       | 0.601      |
| AbsLearningOld          | 0.601      |
| AverageDiscountedReturn | 173        |
| AveragePhiLoss          | 7.52945    |
| AveragePolicyStd        | 0.801083   |
| AverageReturn           | 367        |
| Entropy                 | 3.59058    |
| EnvExecTime             | 1.99       |
| ExplainedVariance       | 0.958      |
| Iteration               | 54         |
| ItrTime                 | 12.9       |
| LossAfter               | 0.316459   |
| LossBefore              | 0.35205    |
| MaxReturn               | 394        |
| MeanKL                  | 0.00954163 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 313        |
| NumTrajs                | 36         |
| Perplexity              | 36.2552    |
| PolicyExecTime          | 0.479      |
| ProcessExecTime         | 0.0589     |
| StdReturn               | 17.4       |
| Time                    | 699        |
| dLoss                   | 0.0355908  |
----------------------------------------
itr #55 | 
Mem: 657.531250
Obtaining samples...
Obtaining samples for iteration 55...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5009, #subsample_inputs: 5009
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.606     |
| AbsLearnSignalNew       | 0.606     |
| AbsLearningOld          | 0.605     |
| AverageDiscountedReturn | 174       |
| AveragePhiLoss          | 7.54711   |
| AveragePolicyStd        | 0.799112  |
| AverageReturn           | 370       |
| Entropy                 | 3.58308   |
| EnvExecTime             | 1.96      |
| ExplainedVariance       | 0.931     |
| Iteration               | 55        |
| ItrTime                 | 12.7      |
| LossAfter               | 0.247798  |
| LossBefore              | 0.277022  |
| MaxReturn               | 477       |
| MeanKL                  | 0.0093765 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 313       |
| NumTrajs                | 35        |
| Perplexity              | 35.9843   |
| PolicyExecTime          | 0.465     |
| ProcessExecTime         | 0.059     |
| StdReturn               | 26.7      |
| Time                    | 711       |
| dLoss                   | 0.0292237 |
---------------------------------------
itr #56 | 
Mem: 657.531250
Obtaining samples...
Obtaining samples for iteration 56...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5099, #subsample_inputs: 5099
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.642      |
| AbsLearnSignalNew       | 0.642      |
| AbsLearningOld          | 0.641      |
| AverageDiscountedReturn | 177        |
| AveragePhiLoss          | 7.25222    |
| AveragePolicyStd        | 0.802243   |
| AverageReturn           | 382        |
| Entropy                 | 3.59418    |
| EnvExecTime             | 1.86       |
| ExplainedVariance       | 0.945      |
| Iteration               | 56         |
| ItrTime                 | 12.7       |
| LossAfter               | 0.132744   |
| LossBefore              | 0.155526   |
| MaxReturn               | 484        |
| MeanKL                  | 0.00664338 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 350        |
| NumTrajs                | 35         |
| Perplexity              | 36.3858    |
| PolicyExecTime          | 0.447      |
| ProcessExecTime         | 0.0569     |
| StdReturn               | 31.4       |
| Time                    | 724        |
| dLoss                   | 0.0227822  |
----------------------------------------
itr #57 | 
Mem: 657.531250
Obtaining samples...
Obtaining samples for iteration 57...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5136, #subsample_inputs: 5136
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.565      |
| AbsLearnSignalNew       | 0.565      |
| AbsLearningOld          | 0.565      |
| AverageDiscountedReturn | 178        |
| AveragePhiLoss          | 8.39998    |
| AveragePolicyStd        | 0.795026   |
| AverageReturn           | 388        |
| Entropy                 | 3.5666     |
| EnvExecTime             | 1.78       |
| ExplainedVariance       | 0.836      |
| Iteration               | 57         |
| ItrTime                 | 12.7       |
| LossAfter               | 0.331712   |
| LossBefore              | 0.362003   |
| MaxReturn               | 597        |
| MeanKL                  | 0.00995369 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 229        |
| NumTrajs                | 35         |
| Perplexity              | 35.396     |
| PolicyExecTime          | 0.432      |
| ProcessExecTime         | 0.0542     |
| StdReturn               | 57.8       |
| Time                    | 737        |
| dLoss                   | 0.0302915  |
----------------------------------------
itr #58 | 
Mem: 657.531250
Obtaining samples...
Obtaining samples for iteration 58...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5050, #subsample_inputs: 5050
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.678      |
| AbsLearnSignalNew       | 0.678      |
| AbsLearningOld          | 0.678      |
| AverageDiscountedReturn | 184        |
| AveragePhiLoss          | 7.96391    |
| AveragePolicyStd        | 0.792869   |
| AverageReturn           | 416        |
| Entropy                 | 3.55732    |
| EnvExecTime             | 1.87       |
| ExplainedVariance       | 0.848      |
| Iteration               | 58         |
| ItrTime                 | 12.6       |
| LossAfter               | 0.0072967  |
| LossBefore              | 0.0446244  |
| MaxReturn               | 558        |
| MeanKL                  | 0.00967756 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 336        |
| NumTrajs                | 33         |
| Perplexity              | 35.0692    |
| PolicyExecTime          | 0.454      |
| ProcessExecTime         | 0.0573     |
| StdReturn               | 62.1       |
| Time                    | 750        |
| dLoss                   | 0.0373277  |
----------------------------------------
itr #59 | 
Mem: 657.531250
Obtaining samples...
Obtaining samples for iteration 59...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5130, #subsample_inputs: 5130
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.625      |
| AbsLearnSignalNew       | 0.625      |
| AbsLearningOld          | 0.624      |
| AverageDiscountedReturn | 182        |
| AveragePhiLoss          | 7.90383    |
| AveragePolicyStd        | 0.798274   |
| AverageReturn           | 406        |
| Entropy                 | 3.57744    |
| EnvExecTime             | 1.83       |
| ExplainedVariance       | 0.8        |
| Iteration               | 59         |
| ItrTime                 | 12.7       |
| LossAfter               | 0.283419   |
| LossBefore              | 0.31059    |
| MaxReturn               | 575        |
| MeanKL                  | 0.00955367 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 232        |
| NumTrajs                | 34         |
| Perplexity              | 35.7819    |
| PolicyExecTime          | 0.446      |
| ProcessExecTime         | 0.0563     |
| StdReturn               | 66         |
| Time                    | 763        |
| dLoss                   | 0.0271713  |
----------------------------------------
itr #60 | 
Mem: 657.531250
Obtaining samples...
Obtaining samples for iteration 60...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5010, #subsample_inputs: 5010
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.696      |
| AbsLearnSignalNew       | 0.696      |
| AbsLearningOld          | 0.696      |
| AverageDiscountedReturn | 191        |
| AveragePhiLoss          | 8.59776    |
| AveragePolicyStd        | 0.797802   |
| AverageReturn           | 451        |
| Entropy                 | 3.57549    |
| EnvExecTime             | 1.75       |
| ExplainedVariance       | 0.752      |
| Iteration               | 60         |
| ItrTime                 | 12.4       |
| LossAfter               | 0.705383   |
| LossBefore              | 0.730236   |
| MaxReturn               | 641        |
| MeanKL                  | 0.00904979 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 316        |
| NumTrajs                | 31         |
| Perplexity              | 35.712     |
| PolicyExecTime          | 0.432      |
| ProcessExecTime         | 0.0535     |
| StdReturn               | 93.7       |
| Time                    | 775        |
| dLoss                   | 0.0248535  |
----------------------------------------
itr #61 | 
Mem: 657.531250
Obtaining samples...
Obtaining samples for iteration 61...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5136, #subsample_inputs: 5136
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.736      |
| AbsLearnSignalNew       | 0.736      |
| AbsLearningOld          | 0.736      |
| AverageDiscountedReturn | 202        |
| AveragePhiLoss          | 8.16955    |
| AveragePolicyStd        | 0.802595   |
| AverageReturn           | 513        |
| Entropy                 | 3.59357    |
| EnvExecTime             | 1.88       |
| ExplainedVariance       | 0.824      |
| Iteration               | 61         |
| ItrTime                 | 12.8       |
| LossAfter               | 0.154859   |
| LossBefore              | 0.186807   |
| MaxReturn               | 836        |
| MeanKL                  | 0.00953879 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 374        |
| NumTrajs                | 29         |
| Perplexity              | 36.3635    |
| PolicyExecTime          | 0.458      |
| ProcessExecTime         | 0.0577     |
| StdReturn               | 97.7       |
| Time                    | 788        |
| dLoss                   | 0.0319485  |
----------------------------------------
itr #62 | 
Mem: 658.042969
Obtaining samples...
Obtaining samples for iteration 62...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5150, #subsample_inputs: 5150
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.771      |
| AbsLearnSignalNew       | 0.771      |
| AbsLearningOld          | 0.771      |
| AverageDiscountedReturn | 208        |
| AveragePhiLoss          | 7.63539    |
| AveragePolicyStd        | 0.805008   |
| AverageReturn           | 545        |
| Entropy                 | 3.60224    |
| EnvExecTime             | 1.81       |
| ExplainedVariance       | 0.877      |
| Iteration               | 62         |
| ItrTime                 | 12.9       |
| LossAfter               | -0.308704  |
| LossBefore              | -0.28251   |
| MaxReturn               | 779        |
| MeanKL                  | 0.00980905 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 380        |
| NumTrajs                | 28         |
| Perplexity              | 36.6802    |
| PolicyExecTime          | 0.454      |
| ProcessExecTime         | 0.055      |
| StdReturn               | 98.5       |
| Time                    | 801        |
| dLoss                   | 0.0261937  |
----------------------------------------
itr #63 | 
Mem: 658.042969
Obtaining samples...
Obtaining samples for iteration 63...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5118, #subsample_inputs: 5118
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.698      |
| AbsLearnSignalNew       | 0.698      |
| AbsLearningOld          | 0.698      |
| AverageDiscountedReturn | 216        |
| AveragePhiLoss          | 6.98745    |
| AveragePolicyStd        | 0.802761   |
| AverageReturn           | 621        |
| Entropy                 | 3.59292    |
| EnvExecTime             | 1.74       |
| ExplainedVariance       | 0.783      |
| Iteration               | 63         |
| ItrTime                 | 12.7       |
| LossAfter               | -0.0580502 |
| LossBefore              | -0.0393744 |
| MaxReturn               | 929        |
| MeanKL                  | 0.00677722 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 392        |
| NumTrajs                | 25         |
| Perplexity              | 36.3402    |
| PolicyExecTime          | 0.431      |
| ProcessExecTime         | 0.055      |
| StdReturn               | 150        |
| Time                    | 814        |
| dLoss                   | 0.0186758  |
----------------------------------------
itr #64 | 
Mem: 658.042969
Obtaining samples...
Obtaining samples for iteration 64...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5059, #subsample_inputs: 5059
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.717      |
| AbsLearnSignalNew       | 0.717      |
| AbsLearningOld          | 0.717      |
| AverageDiscountedReturn | 216        |
| AveragePhiLoss          | 7.52464    |
| AveragePolicyStd        | 0.800698   |
| AverageReturn           | 641        |
| Entropy                 | 3.587      |
| EnvExecTime             | 1.83       |
| ExplainedVariance       | 0.787      |
| Iteration               | 64         |
| ItrTime                 | 12.7       |
| LossAfter               | -0.200937  |
| LossBefore              | -0.169885  |
| MaxReturn               | 1.24e+03   |
| MeanKL                  | 0.00988393 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 314        |
| NumTrajs                | 24         |
| Perplexity              | 36.1256    |
| PolicyExecTime          | 0.45       |
| ProcessExecTime         | 0.0561     |
| StdReturn               | 194        |
| Time                    | 826        |
| dLoss                   | 0.0310519  |
----------------------------------------
itr #65 | 
Mem: 670.042969
Obtaining samples...
Obtaining samples for iteration 65...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5130, #subsample_inputs: 5130
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.671      |
| AbsLearnSignalNew       | 0.671      |
| AbsLearningOld          | 0.671      |
| AverageDiscountedReturn | 221        |
| AveragePhiLoss          | 7.54523    |
| AveragePolicyStd        | 0.795884   |
| AverageReturn           | 657        |
| Entropy                 | 3.5681     |
| EnvExecTime             | 1.82       |
| ExplainedVariance       | 0.825      |
| Iteration               | 65         |
| ItrTime                 | 12.7       |
| LossAfter               | -0.179429  |
| LossBefore              | -0.150682  |
| MaxReturn               | 996        |
| MeanKL                  | 0.00982094 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 428        |
| NumTrajs                | 24         |
| Perplexity              | 35.449     |
| PolicyExecTime          | 0.449      |
| ProcessExecTime         | 0.0564     |
| StdReturn               | 119        |
| Time                    | 839        |
| dLoss                   | 0.0287475  |
----------------------------------------
itr #66 | 
Mem: 670.042969
Obtaining samples...
Obtaining samples for iteration 66...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5100, #subsample_inputs: 5100
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.667      |
| AbsLearnSignalNew       | 0.667      |
| AbsLearningOld          | 0.667      |
| AverageDiscountedReturn | 211        |
| AveragePhiLoss          | 7.44808    |
| AveragePolicyStd        | 0.793642   |
| AverageReturn           | 612        |
| Entropy                 | 3.56034    |
| EnvExecTime             | 1.78       |
| ExplainedVariance       | 0.712      |
| Iteration               | 66         |
| ItrTime                 | 12.6       |
| LossAfter               | -0.253224  |
| LossBefore              | -0.225662  |
| MaxReturn               | 885        |
| MeanKL                  | 0.00871562 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 223        |
| NumTrajs                | 25         |
| Perplexity              | 35.1752    |
| PolicyExecTime          | 0.45       |
| ProcessExecTime         | 0.0545     |
| StdReturn               | 177        |
| Time                    | 852        |
| dLoss                   | 0.0275622  |
----------------------------------------
itr #67 | 
Mem: 670.042969
Obtaining samples...
Obtaining samples for iteration 67...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5180, #subsample_inputs: 5180
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.772      |
| AbsLearnSignalNew       | 0.772      |
| AbsLearningOld          | 0.772      |
| AverageDiscountedReturn | 224        |
| AveragePhiLoss          | 8.39528    |
| AveragePolicyStd        | 0.789238   |
| AverageReturn           | 697        |
| Entropy                 | 3.544      |
| EnvExecTime             | 1.93       |
| ExplainedVariance       | 0.882      |
| Iteration               | 67         |
| ItrTime                 | 12.9       |
| LossAfter               | -0.617536  |
| LossBefore              | -0.583837  |
| MaxReturn               | 991        |
| MeanKL                  | 0.00996278 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 482        |
| NumTrajs                | 23         |
| Perplexity              | 34.6049    |
| PolicyExecTime          | 0.475      |
| ProcessExecTime         | 0.0594     |
| StdReturn               | 140        |
| Time                    | 865        |
| dLoss                   | 0.0336988  |
----------------------------------------
itr #68 | 
Mem: 670.558594
Obtaining samples...
Obtaining samples for iteration 68...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5102, #subsample_inputs: 5102
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.636      |
| AbsLearnSignalNew       | 0.636      |
| AbsLearningOld          | 0.636      |
| AverageDiscountedReturn | 229        |
| AveragePhiLoss          | 7.37495    |
| AveragePolicyStd        | 0.786602   |
| AverageReturn           | 729        |
| Entropy                 | 3.53394    |
| EnvExecTime             | 2.02       |
| ExplainedVariance       | 0.837      |
| Iteration               | 68         |
| ItrTime                 | 12.9       |
| LossAfter               | 0.426803   |
| LossBefore              | 0.44762    |
| MaxReturn               | 1.03e+03   |
| MeanKL                  | 0.00644766 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 484        |
| NumTrajs                | 22         |
| Perplexity              | 34.2585    |
| PolicyExecTime          | 0.491      |
| ProcessExecTime         | 0.0625     |
| StdReturn               | 132        |
| Time                    | 878        |
| dLoss                   | 0.0208161  |
----------------------------------------
itr #69 | 
Mem: 670.558594
Obtaining samples...
Obtaining samples for iteration 69...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5008, #subsample_inputs: 5008
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.797      |
| AbsLearnSignalNew       | 0.797      |
| AbsLearningOld          | 0.797      |
| AverageDiscountedReturn | 234        |
| AveragePhiLoss          | 8.53305    |
| AveragePolicyStd        | 0.785294   |
| AverageReturn           | 763        |
| Entropy                 | 3.52806    |
| EnvExecTime             | 1.84       |
| ExplainedVariance       | 0.944      |
| Iteration               | 69         |
| ItrTime                 | 12.5       |
| LossAfter               | -0.0802183 |
| LossBefore              | -0.0515377 |
| MaxReturn               | 927        |
| MeanKL                  | 0.00939613 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 618        |
| NumTrajs                | 21         |
| Perplexity              | 34.058     |
| PolicyExecTime          | 0.459      |
| ProcessExecTime         | 0.0564     |
| StdReturn               | 85.6       |
| Time                    | 891        |
| dLoss                   | 0.0286806  |
----------------------------------------
itr #70 | 
Mem: 670.558594
Obtaining samples...
Obtaining samples for iteration 70...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5034, #subsample_inputs: 5034
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.528      |
| AbsLearnSignalNew       | 0.528      |
| AbsLearningOld          | 0.528      |
| AverageDiscountedReturn | 232        |
| AveragePhiLoss          | 10.161     |
| AveragePolicyStd        | 0.784415   |
| AverageReturn           | 844        |
| Entropy                 | 3.52413    |
| EnvExecTime             | 1.87       |
| ExplainedVariance       | 0.633      |
| Iteration               | 70         |
| ItrTime                 | 12.7       |
| LossAfter               | 0.300647   |
| LossBefore              | 0.324642   |
| MaxReturn               | 1.23e+03   |
| MeanKL                  | 0.00675818 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 300        |
| NumTrajs                | 19         |
| Perplexity              | 33.9244    |
| PolicyExecTime          | 0.462      |
| ProcessExecTime         | 0.057      |
| StdReturn               | 226        |
| Time                    | 904        |
| dLoss                   | 0.0239946  |
----------------------------------------
itr #71 | 
Mem: 670.582031
Obtaining samples...
Obtaining samples for iteration 71...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5034, #subsample_inputs: 5034
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.785      |
| AbsLearnSignalNew       | 0.785      |
| AbsLearningOld          | 0.785      |
| AverageDiscountedReturn | 234        |
| AveragePhiLoss          | 9.36095    |
| AveragePolicyStd        | 0.782536   |
| AverageReturn           | 806        |
| Entropy                 | 3.51512    |
| EnvExecTime             | 1.91       |
| ExplainedVariance       | 0.904      |
| Iteration               | 71         |
| ItrTime                 | 12.7       |
| LossAfter               | 0.196479   |
| LossBefore              | 0.222784   |
| MaxReturn               | 1.19e+03   |
| MeanKL                  | 0.00641467 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 425        |
| NumTrajs                | 20         |
| Perplexity              | 33.62      |
| PolicyExecTime          | 0.483      |
| ProcessExecTime         | 0.0575     |
| StdReturn               | 149        |
| Time                    | 916        |
| dLoss                   | 0.0263048  |
----------------------------------------
itr #72 | 
Mem: 670.582031
Obtaining samples...
Obtaining samples for iteration 72...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5235, #subsample_inputs: 5235
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.614      |
| AbsLearnSignalNew       | 0.614      |
| AbsLearningOld          | 0.614      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 8.47524    |
| AveragePolicyStd        | 0.780858   |
| AverageReturn           | 990        |
| Entropy                 | 3.50712    |
| EnvExecTime             | 2.08       |
| ExplainedVariance       | 0.76       |
| Iteration               | 72         |
| ItrTime                 | 13.3       |
| LossAfter               | -0.661834  |
| LossBefore              | -0.643185  |
| MaxReturn               | 1.22e+03   |
| MeanKL                  | 0.00653092 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 690        |
| NumTrajs                | 17         |
| Perplexity              | 33.3521    |
| PolicyExecTime          | 0.519      |
| ProcessExecTime         | 0.0622     |
| StdReturn               | 167        |
| Time                    | 930        |
| dLoss                   | 0.0186485  |
----------------------------------------
itr #73 | 
Mem: 671.093750
Obtaining samples...
Obtaining samples for iteration 73...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5060, #subsample_inputs: 5060
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.527      |
| AbsLearnSignalNew       | 0.527      |
| AbsLearningOld          | 0.527      |
| AverageDiscountedReturn | 230        |
| AveragePhiLoss          | 7.69823    |
| AveragePolicyStd        | 0.782416   |
| AverageReturn           | 889        |
| Entropy                 | 3.51114    |
| EnvExecTime             | 1.88       |
| ExplainedVariance       | 0.48       |
| Iteration               | 73         |
| ItrTime                 | 12.7       |
| LossAfter               | 0.13821    |
| LossBefore              | 0.164673   |
| MaxReturn               | 1.56e+03   |
| MeanKL                  | 0.00984193 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 185        |
| NumTrajs                | 18         |
| Perplexity              | 33.4865    |
| PolicyExecTime          | 0.467      |
| ProcessExecTime         | 0.0572     |
| StdReturn               | 301        |
| Time                    | 943        |
| dLoss                   | 0.0264628  |
----------------------------------------
itr #74 | 
Mem: 671.093750
Obtaining samples...
Obtaining samples for iteration 74...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5087, #subsample_inputs: 5087
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.719      |
| AbsLearnSignalNew       | 0.719      |
| AbsLearningOld          | 0.719      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 8.47415    |
| AveragePolicyStd        | 0.790848   |
| AverageReturn           | 958        |
| Entropy                 | 3.54317    |
| EnvExecTime             | 1.9        |
| ExplainedVariance       | 0.66       |
| Iteration               | 74         |
| ItrTime                 | 12.8       |
| LossAfter               | 0.401768   |
| LossBefore              | 0.420592   |
| MaxReturn               | 2.03e+03   |
| MeanKL                  | 0.00670024 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 649        |
| NumTrajs                | 17         |
| Perplexity              | 34.5764    |
| PolicyExecTime          | 0.475      |
| ProcessExecTime         | 0.058      |
| StdReturn               | 310        |
| Time                    | 955        |
| dLoss                   | 0.0188233  |
----------------------------------------
itr #75 | 
Mem: 671.347656
Obtaining samples...
Obtaining samples for iteration 75...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5023, #subsample_inputs: 5023
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.664      |
| AbsLearnSignalNew       | 0.664      |
| AbsLearningOld          | 0.664      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 8.19022    |
| AveragePolicyStd        | 0.782229   |
| AverageReturn           | 1.01e+03   |
| Entropy                 | 3.50979    |
| EnvExecTime             | 1.88       |
| ExplainedVariance       | 0.737      |
| Iteration               | 75         |
| ItrTime                 | 12.7       |
| LossAfter               | -0.0103831 |
| LossBefore              | 0.0117357  |
| MaxReturn               | 1.79e+03   |
| MeanKL                  | 0.00998322 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 538        |
| NumTrajs                | 16         |
| Perplexity              | 33.4413    |
| PolicyExecTime          | 0.475      |
| ProcessExecTime         | 0.0565     |
| StdReturn               | 317        |
| Time                    | 968        |
| dLoss                   | 0.0221188  |
----------------------------------------
itr #76 | 
Mem: 671.347656
Obtaining samples...
Obtaining samples for iteration 76...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5065, #subsample_inputs: 5065
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.773      |
| AbsLearnSignalNew       | 0.773      |
| AbsLearningOld          | 0.773      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 8.43081    |
| AveragePolicyStd        | 0.784004   |
| AverageReturn           | 904        |
| Entropy                 | 3.5154     |
| EnvExecTime             | 1.88       |
| ExplainedVariance       | 0.882      |
| Iteration               | 76         |
| ItrTime                 | 12.7       |
| LossAfter               | -0.0713187 |
| LossBefore              | -0.0477513 |
| MaxReturn               | 1.41e+03   |
| MeanKL                  | 0.00643771 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 520        |
| NumTrajs                | 18         |
| Perplexity              | 33.6294    |
| PolicyExecTime          | 0.467      |
| ProcessExecTime         | 0.0571     |
| StdReturn               | 236        |
| Time                    | 981        |
| dLoss                   | 0.0235674  |
----------------------------------------
itr #77 | 
Mem: 671.347656
Obtaining samples...
Obtaining samples for iteration 77...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5139, #subsample_inputs: 5139
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.389      |
| AbsLearnSignalNew       | 0.389      |
| AbsLearningOld          | 0.389      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 7.67651    |
| AveragePolicyStd        | 0.785672   |
| AverageReturn           | 960        |
| Entropy                 | 3.52106    |
| EnvExecTime             | 1.91       |
| ExplainedVariance       | -1.18      |
| Iteration               | 77         |
| ItrTime                 | 12.9       |
| LossAfter               | 0.119033   |
| LossBefore              | 0.140729   |
| MaxReturn               | 2.05e+03   |
| MeanKL                  | 0.00980372 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 661        |
| NumTrajs                | 17         |
| Perplexity              | 33.8202    |
| PolicyExecTime          | 0.487      |
| ProcessExecTime         | 0.0578     |
| StdReturn               | 380        |
| Time                    | 994        |
| dLoss                   | 0.0216959  |
----------------------------------------
itr #78 | 
Mem: 671.347656
Obtaining samples...
Obtaining samples for iteration 78...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5090, #subsample_inputs: 5090
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.605      |
| AbsLearnSignalNew       | 0.605      |
| AbsLearningOld          | 0.605      |
| AverageDiscountedReturn | 222        |
| AveragePhiLoss          | 9.84432    |
| AveragePolicyStd        | 0.781037   |
| AverageReturn           | 770        |
| Entropy                 | 3.50641    |
| EnvExecTime             | 2.06       |
| ExplainedVariance       | 0.599      |
| Iteration               | 78         |
| ItrTime                 | 13         |
| LossAfter               | -0.539774  |
| LossBefore              | -0.503412  |
| MaxReturn               | 1.43e+03   |
| MeanKL                  | 0.00672646 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 123        |
| NumTrajs                | 21         |
| Perplexity              | 33.3285    |
| PolicyExecTime          | 0.511      |
| ProcessExecTime         | 0.0621     |
| StdReturn               | 302        |
| Time                    | 1.01e+03   |
| dLoss                   | 0.0363625  |
----------------------------------------
itr #79 | 
Mem: 671.347656
Obtaining samples...
Obtaining samples for iteration 79...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5113, #subsample_inputs: 5113
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.798      |
| AbsLearnSignalNew       | 0.798      |
| AbsLearningOld          | 0.798      |
| AverageDiscountedReturn | 236        |
| AveragePhiLoss          | 8.85446    |
| AveragePolicyStd        | 0.777686   |
| AverageReturn           | 823        |
| Entropy                 | 3.49359    |
| EnvExecTime             | 1.86       |
| ExplainedVariance       | 0.852      |
| Iteration               | 79         |
| ItrTime                 | 12.7       |
| LossAfter               | 0.163411   |
| LossBefore              | 0.195911   |
| MaxReturn               | 1.14e+03   |
| MeanKL                  | 0.00952493 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 568        |
| NumTrajs                | 20         |
| Perplexity              | 32.904     |
| PolicyExecTime          | 0.471      |
| ProcessExecTime         | 0.0563     |
| StdReturn               | 154        |
| Time                    | 1.02e+03   |
| dLoss                   | 0.0324998  |
----------------------------------------
itr #80 | 
Mem: 671.347656
Obtaining samples...
Obtaining samples for iteration 80...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5257, #subsample_inputs: 5257
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.582      |
| AbsLearnSignalNew       | 0.582      |
| AbsLearningOld          | 0.581      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 9.33477    |
| AveragePolicyStd        | 0.781177   |
| AverageReturn           | 845        |
| Entropy                 | 3.50555    |
| EnvExecTime             | 2.05       |
| ExplainedVariance       | 0.758      |
| Iteration               | 80         |
| ItrTime                 | 13.2       |
| LossAfter               | 0.0841977  |
| LossBefore              | 0.120412   |
| MaxReturn               | 1.18e+03   |
| MeanKL                  | 0.00977626 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 532        |
| NumTrajs                | 20         |
| Perplexity              | 33.2998    |
| PolicyExecTime          | 0.501      |
| ProcessExecTime         | 0.0642     |
| StdReturn               | 154        |
| Time                    | 1.03e+03   |
| dLoss                   | 0.0362144  |
----------------------------------------
itr #81 | 
Mem: 672.890625
Obtaining samples...
Obtaining samples for iteration 81...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5222, #subsample_inputs: 5222
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.725      |
| AbsLearnSignalNew       | 0.725      |
| AbsLearningOld          | 0.725      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 9.43871    |
| AveragePolicyStd        | 0.777335   |
| AverageReturn           | 841        |
| Entropy                 | 3.48957    |
| EnvExecTime             | 1.75       |
| ExplainedVariance       | 0.875      |
| Iteration               | 81         |
| ItrTime                 | 12.9       |
| LossAfter               | -0.357203  |
| LossBefore              | -0.331652  |
| MaxReturn               | 1.19e+03   |
| MeanKL                  | 0.00996617 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 639        |
| NumTrajs                | 20         |
| Perplexity              | 32.7719    |
| PolicyExecTime          | 0.445      |
| ProcessExecTime         | 0.0552     |
| StdReturn               | 138        |
| Time                    | 1.05e+03   |
| dLoss                   | 0.0255513  |
----------------------------------------
itr #82 | 
Mem: 674.437500
Obtaining samples...
Obtaining samples for iteration 82...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5148, #subsample_inputs: 5148
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.653      |
| AbsLearnSignalNew       | 0.653      |
| AbsLearningOld          | 0.653      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 8.74506    |
| AveragePolicyStd        | 0.773518   |
| AverageReturn           | 935        |
| Entropy                 | 3.47267    |
| EnvExecTime             | 1.92       |
| ExplainedVariance       | 0.845      |
| Iteration               | 82         |
| ItrTime                 | 12.9       |
| LossAfter               | -0.419896  |
| LossBefore              | -0.391118  |
| MaxReturn               | 1.44e+03   |
| MeanKL                  | 0.00977585 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 585        |
| NumTrajs                | 18         |
| Perplexity              | 32.2227    |
| PolicyExecTime          | 0.478      |
| ProcessExecTime         | 0.0578     |
| StdReturn               | 234        |
| Time                    | 1.06e+03   |
| dLoss                   | 0.0287781  |
----------------------------------------
itr #83 | 
Mem: 674.437500
Obtaining samples...
Obtaining samples for iteration 83...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5214, #subsample_inputs: 5214
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.481     |
| AbsLearnSignalNew       | 0.481     |
| AbsLearningOld          | 0.481     |
| AverageDiscountedReturn | 240       |
| AveragePhiLoss          | 10.4623   |
| AveragePolicyStd        | 0.774704  |
| AverageReturn           | 931       |
| Entropy                 | 3.47607   |
| EnvExecTime             | 1.88      |
| ExplainedVariance       | 0.352     |
| Iteration               | 83        |
| ItrTime                 | 13        |
| LossAfter               | -0.512633 |
| LossBefore              | -0.484635 |
| MaxReturn               | 1.47e+03  |
| MeanKL                  | 0.0066599 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 670       |
| NumTrajs                | 18        |
| Perplexity              | 32.3323   |
| PolicyExecTime          | 0.473     |
| ProcessExecTime         | 0.0572    |
| StdReturn               | 220       |
| Time                    | 1.07e+03  |
| dLoss                   | 0.0279978 |
---------------------------------------
itr #84 | 
Mem: 674.691406
Obtaining samples...
Obtaining samples for iteration 84...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5098, #subsample_inputs: 5098
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.704      |
| AbsLearnSignalNew       | 0.704      |
| AbsLearningOld          | 0.704      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 10.7415    |
| AveragePolicyStd        | 0.769425   |
| AverageReturn           | 873        |
| Entropy                 | 3.45521    |
| EnvExecTime             | 1.97       |
| ExplainedVariance       | 0.863      |
| Iteration               | 84         |
| ItrTime                 | 12.9       |
| LossAfter               | 0.47004    |
| LossBefore              | 0.506218   |
| MaxReturn               | 1.17e+03   |
| MeanKL                  | 0.00993429 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 637        |
| NumTrajs                | 19         |
| Perplexity              | 31.6651    |
| PolicyExecTime          | 0.484      |
| ProcessExecTime         | 0.0599     |
| StdReturn               | 156        |
| Time                    | 1.09e+03   |
| dLoss                   | 0.0361783  |
----------------------------------------
itr #85 | 
Mem: 674.691406
Obtaining samples...
Obtaining samples for iteration 85...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5031, #subsample_inputs: 5031
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.669      |
| AbsLearnSignalNew       | 0.669      |
| AbsLearningOld          | 0.669      |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 9.14308    |
| AveragePolicyStd        | 0.764337   |
| AverageReturn           | 860        |
| Entropy                 | 3.43388    |
| EnvExecTime             | 1.93       |
| ExplainedVariance       | 0.901      |
| Iteration               | 85         |
| ItrTime                 | 12.8       |
| LossAfter               | 0.137784   |
| LossBefore              | 0.159658   |
| MaxReturn               | 1.34e+03   |
| MeanKL                  | 0.00644648 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 619        |
| NumTrajs                | 19         |
| Perplexity              | 30.9965    |
| PolicyExecTime          | 0.493      |
| ProcessExecTime         | 0.058      |
| StdReturn               | 174        |
| Time                    | 1.1e+03    |
| dLoss                   | 0.0218741  |
----------------------------------------
itr #86 | 
Mem: 674.691406
Obtaining samples...
Obtaining samples for iteration 86...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5068, #subsample_inputs: 5068
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.753      |
| AbsLearnSignalNew       | 0.753      |
| AbsLearningOld          | 0.753      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 9.28154    |
| AveragePolicyStd        | 0.768485   |
| AverageReturn           | 871        |
| Entropy                 | 3.45288    |
| EnvExecTime             | 1.86       |
| ExplainedVariance       | 0.932      |
| Iteration               | 86         |
| ItrTime                 | 12.7       |
| LossAfter               | -0.25179   |
| LossBefore              | -0.231152  |
| MaxReturn               | 1.4e+03    |
| MeanKL                  | 0.00652243 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 646        |
| NumTrajs                | 19         |
| Perplexity              | 31.5912    |
| PolicyExecTime          | 0.461      |
| ProcessExecTime         | 0.0581     |
| StdReturn               | 182        |
| Time                    | 1.11e+03   |
| dLoss                   | 0.0206379  |
----------------------------------------
itr #87 | 
Mem: 674.691406
Obtaining samples...
Obtaining samples for iteration 87...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5208, #subsample_inputs: 5208
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.648      |
| AbsLearnSignalNew       | 0.648      |
| AbsLearningOld          | 0.648      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 9.89374    |
| AveragePolicyStd        | 0.76235    |
| AverageReturn           | 1e+03      |
| Entropy                 | 3.42933    |
| EnvExecTime             | 1.96       |
| ExplainedVariance       | 0.819      |
| Iteration               | 87         |
| ItrTime                 | 13.2       |
| LossAfter               | -0.35466   |
| LossBefore              | -0.33132   |
| MaxReturn               | 1.69e+03   |
| MeanKL                  | 0.00652679 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 633        |
| NumTrajs                | 17         |
| Perplexity              | 30.856     |
| PolicyExecTime          | 0.488      |
| ProcessExecTime         | 0.0618     |
| StdReturn               | 283        |
| Time                    | 1.12e+03   |
| dLoss                   | 0.0233401  |
----------------------------------------
itr #88 | 
Mem: 674.691406
Obtaining samples...
Obtaining samples for iteration 88...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5124, #subsample_inputs: 5124
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.722      |
| AbsLearnSignalNew       | 0.722      |
| AbsLearningOld          | 0.722      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 11.03      |
| AveragePolicyStd        | 0.755051   |
| AverageReturn           | 927        |
| Entropy                 | 3.40129    |
| EnvExecTime             | 1.9        |
| ExplainedVariance       | 0.876      |
| Iteration               | 88         |
| ItrTime                 | 12.8       |
| LossAfter               | 0.0590477  |
| LossBefore              | 0.0811155  |
| MaxReturn               | 1.24e+03   |
| MeanKL                  | 0.00648787 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 479        |
| NumTrajs                | 18         |
| Perplexity              | 30.0028    |
| PolicyExecTime          | 0.471      |
| ProcessExecTime         | 0.0583     |
| StdReturn               | 185        |
| Time                    | 1.14e+03   |
| dLoss                   | 0.0220678  |
----------------------------------------
itr #89 | 
Mem: 674.691406
Obtaining samples...
Obtaining samples for iteration 89...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5108, #subsample_inputs: 5108
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.548      |
| AbsLearnSignalNew       | 0.548      |
| AbsLearningOld          | 0.548      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 9.12635    |
| AveragePolicyStd        | 0.753833   |
| AverageReturn           | 1.05e+03   |
| Entropy                 | 3.39658    |
| EnvExecTime             | 1.9        |
| ExplainedVariance       | 0.691      |
| Iteration               | 89         |
| ItrTime                 | 12.9       |
| LossAfter               | 0.00994801 |
| LossBefore              | 0.0324126  |
| MaxReturn               | 1.56e+03   |
| MeanKL                  | 0.00659533 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 691        |
| NumTrajs                | 16         |
| Perplexity              | 29.8617    |
| PolicyExecTime          | 0.48       |
| ProcessExecTime         | 0.0571     |
| StdReturn               | 244        |
| Time                    | 1.15e+03   |
| dLoss                   | 0.0224646  |
----------------------------------------
itr #90 | 
Mem: 674.691406
Obtaining samples...
Obtaining samples for iteration 90...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5024, #subsample_inputs: 5024
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.77       |
| AbsLearnSignalNew       | 0.77       |
| AbsLearningOld          | 0.77       |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 9.80346    |
| AveragePolicyStd        | 0.753798   |
| AverageReturn           | 968        |
| Entropy                 | 3.39508    |
| EnvExecTime             | 2.03       |
| ExplainedVariance       | 0.934      |
| Iteration               | 90         |
| ItrTime                 | 12.9       |
| LossAfter               | -0.441373  |
| LossBefore              | -0.417052  |
| MaxReturn               | 1.25e+03   |
| MeanKL                  | 0.00959583 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 710        |
| NumTrajs                | 17         |
| Perplexity              | 29.817     |
| PolicyExecTime          | 0.499      |
| ProcessExecTime         | 0.0617     |
| StdReturn               | 163        |
| Time                    | 1.16e+03   |
| dLoss                   | 0.0243217  |
----------------------------------------
itr #91 | 
Mem: 674.691406
Obtaining samples...
Obtaining samples for iteration 91...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5011, #subsample_inputs: 5011
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.53       |
| AbsLearnSignalNew       | 0.53       |
| AbsLearningOld          | 0.53       |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 7.96273    |
| AveragePolicyStd        | 0.763629   |
| AverageReturn           | 901        |
| Entropy                 | 3.43455    |
| EnvExecTime             | 1.83       |
| ExplainedVariance       | 0.765      |
| Iteration               | 91         |
| ItrTime                 | 12.6       |
| LossAfter               | 0.387031   |
| LossBefore              | 0.41425    |
| MaxReturn               | 1.27e+03   |
| MeanKL                  | 0.00643009 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 416        |
| NumTrajs                | 18         |
| Perplexity              | 31.0176    |
| PolicyExecTime          | 0.462      |
| ProcessExecTime         | 0.0558     |
| StdReturn               | 169        |
| Time                    | 1.18e+03   |
| dLoss                   | 0.0272194  |
----------------------------------------
itr #92 | 
Mem: 674.691406
Obtaining samples...
Obtaining samples for iteration 92...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5248, #subsample_inputs: 5248
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.752      |
| AbsLearnSignalNew       | 0.752      |
| AbsLearningOld          | 0.752      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 9.60414    |
| AveragePolicyStd        | 0.760689   |
| AverageReturn           | 954        |
| Entropy                 | 3.42368    |
| EnvExecTime             | 1.84       |
| ExplainedVariance       | 0.904      |
| Iteration               | 92         |
| ItrTime                 | 13         |
| LossAfter               | -0.417995  |
| LossBefore              | -0.38703   |
| MaxReturn               | 1.27e+03   |
| MeanKL                  | 0.00932072 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 648        |
| NumTrajs                | 18         |
| Perplexity              | 30.682     |
| PolicyExecTime          | 0.46       |
| ProcessExecTime         | 0.0574     |
| StdReturn               | 182        |
| Time                    | 1.19e+03   |
| dLoss                   | 0.0309651  |
----------------------------------------
itr #93 | 
Mem: 674.691406
Obtaining samples...
Obtaining samples for iteration 93...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5080, #subsample_inputs: 5080
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.495      |
| AbsLearnSignalNew       | 0.495      |
| AbsLearningOld          | 0.495      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 10.9702    |
| AveragePolicyStd        | 0.757537   |
| AverageReturn           | 969        |
| Entropy                 | 3.41231    |
| EnvExecTime             | 2.01       |
| ExplainedVariance       | 0.621      |
| Iteration               | 93         |
| ItrTime                 | 12.9       |
| LossAfter               | -0.49366   |
| LossBefore              | -0.472453  |
| MaxReturn               | 1.2e+03    |
| MeanKL                  | 0.00646782 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 720        |
| NumTrajs                | 17         |
| Perplexity              | 30.3351    |
| PolicyExecTime          | 0.497      |
| ProcessExecTime         | 0.0619     |
| StdReturn               | 126        |
| Time                    | 1.2e+03    |
| dLoss                   | 0.0212074  |
----------------------------------------
itr #94 | 
Mem: 674.691406
Obtaining samples...
Obtaining samples for iteration 94...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5147, #subsample_inputs: 5147
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.641     |
| AbsLearnSignalNew       | 0.641     |
| AbsLearningOld          | 0.641     |
| AverageDiscountedReturn | 237       |
| AveragePhiLoss          | 10.3672   |
| AveragePolicyStd        | 0.753596  |
| AverageReturn           | 917       |
| Entropy                 | 3.39737   |
| EnvExecTime             | 2.14      |
| ExplainedVariance       | 0.547     |
| Iteration               | 94        |
| ItrTime                 | 13.2      |
| LossAfter               | 0.120982  |
| LossBefore              | 0.143307  |
| MaxReturn               | 1.45e+03  |
| MeanKL                  | 0.0066268 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 523       |
| NumTrajs                | 18        |
| Perplexity              | 29.8853   |
| PolicyExecTime          | 0.526     |
| ProcessExecTime         | 0.0632    |
| StdReturn               | 238       |
| Time                    | 1.22e+03  |
| dLoss                   | 0.0223248 |
---------------------------------------
itr #95 | 
Mem: 674.691406
Obtaining samples...
Obtaining samples for iteration 95...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5171, #subsample_inputs: 5171
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.755      |
| AbsLearnSignalNew       | 0.755      |
| AbsLearningOld          | 0.755      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 11.0044    |
| AveragePolicyStd        | 0.744261   |
| AverageReturn           | 993        |
| Entropy                 | 3.35944    |
| EnvExecTime             | 1.92       |
| ExplainedVariance       | 0.865      |
| Iteration               | 95         |
| ItrTime                 | 13         |
| LossAfter               | 0.0605911  |
| LossBefore              | 0.0851782  |
| MaxReturn               | 1.56e+03   |
| MeanKL                  | 0.00997229 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 643        |
| NumTrajs                | 17         |
| Perplexity              | 28.7732    |
| PolicyExecTime          | 0.483      |
| ProcessExecTime         | 0.0588     |
| StdReturn               | 220        |
| Time                    | 1.23e+03   |
| dLoss                   | 0.024587   |
----------------------------------------
itr #96 | 
Mem: 674.691406
Obtaining samples...
Obtaining samples for iteration 96...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5209, #subsample_inputs: 5209
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.52       |
| AbsLearnSignalNew       | 0.52       |
| AbsLearningOld          | 0.52       |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 10.5128    |
| AveragePolicyStd        | 0.734487   |
| AverageReturn           | 929        |
| Entropy                 | 3.3185     |
| EnvExecTime             | 2.04       |
| ExplainedVariance       | 0.57       |
| Iteration               | 96         |
| ItrTime                 | 13.2       |
| LossAfter               | -0.316795  |
| LossBefore              | -0.287043  |
| MaxReturn               | 1.47e+03   |
| MeanKL                  | 0.00937533 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 617        |
| NumTrajs                | 18         |
| Perplexity              | 27.619     |
| PolicyExecTime          | 0.506      |
| ProcessExecTime         | 0.0644     |
| StdReturn               | 205        |
| Time                    | 1.24e+03   |
| dLoss                   | 0.029753   |
----------------------------------------
itr #97 | 
Mem: 674.949219
Obtaining samples...
Obtaining samples for iteration 97...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5166, #subsample_inputs: 5166
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.684      |
| AbsLearnSignalNew       | 0.684      |
| AbsLearningOld          | 0.684      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 10.6338    |
| AveragePolicyStd        | 0.739091   |
| AverageReturn           | 1.05e+03   |
| Entropy                 | 3.33818    |
| EnvExecTime             | 2.02       |
| ExplainedVariance       | 0.775      |
| Iteration               | 97         |
| ItrTime                 | 13.1       |
| LossAfter               | 0.723975   |
| LossBefore              | 0.753648   |
| MaxReturn               | 1.47e+03   |
| MeanKL                  | 0.00968657 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 639        |
| NumTrajs                | 16         |
| Perplexity              | 28.1679    |
| PolicyExecTime          | 0.51       |
| ProcessExecTime         | 0.0605     |
| StdReturn               | 206        |
| Time                    | 1.26e+03   |
| dLoss                   | 0.0296723  |
----------------------------------------
itr #98 | 
Mem: 677.007812
Obtaining samples...
Obtaining samples for iteration 98...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5195, #subsample_inputs: 5195
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.612      |
| AbsLearnSignalNew       | 0.612      |
| AbsLearningOld          | 0.612      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 9.84848    |
| AveragePolicyStd        | 0.734538   |
| AverageReturn           | 1.2e+03    |
| Entropy                 | 3.32152    |
| EnvExecTime             | 2.02       |
| ExplainedVariance       | 0.714      |
| Iteration               | 98         |
| ItrTime                 | 13.1       |
| LossAfter               | -0.20294   |
| LossBefore              | -0.178523  |
| MaxReturn               | 1.65e+03   |
| MeanKL                  | 0.00672151 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 450        |
| NumTrajs                | 14         |
| Perplexity              | 27.7024    |
| PolicyExecTime          | 0.503      |
| ProcessExecTime         | 0.0616     |
| StdReturn               | 322        |
| Time                    | 1.27e+03   |
| dLoss                   | 0.0244164  |
----------------------------------------
itr #99 | 
Mem: 678.539062
Obtaining samples...
Obtaining samples for iteration 99...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5140, #subsample_inputs: 5140
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.749      |
| AbsLearnSignalNew       | 0.749      |
| AbsLearningOld          | 0.749      |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 9.89397    |
| AveragePolicyStd        | 0.732271   |
| AverageReturn           | 1.04e+03   |
| Entropy                 | 3.31225    |
| EnvExecTime             | 2.06       |
| ExplainedVariance       | 0.85       |
| Iteration               | 99         |
| ItrTime                 | 13.1       |
| LossAfter               | 0.0509154  |
| LossBefore              | 0.0763232  |
| MaxReturn               | 1.52e+03   |
| MeanKL                  | 0.00670899 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 373        |
| NumTrajs                | 16         |
| Perplexity              | 27.4469    |
| PolicyExecTime          | 0.521      |
| ProcessExecTime         | 0.0625     |
| StdReturn               | 267        |
| Time                    | 1.28e+03   |
| dLoss                   | 0.0254078  |
----------------------------------------
itr #100 | 
Mem: 678.539062
Obtaining samples...
Obtaining samples for iteration 100...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5126, #subsample_inputs: 5126
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.568      |
| AbsLearnSignalNew       | 0.568      |
| AbsLearningOld          | 0.568      |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 13.2898    |
| AveragePolicyStd        | 0.731894   |
| AverageReturn           | 965        |
| Entropy                 | 3.31084    |
| EnvExecTime             | 1.82       |
| ExplainedVariance       | 0.627      |
| Iteration               | 100        |
| ItrTime                 | 12.8       |
| LossAfter               | -0.374065  |
| LossBefore              | -0.350756  |
| MaxReturn               | 1.61e+03   |
| MeanKL                  | 0.00640236 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 617        |
| NumTrajs                | 17         |
| Perplexity              | 27.4082    |
| PolicyExecTime          | 0.465      |
| ProcessExecTime         | 0.0558     |
| StdReturn               | 247        |
| Time                    | 1.29e+03   |
| dLoss                   | 0.0233092  |
----------------------------------------
itr #101 | 
Mem: 678.539062
Obtaining samples...
Obtaining samples for iteration 101...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5210, #subsample_inputs: 5210
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.759      |
| AbsLearnSignalNew       | 0.759      |
| AbsLearningOld          | 0.759      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 11.3698    |
| AveragePolicyStd        | 0.725282   |
| AverageReturn           | 1.13e+03   |
| Entropy                 | 3.28189    |
| EnvExecTime             | 1.9        |
| ExplainedVariance       | 0.773      |
| Iteration               | 101        |
| ItrTime                 | 13         |
| LossAfter               | -0.536876  |
| LossBefore              | -0.505951  |
| MaxReturn               | 1.49e+03   |
| MeanKL                  | 0.00992497 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 732        |
| NumTrajs                | 15         |
| Perplexity              | 26.6261    |
| PolicyExecTime          | 0.481      |
| ProcessExecTime         | 0.0591     |
| StdReturn               | 212        |
| Time                    | 1.31e+03   |
| dLoss                   | 0.0309241  |
----------------------------------------
itr #102 | 
Mem: 678.539062
Obtaining samples...
Obtaining samples for iteration 102...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5239, #subsample_inputs: 5239
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.401      |
| AbsLearnSignalNew       | 0.401      |
| AbsLearningOld          | 0.401      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 9.47531    |
| AveragePolicyStd        | 0.728849   |
| AverageReturn           | 1.13e+03   |
| Entropy                 | 3.29687    |
| EnvExecTime             | 1.99       |
| ExplainedVariance       | -0.143     |
| Iteration               | 102        |
| ItrTime                 | 13.1       |
| LossAfter               | 0.910838   |
| LossBefore              | 0.933077   |
| MaxReturn               | 2.14e+03   |
| MeanKL                  | 0.00998855 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 739        |
| NumTrajs                | 15         |
| Perplexity              | 27.0279    |
| PolicyExecTime          | 0.507      |
| ProcessExecTime         | 0.0603     |
| StdReturn               | 342        |
| Time                    | 1.32e+03   |
| dLoss                   | 0.0222389  |
----------------------------------------
itr #103 | 
Mem: 678.796875
Obtaining samples...
Obtaining samples for iteration 103...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5462, #subsample_inputs: 5462
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.601     |
| AbsLearnSignalNew       | 0.601     |
| AbsLearningOld          | 0.601     |
| AverageDiscountedReturn | 232       |
| AveragePhiLoss          | 10.7059   |
| AveragePolicyStd        | 0.732489  |
| AverageReturn           | 929       |
| Entropy                 | 3.30835   |
| EnvExecTime             | 2.13      |
| ExplainedVariance       | 0.708     |
| Iteration               | 103       |
| ItrTime                 | 13.8      |
| LossAfter               | 0.336861  |
| LossBefore              | 0.36988   |
| MaxReturn               | 1.46e+03  |
| MeanKL                  | 0.0099384 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 267       |
| NumTrajs                | 19        |
| Perplexity              | 27.3401   |
| PolicyExecTime          | 0.531     |
| ProcessExecTime         | 0.0644    |
| StdReturn               | 284       |
| Time                    | 1.33e+03  |
| dLoss                   | 0.0330189 |
---------------------------------------
itr #104 | 
Mem: 680.859375
Obtaining samples...
Obtaining samples for iteration 104...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5130, #subsample_inputs: 5130
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.76      |
| AbsLearnSignalNew       | 0.76      |
| AbsLearningOld          | 0.76      |
| AverageDiscountedReturn | 243       |
| AveragePhiLoss          | 10.3383   |
| AveragePolicyStd        | 0.728703  |
| AverageReturn           | 992       |
| Entropy                 | 3.29232   |
| EnvExecTime             | 1.96      |
| ExplainedVariance       | 0.907     |
| Iteration               | 104       |
| ItrTime                 | 13        |
| LossAfter               | 0.0572565 |
| LossBefore              | 0.0832155 |
| MaxReturn               | 1.29e+03  |
| MeanKL                  | 0.0068822 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 720       |
| NumTrajs                | 17        |
| Perplexity              | 26.9053   |
| PolicyExecTime          | 0.496     |
| ProcessExecTime         | 0.0587    |
| StdReturn               | 164       |
| Time                    | 1.35e+03  |
| dLoss                   | 0.025959  |
---------------------------------------
itr #105 | 
Mem: 680.859375
Obtaining samples...
Obtaining samples for iteration 105...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5102, #subsample_inputs: 5102
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.565      |
| AbsLearnSignalNew       | 0.565      |
| AbsLearningOld          | 0.565      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 9.60692    |
| AveragePolicyStd        | 0.725113   |
| AverageReturn           | 922        |
| Entropy                 | 3.27686    |
| EnvExecTime             | 1.85       |
| ExplainedVariance       | 0.805      |
| Iteration               | 105        |
| ItrTime                 | 12.7       |
| LossAfter               | 0.31118    |
| LossBefore              | 0.331358   |
| MaxReturn               | 1.27e+03   |
| MeanKL                  | 0.00643227 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 711        |
| NumTrajs                | 18         |
| Perplexity              | 26.4924    |
| PolicyExecTime          | 0.468      |
| ProcessExecTime         | 0.0577     |
| StdReturn               | 128        |
| Time                    | 1.36e+03   |
| dLoss                   | 0.0201772  |
----------------------------------------
itr #106 | 
Mem: 680.859375
Obtaining samples...
Obtaining samples for iteration 106...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5142, #subsample_inputs: 5142
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.731     |
| AbsLearnSignalNew       | 0.731     |
| AbsLearningOld          | 0.73      |
| AverageDiscountedReturn | 243       |
| AveragePhiLoss          | 11.1186   |
| AveragePolicyStd        | 0.727058  |
| AverageReturn           | 942       |
| Entropy                 | 3.28601   |
| EnvExecTime             | 1.91      |
| ExplainedVariance       | 0.929     |
| Iteration               | 106       |
| ItrTime                 | 12.9      |
| LossAfter               | 0.094533  |
| LossBefore              | 0.120505  |
| MaxReturn               | 1.23e+03  |
| MeanKL                  | 0.0097741 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 719       |
| NumTrajs                | 18        |
| Perplexity              | 26.7359   |
| PolicyExecTime          | 0.479     |
| ProcessExecTime         | 0.0597    |
| StdReturn               | 122       |
| Time                    | 1.37e+03  |
| dLoss                   | 0.0259724 |
---------------------------------------
itr #107 | 
Mem: 680.859375
Obtaining samples...
Obtaining samples for iteration 107...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5023, #subsample_inputs: 5023
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.587      |
| AbsLearnSignalNew       | 0.587      |
| AbsLearningOld          | 0.587      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 14.6896    |
| AveragePolicyStd        | 0.726158   |
| AverageReturn           | 966        |
| Entropy                 | 3.28192    |
| EnvExecTime             | 1.9        |
| ExplainedVariance       | 0.894      |
| Iteration               | 107        |
| ItrTime                 | 12.7       |
| LossAfter               | -0.394944  |
| LossBefore              | -0.37082   |
| MaxReturn               | 1.47e+03   |
| MeanKL                  | 0.00654647 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 772        |
| NumTrajs                | 17         |
| Perplexity              | 26.6267    |
| PolicyExecTime          | 0.476      |
| ProcessExecTime         | 0.0579     |
| StdReturn               | 170        |
| Time                    | 1.39e+03   |
| dLoss                   | 0.0241232  |
----------------------------------------
itr #108 | 
Mem: 680.859375
Obtaining samples...
Obtaining samples for iteration 108...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5146, #subsample_inputs: 5146
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.77       |
| AbsLearnSignalNew       | 0.77       |
| AbsLearningOld          | 0.77       |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 11.5362    |
| AveragePolicyStd        | 0.720601   |
| AverageReturn           | 931        |
| Entropy                 | 3.26032    |
| EnvExecTime             | 1.87       |
| ExplainedVariance       | 0.938      |
| Iteration               | 108        |
| ItrTime                 | 12.9       |
| LossAfter               | 0.397209   |
| LossBefore              | 0.421927   |
| MaxReturn               | 1.33e+03   |
| MeanKL                  | 0.00650877 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 672        |
| NumTrajs                | 18         |
| Perplexity              | 26.0578    |
| PolicyExecTime          | 0.468      |
| ProcessExecTime         | 0.0578     |
| StdReturn               | 153        |
| Time                    | 1.4e+03    |
| dLoss                   | 0.0247175  |
----------------------------------------
itr #109 | 
Mem: 680.859375
Obtaining samples...
Obtaining samples for iteration 109...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5014, #subsample_inputs: 5014
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.738      |
| AbsLearnSignalNew       | 0.738      |
| AbsLearningOld          | 0.738      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 12.4211    |
| AveragePolicyStd        | 0.715417   |
| AverageReturn           | 1.03e+03   |
| Entropy                 | 3.23972    |
| EnvExecTime             | 1.99       |
| ExplainedVariance       | 0.935      |
| Iteration               | 109        |
| ItrTime                 | 12.8       |
| LossAfter               | 0.407707   |
| LossBefore              | 0.440922   |
| MaxReturn               | 1.42e+03   |
| MeanKL                  | 0.00991072 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 805        |
| NumTrajs                | 16         |
| Perplexity              | 25.5267    |
| PolicyExecTime          | 0.502      |
| ProcessExecTime         | 0.0591     |
| StdReturn               | 178        |
| Time                    | 1.41e+03   |
| dLoss                   | 0.0332157  |
----------------------------------------
itr #110 | 
Mem: 680.859375
Obtaining samples...
Obtaining samples for iteration 110...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5149, #subsample_inputs: 5149
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.525      |
| AbsLearnSignalNew       | 0.525      |
| AbsLearningOld          | 0.525      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 10.1359    |
| AveragePolicyStd        | 0.719552   |
| AverageReturn           | 986        |
| Entropy                 | 3.25644    |
| EnvExecTime             | 1.85       |
| ExplainedVariance       | 0.704      |
| Iteration               | 110        |
| ItrTime                 | 13         |
| LossAfter               | -0.386764  |
| LossBefore              | -0.359686  |
| MaxReturn               | 1.32e+03   |
| MeanKL                  | 0.00988372 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 721        |
| NumTrajs                | 17         |
| Perplexity              | 25.9569    |
| PolicyExecTime          | 0.469      |
| ProcessExecTime         | 0.0571     |
| StdReturn               | 158        |
| Time                    | 1.43e+03   |
| dLoss                   | 0.0270782  |
----------------------------------------
itr #111 | 
Mem: 680.859375
Obtaining samples...
Obtaining samples for iteration 111...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5243, #subsample_inputs: 5243
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.774      |
| AbsLearnSignalNew       | 0.774      |
| AbsLearningOld          | 0.774      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 10.6127    |
| AveragePolicyStd        | 0.72223    |
| AverageReturn           | 861        |
| Entropy                 | 3.26786    |
| EnvExecTime             | 1.88       |
| ExplainedVariance       | 0.909      |
| Iteration               | 111        |
| ItrTime                 | 13         |
| LossAfter               | -0.285979  |
| LossBefore              | -0.261644  |
| MaxReturn               | 1.14e+03   |
| MeanKL                  | 0.00989613 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 651        |
| NumTrajs                | 20         |
| Perplexity              | 26.255     |
| PolicyExecTime          | 0.472      |
| ProcessExecTime         | 0.0579     |
| StdReturn               | 121        |
| Time                    | 1.44e+03   |
| dLoss                   | 0.0243343  |
----------------------------------------
itr #112 | 
Mem: 680.859375
Obtaining samples...
Obtaining samples for iteration 112...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5105, #subsample_inputs: 5105
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.428      |
| AbsLearnSignalNew       | 0.428      |
| AbsLearningOld          | 0.428      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 11.422     |
| AveragePolicyStd        | 0.721978   |
| AverageReturn           | 1.04e+03   |
| Entropy                 | 3.26321    |
| EnvExecTime             | 1.92       |
| ExplainedVariance       | 0.254      |
| Iteration               | 112        |
| ItrTime                 | 12.8       |
| LossAfter               | 0.288005   |
| LossBefore              | 0.308631   |
| MaxReturn               | 1.57e+03   |
| MeanKL                  | 0.00666642 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 664        |
| NumTrajs                | 16         |
| Perplexity              | 26.1332    |
| PolicyExecTime          | 0.478      |
| ProcessExecTime         | 0.0584     |
| StdReturn               | 207        |
| Time                    | 1.45e+03   |
| dLoss                   | 0.0206255  |
----------------------------------------
itr #113 | 
Mem: 680.859375
Obtaining samples...
Obtaining samples for iteration 113...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5005, #subsample_inputs: 5005
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.72      |
| AbsLearnSignalNew       | 0.72      |
| AbsLearningOld          | 0.72      |
| AverageDiscountedReturn | 243       |
| AveragePhiLoss          | 11.8573   |
| AveragePolicyStd        | 0.720623  |
| AverageReturn           | 964       |
| Entropy                 | 3.25834   |
| EnvExecTime             | 2         |
| ExplainedVariance       | 0.939     |
| Iteration               | 113       |
| ItrTime                 | 12.8      |
| LossAfter               | 0.486177  |
| LossBefore              | 0.516613  |
| MaxReturn               | 1.28e+03  |
| MeanKL                  | 0.006592  |
| MeanKLBefore            | 0.0       |
| MinReturn               | 729       |
| NumTrajs                | 17        |
| Perplexity              | 26.0065   |
| PolicyExecTime          | 0.498     |
| ProcessExecTime         | 0.061     |
| StdReturn               | 128       |
| Time                    | 1.46e+03  |
| dLoss                   | 0.0304358 |
---------------------------------------
itr #114 | 
Mem: 680.859375
Obtaining samples...
Obtaining samples for iteration 114...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5040, #subsample_inputs: 5040
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.681     |
| AbsLearnSignalNew       | 0.681     |
| AbsLearningOld          | 0.68      |
| AverageDiscountedReturn | 244       |
| AveragePhiLoss          | 11.1622   |
| AveragePolicyStd        | 0.724287  |
| AverageReturn           | 1.03e+03  |
| Entropy                 | 3.27416   |
| EnvExecTime             | 1.87      |
| ExplainedVariance       | 0.914     |
| Iteration               | 114       |
| ItrTime                 | 12.7      |
| LossAfter               | 0.141459  |
| LossBefore              | 0.163457  |
| MaxReturn               | 1.47e+03  |
| MeanKL                  | 0.0064326 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 736       |
| NumTrajs                | 16        |
| Perplexity              | 26.421    |
| PolicyExecTime          | 0.471     |
| ProcessExecTime         | 0.0582    |
| StdReturn               | 198       |
| Time                    | 1.48e+03  |
| dLoss                   | 0.021998  |
---------------------------------------
itr #115 | 
Mem: 680.859375
Obtaining samples...
Obtaining samples for iteration 115...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5082, #subsample_inputs: 5082
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.476      |
| AbsLearnSignalNew       | 0.476      |
| AbsLearningOld          | 0.476      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 14.5866    |
| AveragePolicyStd        | 0.723409   |
| AverageReturn           | 1.02e+03   |
| Entropy                 | 3.26985    |
| EnvExecTime             | 2.01       |
| ExplainedVariance       | 0.535      |
| Iteration               | 115        |
| ItrTime                 | 12.9       |
| LossAfter               | 0.233397   |
| LossBefore              | 0.253837   |
| MaxReturn               | 1.53e+03   |
| MeanKL                  | 0.00662017 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 608        |
| NumTrajs                | 16         |
| Perplexity              | 26.3073    |
| PolicyExecTime          | 0.51       |
| ProcessExecTime         | 0.0595     |
| StdReturn               | 208        |
| Time                    | 1.49e+03   |
| dLoss                   | 0.02044    |
----------------------------------------
itr #116 | 
Mem: 680.859375
Obtaining samples...
Obtaining samples for iteration 116...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5197, #subsample_inputs: 5197
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.725      |
| AbsLearnSignalNew       | 0.725      |
| AbsLearningOld          | 0.725      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 11.9718    |
| AveragePolicyStd        | 0.715967   |
| AverageReturn           | 952        |
| Entropy                 | 3.23695    |
| EnvExecTime             | 1.98       |
| ExplainedVariance       | 0.854      |
| Iteration               | 116        |
| ItrTime                 | 13.1       |
| LossAfter               | -0.510826  |
| LossBefore              | -0.481876  |
| MaxReturn               | 1.21e+03   |
| MeanKL                  | 0.00965076 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 691        |
| NumTrajs                | 18         |
| Perplexity              | 25.4561    |
| PolicyExecTime          | 0.498      |
| ProcessExecTime         | 0.0604     |
| StdReturn               | 137        |
| Time                    | 1.5e+03    |
| dLoss                   | 0.0289503  |
----------------------------------------
itr #117 | 
Mem: 681.632812
Obtaining samples...
Obtaining samples for iteration 117...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5256, #subsample_inputs: 5256
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.58       |
| AbsLearnSignalNew       | 0.58       |
| AbsLearningOld          | 0.58       |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 13.1684    |
| AveragePolicyStd        | 0.717599   |
| AverageReturn           | 958        |
| Entropy                 | 3.24412    |
| EnvExecTime             | 1.79       |
| ExplainedVariance       | 0.829      |
| Iteration               | 117        |
| ItrTime                 | 12.9       |
| LossAfter               | 0.263929   |
| LossBefore              | 0.284753   |
| MaxReturn               | 1.25e+03   |
| MeanKL                  | 0.00660173 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 681        |
| NumTrajs                | 18         |
| Perplexity              | 25.6392    |
| PolicyExecTime          | 0.456      |
| ProcessExecTime         | 0.0553     |
| StdReturn               | 132        |
| Time                    | 1.52e+03   |
| dLoss                   | 0.0208238  |
----------------------------------------
itr #118 | 
Mem: 681.890625
Obtaining samples...
Obtaining samples for iteration 118...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5086, #subsample_inputs: 5086
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.519      |
| AbsLearnSignalNew       | 0.519      |
| AbsLearningOld          | 0.519      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 11.6133    |
| AveragePolicyStd        | 0.717699   |
| AverageReturn           | 1.04e+03   |
| Entropy                 | 3.24435    |
| EnvExecTime             | 2.07       |
| ExplainedVariance       | 0.509      |
| Iteration               | 118        |
| ItrTime                 | 13.1       |
| LossAfter               | 0.156005   |
| LossBefore              | 0.188251   |
| MaxReturn               | 1.68e+03   |
| MeanKL                  | 0.00963668 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 440        |
| NumTrajs                | 16         |
| Perplexity              | 25.645     |
| PolicyExecTime          | 0.512      |
| ProcessExecTime         | 0.0628     |
| StdReturn               | 287        |
| Time                    | 1.53e+03   |
| dLoss                   | 0.032246   |
----------------------------------------
itr #119 | 
Mem: 681.890625
Obtaining samples...
Obtaining samples for iteration 119...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5256, #subsample_inputs: 5256
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.776      |
| AbsLearnSignalNew       | 0.776      |
| AbsLearningOld          | 0.776      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 11.2273    |
| AveragePolicyStd        | 0.714111   |
| AverageReturn           | 960        |
| Entropy                 | 3.23134    |
| EnvExecTime             | 1.83       |
| ExplainedVariance       | 0.879      |
| Iteration               | 119        |
| ItrTime                 | 13.1       |
| LossAfter               | -0.150176  |
| LossBefore              | -0.12776   |
| MaxReturn               | 1.57e+03   |
| MeanKL                  | 0.00644505 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 725        |
| NumTrajs                | 18         |
| Perplexity              | 25.3134    |
| PolicyExecTime          | 0.464      |
| ProcessExecTime         | 0.0564     |
| StdReturn               | 221        |
| Time                    | 1.54e+03   |
| dLoss                   | 0.0224159  |
----------------------------------------
itr #120 | 
Mem: 682.406250
Obtaining samples...
Obtaining samples for iteration 120...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5010, #subsample_inputs: 5010
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.773      |
| AbsLearnSignalNew       | 0.773      |
| AbsLearningOld          | 0.773      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 12.3998    |
| AveragePolicyStd        | 0.709932   |
| AverageReturn           | 975        |
| Entropy                 | 3.21556    |
| EnvExecTime             | 1.86       |
| ExplainedVariance       | 0.953      |
| Iteration               | 120        |
| ItrTime                 | 12.7       |
| LossAfter               | 0.250362   |
| LossBefore              | 0.279515   |
| MaxReturn               | 1.29e+03   |
| MeanKL                  | 0.00981545 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 744        |
| NumTrajs                | 17         |
| Perplexity              | 24.9172    |
| PolicyExecTime          | 0.477      |
| ProcessExecTime         | 0.0557     |
| StdReturn               | 141        |
| Time                    | 1.56e+03   |
| dLoss                   | 0.0291528  |
----------------------------------------
itr #121 | 
Mem: 682.406250
Obtaining samples...
Obtaining samples for iteration 121...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5226, #subsample_inputs: 5226
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.602      |
| AbsLearnSignalNew       | 0.602      |
| AbsLearningOld          | 0.602      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 11.0082    |
| AveragePolicyStd        | 0.708868   |
| AverageReturn           | 1.07e+03   |
| Entropy                 | 3.2083     |
| EnvExecTime             | 2.14       |
| ExplainedVariance       | 0.86       |
| Iteration               | 121        |
| ItrTime                 | 13.5       |
| LossAfter               | 0.397036   |
| LossBefore              | 0.426374   |
| MaxReturn               | 1.53e+03   |
| MeanKL                  | 0.00983744 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 775        |
| NumTrajs                | 16         |
| Perplexity              | 24.7369    |
| PolicyExecTime          | 0.523      |
| ProcessExecTime         | 0.0645     |
| StdReturn               | 203        |
| Time                    | 1.57e+03   |
| dLoss                   | 0.0293379  |
----------------------------------------
itr #122 | 
Mem: 682.406250
Obtaining samples...
Obtaining samples for iteration 122...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5151, #subsample_inputs: 5151
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.565      |
| AbsLearnSignalNew       | 0.565      |
| AbsLearningOld          | 0.565      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 10.9876    |
| AveragePolicyStd        | 0.711068   |
| AverageReturn           | 1.11e+03   |
| Entropy                 | 3.21868    |
| EnvExecTime             | 2.16       |
| ExplainedVariance       | 0.741      |
| Iteration               | 122        |
| ItrTime                 | 13.2       |
| LossAfter               | -0.320381  |
| LossBefore              | -0.294924  |
| MaxReturn               | 1.94e+03   |
| MeanKL                  | 0.00967758 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 632        |
| NumTrajs                | 15         |
| Perplexity              | 24.995     |
| PolicyExecTime          | 0.543      |
| ProcessExecTime         | 0.0666     |
| StdReturn               | 284        |
| Time                    | 1.58e+03   |
| dLoss                   | 0.0254569  |
----------------------------------------
itr #123 | 
Mem: 682.406250
Obtaining samples...
Obtaining samples for iteration 123...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5426, #subsample_inputs: 5426
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.725      |
| AbsLearnSignalNew       | 0.725      |
| AbsLearningOld          | 0.725      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 10.9914    |
| AveragePolicyStd        | 0.715061   |
| AverageReturn           | 1.2e+03    |
| Entropy                 | 3.23507    |
| EnvExecTime             | 2.12       |
| ExplainedVariance       | 0.896      |
| Iteration               | 123        |
| ItrTime                 | 13.9       |
| LossAfter               | -0.0892388 |
| LossBefore              | -0.070209  |
| MaxReturn               | 1.7e+03    |
| MeanKL                  | 0.00661433 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 946        |
| NumTrajs                | 15         |
| Perplexity              | 25.4081    |
| PolicyExecTime          | 0.531      |
| ProcessExecTime         | 0.0644     |
| StdReturn               | 203        |
| Time                    | 1.6e+03    |
| dLoss                   | 0.0190298  |
----------------------------------------
itr #124 | 
Mem: 683.179688
Obtaining samples...
Obtaining samples for iteration 124...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5020, #subsample_inputs: 5020
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.767      |
| AbsLearnSignalNew       | 0.767      |
| AbsLearningOld          | 0.767      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 12.3505    |
| AveragePolicyStd        | 0.713315   |
| AverageReturn           | 1.03e+03   |
| Entropy                 | 3.23064    |
| EnvExecTime             | 2.1        |
| ExplainedVariance       | 0.934      |
| Iteration               | 124        |
| ItrTime                 | 13         |
| LossAfter               | -0.386364  |
| LossBefore              | -0.365842  |
| MaxReturn               | 1.41e+03   |
| MeanKL                  | 0.00656525 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 599        |
| NumTrajs                | 16         |
| Perplexity              | 25.296     |
| PolicyExecTime          | 0.516      |
| ProcessExecTime         | 0.0636     |
| StdReturn               | 218        |
| Time                    | 1.61e+03   |
| dLoss                   | 0.0205213  |
----------------------------------------
itr #125 | 
Mem: 683.179688
Obtaining samples...
Obtaining samples for iteration 125...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5073, #subsample_inputs: 5073
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.287      |
| AbsLearnSignalNew       | 0.287      |
| AbsLearningOld          | 0.287      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 17.5798    |
| AveragePolicyStd        | 0.708304   |
| AverageReturn           | 1.17e+03   |
| Entropy                 | 3.20894    |
| EnvExecTime             | 1.97       |
| ExplainedVariance       | -8.21      |
| Iteration               | 125        |
| ItrTime                 | 12.8       |
| LossAfter               | 0.66663    |
| LossBefore              | 0.704944   |
| MaxReturn               | 2.56e+03   |
| MeanKL                  | 0.00911974 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 890        |
| NumTrajs                | 14         |
| Perplexity              | 24.7529    |
| PolicyExecTime          | 0.504      |
| ProcessExecTime         | 0.059      |
| StdReturn               | 439        |
| Time                    | 1.62e+03   |
| dLoss                   | 0.0383145  |
----------------------------------------
itr #126 | 
Mem: 683.429688
Obtaining samples...
Obtaining samples for iteration 126...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5269, #subsample_inputs: 5269
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.578      |
| AbsLearnSignalNew       | 0.578      |
| AbsLearningOld          | 0.578      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 12.7068    |
| AveragePolicyStd        | 0.701807   |
| AverageReturn           | 1.06e+03   |
| Entropy                 | 3.18074    |
| EnvExecTime             | 1.86       |
| ExplainedVariance       | 0.636      |
| Iteration               | 126        |
| ItrTime                 | 13         |
| LossAfter               | 0.404256   |
| LossBefore              | 0.438039   |
| MaxReturn               | 1.77e+03   |
| MeanKL                  | 0.00981883 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 637        |
| NumTrajs                | 16         |
| Perplexity              | 24.0646    |
| PolicyExecTime          | 0.471      |
| ProcessExecTime         | 0.0573     |
| StdReturn               | 285        |
| Time                    | 1.64e+03   |
| dLoss                   | 0.0337823  |
----------------------------------------
itr #127 | 
Mem: 685.722656
Obtaining samples...
Obtaining samples for iteration 127...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5411, #subsample_inputs: 5411
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.737      |
| AbsLearnSignalNew       | 0.737      |
| AbsLearningOld          | 0.737      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 12.1962    |
| AveragePolicyStd        | 0.696664   |
| AverageReturn           | 1.19e+03   |
| Entropy                 | 3.15963    |
| EnvExecTime             | 2.13       |
| ExplainedVariance       | 0.879      |
| Iteration               | 127        |
| ItrTime                 | 13.7       |
| LossAfter               | 0.269545   |
| LossBefore              | 0.292807   |
| MaxReturn               | 1.54e+03   |
| MeanKL                  | 0.00641144 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 877        |
| NumTrajs                | 15         |
| Perplexity              | 23.5619    |
| PolicyExecTime          | 0.523      |
| ProcessExecTime         | 0.066      |
| StdReturn               | 176        |
| Time                    | 1.65e+03   |
| dLoss                   | 0.0232626  |
----------------------------------------
itr #128 | 
Mem: 686.496094
Obtaining samples...
Obtaining samples for iteration 128...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5023, #subsample_inputs: 5023
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.722     |
| AbsLearnSignalNew       | 0.722     |
| AbsLearningOld          | 0.721     |
| AverageDiscountedReturn | 245       |
| AveragePhiLoss          | 12.4893   |
| AveragePolicyStd        | 0.691419  |
| AverageReturn           | 1.27e+03  |
| Entropy                 | 3.13735   |
| EnvExecTime             | 1.98      |
| ExplainedVariance       | 0.928     |
| Iteration               | 128       |
| ItrTime                 | 12.8      |
| LossAfter               | 0.0293592 |
| LossBefore              | 0.0523666 |
| MaxReturn               | 1.83e+03  |
| MeanKL                  | 0.0065681 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 917       |
| NumTrajs                | 13        |
| Perplexity              | 23.0427   |
| PolicyExecTime          | 0.504     |
| ProcessExecTime         | 0.0612    |
| StdReturn               | 265       |
| Time                    | 1.66e+03  |
| dLoss                   | 0.0230074 |
---------------------------------------
itr #129 | 
Mem: 686.496094
Obtaining samples...
Obtaining samples for iteration 129...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5287, #subsample_inputs: 5287
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.779      |
| AbsLearnSignalNew       | 0.779      |
| AbsLearningOld          | 0.779      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 13.0315    |
| AveragePolicyStd        | 0.687668   |
| AverageReturn           | 1.16e+03   |
| Entropy                 | 3.12034    |
| EnvExecTime             | 1.93       |
| ExplainedVariance       | 0.928      |
| Iteration               | 129        |
| ItrTime                 | 13.1       |
| LossAfter               | 0.0682703  |
| LossBefore              | 0.0907976  |
| MaxReturn               | 1.74e+03   |
| MeanKL                  | 0.00640368 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 723        |
| NumTrajs                | 15         |
| Perplexity              | 22.654     |
| PolicyExecTime          | 0.489      |
| ProcessExecTime         | 0.0583     |
| StdReturn               | 300        |
| Time                    | 1.68e+03   |
| dLoss                   | 0.0225273  |
----------------------------------------
itr #130 | 
Mem: 686.503906
Obtaining samples...
Obtaining samples for iteration 130...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5070, #subsample_inputs: 5070
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.531      |
| AbsLearnSignalNew       | 0.531      |
| AbsLearningOld          | 0.531      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 12.1504    |
| AveragePolicyStd        | 0.687571   |
| AverageReturn           | 1.38e+03   |
| Entropy                 | 3.11923    |
| EnvExecTime             | 1.94       |
| ExplainedVariance       | 0.295      |
| Iteration               | 130        |
| ItrTime                 | 12.8       |
| LossAfter               | 0.606759   |
| LossBefore              | 0.635319   |
| MaxReturn               | 2.83e+03   |
| MeanKL                  | 0.00980932 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 879        |
| NumTrajs                | 12         |
| Perplexity              | 22.6289    |
| PolicyExecTime          | 0.488      |
| ProcessExecTime         | 0.061      |
| StdReturn               | 475        |
| Time                    | 1.69e+03   |
| dLoss                   | 0.0285603  |
----------------------------------------
itr #131 | 
Mem: 686.753906
Obtaining samples...
Obtaining samples for iteration 131...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5058, #subsample_inputs: 5058
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.761      |
| AbsLearnSignalNew       | 0.761      |
| AbsLearningOld          | 0.76       |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 12.7937    |
| AveragePolicyStd        | 0.688398   |
| AverageReturn           | 1.5e+03    |
| Entropy                 | 3.12092    |
| EnvExecTime             | 2.1        |
| ExplainedVariance       | 0.888      |
| Iteration               | 131        |
| ItrTime                 | 13         |
| LossAfter               | -0.289072  |
| LossBefore              | -0.258969  |
| MaxReturn               | 2.23e+03   |
| MeanKL                  | 0.00964468 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 891        |
| NumTrajs                | 11         |
| Perplexity              | 22.6673    |
| PolicyExecTime          | 0.539      |
| ProcessExecTime         | 0.0616     |
| StdReturn               | 409        |
| Time                    | 1.7e+03    |
| dLoss                   | 0.0301026  |
----------------------------------------
itr #132 | 
Mem: 686.753906
Obtaining samples...
Obtaining samples for iteration 132...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5498, #subsample_inputs: 5498
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.576      |
| AbsLearnSignalNew       | 0.576      |
| AbsLearningOld          | 0.576      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 13.2088    |
| AveragePolicyStd        | 0.689563   |
| AverageReturn           | 1.54e+03   |
| Entropy                 | 3.12613    |
| EnvExecTime             | 2.07       |
| ExplainedVariance       | 0.466      |
| Iteration               | 132        |
| ItrTime                 | 13.6       |
| LossAfter               | -0.493459  |
| LossBefore              | -0.469142  |
| MaxReturn               | 2.4e+03    |
| MeanKL                  | 0.00957742 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 720        |
| NumTrajs                | 11         |
| Perplexity              | 22.7855    |
| PolicyExecTime          | 0.527      |
| ProcessExecTime         | 0.0628     |
| StdReturn               | 496        |
| Time                    | 1.72e+03   |
| dLoss                   | 0.0243171  |
----------------------------------------
itr #133 | 
Mem: 686.753906
Obtaining samples...
Obtaining samples for iteration 133...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5126, #subsample_inputs: 5126
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.692     |
| AbsLearnSignalNew       | 0.692     |
| AbsLearningOld          | 0.692     |
| AverageDiscountedReturn | 243       |
| AveragePhiLoss          | 11.6345   |
| AveragePolicyStd        | 0.690028  |
| AverageReturn           | 1.62e+03  |
| Entropy                 | 3.12754   |
| EnvExecTime             | 2.13      |
| ExplainedVariance       | 0.675     |
| Iteration               | 133       |
| ItrTime                 | 13.1      |
| LossAfter               | 0.493825  |
| LossBefore              | 0.517158  |
| MaxReturn               | 2.29e+03  |
| MeanKL                  | 0.0066798 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.12e+03  |
| NumTrajs                | 10        |
| Perplexity              | 22.8178   |
| PolicyExecTime          | 0.536     |
| ProcessExecTime         | 0.0666    |
| StdReturn               | 385       |
| Time                    | 1.73e+03  |
| dLoss                   | 0.0233328 |
---------------------------------------
itr #134 | 
Mem: 686.753906
Obtaining samples...
Obtaining samples for iteration 134...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5648, #subsample_inputs: 5648
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.711      |
| AbsLearnSignalNew       | 0.711      |
| AbsLearningOld          | 0.711      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 12.9837    |
| AveragePolicyStd        | 0.687608   |
| AverageReturn           | 1.8e+03    |
| Entropy                 | 3.1189     |
| EnvExecTime             | 2.3        |
| ExplainedVariance       | 0.789      |
| Iteration               | 134        |
| ItrTime                 | 14.1       |
| LossAfter               | 0.676043   |
| LossBefore              | 0.699629   |
| MaxReturn               | 3.01e+03   |
| MeanKL                  | 0.00642962 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.22e+03   |
| NumTrajs                | 10         |
| Perplexity              | 22.6215    |
| PolicyExecTime          | 0.582      |
| ProcessExecTime         | 0.0689     |
| StdReturn               | 577        |
| Time                    | 1.74e+03   |
| dLoss                   | 0.0235855  |
----------------------------------------
itr #135 | 
Mem: 687.503906
Obtaining samples...
Obtaining samples for iteration 135...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5509, #subsample_inputs: 5509
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.721      |
| AbsLearnSignalNew       | 0.721      |
| AbsLearningOld          | 0.721      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 12.9282    |
| AveragePolicyStd        | 0.683858   |
| AverageReturn           | 1.72e+03   |
| Entropy                 | 3.10232    |
| EnvExecTime             | 2.31       |
| ExplainedVariance       | 0.828      |
| Iteration               | 135        |
| ItrTime                 | 13.9       |
| LossAfter               | 0.527567   |
| LossBefore              | 0.554471   |
| MaxReturn               | 2.89e+03   |
| MeanKL                  | 0.00997263 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.36e+03   |
| NumTrajs                | 10         |
| Perplexity              | 22.2496    |
| PolicyExecTime          | 0.593      |
| ProcessExecTime         | 0.0677     |
| StdReturn               | 470        |
| Time                    | 1.76e+03   |
| dLoss                   | 0.0269042  |
----------------------------------------
itr #136 | 
Mem: 687.804688
Obtaining samples...
Obtaining samples for iteration 136...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5189, #subsample_inputs: 5189
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.768      |
| AbsLearnSignalNew       | 0.768      |
| AbsLearningOld          | 0.768      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 13.5661    |
| AveragePolicyStd        | 0.680844   |
| AverageReturn           | 1.81e+03   |
| Entropy                 | 3.08836    |
| EnvExecTime             | 2.25       |
| ExplainedVariance       | 0.825      |
| Iteration               | 136        |
| ItrTime                 | 13.5       |
| LossAfter               | 0.426247   |
| LossBefore              | 0.450675   |
| MaxReturn               | 2.84e+03   |
| MeanKL                  | 0.00654379 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.19e+03   |
| NumTrajs                | 9          |
| Perplexity              | 21.9411    |
| PolicyExecTime          | 0.566      |
| ProcessExecTime         | 0.0655     |
| StdReturn               | 575        |
| Time                    | 1.77e+03   |
| dLoss                   | 0.0244277  |
----------------------------------------
itr #137 | 
Mem: 687.804688
Obtaining samples...
Obtaining samples for iteration 137...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5276, #subsample_inputs: 5276
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.706      |
| AbsLearnSignalNew       | 0.706      |
| AbsLearningOld          | 0.706      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 14.0124    |
| AveragePolicyStd        | 0.680451   |
| AverageReturn           | 1.65e+03   |
| Entropy                 | 3.08587    |
| EnvExecTime             | 2.13       |
| ExplainedVariance       | 0.807      |
| Iteration               | 137        |
| ItrTime                 | 13.4       |
| LossAfter               | -0.216043  |
| LossBefore              | -0.192504  |
| MaxReturn               | 2.9e+03    |
| MeanKL                  | 0.00652345 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.16e+03   |
| NumTrajs                | 10         |
| Perplexity              | 21.8866    |
| PolicyExecTime          | 0.547      |
| ProcessExecTime         | 0.0637     |
| StdReturn               | 587        |
| Time                    | 1.78e+03   |
| dLoss                   | 0.0235385  |
----------------------------------------
itr #138 | 
Mem: 687.804688
Obtaining samples...
Obtaining samples for iteration 138...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5328, #subsample_inputs: 5328
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.724      |
| AbsLearnSignalNew       | 0.724      |
| AbsLearningOld          | 0.724      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 12.1103    |
| AveragePolicyStd        | 0.676064   |
| AverageReturn           | 1.71e+03   |
| Entropy                 | 3.06742    |
| EnvExecTime             | 2.12       |
| ExplainedVariance       | 0.841      |
| Iteration               | 138        |
| ItrTime                 | 13.6       |
| LossAfter               | 0.297797   |
| LossBefore              | 0.327136   |
| MaxReturn               | 3.16e+03   |
| MeanKL                  | 0.00979641 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 857        |
| NumTrajs                | 10         |
| Perplexity              | 21.4864    |
| PolicyExecTime          | 0.545      |
| ProcessExecTime         | 0.0633     |
| StdReturn               | 751        |
| Time                    | 1.8e+03    |
| dLoss                   | 0.0293386  |
----------------------------------------
itr #139 | 
Mem: 687.804688
Obtaining samples...
Obtaining samples for iteration 139...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5100, #subsample_inputs: 5100
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.773     |
| AbsLearnSignalNew       | 0.773     |
| AbsLearningOld          | 0.773     |
| AverageDiscountedReturn | 249       |
| AveragePhiLoss          | 14.0009   |
| AveragePolicyStd        | 0.680128  |
| AverageReturn           | 1.68e+03  |
| Entropy                 | 3.08626   |
| EnvExecTime             | 2.08      |
| ExplainedVariance       | 0.817     |
| Iteration               | 139       |
| ItrTime                 | 13.1      |
| LossAfter               | -0.685038 |
| LossBefore              | -0.662117 |
| MaxReturn               | 2.28e+03  |
| MeanKL                  | 0.0066848 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 955       |
| NumTrajs                | 10        |
| Perplexity              | 21.8951   |
| PolicyExecTime          | 0.519     |
| ProcessExecTime         | 0.0613    |
| StdReturn               | 449       |
| Time                    | 1.81e+03  |
| dLoss                   | 0.0229203 |
---------------------------------------
itr #140 | 
Mem: 687.804688
Obtaining samples...
Obtaining samples for iteration 140...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5130, #subsample_inputs: 5130
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.612      |
| AbsLearnSignalNew       | 0.612      |
| AbsLearningOld          | 0.612      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 14.5177    |
| AveragePolicyStd        | 0.672818   |
| AverageReturn           | 1.49e+03   |
| Entropy                 | 3.05306    |
| EnvExecTime             | 2.26       |
| ExplainedVariance       | 0.652      |
| Iteration               | 140        |
| ItrTime                 | 13.3       |
| LossAfter               | -0.189831  |
| LossBefore              | -0.169862  |
| MaxReturn               | 2.94e+03   |
| MeanKL                  | 0.00648921 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 675        |
| NumTrajs                | 11         |
| Perplexity              | 21.1801    |
| PolicyExecTime          | 0.564      |
| ProcessExecTime         | 0.0677     |
| StdReturn               | 600        |
| Time                    | 1.82e+03   |
| dLoss                   | 0.0199688  |
----------------------------------------
itr #141 | 
Mem: 688.429688
Obtaining samples...
Obtaining samples for iteration 141...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5082, #subsample_inputs: 5082
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.767      |
| AbsLearnSignalNew       | 0.767      |
| AbsLearningOld          | 0.767      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 14.4561    |
| AveragePolicyStd        | 0.671959   |
| AverageReturn           | 1.68e+03   |
| Entropy                 | 3.04971    |
| EnvExecTime             | 2.47       |
| ExplainedVariance       | 0.807      |
| Iteration               | 141        |
| ItrTime                 | 13.6       |
| LossAfter               | -0.0566417 |
| LossBefore              | -0.0364948 |
| MaxReturn               | 3.31e+03   |
| MeanKL                  | 0.00641198 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 714        |
| NumTrajs                | 10         |
| Perplexity              | 21.1093    |
| PolicyExecTime          | 0.613      |
| ProcessExecTime         | 0.0715     |
| StdReturn               | 780        |
| Time                    | 1.84e+03   |
| dLoss                   | 0.0201469  |
----------------------------------------
itr #142 | 
Mem: 688.941406
Obtaining samples...
Obtaining samples for iteration 142...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5344, #subsample_inputs: 5344
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.753      |
| AbsLearnSignalNew       | 0.753      |
| AbsLearningOld          | 0.753      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 13.91      |
| AveragePolicyStd        | 0.664968   |
| AverageReturn           | 2.14e+03   |
| Entropy                 | 3.01868    |
| EnvExecTime             | 2.31       |
| ExplainedVariance       | 0.737      |
| Iteration               | 142        |
| ItrTime                 | 13.8       |
| LossAfter               | 0.179017   |
| LossBefore              | 0.197992   |
| MaxReturn               | 3.22e+03   |
| MeanKL                  | 0.00653113 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.39e+03   |
| NumTrajs                | 8          |
| Perplexity              | 20.4642    |
| PolicyExecTime          | 0.591      |
| ProcessExecTime         | 0.0692     |
| StdReturn               | 749        |
| Time                    | 1.85e+03   |
| dLoss                   | 0.0189755  |
----------------------------------------
itr #143 | 
Mem: 689.968750
Obtaining samples...
Obtaining samples for iteration 143...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5113, #subsample_inputs: 5113
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.729      |
| AbsLearnSignalNew       | 0.729      |
| AbsLearningOld          | 0.729      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 15.5903    |
| AveragePolicyStd        | 0.661125   |
| AverageReturn           | 2.52e+03   |
| Entropy                 | 3.00309    |
| EnvExecTime             | 1.71       |
| ExplainedVariance       | 0.794      |
| Iteration               | 143        |
| ItrTime                 | 12.6       |
| LossAfter               | -0.964791  |
| LossBefore              | -0.942931  |
| MaxReturn               | 2.99e+03   |
| MeanKL                  | 0.00645555 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.67e+03   |
| NumTrajs                | 6          |
| Perplexity              | 20.1477    |
| PolicyExecTime          | 0.445      |
| ProcessExecTime         | 0.0554     |
| StdReturn               | 505        |
| Time                    | 1.86e+03   |
| dLoss                   | 0.0218598  |
----------------------------------------
itr #144 | 
Mem: 690.457031
Obtaining samples...
Obtaining samples for iteration 144...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5838, #subsample_inputs: 5838
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.722      |
| AbsLearnSignalNew       | 0.722      |
| AbsLearningOld          | 0.722      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 14.4385    |
| AveragePolicyStd        | 0.660433   |
| AverageReturn           | 1.72e+03   |
| Entropy                 | 3.00062    |
| EnvExecTime             | 2.15       |
| ExplainedVariance       | 0.784      |
| Iteration               | 144        |
| ItrTime                 | 14.3       |
| LossAfter               | 0.063083   |
| LossBefore              | 0.087487   |
| MaxReturn               | 2.97e+03   |
| MeanKL                  | 0.00644189 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 919        |
| NumTrajs                | 11         |
| Perplexity              | 20.0981    |
| PolicyExecTime          | 0.548      |
| ProcessExecTime         | 0.0655     |
| StdReturn               | 639        |
| Time                    | 1.88e+03   |
| dLoss                   | 0.0244041  |
----------------------------------------
itr #145 | 
Mem: 693.613281
Obtaining samples...
Obtaining samples for iteration 145...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5318, #subsample_inputs: 5318
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.742      |
| AbsLearnSignalNew       | 0.742      |
| AbsLearningOld          | 0.741      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 14.9851    |
| AveragePolicyStd        | 0.658124   |
| AverageReturn           | 1.6e+03    |
| Entropy                 | 2.9894     |
| EnvExecTime             | 2.07       |
| ExplainedVariance       | 0.886      |
| Iteration               | 145        |
| ItrTime                 | 13.4       |
| LossAfter               | 0.289292   |
| LossBefore              | 0.30916    |
| MaxReturn               | 2.31e+03   |
| MeanKL                  | 0.00645714 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.04e+03   |
| NumTrajs                | 11         |
| Perplexity              | 19.8737    |
| PolicyExecTime          | 0.529      |
| ProcessExecTime         | 0.0618     |
| StdReturn               | 426        |
| Time                    | 1.89e+03   |
| dLoss                   | 0.0198683  |
----------------------------------------
itr #146 | 
Mem: 693.871094
Obtaining samples...
Obtaining samples for iteration 146...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5231, #subsample_inputs: 5231
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.736     |
| AbsLearnSignalNew       | 0.736     |
| AbsLearningOld          | 0.737     |
| AverageDiscountedReturn | 249       |
| AveragePhiLoss          | 16.5948   |
| AveragePolicyStd        | 0.652365  |
| AverageReturn           | 1.52e+03  |
| Entropy                 | 2.96323   |
| EnvExecTime             | 2.05      |
| ExplainedVariance       | 0.865     |
| Iteration               | 146       |
| ItrTime                 | 13.2      |
| LossAfter               | 0.214063  |
| LossBefore              | 0.235997  |
| MaxReturn               | 3.12e+03  |
| MeanKL                  | 0.0065792 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 974       |
| NumTrajs                | 11        |
| Perplexity              | 19.3605   |
| PolicyExecTime          | 0.523     |
| ProcessExecTime         | 0.0607    |
| StdReturn               | 726       |
| Time                    | 1.91e+03  |
| dLoss                   | 0.0219336 |
---------------------------------------
itr #147 | 
Mem: 693.871094
Obtaining samples...
Obtaining samples for iteration 147...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5312, #subsample_inputs: 5312
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.687      |
| AbsLearnSignalNew       | 0.687      |
| AbsLearningOld          | 0.687      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 15.9086    |
| AveragePolicyStd        | 0.648229   |
| AverageReturn           | 1.57e+03   |
| Entropy                 | 2.94185    |
| EnvExecTime             | 2.28       |
| ExplainedVariance       | 0.683      |
| Iteration               | 147        |
| ItrTime                 | 13.7       |
| LossAfter               | 0.0298653  |
| LossBefore              | 0.0602381  |
| MaxReturn               | 2.56e+03   |
| MeanKL                  | 0.00974366 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 947        |
| NumTrajs                | 11         |
| Perplexity              | 18.9509    |
| PolicyExecTime          | 0.583      |
| ProcessExecTime         | 0.0673     |
| StdReturn               | 508        |
| Time                    | 1.92e+03   |
| dLoss                   | 0.0303728  |
----------------------------------------
itr #148 | 
Mem: 693.871094
Obtaining samples...
Obtaining samples for iteration 148...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5687, #subsample_inputs: 5687
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.712      |
| AbsLearnSignalNew       | 0.712      |
| AbsLearningOld          | 0.712      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 18.2235    |
| AveragePolicyStd        | 0.64417    |
| AverageReturn           | 2.15e+03   |
| Entropy                 | 2.92303    |
| EnvExecTime             | 2.24       |
| ExplainedVariance       | 0.651      |
| Iteration               | 148        |
| ItrTime                 | 14.1       |
| LossAfter               | -0.471533  |
| LossBefore              | -0.450378  |
| MaxReturn               | 2.86e+03   |
| MeanKL                  | 0.00665034 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 789        |
| NumTrajs                | 8          |
| Perplexity              | 18.5976    |
| PolicyExecTime          | 0.573      |
| ProcessExecTime         | 0.0684     |
| StdReturn               | 747        |
| Time                    | 1.93e+03   |
| dLoss                   | 0.0211554  |
----------------------------------------
itr #149 | 
Mem: 698.250000
Obtaining samples...
Obtaining samples for iteration 149...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5569, #subsample_inputs: 5569
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.714      |
| AbsLearnSignalNew       | 0.714      |
| AbsLearningOld          | 0.714      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 17.3359    |
| AveragePolicyStd        | 0.640125   |
| AverageReturn           | 1.92e+03   |
| Entropy                 | 2.90505    |
| EnvExecTime             | 2.19       |
| ExplainedVariance       | 0.799      |
| Iteration               | 149        |
| ItrTime                 | 13.9       |
| LossAfter               | 0.614757   |
| LossBefore              | 0.643638   |
| MaxReturn               | 2.96e+03   |
| MeanKL                  | 0.00983403 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 890        |
| NumTrajs                | 9          |
| Perplexity              | 18.2661    |
| PolicyExecTime          | 0.56       |
| ProcessExecTime         | 0.0674     |
| StdReturn               | 751        |
| Time                    | 1.95e+03   |
| dLoss                   | 0.0288808  |
----------------------------------------
itr #150 | 
Mem: 698.703125
Obtaining samples...
Obtaining samples for iteration 150...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5309, #subsample_inputs: 5309
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.733      |
| AbsLearnSignalNew       | 0.733      |
| AbsLearningOld          | 0.733      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 16.7151    |
| AveragePolicyStd        | 0.63672    |
| AverageReturn           | 1.26e+03   |
| Entropy                 | 2.88909    |
| EnvExecTime             | 2.34       |
| ExplainedVariance       | 0.789      |
| Iteration               | 150        |
| ItrTime                 | 13.7       |
| LossAfter               | 0.423585   |
| LossBefore              | 0.448029   |
| MaxReturn               | 2.01e+03   |
| MeanKL                  | 0.00699533 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 602        |
| NumTrajs                | 14         |
| Perplexity              | 17.977     |
| PolicyExecTime          | 0.581      |
| ProcessExecTime         | 0.0698     |
| StdReturn               | 287        |
| Time                    | 1.96e+03   |
| dLoss                   | 0.0244443  |
----------------------------------------
itr #151 | 
Mem: 698.972656
Obtaining samples...
Obtaining samples for iteration 151...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5395, #subsample_inputs: 5395
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.643      |
| AbsLearnSignalNew       | 0.643      |
| AbsLearningOld          | 0.643      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 17.8403    |
| AveragePolicyStd        | 0.634673   |
| AverageReturn           | 1.47e+03   |
| Entropy                 | 2.87987    |
| EnvExecTime             | 2.33       |
| ExplainedVariance       | 0.668      |
| Iteration               | 151        |
| ItrTime                 | 13.9       |
| LossAfter               | 0.416436   |
| LossBefore              | 0.438735   |
| MaxReturn               | 2.81e+03   |
| MeanKL                  | 0.00640685 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 844        |
| NumTrajs                | 12         |
| Perplexity              | 17.812     |
| PolicyExecTime          | 0.596      |
| ProcessExecTime         | 0.0673     |
| StdReturn               | 566        |
| Time                    | 1.98e+03   |
| dLoss                   | 0.0222988  |
----------------------------------------
itr #152 | 
Mem: 699.824219
Obtaining samples...
Obtaining samples for iteration 152...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5105, #subsample_inputs: 5105
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.749      |
| AbsLearnSignalNew       | 0.749      |
| AbsLearningOld          | 0.75       |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 16.8486    |
| AveragePolicyStd        | 0.634695   |
| AverageReturn           | 1.42e+03   |
| Entropy                 | 2.87977    |
| EnvExecTime             | 1.88       |
| ExplainedVariance       | 0.86       |
| Iteration               | 152        |
| ItrTime                 | 12.8       |
| LossAfter               | 0.266566   |
| LossBefore              | 0.28506    |
| MaxReturn               | 3.39e+03   |
| MeanKL                  | 0.00651236 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 730        |
| NumTrajs                | 12         |
| Perplexity              | 17.8102    |
| PolicyExecTime          | 0.483      |
| ProcessExecTime         | 0.0572     |
| StdReturn               | 692        |
| Time                    | 1.99e+03   |
| dLoss                   | 0.0184943  |
----------------------------------------
itr #153 | 
Mem: 699.824219
Obtaining samples...
Obtaining samples for iteration 153...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5263, #subsample_inputs: 5263
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.721      |
| AbsLearnSignalNew       | 0.721      |
| AbsLearningOld          | 0.721      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 17.2084    |
| AveragePolicyStd        | 0.633718   |
| AverageReturn           | 1.26e+03   |
| Entropy                 | 2.87629    |
| EnvExecTime             | 2.04       |
| ExplainedVariance       | 0.934      |
| Iteration               | 153        |
| ItrTime                 | 13.3       |
| LossAfter               | -0.231689  |
| LossBefore              | -0.206552  |
| MaxReturn               | 1.71e+03   |
| MeanKL                  | 0.00994606 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 890        |
| NumTrajs                | 14         |
| Perplexity              | 17.7483    |
| PolicyExecTime          | 0.517      |
| ProcessExecTime         | 0.0595     |
| StdReturn               | 269        |
| Time                    | 2e+03      |
| dLoss                   | 0.025137   |
----------------------------------------
itr #154 | 
Mem: 699.824219
Obtaining samples...
Obtaining samples for iteration 154...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5974, #subsample_inputs: 5974
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.709     |
| AbsLearnSignalNew       | 0.709     |
| AbsLearningOld          | 0.709     |
| AverageDiscountedReturn | 251       |
| AveragePhiLoss          | 16.134    |
| AveragePolicyStd        | 0.635815  |
| AverageReturn           | 1.79e+03  |
| Entropy                 | 2.88548   |
| EnvExecTime             | 2.32      |
| ExplainedVariance       | 0.692     |
| Iteration               | 154       |
| ItrTime                 | 14.7      |
| LossAfter               | -0.265799 |
| LossBefore              | -0.245155 |
| MaxReturn               | 3.38e+03  |
| MeanKL                  | 0.0064031 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 935       |
| NumTrajs                | 11        |
| Perplexity              | 17.9122   |
| PolicyExecTime          | 0.583     |
| ProcessExecTime         | 0.0668    |
| StdReturn               | 725       |
| Time                    | 2.02e+03  |
| dLoss                   | 0.020644  |
---------------------------------------
itr #155 | 
Mem: 701.136719
Obtaining samples...
Obtaining samples for iteration 155...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5163, #subsample_inputs: 5163
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.583      |
| AbsLearnSignalNew       | 0.583      |
| AbsLearningOld          | 0.583      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 16.2626    |
| AveragePolicyStd        | 0.637445   |
| AverageReturn           | 1.6e+03    |
| Entropy                 | 2.8941     |
| EnvExecTime             | 1.75       |
| ExplainedVariance       | 0.447      |
| Iteration               | 155        |
| ItrTime                 | 12.7       |
| LossAfter               | -0.473435  |
| LossBefore              | -0.448473  |
| MaxReturn               | 2.83e+03   |
| MeanKL                  | 0.00651794 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 932        |
| NumTrajs                | 10         |
| Perplexity              | 18.0672    |
| PolicyExecTime          | 0.444      |
| ProcessExecTime         | 0.0533     |
| StdReturn               | 590        |
| Time                    | 2.03e+03   |
| dLoss                   | 0.0249615  |
----------------------------------------
itr #156 | 
Mem: 701.316406
Obtaining samples...
Obtaining samples for iteration 156...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5515, #subsample_inputs: 5515
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.692      |
| AbsLearnSignalNew       | 0.692      |
| AbsLearningOld          | 0.692      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 15.8344    |
| AveragePolicyStd        | 0.63607    |
| AverageReturn           | 1.71e+03   |
| Entropy                 | 2.88754    |
| EnvExecTime             | 2.22       |
| ExplainedVariance       | 0.765      |
| Iteration               | 156        |
| ItrTime                 | 13.7       |
| LossAfter               | -0.0938254 |
| LossBefore              | -0.0623646 |
| MaxReturn               | 2.96e+03   |
| MeanKL                  | 0.00988704 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 839        |
| NumTrajs                | 10         |
| Perplexity              | 17.9492    |
| PolicyExecTime          | 0.561      |
| ProcessExecTime         | 0.0644     |
| StdReturn               | 756        |
| Time                    | 2.04e+03   |
| dLoss                   | 0.0314608  |
----------------------------------------
itr #157 | 
Mem: 702.343750
Obtaining samples...
Obtaining samples for iteration 157...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5824, #subsample_inputs: 5824
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.682      |
| AbsLearnSignalNew       | 0.682      |
| AbsLearningOld          | 0.681      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 15.8181    |
| AveragePolicyStd        | 0.631991   |
| AverageReturn           | 1.71e+03   |
| Entropy                 | 2.86883    |
| EnvExecTime             | 2.46       |
| ExplainedVariance       | 0.679      |
| Iteration               | 157        |
| ItrTime                 | 14.6       |
| LossAfter               | 0.193351   |
| LossBefore              | 0.216387   |
| MaxReturn               | 3.21e+03   |
| MeanKL                  | 0.00987293 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 787        |
| NumTrajs                | 11         |
| Perplexity              | 17.6163    |
| PolicyExecTime          | 0.615      |
| ProcessExecTime         | 0.072      |
| StdReturn               | 694        |
| Time                    | 2.06e+03   |
| dLoss                   | 0.0230356  |
----------------------------------------
itr #158 | 
Mem: 703.117188
Obtaining samples...
Obtaining samples for iteration 158...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5016, #subsample_inputs: 5016
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.729      |
| AbsLearnSignalNew       | 0.729      |
| AbsLearningOld          | 0.729      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 16.709     |
| AveragePolicyStd        | 0.627137   |
| AverageReturn           | 1.97e+03   |
| Entropy                 | 2.84654    |
| EnvExecTime             | 1.99       |
| ExplainedVariance       | 0.768      |
| Iteration               | 158        |
| ItrTime                 | 12.8       |
| LossAfter               | 0.527535   |
| LossBefore              | 0.553423   |
| MaxReturn               | 2.92e+03   |
| MeanKL                  | 0.00642743 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 932        |
| NumTrajs                | 8          |
| Perplexity              | 17.2281    |
| PolicyExecTime          | 0.512      |
| ProcessExecTime         | 0.057      |
| StdReturn               | 736        |
| Time                    | 2.07e+03   |
| dLoss                   | 0.0258881  |
----------------------------------------
itr #159 | 
Mem: 703.117188
Obtaining samples...
Obtaining samples for iteration 159...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5831, #subsample_inputs: 5831
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.756      |
| AbsLearnSignalNew       | 0.756      |
| AbsLearningOld          | 0.756      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 17.288     |
| AveragePolicyStd        | 0.624778   |
| AverageReturn           | 2.47e+03   |
| Entropy                 | 2.835      |
| EnvExecTime             | 2.74       |
| ExplainedVariance       | 0.841      |
| Iteration               | 159        |
| ItrTime                 | 15         |
| LossAfter               | -0.253147  |
| LossBefore              | -0.221022  |
| MaxReturn               | 2.97e+03   |
| MeanKL                  | 0.00992032 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.61e+03   |
| NumTrajs                | 7          |
| Perplexity              | 17.0304    |
| PolicyExecTime          | 0.693      |
| ProcessExecTime         | 0.0769     |
| StdReturn               | 485        |
| Time                    | 2.09e+03   |
| dLoss                   | 0.0321252  |
----------------------------------------
itr #160 | 
Mem: 708.781250
Obtaining samples...
Obtaining samples for iteration 160...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5328, #subsample_inputs: 5328
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.731      |
| AbsLearnSignalNew       | 0.731      |
| AbsLearningOld          | 0.731      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 16.4227    |
| AveragePolicyStd        | 0.623032   |
| AverageReturn           | 1.82e+03   |
| Entropy                 | 2.82607    |
| EnvExecTime             | 2.34       |
| ExplainedVariance       | 0.813      |
| Iteration               | 160        |
| ItrTime                 | 13.8       |
| LossAfter               | 0.201048   |
| LossBefore              | 0.221287   |
| MaxReturn               | 2.86e+03   |
| MeanKL                  | 0.00644247 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 851        |
| NumTrajs                | 9          |
| Perplexity              | 16.879     |
| PolicyExecTime          | 0.593      |
| ProcessExecTime         | 0.0661     |
| StdReturn               | 714        |
| Time                    | 2.1e+03    |
| dLoss                   | 0.0202391  |
----------------------------------------
itr #161 | 
Mem: 708.781250
Obtaining samples...
Obtaining samples for iteration 161...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5165, #subsample_inputs: 5165
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.72       |
| AbsLearnSignalNew       | 0.72       |
| AbsLearningOld          | 0.72       |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 19.2535    |
| AveragePolicyStd        | 0.620984   |
| AverageReturn           | 2.07e+03   |
| Entropy                 | 2.8181     |
| EnvExecTime             | 2.31       |
| ExplainedVariance       | 0.807      |
| Iteration               | 161        |
| ItrTime                 | 13.4       |
| LossAfter               | -1.04293   |
| LossBefore              | -1.00602   |
| MaxReturn               | 3.19e+03   |
| MeanKL                  | 0.00968562 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 927        |
| NumTrajs                | 8          |
| Perplexity              | 16.7451    |
| PolicyExecTime          | 0.573      |
| ProcessExecTime         | 0.0666     |
| StdReturn               | 832        |
| Time                    | 2.11e+03   |
| dLoss                   | 0.0369164  |
----------------------------------------
itr #162 | 
Mem: 708.781250
Obtaining samples...
Obtaining samples for iteration 162...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5209, #subsample_inputs: 5209
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.721      |
| AbsLearnSignalNew       | 0.721      |
| AbsLearningOld          | 0.721      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 15.7482    |
| AveragePolicyStd        | 0.626562   |
| AverageReturn           | 1.83e+03   |
| Entropy                 | 2.8453     |
| EnvExecTime             | 2.17       |
| ExplainedVariance       | 0.809      |
| Iteration               | 162        |
| ItrTime                 | 13.3       |
| LossAfter               | -0.908329  |
| LossBefore              | -0.883743  |
| MaxReturn               | 2.74e+03   |
| MeanKL                  | 0.00641202 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 902        |
| NumTrajs                | 9          |
| Perplexity              | 17.2067    |
| PolicyExecTime          | 0.532      |
| ProcessExecTime         | 0.0636     |
| StdReturn               | 735        |
| Time                    | 2.13e+03   |
| dLoss                   | 0.024586   |
----------------------------------------
itr #163 | 
Mem: 708.781250
Obtaining samples...
Obtaining samples for iteration 163...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5960, #subsample_inputs: 5960
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.751      |
| AbsLearnSignalNew       | 0.751      |
| AbsLearningOld          | 0.751      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 17.0287    |
| AveragePolicyStd        | 0.624675   |
| AverageReturn           | 2.13e+03   |
| Entropy                 | 2.83558    |
| EnvExecTime             | 2.47       |
| ExplainedVariance       | 0.83       |
| Iteration               | 163        |
| ItrTime                 | 14.9       |
| LossAfter               | 0.759066   |
| LossBefore              | 0.784582   |
| MaxReturn               | 3.21e+03   |
| MeanKL                  | 0.00650807 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.15e+03   |
| NumTrajs                | 9          |
| Perplexity              | 17.0404    |
| PolicyExecTime          | 0.604      |
| ProcessExecTime         | 0.0713     |
| StdReturn               | 798        |
| Time                    | 2.14e+03   |
| dLoss                   | 0.0255165  |
----------------------------------------
itr #164 | 
Mem: 710.140625
Obtaining samples...
Obtaining samples for iteration 164...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5158, #subsample_inputs: 5158
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.687     |
| AbsLearnSignalNew       | 0.687     |
| AbsLearningOld          | 0.687     |
| AverageDiscountedReturn | 249       |
| AveragePhiLoss          | 16.6057   |
| AveragePolicyStd        | 0.626073  |
| AverageReturn           | 1.32e+03  |
| Entropy                 | 2.84213   |
| EnvExecTime             | 2.72      |
| ExplainedVariance       | 0.835     |
| Iteration               | 164       |
| ItrTime                 | 14        |
| LossAfter               | 0.532125  |
| LossBefore              | 0.556112  |
| MaxReturn               | 2.11e+03  |
| MeanKL                  | 0.0065232 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 542       |
| NumTrajs                | 13        |
| Perplexity              | 17.1522   |
| PolicyExecTime          | 0.679     |
| ProcessExecTime         | 0.0739    |
| StdReturn               | 402       |
| Time                    | 2.16e+03  |
| dLoss                   | 0.0239871 |
---------------------------------------
itr #165 | 
Mem: 710.140625
Obtaining samples...
Obtaining samples for iteration 165...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5172, #subsample_inputs: 5172
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.72       |
| AbsLearnSignalNew       | 0.72       |
| AbsLearningOld          | 0.72       |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 18.8686    |
| AveragePolicyStd        | 0.623822   |
| AverageReturn           | 1.85e+03   |
| Entropy                 | 2.83139    |
| EnvExecTime             | 2.16       |
| ExplainedVariance       | 0.824      |
| Iteration               | 165        |
| ItrTime                 | 13.3       |
| LossAfter               | 0.0386061  |
| LossBefore              | 0.0621947  |
| MaxReturn               | 3.18e+03   |
| MeanKL                  | 0.00702796 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.12e+03   |
| NumTrajs                | 9          |
| Perplexity              | 16.969     |
| PolicyExecTime          | 0.545      |
| ProcessExecTime         | 0.0627     |
| StdReturn               | 804        |
| Time                    | 2.17e+03   |
| dLoss                   | 0.0235886  |
----------------------------------------
itr #166 | 
Mem: 710.140625
Obtaining samples...
Obtaining samples for iteration 166...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5515, #subsample_inputs: 5515
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.756      |
| AbsLearnSignalNew       | 0.756      |
| AbsLearningOld          | 0.756      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 19.1657    |
| AveragePolicyStd        | 0.619926   |
| AverageReturn           | 1.63e+03   |
| Entropy                 | 2.81101    |
| EnvExecTime             | 2.05       |
| ExplainedVariance       | 0.881      |
| Iteration               | 166        |
| ItrTime                 | 13.6       |
| LossAfter               | 0.0796577  |
| LossBefore              | 0.108394   |
| MaxReturn               | 2.95e+03   |
| MeanKL                  | 0.00985625 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 938        |
| NumTrajs                | 11         |
| Perplexity              | 16.6267    |
| PolicyExecTime          | 0.52       |
| ProcessExecTime         | 0.061      |
| StdReturn               | 645        |
| Time                    | 2.18e+03   |
| dLoss                   | 0.0287361  |
----------------------------------------
itr #167 | 
Mem: 710.140625
Obtaining samples...
Obtaining samples for iteration 167...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5188, #subsample_inputs: 5188
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.778      |
| AbsLearnSignalNew       | 0.778      |
| AbsLearningOld          | 0.778      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 18.3418    |
| AveragePolicyStd        | 0.616592   |
| AverageReturn           | 1.43e+03   |
| Entropy                 | 2.7933     |
| EnvExecTime             | 2.1        |
| ExplainedVariance       | 0.825      |
| Iteration               | 167        |
| ItrTime                 | 13.2       |
| LossAfter               | -0.283011  |
| LossBefore              | -0.258245  |
| MaxReturn               | 3.2e+03    |
| MeanKL                  | 0.00982033 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 729        |
| NumTrajs                | 12         |
| Perplexity              | 16.3348    |
| PolicyExecTime          | 0.527      |
| ProcessExecTime         | 0.0611     |
| StdReturn               | 718        |
| Time                    | 2.2e+03    |
| dLoss                   | 0.0247654  |
----------------------------------------
itr #168 | 
Mem: 710.140625
Obtaining samples...
Obtaining samples for iteration 168...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5126, #subsample_inputs: 5126
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.649      |
| AbsLearnSignalNew       | 0.649      |
| AbsLearningOld          | 0.649      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 16.4371    |
| AveragePolicyStd        | 0.613481   |
| AverageReturn           | 1.37e+03   |
| Entropy                 | 2.77883    |
| EnvExecTime             | 2.45       |
| ExplainedVariance       | 0.698      |
| Iteration               | 168        |
| ItrTime                 | 13.5       |
| LossAfter               | 0.163197   |
| LossBefore              | 0.186445   |
| MaxReturn               | 2.88e+03   |
| MeanKL                  | 0.00659193 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 647        |
| NumTrajs                | 12         |
| Perplexity              | 16.1002    |
| PolicyExecTime          | 0.609      |
| ProcessExecTime         | 0.0705     |
| StdReturn               | 683        |
| Time                    | 2.21e+03   |
| dLoss                   | 0.0232487  |
----------------------------------------
itr #169 | 
Mem: 710.140625
Obtaining samples...
Obtaining samples for iteration 169...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5346, #subsample_inputs: 5346
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.734      |
| AbsLearnSignalNew       | 0.734      |
| AbsLearningOld          | 0.734      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 17.7264    |
| AveragePolicyStd        | 0.611154   |
| AverageReturn           | 1.62e+03   |
| Entropy                 | 2.76636    |
| EnvExecTime             | 2.25       |
| ExplainedVariance       | 0.769      |
| Iteration               | 169        |
| ItrTime                 | 13.7       |
| LossAfter               | -0.138016  |
| LossBefore              | -0.115701  |
| MaxReturn               | 2.96e+03   |
| MeanKL                  | 0.00641581 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 572        |
| NumTrajs                | 10         |
| Perplexity              | 15.9007    |
| PolicyExecTime          | 0.567      |
| ProcessExecTime         | 0.0648     |
| StdReturn               | 851        |
| Time                    | 2.22e+03   |
| dLoss                   | 0.0223152  |
----------------------------------------
itr #170 | 
Mem: 710.140625
Obtaining samples...
Obtaining samples for iteration 170...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5460, #subsample_inputs: 5460
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.79       |
| AbsLearnSignalNew       | 0.79       |
| AbsLearningOld          | 0.79       |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 19.0306    |
| AveragePolicyStd        | 0.60662    |
| AverageReturn           | 2.09e+03   |
| Entropy                 | 2.74376    |
| EnvExecTime             | 2.24       |
| ExplainedVariance       | 0.818      |
| Iteration               | 170        |
| ItrTime                 | 13.9       |
| LossAfter               | 0.75984    |
| LossBefore              | 0.782174   |
| MaxReturn               | 3.19e+03   |
| MeanKL                  | 0.00666783 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 733        |
| NumTrajs                | 8          |
| Perplexity              | 15.5454    |
| PolicyExecTime          | 0.562      |
| ProcessExecTime         | 0.0643     |
| StdReturn               | 860        |
| Time                    | 2.24e+03   |
| dLoss                   | 0.0223336  |
----------------------------------------
itr #171 | 
Mem: 710.140625
Obtaining samples...
Obtaining samples for iteration 171...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5315, #subsample_inputs: 5315
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.715     |
| AbsLearnSignalNew       | 0.715     |
| AbsLearningOld          | 0.715     |
| AverageDiscountedReturn | 250       |
| AveragePhiLoss          | 20.8225   |
| AveragePolicyStd        | 0.605564  |
| AverageReturn           | 1.86e+03  |
| Entropy                 | 2.73778   |
| EnvExecTime             | 2.3       |
| ExplainedVariance       | 0.803     |
| Iteration               | 171       |
| ItrTime                 | 13.7      |
| LossAfter               | 1.35014   |
| LossBefore              | 1.38126   |
| MaxReturn               | 3.13e+03  |
| MeanKL                  | 0.0096383 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 960       |
| NumTrajs                | 9         |
| Perplexity              | 15.4526   |
| PolicyExecTime          | 0.571     |
| ProcessExecTime         | 0.0678    |
| StdReturn               | 698       |
| Time                    | 2.25e+03  |
| dLoss                   | 0.0311213 |
---------------------------------------
itr #172 | 
Mem: 710.140625
Obtaining samples...
Obtaining samples for iteration 172...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5642, #subsample_inputs: 5642
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.692      |
| AbsLearnSignalNew       | 0.692      |
| AbsLearningOld          | 0.692      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 19.0458    |
| AveragePolicyStd        | 0.60405    |
| AverageReturn           | 1.83e+03   |
| Entropy                 | 2.73116    |
| EnvExecTime             | 2.24       |
| ExplainedVariance       | 0.701      |
| Iteration               | 172        |
| ItrTime                 | 14.1       |
| LossAfter               | -1.21201   |
| LossBefore              | -1.185     |
| MaxReturn               | 3.35e+03   |
| MeanKL                  | 0.00977119 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 959        |
| NumTrajs                | 10         |
| Perplexity              | 15.3507    |
| PolicyExecTime          | 0.565      |
| ProcessExecTime         | 0.0669     |
| StdReturn               | 786        |
| Time                    | 2.27e+03   |
| dLoss                   | 0.0270071  |
----------------------------------------
itr #173 | 
Mem: 710.140625
Obtaining samples...
Obtaining samples for iteration 173...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5073, #subsample_inputs: 5073
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.668      |
| AbsLearnSignalNew       | 0.668      |
| AbsLearningOld          | 0.668      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 17.877     |
| AveragePolicyStd        | 0.603484   |
| AverageReturn           | 1.8e+03    |
| Entropy                 | 2.72734    |
| EnvExecTime             | 2.15       |
| ExplainedVariance       | 0.768      |
| Iteration               | 173        |
| ItrTime                 | 13.1       |
| LossAfter               | -0.197916  |
| LossBefore              | -0.17266   |
| MaxReturn               | 3.15e+03   |
| MeanKL                  | 0.00972381 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 888        |
| NumTrajs                | 9          |
| Perplexity              | 15.2922    |
| PolicyExecTime          | 0.543      |
| ProcessExecTime         | 0.0617     |
| StdReturn               | 715        |
| Time                    | 2.28e+03   |
| dLoss                   | 0.0252559  |
----------------------------------------
itr #174 | 
Mem: 710.140625
Obtaining samples...
Obtaining samples for iteration 174...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5222, #subsample_inputs: 5222
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.752      |
| AbsLearnSignalNew       | 0.752      |
| AbsLearningOld          | 0.752      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 19.0208    |
| AveragePolicyStd        | 0.606893   |
| AverageReturn           | 2.02e+03   |
| Entropy                 | 2.74219    |
| EnvExecTime             | 2.37       |
| ExplainedVariance       | 0.834      |
| Iteration               | 174        |
| ItrTime                 | 13.6       |
| LossAfter               | 0.430849   |
| LossBefore              | 0.452441   |
| MaxReturn               | 3.01e+03   |
| MeanKL                  | 0.00652184 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 889        |
| NumTrajs                | 8          |
| Perplexity              | 15.521     |
| PolicyExecTime          | 0.597      |
| ProcessExecTime         | 0.0674     |
| StdReturn               | 761        |
| Time                    | 2.29e+03   |
| dLoss                   | 0.0215927  |
----------------------------------------
itr #175 | 
Mem: 710.140625
Obtaining samples...
Obtaining samples for iteration 175...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5001, #subsample_inputs: 5001
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
-----------------------------------------
| AbsLearnSignal          | 0.733       |
| AbsLearnSignalNew       | 0.733       |
| AbsLearningOld          | 0.733       |
| AverageDiscountedReturn | 249         |
| AveragePhiLoss          | 20.8336     |
| AveragePolicyStd        | 0.603785    |
| AverageReturn           | 2.62e+03    |
| Entropy                 | 2.72696     |
| EnvExecTime             | 1.97        |
| ExplainedVariance       | 0.835       |
| Iteration               | 175         |
| ItrTime                 | 12.8        |
| LossAfter               | -0.0380027  |
| LossBefore              | -0.00874127 |
| MaxReturn               | 3.18e+03    |
| MeanKL                  | 0.00994629  |
| MeanKLBefore            | 0.0         |
| MinReturn               | 1.94e+03    |
| NumTrajs                | 6           |
| Perplexity              | 15.2863     |
| PolicyExecTime          | 0.499       |
| ProcessExecTime         | 0.0574      |
| StdReturn               | 476         |
| Time                    | 2.31e+03    |
| dLoss                   | 0.0292615   |
-----------------------------------------
itr #176 | 
Mem: 710.140625
Obtaining samples...
Obtaining samples for iteration 176...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5616, #subsample_inputs: 5616
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.74       |
| AbsLearnSignalNew       | 0.74       |
| AbsLearningOld          | 0.74       |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 20.8357    |
| AveragePolicyStd        | 0.600484   |
| AverageReturn           | 1.54e+03   |
| Entropy                 | 2.71134    |
| EnvExecTime             | 2.17       |
| ExplainedVariance       | 0.875      |
| Iteration               | 176        |
| ItrTime                 | 13.9       |
| LossAfter               | -0.120796  |
| LossBefore              | -0.0932229 |
| MaxReturn               | 3.04e+03   |
| MeanKL                  | 0.00995587 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 913        |
| NumTrajs                | 12         |
| Perplexity              | 15.0494    |
| PolicyExecTime          | 0.542      |
| ProcessExecTime         | 0.0706     |
| StdReturn               | 649        |
| Time                    | 2.32e+03   |
| dLoss                   | 0.0275733  |
----------------------------------------
itr #177 | 
Mem: 710.140625
Obtaining samples...
Obtaining samples for iteration 177...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5140, #subsample_inputs: 5140
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.61       |
| AbsLearnSignalNew       | 0.61       |
| AbsLearningOld          | 0.61       |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 21.0769    |
| AveragePolicyStd        | 0.593687   |
| AverageReturn           | 1.38e+03   |
| Entropy                 | 2.67854    |
| EnvExecTime             | 2.18       |
| ExplainedVariance       | 0.573      |
| Iteration               | 177        |
| ItrTime                 | 13.2       |
| LossAfter               | -1.03517   |
| LossBefore              | -1.00892   |
| MaxReturn               | 2.49e+03   |
| MeanKL                  | 0.00655442 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 608        |
| NumTrajs                | 12         |
| Perplexity              | 14.5639    |
| PolicyExecTime          | 0.559      |
| ProcessExecTime         | 0.0617     |
| StdReturn               | 491        |
| Time                    | 2.33e+03   |
| dLoss                   | 0.0262455  |
----------------------------------------
itr #178 | 
Mem: 710.140625
Obtaining samples...
Obtaining samples for iteration 178...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5020, #subsample_inputs: 5020
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.757      |
| AbsLearnSignalNew       | 0.757      |
| AbsLearningOld          | 0.757      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 19.8378    |
| AveragePolicyStd        | 0.59111    |
| AverageReturn           | 1.39e+03   |
| Entropy                 | 2.66601    |
| EnvExecTime             | 2.06       |
| ExplainedVariance       | 0.899      |
| Iteration               | 178        |
| ItrTime                 | 12.9       |
| LossAfter               | -0.486754  |
| LossBefore              | -0.457973  |
| MaxReturn               | 1.94e+03   |
| MeanKL                  | 0.00920622 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 889        |
| NumTrajs                | 12         |
| Perplexity              | 14.3825    |
| PolicyExecTime          | 0.504      |
| ProcessExecTime         | 0.0619     |
| StdReturn               | 336        |
| Time                    | 2.35e+03   |
| dLoss                   | 0.0287808  |
----------------------------------------
itr #179 | 
Mem: 710.140625
Obtaining samples...
Obtaining samples for iteration 179...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5070, #subsample_inputs: 5070
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.706      |
| AbsLearnSignalNew       | 0.706      |
| AbsLearningOld          | 0.706      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 20.668     |
| AveragePolicyStd        | 0.59093    |
| AverageReturn           | 1.4e+03    |
| Entropy                 | 2.66637    |
| EnvExecTime             | 2.27       |
| ExplainedVariance       | 0.842      |
| Iteration               | 179        |
| ItrTime                 | 13.2       |
| LossAfter               | 0.253678   |
| LossBefore              | 0.276846   |
| MaxReturn               | 2.9e+03    |
| MeanKL                  | 0.00651648 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 906        |
| NumTrajs                | 12         |
| Perplexity              | 14.3877    |
| PolicyExecTime          | 0.56       |
| ProcessExecTime         | 0.0629     |
| StdReturn               | 530        |
| Time                    | 2.36e+03   |
| dLoss                   | 0.0231677  |
----------------------------------------
itr #180 | 
Mem: 710.140625
Obtaining samples...
Obtaining samples for iteration 180...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5476, #subsample_inputs: 5476
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.639      |
| AbsLearnSignalNew       | 0.639      |
| AbsLearningOld          | 0.639      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 21.2615    |
| AveragePolicyStd        | 0.58734    |
| AverageReturn           | 1.68e+03   |
| Entropy                 | 2.64639    |
| EnvExecTime             | 2.39       |
| ExplainedVariance       | 0.777      |
| Iteration               | 180        |
| ItrTime                 | 13.9       |
| LossAfter               | 0.517179   |
| LossBefore              | 0.539977   |
| MaxReturn               | 3.37e+03   |
| MeanKL                  | 0.00640889 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 948        |
| NumTrajs                | 11         |
| Perplexity              | 14.1031    |
| PolicyExecTime          | 0.604      |
| ProcessExecTime         | 0.068      |
| StdReturn               | 641        |
| Time                    | 2.37e+03   |
| dLoss                   | 0.0227973  |
----------------------------------------
itr #181 | 
Mem: 710.140625
Obtaining samples...
Obtaining samples for iteration 181...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5072, #subsample_inputs: 5072
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.732      |
| AbsLearnSignalNew       | 0.732      |
| AbsLearningOld          | 0.732      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 21.4597    |
| AveragePolicyStd        | 0.584015   |
| AverageReturn           | 1.68e+03   |
| Entropy                 | 2.62994    |
| EnvExecTime             | 1.78       |
| ExplainedVariance       | 0.826      |
| Iteration               | 181        |
| ItrTime                 | 12.8       |
| LossAfter               | -0.636124  |
| LossBefore              | -0.604497  |
| MaxReturn               | 3.1e+03    |
| MeanKL                  | 0.00988909 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 881        |
| NumTrajs                | 10         |
| Perplexity              | 13.873     |
| PolicyExecTime          | 0.452      |
| ProcessExecTime         | 0.0533     |
| StdReturn               | 682        |
| Time                    | 2.39e+03   |
| dLoss                   | 0.031627   |
----------------------------------------
itr #182 | 
Mem: 710.140625
Obtaining samples...
Obtaining samples for iteration 182...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5535, #subsample_inputs: 5535
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.768      |
| AbsLearnSignalNew       | 0.768      |
| AbsLearningOld          | 0.768      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 21.4618    |
| AveragePolicyStd        | 0.583714   |
| AverageReturn           | 2.18e+03   |
| Entropy                 | 2.62932    |
| EnvExecTime             | 2.29       |
| ExplainedVariance       | 0.748      |
| Iteration               | 182        |
| ItrTime                 | 14         |
| LossAfter               | 0.709268   |
| LossBefore              | 0.729055   |
| MaxReturn               | 3.33e+03   |
| MeanKL                  | 0.00647977 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 932        |
| NumTrajs                | 8          |
| Perplexity              | 13.8643    |
| PolicyExecTime          | 0.588      |
| ProcessExecTime         | 0.0665     |
| StdReturn               | 916        |
| Time                    | 2.4e+03    |
| dLoss                   | 0.0197875  |
----------------------------------------
itr #183 | 
Mem: 711.238281
Obtaining samples...
Obtaining samples for iteration 183...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5099, #subsample_inputs: 5099
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.783      |
| AbsLearnSignalNew       | 0.783      |
| AbsLearningOld          | 0.783      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 22.1882    |
| AveragePolicyStd        | 0.583367   |
| AverageReturn           | 2.62e+03   |
| Entropy                 | 2.62783    |
| EnvExecTime             | 1.76       |
| ExplainedVariance       | 0.841      |
| Iteration               | 183        |
| ItrTime                 | 12.6       |
| LossAfter               | 0.30775    |
| LossBefore              | 0.33219    |
| MaxReturn               | 3.34e+03   |
| MeanKL                  | 0.00655467 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.2e+03    |
| NumTrajs                | 6          |
| Perplexity              | 13.8437    |
| PolicyExecTime          | 0.448      |
| ProcessExecTime         | 0.0542     |
| StdReturn               | 689        |
| Time                    | 2.41e+03   |
| dLoss                   | 0.0244393  |
----------------------------------------
itr #184 | 
Mem: 711.738281
Obtaining samples...
Obtaining samples for iteration 184...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5377, #subsample_inputs: 5377
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.663      |
| AbsLearnSignalNew       | 0.663      |
| AbsLearningOld          | 0.663      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 20.4975    |
| AveragePolicyStd        | 0.583554   |
| AverageReturn           | 2.75e+03   |
| Entropy                 | 2.63034    |
| EnvExecTime             | 2.35       |
| ExplainedVariance       | 0.844      |
| Iteration               | 184        |
| ItrTime                 | 13.9       |
| LossAfter               | 0.249971   |
| LossBefore              | 0.277827   |
| MaxReturn               | 3.17e+03   |
| MeanKL                  | 0.00642111 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.28e+03   |
| NumTrajs                | 6          |
| Perplexity              | 13.8785    |
| PolicyExecTime          | 0.586      |
| ProcessExecTime         | 0.0707     |
| StdReturn               | 672        |
| Time                    | 2.43e+03   |
| dLoss                   | 0.027856   |
----------------------------------------
itr #185 | 
Mem: 711.738281
Obtaining samples...
Obtaining samples for iteration 185...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5376, #subsample_inputs: 5376
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.67       |
| AbsLearnSignalNew       | 0.67       |
| AbsLearningOld          | 0.67       |
| AverageDiscountedReturn | 254        |
| AveragePhiLoss          | 20.8198    |
| AveragePolicyStd        | 0.581625   |
| AverageReturn           | 1.51e+03   |
| Entropy                 | 2.62149    |
| EnvExecTime             | 2.15       |
| ExplainedVariance       | 0.751      |
| Iteration               | 185        |
| ItrTime                 | 13.6       |
| LossAfter               | 0.0327543  |
| LossBefore              | 0.0576708  |
| MaxReturn               | 2.06e+03   |
| MeanKL                  | 0.00651463 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 990        |
| NumTrajs                | 12         |
| Perplexity              | 13.7562    |
| PolicyExecTime          | 0.538      |
| ProcessExecTime         | 0.0637     |
| StdReturn               | 342        |
| Time                    | 2.44e+03   |
| dLoss                   | 0.0249166  |
----------------------------------------
itr #186 | 
Mem: 711.738281
Obtaining samples...
Obtaining samples for iteration 186...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5391, #subsample_inputs: 5391
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.74       |
| AbsLearnSignalNew       | 0.74       |
| AbsLearningOld          | 0.74       |
| AverageDiscountedReturn | 254        |
| AveragePhiLoss          | 19.5685    |
| AveragePolicyStd        | 0.580024   |
| AverageReturn           | 2.28e+03   |
| Entropy                 | 2.61432    |
| EnvExecTime             | 2.23       |
| ExplainedVariance       | 0.762      |
| Iteration               | 186        |
| ItrTime                 | 13.8       |
| LossAfter               | -0.23048   |
| LossBefore              | -0.210732  |
| MaxReturn               | 3.34e+03   |
| MeanKL                  | 0.00655956 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.21e+03   |
| NumTrajs                | 8          |
| Perplexity              | 13.6579    |
| PolicyExecTime          | 0.572      |
| ProcessExecTime         | 0.0644     |
| StdReturn               | 853        |
| Time                    | 2.45e+03   |
| dLoss                   | 0.0197484  |
----------------------------------------
itr #187 | 
Mem: 715.308594
Obtaining samples...
Obtaining samples for iteration 187...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5380, #subsample_inputs: 5380
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.655      |
| AbsLearnSignalNew       | 0.655      |
| AbsLearningOld          | 0.655      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 24.7459    |
| AveragePolicyStd        | 0.578603   |
| AverageReturn           | 1.8e+03    |
| Entropy                 | 2.6054     |
| EnvExecTime             | 2.32       |
| ExplainedVariance       | 0.783      |
| Iteration               | 187        |
| ItrTime                 | 13.9       |
| LossAfter               | -1.26372   |
| LossBefore              | -1.23937   |
| MaxReturn               | 3.3e+03    |
| MeanKL                  | 0.00994555 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 930        |
| NumTrajs                | 10         |
| Perplexity              | 13.5366    |
| PolicyExecTime          | 0.579      |
| ProcessExecTime         | 0.0662     |
| StdReturn               | 844        |
| Time                    | 2.47e+03   |
| dLoss                   | 0.0243503  |
----------------------------------------
itr #188 | 
Mem: 715.308594
Obtaining samples...
Obtaining samples for iteration 188...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5627, #subsample_inputs: 5627
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.586      |
| AbsLearnSignalNew       | 0.586      |
| AbsLearningOld          | 0.586      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 24.5175    |
| AveragePolicyStd        | 0.574477   |
| AverageReturn           | 2.33e+03   |
| Entropy                 | 2.58358    |
| EnvExecTime             | 2.28       |
| ExplainedVariance       | 0.41       |
| Iteration               | 188        |
| ItrTime                 | 14         |
| LossAfter               | -0.222014  |
| LossBefore              | -0.194769  |
| MaxReturn               | 3.38e+03   |
| MeanKL                  | 0.00649335 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 773        |
| NumTrajs                | 8          |
| Perplexity              | 13.2445    |
| PolicyExecTime          | 0.565      |
| ProcessExecTime         | 0.0684     |
| StdReturn               | 930        |
| Time                    | 2.48e+03   |
| dLoss                   | 0.0272443  |
----------------------------------------
itr #189 | 
Mem: 715.308594
Obtaining samples...
Obtaining samples for iteration 189...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5639, #subsample_inputs: 5639
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.68      |
| AbsLearnSignalNew       | 0.68      |
| AbsLearningOld          | 0.68      |
| AverageDiscountedReturn | 253       |
| AveragePhiLoss          | 30.9014   |
| AveragePolicyStd        | 0.571528  |
| AverageReturn           | 1.87e+03  |
| Entropy                 | 2.56808   |
| EnvExecTime             | 2.12      |
| ExplainedVariance       | 0.791     |
| Iteration               | 189       |
| ItrTime                 | 14        |
| LossAfter               | 1.51188   |
| LossBefore              | 1.53261   |
| MaxReturn               | 3.27e+03  |
| MeanKL                  | 0.0064691 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.18e+03  |
| NumTrajs                | 10        |
| Perplexity              | 13.0408   |
| PolicyExecTime          | 0.544     |
| ProcessExecTime         | 0.0631    |
| StdReturn               | 772       |
| Time                    | 2.5e+03   |
| dLoss                   | 0.0207319 |
---------------------------------------
itr #190 | 
Mem: 715.308594
Obtaining samples...
Obtaining samples for iteration 190...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5009, #subsample_inputs: 5009
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.769      |
| AbsLearnSignalNew       | 0.769      |
| AbsLearningOld          | 0.769      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 22.5606    |
| AveragePolicyStd        | 0.570048   |
| AverageReturn           | 2.02e+03   |
| Entropy                 | 2.55941    |
| EnvExecTime             | 2.01       |
| ExplainedVariance       | 0.834      |
| Iteration               | 190        |
| ItrTime                 | 12.8       |
| LossAfter               | -0.743356  |
| LossBefore              | -0.719927  |
| MaxReturn               | 3.2e+03    |
| MeanKL                  | 0.00666265 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 851        |
| NumTrajs                | 8          |
| Perplexity              | 12.9282    |
| PolicyExecTime          | 0.508      |
| ProcessExecTime         | 0.0585     |
| StdReturn               | 707        |
| Time                    | 2.51e+03   |
| dLoss                   | 0.0234293  |
----------------------------------------
itr #191 | 
Mem: 715.308594
Obtaining samples...
Obtaining samples for iteration 191...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5199, #subsample_inputs: 5199
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.742      |
| AbsLearnSignalNew       | 0.742      |
| AbsLearningOld          | 0.742      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 24.4267    |
| AveragePolicyStd        | 0.566319   |
| AverageReturn           | 1.46e+03   |
| Entropy                 | 2.53819    |
| EnvExecTime             | 2.1        |
| ExplainedVariance       | 0.879      |
| Iteration               | 191        |
| ItrTime                 | 13.3       |
| LossAfter               | -0.99961   |
| LossBefore              | -0.972553  |
| MaxReturn               | 2.57e+03   |
| MeanKL                  | 0.00984187 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 765        |
| NumTrajs                | 12         |
| Perplexity              | 12.6567    |
| PolicyExecTime          | 0.523      |
| ProcessExecTime         | 0.0621     |
| StdReturn               | 454        |
| Time                    | 2.52e+03   |
| dLoss                   | 0.0270572  |
----------------------------------------
itr #192 | 
Mem: 715.308594
Obtaining samples...
Obtaining samples for iteration 192...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5539, #subsample_inputs: 5539
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.761      |
| AbsLearnSignalNew       | 0.761      |
| AbsLearningOld          | 0.761      |
| AverageDiscountedReturn | 254        |
| AveragePhiLoss          | 23.8526    |
| AveragePolicyStd        | 0.565569   |
| AverageReturn           | 1.69e+03   |
| Entropy                 | 2.5359     |
| EnvExecTime             | 2.27       |
| ExplainedVariance       | 0.886      |
| Iteration               | 192        |
| ItrTime                 | 14         |
| LossAfter               | 0.241327   |
| LossBefore              | 0.271465   |
| MaxReturn               | 2.94e+03   |
| MeanKL                  | 0.00970009 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 947        |
| NumTrajs                | 11         |
| Perplexity              | 12.6278    |
| PolicyExecTime          | 0.575      |
| ProcessExecTime         | 0.0655     |
| StdReturn               | 606        |
| Time                    | 2.54e+03   |
| dLoss                   | 0.0301374  |
----------------------------------------
itr #193 | 
Mem: 715.308594
Obtaining samples...
Obtaining samples for iteration 193...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5548, #subsample_inputs: 5548
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.742     |
| AbsLearnSignalNew       | 0.742     |
| AbsLearningOld          | 0.742     |
| AverageDiscountedReturn | 250       |
| AveragePhiLoss          | 23.2062   |
| AveragePolicyStd        | 0.566268  |
| AverageReturn           | 1.79e+03  |
| Entropy                 | 2.54071   |
| EnvExecTime             | 2.34      |
| ExplainedVariance       | 0.84      |
| Iteration               | 193       |
| ItrTime                 | 14.1      |
| LossAfter               | 0.0531238 |
| LossBefore              | 0.0730544 |
| MaxReturn               | 3.08e+03  |
| MeanKL                  | 0.0064752 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 921       |
| NumTrajs                | 10        |
| Perplexity              | 12.6887   |
| PolicyExecTime          | 0.599     |
| ProcessExecTime         | 0.0672    |
| StdReturn               | 703       |
| Time                    | 2.55e+03  |
| dLoss                   | 0.0199306 |
---------------------------------------
itr #194 | 
Mem: 715.308594
Obtaining samples...
Obtaining samples for iteration 194...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5542, #subsample_inputs: 5542
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.722      |
| AbsLearnSignalNew       | 0.722      |
| AbsLearningOld          | 0.722      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 23.0952    |
| AveragePolicyStd        | 0.566356   |
| AverageReturn           | 1.79e+03   |
| Entropy                 | 2.54236    |
| EnvExecTime             | 2.1        |
| ExplainedVariance       | 0.813      |
| Iteration               | 194        |
| ItrTime                 | 13.6       |
| LossAfter               | 0.956553   |
| LossBefore              | 0.977791   |
| MaxReturn               | 3.13e+03   |
| MeanKL                  | 0.00657147 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 952        |
| NumTrajs                | 10         |
| Perplexity              | 12.7096    |
| PolicyExecTime          | 0.535      |
| ProcessExecTime         | 0.062      |
| StdReturn               | 815        |
| Time                    | 2.56e+03   |
| dLoss                   | 0.0212386  |
----------------------------------------
itr #195 | 
Mem: 715.308594
Obtaining samples...
Obtaining samples for iteration 195...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5426, #subsample_inputs: 5426
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.658     |
| AbsLearnSignalNew       | 0.658     |
| AbsLearningOld          | 0.658     |
| AverageDiscountedReturn | 249       |
| AveragePhiLoss          | 24.1257   |
| AveragePolicyStd        | 0.567454  |
| AverageReturn           | 1.77e+03  |
| Entropy                 | 2.54785   |
| EnvExecTime             | 2.15      |
| ExplainedVariance       | 0.8       |
| Iteration               | 195       |
| ItrTime                 | 13.7      |
| LossAfter               | -0.374459 |
| LossBefore              | -0.351837 |
| MaxReturn               | 3.17e+03  |
| MeanKL                  | 0.0064762 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 834       |
| NumTrajs                | 10        |
| Perplexity              | 12.7796   |
| PolicyExecTime          | 0.546     |
| ProcessExecTime         | 0.0627    |
| StdReturn               | 820       |
| Time                    | 2.58e+03  |
| dLoss                   | 0.0226221 |
---------------------------------------
itr #196 | 
Mem: 715.308594
Obtaining samples...
Obtaining samples for iteration 196...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5878, #subsample_inputs: 5878
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.719      |
| AbsLearnSignalNew       | 0.719      |
| AbsLearningOld          | 0.72       |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 24.4116    |
| AveragePolicyStd        | 0.565218   |
| AverageReturn           | 2.17e+03   |
| Entropy                 | 2.53658    |
| EnvExecTime             | 2.6        |
| ExplainedVariance       | 0.872      |
| Iteration               | 196        |
| ItrTime                 | 14.8       |
| LossAfter               | -0.104597  |
| LossBefore              | -0.0834111 |
| MaxReturn               | 3.17e+03   |
| MeanKL                  | 0.0064255  |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.51e+03   |
| NumTrajs                | 9          |
| Perplexity              | 12.6364    |
| PolicyExecTime          | 0.638      |
| ProcessExecTime         | 0.0756     |
| StdReturn               | 507        |
| Time                    | 2.59e+03   |
| dLoss                   | 0.0211859  |
----------------------------------------
itr #197 | 
Mem: 715.308594
Obtaining samples...
Obtaining samples for iteration 197...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5253, #subsample_inputs: 5253
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.689      |
| AbsLearnSignalNew       | 0.689      |
| AbsLearningOld          | 0.689      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 23.6345    |
| AveragePolicyStd        | 0.566228   |
| AverageReturn           | 1.7e+03    |
| Entropy                 | 2.54122    |
| EnvExecTime             | 1.97       |
| ExplainedVariance       | 0.819      |
| Iteration               | 197        |
| ItrTime                 | 13.1       |
| LossAfter               | -0.19169   |
| LossBefore              | -0.161419  |
| MaxReturn               | 2.72e+03   |
| MeanKL                  | 0.00999531 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.02e+03   |
| NumTrajs                | 10         |
| Perplexity              | 12.6951    |
| PolicyExecTime          | 0.5        |
| ProcessExecTime         | 0.0577     |
| StdReturn               | 532        |
| Time                    | 2.61e+03   |
| dLoss                   | 0.0302707  |
----------------------------------------
itr #198 | 
Mem: 715.308594
Obtaining samples...
Obtaining samples for iteration 198...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5207, #subsample_inputs: 5207
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.645      |
| AbsLearnSignalNew       | 0.645      |
| AbsLearningOld          | 0.645      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 23.1007    |
| AveragePolicyStd        | 0.560645   |
| AverageReturn           | 1.92e+03   |
| Entropy                 | 2.51225    |
| EnvExecTime             | 1.74       |
| ExplainedVariance       | 0.779      |
| Iteration               | 198        |
| ItrTime                 | 12.9       |
| LossAfter               | 1.07383    |
| LossBefore              | 1.09291    |
| MaxReturn               | 3.11e+03   |
| MeanKL                  | 0.00656818 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.37e+03   |
| NumTrajs                | 9          |
| Perplexity              | 12.3327    |
| PolicyExecTime          | 0.443      |
| ProcessExecTime         | 0.0562     |
| StdReturn               | 482        |
| Time                    | 2.62e+03   |
| dLoss                   | 0.0190845  |
----------------------------------------
itr #199 | 
Mem: 715.308594
Obtaining samples...
Obtaining samples for iteration 199...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5582, #subsample_inputs: 5582
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.766      |
| AbsLearnSignalNew       | 0.766      |
| AbsLearningOld          | 0.766      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 23.1591    |
| AveragePolicyStd        | 0.558647   |
| AverageReturn           | 1.69e+03   |
| Entropy                 | 2.50266    |
| EnvExecTime             | 2.07       |
| ExplainedVariance       | 0.913      |
| Iteration               | 199        |
| ItrTime                 | 13.8       |
| LossAfter               | 0.823523   |
| LossBefore              | 0.847552   |
| MaxReturn               | 2.33e+03   |
| MeanKL                  | 0.00992342 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.05e+03   |
| NumTrajs                | 11         |
| Perplexity              | 12.2149    |
| PolicyExecTime          | 0.529      |
| ProcessExecTime         | 0.0614     |
| StdReturn               | 420        |
| Time                    | 2.63e+03   |
| dLoss                   | 0.0240287  |
----------------------------------------
itr #200 | 
Mem: 715.308594
Obtaining samples...
Obtaining samples for iteration 200...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5397, #subsample_inputs: 5397
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.672     |
| AbsLearnSignalNew       | 0.672     |
| AbsLearningOld          | 0.672     |
| AverageDiscountedReturn | 252       |
| AveragePhiLoss          | 23.4339   |
| AveragePolicyStd        | 0.558128  |
| AverageReturn           | 1.51e+03  |
| Entropy                 | 2.49775   |
| EnvExecTime             | 1.92      |
| ExplainedVariance       | 0.84      |
| Iteration               | 200       |
| ItrTime                 | 13.4      |
| LossAfter               | 0.814468  |
| LossBefore              | 0.8421    |
| MaxReturn               | 2.87e+03  |
| MeanKL                  | 0.009804  |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.03e+03  |
| NumTrajs                | 12        |
| Perplexity              | 12.1551   |
| PolicyExecTime          | 0.483     |
| ProcessExecTime         | 0.0575    |
| StdReturn               | 508       |
| Time                    | 2.65e+03  |
| dLoss                   | 0.0276319 |
---------------------------------------
itr #201 | 
Mem: 715.308594
Obtaining samples...
Obtaining samples for iteration 201...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5062, #subsample_inputs: 5062
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.73       |
| AbsLearnSignalNew       | 0.73       |
| AbsLearningOld          | 0.73       |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 24.3579    |
| AveragePolicyStd        | 0.560882   |
| AverageReturn           | 1.43e+03   |
| Entropy                 | 2.51289    |
| EnvExecTime             | 2.08       |
| ExplainedVariance       | 0.938      |
| Iteration               | 201        |
| ItrTime                 | 13         |
| LossAfter               | -0.162932  |
| LossBefore              | -0.139556  |
| MaxReturn               | 2.29e+03   |
| MeanKL                  | 0.00665501 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 897        |
| NumTrajs                | 12         |
| Perplexity              | 12.3405    |
| PolicyExecTime          | 0.511      |
| ProcessExecTime         | 0.0604     |
| StdReturn               | 391        |
| Time                    | 2.66e+03   |
| dLoss                   | 0.0233758  |
----------------------------------------
itr #202 | 
Mem: 715.308594
Obtaining samples...
Obtaining samples for iteration 202...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5185, #subsample_inputs: 5185
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.756     |
| AbsLearnSignalNew       | 0.756     |
| AbsLearningOld          | 0.756     |
| AverageDiscountedReturn | 252       |
| AveragePhiLoss          | 22.9242   |
| AveragePolicyStd        | 0.557708  |
| AverageReturn           | 1.34e+03  |
| Entropy                 | 2.4958    |
| EnvExecTime             | 2.01      |
| ExplainedVariance       | 0.939     |
| Iteration               | 202       |
| ItrTime                 | 13.1      |
| LossAfter               | -0.481815 |
| LossBefore              | -0.462873 |
| MaxReturn               | 1.87e+03  |
| MeanKL                  | 0.0065722 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.14e+03  |
| NumTrajs                | 13        |
| Perplexity              | 12.1315   |
| PolicyExecTime          | 0.502     |
| ProcessExecTime         | 0.0583    |
| StdReturn               | 230       |
| Time                    | 2.67e+03  |
| dLoss                   | 0.0189427 |
---------------------------------------
itr #203 | 
Mem: 715.308594
Obtaining samples...
Obtaining samples for iteration 203...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5057, #subsample_inputs: 5057
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.783      |
| AbsLearnSignalNew       | 0.783      |
| AbsLearningOld          | 0.783      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 24.7324    |
| AveragePolicyStd        | 0.554808   |
| AverageReturn           | 1.54e+03   |
| Entropy                 | 2.47974    |
| EnvExecTime             | 1.85       |
| ExplainedVariance       | 0.923      |
| Iteration               | 203        |
| ItrTime                 | 12.7       |
| LossAfter               | 0.00146961 |
| LossBefore              | 0.0288692  |
| MaxReturn               | 2.17e+03   |
| MeanKL                  | 0.00970128 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.11e+03   |
| NumTrajs                | 11         |
| Perplexity              | 11.9382    |
| PolicyExecTime          | 0.469      |
| ProcessExecTime         | 0.0536     |
| StdReturn               | 314        |
| Time                    | 2.69e+03   |
| dLoss                   | 0.0273996  |
----------------------------------------
itr #204 | 
Mem: 715.308594
Obtaining samples...
Obtaining samples for iteration 204...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5409, #subsample_inputs: 5409
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.722      |
| AbsLearnSignalNew       | 0.722      |
| AbsLearningOld          | 0.722      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 26.4137    |
| AveragePolicyStd        | 0.555767   |
| AverageReturn           | 2.88e+03   |
| Entropy                 | 2.48529    |
| EnvExecTime             | 2.18       |
| ExplainedVariance       | 0.732      |
| Iteration               | 204        |
| ItrTime                 | 13.7       |
| LossAfter               | -0.407871  |
| LossBefore              | -0.378444  |
| MaxReturn               | 3.27e+03   |
| MeanKL                  | 0.00982556 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.45e+03   |
| NumTrajs                | 6          |
| Perplexity              | 12.0046    |
| PolicyExecTime          | 0.559      |
| ProcessExecTime         | 0.0646     |
| StdReturn               | 641        |
| Time                    | 2.7e+03    |
| dLoss                   | 0.029427   |
----------------------------------------
itr #205 | 
Mem: 715.746094
Obtaining samples...
Obtaining samples for iteration 205...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5061, #subsample_inputs: 5061
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.614      |
| AbsLearnSignalNew       | 0.614      |
| AbsLearningOld          | 0.614      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 23.3243    |
| AveragePolicyStd        | 0.553328   |
| AverageReturn           | 2.04e+03   |
| Entropy                 | 2.47071    |
| EnvExecTime             | 1.99       |
| ExplainedVariance       | 0.746      |
| Iteration               | 205        |
| ItrTime                 | 12.8       |
| LossAfter               | 0.0866362  |
| LossBefore              | 0.110394   |
| MaxReturn               | 3.2e+03    |
| MeanKL                  | 0.00642447 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.22e+03   |
| NumTrajs                | 8          |
| Perplexity              | 11.8309    |
| PolicyExecTime          | 0.504      |
| ProcessExecTime         | 0.0599     |
| StdReturn               | 711        |
| Time                    | 2.71e+03   |
| dLoss                   | 0.0237575  |
----------------------------------------
itr #206 | 
Mem: 715.980469
Obtaining samples...
Obtaining samples for iteration 206...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5394, #subsample_inputs: 5394
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.598      |
| AbsLearnSignalNew       | 0.598      |
| AbsLearningOld          | 0.598      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 28.536     |
| AveragePolicyStd        | 0.55487    |
| AverageReturn           | 1.79e+03   |
| Entropy                 | 2.47952    |
| EnvExecTime             | 2.07       |
| ExplainedVariance       | 0.742      |
| Iteration               | 206        |
| ItrTime                 | 13.6       |
| LossAfter               | 0.647893   |
| LossBefore              | 0.671031   |
| MaxReturn               | 2.8e+03    |
| MeanKL                  | 0.00651664 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.17e+03   |
| NumTrajs                | 10         |
| Perplexity              | 11.9355    |
| PolicyExecTime          | 0.519      |
| ProcessExecTime         | 0.0604     |
| StdReturn               | 551        |
| Time                    | 2.73e+03   |
| dLoss                   | 0.023138   |
----------------------------------------
itr #207 | 
Mem: 716.703125
Obtaining samples...
Obtaining samples for iteration 207...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5678, #subsample_inputs: 5678
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.683      |
| AbsLearnSignalNew       | 0.683      |
| AbsLearningOld          | 0.683      |
| AverageDiscountedReturn | 254        |
| AveragePhiLoss          | 25.525     |
| AveragePolicyStd        | 0.551535   |
| AverageReturn           | 1.73e+03   |
| Entropy                 | 2.46212    |
| EnvExecTime             | 2.35       |
| ExplainedVariance       | 0.76       |
| Iteration               | 207        |
| ItrTime                 | 14.2       |
| LossAfter               | 0.201693   |
| LossBefore              | 0.225886   |
| MaxReturn               | 3.15e+03   |
| MeanKL                  | 0.00652119 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.12e+03   |
| NumTrajs                | 11         |
| Perplexity              | 11.7297    |
| PolicyExecTime          | 0.574      |
| ProcessExecTime         | 0.0689     |
| StdReturn               | 579        |
| Time                    | 2.74e+03   |
| dLoss                   | 0.0241934  |
----------------------------------------
itr #208 | 
Mem: 716.761719
Obtaining samples...
Obtaining samples for iteration 208...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5039, #subsample_inputs: 5039
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.748     |
| AbsLearnSignalNew       | 0.748     |
| AbsLearningOld          | 0.748     |
| AverageDiscountedReturn | 254       |
| AveragePhiLoss          | 25.4487   |
| AveragePolicyStd        | 0.547942  |
| AverageReturn           | 1.89e+03  |
| Entropy                 | 2.44377   |
| EnvExecTime             | 2.03      |
| ExplainedVariance       | 0.895     |
| Iteration               | 208       |
| ItrTime                 | 12.8      |
| LossAfter               | 1.31731   |
| LossBefore              | 1.33928   |
| MaxReturn               | 2.58e+03  |
| MeanKL                  | 0.0064026 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.19e+03  |
| NumTrajs                | 9         |
| Perplexity              | 11.5164   |
| PolicyExecTime          | 0.514     |
| ProcessExecTime         | 0.0586    |
| StdReturn               | 490       |
| Time                    | 2.75e+03  |
| dLoss                   | 0.0219719 |
---------------------------------------
itr #209 | 
Mem: 716.761719
Obtaining samples...
Obtaining samples for iteration 209...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5126, #subsample_inputs: 5126
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
-----------------------------------------
| AbsLearnSignal          | 0.727       |
| AbsLearnSignalNew       | 0.727       |
| AbsLearningOld          | 0.727       |
| AverageDiscountedReturn | 254         |
| AveragePhiLoss          | 26.0075     |
| AveragePolicyStd        | 0.545851    |
| AverageReturn           | 2.12e+03    |
| Entropy                 | 2.43242     |
| EnvExecTime             | 1.78        |
| ExplainedVariance       | 0.862       |
| Iteration               | 209         |
| ItrTime                 | 12.7        |
| LossAfter               | -0.0308864  |
| LossBefore              | -0.00605559 |
| MaxReturn               | 3.2e+03     |
| MeanKL                  | 0.00655661  |
| MeanKLBefore            | 0.0         |
| MinReturn               | 1.27e+03    |
| NumTrajs                | 8           |
| Perplexity              | 11.3864     |
| PolicyExecTime          | 0.446       |
| ProcessExecTime         | 0.0541      |
| StdReturn               | 700         |
| Time                    | 2.77e+03    |
| dLoss                   | 0.0248308   |
-----------------------------------------
itr #210 | 
Mem: 717.261719
Obtaining samples...
Obtaining samples for iteration 210...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5865, #subsample_inputs: 5865
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.721      |
| AbsLearnSignalNew       | 0.721      |
| AbsLearningOld          | 0.721      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 25.1133    |
| AveragePolicyStd        | 0.546713   |
| AverageReturn           | 2.31e+03   |
| Entropy                 | 2.43603    |
| EnvExecTime             | 2.44       |
| ExplainedVariance       | 0.829      |
| Iteration               | 210        |
| ItrTime                 | 14.6       |
| LossAfter               | 0.107729   |
| LossBefore              | 0.129796   |
| MaxReturn               | 3.16e+03   |
| MeanKL                  | 0.00654031 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.48e+03   |
| NumTrajs                | 8          |
| Perplexity              | 11.4276    |
| PolicyExecTime          | 0.614      |
| ProcessExecTime         | 0.0715     |
| StdReturn               | 614        |
| Time                    | 2.78e+03   |
| dLoss                   | 0.022067   |
----------------------------------------
itr #211 | 
Mem: 718.558594
Obtaining samples...
Obtaining samples for iteration 211...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5232, #subsample_inputs: 5232
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.68      |
| AbsLearnSignalNew       | 0.68      |
| AbsLearningOld          | 0.68      |
| AverageDiscountedReturn | 251       |
| AveragePhiLoss          | 28.1294   |
| AveragePolicyStd        | 0.546314  |
| AverageReturn           | 2.15e+03  |
| Entropy                 | 2.4346    |
| EnvExecTime             | 2.06      |
| ExplainedVariance       | 0.79      |
| Iteration               | 211       |
| ItrTime                 | 13.3      |
| LossAfter               | 1.10385   |
| LossBefore              | 1.14549   |
| MaxReturn               | 3.13e+03  |
| MeanKL                  | 0.009859  |
| MeanKLBefore            | 0.0       |
| MinReturn               | 948       |
| NumTrajs                | 8         |
| Perplexity              | 11.4112   |
| PolicyExecTime          | 0.526     |
| ProcessExecTime         | 0.0589    |
| StdReturn               | 796       |
| Time                    | 2.79e+03  |
| dLoss                   | 0.0416428 |
---------------------------------------
itr #212 | 
Mem: 718.558594
Obtaining samples...
Obtaining samples for iteration 212...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5525, #subsample_inputs: 5525
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.78       |
| AbsLearnSignalNew       | 0.78       |
| AbsLearningOld          | 0.78       |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 25.8726    |
| AveragePolicyStd        | 0.54552    |
| AverageReturn           | 1.76e+03   |
| Entropy                 | 2.43043    |
| EnvExecTime             | 2.27       |
| ExplainedVariance       | 0.818      |
| Iteration               | 212        |
| ItrTime                 | 13.9       |
| LossAfter               | 0.237125   |
| LossBefore              | 0.262868   |
| MaxReturn               | 2.87e+03   |
| MeanKL                  | 0.00989626 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 930        |
| NumTrajs                | 10         |
| Perplexity              | 11.3637    |
| PolicyExecTime          | 0.573      |
| ProcessExecTime         | 0.0665     |
| StdReturn               | 627        |
| Time                    | 2.81e+03   |
| dLoss                   | 0.0257427  |
----------------------------------------
itr #213 | 
Mem: 718.558594
Obtaining samples...
Obtaining samples for iteration 213...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5897, #subsample_inputs: 5897
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.787      |
| AbsLearnSignalNew       | 0.787      |
| AbsLearningOld          | 0.787      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 26.0942    |
| AveragePolicyStd        | 0.548233   |
| AverageReturn           | 2.1e+03    |
| Entropy                 | 2.44472    |
| EnvExecTime             | 2.44       |
| ExplainedVariance       | 0.823      |
| Iteration               | 213        |
| ItrTime                 | 14.7       |
| LossAfter               | -1.70216   |
| LossBefore              | -1.67474   |
| MaxReturn               | 3.11e+03   |
| MeanKL                  | 0.00970846 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.17e+03   |
| NumTrajs                | 9          |
| Perplexity              | 11.5273    |
| PolicyExecTime          | 0.608      |
| ProcessExecTime         | 0.0729     |
| StdReturn               | 737        |
| Time                    | 2.82e+03   |
| dLoss                   | 0.0274173  |
----------------------------------------
itr #214 | 
Mem: 722.402344
Obtaining samples...
Obtaining samples for iteration 214...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5443, #subsample_inputs: 5443
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.704      |
| AbsLearnSignalNew       | 0.704      |
| AbsLearningOld          | 0.704      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 27.0453    |
| AveragePolicyStd        | 0.54725    |
| AverageReturn           | 2.32e+03   |
| Entropy                 | 2.43806    |
| EnvExecTime             | 2.26       |
| ExplainedVariance       | 0.848      |
| Iteration               | 214        |
| ItrTime                 | 13.9       |
| LossAfter               | 0.0312796  |
| LossBefore              | 0.0540303  |
| MaxReturn               | 2.95e+03   |
| MeanKL                  | 0.00663039 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.21e+03   |
| NumTrajs                | 7          |
| Perplexity              | 11.4507    |
| PolicyExecTime          | 0.563      |
| ProcessExecTime         | 0.0662     |
| StdReturn               | 632        |
| Time                    | 2.84e+03   |
| dLoss                   | 0.0227507  |
----------------------------------------
itr #215 | 
Mem: 722.402344
Obtaining samples...
Obtaining samples for iteration 215...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5431, #subsample_inputs: 5431
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.593      |
| AbsLearnSignalNew       | 0.593      |
| AbsLearningOld          | 0.593      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 28.4073    |
| AveragePolicyStd        | 0.545165   |
| AverageReturn           | 2.25e+03   |
| Entropy                 | 2.42502    |
| EnvExecTime             | 2.2        |
| ExplainedVariance       | 0.636      |
| Iteration               | 215        |
| ItrTime                 | 13.8       |
| LossAfter               | -0.425264  |
| LossBefore              | -0.391394  |
| MaxReturn               | 3.41e+03   |
| MeanKL                  | 0.00988043 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 823        |
| NumTrajs                | 8          |
| Perplexity              | 11.3024    |
| PolicyExecTime          | 0.56       |
| ProcessExecTime         | 0.064      |
| StdReturn               | 939        |
| Time                    | 2.85e+03   |
| dLoss                   | 0.0338694  |
----------------------------------------
itr #216 | 
Mem: 722.402344
Obtaining samples...
Obtaining samples for iteration 216...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5308, #subsample_inputs: 5308
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.73       |
| AbsLearnSignalNew       | 0.73       |
| AbsLearningOld          | 0.73       |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 25.7065    |
| AveragePolicyStd        | 0.544613   |
| AverageReturn           | 2.38e+03   |
| Entropy                 | 2.42296    |
| EnvExecTime             | 1.95       |
| ExplainedVariance       | 0.729      |
| Iteration               | 216        |
| ItrTime                 | 13.2       |
| LossAfter               | -0.766288  |
| LossBefore              | -0.741166  |
| MaxReturn               | 3.03e+03   |
| MeanKL                  | 0.00995928 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.69e+03   |
| NumTrajs                | 7          |
| Perplexity              | 11.2792    |
| PolicyExecTime          | 0.496      |
| ProcessExecTime         | 0.0585     |
| StdReturn               | 545        |
| Time                    | 2.86e+03   |
| dLoss                   | 0.0251213  |
----------------------------------------
itr #217 | 
Mem: 722.402344
Obtaining samples...
Obtaining samples for iteration 217...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5817, #subsample_inputs: 5817
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.664     |
| AbsLearnSignalNew       | 0.664     |
| AbsLearningOld          | 0.664     |
| AverageDiscountedReturn | 250       |
| AveragePhiLoss          | 25.2552   |
| AveragePolicyStd        | 0.544088  |
| AverageReturn           | 2.07e+03  |
| Entropy                 | 2.42009   |
| EnvExecTime             | 2.98      |
| ExplainedVariance       | 0.696     |
| Iteration               | 217       |
| ItrTime                 | 15.3      |
| LossAfter               | 0.0538504 |
| LossBefore              | 0.0783472 |
| MaxReturn               | 3.2e+03   |
| MeanKL                  | 0.0064414 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.19e+03  |
| NumTrajs                | 9         |
| Perplexity              | 11.2469   |
| PolicyExecTime          | 0.743     |
| ProcessExecTime         | 0.0819    |
| StdReturn               | 799       |
| Time                    | 2.88e+03  |
| dLoss                   | 0.0244967 |
---------------------------------------
itr #218 | 
Mem: 722.402344
Obtaining samples...
Obtaining samples for iteration 218...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5311, #subsample_inputs: 5311
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.708      |
| AbsLearnSignalNew       | 0.708      |
| AbsLearningOld          | 0.708      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 28.8122    |
| AveragePolicyStd        | 0.543564   |
| AverageReturn           | 2.71e+03   |
| Entropy                 | 2.41826    |
| EnvExecTime             | 2.39       |
| ExplainedVariance       | 0.876      |
| Iteration               | 218        |
| ItrTime                 | 13.7       |
| LossAfter               | 0.534317   |
| LossBefore              | 0.555806   |
| MaxReturn               | 3.02e+03   |
| MeanKL                  | 0.00646157 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.42e+03   |
| NumTrajs                | 6          |
| Perplexity              | 11.2264    |
| PolicyExecTime          | 0.599      |
| ProcessExecTime         | 0.0684     |
| StdReturn               | 579        |
| Time                    | 2.89e+03   |
| dLoss                   | 0.0214894  |
----------------------------------------
itr #219 | 
Mem: 722.402344
Obtaining samples...
Obtaining samples for iteration 219...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5816, #subsample_inputs: 5816
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.662      |
| AbsLearnSignalNew       | 0.662      |
| AbsLearningOld          | 0.662      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 30.1473    |
| AveragePolicyStd        | 0.542314   |
| AverageReturn           | 2.38e+03   |
| Entropy                 | 2.41188    |
| EnvExecTime             | 2.46       |
| ExplainedVariance       | 0.817      |
| Iteration               | 219        |
| ItrTime                 | 14.6       |
| LossAfter               | 0.0224947  |
| LossBefore              | 0.0415709  |
| MaxReturn               | 3.33e+03   |
| MeanKL                  | 0.00644794 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.21e+03   |
| NumTrajs                | 8          |
| Perplexity              | 11.1549    |
| PolicyExecTime          | 0.616      |
| ProcessExecTime         | 0.0701     |
| StdReturn               | 712        |
| Time                    | 2.91e+03   |
| dLoss                   | 0.0190762  |
----------------------------------------
itr #220 | 
Mem: 722.402344
Obtaining samples...
Obtaining samples for iteration 220...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5321, #subsample_inputs: 5321
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.679     |
| AbsLearnSignalNew       | 0.679     |
| AbsLearningOld          | 0.679     |
| AverageDiscountedReturn | 248       |
| AveragePhiLoss          | 26.6295   |
| AveragePolicyStd        | 0.541441  |
| AverageReturn           | 2.79e+03  |
| Entropy                 | 2.40689   |
| EnvExecTime             | 2.09      |
| ExplainedVariance       | 0.704     |
| Iteration               | 220       |
| ItrTime                 | 13.5      |
| LossAfter               | -0.387726 |
| LossBefore              | -0.355146 |
| MaxReturn               | 3.16e+03  |
| MeanKL                  | 0.0064784 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 2.04e+03  |
| NumTrajs                | 6         |
| Perplexity              | 11.0994   |
| PolicyExecTime          | 0.532     |
| ProcessExecTime         | 0.0619    |
| StdReturn               | 422       |
| Time                    | 2.92e+03  |
| dLoss                   | 0.0325801 |
---------------------------------------
itr #221 | 
Mem: 722.402344
Obtaining samples...
Obtaining samples for iteration 221...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5336, #subsample_inputs: 5336
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.608      |
| AbsLearnSignalNew       | 0.608      |
| AbsLearningOld          | 0.608      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 28.3439    |
| AveragePolicyStd        | 0.54134    |
| AverageReturn           | 2.84e+03   |
| Entropy                 | 2.40603    |
| EnvExecTime             | 2.13       |
| ExplainedVariance       | 0.807      |
| Iteration               | 221        |
| ItrTime                 | 13.5       |
| LossAfter               | -0.36296   |
| LossBefore              | -0.334563  |
| MaxReturn               | 3.26e+03   |
| MeanKL                  | 0.00995572 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.73e+03   |
| NumTrajs                | 6          |
| Perplexity              | 11.0898    |
| PolicyExecTime          | 0.537      |
| ProcessExecTime         | 0.0629     |
| StdReturn               | 519        |
| Time                    | 2.94e+03   |
| dLoss                   | 0.0283976  |
----------------------------------------
itr #222 | 
Mem: 722.402344
Obtaining samples...
Obtaining samples for iteration 222...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5271, #subsample_inputs: 5271
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.667      |
| AbsLearnSignalNew       | 0.667      |
| AbsLearningOld          | 0.667      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 25.6501    |
| AveragePolicyStd        | 0.538567   |
| AverageReturn           | 2.73e+03   |
| Entropy                 | 2.39052    |
| EnvExecTime             | 2.61       |
| ExplainedVariance       | 0.723      |
| Iteration               | 222        |
| ItrTime                 | 14         |
| LossAfter               | 0.203421   |
| LossBefore              | 0.225471   |
| MaxReturn               | 3.11e+03   |
| MeanKL                  | 0.00655127 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.85e+03   |
| NumTrajs                | 6          |
| Perplexity              | 10.9192    |
| PolicyExecTime          | 0.659      |
| ProcessExecTime         | 0.0732     |
| StdReturn               | 481        |
| Time                    | 2.95e+03   |
| dLoss                   | 0.0220507  |
----------------------------------------
itr #223 | 
Mem: 722.402344
Obtaining samples...
Obtaining samples for iteration 223...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5702, #subsample_inputs: 5702
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.629     |
| AbsLearnSignalNew       | 0.629     |
| AbsLearningOld          | 0.629     |
| AverageDiscountedReturn | 244       |
| AveragePhiLoss          | 28.2618   |
| AveragePolicyStd        | 0.536549  |
| AverageReturn           | 2.6e+03   |
| Entropy                 | 2.37926   |
| EnvExecTime             | 2.38      |
| ExplainedVariance       | 0.722     |
| Iteration               | 223       |
| ItrTime                 | 14.5      |
| LossAfter               | 0.421983  |
| LossBefore              | 0.445484  |
| MaxReturn               | 3.12e+03  |
| MeanKL                  | 0.0099468 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.96e+03  |
| NumTrajs                | 7         |
| Perplexity              | 10.797    |
| PolicyExecTime          | 0.603     |
| ProcessExecTime         | 0.0673    |
| StdReturn               | 379       |
| Time                    | 2.96e+03  |
| dLoss                   | 0.0235017 |
---------------------------------------
itr #224 | 
Mem: 723.378906
Obtaining samples...
Obtaining samples for iteration 224...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5537, #subsample_inputs: 5537
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.55       |
| AbsLearnSignalNew       | 0.55       |
| AbsLearningOld          | 0.55       |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 25.404     |
| AveragePolicyStd        | 0.540124   |
| AverageReturn           | 2.94e+03   |
| Entropy                 | 2.39838    |
| EnvExecTime             | 2.49       |
| ExplainedVariance       | 0.763      |
| Iteration               | 224        |
| ItrTime                 | 14.2       |
| LossAfter               | 0.84695    |
| LossBefore              | 0.865492   |
| MaxReturn               | 3.3e+03    |
| MeanKL                  | 0.00642248 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.79e+03   |
| NumTrajs                | 6          |
| Perplexity              | 11.0054    |
| PolicyExecTime          | 0.632      |
| ProcessExecTime         | 0.0703     |
| StdReturn               | 524        |
| Time                    | 2.98e+03   |
| dLoss                   | 0.0185412  |
----------------------------------------
itr #225 | 
Mem: 724.128906
Obtaining samples...
Obtaining samples for iteration 225...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5132, #subsample_inputs: 5132
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.555      |
| AbsLearnSignalNew       | 0.555      |
| AbsLearningOld          | 0.555      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 39.8863    |
| AveragePolicyStd        | 0.540828   |
| AverageReturn           | 2.39e+03   |
| Entropy                 | 2.40073    |
| EnvExecTime             | 2.32       |
| ExplainedVariance       | 0.697      |
| Iteration               | 225        |
| ItrTime                 | 13.4       |
| LossAfter               | -0.206152  |
| LossBefore              | -0.179403  |
| MaxReturn               | 3.32e+03   |
| MeanKL                  | 0.00648909 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.49e+03   |
| NumTrajs                | 7          |
| Perplexity              | 11.0313    |
| PolicyExecTime          | 0.586      |
| ProcessExecTime         | 0.0649     |
| StdReturn               | 749        |
| Time                    | 2.99e+03   |
| dLoss                   | 0.0267491  |
----------------------------------------
itr #226 | 
Mem: 724.144531
Obtaining samples...
Obtaining samples for iteration 226...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5187, #subsample_inputs: 5187
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.696     |
| AbsLearnSignalNew       | 0.696     |
| AbsLearningOld          | 0.696     |
| AverageDiscountedReturn | 250       |
| AveragePhiLoss          | 27.1496   |
| AveragePolicyStd        | 0.540255  |
| AverageReturn           | 2.42e+03  |
| Entropy                 | 2.39692   |
| EnvExecTime             | 1.95      |
| ExplainedVariance       | 0.767     |
| Iteration               | 226       |
| ItrTime                 | 13.1      |
| LossAfter               | -0.46161  |
| LossBefore              | -0.433542 |
| MaxReturn               | 3.2e+03   |
| MeanKL                  | 0.0098644 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.81e+03  |
| NumTrajs                | 7         |
| Perplexity              | 10.9893   |
| PolicyExecTime          | 0.481     |
| ProcessExecTime         | 0.0583    |
| StdReturn               | 607       |
| Time                    | 3.01e+03  |
| dLoss                   | 0.0280674 |
---------------------------------------
itr #227 | 
Mem: 724.144531
Obtaining samples...
Obtaining samples for iteration 227...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5537, #subsample_inputs: 5537
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.725      |
| AbsLearnSignalNew       | 0.725      |
| AbsLearningOld          | 0.725      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 27.0749    |
| AveragePolicyStd        | 0.540579   |
| AverageReturn           | 2.6e+03    |
| Entropy                 | 2.39801    |
| EnvExecTime             | 2.41       |
| ExplainedVariance       | 0.812      |
| Iteration               | 227        |
| ItrTime                 | 14.2       |
| LossAfter               | 0.456185   |
| LossBefore              | 0.480501   |
| MaxReturn               | 3.24e+03   |
| MeanKL                  | 0.00646298 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.32e+03   |
| NumTrajs                | 7          |
| Perplexity              | 11.0013    |
| PolicyExecTime          | 0.599      |
| ProcessExecTime         | 0.0707     |
| StdReturn               | 682        |
| Time                    | 3.02e+03   |
| dLoss                   | 0.0243151  |
----------------------------------------
itr #228 | 
Mem: 724.144531
Obtaining samples...
Obtaining samples for iteration 228...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5272, #subsample_inputs: 5272
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.693      |
| AbsLearnSignalNew       | 0.693      |
| AbsLearningOld          | 0.693      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 26.3242    |
| AveragePolicyStd        | 0.54023    |
| AverageReturn           | 2.42e+03   |
| Entropy                 | 2.39637    |
| EnvExecTime             | 2.24       |
| ExplainedVariance       | 0.843      |
| Iteration               | 228        |
| ItrTime                 | 13.5       |
| LossAfter               | 0.0505485  |
| LossBefore              | 0.078195   |
| MaxReturn               | 3.23e+03   |
| MeanKL                  | 0.00989148 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.64e+03   |
| NumTrajs                | 7          |
| Perplexity              | 10.9833    |
| PolicyExecTime          | 0.554      |
| ProcessExecTime         | 0.0654     |
| StdReturn               | 613        |
| Time                    | 3.03e+03   |
| dLoss                   | 0.0276465  |
----------------------------------------
itr #229 | 
Mem: 724.210938
Obtaining samples...
Obtaining samples for iteration 229...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5033, #subsample_inputs: 5033
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.715      |
| AbsLearnSignalNew       | 0.715      |
| AbsLearningOld          | 0.715      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 26.9641    |
| AveragePolicyStd        | 0.540316   |
| AverageReturn           | 1.85e+03   |
| Entropy                 | 2.39739    |
| EnvExecTime             | 2.37       |
| ExplainedVariance       | 0.861      |
| Iteration               | 229        |
| ItrTime                 | 13.3       |
| LossAfter               | -0.827974  |
| LossBefore              | -0.803404  |
| MaxReturn               | 3.1e+03    |
| MeanKL                  | 0.00644256 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.29e+03   |
| NumTrajs                | 9          |
| Perplexity              | 10.9944    |
| PolicyExecTime          | 0.589      |
| ProcessExecTime         | 0.0668     |
| StdReturn               | 588        |
| Time                    | 3.05e+03   |
| dLoss                   | 0.0245699  |
----------------------------------------
itr #230 | 
Mem: 724.210938
Obtaining samples...
Obtaining samples for iteration 230...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5542, #subsample_inputs: 5542
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.67       |
| AbsLearnSignalNew       | 0.67       |
| AbsLearningOld          | 0.669      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 30.3009    |
| AveragePolicyStd        | 0.542464   |
| AverageReturn           | 2.28e+03   |
| Entropy                 | 2.4089     |
| EnvExecTime             | 2.27       |
| ExplainedVariance       | 0.754      |
| Iteration               | 230        |
| ItrTime                 | 13.9       |
| LossAfter               | 0.413081   |
| LossBefore              | 0.444399   |
| MaxReturn               | 3.15e+03   |
| MeanKL                  | 0.00999867 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.42e+03   |
| NumTrajs                | 8          |
| Perplexity              | 11.1217    |
| PolicyExecTime          | 0.576      |
| ProcessExecTime         | 0.0648     |
| StdReturn               | 604        |
| Time                    | 3.06e+03   |
| dLoss                   | 0.0313179  |
----------------------------------------
itr #231 | 
Mem: 724.210938
Obtaining samples...
Obtaining samples for iteration 231...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5696, #subsample_inputs: 5696
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.671      |
| AbsLearnSignalNew       | 0.671      |
| AbsLearningOld          | 0.671      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 25.9383    |
| AveragePolicyStd        | 0.542416   |
| AverageReturn           | 2.08e+03   |
| Entropy                 | 2.40727    |
| EnvExecTime             | 2.14       |
| ExplainedVariance       | 0.822      |
| Iteration               | 231        |
| ItrTime                 | 14.1       |
| LossAfter               | -0.767171  |
| LossBefore              | -0.745756  |
| MaxReturn               | 3.25e+03   |
| MeanKL                  | 0.00645063 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.1e+03    |
| NumTrajs                | 9          |
| Perplexity              | 11.1036    |
| PolicyExecTime          | 0.542      |
| ProcessExecTime         | 0.0647     |
| StdReturn               | 772        |
| Time                    | 3.07e+03   |
| dLoss                   | 0.0214149  |
----------------------------------------
itr #232 | 
Mem: 724.210938
Obtaining samples...
Obtaining samples for iteration 232...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5383, #subsample_inputs: 5383
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.643      |
| AbsLearnSignalNew       | 0.643      |
| AbsLearningOld          | 0.643      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 32.8109    |
| AveragePolicyStd        | 0.541638   |
| AverageReturn           | 2e+03      |
| Entropy                 | 2.40275    |
| EnvExecTime             | 2.17       |
| ExplainedVariance       | 0.79       |
| Iteration               | 232        |
| ItrTime                 | 13.6       |
| LossAfter               | 0.152472   |
| LossBefore              | 0.175369   |
| MaxReturn               | 3.13e+03   |
| MeanKL                  | 0.00644837 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.21e+03   |
| NumTrajs                | 9          |
| Perplexity              | 11.0535    |
| PolicyExecTime          | 0.547      |
| ProcessExecTime         | 0.0618     |
| StdReturn               | 654        |
| Time                    | 3.09e+03   |
| dLoss                   | 0.0228963  |
----------------------------------------
itr #233 | 
Mem: 724.210938
Obtaining samples...
Obtaining samples for iteration 233...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5055, #subsample_inputs: 5055
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.728      |
| AbsLearnSignalNew       | 0.728      |
| AbsLearningOld          | 0.728      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 28.6635    |
| AveragePolicyStd        | 0.538497   |
| AverageReturn           | 2.35e+03   |
| Entropy                 | 2.38622    |
| EnvExecTime             | 1.79       |
| ExplainedVariance       | 0.73       |
| Iteration               | 233        |
| ItrTime                 | 12.6       |
| LossAfter               | -0.192495  |
| LossBefore              | -0.163305  |
| MaxReturn               | 3.19e+03   |
| MeanKL                  | 0.00990995 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.42e+03   |
| NumTrajs                | 7          |
| Perplexity              | 10.8723    |
| PolicyExecTime          | 0.462      |
| ProcessExecTime         | 0.0535     |
| StdReturn               | 590        |
| Time                    | 3.1e+03    |
| dLoss                   | 0.0291905  |
----------------------------------------
itr #234 | 
Mem: 724.210938
Obtaining samples...
Obtaining samples for iteration 234...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5013, #subsample_inputs: 5013
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.688      |
| AbsLearnSignalNew       | 0.688      |
| AbsLearningOld          | 0.688      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 28.9768    |
| AveragePolicyStd        | 0.539902   |
| AverageReturn           | 2.7e+03    |
| Entropy                 | 2.39181    |
| EnvExecTime             | 2.11       |
| ExplainedVariance       | 0.822      |
| Iteration               | 234        |
| ItrTime                 | 12.9       |
| LossAfter               | -1.12673   |
| LossBefore              | -1.09191   |
| MaxReturn               | 3.32e+03   |
| MeanKL                  | 0.00992531 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.01e+03   |
| NumTrajs                | 6          |
| Perplexity              | 10.9333    |
| PolicyExecTime          | 0.536      |
| ProcessExecTime         | 0.0602     |
| StdReturn               | 776        |
| Time                    | 3.11e+03   |
| dLoss                   | 0.0348176  |
----------------------------------------
itr #235 | 
Mem: 724.398438
Obtaining samples...
Obtaining samples for iteration 235...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5417, #subsample_inputs: 5417
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.734      |
| AbsLearnSignalNew       | 0.734      |
| AbsLearningOld          | 0.734      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 29.0766    |
| AveragePolicyStd        | 0.538925   |
| AverageReturn           | 2.87e+03   |
| Entropy                 | 2.3863     |
| EnvExecTime             | 2.67       |
| ExplainedVariance       | 0.841      |
| Iteration               | 235        |
| ItrTime                 | 14.3       |
| LossAfter               | 0.338463   |
| LossBefore              | 0.364288   |
| MaxReturn               | 3.26e+03   |
| MeanKL                  | 0.00982155 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.94e+03   |
| NumTrajs                | 6          |
| Perplexity              | 10.8732    |
| PolicyExecTime          | 0.668      |
| ProcessExecTime         | 0.0743     |
| StdReturn               | 437        |
| Time                    | 3.13e+03   |
| dLoss                   | 0.0258246  |
----------------------------------------
itr #236 | 
Mem: 724.398438
Obtaining samples...
Obtaining samples for iteration 236...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5179, #subsample_inputs: 5179
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.53       |
| AbsLearnSignalNew       | 0.53       |
| AbsLearningOld          | 0.53       |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 33.2912    |
| AveragePolicyStd        | 0.537513   |
| AverageReturn           | 2.47e+03   |
| Entropy                 | 2.3787     |
| EnvExecTime             | 2.24       |
| ExplainedVariance       | 0.466      |
| Iteration               | 236        |
| ItrTime                 | 13.4       |
| LossAfter               | -0.696182  |
| LossBefore              | -0.674592  |
| MaxReturn               | 3.43e+03   |
| MeanKL                  | 0.00661883 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.96e+03   |
| NumTrajs                | 7          |
| Perplexity              | 10.7908    |
| PolicyExecTime          | 0.559      |
| ProcessExecTime         | 0.0642     |
| StdReturn               | 569        |
| Time                    | 3.14e+03   |
| dLoss                   | 0.0215895  |
----------------------------------------
itr #237 | 
Mem: 724.398438
Obtaining samples...
Obtaining samples for iteration 237...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5125, #subsample_inputs: 5125
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.676      |
| AbsLearnSignalNew       | 0.676      |
| AbsLearningOld          | 0.676      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 24.7438    |
| AveragePolicyStd        | 0.535907   |
| AverageReturn           | 2.44e+03   |
| Entropy                 | 2.3705     |
| EnvExecTime             | 2.28       |
| ExplainedVariance       | 0.778      |
| Iteration               | 237        |
| ItrTime                 | 13.4       |
| LossAfter               | 0.964702   |
| LossBefore              | 0.991414   |
| MaxReturn               | 3.17e+03   |
| MeanKL                  | 0.00980026 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.91e+03   |
| NumTrajs                | 7          |
| Perplexity              | 10.7028    |
| PolicyExecTime          | 0.576      |
| ProcessExecTime         | 0.065      |
| StdReturn               | 389        |
| Time                    | 3.16e+03   |
| dLoss                   | 0.0267121  |
----------------------------------------
itr #238 | 
Mem: 724.398438
Obtaining samples...
Obtaining samples for iteration 238...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5798, #subsample_inputs: 5798
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.696      |
| AbsLearnSignalNew       | 0.696      |
| AbsLearningOld          | 0.696      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 28.9904    |
| AveragePolicyStd        | 0.537995   |
| AverageReturn           | 2.15e+03   |
| Entropy                 | 2.38262    |
| EnvExecTime             | 2.75       |
| ExplainedVariance       | 0.745      |
| Iteration               | 238        |
| ItrTime                 | 14.9       |
| LossAfter               | 0.0656864  |
| LossBefore              | 0.0862999  |
| MaxReturn               | 3.3e+03    |
| MeanKL                  | 0.00661343 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.21e+03   |
| NumTrajs                | 9          |
| Perplexity              | 10.8332    |
| PolicyExecTime          | 0.679      |
| ProcessExecTime         | 0.0798     |
| StdReturn               | 666        |
| Time                    | 3.17e+03   |
| dLoss                   | 0.0206135  |
----------------------------------------
itr #239 | 
Mem: 724.398438
Obtaining samples...
Obtaining samples for iteration 239...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5874, #subsample_inputs: 5874
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.723      |
| AbsLearnSignalNew       | 0.723      |
| AbsLearningOld          | 0.723      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 31.0722    |
| AveragePolicyStd        | 0.53593    |
| AverageReturn           | 1.8e+03    |
| Entropy                 | 2.37144    |
| EnvExecTime             | 2.98       |
| ExplainedVariance       | 0.871      |
| Iteration               | 239        |
| ItrTime                 | 15.3       |
| LossAfter               | 0.154267   |
| LossBefore              | 0.175677   |
| MaxReturn               | 2.92e+03   |
| MeanKL                  | 0.00641388 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.14e+03   |
| NumTrajs                | 11         |
| Perplexity              | 10.7128    |
| PolicyExecTime          | 0.728      |
| ProcessExecTime         | 0.0835     |
| StdReturn               | 611        |
| Time                    | 3.19e+03   |
| dLoss                   | 0.0214094  |
----------------------------------------
itr #240 | 
Mem: 724.398438
Obtaining samples...
Obtaining samples for iteration 240...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5072, #subsample_inputs: 5072
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.542      |
| AbsLearnSignalNew       | 0.542      |
| AbsLearningOld          | 0.542      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 27.7936    |
| AveragePolicyStd        | 0.533466   |
| AverageReturn           | 1.69e+03   |
| Entropy                 | 2.35785    |
| EnvExecTime             | 2.29       |
| ExplainedVariance       | 0.571      |
| Iteration               | 240        |
| ItrTime                 | 13.2       |
| LossAfter               | 0.367732   |
| LossBefore              | 0.392621   |
| MaxReturn               | 3.22e+03   |
| MeanKL                  | 0.00641916 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 163        |
| NumTrajs                | 10         |
| Perplexity              | 10.5682    |
| PolicyExecTime          | 0.586      |
| ProcessExecTime         | 0.0638     |
| StdReturn               | 800        |
| Time                    | 3.2e+03    |
| dLoss                   | 0.0248891  |
----------------------------------------
itr #241 | 
Mem: 724.398438
Obtaining samples...
Obtaining samples for iteration 241...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5586, #subsample_inputs: 5586
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.649      |
| AbsLearnSignalNew       | 0.649      |
| AbsLearningOld          | 0.649      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 27.2962    |
| AveragePolicyStd        | 0.533918   |
| AverageReturn           | 2.03e+03   |
| Entropy                 | 2.36107    |
| EnvExecTime             | 2.73       |
| ExplainedVariance       | 0.601      |
| Iteration               | 241        |
| ItrTime                 | 14.6       |
| LossAfter               | 0.00522351 |
| LossBefore              | 0.027582   |
| MaxReturn               | 3.23e+03   |
| MeanKL                  | 0.00645819 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.01e+03   |
| NumTrajs                | 9          |
| Perplexity              | 10.6023    |
| PolicyExecTime          | 0.684      |
| ProcessExecTime         | 0.0746     |
| StdReturn               | 780        |
| Time                    | 3.21e+03   |
| dLoss                   | 0.0223585  |
----------------------------------------
itr #242 | 
Mem: 724.402344
Obtaining samples...
Obtaining samples for iteration 242...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5430, #subsample_inputs: 5430
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.707      |
| AbsLearnSignalNew       | 0.707      |
| AbsLearningOld          | 0.707      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 29.3371    |
| AveragePolicyStd        | 0.534913   |
| AverageReturn           | 2e+03      |
| Entropy                 | 2.36695    |
| EnvExecTime             | 2.24       |
| ExplainedVariance       | 0.685      |
| Iteration               | 242        |
| ItrTime                 | 13.9       |
| LossAfter               | -0.427568  |
| LossBefore              | -0.403036  |
| MaxReturn               | 3.24e+03   |
| MeanKL                  | 0.00669288 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1e+03      |
| NumTrajs                | 9          |
| Perplexity              | 10.6648    |
| PolicyExecTime          | 0.561      |
| ProcessExecTime         | 0.0653     |
| StdReturn               | 690        |
| Time                    | 3.23e+03   |
| dLoss                   | 0.0245316  |
----------------------------------------
itr #243 | 
Mem: 724.402344
Obtaining samples...
Obtaining samples for iteration 243...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5326, #subsample_inputs: 5326
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.69       |
| AbsLearnSignalNew       | 0.69       |
| AbsLearningOld          | 0.69       |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 33.5986    |
| AveragePolicyStd        | 0.532434   |
| AverageReturn           | 1.98e+03   |
| Entropy                 | 2.35254    |
| EnvExecTime             | 2.47       |
| ExplainedVariance       | 0.727      |
| Iteration               | 243        |
| ItrTime                 | 13.9       |
| LossAfter               | -0.478397  |
| LossBefore              | -0.454436  |
| MaxReturn               | 3.38e+03   |
| MeanKL                  | 0.00648928 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 996        |
| NumTrajs                | 9          |
| Perplexity              | 10.5122    |
| PolicyExecTime          | 0.623      |
| ProcessExecTime         | 0.0696     |
| StdReturn               | 837        |
| Time                    | 3.24e+03   |
| dLoss                   | 0.0239614  |
----------------------------------------
itr #244 | 
Mem: 724.402344
Obtaining samples...
Obtaining samples for iteration 244...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5685, #subsample_inputs: 5685
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.62       |
| AbsLearnSignalNew       | 0.62       |
| AbsLearningOld          | 0.62       |
| AverageDiscountedReturn | 254        |
| AveragePhiLoss          | 31.9025    |
| AveragePolicyStd        | 0.531273   |
| AverageReturn           | 2.71e+03   |
| Entropy                 | 2.34548    |
| EnvExecTime             | 2.25       |
| ExplainedVariance       | 0.76       |
| Iteration               | 244        |
| ItrTime                 | 14.1       |
| LossAfter               | -0.578523  |
| LossBefore              | -0.552963  |
| MaxReturn               | 3.34e+03   |
| MeanKL                  | 0.00966921 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.55e+03   |
| NumTrajs                | 7          |
| Perplexity              | 10.4383    |
| PolicyExecTime          | 0.577      |
| ProcessExecTime         | 0.0642     |
| StdReturn               | 690        |
| Time                    | 3.26e+03   |
| dLoss                   | 0.02556    |
----------------------------------------
itr #245 | 
Mem: 724.402344
Obtaining samples...
Obtaining samples for iteration 245...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5370, #subsample_inputs: 5370
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.548      |
| AbsLearnSignalNew       | 0.548      |
| AbsLearningOld          | 0.548      |
| AverageDiscountedReturn | 236        |
| AveragePhiLoss          | 31.7165    |
| AveragePolicyStd        | 0.531619   |
| AverageReturn           | 1.96e+03   |
| Entropy                 | 2.34723    |
| EnvExecTime             | 2.17       |
| ExplainedVariance       | 0.706      |
| Iteration               | 245        |
| ItrTime                 | 13.7       |
| LossAfter               | 0.444838   |
| LossBefore              | 0.478161   |
| MaxReturn               | 3.28e+03   |
| MeanKL                  | 0.00996552 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 176        |
| NumTrajs                | 9          |
| Perplexity              | 10.4566    |
| PolicyExecTime          | 0.548      |
| ProcessExecTime         | 0.0637     |
| StdReturn               | 980        |
| Time                    | 3.27e+03   |
| dLoss                   | 0.0333227  |
----------------------------------------
itr #246 | 
Mem: 724.402344
Obtaining samples...
Obtaining samples for iteration 246...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5000, #subsample_inputs: 5000
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.768      |
| AbsLearnSignalNew       | 0.768      |
| AbsLearningOld          | 0.768      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 28.9324    |
| AveragePolicyStd        | 0.531184   |
| AverageReturn           | 3.1e+03    |
| Entropy                 | 2.34554    |
| EnvExecTime             | 1.73       |
| ExplainedVariance       | 0.808      |
| Iteration               | 246        |
| ItrTime                 | 12.4       |
| LossAfter               | 0.233288   |
| LossBefore              | 0.253611   |
| MaxReturn               | 3.32e+03   |
| MeanKL                  | 0.00648644 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 2.87e+03   |
| NumTrajs                | 5          |
| Perplexity              | 10.4389    |
| PolicyExecTime          | 0.431      |
| ProcessExecTime         | 0.0534     |
| StdReturn               | 154        |
| Time                    | 3.28e+03   |
| dLoss                   | 0.0203229  |
----------------------------------------
itr #247 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 247...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5345, #subsample_inputs: 5345
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.5        |
| AbsLearnSignalNew       | 0.5        |
| AbsLearningOld          | 0.5        |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 39.814     |
| AveragePolicyStd        | 0.530383   |
| AverageReturn           | 2.48e+03   |
| Entropy                 | 2.34142    |
| EnvExecTime             | 2.09       |
| ExplainedVariance       | 0.665      |
| Iteration               | 247        |
| ItrTime                 | 13.5       |
| LossAfter               | 0.822728   |
| LossBefore              | 0.858237   |
| MaxReturn               | 3.25e+03   |
| MeanKL                  | 0.00973661 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.15e+03   |
| NumTrajs                | 7          |
| Perplexity              | 10.396     |
| PolicyExecTime          | 0.533      |
| ProcessExecTime         | 0.0616     |
| StdReturn               | 857        |
| Time                    | 3.3e+03    |
| dLoss                   | 0.0355089  |
----------------------------------------
itr #248 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 248...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5381, #subsample_inputs: 5381
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
-----------------------------------------
| AbsLearnSignal          | 0.664       |
| AbsLearnSignalNew       | 0.664       |
| AbsLearningOld          | 0.664       |
| AverageDiscountedReturn | 249         |
| AveragePhiLoss          | 28.4798     |
| AveragePolicyStd        | 0.530354    |
| AverageReturn           | 2.21e+03    |
| Entropy                 | 2.34021     |
| EnvExecTime             | 2.52        |
| ExplainedVariance       | 0.84        |
| Iteration               | 248         |
| ItrTime                 | 14.1        |
| LossAfter               | -0.00875805 |
| LossBefore              | 0.0118169   |
| MaxReturn               | 3.11e+03    |
| MeanKL                  | 0.00644297  |
| MeanKLBefore            | 0.0         |
| MinReturn               | 1.04e+03    |
| NumTrajs                | 8           |
| Perplexity              | 10.3835     |
| PolicyExecTime          | 0.632       |
| ProcessExecTime         | 0.0721      |
| StdReturn               | 608         |
| Time                    | 3.31e+03    |
| dLoss                   | 0.020575    |
-----------------------------------------
itr #249 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 249...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5228, #subsample_inputs: 5228
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.554      |
| AbsLearnSignalNew       | 0.554      |
| AbsLearningOld          | 0.554      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 34.9876    |
| AveragePolicyStd        | 0.528148   |
| AverageReturn           | 2.5e+03    |
| Entropy                 | 2.32836    |
| EnvExecTime             | 2.11       |
| ExplainedVariance       | 0.642      |
| Iteration               | 249        |
| ItrTime                 | 13.2       |
| LossAfter               | -0.958441  |
| LossBefore              | -0.939534  |
| MaxReturn               | 3.35e+03   |
| MeanKL                  | 0.00641206 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.19e+03   |
| NumTrajs                | 7          |
| Perplexity              | 10.2611    |
| PolicyExecTime          | 0.544      |
| ProcessExecTime         | 0.0609     |
| StdReturn               | 810        |
| Time                    | 3.32e+03   |
| dLoss                   | 0.0189075  |
----------------------------------------
itr #250 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 250...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5330, #subsample_inputs: 5330
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.62       |
| AbsLearnSignalNew       | 0.62       |
| AbsLearningOld          | 0.62       |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 35.5756    |
| AveragePolicyStd        | 0.526351   |
| AverageReturn           | 2.85e+03   |
| Entropy                 | 2.31976    |
| EnvExecTime             | 2.31       |
| ExplainedVariance       | 0.806      |
| Iteration               | 250        |
| ItrTime                 | 13.8       |
| LossAfter               | -0.219323  |
| LossBefore              | -0.197938  |
| MaxReturn               | 3.28e+03   |
| MeanKL                  | 0.00648723 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.49e+03   |
| NumTrajs                | 6          |
| Perplexity              | 10.1733    |
| PolicyExecTime          | 0.586      |
| ProcessExecTime         | 0.0657     |
| StdReturn               | 622        |
| Time                    | 3.34e+03   |
| dLoss                   | 0.0213842  |
----------------------------------------
itr #251 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 251...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5625, #subsample_inputs: 5625
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.707      |
| AbsLearnSignalNew       | 0.707      |
| AbsLearningOld          | 0.707      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 30.1883    |
| AveragePolicyStd        | 0.526125   |
| AverageReturn           | 2.29e+03   |
| Entropy                 | 2.31759    |
| EnvExecTime             | 2.14       |
| ExplainedVariance       | 0.822      |
| Iteration               | 251        |
| ItrTime                 | 13.9       |
| LossAfter               | 0.166868   |
| LossBefore              | 0.18736    |
| MaxReturn               | 2.96e+03   |
| MeanKL                  | 0.00643052 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.5e+03    |
| NumTrajs                | 8          |
| Perplexity              | 10.1512    |
| PolicyExecTime          | 0.547      |
| ProcessExecTime         | 0.0624     |
| StdReturn               | 495        |
| Time                    | 3.35e+03   |
| dLoss                   | 0.0204921  |
----------------------------------------
itr #252 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 252...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5221, #subsample_inputs: 5221
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.713      |
| AbsLearnSignalNew       | 0.713      |
| AbsLearningOld          | 0.713      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 29.2337    |
| AveragePolicyStd        | 0.524257   |
| AverageReturn           | 1.7e+03    |
| Entropy                 | 2.30856    |
| EnvExecTime             | 2.28       |
| ExplainedVariance       | 0.88       |
| Iteration               | 252        |
| ItrTime                 | 13.5       |
| LossAfter               | 0.151871   |
| LossBefore              | 0.177149   |
| MaxReturn               | 3.01e+03   |
| MeanKL                  | 0.00990262 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.35e+03   |
| NumTrajs                | 10         |
| Perplexity              | 10.06      |
| PolicyExecTime          | 0.577      |
| ProcessExecTime         | 0.0645     |
| StdReturn               | 479        |
| Time                    | 3.36e+03   |
| dLoss                   | 0.0252787  |
----------------------------------------
itr #253 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 253...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5621, #subsample_inputs: 5621
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.647      |
| AbsLearnSignalNew       | 0.647      |
| AbsLearningOld          | 0.647      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 69.558     |
| AveragePolicyStd        | 0.524789   |
| AverageReturn           | 2.25e+03   |
| Entropy                 | 2.30893    |
| EnvExecTime             | 2.63       |
| ExplainedVariance       | 0.806      |
| Iteration               | 253        |
| ItrTime                 | 14.4       |
| LossAfter               | -3.13495   |
| LossBefore              | -3.05024   |
| MaxReturn               | 2.99e+03   |
| MeanKL                  | 0.00992445 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.56e+03   |
| NumTrajs                | 8          |
| Perplexity              | 10.0637    |
| PolicyExecTime          | 0.648      |
| ProcessExecTime         | 0.0747     |
| StdReturn               | 525        |
| Time                    | 3.38e+03   |
| dLoss                   | 0.0847101  |
----------------------------------------
itr #254 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 254...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5224, #subsample_inputs: 5224
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.719      |
| AbsLearnSignalNew       | 0.719      |
| AbsLearningOld          | 0.719      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 32.6244    |
| AveragePolicyStd        | 0.525102   |
| AverageReturn           | 2.4e+03    |
| Entropy                 | 2.31064    |
| EnvExecTime             | 2.16       |
| ExplainedVariance       | 0.802      |
| Iteration               | 254        |
| ItrTime                 | 13.3       |
| LossAfter               | 0.134049   |
| LossBefore              | 0.156884   |
| MaxReturn               | 3.02e+03   |
| MeanKL                  | 0.00994599 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.76e+03   |
| NumTrajs                | 7          |
| Perplexity              | 10.0809    |
| PolicyExecTime          | 0.541      |
| ProcessExecTime         | 0.0633     |
| StdReturn               | 432        |
| Time                    | 3.39e+03   |
| dLoss                   | 0.0228346  |
----------------------------------------
itr #255 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 255...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5212, #subsample_inputs: 5212
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.716      |
| AbsLearnSignalNew       | 0.716      |
| AbsLearningOld          | 0.716      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 30.0877    |
| AveragePolicyStd        | 0.524201   |
| AverageReturn           | 2.36e+03   |
| Entropy                 | 2.30493    |
| EnvExecTime             | 2.34       |
| ExplainedVariance       | 0.824      |
| Iteration               | 255        |
| ItrTime                 | 13.6       |
| LossAfter               | -0.0524962 |
| LossBefore              | -0.0214038 |
| MaxReturn               | 3.05e+03   |
| MeanKL                  | 0.00973004 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.73e+03   |
| NumTrajs                | 7          |
| Perplexity              | 10.0235    |
| PolicyExecTime          | 0.591      |
| ProcessExecTime         | 0.0687     |
| StdReturn               | 433        |
| Time                    | 3.41e+03   |
| dLoss                   | 0.0310924  |
----------------------------------------
itr #256 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 256...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5188, #subsample_inputs: 5188
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.729      |
| AbsLearnSignalNew       | 0.729      |
| AbsLearningOld          | 0.729      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 32.3029    |
| AveragePolicyStd        | 0.525076   |
| AverageReturn           | 2.09e+03   |
| Entropy                 | 2.31054    |
| EnvExecTime             | 1.93       |
| ExplainedVariance       | 0.874      |
| Iteration               | 256        |
| ItrTime                 | 13         |
| LossAfter               | -0.405533  |
| LossBefore              | -0.382299  |
| MaxReturn               | 3.26e+03   |
| MeanKL                  | 0.00657152 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.37e+03   |
| NumTrajs                | 8          |
| Perplexity              | 10.0798    |
| PolicyExecTime          | 0.485      |
| ProcessExecTime         | 0.0586     |
| StdReturn               | 627        |
| Time                    | 3.42e+03   |
| dLoss                   | 0.0232342  |
----------------------------------------
itr #257 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 257...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5733, #subsample_inputs: 5733
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.61       |
| AbsLearnSignalNew       | 0.61       |
| AbsLearningOld          | 0.61       |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 29.8357    |
| AveragePolicyStd        | 0.524857   |
| AverageReturn           | 1.73e+03   |
| Entropy                 | 2.30924    |
| EnvExecTime             | 2.25       |
| ExplainedVariance       | 0.782      |
| Iteration               | 257        |
| ItrTime                 | 14.1       |
| LossAfter               | 0.379969   |
| LossBefore              | 0.405194   |
| MaxReturn               | 2.59e+03   |
| MeanKL                  | 0.00984726 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 188        |
| NumTrajs                | 11         |
| Perplexity              | 10.0668    |
| PolicyExecTime          | 0.548      |
| ProcessExecTime         | 0.0685     |
| StdReturn               | 624        |
| Time                    | 3.43e+03   |
| dLoss                   | 0.0252255  |
----------------------------------------
itr #258 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 258...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5338, #subsample_inputs: 5338
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.698      |
| AbsLearnSignalNew       | 0.698      |
| AbsLearningOld          | 0.698      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 29.3192    |
| AveragePolicyStd        | 0.523894   |
| AverageReturn           | 2.16e+03   |
| Entropy                 | 2.30391    |
| EnvExecTime             | 2.46       |
| ExplainedVariance       | 0.764      |
| Iteration               | 258        |
| ItrTime                 | 14         |
| LossAfter               | 0.502217   |
| LossBefore              | 0.527879   |
| MaxReturn               | 3.18e+03   |
| MeanKL                  | 0.00981073 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.08e+03   |
| NumTrajs                | 8          |
| Perplexity              | 10.0133    |
| PolicyExecTime          | 0.62       |
| ProcessExecTime         | 0.0688     |
| StdReturn               | 731        |
| Time                    | 3.45e+03   |
| dLoss                   | 0.0256615  |
----------------------------------------
itr #259 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 259...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5333, #subsample_inputs: 5333
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.706      |
| AbsLearnSignalNew       | 0.706      |
| AbsLearningOld          | 0.706      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 30.2824    |
| AveragePolicyStd        | 0.523362   |
| AverageReturn           | 2.41e+03   |
| Entropy                 | 2.30052    |
| EnvExecTime             | 2.14       |
| ExplainedVariance       | 0.744      |
| Iteration               | 259        |
| ItrTime                 | 13.6       |
| LossAfter               | 0.136487   |
| LossBefore              | 0.165976   |
| MaxReturn               | 3.27e+03   |
| MeanKL                  | 0.00977064 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.44e+03   |
| NumTrajs                | 7          |
| Perplexity              | 9.97941    |
| PolicyExecTime          | 0.555      |
| ProcessExecTime         | 0.0612     |
| StdReturn               | 687        |
| Time                    | 3.46e+03   |
| dLoss                   | 0.0294892  |
----------------------------------------
itr #260 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 260...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5055, #subsample_inputs: 5055
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.647      |
| AbsLearnSignalNew       | 0.647      |
| AbsLearningOld          | 0.647      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 29.2342    |
| AveragePolicyStd        | 0.524069   |
| AverageReturn           | 2.46e+03   |
| Entropy                 | 2.3055     |
| EnvExecTime             | 2.33       |
| ExplainedVariance       | 0.821      |
| Iteration               | 260        |
| ItrTime                 | 13.3       |
| LossAfter               | -0.841922  |
| LossBefore              | -0.812158  |
| MaxReturn               | 2.97e+03   |
| MeanKL                  | 0.00991303 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.52e+03   |
| NumTrajs                | 6          |
| Perplexity              | 10.0292    |
| PolicyExecTime          | 0.592      |
| ProcessExecTime         | 0.0655     |
| StdReturn               | 526        |
| Time                    | 3.48e+03   |
| dLoss                   | 0.0297636  |
----------------------------------------
itr #261 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 261...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5386, #subsample_inputs: 5386
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.509      |
| AbsLearnSignalNew       | 0.509      |
| AbsLearningOld          | 0.509      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 33.8095    |
| AveragePolicyStd        | 0.52298    |
| AverageReturn           | 2.51e+03   |
| Entropy                 | 2.29935    |
| EnvExecTime             | 2.17       |
| ExplainedVariance       | 0.629      |
| Iteration               | 261        |
| ItrTime                 | 13.6       |
| LossAfter               | -1.08477   |
| LossBefore              | -1.05663   |
| MaxReturn               | 3.19e+03   |
| MeanKL                  | 0.00996537 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.28e+03   |
| NumTrajs                | 7          |
| Perplexity              | 9.96774    |
| PolicyExecTime          | 0.551      |
| ProcessExecTime         | 0.0628     |
| StdReturn               | 624        |
| Time                    | 3.49e+03   |
| dLoss                   | 0.0281367  |
----------------------------------------
itr #262 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 262...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5765, #subsample_inputs: 5765
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.72      |
| AbsLearnSignalNew       | 0.72      |
| AbsLearningOld          | 0.72      |
| AverageDiscountedReturn | 248       |
| AveragePhiLoss          | 30.4285   |
| AveragePolicyStd        | 0.520175  |
| AverageReturn           | 1.9e+03   |
| Entropy                 | 2.28303   |
| EnvExecTime             | 2.55      |
| ExplainedVariance       | 0.811     |
| Iteration               | 262       |
| ItrTime                 | 14.6      |
| LossAfter               | 0.192205  |
| LossBefore              | 0.212747  |
| MaxReturn               | 2.85e+03  |
| MeanKL                  | 0.0065257 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.19e+03  |
| NumTrajs                | 10        |
| Perplexity              | 9.80631   |
| PolicyExecTime          | 0.639     |
| ProcessExecTime         | 0.0723    |
| StdReturn               | 539       |
| Time                    | 3.5e+03   |
| dLoss                   | 0.0205419 |
---------------------------------------
itr #263 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 263...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5035, #subsample_inputs: 5035
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.668      |
| AbsLearnSignalNew       | 0.668      |
| AbsLearningOld          | 0.668      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 31.0804    |
| AveragePolicyStd        | 0.521356   |
| AverageReturn           | 1.86e+03   |
| Entropy                 | 2.29017    |
| EnvExecTime             | 2.21       |
| ExplainedVariance       | 0.841      |
| Iteration               | 263        |
| ItrTime                 | 13.2       |
| LossAfter               | -1.31368   |
| LossBefore              | -1.29074   |
| MaxReturn               | 2.49e+03   |
| MeanKL                  | 0.00649201 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.44e+03   |
| NumTrajs                | 9          |
| Perplexity              | 9.8766     |
| PolicyExecTime          | 0.552      |
| ProcessExecTime         | 0.0635     |
| StdReturn               | 344        |
| Time                    | 3.52e+03   |
| dLoss                   | 0.0229423  |
----------------------------------------
itr #264 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 264...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5526, #subsample_inputs: 5526
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.782      |
| AbsLearnSignalNew       | 0.782      |
| AbsLearningOld          | 0.782      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 31.1644    |
| AveragePolicyStd        | 0.522123   |
| AverageReturn           | 1.84e+03   |
| Entropy                 | 2.29449    |
| EnvExecTime             | 2.01       |
| ExplainedVariance       | 0.897      |
| Iteration               | 264        |
| ItrTime                 | 13.5       |
| LossAfter               | 0.305379   |
| LossBefore              | 0.331743   |
| MaxReturn               | 2.91e+03   |
| MeanKL                  | 0.00648254 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.18e+03   |
| NumTrajs                | 10         |
| Perplexity              | 9.91941    |
| PolicyExecTime          | 0.508      |
| ProcessExecTime         | 0.0591     |
| StdReturn               | 506        |
| Time                    | 3.53e+03   |
| dLoss                   | 0.0263641  |
----------------------------------------
itr #265 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 265...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5386, #subsample_inputs: 5386
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.695      |
| AbsLearnSignalNew       | 0.695      |
| AbsLearningOld          | 0.695      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 30.758     |
| AveragePolicyStd        | 0.521487   |
| AverageReturn           | 2.32e+03   |
| Entropy                 | 2.29122    |
| EnvExecTime             | 2.65       |
| ExplainedVariance       | 0.756      |
| Iteration               | 265        |
| ItrTime                 | 14.3       |
| LossAfter               | 0.254485   |
| LossBefore              | 0.274818   |
| MaxReturn               | 3.18e+03   |
| MeanKL                  | 0.00643851 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.23e+03   |
| NumTrajs                | 7          |
| Perplexity              | 9.88703    |
| PolicyExecTime          | 0.654      |
| ProcessExecTime         | 0.0729     |
| StdReturn               | 691        |
| Time                    | 3.55e+03   |
| dLoss                   | 0.0203335  |
----------------------------------------
itr #266 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 266...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5635, #subsample_inputs: 5635
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.644      |
| AbsLearnSignalNew       | 0.644      |
| AbsLearningOld          | 0.644      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 34.5417    |
| AveragePolicyStd        | 0.520138   |
| AverageReturn           | 2.56e+03   |
| Entropy                 | 2.28291    |
| EnvExecTime             | 2.17       |
| ExplainedVariance       | 0.773      |
| Iteration               | 266        |
| ItrTime                 | 13.9       |
| LossAfter               | 0.244394   |
| LossBefore              | 0.28016    |
| MaxReturn               | 3.26e+03   |
| MeanKL                  | 0.00991136 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.08e+03   |
| NumTrajs                | 7          |
| Perplexity              | 9.80516    |
| PolicyExecTime          | 0.547      |
| ProcessExecTime         | 0.0642     |
| StdReturn               | 763        |
| Time                    | 3.56e+03   |
| dLoss                   | 0.035766   |
----------------------------------------
itr #267 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 267...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5172, #subsample_inputs: 5172
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.535      |
| AbsLearnSignalNew       | 0.535      |
| AbsLearningOld          | 0.535      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 32.3459    |
| AveragePolicyStd        | 0.523395   |
| AverageReturn           | 2.05e+03   |
| Entropy                 | 2.30035    |
| EnvExecTime             | 2.54       |
| ExplainedVariance       | 0.559      |
| Iteration               | 267        |
| ItrTime                 | 13.8       |
| LossAfter               | 0.273704   |
| LossBefore              | 0.293614   |
| MaxReturn               | 2.89e+03   |
| MeanKL                  | 0.00642786 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.13e+03   |
| NumTrajs                | 8          |
| Perplexity              | 9.97771    |
| PolicyExecTime          | 0.637      |
| ProcessExecTime         | 0.0694     |
| StdReturn               | 562        |
| Time                    | 3.57e+03   |
| dLoss                   | 0.0199097  |
----------------------------------------
itr #268 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 268...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5659, #subsample_inputs: 5659
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.537      |
| AbsLearnSignalNew       | 0.537      |
| AbsLearningOld          | 0.537      |
| AverageDiscountedReturn | 195        |
| AveragePhiLoss          | 33.2763    |
| AveragePolicyStd        | 0.523546   |
| AverageReturn           | 1.37e+03   |
| Entropy                 | 2.30056    |
| EnvExecTime             | 2.5        |
| ExplainedVariance       | 0.307      |
| Iteration               | 268        |
| ItrTime                 | 14.4       |
| LossAfter               | 0.307709   |
| LossBefore              | 0.336503   |
| MaxReturn               | 3.06e+03   |
| MeanKL                  | 0.00654704 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 153        |
| NumTrajs                | 13         |
| Perplexity              | 9.97975    |
| PolicyExecTime          | 0.629      |
| ProcessExecTime         | 0.0722     |
| StdReturn               | 1.11e+03   |
| Time                    | 3.59e+03   |
| dLoss                   | 0.0287944  |
----------------------------------------
itr #269 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 269...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5276, #subsample_inputs: 5276
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.614      |
| AbsLearnSignalNew       | 0.614      |
| AbsLearningOld          | 0.614      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 32.6724    |
| AveragePolicyStd        | 0.523112   |
| AverageReturn           | 2.13e+03   |
| Entropy                 | 2.2978     |
| EnvExecTime             | 2.34       |
| ExplainedVariance       | 0.483      |
| Iteration               | 269        |
| ItrTime                 | 13.6       |
| LossAfter               | -1.14996   |
| LossBefore              | -1.12443   |
| MaxReturn               | 2.68e+03   |
| MeanKL                  | 0.00995723 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.47e+03   |
| NumTrajs                | 8          |
| Perplexity              | 9.95226    |
| PolicyExecTime          | 0.588      |
| ProcessExecTime         | 0.0672     |
| StdReturn               | 350        |
| Time                    | 3.6e+03    |
| dLoss                   | 0.0255363  |
----------------------------------------
itr #270 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 270...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5310, #subsample_inputs: 5310
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.518      |
| AbsLearnSignalNew       | 0.518      |
| AbsLearningOld          | 0.518      |
| AverageDiscountedReturn | 227        |
| AveragePhiLoss          | 35.2049    |
| AveragePolicyStd        | 0.521854   |
| AverageReturn           | 2.07e+03   |
| Entropy                 | 2.29086    |
| EnvExecTime             | 2.35       |
| ExplainedVariance       | 0.306      |
| Iteration               | 270        |
| ItrTime                 | 13.7       |
| LossAfter               | -0.634815  |
| LossBefore              | -0.612541  |
| MaxReturn               | 3.11e+03   |
| MeanKL                  | 0.00641714 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 166        |
| NumTrajs                | 8          |
| Perplexity              | 9.88339    |
| PolicyExecTime          | 0.595      |
| ProcessExecTime         | 0.0659     |
| StdReturn               | 863        |
| Time                    | 3.61e+03   |
| dLoss                   | 0.0222737  |
----------------------------------------
itr #271 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 271...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5615, #subsample_inputs: 5615
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.642      |
| AbsLearnSignalNew       | 0.642      |
| AbsLearningOld          | 0.642      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 32.2729    |
| AveragePolicyStd        | 0.521176   |
| AverageReturn           | 2.2e+03    |
| Entropy                 | 2.28762    |
| EnvExecTime             | 2.35       |
| ExplainedVariance       | 0.676      |
| Iteration               | 271        |
| ItrTime                 | 14.1       |
| LossAfter               | 0.332011   |
| LossBefore              | 0.357255   |
| MaxReturn               | 3.21e+03   |
| MeanKL                  | 0.00656067 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.48e+03   |
| NumTrajs                | 8          |
| Perplexity              | 9.85147    |
| PolicyExecTime          | 0.597      |
| ProcessExecTime         | 0.0687     |
| StdReturn               | 662        |
| Time                    | 3.63e+03   |
| dLoss                   | 0.0252433  |
----------------------------------------
itr #272 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 272...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5043, #subsample_inputs: 5043
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.731      |
| AbsLearnSignalNew       | 0.731      |
| AbsLearningOld          | 0.731      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 30.3809    |
| AveragePolicyStd        | 0.520269   |
| AverageReturn           | 2.67e+03   |
| Entropy                 | 2.28234    |
| EnvExecTime             | 2.66       |
| ExplainedVariance       | 0.812      |
| Iteration               | 272        |
| ItrTime                 | 13.7       |
| LossAfter               | -1.13001   |
| LossBefore              | -1.10059   |
| MaxReturn               | 3.31e+03   |
| MeanKL                  | 0.00996886 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 2.1e+03    |
| NumTrajs                | 6          |
| Perplexity              | 9.79958    |
| PolicyExecTime          | 0.661      |
| ProcessExecTime         | 0.071      |
| StdReturn               | 424        |
| Time                    | 3.64e+03   |
| dLoss                   | 0.0294255  |
----------------------------------------
itr #273 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 273...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5567, #subsample_inputs: 5567
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.719      |
| AbsLearnSignalNew       | 0.719      |
| AbsLearningOld          | 0.719      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 32.098     |
| AveragePolicyStd        | 0.520715   |
| AverageReturn           | 2.27e+03   |
| Entropy                 | 2.28445    |
| EnvExecTime             | 2.38       |
| ExplainedVariance       | 0.861      |
| Iteration               | 273        |
| ItrTime                 | 14.2       |
| LossAfter               | -0.465281  |
| LossBefore              | -0.437296  |
| MaxReturn               | 3.19e+03   |
| MeanKL                  | 0.00980037 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.56e+03   |
| NumTrajs                | 8          |
| Perplexity              | 9.82025    |
| PolicyExecTime          | 0.591      |
| ProcessExecTime         | 0.0718     |
| StdReturn               | 490        |
| Time                    | 3.66e+03   |
| dLoss                   | 0.0279856  |
----------------------------------------
itr #274 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 274...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5097, #subsample_inputs: 5097
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.691      |
| AbsLearnSignalNew       | 0.691      |
| AbsLearningOld          | 0.691      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 31.7648    |
| AveragePolicyStd        | 0.519942   |
| AverageReturn           | 2.51e+03   |
| Entropy                 | 2.28094    |
| EnvExecTime             | 2.5        |
| ExplainedVariance       | 0.733      |
| Iteration               | 274        |
| ItrTime                 | 13.5       |
| LossAfter               | 0.36501    |
| LossBefore              | 0.382824   |
| MaxReturn               | 3.23e+03   |
| MeanKL                  | 0.00645543 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.48e+03   |
| NumTrajs                | 6          |
| Perplexity              | 9.78585    |
| PolicyExecTime          | 0.62       |
| ProcessExecTime         | 0.072      |
| StdReturn               | 581        |
| Time                    | 3.67e+03   |
| dLoss                   | 0.0178138  |
----------------------------------------
itr #275 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 275...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5586, #subsample_inputs: 5586
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.663      |
| AbsLearnSignalNew       | 0.663      |
| AbsLearningOld          | 0.662      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 33.4287    |
| AveragePolicyStd        | 0.517885   |
| AverageReturn           | 2.73e+03   |
| Entropy                 | 2.268      |
| EnvExecTime             | 2.59       |
| ExplainedVariance       | 0.874      |
| Iteration               | 275        |
| ItrTime                 | 14.4       |
| LossAfter               | -0.661021  |
| LossBefore              | -0.637624  |
| MaxReturn               | 3.07e+03   |
| MeanKL                  | 0.00640058 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.93e+03   |
| NumTrajs                | 6          |
| Perplexity              | 9.66002    |
| PolicyExecTime          | 0.656      |
| ProcessExecTime         | 0.0743     |
| StdReturn               | 369        |
| Time                    | 3.69e+03   |
| dLoss                   | 0.023397   |
----------------------------------------
itr #276 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 276...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5311, #subsample_inputs: 5311
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.584      |
| AbsLearnSignalNew       | 0.584      |
| AbsLearningOld          | 0.583      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 34.2332    |
| AveragePolicyStd        | 0.518327   |
| AverageReturn           | 1.95e+03   |
| Entropy                 | 2.27051    |
| EnvExecTime             | 2.32       |
| ExplainedVariance       | 0.678      |
| Iteration               | 276        |
| ItrTime                 | 13.6       |
| LossAfter               | 1.18851    |
| LossBefore              | 1.21284    |
| MaxReturn               | 2.96e+03   |
| MeanKL                  | 0.00641586 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.47e+03   |
| NumTrajs                | 9          |
| Perplexity              | 9.6843     |
| PolicyExecTime          | 0.579      |
| ProcessExecTime         | 0.0664     |
| StdReturn               | 473        |
| Time                    | 3.7e+03    |
| dLoss                   | 0.0243326  |
----------------------------------------
itr #277 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 277...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5748, #subsample_inputs: 5748
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.74       |
| AbsLearnSignalNew       | 0.74       |
| AbsLearningOld          | 0.74       |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 53.6862    |
| AveragePolicyStd        | 0.515739   |
| AverageReturn           | 2.36e+03   |
| Entropy                 | 2.25629    |
| EnvExecTime             | 2.44       |
| ExplainedVariance       | 0.806      |
| Iteration               | 277        |
| ItrTime                 | 14.4       |
| LossAfter               | -0.167622  |
| LossBefore              | -0.131207  |
| MaxReturn               | 3.16e+03   |
| MeanKL                  | 0.00966498 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.2e+03    |
| NumTrajs                | 8          |
| Perplexity              | 9.54763    |
| PolicyExecTime          | 0.611      |
| ProcessExecTime         | 0.0718     |
| StdReturn               | 586        |
| Time                    | 3.71e+03   |
| dLoss                   | 0.0364147  |
----------------------------------------
itr #278 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 278...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5006, #subsample_inputs: 5006
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.584      |
| AbsLearnSignalNew       | 0.584      |
| AbsLearningOld          | 0.584      |
| AverageDiscountedReturn | 235        |
| AveragePhiLoss          | 29.065     |
| AveragePolicyStd        | 0.515157   |
| AverageReturn           | 1.67e+03   |
| Entropy                 | 2.25246    |
| EnvExecTime             | 2.08       |
| ExplainedVariance       | 0.785      |
| Iteration               | 278        |
| ItrTime                 | 12.9       |
| LossAfter               | -1.45557   |
| LossBefore              | -1.43316   |
| MaxReturn               | 2.08e+03   |
| MeanKL                  | 0.00645581 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 176        |
| NumTrajs                | 10         |
| Perplexity              | 9.51111    |
| PolicyExecTime          | 0.521      |
| ProcessExecTime         | 0.0588     |
| StdReturn               | 568        |
| Time                    | 3.73e+03   |
| dLoss                   | 0.0224162  |
----------------------------------------
itr #279 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 279...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5038, #subsample_inputs: 5038
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.515      |
| AbsLearnSignalNew       | 0.515      |
| AbsLearningOld          | 0.515      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 30.6734    |
| AveragePolicyStd        | 0.515987   |
| AverageReturn           | 1.51e+03   |
| Entropy                 | 2.25741    |
| EnvExecTime             | 2.09       |
| ExplainedVariance       | 0.0396     |
| Iteration               | 279        |
| ItrTime                 | 13         |
| LossAfter               | 0.310679   |
| LossBefore              | 0.328491   |
| MaxReturn               | 3.1e+03    |
| MeanKL                  | 0.00653267 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 849        |
| NumTrajs                | 11         |
| Perplexity              | 9.55831    |
| PolicyExecTime          | 0.537      |
| ProcessExecTime         | 0.0594     |
| StdReturn               | 539        |
| Time                    | 3.74e+03   |
| dLoss                   | 0.0178116  |
----------------------------------------
itr #280 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 280...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5257, #subsample_inputs: 5257
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.664      |
| AbsLearnSignalNew       | 0.664      |
| AbsLearningOld          | 0.664      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 29.6432    |
| AveragePolicyStd        | 0.513418   |
| AverageReturn           | 2.13e+03   |
| Entropy                 | 2.24311    |
| EnvExecTime             | 2.03       |
| ExplainedVariance       | 0.796      |
| Iteration               | 280        |
| ItrTime                 | 13.3       |
| LossAfter               | -0.0987893 |
| LossBefore              | -0.0734716 |
| MaxReturn               | 2.97e+03   |
| MeanKL                  | 0.00993364 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.48e+03   |
| NumTrajs                | 8          |
| Perplexity              | 9.42263    |
| PolicyExecTime          | 0.511      |
| ProcessExecTime         | 0.0601     |
| StdReturn               | 436        |
| Time                    | 3.75e+03   |
| dLoss                   | 0.0253177  |
----------------------------------------
itr #281 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 281...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5224, #subsample_inputs: 5224
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.784      |
| AbsLearnSignalNew       | 0.784      |
| AbsLearningOld          | 0.784      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 33.0223    |
| AveragePolicyStd        | 0.513294   |
| AverageReturn           | 2.44e+03   |
| Entropy                 | 2.24221    |
| EnvExecTime             | 2.34       |
| ExplainedVariance       | 0.864      |
| Iteration               | 281        |
| ItrTime                 | 13.5       |
| LossAfter               | 0.428425   |
| LossBefore              | 0.45239    |
| MaxReturn               | 3.11e+03   |
| MeanKL                  | 0.00649762 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.74e+03   |
| NumTrajs                | 7          |
| Perplexity              | 9.4141     |
| PolicyExecTime          | 0.589      |
| ProcessExecTime         | 0.0663     |
| StdReturn               | 423        |
| Time                    | 3.77e+03   |
| dLoss                   | 0.0239654  |
----------------------------------------
itr #282 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 282...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5641, #subsample_inputs: 5641
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
-----------------------------------------
| AbsLearnSignal          | 0.706       |
| AbsLearnSignalNew       | 0.706       |
| AbsLearningOld          | 0.706       |
| AverageDiscountedReturn | 252         |
| AveragePhiLoss          | 32.0459     |
| AveragePolicyStd        | 0.513264    |
| AverageReturn           | 1.9e+03     |
| Entropy                 | 2.2417      |
| EnvExecTime             | 2.25        |
| ExplainedVariance       | 0.838       |
| Iteration               | 282         |
| ItrTime                 | 14          |
| LossAfter               | -0.00932795 |
| LossBefore              | 0.0156422   |
| MaxReturn               | 2.45e+03    |
| MeanKL                  | 0.00988611  |
| MeanKLBefore            | 0.0         |
| MinReturn               | 1.2e+03     |
| NumTrajs                | 10          |
| Perplexity              | 9.40929     |
| PolicyExecTime          | 0.57        |
| ProcessExecTime         | 0.0667      |
| StdReturn               | 405         |
| Time                    | 3.78e+03    |
| dLoss                   | 0.0249701   |
-----------------------------------------
itr #283 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 283...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5220, #subsample_inputs: 5220
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.61       |
| AbsLearnSignalNew       | 0.61       |
| AbsLearningOld          | 0.61       |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 34.1666    |
| AveragePolicyStd        | 0.512495   |
| AverageReturn           | 1.95e+03   |
| Entropy                 | 2.23712    |
| EnvExecTime             | 2.19       |
| ExplainedVariance       | 0.775      |
| Iteration               | 283        |
| ItrTime                 | 13.4       |
| LossAfter               | 1.5297     |
| LossBefore              | 1.55617    |
| MaxReturn               | 2.99e+03   |
| MeanKL                  | 0.00977115 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.3e+03    |
| NumTrajs                | 9          |
| Perplexity              | 9.3663     |
| PolicyExecTime          | 0.559      |
| ProcessExecTime         | 0.0629     |
| StdReturn               | 523        |
| Time                    | 3.79e+03   |
| dLoss                   | 0.0264713  |
----------------------------------------
itr #284 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 284...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5130, #subsample_inputs: 5130
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.594      |
| AbsLearnSignalNew       | 0.594      |
| AbsLearningOld          | 0.594      |
| AverageDiscountedReturn | 236        |
| AveragePhiLoss          | 39.4962    |
| AveragePolicyStd        | 0.51298    |
| AverageReturn           | 1.71e+03   |
| Entropy                 | 2.23974    |
| EnvExecTime             | 2.11       |
| ExplainedVariance       | 0.719      |
| Iteration               | 284        |
| ItrTime                 | 13.1       |
| LossAfter               | -0.29803   |
| LossBefore              | -0.273442  |
| MaxReturn               | 2.62e+03   |
| MeanKL                  | 0.00647307 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 152        |
| NumTrajs                | 10         |
| Perplexity              | 9.39091    |
| PolicyExecTime          | 0.521      |
| ProcessExecTime         | 0.0598     |
| StdReturn               | 672        |
| Time                    | 3.81e+03   |
| dLoss                   | 0.024588   |
----------------------------------------
itr #285 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 285...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5311, #subsample_inputs: 5311
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.598      |
| AbsLearnSignalNew       | 0.598      |
| AbsLearningOld          | 0.598      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 38.377     |
| AveragePolicyStd        | 0.511961   |
| AverageReturn           | 1.62e+03   |
| Entropy                 | 2.23275    |
| EnvExecTime             | 2.24       |
| ExplainedVariance       | 0.72       |
| Iteration               | 285        |
| ItrTime                 | 13.6       |
| LossAfter               | -1.19982   |
| LossBefore              | -1.16684   |
| MaxReturn               | 2.61e+03   |
| MeanKL                  | 0.00642246 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.01e+03   |
| NumTrajs                | 11         |
| Perplexity              | 9.32549    |
| PolicyExecTime          | 0.564      |
| ProcessExecTime         | 0.0633     |
| StdReturn               | 487        |
| Time                    | 3.82e+03   |
| dLoss                   | 0.03298    |
----------------------------------------
itr #286 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 286...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5263, #subsample_inputs: 5263
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.761      |
| AbsLearnSignalNew       | 0.761      |
| AbsLearningOld          | 0.761      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 35.2177    |
| AveragePolicyStd        | 0.510607   |
| AverageReturn           | 1.61e+03   |
| Entropy                 | 2.22539    |
| EnvExecTime             | 2.22       |
| ExplainedVariance       | 0.874      |
| Iteration               | 286        |
| ItrTime                 | 13.5       |
| LossAfter               | -0.294557  |
| LossBefore              | -0.26845   |
| MaxReturn               | 3.09e+03   |
| MeanKL                  | 0.00956084 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.1e+03    |
| NumTrajs                | 11         |
| Perplexity              | 9.25707    |
| PolicyExecTime          | 0.562      |
| ProcessExecTime         | 0.0627     |
| StdReturn               | 579        |
| Time                    | 3.83e+03   |
| dLoss                   | 0.0261075  |
----------------------------------------
itr #287 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 287...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5337, #subsample_inputs: 5337
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.749      |
| AbsLearnSignalNew       | 0.749      |
| AbsLearningOld          | 0.749      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 34.099     |
| AveragePolicyStd        | 0.514496   |
| AverageReturn           | 1.99e+03   |
| Entropy                 | 2.24757    |
| EnvExecTime             | 2.16       |
| ExplainedVariance       | 0.867      |
| Iteration               | 287        |
| ItrTime                 | 13.7       |
| LossAfter               | -0.0477138 |
| LossBefore              | -0.027543  |
| MaxReturn               | 2.86e+03   |
| MeanKL                  | 0.00654706 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.43e+03   |
| NumTrajs                | 9          |
| Perplexity              | 9.46469    |
| PolicyExecTime          | 0.559      |
| ProcessExecTime         | 0.062      |
| StdReturn               | 509        |
| Time                    | 3.85e+03   |
| dLoss                   | 0.0201708  |
----------------------------------------
itr #288 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 288...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5061, #subsample_inputs: 5061
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.74       |
| AbsLearnSignalNew       | 0.74       |
| AbsLearningOld          | 0.741      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 41.0035    |
| AveragePolicyStd        | 0.514378   |
| AverageReturn           | 2.38e+03   |
| Entropy                 | 2.24669    |
| EnvExecTime             | 2.21       |
| ExplainedVariance       | 0.845      |
| Iteration               | 288        |
| ItrTime                 | 13.1       |
| LossAfter               | 1.18122    |
| LossBefore              | 1.20743    |
| MaxReturn               | 3.23e+03   |
| MeanKL                  | 0.00997694 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.25e+03   |
| NumTrajs                | 7          |
| Perplexity              | 9.45634    |
| PolicyExecTime          | 0.558      |
| ProcessExecTime         | 0.063      |
| StdReturn               | 684        |
| Time                    | 3.86e+03   |
| dLoss                   | 0.0262133  |
----------------------------------------
itr #289 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 289...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5198, #subsample_inputs: 5198
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.661      |
| AbsLearnSignalNew       | 0.661      |
| AbsLearningOld          | 0.661      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 36.3901    |
| AveragePolicyStd        | 0.515133   |
| AverageReturn           | 1.71e+03   |
| Entropy                 | 2.25138    |
| EnvExecTime             | 1.96       |
| ExplainedVariance       | 0.749      |
| Iteration               | 289        |
| ItrTime                 | 13         |
| LossAfter               | -0.748947  |
| LossBefore              | -0.722243  |
| MaxReturn               | 2.73e+03   |
| MeanKL                  | 0.00644243 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.23e+03   |
| NumTrajs                | 10         |
| Perplexity              | 9.50088    |
| PolicyExecTime          | 0.497      |
| ProcessExecTime         | 0.0575     |
| StdReturn               | 509        |
| Time                    | 3.87e+03   |
| dLoss                   | 0.026704   |
----------------------------------------
itr #290 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 290...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5403, #subsample_inputs: 5403
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.749      |
| AbsLearnSignalNew       | 0.749      |
| AbsLearningOld          | 0.749      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 33.1607    |
| AveragePolicyStd        | 0.513436   |
| AverageReturn           | 2.01e+03   |
| Entropy                 | 2.24118    |
| EnvExecTime             | 2.46       |
| ExplainedVariance       | 0.799      |
| Iteration               | 290        |
| ItrTime                 | 14.3       |
| LossAfter               | 0.226527   |
| LossBefore              | 0.257058   |
| MaxReturn               | 3.17e+03   |
| MeanKL                  | 0.00999045 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.49e+03   |
| NumTrajs                | 9          |
| Perplexity              | 9.40444    |
| PolicyExecTime          | 0.619      |
| ProcessExecTime         | 0.0706     |
| StdReturn               | 508        |
| Time                    | 3.89e+03   |
| dLoss                   | 0.0305301  |
----------------------------------------
itr #291 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 291...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5469, #subsample_inputs: 5469
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.724      |
| AbsLearnSignalNew       | 0.724      |
| AbsLearningOld          | 0.724      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 31.3731    |
| AveragePolicyStd        | 0.514239   |
| AverageReturn           | 1.68e+03   |
| Entropy                 | 2.24645    |
| EnvExecTime             | 2.17       |
| ExplainedVariance       | 0.881      |
| Iteration               | 291        |
| ItrTime                 | 13.7       |
| LossAfter               | 0.357699   |
| LossBefore              | 0.382635   |
| MaxReturn               | 2.34e+03   |
| MeanKL                  | 0.00991572 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 902        |
| NumTrajs                | 11         |
| Perplexity              | 9.45415    |
| PolicyExecTime          | 0.533      |
| ProcessExecTime         | 0.0667     |
| StdReturn               | 386        |
| Time                    | 3.9e+03    |
| dLoss                   | 0.0249365  |
----------------------------------------
itr #292 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 292...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5348, #subsample_inputs: 5348
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.69      |
| AbsLearnSignalNew       | 0.69      |
| AbsLearningOld          | 0.69      |
| AverageDiscountedReturn | 249       |
| AveragePhiLoss          | 33.3117   |
| AveragePolicyStd        | 0.515474  |
| AverageReturn           | 1.78e+03  |
| Entropy                 | 2.2536    |
| EnvExecTime             | 1.91      |
| ExplainedVariance       | 0.746     |
| Iteration               | 292       |
| ItrTime                 | 13.4      |
| LossAfter               | -1.03282  |
| LossBefore              | -1.00606  |
| MaxReturn               | 2.91e+03  |
| MeanKL                  | 0.0064445 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.19e+03  |
| NumTrajs                | 10        |
| Perplexity              | 9.52194   |
| PolicyExecTime          | 0.489     |
| ProcessExecTime         | 0.0571    |
| StdReturn               | 625       |
| Time                    | 3.92e+03  |
| dLoss                   | 0.0267612 |
---------------------------------------
itr #293 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 293...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5493, #subsample_inputs: 5493
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.646      |
| AbsLearnSignalNew       | 0.646      |
| AbsLearningOld          | 0.646      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 33.4127    |
| AveragePolicyStd        | 0.515196   |
| AverageReturn           | 2e+03      |
| Entropy                 | 2.25239    |
| EnvExecTime             | 2.49       |
| ExplainedVariance       | 0.654      |
| Iteration               | 293        |
| ItrTime                 | 14.1       |
| LossAfter               | -0.573656  |
| LossBefore              | -0.545929  |
| MaxReturn               | 2.92e+03   |
| MeanKL                  | 0.00998943 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.57e+03   |
| NumTrajs                | 9          |
| Perplexity              | 9.51043    |
| PolicyExecTime          | 0.614      |
| ProcessExecTime         | 0.0695     |
| StdReturn               | 391        |
| Time                    | 3.93e+03   |
| dLoss                   | 0.0277274  |
----------------------------------------
itr #294 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 294...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5733, #subsample_inputs: 5733
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.739      |
| AbsLearnSignalNew       | 0.739      |
| AbsLearningOld          | 0.739      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 40.6099    |
| AveragePolicyStd        | 0.513955   |
| AverageReturn           | 1.89e+03   |
| Entropy                 | 2.24449    |
| EnvExecTime             | 2.17       |
| ExplainedVariance       | 0.845      |
| Iteration               | 294        |
| ItrTime                 | 14         |
| LossAfter               | -0.888494  |
| LossBefore              | -0.862791  |
| MaxReturn               | 2.88e+03   |
| MeanKL                  | 0.00647911 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.18e+03   |
| NumTrajs                | 10         |
| Perplexity              | 9.43563    |
| PolicyExecTime          | 0.546      |
| ProcessExecTime         | 0.065      |
| StdReturn               | 611        |
| Time                    | 3.94e+03   |
| dLoss                   | 0.0257037  |
----------------------------------------
itr #295 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 295...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5388, #subsample_inputs: 5388
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.73       |
| AbsLearnSignalNew       | 0.73       |
| AbsLearningOld          | 0.73       |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 33.3746    |
| AveragePolicyStd        | 0.513482   |
| AverageReturn           | 2.02e+03   |
| Entropy                 | 2.2413     |
| EnvExecTime             | 2.15       |
| ExplainedVariance       | 0.807      |
| Iteration               | 295        |
| ItrTime                 | 13.7       |
| LossAfter               | 0.921461   |
| LossBefore              | 0.94817    |
| MaxReturn               | 3.38e+03   |
| MeanKL                  | 0.00989619 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.21e+03   |
| NumTrajs                | 9          |
| Perplexity              | 9.40555    |
| PolicyExecTime          | 0.533      |
| ProcessExecTime         | 0.0632     |
| StdReturn               | 725        |
| Time                    | 3.96e+03   |
| dLoss                   | 0.0267084  |
----------------------------------------
itr #296 | 
Mem: 724.902344
Obtaining samples...
Obtaining samples for iteration 296...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5125, #subsample_inputs: 5125
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.711      |
| AbsLearnSignalNew       | 0.711      |
| AbsLearningOld          | 0.711      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 32.3861    |
| AveragePolicyStd        | 0.513487   |
| AverageReturn           | 2.38e+03   |
| Entropy                 | 2.2403     |
| EnvExecTime             | 2.29       |
| ExplainedVariance       | 0.816      |
| Iteration               | 296        |
| ItrTime                 | 13.3       |
| LossAfter               | -0.728452  |
| LossBefore              | -0.707279  |
| MaxReturn               | 3.04e+03   |
| MeanKL                  | 0.00642388 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.37e+03   |
| NumTrajs                | 7          |
| Perplexity              | 9.39611    |
| PolicyExecTime          | 0.571      |
| ProcessExecTime         | 0.0687     |
| StdReturn               | 653        |
| Time                    | 3.97e+03   |
| dLoss                   | 0.0211726  |
----------------------------------------
itr #297 | 
Mem: 725.070312
Obtaining samples...
Obtaining samples for iteration 297...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5036, #subsample_inputs: 5036
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.694      |
| AbsLearnSignalNew       | 0.694      |
| AbsLearningOld          | 0.694      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 32.4337    |
| AveragePolicyStd        | 0.513272   |
| AverageReturn           | 2.1e+03    |
| Entropy                 | 2.23914    |
| EnvExecTime             | 2.34       |
| ExplainedVariance       | 0.863      |
| Iteration               | 297        |
| ItrTime                 | 13.4       |
| LossAfter               | 0.821988   |
| LossBefore              | 0.842672   |
| MaxReturn               | 2.67e+03   |
| MeanKL                  | 0.00646468 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.43e+03   |
| NumTrajs                | 8          |
| Perplexity              | 9.38522    |
| PolicyExecTime          | 0.593      |
| ProcessExecTime         | 0.0667     |
| StdReturn               | 375        |
| Time                    | 3.99e+03   |
| dLoss                   | 0.0206839  |
----------------------------------------
itr #298 | 
Mem: 725.070312
Obtaining samples...
Obtaining samples for iteration 298...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5000, #subsample_inputs: 5000
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.615     |
| AbsLearnSignalNew       | 0.615     |
| AbsLearningOld          | 0.615     |
| AverageDiscountedReturn | 244       |
| AveragePhiLoss          | 32.5032   |
| AveragePolicyStd        | 0.512818  |
| AverageReturn           | 3.11e+03  |
| Entropy                 | 2.23599   |
| EnvExecTime             | 1.85      |
| ExplainedVariance       | 0.633     |
| Iteration               | 298       |
| ItrTime                 | 12.5      |
| LossAfter               | -0.264064 |
| LossBefore              | -0.239687 |
| MaxReturn               | 3.39e+03  |
| MeanKL                  | 0.0099099 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 2.78e+03  |
| NumTrajs                | 5         |
| Perplexity              | 9.35574   |
| PolicyExecTime          | 0.45      |
| ProcessExecTime         | 0.0554    |
| StdReturn               | 219       |
| Time                    | 4e+03     |
| dLoss                   | 0.0243767 |
---------------------------------------
itr #299 | 
Mem: 725.628906
Obtaining samples...
Obtaining samples for iteration 299...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5507, #subsample_inputs: 5507
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.472      |
| AbsLearnSignalNew       | 0.472      |
| AbsLearningOld          | 0.472      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 31.96      |
| AveragePolicyStd        | 0.513248   |
| AverageReturn           | 2.2e+03    |
| Entropy                 | 2.23835    |
| EnvExecTime             | 2.4        |
| ExplainedVariance       | 0.389      |
| Iteration               | 299        |
| ItrTime                 | 14         |
| LossAfter               | -1.33336   |
| LossBefore              | -1.29704   |
| MaxReturn               | 3.19e+03   |
| MeanKL                  | 0.00989701 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.35e+03   |
| NumTrajs                | 8          |
| Perplexity              | 9.37788    |
| PolicyExecTime          | 0.604      |
| ProcessExecTime         | 0.0682     |
| StdReturn               | 677        |
| Time                    | 4.01e+03   |
| dLoss                   | 0.0363131  |
----------------------------------------
itr #300 | 
Mem: 725.628906
Obtaining samples...
Obtaining samples for iteration 300...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5393, #subsample_inputs: 5393
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.706      |
| AbsLearnSignalNew       | 0.706      |
| AbsLearningOld          | 0.706      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 37.1562    |
| AveragePolicyStd        | 0.512816   |
| AverageReturn           | 2.47e+03   |
| Entropy                 | 2.236      |
| EnvExecTime             | 2.63       |
| ExplainedVariance       | 0.715      |
| Iteration               | 300        |
| ItrTime                 | 14.3       |
| LossAfter               | 1.84422    |
| LossBefore              | 1.8662     |
| MaxReturn               | 3.1e+03    |
| MeanKL                  | 0.00642553 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.78e+03   |
| NumTrajs                | 7          |
| Perplexity              | 9.35587    |
| PolicyExecTime          | 0.654      |
| ProcessExecTime         | 0.0734     |
| StdReturn               | 442        |
| Time                    | 4.03e+03   |
| dLoss                   | 0.0219824  |
----------------------------------------
itr #301 | 
Mem: 725.628906
Obtaining samples...
Obtaining samples for iteration 301...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5579, #subsample_inputs: 5579
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.703      |
| AbsLearnSignalNew       | 0.703      |
| AbsLearningOld          | 0.703      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 36.4672    |
| AveragePolicyStd        | 0.512933   |
| AverageReturn           | 2.26e+03   |
| Entropy                 | 2.23558    |
| EnvExecTime             | 2.18       |
| ExplainedVariance       | 0.84       |
| Iteration               | 301        |
| ItrTime                 | 14         |
| LossAfter               | 0.376871   |
| LossBefore              | 0.399657   |
| MaxReturn               | 3.05e+03   |
| MeanKL                  | 0.00641945 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.4e+03    |
| NumTrajs                | 8          |
| Perplexity              | 9.35195    |
| PolicyExecTime          | 0.56       |
| ProcessExecTime         | 0.0638     |
| StdReturn               | 633        |
| Time                    | 4.04e+03   |
| dLoss                   | 0.0227861  |
----------------------------------------
itr #302 | 
Mem: 725.628906
Obtaining samples...
Obtaining samples for iteration 302...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5432, #subsample_inputs: 5432
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.687      |
| AbsLearnSignalNew       | 0.687      |
| AbsLearningOld          | 0.686      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 35.149     |
| AveragePolicyStd        | 0.512793   |
| AverageReturn           | 2e+03      |
| Entropy                 | 2.23312    |
| EnvExecTime             | 1.95       |
| ExplainedVariance       | 0.858      |
| Iteration               | 302        |
| ItrTime                 | 13.5       |
| LossAfter               | 0.542629   |
| LossBefore              | 0.573687   |
| MaxReturn               | 2.96e+03   |
| MeanKL                  | 0.00974861 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.24e+03   |
| NumTrajs                | 9          |
| Perplexity              | 9.32888    |
| PolicyExecTime          | 0.495      |
| ProcessExecTime         | 0.0581     |
| StdReturn               | 527        |
| Time                    | 4.05e+03   |
| dLoss                   | 0.0310577  |
----------------------------------------
itr #303 | 
Mem: 725.628906
Obtaining samples...
Obtaining samples for iteration 303...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5038, #subsample_inputs: 5038
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.707      |
| AbsLearnSignalNew       | 0.707      |
| AbsLearningOld          | 0.707      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 31.7641    |
| AveragePolicyStd        | 0.512608   |
| AverageReturn           | 1.88e+03   |
| Entropy                 | 2.23408    |
| EnvExecTime             | 2.25       |
| ExplainedVariance       | 0.888      |
| Iteration               | 303        |
| ItrTime                 | 13.1       |
| LossAfter               | 0.00876194 |
| LossBefore              | 0.0368738  |
| MaxReturn               | 2.68e+03   |
| MeanKL                  | 0.00977096 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.27e+03   |
| NumTrajs                | 9          |
| Perplexity              | 9.33788    |
| PolicyExecTime          | 0.558      |
| ProcessExecTime         | 0.0651     |
| StdReturn               | 424        |
| Time                    | 4.07e+03   |
| dLoss                   | 0.0281118  |
----------------------------------------
itr #304 | 
Mem: 725.628906
Obtaining samples...
Obtaining samples for iteration 304...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5626, #subsample_inputs: 5626
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.567      |
| AbsLearnSignalNew       | 0.567      |
| AbsLearningOld          | 0.568      |
| AverageDiscountedReturn | 236        |
| AveragePhiLoss          | 35.2389    |
| AveragePolicyStd        | 0.513016   |
| AverageReturn           | 1.99e+03   |
| Entropy                 | 2.23819    |
| EnvExecTime             | 2.29       |
| ExplainedVariance       | 0.647      |
| Iteration               | 304        |
| ItrTime                 | 14         |
| LossAfter               | 1.21937    |
| LossBefore              | 1.25104    |
| MaxReturn               | 3.17e+03   |
| MeanKL                  | 0.00993744 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 178        |
| NumTrajs                | 9          |
| Perplexity              | 9.37637    |
| PolicyExecTime          | 0.569      |
| ProcessExecTime         | 0.067      |
| StdReturn               | 1.03e+03   |
| Time                    | 4.08e+03   |
| dLoss                   | 0.0316694  |
----------------------------------------
itr #305 | 
Mem: 725.628906
Obtaining samples...
Obtaining samples for iteration 305...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5174, #subsample_inputs: 5174
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.658     |
| AbsLearnSignalNew       | 0.658     |
| AbsLearningOld          | 0.658     |
| AverageDiscountedReturn | 250       |
| AveragePhiLoss          | 31.3851   |
| AveragePolicyStd        | 0.513261  |
| AverageReturn           | 2.41e+03  |
| Entropy                 | 2.23978   |
| EnvExecTime             | 2.04      |
| ExplainedVariance       | 0.787     |
| Iteration               | 305       |
| ItrTime                 | 13.1      |
| LossAfter               | 0.321804  |
| LossBefore              | 0.353386  |
| MaxReturn               | 3.19e+03  |
| MeanKL                  | 0.0064081 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.71e+03  |
| NumTrajs                | 7         |
| Perplexity              | 9.39124   |
| PolicyExecTime          | 0.525     |
| ProcessExecTime         | 0.0596    |
| StdReturn               | 524       |
| Time                    | 4.09e+03  |
| dLoss                   | 0.0315822 |
---------------------------------------
itr #306 | 
Mem: 725.628906
Obtaining samples...
Obtaining samples for iteration 306...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5787, #subsample_inputs: 5787
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.698     |
| AbsLearnSignalNew       | 0.698     |
| AbsLearningOld          | 0.698     |
| AverageDiscountedReturn | 251       |
| AveragePhiLoss          | 35.2142   |
| AveragePolicyStd        | 0.512364  |
| AverageReturn           | 2.15e+03  |
| Entropy                 | 2.23481   |
| EnvExecTime             | 2.53      |
| ExplainedVariance       | 0.879     |
| Iteration               | 306       |
| ItrTime                 | 14.6      |
| LossAfter               | -0.995157 |
| LossBefore              | -0.972695 |
| MaxReturn               | 3.29e+03  |
| MeanKL                  | 0.0064131 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.2e+03   |
| NumTrajs                | 9         |
| Perplexity              | 9.34468   |
| PolicyExecTime          | 0.633     |
| ProcessExecTime         | 0.074     |
| StdReturn               | 745       |
| Time                    | 4.11e+03  |
| dLoss                   | 0.0224616 |
---------------------------------------
itr #307 | 
Mem: 725.628906
Obtaining samples...
Obtaining samples for iteration 307...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5351, #subsample_inputs: 5351
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.755      |
| AbsLearnSignalNew       | 0.755      |
| AbsLearningOld          | 0.755      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 36.1543    |
| AveragePolicyStd        | 0.512407   |
| AverageReturn           | 2.15e+03   |
| Entropy                 | 2.23444    |
| EnvExecTime             | 2.26       |
| ExplainedVariance       | 0.877      |
| Iteration               | 307        |
| ItrTime                 | 13.8       |
| LossAfter               | 0.597178   |
| LossBefore              | 0.621421   |
| MaxReturn               | 3.19e+03   |
| MeanKL                  | 0.00979465 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.23e+03   |
| NumTrajs                | 8          |
| Perplexity              | 9.34128    |
| PolicyExecTime          | 0.573      |
| ProcessExecTime         | 0.0654     |
| StdReturn               | 753        |
| Time                    | 4.12e+03   |
| dLoss                   | 0.0242426  |
----------------------------------------
itr #308 | 
Mem: 725.628906
Obtaining samples...
Obtaining samples for iteration 308...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5214, #subsample_inputs: 5214
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.745     |
| AbsLearnSignalNew       | 0.745     |
| AbsLearningOld          | 0.745     |
| AverageDiscountedReturn | 252       |
| AveragePhiLoss          | 35.9065   |
| AveragePolicyStd        | 0.514573  |
| AverageReturn           | 1.6e+03   |
| Entropy                 | 2.24442   |
| EnvExecTime             | 2.32      |
| ExplainedVariance       | 0.911     |
| Iteration               | 308       |
| ItrTime                 | 13.5      |
| LossAfter               | -0.320859 |
| LossBefore              | -0.287471 |
| MaxReturn               | 2.39e+03  |
| MeanKL                  | 0.0099257 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 988       |
| NumTrajs                | 11        |
| Perplexity              | 9.43493   |
| PolicyExecTime          | 0.578     |
| ProcessExecTime         | 0.0647    |
| StdReturn               | 491       |
| Time                    | 4.14e+03  |
| dLoss                   | 0.0333884 |
---------------------------------------
itr #309 | 
Mem: 725.628906
Obtaining samples...
Obtaining samples for iteration 309...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5586, #subsample_inputs: 5586
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.736      |
| AbsLearnSignalNew       | 0.736      |
| AbsLearningOld          | 0.736      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 35.104     |
| AveragePolicyStd        | 0.515212   |
| AverageReturn           | 2.27e+03   |
| Entropy                 | 2.24874    |
| EnvExecTime             | 2.23       |
| ExplainedVariance       | 0.806      |
| Iteration               | 309        |
| ItrTime                 | 13.9       |
| LossAfter               | -1.49804   |
| LossBefore              | -1.47482   |
| MaxReturn               | 3.28e+03   |
| MeanKL                  | 0.00654312 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.53e+03   |
| NumTrajs                | 8          |
| Perplexity              | 9.47576    |
| PolicyExecTime          | 0.573      |
| ProcessExecTime         | 0.0645     |
| StdReturn               | 529        |
| Time                    | 4.15e+03   |
| dLoss                   | 0.0232131  |
----------------------------------------
itr #310 | 
Mem: 725.628906
Obtaining samples...
Obtaining samples for iteration 310...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5301, #subsample_inputs: 5301
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.745      |
| AbsLearnSignalNew       | 0.745      |
| AbsLearningOld          | 0.745      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 33.6736    |
| AveragePolicyStd        | 0.514575   |
| AverageReturn           | 2.46e+03   |
| Entropy                 | 2.24607    |
| EnvExecTime             | 1.92       |
| ExplainedVariance       | 0.887      |
| Iteration               | 310        |
| ItrTime                 | 13.1       |
| LossAfter               | 1.30709    |
| LossBefore              | 1.33297    |
| MaxReturn               | 3.21e+03   |
| MeanKL                  | 0.00991476 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.57e+03   |
| NumTrajs                | 7          |
| Perplexity              | 9.45049    |
| PolicyExecTime          | 0.493      |
| ProcessExecTime         | 0.0569     |
| StdReturn               | 509        |
| Time                    | 4.16e+03   |
| dLoss                   | 0.0258824  |
----------------------------------------
itr #311 | 
Mem: 725.628906
Obtaining samples...
Obtaining samples for iteration 311...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5103, #subsample_inputs: 5103
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.628      |
| AbsLearnSignalNew       | 0.628      |
| AbsLearningOld          | 0.628      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 36.1013    |
| AveragePolicyStd        | 0.511684   |
| AverageReturn           | 1.73e+03   |
| Entropy                 | 2.2295     |
| EnvExecTime             | 2.58       |
| ExplainedVariance       | 0.794      |
| Iteration               | 311        |
| ItrTime                 | 13.7       |
| LossAfter               | 0.234712   |
| LossBefore              | 0.256498   |
| MaxReturn               | 2.33e+03   |
| MeanKL                  | 0.00640594 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 940        |
| NumTrajs                | 10         |
| Perplexity              | 9.29522    |
| PolicyExecTime          | 0.638      |
| ProcessExecTime         | 0.0721     |
| StdReturn               | 466        |
| Time                    | 4.18e+03   |
| dLoss                   | 0.0217855  |
----------------------------------------
itr #312 | 
Mem: 725.628906
Obtaining samples...
Obtaining samples for iteration 312...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5635, #subsample_inputs: 5635
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.664     |
| AbsLearnSignalNew       | 0.664     |
| AbsLearningOld          | 0.664     |
| AverageDiscountedReturn | 250       |
| AveragePhiLoss          | 35.8048   |
| AveragePolicyStd        | 0.511688  |
| AverageReturn           | 2.09e+03  |
| Entropy                 | 2.22999   |
| EnvExecTime             | 2.36      |
| ExplainedVariance       | 0.658     |
| Iteration               | 312       |
| ItrTime                 | 14.1      |
| LossAfter               | -1.08465  |
| LossBefore              | -1.06248  |
| MaxReturn               | 3.29e+03  |
| MeanKL                  | 0.0065661 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.12e+03  |
| NumTrajs                | 9         |
| Perplexity              | 9.29981   |
| PolicyExecTime          | 0.586     |
| ProcessExecTime         | 0.0733    |
| StdReturn               | 751       |
| Time                    | 4.19e+03  |
| dLoss                   | 0.0221633 |
---------------------------------------
itr #313 | 
Mem: 725.628906
Obtaining samples...
Obtaining samples for iteration 313...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5490, #subsample_inputs: 5490
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.749      |
| AbsLearnSignalNew       | 0.749      |
| AbsLearningOld          | 0.749      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 35.1309    |
| AveragePolicyStd        | 0.510836   |
| AverageReturn           | 2.3e+03    |
| Entropy                 | 2.22611    |
| EnvExecTime             | 2.36       |
| ExplainedVariance       | 0.847      |
| Iteration               | 313        |
| ItrTime                 | 13.9       |
| LossAfter               | -1.04187   |
| LossBefore              | -1.01623   |
| MaxReturn               | 3.08e+03   |
| MeanKL                  | 0.00641229 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.48e+03   |
| NumTrajs                | 8          |
| Perplexity              | 9.2638     |
| PolicyExecTime          | 0.604      |
| ProcessExecTime         | 0.0666     |
| StdReturn               | 502        |
| Time                    | 4.21e+03   |
| dLoss                   | 0.0256438  |
----------------------------------------
itr #314 | 
Mem: 725.628906
Obtaining samples...
Obtaining samples for iteration 314...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5368, #subsample_inputs: 5368
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.571      |
| AbsLearnSignalNew       | 0.571      |
| AbsLearningOld          | 0.571      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 27.6896    |
| AveragePolicyStd        | 0.508888   |
| AverageReturn           | 2.42e+03   |
| Entropy                 | 2.21495    |
| EnvExecTime             | 2.3        |
| ExplainedVariance       | 0.502      |
| Iteration               | 314        |
| ItrTime                 | 13.8       |
| LossAfter               | -0.0631977 |
| LossBefore              | -0.0412599 |
| MaxReturn               | 3.17e+03   |
| MeanKL                  | 0.0099551  |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.17e+03   |
| NumTrajs                | 7          |
| Perplexity              | 9.16095    |
| PolicyExecTime          | 0.584      |
| ProcessExecTime         | 0.0649     |
| StdReturn               | 642        |
| Time                    | 4.22e+03   |
| dLoss                   | 0.0219378  |
----------------------------------------
itr #315 | 
Mem: 725.628906
Obtaining samples...
Obtaining samples for iteration 315...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5344, #subsample_inputs: 5344
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.632      |
| AbsLearnSignalNew       | 0.632      |
| AbsLearningOld          | 0.632      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 33.8271    |
| AveragePolicyStd        | 0.508225   |
| AverageReturn           | 2.01e+03   |
| Entropy                 | 2.21227    |
| EnvExecTime             | 2.04       |
| ExplainedVariance       | 0.736      |
| Iteration               | 315        |
| ItrTime                 | 13.4       |
| LossAfter               | 0.688131   |
| LossBefore              | 0.711144   |
| MaxReturn               | 3.28e+03   |
| MeanKL                  | 0.00649784 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.09e+03   |
| NumTrajs                | 9          |
| Perplexity              | 9.13642    |
| PolicyExecTime          | 0.513      |
| ProcessExecTime         | 0.0597     |
| StdReturn               | 718        |
| Time                    | 4.23e+03   |
| dLoss                   | 0.0230135  |
----------------------------------------
itr #316 | 
Mem: 725.628906
Obtaining samples...
Obtaining samples for iteration 316...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5455, #subsample_inputs: 5455
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.559      |
| AbsLearnSignalNew       | 0.559      |
| AbsLearningOld          | 0.559      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 36.4368    |
| AveragePolicyStd        | 0.508346   |
| AverageReturn           | 2.76e+03   |
| Entropy                 | 2.21355    |
| EnvExecTime             | 2.35       |
| ExplainedVariance       | 0.268      |
| Iteration               | 316        |
| ItrTime                 | 14         |
| LossAfter               | -0.316234  |
| LossBefore              | -0.297683  |
| MaxReturn               | 3.27e+03   |
| MeanKL                  | 0.00641815 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.49e+03   |
| NumTrajs                | 6          |
| Perplexity              | 9.14811    |
| PolicyExecTime          | 0.594      |
| ProcessExecTime         | 0.0667     |
| StdReturn               | 600        |
| Time                    | 4.25e+03   |
| dLoss                   | 0.0185511  |
----------------------------------------
itr #317 | 
Mem: 725.628906
Obtaining samples...
Obtaining samples for iteration 317...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5773, #subsample_inputs: 5773
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.452     |
| AbsLearnSignalNew       | 0.452     |
| AbsLearningOld          | 0.452     |
| AverageDiscountedReturn | 245       |
| AveragePhiLoss          | 31.3272   |
| AveragePolicyStd        | 0.508566  |
| AverageReturn           | 2.71e+03  |
| Entropy                 | 2.21511   |
| EnvExecTime             | 2.46      |
| ExplainedVariance       | 0.527     |
| Iteration               | 317       |
| ItrTime                 | 14.5      |
| LossAfter               | 0.0954495 |
| LossBefore              | 0.132066  |
| MaxReturn               | 3.4e+03   |
| MeanKL                  | 0.0098496 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.47e+03  |
| NumTrajs                | 7         |
| Perplexity              | 9.16245   |
| PolicyExecTime          | 0.622     |
| ProcessExecTime         | 0.0702    |
| StdReturn               | 648       |
| Time                    | 4.26e+03  |
| dLoss                   | 0.036617  |
---------------------------------------
itr #318 | 
Mem: 725.628906
Obtaining samples...
Obtaining samples for iteration 318...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5168, #subsample_inputs: 5168
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.713      |
| AbsLearnSignalNew       | 0.713      |
| AbsLearningOld          | 0.713      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 35.4181    |
| AveragePolicyStd        | 0.50734    |
| AverageReturn           | 2.06e+03   |
| Entropy                 | 2.20783    |
| EnvExecTime             | 2.58       |
| ExplainedVariance       | 0.775      |
| Iteration               | 318        |
| ItrTime                 | 13.8       |
| LossAfter               | -0.855496  |
| LossBefore              | -0.833068  |
| MaxReturn               | 2.8e+03    |
| MeanKL                  | 0.00644684 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.19e+03   |
| NumTrajs                | 8          |
| Perplexity              | 9.09596    |
| PolicyExecTime          | 0.634      |
| ProcessExecTime         | 0.0733     |
| StdReturn               | 445        |
| Time                    | 4.28e+03   |
| dLoss                   | 0.0224271  |
----------------------------------------
itr #319 | 
Mem: 725.628906
Obtaining samples...
Obtaining samples for iteration 319...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5159, #subsample_inputs: 5159
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.733      |
| AbsLearnSignalNew       | 0.733      |
| AbsLearningOld          | 0.733      |
| AverageDiscountedReturn | 254        |
| AveragePhiLoss          | 33.627     |
| AveragePolicyStd        | 0.508833   |
| AverageReturn           | 2.17e+03   |
| Entropy                 | 2.21686    |
| EnvExecTime             | 1.87       |
| ExplainedVariance       | 0.84       |
| Iteration               | 319        |
| ItrTime                 | 12.8       |
| LossAfter               | -0.57858   |
| LossBefore              | -0.546219  |
| MaxReturn               | 3.15e+03   |
| MeanKL                  | 0.00987518 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.68e+03   |
| NumTrajs                | 8          |
| Perplexity              | 9.17845    |
| PolicyExecTime          | 0.476      |
| ProcessExecTime         | 0.0557     |
| StdReturn               | 487        |
| Time                    | 4.29e+03   |
| dLoss                   | 0.0323611  |
----------------------------------------
itr #320 | 
Mem: 725.628906
Obtaining samples...
Obtaining samples for iteration 320...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5306, #subsample_inputs: 5306
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.633     |
| AbsLearnSignalNew       | 0.633     |
| AbsLearningOld          | 0.632     |
| AverageDiscountedReturn | 249       |
| AveragePhiLoss          | 37.1402   |
| AveragePolicyStd        | 0.509546  |
| AverageReturn           | 2.46e+03  |
| Entropy                 | 2.22088   |
| EnvExecTime             | 2.31      |
| ExplainedVariance       | 0.68      |
| Iteration               | 320       |
| ItrTime                 | 13.6      |
| LossAfter               | 0.391306  |
| LossBefore              | 0.422268  |
| MaxReturn               | 3.41e+03  |
| MeanKL                  | 0.0099301 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.16e+03  |
| NumTrajs                | 7         |
| Perplexity              | 9.21539   |
| PolicyExecTime          | 0.576     |
| ProcessExecTime         | 0.0664    |
| StdReturn               | 707       |
| Time                    | 4.3e+03   |
| dLoss                   | 0.0309623 |
---------------------------------------
itr #321 | 
Mem: 725.804688
Obtaining samples...
Obtaining samples for iteration 321...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5344, #subsample_inputs: 5344
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.726      |
| AbsLearnSignalNew       | 0.726      |
| AbsLearningOld          | 0.726      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 36.1517    |
| AveragePolicyStd        | 0.509429   |
| AverageReturn           | 2.35e+03   |
| Entropy                 | 2.21949    |
| EnvExecTime             | 2.33       |
| ExplainedVariance       | 0.846      |
| Iteration               | 321        |
| ItrTime                 | 13.9       |
| LossAfter               | -0.208491  |
| LossBefore              | -0.188634  |
| MaxReturn               | 3.06e+03   |
| MeanKL                  | 0.00642186 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.34e+03   |
| NumTrajs                | 7          |
| Perplexity              | 9.20262    |
| PolicyExecTime          | 0.58       |
| ProcessExecTime         | 0.0682     |
| StdReturn               | 538        |
| Time                    | 4.32e+03   |
| dLoss                   | 0.0198571  |
----------------------------------------
itr #322 | 
Mem: 725.804688
Obtaining samples...
Obtaining samples for iteration 322...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5282, #subsample_inputs: 5282
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.701      |
| AbsLearnSignalNew       | 0.701      |
| AbsLearningOld          | 0.7        |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 32.3966    |
| AveragePolicyStd        | 0.509948   |
| AverageReturn           | 2.92e+03   |
| Entropy                 | 2.2234     |
| EnvExecTime             | 2.25       |
| ExplainedVariance       | 0.798      |
| Iteration               | 322        |
| ItrTime                 | 13.6       |
| LossAfter               | -0.546969  |
| LossBefore              | -0.523332  |
| MaxReturn               | 3.31e+03   |
| MeanKL                  | 0.00642309 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.5e+03    |
| NumTrajs                | 6          |
| Perplexity              | 9.23868    |
| PolicyExecTime          | 0.576      |
| ProcessExecTime         | 0.0634     |
| StdReturn               | 637        |
| Time                    | 4.33e+03   |
| dLoss                   | 0.0236371  |
----------------------------------------
itr #323 | 
Mem: 726.054688
Obtaining samples...
Obtaining samples for iteration 323...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5476, #subsample_inputs: 5476
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.697      |
| AbsLearnSignalNew       | 0.697      |
| AbsLearningOld          | 0.697      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 33.041     |
| AveragePolicyStd        | 0.510274   |
| AverageReturn           | 2.21e+03   |
| Entropy                 | 2.22559    |
| EnvExecTime             | 2.47       |
| ExplainedVariance       | 0.752      |
| Iteration               | 323        |
| ItrTime                 | 14.1       |
| LossAfter               | 0.0147499  |
| LossBefore              | 0.0367624  |
| MaxReturn               | 3.21e+03   |
| MeanKL                  | 0.00642642 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.2e+03    |
| NumTrajs                | 8          |
| Perplexity              | 9.25892    |
| PolicyExecTime          | 0.623      |
| ProcessExecTime         | 0.0708     |
| StdReturn               | 679        |
| Time                    | 4.34e+03   |
| dLoss                   | 0.0220125  |
----------------------------------------
itr #324 | 
Mem: 726.054688
Obtaining samples...
Obtaining samples for iteration 324...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5853, #subsample_inputs: 5853
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.717      |
| AbsLearnSignalNew       | 0.717      |
| AbsLearningOld          | 0.717      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 34.3116    |
| AveragePolicyStd        | 0.509162   |
| AverageReturn           | 2.27e+03   |
| Entropy                 | 2.21947    |
| EnvExecTime             | 2.23       |
| ExplainedVariance       | 0.853      |
| Iteration               | 324        |
| ItrTime                 | 14.4       |
| LossAfter               | -0.153486  |
| LossBefore              | -0.132036  |
| MaxReturn               | 3.17e+03   |
| MeanKL                  | 0.00645299 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.47e+03   |
| NumTrajs                | 8          |
| Perplexity              | 9.20246    |
| PolicyExecTime          | 0.572      |
| ProcessExecTime         | 0.0665     |
| StdReturn               | 696        |
| Time                    | 4.36e+03   |
| dLoss                   | 0.0214501  |
----------------------------------------
itr #325 | 
Mem: 726.570312
Obtaining samples...
Obtaining samples for iteration 325...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5063, #subsample_inputs: 5063
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.591      |
| AbsLearnSignalNew       | 0.591      |
| AbsLearningOld          | 0.591      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 37.3525    |
| AveragePolicyStd        | 0.508502   |
| AverageReturn           | 2.27e+03   |
| Entropy                 | 2.21525    |
| EnvExecTime             | 2.14       |
| ExplainedVariance       | 0.714      |
| Iteration               | 325        |
| ItrTime                 | 13.2       |
| LossAfter               | -0.216761  |
| LossBefore              | -0.176323  |
| MaxReturn               | 3.22e+03   |
| MeanKL                  | 0.00988485 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.21e+03   |
| NumTrajs                | 7          |
| Perplexity              | 9.16366    |
| PolicyExecTime          | 0.541      |
| ProcessExecTime         | 0.0612     |
| StdReturn               | 844        |
| Time                    | 4.37e+03   |
| dLoss                   | 0.0404382  |
----------------------------------------
itr #326 | 
Mem: 726.570312
Obtaining samples...
Obtaining samples for iteration 326...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5080, #subsample_inputs: 5080
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.697      |
| AbsLearnSignalNew       | 0.697      |
| AbsLearningOld          | 0.697      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 36.0354    |
| AveragePolicyStd        | 0.508728   |
| AverageReturn           | 2.06e+03   |
| Entropy                 | 2.21705    |
| EnvExecTime             | 1.9        |
| ExplainedVariance       | 0.727      |
| Iteration               | 326        |
| ItrTime                 | 12.7       |
| LossAfter               | 0.193      |
| LossBefore              | 0.216515   |
| MaxReturn               | 3.3e+03    |
| MeanKL                  | 0.00641231 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.14e+03   |
| NumTrajs                | 8          |
| Perplexity              | 9.18017    |
| PolicyExecTime          | 0.482      |
| ProcessExecTime         | 0.0568     |
| StdReturn               | 638        |
| Time                    | 4.39e+03   |
| dLoss                   | 0.0235143  |
----------------------------------------
itr #327 | 
Mem: 726.570312
Obtaining samples...
Obtaining samples for iteration 327...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5848, #subsample_inputs: 5848
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.646      |
| AbsLearnSignalNew       | 0.646      |
| AbsLearningOld          | 0.646      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 32.9091    |
| AveragePolicyStd        | 0.509379   |
| AverageReturn           | 1.73e+03   |
| Entropy                 | 2.22015    |
| EnvExecTime             | 2.29       |
| ExplainedVariance       | 0.826      |
| Iteration               | 327        |
| ItrTime                 | 14.4       |
| LossAfter               | -0.672321  |
| LossBefore              | -0.650164  |
| MaxReturn               | 3.07e+03   |
| MeanKL                  | 0.00642256 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.1e+03    |
| NumTrajs                | 11         |
| Perplexity              | 9.20868    |
| PolicyExecTime          | 0.579      |
| ProcessExecTime         | 0.0682     |
| StdReturn               | 607        |
| Time                    | 4.4e+03    |
| dLoss                   | 0.0221573  |
----------------------------------------
itr #328 | 
Mem: 726.570312
Obtaining samples...
Obtaining samples for iteration 328...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5297, #subsample_inputs: 5297
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.759      |
| AbsLearnSignalNew       | 0.759      |
| AbsLearningOld          | 0.759      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 31.9072    |
| AveragePolicyStd        | 0.509033   |
| AverageReturn           | 2.11e+03   |
| Entropy                 | 2.21921    |
| EnvExecTime             | 2.06       |
| ExplainedVariance       | 0.868      |
| Iteration               | 328        |
| ItrTime                 | 13.3       |
| LossAfter               | 0.559397   |
| LossBefore              | 0.581032   |
| MaxReturn               | 2.91e+03   |
| MeanKL                  | 0.00646942 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.08e+03   |
| NumTrajs                | 8          |
| Perplexity              | 9.2001     |
| PolicyExecTime          | 0.524      |
| ProcessExecTime         | 0.0598     |
| StdReturn               | 694        |
| Time                    | 4.41e+03   |
| dLoss                   | 0.0216352  |
----------------------------------------
itr #329 | 
Mem: 726.570312
Obtaining samples...
Obtaining samples for iteration 329...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 6297, #subsample_inputs: 6297
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.712      |
| AbsLearnSignalNew       | 0.712      |
| AbsLearningOld          | 0.712      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 32.1127    |
| AveragePolicyStd        | 0.509031   |
| AverageReturn           | 1.87e+03   |
| Entropy                 | 2.21876    |
| EnvExecTime             | 2.1        |
| ExplainedVariance       | 0.837      |
| Iteration               | 329        |
| ItrTime                 | 14.8       |
| LossAfter               | -0.251289  |
| LossBefore              | -0.224025  |
| MaxReturn               | 3.21e+03   |
| MeanKL                  | 0.00994186 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.13e+03   |
| NumTrajs                | 11         |
| Perplexity              | 9.19589    |
| PolicyExecTime          | 0.541      |
| ProcessExecTime         | 0.0646     |
| StdReturn               | 724        |
| Time                    | 4.43e+03   |
| dLoss                   | 0.0272636  |
----------------------------------------
itr #330 | 
Mem: 730.949219
Obtaining samples...
Obtaining samples for iteration 330...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5778, #subsample_inputs: 5778
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.747      |
| AbsLearnSignalNew       | 0.747      |
| AbsLearningOld          | 0.747      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 30.6058    |
| AveragePolicyStd        | 0.509171   |
| AverageReturn           | 1.56e+03   |
| Entropy                 | 2.21926    |
| EnvExecTime             | 2.3        |
| ExplainedVariance       | 0.879      |
| Iteration               | 330        |
| ItrTime                 | 14.3       |
| LossAfter               | 0.207094   |
| LossBefore              | 0.225861   |
| MaxReturn               | 2.93e+03   |
| MeanKL                  | 0.00649935 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 945        |
| NumTrajs                | 12         |
| Perplexity              | 9.2005     |
| PolicyExecTime          | 0.579      |
| ProcessExecTime         | 0.0699     |
| StdReturn               | 644        |
| Time                    | 4.44e+03   |
| dLoss                   | 0.0187674  |
----------------------------------------
itr #331 | 
Mem: 730.949219
Obtaining samples...
Obtaining samples for iteration 331...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5186, #subsample_inputs: 5186
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.755     |
| AbsLearnSignalNew       | 0.755     |
| AbsLearningOld          | 0.755     |
| AverageDiscountedReturn | 251       |
| AveragePhiLoss          | 32.1469   |
| AveragePolicyStd        | 0.508083  |
| AverageReturn           | 2.3e+03   |
| Entropy                 | 2.21343   |
| EnvExecTime             | 2.19      |
| ExplainedVariance       | 0.871     |
| Iteration               | 331       |
| ItrTime                 | 13.3      |
| LossAfter               | 0.210105  |
| LossBefore              | 0.235816  |
| MaxReturn               | 2.97e+03  |
| MeanKL                  | 0.0099601 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.36e+03  |
| NumTrajs                | 7         |
| Perplexity              | 9.14706   |
| PolicyExecTime          | 0.558     |
| ProcessExecTime         | 0.0621    |
| StdReturn               | 619       |
| Time                    | 4.46e+03  |
| dLoss                   | 0.0257111 |
---------------------------------------
itr #332 | 
Mem: 731.199219
Obtaining samples...
Obtaining samples for iteration 332...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5625, #subsample_inputs: 5625
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.679      |
| AbsLearnSignalNew       | 0.679      |
| AbsLearningOld          | 0.679      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 34.6038    |
| AveragePolicyStd        | 0.508313   |
| AverageReturn           | 1.97e+03   |
| Entropy                 | 2.21465    |
| EnvExecTime             | 2.19       |
| ExplainedVariance       | 0.843      |
| Iteration               | 332        |
| ItrTime                 | 13.9       |
| LossAfter               | -0.816176  |
| LossBefore              | -0.787521  |
| MaxReturn               | 2.75e+03   |
| MeanKL                  | 0.00977473 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.32e+03   |
| NumTrajs                | 9          |
| Perplexity              | 9.15819    |
| PolicyExecTime          | 0.562      |
| ProcessExecTime         | 0.0627     |
| StdReturn               | 542        |
| Time                    | 4.47e+03   |
| dLoss                   | 0.0286549  |
----------------------------------------
itr #333 | 
Mem: 731.199219
Obtaining samples...
Obtaining samples for iteration 333...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5390, #subsample_inputs: 5390
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.75       |
| AbsLearnSignalNew       | 0.75       |
| AbsLearningOld          | 0.75       |
| AverageDiscountedReturn | 254        |
| AveragePhiLoss          | 35.711     |
| AveragePolicyStd        | 0.508551   |
| AverageReturn           | 2.16e+03   |
| Entropy                 | 2.21588    |
| EnvExecTime             | 1.96       |
| ExplainedVariance       | 0.808      |
| Iteration               | 333        |
| ItrTime                 | 13.4       |
| LossAfter               | -0.80612   |
| LossBefore              | -0.777291  |
| MaxReturn               | 2.89e+03   |
| MeanKL                  | 0.00987445 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.29e+03   |
| NumTrajs                | 8          |
| Perplexity              | 9.1695     |
| PolicyExecTime          | 0.499      |
| ProcessExecTime         | 0.059      |
| StdReturn               | 512        |
| Time                    | 4.48e+03   |
| dLoss                   | 0.0288294  |
----------------------------------------
itr #334 | 
Mem: 731.199219
Obtaining samples...
Obtaining samples for iteration 334...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5377, #subsample_inputs: 5377
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.748      |
| AbsLearnSignalNew       | 0.748      |
| AbsLearningOld          | 0.748      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 34.2893    |
| AveragePolicyStd        | 0.506586   |
| AverageReturn           | 2.25e+03   |
| Entropy                 | 2.20309    |
| EnvExecTime             | 2.18       |
| ExplainedVariance       | 0.759      |
| Iteration               | 334        |
| ItrTime                 | 13.6       |
| LossAfter               | 0.507809   |
| LossBefore              | 0.531218   |
| MaxReturn               | 2.88e+03   |
| MeanKL                  | 0.00999376 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.32e+03   |
| NumTrajs                | 7          |
| Perplexity              | 9.05298    |
| PolicyExecTime          | 0.549      |
| ProcessExecTime         | 0.063      |
| StdReturn               | 633        |
| Time                    | 4.5e+03    |
| dLoss                   | 0.0234092  |
----------------------------------------
itr #335 | 
Mem: 731.199219
Obtaining samples...
Obtaining samples for iteration 335...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5371, #subsample_inputs: 5371
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.68       |
| AbsLearnSignalNew       | 0.68       |
| AbsLearningOld          | 0.68       |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 37.2362    |
| AveragePolicyStd        | 0.505493   |
| AverageReturn           | 2.37e+03   |
| Entropy                 | 2.19589    |
| EnvExecTime             | 2.32       |
| ExplainedVariance       | 0.819      |
| Iteration               | 335        |
| ItrTime                 | 13.8       |
| LossAfter               | -0.0500393 |
| LossBefore              | -0.026203  |
| MaxReturn               | 3.02e+03   |
| MeanKL                  | 0.00655753 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.5e+03    |
| NumTrajs                | 7          |
| Perplexity              | 8.98804    |
| PolicyExecTime          | 0.588      |
| ProcessExecTime         | 0.0666     |
| StdReturn               | 621        |
| Time                    | 4.51e+03   |
| dLoss                   | 0.0238363  |
----------------------------------------
itr #336 | 
Mem: 731.601562
Obtaining samples...
Obtaining samples for iteration 336...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5136, #subsample_inputs: 5136
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.711      |
| AbsLearnSignalNew       | 0.711      |
| AbsLearningOld          | 0.711      |
| AverageDiscountedReturn | 256        |
| AveragePhiLoss          | 38.4127    |
| AveragePolicyStd        | 0.503268   |
| AverageReturn           | 1.7e+03    |
| Entropy                 | 2.18186    |
| EnvExecTime             | 1.94       |
| ExplainedVariance       | 0.807      |
| Iteration               | 336        |
| ItrTime                 | 12.9       |
| LossAfter               | -0.440344  |
| LossBefore              | -0.415834  |
| MaxReturn               | 2.8e+03    |
| MeanKL                  | 0.00644437 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.14e+03   |
| NumTrajs                | 10         |
| Perplexity              | 8.86281    |
| PolicyExecTime          | 0.488      |
| ProcessExecTime         | 0.0573     |
| StdReturn               | 486        |
| Time                    | 4.52e+03   |
| dLoss                   | 0.0245101  |
----------------------------------------
itr #337 | 
Mem: 731.601562
Obtaining samples...
Obtaining samples for iteration 337...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5272, #subsample_inputs: 5272
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.748      |
| AbsLearnSignalNew       | 0.748      |
| AbsLearningOld          | 0.748      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 35.2949    |
| AveragePolicyStd        | 0.501237   |
| AverageReturn           | 1.54e+03   |
| Entropy                 | 2.17059    |
| EnvExecTime             | 2.26       |
| ExplainedVariance       | 0.762      |
| Iteration               | 337        |
| ItrTime                 | 13.6       |
| LossAfter               | -0.738759  |
| LossBefore              | -0.710928  |
| MaxReturn               | 2.92e+03   |
| MeanKL                  | 0.00992402 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 963        |
| NumTrajs                | 11         |
| Perplexity              | 8.76343    |
| PolicyExecTime          | 0.565      |
| ProcessExecTime         | 0.0637     |
| StdReturn               | 750        |
| Time                    | 4.54e+03   |
| dLoss                   | 0.0278312  |
----------------------------------------
itr #338 | 
Mem: 731.601562
Obtaining samples...
Obtaining samples for iteration 338...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5251, #subsample_inputs: 5251
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.764      |
| AbsLearnSignalNew       | 0.764      |
| AbsLearningOld          | 0.764      |
| AverageDiscountedReturn | 254        |
| AveragePhiLoss          | 37.6565    |
| AveragePolicyStd        | 0.500998   |
| AverageReturn           | 1.62e+03   |
| Entropy                 | 2.1698     |
| EnvExecTime             | 1.87       |
| ExplainedVariance       | 0.848      |
| Iteration               | 338        |
| ItrTime                 | 13         |
| LossAfter               | 0.162925   |
| LossBefore              | 0.188823   |
| MaxReturn               | 2.55e+03   |
| MeanKL                  | 0.00986864 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 932        |
| NumTrajs                | 11         |
| Perplexity              | 8.75649    |
| PolicyExecTime          | 0.474      |
| ProcessExecTime         | 0.056      |
| StdReturn               | 487        |
| Time                    | 4.55e+03   |
| dLoss                   | 0.0258976  |
----------------------------------------
itr #339 | 
Mem: 731.601562
Obtaining samples...
Obtaining samples for iteration 339...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5258, #subsample_inputs: 5258
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.764      |
| AbsLearnSignalNew       | 0.764      |
| AbsLearningOld          | 0.764      |
| AverageDiscountedReturn | 254        |
| AveragePhiLoss          | 38.3487    |
| AveragePolicyStd        | 0.500722   |
| AverageReturn           | 1.2e+03    |
| Entropy                 | 2.16741    |
| EnvExecTime             | 2.09       |
| ExplainedVariance       | 0.928      |
| Iteration               | 339        |
| ItrTime                 | 13.3       |
| LossAfter               | -1.38931   |
| LossBefore              | -1.36474   |
| MaxReturn               | 1.69e+03   |
| MeanKL                  | 0.00652423 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 934        |
| NumTrajs                | 15         |
| Perplexity              | 8.7356     |
| PolicyExecTime          | 0.533      |
| ProcessExecTime         | 0.0591     |
| StdReturn               | 193        |
| Time                    | 4.56e+03   |
| dLoss                   | 0.0245672  |
----------------------------------------
itr #340 | 
Mem: 731.601562
Obtaining samples...
Obtaining samples for iteration 340...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5384, #subsample_inputs: 5384
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.768      |
| AbsLearnSignalNew       | 0.768      |
| AbsLearningOld          | 0.768      |
| AverageDiscountedReturn | 255        |
| AveragePhiLoss          | 36.6226    |
| AveragePolicyStd        | 0.499782   |
| AverageReturn           | 1.32e+03   |
| Entropy                 | 2.16175    |
| EnvExecTime             | 2.06       |
| ExplainedVariance       | 0.946      |
| Iteration               | 340        |
| ItrTime                 | 13.6       |
| LossAfter               | -0.0101969 |
| LossBefore              | 0.0166827  |
| MaxReturn               | 1.75e+03   |
| MeanKL                  | 0.00969923 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 950        |
| NumTrajs                | 14         |
| Perplexity              | 8.68631    |
| PolicyExecTime          | 0.516      |
| ProcessExecTime         | 0.0607     |
| StdReturn               | 212        |
| Time                    | 4.58e+03   |
| dLoss                   | 0.0268796  |
----------------------------------------
itr #341 | 
Mem: 731.601562
Obtaining samples...
Obtaining samples for iteration 341...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5210, #subsample_inputs: 5210
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.282      |
| AbsLearnSignalNew       | 0.282      |
| AbsLearningOld          | 0.282      |
| AverageDiscountedReturn | 254        |
| AveragePhiLoss          | 53.8767    |
| AveragePolicyStd        | 0.500416   |
| AverageReturn           | 1.45e+03   |
| Entropy                 | 2.16527    |
| EnvExecTime             | 2.25       |
| ExplainedVariance       | -8.62      |
| Iteration               | 341        |
| ItrTime                 | 13.4       |
| LossAfter               | -0.213543  |
| LossBefore              | -0.196276  |
| MaxReturn               | 2.89e+03   |
| MeanKL                  | 0.00654148 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 923        |
| NumTrajs                | 12         |
| Perplexity              | 8.71694    |
| PolicyExecTime          | 0.551      |
| ProcessExecTime         | 0.0648     |
| StdReturn               | 498        |
| Time                    | 4.59e+03   |
| dLoss                   | 0.0172669  |
----------------------------------------
itr #342 | 
Mem: 731.601562
Obtaining samples...
Obtaining samples for iteration 342...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5391, #subsample_inputs: 5391
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.685      |
| AbsLearnSignalNew       | 0.685      |
| AbsLearningOld          | 0.685      |
| AverageDiscountedReturn | 254        |
| AveragePhiLoss          | 34.8879    |
| AveragePolicyStd        | 0.499128   |
| AverageReturn           | 1.39e+03   |
| Entropy                 | 2.15759    |
| EnvExecTime             | 2.35       |
| ExplainedVariance       | 0.831      |
| Iteration               | 342        |
| ItrTime                 | 14         |
| LossAfter               | 0.450267   |
| LossBefore              | 0.472115   |
| MaxReturn               | 2.51e+03   |
| MeanKL                  | 0.00640883 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 939        |
| NumTrajs                | 13         |
| Perplexity              | 8.65027    |
| PolicyExecTime          | 0.598      |
| ProcessExecTime         | 0.0659     |
| StdReturn               | 389        |
| Time                    | 4.61e+03   |
| dLoss                   | 0.0218477  |
----------------------------------------
itr #343 | 
Mem: 731.601562
Obtaining samples...
Obtaining samples for iteration 343...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5835, #subsample_inputs: 5835
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.744      |
| AbsLearnSignalNew       | 0.744      |
| AbsLearningOld          | 0.744      |
| AverageDiscountedReturn | 255        |
| AveragePhiLoss          | 35.4766    |
| AveragePolicyStd        | 0.501248   |
| AverageReturn           | 1.49e+03   |
| Entropy                 | 2.1701     |
| EnvExecTime             | 2.22       |
| ExplainedVariance       | 0.814      |
| Iteration               | 343        |
| ItrTime                 | 14.3       |
| LossAfter               | -0.269395  |
| LossBefore              | -0.243525  |
| MaxReturn               | 2.78e+03   |
| MeanKL                  | 0.00988813 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 978        |
| NumTrajs                | 13         |
| Perplexity              | 8.75915    |
| PolicyExecTime          | 0.565      |
| ProcessExecTime         | 0.065      |
| StdReturn               | 483        |
| Time                    | 4.62e+03   |
| dLoss                   | 0.0258704  |
----------------------------------------
itr #344 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 344...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5046, #subsample_inputs: 5046
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.746      |
| AbsLearnSignalNew       | 0.746      |
| AbsLearningOld          | 0.746      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 37.0436    |
| AveragePolicyStd        | 0.501244   |
| AverageReturn           | 2.03e+03   |
| Entropy                 | 2.17001    |
| EnvExecTime             | 1.82       |
| ExplainedVariance       | 0.772      |
| Iteration               | 344        |
| ItrTime                 | 12.6       |
| LossAfter               | -0.0989077 |
| LossBefore              | -0.0744098 |
| MaxReturn               | 2.91e+03   |
| MeanKL                  | 0.00644625 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.45e+03   |
| NumTrajs                | 8          |
| Perplexity              | 8.75833    |
| PolicyExecTime          | 0.46       |
| ProcessExecTime         | 0.0544     |
| StdReturn               | 470        |
| Time                    | 4.63e+03   |
| dLoss                   | 0.0244979  |
----------------------------------------
itr #345 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 345...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5622, #subsample_inputs: 5622
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.665      |
| AbsLearnSignalNew       | 0.665      |
| AbsLearningOld          | 0.665      |
| AverageDiscountedReturn | 255        |
| AveragePhiLoss          | 38.3745    |
| AveragePolicyStd        | 0.500605   |
| AverageReturn           | 1.93e+03   |
| Entropy                 | 2.16633    |
| EnvExecTime             | 2.24       |
| ExplainedVariance       | 0.805      |
| Iteration               | 345        |
| ItrTime                 | 14         |
| LossAfter               | -0.719381  |
| LossBefore              | -0.684882  |
| MaxReturn               | 3.29e+03   |
| MeanKL                  | 0.00988009 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 947        |
| NumTrajs                | 10         |
| Perplexity              | 8.72623    |
| PolicyExecTime          | 0.559      |
| ProcessExecTime         | 0.0669     |
| StdReturn               | 653        |
| Time                    | 4.65e+03   |
| dLoss                   | 0.034499   |
----------------------------------------
itr #346 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 346...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5131, #subsample_inputs: 5131
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.592      |
| AbsLearnSignalNew       | 0.592      |
| AbsLearningOld          | 0.592      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 35.3022    |
| AveragePolicyStd        | 0.500439   |
| AverageReturn           | 1.69e+03   |
| Entropy                 | 2.16495    |
| EnvExecTime             | 2.23       |
| ExplainedVariance       | 0.561      |
| Iteration               | 346        |
| ItrTime                 | 13.3       |
| LossAfter               | -0.609141  |
| LossBefore              | -0.58263   |
| MaxReturn               | 3.08e+03   |
| MeanKL                  | 0.00992374 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 257        |
| NumTrajs                | 10         |
| Perplexity              | 8.71418    |
| PolicyExecTime          | 0.557      |
| ProcessExecTime         | 0.0655     |
| StdReturn               | 806        |
| Time                    | 4.66e+03   |
| dLoss                   | 0.0265113  |
----------------------------------------
itr #347 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 347...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5530, #subsample_inputs: 5530
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.704      |
| AbsLearnSignalNew       | 0.704      |
| AbsLearningOld          | 0.704      |
| AverageDiscountedReturn | 255        |
| AveragePhiLoss          | 38.5132    |
| AveragePolicyStd        | 0.502959   |
| AverageReturn           | 1.81e+03   |
| Entropy                 | 2.17744    |
| EnvExecTime             | 2.28       |
| ExplainedVariance       | 0.723      |
| Iteration               | 347        |
| ItrTime                 | 14         |
| LossAfter               | 0.526621   |
| LossBefore              | 0.550249   |
| MaxReturn               | 2.96e+03   |
| MeanKL                  | 0.00641679 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 993        |
| NumTrajs                | 10         |
| Perplexity              | 8.82371    |
| PolicyExecTime          | 0.575      |
| ProcessExecTime         | 0.0645     |
| StdReturn               | 552        |
| Time                    | 4.67e+03   |
| dLoss                   | 0.0236278  |
----------------------------------------
itr #348 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 348...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5606, #subsample_inputs: 5606
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.711      |
| AbsLearnSignalNew       | 0.711      |
| AbsLearningOld          | 0.711      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 34.5534    |
| AveragePolicyStd        | 0.50104    |
| AverageReturn           | 1.99e+03   |
| Entropy                 | 2.16588    |
| EnvExecTime             | 2.16       |
| ExplainedVariance       | 0.572      |
| Iteration               | 348        |
| ItrTime                 | 13.9       |
| LossAfter               | 0.0719128  |
| LossBefore              | 0.100289   |
| MaxReturn               | 3.03e+03   |
| MeanKL                  | 0.00996219 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.22e+03   |
| NumTrajs                | 9          |
| Perplexity              | 8.72224    |
| PolicyExecTime          | 0.554      |
| ProcessExecTime         | 0.063      |
| StdReturn               | 673        |
| Time                    | 4.69e+03   |
| dLoss                   | 0.0283765  |
----------------------------------------
itr #349 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 349...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5049, #subsample_inputs: 5049
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.738      |
| AbsLearnSignalNew       | 0.738      |
| AbsLearningOld          | 0.738      |
| AverageDiscountedReturn | 256        |
| AveragePhiLoss          | 36.8448    |
| AveragePolicyStd        | 0.500799   |
| AverageReturn           | 1.71e+03   |
| Entropy                 | 2.16477    |
| EnvExecTime             | 2.28       |
| ExplainedVariance       | 0.846      |
| Iteration               | 349        |
| ItrTime                 | 13.2       |
| LossAfter               | 0.316922   |
| LossBefore              | 0.34732    |
| MaxReturn               | 3.35e+03   |
| MeanKL                  | 0.00648908 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.11e+03   |
| NumTrajs                | 10         |
| Perplexity              | 8.71263    |
| PolicyExecTime          | 0.568      |
| ProcessExecTime         | 0.0645     |
| StdReturn               | 662        |
| Time                    | 4.7e+03    |
| dLoss                   | 0.0303979  |
----------------------------------------
itr #350 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 350...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5069, #subsample_inputs: 5069
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.639      |
| AbsLearnSignalNew       | 0.639      |
| AbsLearningOld          | 0.638      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 38.8482    |
| AveragePolicyStd        | 0.501273   |
| AverageReturn           | 1.99e+03   |
| Entropy                 | 2.16886    |
| EnvExecTime             | 2.13       |
| ExplainedVariance       | 0.619      |
| Iteration               | 350        |
| ItrTime                 | 13.1       |
| LossAfter               | -0.728238  |
| LossBefore              | -0.708786  |
| MaxReturn               | 3.05e+03   |
| MeanKL                  | 0.00650364 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.08e+03   |
| NumTrajs                | 8          |
| Perplexity              | 8.7483     |
| PolicyExecTime          | 0.532      |
| ProcessExecTime         | 0.0621     |
| StdReturn               | 703        |
| Time                    | 4.71e+03   |
| dLoss                   | 0.0194515  |
----------------------------------------
itr #351 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 351...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5418, #subsample_inputs: 5418
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.739      |
| AbsLearnSignalNew       | 0.739      |
| AbsLearningOld          | 0.739      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 35.8978    |
| AveragePolicyStd        | 0.500305   |
| AverageReturn           | 2.45e+03   |
| Entropy                 | 2.16307    |
| EnvExecTime             | 2.36       |
| ExplainedVariance       | 0.851      |
| Iteration               | 351        |
| ItrTime                 | 14         |
| LossAfter               | -0.16215   |
| LossBefore              | -0.137577  |
| MaxReturn               | 3.2e+03    |
| MeanKL                  | 0.00648143 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.46e+03   |
| NumTrajs                | 7          |
| Perplexity              | 8.6978     |
| PolicyExecTime          | 0.605      |
| ProcessExecTime         | 0.0667     |
| StdReturn               | 601        |
| Time                    | 4.73e+03   |
| dLoss                   | 0.0245726  |
----------------------------------------
itr #352 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 352...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5727, #subsample_inputs: 5727
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.682      |
| AbsLearnSignalNew       | 0.682      |
| AbsLearningOld          | 0.682      |
| AverageDiscountedReturn | 254        |
| AveragePhiLoss          | 42.6848    |
| AveragePolicyStd        | 0.499593   |
| AverageReturn           | 2.37e+03   |
| Entropy                 | 2.15834    |
| EnvExecTime             | 2.38       |
| ExplainedVariance       | 0.823      |
| Iteration               | 352        |
| ItrTime                 | 14.3       |
| LossAfter               | 0.920808   |
| LossBefore              | 0.951525   |
| MaxReturn               | 3.23e+03   |
| MeanKL                  | 0.00982848 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.53e+03   |
| NumTrajs                | 8          |
| Perplexity              | 8.65676    |
| PolicyExecTime          | 0.603      |
| ProcessExecTime         | 0.0691     |
| StdReturn               | 510        |
| Time                    | 4.74e+03   |
| dLoss                   | 0.0307174  |
----------------------------------------
itr #353 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 353...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5026, #subsample_inputs: 5026
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.737      |
| AbsLearnSignalNew       | 0.737      |
| AbsLearningOld          | 0.737      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 37.8857    |
| AveragePolicyStd        | 0.497684   |
| AverageReturn           | 2.2e+03    |
| Entropy                 | 2.14797    |
| EnvExecTime             | 2.13       |
| ExplainedVariance       | 0.88       |
| Iteration               | 353        |
| ItrTime                 | 13         |
| LossAfter               | -0.485107  |
| LossBefore              | -0.463381  |
| MaxReturn               | 2.94e+03   |
| MeanKL                  | 0.00642791 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.14e+03   |
| NumTrajs                | 7          |
| Perplexity              | 8.56747    |
| PolicyExecTime          | 0.54       |
| ProcessExecTime         | 0.0604     |
| StdReturn               | 644        |
| Time                    | 4.76e+03   |
| dLoss                   | 0.0217255  |
----------------------------------------
itr #354 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 354...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5457, #subsample_inputs: 5457
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.67       |
| AbsLearnSignalNew       | 0.67       |
| AbsLearningOld          | 0.67       |
| AverageDiscountedReturn | 254        |
| AveragePhiLoss          | 40.0942    |
| AveragePolicyStd        | 0.499341   |
| AverageReturn           | 2.27e+03   |
| Entropy                 | 2.15729    |
| EnvExecTime             | 2.37       |
| ExplainedVariance       | 0.783      |
| Iteration               | 354        |
| ItrTime                 | 14.1       |
| LossAfter               | -0.161572  |
| LossBefore              | -0.139632  |
| MaxReturn               | 2.94e+03   |
| MeanKL                  | 0.00647898 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.19e+03   |
| NumTrajs                | 8          |
| Perplexity              | 8.64768    |
| PolicyExecTime          | 0.594      |
| ProcessExecTime         | 0.0687     |
| StdReturn               | 653        |
| Time                    | 4.77e+03   |
| dLoss                   | 0.0219402  |
----------------------------------------
itr #355 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 355...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5195, #subsample_inputs: 5195
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.738      |
| AbsLearnSignalNew       | 0.738      |
| AbsLearningOld          | 0.738      |
| AverageDiscountedReturn | 257        |
| AveragePhiLoss          | 36.6401    |
| AveragePolicyStd        | 0.499481   |
| AverageReturn           | 1.79e+03   |
| Entropy                 | 2.15804    |
| EnvExecTime             | 2          |
| ExplainedVariance       | 0.894      |
| Iteration               | 355        |
| ItrTime                 | 13.1       |
| LossAfter               | -0.0811103 |
| LossBefore              | -0.0512593 |
| MaxReturn               | 2.36e+03   |
| MeanKL                  | 0.00996263 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.31e+03   |
| NumTrajs                | 10         |
| Perplexity              | 8.65417    |
| PolicyExecTime          | 0.514      |
| ProcessExecTime         | 0.0578     |
| StdReturn               | 377        |
| Time                    | 4.78e+03   |
| dLoss                   | 0.029851   |
----------------------------------------
itr #356 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 356...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5289, #subsample_inputs: 5289
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.475      |
| AbsLearnSignalNew       | 0.475      |
| AbsLearningOld          | 0.475      |
| AverageDiscountedReturn | 255        |
| AveragePhiLoss          | 29.84      |
| AveragePolicyStd        | 0.498265   |
| AverageReturn           | 1.99e+03   |
| Entropy                 | 2.15086    |
| EnvExecTime             | 2.07       |
| ExplainedVariance       | 0.455      |
| Iteration               | 356        |
| ItrTime                 | 13.3       |
| LossAfter               | -0.101694  |
| LossBefore              | -0.0810999 |
| MaxReturn               | 3.35e+03   |
| MeanKL                  | 0.00663937 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.22e+03   |
| NumTrajs                | 9          |
| Perplexity              | 8.59224    |
| PolicyExecTime          | 0.531      |
| ProcessExecTime         | 0.0601     |
| StdReturn               | 837        |
| Time                    | 4.8e+03    |
| dLoss                   | 0.0205942  |
----------------------------------------
itr #357 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 357...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5020, #subsample_inputs: 5020
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.731      |
| AbsLearnSignalNew       | 0.731      |
| AbsLearningOld          | 0.731      |
| AverageDiscountedReturn | 256        |
| AveragePhiLoss          | 38.4883    |
| AveragePolicyStd        | 0.498312   |
| AverageReturn           | 1.93e+03   |
| Entropy                 | 2.15066    |
| EnvExecTime             | 1.81       |
| ExplainedVariance       | 0.873      |
| Iteration               | 357        |
| ItrTime                 | 12.6       |
| LossAfter               | 0.372168   |
| LossBefore              | 0.404681   |
| MaxReturn               | 3.14e+03   |
| MeanKL                  | 0.00994586 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 957        |
| NumTrajs                | 9          |
| Perplexity              | 8.59056    |
| PolicyExecTime          | 0.463      |
| ProcessExecTime         | 0.0539     |
| StdReturn               | 756        |
| Time                    | 4.81e+03   |
| dLoss                   | 0.0325128  |
----------------------------------------
itr #358 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 358...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5118, #subsample_inputs: 5118
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.584      |
| AbsLearnSignalNew       | 0.584      |
| AbsLearningOld          | 0.584      |
| AverageDiscountedReturn | 254        |
| AveragePhiLoss          | 35.1856    |
| AveragePolicyStd        | 0.500426   |
| AverageReturn           | 2.44e+03   |
| Entropy                 | 2.16244    |
| EnvExecTime             | 2.09       |
| ExplainedVariance       | 0.582      |
| Iteration               | 358        |
| ItrTime                 | 13         |
| LossAfter               | -0.385606  |
| LossBefore              | -0.36416   |
| MaxReturn               | 3.25e+03   |
| MeanKL                  | 0.00969795 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.41e+03   |
| NumTrajs                | 7          |
| Perplexity              | 8.69234    |
| PolicyExecTime          | 0.527      |
| ProcessExecTime         | 0.0611     |
| StdReturn               | 651        |
| Time                    | 4.82e+03   |
| dLoss                   | 0.0214458  |
----------------------------------------
itr #359 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 359...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5177, #subsample_inputs: 5177
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.747      |
| AbsLearnSignalNew       | 0.747      |
| AbsLearningOld          | 0.747      |
| AverageDiscountedReturn | 257        |
| AveragePhiLoss          | 35.2136    |
| AveragePolicyStd        | 0.502388   |
| AverageReturn           | 1.94e+03   |
| Entropy                 | 2.17359    |
| EnvExecTime             | 2.65       |
| ExplainedVariance       | 0.852      |
| Iteration               | 359        |
| ItrTime                 | 13.9       |
| LossAfter               | 2.04522    |
| LossBefore              | 2.07377    |
| MaxReturn               | 2.97e+03   |
| MeanKL                  | 0.00970244 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.23e+03   |
| NumTrajs                | 9          |
| Perplexity              | 8.78982    |
| PolicyExecTime          | 0.655      |
| ProcessExecTime         | 0.0745     |
| StdReturn               | 538        |
| Time                    | 4.84e+03   |
| dLoss                   | 0.0285428  |
----------------------------------------
itr #360 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 360...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5158, #subsample_inputs: 5158
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.745      |
| AbsLearnSignalNew       | 0.745      |
| AbsLearningOld          | 0.745      |
| AverageDiscountedReturn | 255        |
| AveragePhiLoss          | 34.1093    |
| AveragePolicyStd        | 0.503341   |
| AverageReturn           | 1.91e+03   |
| Entropy                 | 2.17925    |
| EnvExecTime             | 1.9        |
| ExplainedVariance       | 0.893      |
| Iteration               | 360        |
| ItrTime                 | 12.9       |
| LossAfter               | -0.251358  |
| LossBefore              | -0.226842  |
| MaxReturn               | 2.95e+03   |
| MeanKL                  | 0.00999327 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1e+03      |
| NumTrajs                | 9          |
| Perplexity              | 8.83969    |
| PolicyExecTime          | 0.485      |
| ProcessExecTime         | 0.0563     |
| StdReturn               | 597        |
| Time                    | 4.85e+03   |
| dLoss                   | 0.0245162  |
----------------------------------------
itr #361 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 361...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5311, #subsample_inputs: 5311
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.655     |
| AbsLearnSignalNew       | 0.655     |
| AbsLearningOld          | 0.655     |
| AverageDiscountedReturn | 256       |
| AveragePhiLoss          | 40.3321   |
| AveragePolicyStd        | 0.503747  |
| AverageReturn           | 1.75e+03  |
| Entropy                 | 2.18182   |
| EnvExecTime             | 2.25      |
| ExplainedVariance       | 0.789     |
| Iteration               | 361       |
| ItrTime                 | 13.6      |
| LossAfter               | 0.749443  |
| LossBefore              | 0.776343  |
| MaxReturn               | 3.07e+03  |
| MeanKL                  | 0.0067836 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 931       |
| NumTrajs                | 10        |
| Perplexity              | 8.86245   |
| PolicyExecTime          | 0.563     |
| ProcessExecTime         | 0.0689    |
| StdReturn               | 820       |
| Time                    | 4.86e+03  |
| dLoss                   | 0.0268997 |
---------------------------------------
itr #362 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 362...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5244, #subsample_inputs: 5244
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.742      |
| AbsLearnSignalNew       | 0.742      |
| AbsLearningOld          | 0.742      |
| AverageDiscountedReturn | 258        |
| AveragePhiLoss          | 35.6611    |
| AveragePolicyStd        | 0.502098   |
| AverageReturn           | 1.83e+03   |
| Entropy                 | 2.17214    |
| EnvExecTime             | 2.14       |
| ExplainedVariance       | 0.846      |
| Iteration               | 362        |
| ItrTime                 | 13.3       |
| LossAfter               | 0.00907675 |
| LossBefore              | 0.0358154  |
| MaxReturn               | 3.26e+03   |
| MeanKL                  | 0.0064121  |
| MeanKLBefore            | 0.0        |
| MinReturn               | 951        |
| NumTrajs                | 10         |
| Perplexity              | 8.77703    |
| PolicyExecTime          | 0.542      |
| ProcessExecTime         | 0.0621     |
| StdReturn               | 665        |
| Time                    | 4.88e+03   |
| dLoss                   | 0.0267387  |
----------------------------------------
itr #363 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 363...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5907, #subsample_inputs: 5907
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.621      |
| AbsLearnSignalNew       | 0.621      |
| AbsLearningOld          | 0.621      |
| AverageDiscountedReturn | 254        |
| AveragePhiLoss          | 34.8773    |
| AveragePolicyStd        | 0.502008   |
| AverageReturn           | 1.92e+03   |
| Entropy                 | 2.17255    |
| EnvExecTime             | 2.4        |
| ExplainedVariance       | 0.449      |
| Iteration               | 363        |
| ItrTime                 | 14.7       |
| LossAfter               | 0.128769   |
| LossBefore              | 0.150285   |
| MaxReturn               | 2.98e+03   |
| MeanKL                  | 0.00986998 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.05e+03   |
| NumTrajs                | 10         |
| Perplexity              | 8.78062    |
| PolicyExecTime          | 0.604      |
| ProcessExecTime         | 0.0688     |
| StdReturn               | 747        |
| Time                    | 4.89e+03   |
| dLoss                   | 0.0215157  |
----------------------------------------
itr #364 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 364...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5300, #subsample_inputs: 5300
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.632      |
| AbsLearnSignalNew       | 0.632      |
| AbsLearningOld          | 0.632      |
| AverageDiscountedReturn | 254        |
| AveragePhiLoss          | 38.5988    |
| AveragePolicyStd        | 0.503524   |
| AverageReturn           | 1.61e+03   |
| Entropy                 | 2.18003    |
| EnvExecTime             | 2.06       |
| ExplainedVariance       | 0.805      |
| Iteration               | 364        |
| ItrTime                 | 13.3       |
| LossAfter               | -0.0858945 |
| LossBefore              | -0.0604327 |
| MaxReturn               | 3e+03      |
| MeanKL                  | 0.00649925 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 829        |
| NumTrajs                | 11         |
| Perplexity              | 8.84653    |
| PolicyExecTime          | 0.521      |
| ProcessExecTime         | 0.0603     |
| StdReturn               | 613        |
| Time                    | 4.91e+03   |
| dLoss                   | 0.0254617  |
----------------------------------------
itr #365 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 365...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5284, #subsample_inputs: 5284
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.664      |
| AbsLearnSignalNew       | 0.664      |
| AbsLearningOld          | 0.664      |
| AverageDiscountedReturn | 254        |
| AveragePhiLoss          | 36.5378    |
| AveragePolicyStd        | 0.503998   |
| AverageReturn           | 1.93e+03   |
| Entropy                 | 2.18381    |
| EnvExecTime             | 2.3        |
| ExplainedVariance       | 0.787      |
| Iteration               | 365        |
| ItrTime                 | 13.6       |
| LossAfter               | 1.15272    |
| LossBefore              | 1.17784    |
| MaxReturn               | 3.26e+03   |
| MeanKL                  | 0.00646314 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.1e+03    |
| NumTrajs                | 9          |
| Perplexity              | 8.88007    |
| PolicyExecTime          | 0.583      |
| ProcessExecTime         | 0.0654     |
| StdReturn               | 742        |
| Time                    | 4.92e+03   |
| dLoss                   | 0.0251285  |
----------------------------------------
itr #366 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 366...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5734, #subsample_inputs: 5734
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.662      |
| AbsLearnSignalNew       | 0.662      |
| AbsLearningOld          | 0.662      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 38.1983    |
| AveragePolicyStd        | 0.503402   |
| AverageReturn           | 1.99e+03   |
| Entropy                 | 2.18157    |
| EnvExecTime             | 2.3        |
| ExplainedVariance       | 0.596      |
| Iteration               | 366        |
| ItrTime                 | 14.2       |
| LossAfter               | -0.500456  |
| LossBefore              | -0.476727  |
| MaxReturn               | 3.39e+03   |
| MeanKL                  | 0.00657002 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 253        |
| NumTrajs                | 9          |
| Perplexity              | 8.86022    |
| PolicyExecTime          | 0.581      |
| ProcessExecTime         | 0.0672     |
| StdReturn               | 968        |
| Time                    | 4.93e+03   |
| dLoss                   | 0.0237293  |
----------------------------------------
itr #367 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 367...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5113, #subsample_inputs: 5113
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.737     |
| AbsLearnSignalNew       | 0.737     |
| AbsLearningOld          | 0.737     |
| AverageDiscountedReturn | 253       |
| AveragePhiLoss          | 33.7774   |
| AveragePolicyStd        | 0.504201  |
| AverageReturn           | 1.64e+03  |
| Entropy                 | 2.18662   |
| EnvExecTime             | 2.22      |
| ExplainedVariance       | 0.875     |
| Iteration               | 367       |
| ItrTime                 | 13.2      |
| LossAfter               | -0.353698 |
| LossBefore              | -0.331722 |
| MaxReturn               | 2.95e+03  |
| MeanKL                  | 0.0064295 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.08e+03  |
| NumTrajs                | 10        |
| Perplexity              | 8.90507   |
| PolicyExecTime          | 0.567     |
| ProcessExecTime         | 0.0623    |
| StdReturn               | 669       |
| Time                    | 4.95e+03  |
| dLoss                   | 0.0219766 |
---------------------------------------
itr #368 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 368...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5121, #subsample_inputs: 5121
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.745      |
| AbsLearnSignalNew       | 0.745      |
| AbsLearningOld          | 0.745      |
| AverageDiscountedReturn | 254        |
| AveragePhiLoss          | 37.452     |
| AveragePolicyStd        | 0.502984   |
| AverageReturn           | 1.67e+03   |
| Entropy                 | 2.1798     |
| EnvExecTime             | 2.4        |
| ExplainedVariance       | 0.887      |
| Iteration               | 368        |
| ItrTime                 | 13.5       |
| LossAfter               | 0.458649   |
| LossBefore              | 0.479251   |
| MaxReturn               | 3.18e+03   |
| MeanKL                  | 0.00654854 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.06e+03   |
| NumTrajs                | 10         |
| Perplexity              | 8.84452    |
| PolicyExecTime          | 0.588      |
| ProcessExecTime         | 0.068      |
| StdReturn               | 721        |
| Time                    | 4.96e+03   |
| dLoss                   | 0.0206023  |
----------------------------------------
itr #369 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 369...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5090, #subsample_inputs: 5090
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.606      |
| AbsLearnSignalNew       | 0.606      |
| AbsLearningOld          | 0.606      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 45.1596    |
| AveragePolicyStd        | 0.502557   |
| AverageReturn           | 1.75e+03   |
| Entropy                 | 2.17671    |
| EnvExecTime             | 1.86       |
| ExplainedVariance       | 0.7        |
| Iteration               | 369        |
| ItrTime                 | 12.8       |
| LossAfter               | 0.797882   |
| LossBefore              | 0.823253   |
| MaxReturn               | 3.17e+03   |
| MeanKL                  | 0.00645479 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 247        |
| NumTrajs                | 10         |
| Perplexity              | 8.81727    |
| PolicyExecTime          | 0.472      |
| ProcessExecTime         | 0.0552     |
| StdReturn               | 768        |
| Time                    | 4.97e+03   |
| dLoss                   | 0.0253716  |
----------------------------------------
itr #370 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 370...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5650, #subsample_inputs: 5650
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.652      |
| AbsLearnSignalNew       | 0.652      |
| AbsLearningOld          | 0.653      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 36.8667    |
| AveragePolicyStd        | 0.501218   |
| AverageReturn           | 2.06e+03   |
| Entropy                 | 2.1698     |
| EnvExecTime             | 2.5        |
| ExplainedVariance       | 0.508      |
| Iteration               | 370        |
| ItrTime                 | 14.4       |
| LossAfter               | -0.270466  |
| LossBefore              | -0.249189  |
| MaxReturn               | 2.95e+03   |
| MeanKL                  | 0.00956319 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 972        |
| NumTrajs                | 9          |
| Perplexity              | 8.75653    |
| PolicyExecTime          | 0.623      |
| ProcessExecTime         | 0.0724     |
| StdReturn               | 579        |
| Time                    | 4.99e+03   |
| dLoss                   | 0.0212769  |
----------------------------------------
itr #371 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 371...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5462, #subsample_inputs: 5462
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.717      |
| AbsLearnSignalNew       | 0.717      |
| AbsLearningOld          | 0.717      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 37.9297    |
| AveragePolicyStd        | 0.503914   |
| AverageReturn           | 2.23e+03   |
| Entropy                 | 2.18571    |
| EnvExecTime             | 2.25       |
| ExplainedVariance       | 0.823      |
| Iteration               | 371        |
| ItrTime                 | 13.8       |
| LossAfter               | -0.0910788 |
| LossBefore              | -0.0669051 |
| MaxReturn               | 3.12e+03   |
| MeanKL                  | 0.00654867 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.23e+03   |
| NumTrajs                | 8          |
| Perplexity              | 8.89694    |
| PolicyExecTime          | 0.574      |
| ProcessExecTime         | 0.064      |
| StdReturn               | 724        |
| Time                    | 5e+03      |
| dLoss                   | 0.0241737  |
----------------------------------------
itr #372 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 372...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5497, #subsample_inputs: 5497
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.688      |
| AbsLearnSignalNew       | 0.688      |
| AbsLearningOld          | 0.688      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 36.8205    |
| AveragePolicyStd        | 0.504745   |
| AverageReturn           | 2.52e+03   |
| Entropy                 | 2.18818    |
| EnvExecTime             | 2.28       |
| ExplainedVariance       | 0.791      |
| Iteration               | 372        |
| ItrTime                 | 13.8       |
| LossAfter               | -0.776283  |
| LossBefore              | -0.740091  |
| MaxReturn               | 3.27e+03   |
| MeanKL                  | 0.00998003 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.6e+03    |
| NumTrajs                | 7          |
| Perplexity              | 8.91901    |
| PolicyExecTime          | 0.568      |
| ProcessExecTime         | 0.0658     |
| StdReturn               | 498        |
| Time                    | 5.02e+03   |
| dLoss                   | 0.0361918  |
----------------------------------------
itr #373 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 373...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5044, #subsample_inputs: 5044
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.685      |
| AbsLearnSignalNew       | 0.685      |
| AbsLearningOld          | 0.685      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 41.5406    |
| AveragePolicyStd        | 0.504614   |
| AverageReturn           | 2.09e+03   |
| Entropy                 | 2.18782    |
| EnvExecTime             | 2.02       |
| ExplainedVariance       | 0.814      |
| Iteration               | 373        |
| ItrTime                 | 12.9       |
| LossAfter               | 0.658178   |
| LossBefore              | 0.702468   |
| MaxReturn               | 3.23e+03   |
| MeanKL                  | 0.00996575 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.04e+03   |
| NumTrajs                | 8          |
| Perplexity              | 8.91579    |
| PolicyExecTime          | 0.506      |
| ProcessExecTime         | 0.0589     |
| StdReturn               | 779        |
| Time                    | 5.03e+03   |
| dLoss                   | 0.0442905  |
----------------------------------------
itr #374 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 374...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5489, #subsample_inputs: 5489
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.684      |
| AbsLearnSignalNew       | 0.684      |
| AbsLearningOld          | 0.684      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 34.1332    |
| AveragePolicyStd        | 0.503534   |
| AverageReturn           | 2.76e+03   |
| Entropy                 | 2.18212    |
| EnvExecTime             | 2.38       |
| ExplainedVariance       | 0.715      |
| Iteration               | 374        |
| ItrTime                 | 14         |
| LossAfter               | -0.508984  |
| LossBefore              | -0.487116  |
| MaxReturn               | 3.06e+03   |
| MeanKL                  | 0.00644307 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.72e+03   |
| NumTrajs                | 6          |
| Perplexity              | 8.86509    |
| PolicyExecTime          | 0.602      |
| ProcessExecTime         | 0.0685     |
| StdReturn               | 469        |
| Time                    | 5.04e+03   |
| dLoss                   | 0.0218687  |
----------------------------------------
itr #375 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 375...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5263, #subsample_inputs: 5263
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.542      |
| AbsLearnSignalNew       | 0.542      |
| AbsLearningOld          | 0.542      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 32.1967    |
| AveragePolicyStd        | 0.504612   |
| AverageReturn           | 2.37e+03   |
| Entropy                 | 2.18824    |
| EnvExecTime             | 2.28       |
| ExplainedVariance       | 0.759      |
| Iteration               | 375        |
| ItrTime                 | 13.5       |
| LossAfter               | -1.21228   |
| LossBefore              | -1.19175   |
| MaxReturn               | 3.27e+03   |
| MeanKL                  | 0.00995219 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.09e+03   |
| NumTrajs                | 7          |
| Perplexity              | 8.91952    |
| PolicyExecTime          | 0.571      |
| ProcessExecTime         | 0.0663     |
| StdReturn               | 849        |
| Time                    | 5.06e+03   |
| dLoss                   | 0.0205239  |
----------------------------------------
itr #376 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 376...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5844, #subsample_inputs: 5844
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.635      |
| AbsLearnSignalNew       | 0.635      |
| AbsLearningOld          | 0.635      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 38.588     |
| AveragePolicyStd        | 0.502727   |
| AverageReturn           | 2.08e+03   |
| Entropy                 | 2.17705    |
| EnvExecTime             | 2.41       |
| ExplainedVariance       | 0.775      |
| Iteration               | 376        |
| ItrTime                 | 14.5       |
| LossAfter               | 0.122185   |
| LossBefore              | 0.148937   |
| MaxReturn               | 3.29e+03   |
| MeanKL                  | 0.00989248 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.19e+03   |
| NumTrajs                | 9          |
| Perplexity              | 8.82023    |
| PolicyExecTime          | 0.604      |
| ProcessExecTime         | 0.0701     |
| StdReturn               | 706        |
| Time                    | 5.07e+03   |
| dLoss                   | 0.0267518  |
----------------------------------------
itr #377 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 377...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5050, #subsample_inputs: 5050
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.565      |
| AbsLearnSignalNew       | 0.565      |
| AbsLearningOld          | 0.565      |
| AverageDiscountedReturn | 235        |
| AveragePhiLoss          | 31.7335    |
| AveragePolicyStd        | 0.504035   |
| AverageReturn           | 1.78e+03   |
| Entropy                 | 2.18434    |
| EnvExecTime             | 2.1        |
| ExplainedVariance       | 0.748      |
| Iteration               | 377        |
| ItrTime                 | 13         |
| LossAfter               | 0.344325   |
| LossBefore              | 0.366892   |
| MaxReturn               | 3.19e+03   |
| MeanKL                  | 0.00646301 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 161        |
| NumTrajs                | 9          |
| Perplexity              | 8.88474    |
| PolicyExecTime          | 0.52       |
| ProcessExecTime         | 0.0643     |
| StdReturn               | 944        |
| Time                    | 5.08e+03   |
| dLoss                   | 0.0225674  |
----------------------------------------
itr #378 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 378...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5600, #subsample_inputs: 5600
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.568      |
| AbsLearnSignalNew       | 0.568      |
| AbsLearningOld          | 0.568      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 32.4864    |
| AveragePolicyStd        | 0.503991   |
| AverageReturn           | 1.8e+03    |
| Entropy                 | 2.18433    |
| EnvExecTime             | 2.17       |
| ExplainedVariance       | 0.759      |
| Iteration               | 378        |
| ItrTime                 | 14         |
| LossAfter               | -1.01461   |
| LossBefore              | -0.995178  |
| MaxReturn               | 3.1e+03    |
| MeanKL                  | 0.00652084 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 245        |
| NumTrajs                | 10         |
| Perplexity              | 8.88468    |
| PolicyExecTime          | 0.559      |
| ProcessExecTime         | 0.0634     |
| StdReturn               | 812        |
| Time                    | 5.1e+03    |
| dLoss                   | 0.0194317  |
----------------------------------------
itr #379 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 379...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5598, #subsample_inputs: 5598
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.701      |
| AbsLearnSignalNew       | 0.701      |
| AbsLearningOld          | 0.701      |
| AverageDiscountedReturn | 255        |
| AveragePhiLoss          | 36.8582    |
| AveragePolicyStd        | 0.504755   |
| AverageReturn           | 2.05e+03   |
| Entropy                 | 2.18811    |
| EnvExecTime             | 2.44       |
| ExplainedVariance       | 0.9        |
| Iteration               | 379        |
| ItrTime                 | 14.2       |
| LossAfter               | 0.252807   |
| LossBefore              | 0.279815   |
| MaxReturn               | 3.21e+03   |
| MeanKL                  | 0.00650161 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.02e+03   |
| NumTrajs                | 9          |
| Perplexity              | 8.91833    |
| PolicyExecTime          | 0.611      |
| ProcessExecTime         | 0.0698     |
| StdReturn               | 755        |
| Time                    | 5.11e+03   |
| dLoss                   | 0.0270081  |
----------------------------------------
itr #380 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 380...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5033, #subsample_inputs: 5033
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.686      |
| AbsLearnSignalNew       | 0.686      |
| AbsLearningOld          | 0.686      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 29.9841    |
| AveragePolicyStd        | 0.504571   |
| AverageReturn           | 1.66e+03   |
| Entropy                 | 2.18762    |
| EnvExecTime             | 2.07       |
| ExplainedVariance       | 0.872      |
| Iteration               | 380        |
| ItrTime                 | 12.9       |
| LossAfter               | -0.485294  |
| LossBefore              | -0.461863  |
| MaxReturn               | 2.88e+03   |
| MeanKL                  | 0.00644056 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1e+03      |
| NumTrajs                | 10         |
| Perplexity              | 8.91396    |
| PolicyExecTime          | 0.525      |
| ProcessExecTime         | 0.0601     |
| StdReturn               | 585        |
| Time                    | 5.13e+03   |
| dLoss                   | 0.0234309  |
----------------------------------------
itr #381 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 381...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5201, #subsample_inputs: 5201
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.765      |
| AbsLearnSignalNew       | 0.765      |
| AbsLearningOld          | 0.765      |
| AverageDiscountedReturn | 254        |
| AveragePhiLoss          | 37.3593    |
| AveragePolicyStd        | 0.505012   |
| AverageReturn           | 2.1e+03    |
| Entropy                 | 2.1895     |
| EnvExecTime             | 1.92       |
| ExplainedVariance       | 0.85       |
| Iteration               | 381        |
| ItrTime                 | 13         |
| LossAfter               | -0.228167  |
| LossBefore              | -0.204871  |
| MaxReturn               | 3.33e+03   |
| MeanKL                  | 0.00656385 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.36e+03   |
| NumTrajs                | 8          |
| Perplexity              | 8.93073    |
| PolicyExecTime          | 0.496      |
| ProcessExecTime         | 0.0576     |
| StdReturn               | 777        |
| Time                    | 5.14e+03   |
| dLoss                   | 0.0232961  |
----------------------------------------
itr #382 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 382...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5059, #subsample_inputs: 5059
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.739      |
| AbsLearnSignalNew       | 0.739      |
| AbsLearningOld          | 0.739      |
| AverageDiscountedReturn | 254        |
| AveragePhiLoss          | 36.7541    |
| AveragePolicyStd        | 0.50355    |
| AverageReturn           | 2.1e+03    |
| Entropy                 | 2.18052    |
| EnvExecTime             | 2.17       |
| ExplainedVariance       | 0.828      |
| Iteration               | 382        |
| ItrTime                 | 13.1       |
| LossAfter               | -1.05614   |
| LossBefore              | -1.03171   |
| MaxReturn               | 3.09e+03   |
| MeanKL                  | 0.00647301 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 958        |
| NumTrajs                | 8          |
| Perplexity              | 8.85088    |
| PolicyExecTime          | 0.539      |
| ProcessExecTime         | 0.0631     |
| StdReturn               | 703        |
| Time                    | 5.15e+03   |
| dLoss                   | 0.0244284  |
----------------------------------------
itr #383 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 383...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5088, #subsample_inputs: 5088
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.733      |
| AbsLearnSignalNew       | 0.733      |
| AbsLearningOld          | 0.733      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 35.7073    |
| AveragePolicyStd        | 0.503657   |
| AverageReturn           | 1.69e+03   |
| Entropy                 | 2.18137    |
| EnvExecTime             | 2.1        |
| ExplainedVariance       | 0.825      |
| Iteration               | 383        |
| ItrTime                 | 13         |
| LossAfter               | 0.0435141  |
| LossBefore              | 0.0740336  |
| MaxReturn               | 2.71e+03   |
| MeanKL                  | 0.00989589 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 961        |
| NumTrajs                | 10         |
| Perplexity              | 8.85844    |
| PolicyExecTime          | 0.528      |
| ProcessExecTime         | 0.0623     |
| StdReturn               | 601        |
| Time                    | 5.16e+03   |
| dLoss                   | 0.0305195  |
----------------------------------------
itr #384 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 384...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5853, #subsample_inputs: 5853
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.651      |
| AbsLearnSignalNew       | 0.651      |
| AbsLearningOld          | 0.651      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 34.1559    |
| AveragePolicyStd        | 0.504748   |
| AverageReturn           | 1.88e+03   |
| Entropy                 | 2.1897     |
| EnvExecTime             | 2.21       |
| ExplainedVariance       | 0.697      |
| Iteration               | 384        |
| ItrTime                 | 14.3       |
| LossAfter               | 0.669738   |
| LossBefore              | 0.687584   |
| MaxReturn               | 3.17e+03   |
| MeanKL                  | 0.00642767 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 947        |
| NumTrajs                | 10         |
| Perplexity              | 8.93251    |
| PolicyExecTime          | 0.56       |
| ProcessExecTime         | 0.0662     |
| StdReturn               | 733        |
| Time                    | 5.18e+03   |
| dLoss                   | 0.0178457  |
----------------------------------------
itr #385 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 385...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5234, #subsample_inputs: 5234
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.754      |
| AbsLearnSignalNew       | 0.754      |
| AbsLearningOld          | 0.754      |
| AverageDiscountedReturn | 254        |
| AveragePhiLoss          | 34.1732    |
| AveragePolicyStd        | 0.504592   |
| AverageReturn           | 1.45e+03   |
| Entropy                 | 2.18881    |
| EnvExecTime             | 2.21       |
| ExplainedVariance       | 0.886      |
| Iteration               | 385        |
| ItrTime                 | 13.4       |
| LossAfter               | 0.234109   |
| LossBefore              | 0.257083   |
| MaxReturn               | 3.04e+03   |
| MeanKL                  | 0.00641147 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 951        |
| NumTrajs                | 12         |
| Perplexity              | 8.92461    |
| PolicyExecTime          | 0.567      |
| ProcessExecTime         | 0.0624     |
| StdReturn               | 559        |
| Time                    | 5.19e+03   |
| dLoss                   | 0.0229737  |
----------------------------------------
itr #386 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 386...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5169, #subsample_inputs: 5169
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.708      |
| AbsLearnSignalNew       | 0.708      |
| AbsLearningOld          | 0.708      |
| AverageDiscountedReturn | 255        |
| AveragePhiLoss          | 35.894     |
| AveragePolicyStd        | 0.502626   |
| AverageReturn           | 1.91e+03   |
| Entropy                 | 2.17714    |
| EnvExecTime             | 2.06       |
| ExplainedVariance       | 0.823      |
| Iteration               | 386        |
| ItrTime                 | 13.2       |
| LossAfter               | -0.544452  |
| LossBefore              | -0.508282  |
| MaxReturn               | 3.18e+03   |
| MeanKL                  | 0.00987746 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.17e+03   |
| NumTrajs                | 9          |
| Perplexity              | 8.82105    |
| PolicyExecTime          | 0.523      |
| ProcessExecTime         | 0.0617     |
| StdReturn               | 758        |
| Time                    | 5.21e+03   |
| dLoss                   | 0.0361701  |
----------------------------------------
itr #387 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 387...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5181, #subsample_inputs: 5181
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.715      |
| AbsLearnSignalNew       | 0.715      |
| AbsLearningOld          | 0.715      |
| AverageDiscountedReturn | 255        |
| AveragePhiLoss          | 37.2942    |
| AveragePolicyStd        | 0.500885   |
| AverageReturn           | 1.91e+03   |
| Entropy                 | 2.16607    |
| EnvExecTime             | 2.31       |
| ExplainedVariance       | 0.861      |
| Iteration               | 387        |
| ItrTime                 | 13.4       |
| LossAfter               | 0.217782   |
| LossBefore              | 0.245013   |
| MaxReturn               | 2.9e+03    |
| MeanKL                  | 0.00991902 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 971        |
| NumTrajs                | 9          |
| Perplexity              | 8.72397    |
| PolicyExecTime          | 0.575      |
| ProcessExecTime         | 0.067      |
| StdReturn               | 627        |
| Time                    | 5.22e+03   |
| dLoss                   | 0.0272316  |
----------------------------------------
itr #388 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 388...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5070, #subsample_inputs: 5070
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.65       |
| AbsLearnSignalNew       | 0.65       |
| AbsLearningOld          | 0.65       |
| AverageDiscountedReturn | 255        |
| AveragePhiLoss          | 40.7109    |
| AveragePolicyStd        | 0.502648   |
| AverageReturn           | 2.16e+03   |
| Entropy                 | 2.17596    |
| EnvExecTime             | 2.06       |
| ExplainedVariance       | 0.794      |
| Iteration               | 388        |
| ItrTime                 | 13         |
| LossAfter               | 1.76806    |
| LossBefore              | 1.81144    |
| MaxReturn               | 3.44e+03   |
| MeanKL                  | 0.00953581 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 989        |
| NumTrajs                | 8          |
| Perplexity              | 8.81067    |
| PolicyExecTime          | 0.521      |
| ProcessExecTime         | 0.0586     |
| StdReturn               | 1.02e+03   |
| Time                    | 5.23e+03   |
| dLoss                   | 0.0433779  |
----------------------------------------
itr #389 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 389...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5202, #subsample_inputs: 5202
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.68       |
| AbsLearnSignalNew       | 0.68       |
| AbsLearningOld          | 0.68       |
| AverageDiscountedReturn | 255        |
| AveragePhiLoss          | 36.3232    |
| AveragePolicyStd        | 0.503144   |
| AverageReturn           | 1.78e+03   |
| Entropy                 | 2.17923    |
| EnvExecTime             | 1.86       |
| ExplainedVariance       | 0.875      |
| Iteration               | 389        |
| ItrTime                 | 12.9       |
| LossAfter               | -0.144445  |
| LossBefore              | -0.118973  |
| MaxReturn               | 3.43e+03   |
| MeanKL                  | 0.00643641 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1e+03      |
| NumTrajs                | 10         |
| Perplexity              | 8.83946    |
| PolicyExecTime          | 0.476      |
| ProcessExecTime         | 0.0561     |
| StdReturn               | 700        |
| Time                    | 5.25e+03   |
| dLoss                   | 0.025472   |
----------------------------------------
itr #390 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 390...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5087, #subsample_inputs: 5087
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.634      |
| AbsLearnSignalNew       | 0.634      |
| AbsLearningOld          | 0.634      |
| AverageDiscountedReturn | 257        |
| AveragePhiLoss          | 36.9867    |
| AveragePolicyStd        | 0.501525   |
| AverageReturn           | 2.16e+03   |
| Entropy                 | 2.17003    |
| EnvExecTime             | 2.06       |
| ExplainedVariance       | 0.738      |
| Iteration               | 390        |
| ItrTime                 | 13         |
| LossAfter               | -1.27947   |
| LossBefore              | -1.25514   |
| MaxReturn               | 3.42e+03   |
| MeanKL                  | 0.00985684 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 954        |
| NumTrajs                | 8          |
| Perplexity              | 8.75851    |
| PolicyExecTime          | 0.519      |
| ProcessExecTime         | 0.0588     |
| StdReturn               | 785        |
| Time                    | 5.26e+03   |
| dLoss                   | 0.0243297  |
----------------------------------------
itr #391 | 
Mem: 732.375000
Obtaining samples...
Obtaining samples for iteration 391...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5963, #subsample_inputs: 5963
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.722      |
| AbsLearnSignalNew       | 0.722      |
| AbsLearningOld          | 0.722      |
| AverageDiscountedReturn | 254        |
| AveragePhiLoss          | 34.3611    |
| AveragePolicyStd        | 0.501957   |
| AverageReturn           | 2.25e+03   |
| Entropy                 | 2.17126    |
| EnvExecTime             | 2.9        |
| ExplainedVariance       | 0.867      |
| Iteration               | 391        |
| ItrTime                 | 15.5       |
| LossAfter               | -0.114241  |
| LossBefore              | -0.0746737 |
| MaxReturn               | 3.37e+03   |
| MeanKL                  | 0.00958019 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.29e+03   |
| NumTrajs                | 9          |
| Perplexity              | 8.76929    |
| PolicyExecTime          | 0.719      |
| ProcessExecTime         | 0.0838     |
| StdReturn               | 686        |
| Time                    | 5.27e+03   |
| dLoss                   | 0.0395671  |
----------------------------------------
itr #392 | 
Mem: 732.808594
Obtaining samples...
Obtaining samples for iteration 392...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5858, #subsample_inputs: 5858
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.712      |
| AbsLearnSignalNew       | 0.712      |
| AbsLearningOld          | 0.712      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 34.6436    |
| AveragePolicyStd        | 0.503545   |
| AverageReturn           | 2.14e+03   |
| Entropy                 | 2.18181    |
| EnvExecTime             | 2.19       |
| ExplainedVariance       | 0.792      |
| Iteration               | 392        |
| ItrTime                 | 14.9       |
| LossAfter               | 0.368242   |
| LossBefore              | 0.386907   |
| MaxReturn               | 3.39e+03   |
| MeanKL                  | 0.00643767 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.27e+03   |
| NumTrajs                | 9          |
| Perplexity              | 8.86237    |
| PolicyExecTime          | 0.558      |
| ProcessExecTime         | 0.0645     |
| StdReturn               | 698        |
| Time                    | 5.29e+03   |
| dLoss                   | 0.0186644  |
----------------------------------------
itr #393 | 
Mem: 734.351562
Obtaining samples...
Obtaining samples for iteration 393...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5271, #subsample_inputs: 5271
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.717      |
| AbsLearnSignalNew       | 0.717      |
| AbsLearningOld          | 0.717      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 34.1445    |
| AveragePolicyStd        | 0.503908   |
| AverageReturn           | 2.13e+03   |
| Entropy                 | 2.18422    |
| EnvExecTime             | 2.31       |
| ExplainedVariance       | 0.885      |
| Iteration               | 393        |
| ItrTime                 | 13.7       |
| LossAfter               | -0.165295  |
| LossBefore              | -0.137248  |
| MaxReturn               | 3.3e+03    |
| MeanKL                  | 0.00999922 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.12e+03   |
| NumTrajs                | 8          |
| Perplexity              | 8.88371    |
| PolicyExecTime          | 0.586      |
| ProcessExecTime         | 0.0665     |
| StdReturn               | 795        |
| Time                    | 5.3e+03    |
| dLoss                   | 0.0280469  |
----------------------------------------
itr #394 | 
Mem: 734.386719
Obtaining samples...
Obtaining samples for iteration 394...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5016, #subsample_inputs: 5016
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.76       |
| AbsLearnSignalNew       | 0.76       |
| AbsLearningOld          | 0.76       |
| AverageDiscountedReturn | 256        |
| AveragePhiLoss          | 34.3535    |
| AveragePolicyStd        | 0.505541   |
| AverageReturn           | 1.86e+03   |
| Entropy                 | 2.19421    |
| EnvExecTime             | 2.18       |
| ExplainedVariance       | 0.853      |
| Iteration               | 394        |
| ItrTime                 | 13         |
| LossAfter               | 0.592475   |
| LossBefore              | 0.616661   |
| MaxReturn               | 2.95e+03   |
| MeanKL                  | 0.00653309 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.25e+03   |
| NumTrajs                | 9          |
| Perplexity              | 8.97292    |
| PolicyExecTime          | 0.548      |
| ProcessExecTime         | 0.0634     |
| StdReturn               | 527        |
| Time                    | 5.32e+03   |
| dLoss                   | 0.0241863  |
----------------------------------------
itr #395 | 
Mem: 734.386719
Obtaining samples...
Obtaining samples for iteration 395...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5195, #subsample_inputs: 5195
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.742      |
| AbsLearnSignalNew       | 0.742      |
| AbsLearningOld          | 0.742      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 33.1658    |
| AveragePolicyStd        | 0.503392   |
| AverageReturn           | 2.43e+03   |
| Entropy                 | 2.18228    |
| EnvExecTime             | 2.03       |
| ExplainedVariance       | 0.881      |
| Iteration               | 395        |
| ItrTime                 | 13.1       |
| LossAfter               | -0.374851  |
| LossBefore              | -0.344719  |
| MaxReturn               | 3.05e+03   |
| MeanKL                  | 0.00997557 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.42e+03   |
| NumTrajs                | 7          |
| Perplexity              | 8.86653    |
| PolicyExecTime          | 0.511      |
| ProcessExecTime         | 0.0612     |
| StdReturn               | 558        |
| Time                    | 5.33e+03   |
| dLoss                   | 0.0301319  |
----------------------------------------
itr #396 | 
Mem: 734.386719
Obtaining samples...
Obtaining samples for iteration 396...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5318, #subsample_inputs: 5318
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.712      |
| AbsLearnSignalNew       | 0.712      |
| AbsLearningOld          | 0.712      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 32.9326    |
| AveragePolicyStd        | 0.503909   |
| AverageReturn           | 2.13e+03   |
| Entropy                 | 2.18362    |
| EnvExecTime             | 2.36       |
| ExplainedVariance       | 0.837      |
| Iteration               | 396        |
| ItrTime                 | 13.7       |
| LossAfter               | -0.0838902 |
| LossBefore              | -0.0619124 |
| MaxReturn               | 3.21e+03   |
| MeanKL                  | 0.00651991 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.22e+03   |
| NumTrajs                | 8          |
| Perplexity              | 8.87839    |
| PolicyExecTime          | 0.589      |
| ProcessExecTime         | 0.067      |
| StdReturn               | 791        |
| Time                    | 5.34e+03   |
| dLoss                   | 0.0219778  |
----------------------------------------
itr #397 | 
Mem: 734.636719
Obtaining samples...
Obtaining samples for iteration 397...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5755, #subsample_inputs: 5755
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
------------------------------------------
| AbsLearnSignal          | 0.616        |
| AbsLearnSignalNew       | 0.616        |
| AbsLearningOld          | 0.616        |
| AverageDiscountedReturn | 252          |
| AveragePhiLoss          | 36.8544      |
| AveragePolicyStd        | 0.503093     |
| AverageReturn           | 2.1e+03      |
| Entropy                 | 2.17871      |
| EnvExecTime             | 2.17         |
| ExplainedVariance       | 0.803        |
| Iteration               | 397          |
| ItrTime                 | 14.1         |
| LossAfter               | -0.000811556 |
| LossBefore              | 0.0270494    |
| MaxReturn               | 3.12e+03     |
| MeanKL                  | 0.0098807    |
| MeanKLBefore            | 0.0          |
| MinReturn               | 1.09e+03     |
| NumTrajs                | 9            |
| Perplexity              | 8.83489      |
| PolicyExecTime          | 0.557        |
| ProcessExecTime         | 0.0633       |
| StdReturn               | 770          |
| Time                    | 5.36e+03     |
| dLoss                   | 0.0278609    |
------------------------------------------
itr #398 | 
Mem: 734.636719
Obtaining samples...
Obtaining samples for iteration 398...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5630, #subsample_inputs: 5630
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.731      |
| AbsLearnSignalNew       | 0.731      |
| AbsLearningOld          | 0.731      |
| AverageDiscountedReturn | 254        |
| AveragePhiLoss          | 33.9076    |
| AveragePolicyStd        | 0.503129   |
| AverageReturn           | 1.9e+03    |
| Entropy                 | 2.17962    |
| EnvExecTime             | 2.45       |
| ExplainedVariance       | 0.896      |
| Iteration               | 398        |
| ItrTime                 | 14.2       |
| LossAfter               | 0.330497   |
| LossBefore              | 0.360972   |
| MaxReturn               | 3.35e+03   |
| MeanKL                  | 0.00980517 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 942        |
| NumTrajs                | 10         |
| Perplexity              | 8.84299    |
| PolicyExecTime          | 0.616      |
| ProcessExecTime         | 0.072      |
| StdReturn               | 682        |
| Time                    | 5.37e+03   |
| dLoss                   | 0.0304752  |
----------------------------------------
itr #399 | 
Mem: 734.636719
Obtaining samples...
Obtaining samples for iteration 399...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5856, #subsample_inputs: 5856
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.767      |
| AbsLearnSignalNew       | 0.767      |
| AbsLearningOld          | 0.767      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 36.3527    |
| AveragePolicyStd        | 0.503656   |
| AverageReturn           | 2.1e+03    |
| Entropy                 | 2.18378    |
| EnvExecTime             | 2.37       |
| ExplainedVariance       | 0.841      |
| Iteration               | 399        |
| ItrTime                 | 14.4       |
| LossAfter               | -0.0142667 |
| LossBefore              | 0.00592325 |
| MaxReturn               | 3.1e+03    |
| MeanKL                  | 0.00647167 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.24e+03   |
| NumTrajs                | 9          |
| Perplexity              | 8.87985    |
| PolicyExecTime          | 0.6        |
| ProcessExecTime         | 0.0682     |
| StdReturn               | 720        |
| Time                    | 5.39e+03   |
| dLoss                   | 0.0201899  |
----------------------------------------
itr #400 | 
Mem: 734.644531
Obtaining samples...
Obtaining samples for iteration 400...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5205, #subsample_inputs: 5205
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.724     |
| AbsLearnSignalNew       | 0.724     |
| AbsLearningOld          | 0.724     |
| AverageDiscountedReturn | 250       |
| AveragePhiLoss          | 35.2955   |
| AveragePolicyStd        | 0.50321   |
| AverageReturn           | 2.02e+03  |
| Entropy                 | 2.18028   |
| EnvExecTime             | 2.28      |
| ExplainedVariance       | 0.862     |
| Iteration               | 400       |
| ItrTime                 | 13.5      |
| LossAfter               | -1.04411  |
| LossBefore              | -1.01575  |
| MaxReturn               | 2.95e+03  |
| MeanKL                  | 0.0099732 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 970       |
| NumTrajs                | 8         |
| Perplexity              | 8.84876   |
| PolicyExecTime          | 0.572     |
| ProcessExecTime         | 0.0659    |
| StdReturn               | 769       |
| Time                    | 5.4e+03   |
| dLoss                   | 0.0283552 |
---------------------------------------
itr #401 | 
Mem: 734.894531
Obtaining samples...
Obtaining samples for iteration 401...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5022, #subsample_inputs: 5022
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.753      |
| AbsLearnSignalNew       | 0.753      |
| AbsLearningOld          | 0.753      |
| AverageDiscountedReturn | 255        |
| AveragePhiLoss          | 33.7443    |
| AveragePolicyStd        | 0.502913   |
| AverageReturn           | 1.71e+03   |
| Entropy                 | 2.17769    |
| EnvExecTime             | 2.15       |
| ExplainedVariance       | 0.88       |
| Iteration               | 401        |
| ItrTime                 | 13         |
| LossAfter               | -0.581128  |
| LossBefore              | -0.550881  |
| MaxReturn               | 2.71e+03   |
| MeanKL                  | 0.00998438 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.02e+03   |
| NumTrajs                | 10         |
| Perplexity              | 8.82586    |
| PolicyExecTime          | 0.542      |
| ProcessExecTime         | 0.0628     |
| StdReturn               | 477        |
| Time                    | 5.41e+03   |
| dLoss                   | 0.0302467  |
----------------------------------------
itr #402 | 
Mem: 734.894531
Obtaining samples...
Obtaining samples for iteration 402...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5224, #subsample_inputs: 5224
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.74       |
| AbsLearnSignalNew       | 0.74       |
| AbsLearningOld          | 0.74       |
| AverageDiscountedReturn | 256        |
| AveragePhiLoss          | 33.98      |
| AveragePolicyStd        | 0.503074   |
| AverageReturn           | 1.98e+03   |
| Entropy                 | 2.17929    |
| EnvExecTime             | 1.96       |
| ExplainedVariance       | 0.897      |
| Iteration               | 402        |
| ItrTime                 | 13.2       |
| LossAfter               | 0.0260551  |
| LossBefore              | 0.0500766  |
| MaxReturn               | 3.14e+03   |
| MeanKL                  | 0.00643879 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.21e+03   |
| NumTrajs                | 9          |
| Perplexity              | 8.84006    |
| PolicyExecTime          | 0.499      |
| ProcessExecTime         | 0.0573     |
| StdReturn               | 561        |
| Time                    | 5.43e+03   |
| dLoss                   | 0.0240216  |
----------------------------------------
itr #403 | 
Mem: 734.894531
Obtaining samples...
Obtaining samples for iteration 403...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5247, #subsample_inputs: 5247
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.546      |
| AbsLearnSignalNew       | 0.546      |
| AbsLearningOld          | 0.546      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 36.4493    |
| AveragePolicyStd        | 0.50272    |
| AverageReturn           | 2.17e+03   |
| Entropy                 | 2.17551    |
| EnvExecTime             | 2.29       |
| ExplainedVariance       | 0.533      |
| Iteration               | 403        |
| ItrTime                 | 13.5       |
| LossAfter               | -0.308158  |
| LossBefore              | -0.288352  |
| MaxReturn               | 3.27e+03   |
| MeanKL                  | 0.00975087 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.16e+03   |
| NumTrajs                | 8          |
| Perplexity              | 8.80668    |
| PolicyExecTime          | 0.57       |
| ProcessExecTime         | 0.0667     |
| StdReturn               | 773        |
| Time                    | 5.44e+03   |
| dLoss                   | 0.0198067  |
----------------------------------------
itr #404 | 
Mem: 734.894531
Obtaining samples...
Obtaining samples for iteration 404...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5232, #subsample_inputs: 5232
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.708      |
| AbsLearnSignalNew       | 0.708      |
| AbsLearningOld          | 0.708      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 36.0465    |
| AveragePolicyStd        | 0.501848   |
| AverageReturn           | 1.95e+03   |
| Entropy                 | 2.1694     |
| EnvExecTime             | 2.35       |
| ExplainedVariance       | 0.88       |
| Iteration               | 404        |
| ItrTime                 | 13.6       |
| LossAfter               | -1.19387   |
| LossBefore              | -1.16601   |
| MaxReturn               | 3.27e+03   |
| MeanKL                  | 0.00983243 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.23e+03   |
| NumTrajs                | 9          |
| Perplexity              | 8.75306    |
| PolicyExecTime          | 0.605      |
| ProcessExecTime         | 0.0651     |
| StdReturn               | 587        |
| Time                    | 5.45e+03   |
| dLoss                   | 0.027866   |
----------------------------------------
itr #405 | 
Mem: 734.894531
Obtaining samples...
Obtaining samples for iteration 405...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5490, #subsample_inputs: 5490
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.611      |
| AbsLearnSignalNew       | 0.611      |
| AbsLearningOld          | 0.611      |
| AverageDiscountedReturn | 254        |
| AveragePhiLoss          | 36.2446    |
| AveragePolicyStd        | 0.501598   |
| AverageReturn           | 2.07e+03   |
| Entropy                 | 2.16704    |
| EnvExecTime             | 2.41       |
| ExplainedVariance       | 0.798      |
| Iteration               | 405        |
| ItrTime                 | 14         |
| LossAfter               | -0.965578  |
| LossBefore              | -0.926665  |
| MaxReturn               | 3.35e+03   |
| MeanKL                  | 0.00948354 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.15e+03   |
| NumTrajs                | 9          |
| Perplexity              | 8.73242    |
| PolicyExecTime          | 0.611      |
| ProcessExecTime         | 0.0689     |
| StdReturn               | 777        |
| Time                    | 5.47e+03   |
| dLoss                   | 0.0389131  |
----------------------------------------
itr #406 | 
Mem: 734.894531
Obtaining samples...
Obtaining samples for iteration 406...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5033, #subsample_inputs: 5033
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.722      |
| AbsLearnSignalNew       | 0.722      |
| AbsLearningOld          | 0.722      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 36.3163    |
| AveragePolicyStd        | 0.502121   |
| AverageReturn           | 2.35e+03   |
| Entropy                 | 2.17051    |
| EnvExecTime             | 1.88       |
| ExplainedVariance       | 0.805      |
| Iteration               | 406        |
| ItrTime                 | 12.7       |
| LossAfter               | -0.093268  |
| LossBefore              | -0.0725653 |
| MaxReturn               | 3e+03      |
| MeanKL                  | 0.00652913 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.68e+03   |
| NumTrajs                | 7          |
| Perplexity              | 8.76278    |
| PolicyExecTime          | 0.477      |
| ProcessExecTime         | 0.0558     |
| StdReturn               | 500        |
| Time                    | 5.48e+03   |
| dLoss                   | 0.0207027  |
----------------------------------------
itr #407 | 
Mem: 734.894531
Obtaining samples...
Obtaining samples for iteration 407...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5214, #subsample_inputs: 5214
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.676      |
| AbsLearnSignalNew       | 0.676      |
| AbsLearningOld          | 0.676      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 32.939     |
| AveragePolicyStd        | 0.500971   |
| AverageReturn           | 2.17e+03   |
| Entropy                 | 2.16415    |
| EnvExecTime             | 2.14       |
| ExplainedVariance       | 0.754      |
| Iteration               | 407        |
| ItrTime                 | 13.2       |
| LossAfter               | -1.01981   |
| LossBefore              | -0.997655  |
| MaxReturn               | 3.13e+03   |
| MeanKL                  | 0.00643228 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.59e+03   |
| NumTrajs                | 8          |
| Perplexity              | 8.70718    |
| PolicyExecTime          | 0.54       |
| ProcessExecTime         | 0.061      |
| StdReturn               | 487        |
| Time                    | 5.49e+03   |
| dLoss                   | 0.0221548  |
----------------------------------------
itr #408 | 
Mem: 734.894531
Obtaining samples...
Obtaining samples for iteration 408...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5145, #subsample_inputs: 5145
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.507      |
| AbsLearnSignalNew       | 0.507      |
| AbsLearningOld          | 0.507      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 37.054     |
| AveragePolicyStd        | 0.499903   |
| AverageReturn           | 2.77e+03   |
| Entropy                 | 2.15757    |
| EnvExecTime             | 2.22       |
| ExplainedVariance       | 0.406      |
| Iteration               | 408        |
| ItrTime                 | 13.2       |
| LossAfter               | -1.67487   |
| LossBefore              | -1.64951   |
| MaxReturn               | 3.29e+03   |
| MeanKL                  | 0.00972166 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.52e+03   |
| NumTrajs                | 6          |
| Perplexity              | 8.65012    |
| PolicyExecTime          | 0.565      |
| ProcessExecTime         | 0.0628     |
| StdReturn               | 637        |
| Time                    | 5.51e+03   |
| dLoss                   | 0.0253594  |
----------------------------------------
itr #409 | 
Mem: 734.894531
Obtaining samples...
Obtaining samples for iteration 409...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5229, #subsample_inputs: 5229
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.553      |
| AbsLearnSignalNew       | 0.553      |
| AbsLearningOld          | 0.553      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 38.9754    |
| AveragePolicyStd        | 0.499821   |
| AverageReturn           | 2.39e+03   |
| Entropy                 | 2.15644    |
| EnvExecTime             | 2.57       |
| ExplainedVariance       | 0.672      |
| Iteration               | 409        |
| ItrTime                 | 13.8       |
| LossAfter               | 1.29364    |
| LossBefore              | 1.32315    |
| MaxReturn               | 3.13e+03   |
| MeanKL                  | 0.00644784 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.49e+03   |
| NumTrajs                | 7          |
| Perplexity              | 8.64033    |
| PolicyExecTime          | 0.63       |
| ProcessExecTime         | 0.0718     |
| StdReturn               | 629        |
| Time                    | 5.52e+03   |
| dLoss                   | 0.0295047  |
----------------------------------------
itr #410 | 
Mem: 734.894531
Obtaining samples...
Obtaining samples for iteration 410...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5787, #subsample_inputs: 5787
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.712      |
| AbsLearnSignalNew       | 0.712      |
| AbsLearningOld          | 0.712      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 39.6338    |
| AveragePolicyStd        | 0.499931   |
| AverageReturn           | 2.39e+03   |
| Entropy                 | 2.15721    |
| EnvExecTime             | 2.5        |
| ExplainedVariance       | 0.791      |
| Iteration               | 410        |
| ItrTime                 | 14.5       |
| LossAfter               | 0.00938468 |
| LossBefore              | 0.0317324  |
| MaxReturn               | 3.2e+03    |
| MeanKL                  | 0.00644861 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.7e+03    |
| NumTrajs                | 8          |
| Perplexity              | 8.64702    |
| PolicyExecTime          | 0.617      |
| ProcessExecTime         | 0.0762     |
| StdReturn               | 428        |
| Time                    | 5.54e+03   |
| dLoss                   | 0.0223477  |
----------------------------------------
itr #411 | 
Mem: 736.156250
Obtaining samples...
Obtaining samples for iteration 411...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5992, #subsample_inputs: 5992
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.693      |
| AbsLearnSignalNew       | 0.693      |
| AbsLearningOld          | 0.693      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 34.0068    |
| AveragePolicyStd        | 0.498869   |
| AverageReturn           | 2.45e+03   |
| Entropy                 | 2.1514     |
| EnvExecTime             | 2.59       |
| ExplainedVariance       | 0.754      |
| Iteration               | 411        |
| ItrTime                 | 15.1       |
| LossAfter               | 1.46009    |
| LossBefore              | 1.48529    |
| MaxReturn               | 3.22e+03   |
| MeanKL                  | 0.00942545 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.32e+03   |
| NumTrajs                | 8          |
| Perplexity              | 8.59692    |
| PolicyExecTime          | 0.658      |
| ProcessExecTime         | 0.0725     |
| StdReturn               | 561        |
| Time                    | 5.55e+03   |
| dLoss                   | 0.0251936  |
----------------------------------------
itr #412 | 
Mem: 736.156250
Obtaining samples...
Obtaining samples for iteration 412...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5757, #subsample_inputs: 5757
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.628      |
| AbsLearnSignalNew       | 0.628      |
| AbsLearningOld          | 0.628      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 41.1116    |
| AveragePolicyStd        | 0.497532   |
| AverageReturn           | 2.64e+03   |
| Entropy                 | 2.14376    |
| EnvExecTime             | 2.67       |
| ExplainedVariance       | 0.718      |
| Iteration               | 412        |
| ItrTime                 | 14.7       |
| LossAfter               | 1.25451    |
| LossBefore              | 1.27417    |
| MaxReturn               | 3.32e+03   |
| MeanKL                  | 0.00645529 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.83e+03   |
| NumTrajs                | 7          |
| Perplexity              | 8.53143    |
| PolicyExecTime          | 0.674      |
| ProcessExecTime         | 0.0761     |
| StdReturn               | 565        |
| Time                    | 5.57e+03   |
| dLoss                   | 0.0196687  |
----------------------------------------
itr #413 | 
Mem: 736.156250
Obtaining samples...
Obtaining samples for iteration 413...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5254, #subsample_inputs: 5254
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.63       |
| AbsLearnSignalNew       | 0.63       |
| AbsLearningOld          | 0.63       |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 47.1216    |
| AveragePolicyStd        | 0.495849   |
| AverageReturn           | 2.4e+03    |
| Entropy                 | 2.13337    |
| EnvExecTime             | 2.28       |
| ExplainedVariance       | 0.816      |
| Iteration               | 413        |
| ItrTime                 | 13.5       |
| LossAfter               | -0.537077  |
| LossBefore              | -0.513753  |
| MaxReturn               | 3.08e+03   |
| MeanKL                  | 0.00649016 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 945        |
| NumTrajs                | 7          |
| Perplexity              | 8.4433     |
| PolicyExecTime          | 0.566      |
| ProcessExecTime         | 0.0643     |
| StdReturn               | 682        |
| Time                    | 5.58e+03   |
| dLoss                   | 0.023324   |
----------------------------------------
itr #414 | 
Mem: 736.156250
Obtaining samples...
Obtaining samples for iteration 414...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5437, #subsample_inputs: 5437
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.653      |
| AbsLearnSignalNew       | 0.653      |
| AbsLearningOld          | 0.652      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 35.394     |
| AveragePolicyStd        | 0.496072   |
| AverageReturn           | 2.57e+03   |
| Entropy                 | 2.13547    |
| EnvExecTime             | 2.37       |
| ExplainedVariance       | 0.741      |
| Iteration               | 414        |
| ItrTime                 | 14         |
| LossAfter               | -0.334061  |
| LossBefore              | -0.297887  |
| MaxReturn               | 3.37e+03   |
| MeanKL                  | 0.00981198 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.5e+03    |
| NumTrajs                | 7          |
| Perplexity              | 8.46101    |
| PolicyExecTime          | 0.603      |
| ProcessExecTime         | 0.0687     |
| StdReturn               | 802        |
| Time                    | 5.59e+03   |
| dLoss                   | 0.0361739  |
----------------------------------------
itr #415 | 
Mem: 736.156250
Obtaining samples...
Obtaining samples for iteration 415...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5161, #subsample_inputs: 5161
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.648      |
| AbsLearnSignalNew       | 0.648      |
| AbsLearningOld          | 0.648      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 35.9114    |
| AveragePolicyStd        | 0.497313   |
| AverageReturn           | 2.16e+03   |
| Entropy                 | 2.14291    |
| EnvExecTime             | 1.97       |
| ExplainedVariance       | 0.857      |
| Iteration               | 415        |
| ItrTime                 | 13         |
| LossAfter               | -0.790551  |
| LossBefore              | -0.760982  |
| MaxReturn               | 3.28e+03   |
| MeanKL                  | 0.00994659 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.23e+03   |
| NumTrajs                | 8          |
| Perplexity              | 8.52422    |
| PolicyExecTime          | 0.503      |
| ProcessExecTime         | 0.057      |
| StdReturn               | 616        |
| Time                    | 5.61e+03   |
| dLoss                   | 0.0295695  |
----------------------------------------
itr #416 | 
Mem: 736.156250
Obtaining samples...
Obtaining samples for iteration 416...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5063, #subsample_inputs: 5063
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.754      |
| AbsLearnSignalNew       | 0.754      |
| AbsLearningOld          | 0.754      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 36.99      |
| AveragePolicyStd        | 0.499051   |
| AverageReturn           | 2.12e+03   |
| Entropy                 | 2.15187    |
| EnvExecTime             | 1.94       |
| ExplainedVariance       | 0.906      |
| Iteration               | 416        |
| ItrTime                 | 12.8       |
| LossAfter               | 0.40456    |
| LossBefore              | 0.429291   |
| MaxReturn               | 2.7e+03    |
| MeanKL                  | 0.00986527 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.68e+03   |
| NumTrajs                | 8          |
| Perplexity              | 8.60095    |
| PolicyExecTime          | 0.494      |
| ProcessExecTime         | 0.0568     |
| StdReturn               | 303        |
| Time                    | 5.62e+03   |
| dLoss                   | 0.024731   |
----------------------------------------
itr #417 | 
Mem: 736.156250
Obtaining samples...
Obtaining samples for iteration 417...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5280, #subsample_inputs: 5280
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.598      |
| AbsLearnSignalNew       | 0.598      |
| AbsLearningOld          | 0.598      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 33.2996    |
| AveragePolicyStd        | 0.497718   |
| AverageReturn           | 2.22e+03   |
| Entropy                 | 2.14397    |
| EnvExecTime             | 2.07       |
| ExplainedVariance       | 0.78       |
| Iteration               | 417        |
| ItrTime                 | 13.3       |
| LossAfter               | 0.750878   |
| LossBefore              | 0.776469   |
| MaxReturn               | 3.25e+03   |
| MeanKL                  | 0.00993271 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.44e+03   |
| NumTrajs                | 8          |
| Perplexity              | 8.53327    |
| PolicyExecTime          | 0.529      |
| ProcessExecTime         | 0.0604     |
| StdReturn               | 643        |
| Time                    | 5.63e+03   |
| dLoss                   | 0.0255911  |
----------------------------------------
itr #418 | 
Mem: 736.156250
Obtaining samples...
Obtaining samples for iteration 418...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5296, #subsample_inputs: 5296
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.659      |
| AbsLearnSignalNew       | 0.659      |
| AbsLearningOld          | 0.659      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 44.5168    |
| AveragePolicyStd        | 0.49874    |
| AverageReturn           | 1.98e+03   |
| Entropy                 | 2.1505     |
| EnvExecTime             | 2.39       |
| ExplainedVariance       | 0.853      |
| Iteration               | 418        |
| ItrTime                 | 13.8       |
| LossAfter               | -0.563343  |
| LossBefore              | -0.539664  |
| MaxReturn               | 2.97e+03   |
| MeanKL                  | 0.00644875 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.24e+03   |
| NumTrajs                | 9          |
| Perplexity              | 8.58918    |
| PolicyExecTime          | 0.606      |
| ProcessExecTime         | 0.0661     |
| StdReturn               | 556        |
| Time                    | 5.65e+03   |
| dLoss                   | 0.0236788  |
----------------------------------------
itr #419 | 
Mem: 736.156250
Obtaining samples...
Obtaining samples for iteration 419...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5406, #subsample_inputs: 5406
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.756      |
| AbsLearnSignalNew       | 0.756      |
| AbsLearningOld          | 0.756      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 36.2329    |
| AveragePolicyStd        | 0.496875   |
| AverageReturn           | 2.01e+03   |
| Entropy                 | 2.1383     |
| EnvExecTime             | 2.31       |
| ExplainedVariance       | 0.9        |
| Iteration               | 419        |
| ItrTime                 | 13.9       |
| LossAfter               | 1.61504    |
| LossBefore              | 1.64291    |
| MaxReturn               | 2.94e+03   |
| MeanKL                  | 0.00973744 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.54e+03   |
| NumTrajs                | 9          |
| Perplexity              | 8.48497    |
| PolicyExecTime          | 0.573      |
| ProcessExecTime         | 0.0673     |
| StdReturn               | 402        |
| Time                    | 5.66e+03   |
| dLoss                   | 0.0278674  |
----------------------------------------
itr #420 | 
Mem: 736.156250
Obtaining samples...
Obtaining samples for iteration 420...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5698, #subsample_inputs: 5698
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.65       |
| AbsLearnSignalNew       | 0.65       |
| AbsLearningOld          | 0.65       |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 47.8666    |
| AveragePolicyStd        | 0.497745   |
| AverageReturn           | 1.92e+03   |
| Entropy                 | 2.14413    |
| EnvExecTime             | 2.51       |
| ExplainedVariance       | 0.848      |
| Iteration               | 420        |
| ItrTime                 | 14.4       |
| LossAfter               | -0.400068  |
| LossBefore              | -0.370408  |
| MaxReturn               | 3.32e+03   |
| MeanKL                  | 0.00645648 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.19e+03   |
| NumTrajs                | 10         |
| Perplexity              | 8.53465    |
| PolicyExecTime          | 0.626      |
| ProcessExecTime         | 0.0712     |
| StdReturn               | 658        |
| Time                    | 5.68e+03   |
| dLoss                   | 0.0296603  |
----------------------------------------
itr #421 | 
Mem: 736.156250
Obtaining samples...
Obtaining samples for iteration 421...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5213, #subsample_inputs: 5213
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.716      |
| AbsLearnSignalNew       | 0.716      |
| AbsLearningOld          | 0.716      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 36.5946    |
| AveragePolicyStd        | 0.49729    |
| AverageReturn           | 2.51e+03   |
| Entropy                 | 2.14055    |
| EnvExecTime             | 2.01       |
| ExplainedVariance       | 0.819      |
| Iteration               | 421        |
| ItrTime                 | 13.1       |
| LossAfter               | -1.7471    |
| LossBefore              | -1.71848   |
| MaxReturn               | 3.13e+03   |
| MeanKL                  | 0.00645971 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.87e+03   |
| NumTrajs                | 7          |
| Perplexity              | 8.50414    |
| PolicyExecTime          | 0.51       |
| ProcessExecTime         | 0.0578     |
| StdReturn               | 469        |
| Time                    | 5.69e+03   |
| dLoss                   | 0.0286252  |
----------------------------------------
itr #422 | 
Mem: 736.156250
Obtaining samples...
Obtaining samples for iteration 422...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5474, #subsample_inputs: 5474
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.542      |
| AbsLearnSignalNew       | 0.542      |
| AbsLearningOld          | 0.541      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 34.4998    |
| AveragePolicyStd        | 0.496738   |
| AverageReturn           | 2.55e+03   |
| Entropy                 | 2.13749    |
| EnvExecTime             | 2.52       |
| ExplainedVariance       | 0.537      |
| Iteration               | 422        |
| ItrTime                 | 14.1       |
| LossAfter               | -0.587495  |
| LossBefore              | -0.562796  |
| MaxReturn               | 3.33e+03   |
| MeanKL                  | 0.00987912 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.46e+03   |
| NumTrajs                | 7          |
| Perplexity              | 8.47812    |
| PolicyExecTime          | 0.634      |
| ProcessExecTime         | 0.0709     |
| StdReturn               | 772        |
| Time                    | 5.7e+03    |
| dLoss                   | 0.0246986  |
----------------------------------------
itr #423 | 
Mem: 736.156250
Obtaining samples...
Obtaining samples for iteration 423...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5655, #subsample_inputs: 5655
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.709      |
| AbsLearnSignalNew       | 0.709      |
| AbsLearningOld          | 0.709      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 37.2876    |
| AveragePolicyStd        | 0.496934   |
| AverageReturn           | 2.86e+03   |
| Entropy                 | 2.13823    |
| EnvExecTime             | 2.52       |
| ExplainedVariance       | 0.854      |
| Iteration               | 423        |
| ItrTime                 | 14.4       |
| LossAfter               | 0.44352    |
| LossBefore              | 0.473767   |
| MaxReturn               | 3.22e+03   |
| MeanKL                  | 0.00976122 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 2.21e+03   |
| NumTrajs                | 6          |
| Perplexity              | 8.48438    |
| PolicyExecTime          | 0.649      |
| ProcessExecTime         | 0.071      |
| StdReturn               | 309        |
| Time                    | 5.72e+03   |
| dLoss                   | 0.0302473  |
----------------------------------------
itr #424 | 
Mem: 736.156250
Obtaining samples...
Obtaining samples for iteration 424...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5086, #subsample_inputs: 5086
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.626      |
| AbsLearnSignalNew       | 0.626      |
| AbsLearningOld          | 0.626      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 36.7486    |
| AveragePolicyStd        | 0.496772   |
| AverageReturn           | 2.36e+03   |
| Entropy                 | 2.13761    |
| EnvExecTime             | 1.78       |
| ExplainedVariance       | 0.781      |
| Iteration               | 424        |
| ItrTime                 | 12.7       |
| LossAfter               | 0.881634   |
| LossBefore              | 0.915513   |
| MaxReturn               | 3.2e+03    |
| MeanKL                  | 0.00640603 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.56e+03   |
| NumTrajs                | 7          |
| Perplexity              | 8.47919    |
| PolicyExecTime          | 0.446      |
| ProcessExecTime         | 0.0547     |
| StdReturn               | 710        |
| Time                    | 5.73e+03   |
| dLoss                   | 0.0338787  |
----------------------------------------
itr #425 | 
Mem: 736.156250
Obtaining samples...
Obtaining samples for iteration 425...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5364, #subsample_inputs: 5364
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.717      |
| AbsLearnSignalNew       | 0.717      |
| AbsLearningOld          | 0.718      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 39.4325    |
| AveragePolicyStd        | 0.496914   |
| AverageReturn           | 2.17e+03   |
| Entropy                 | 2.13901    |
| EnvExecTime             | 2.35       |
| ExplainedVariance       | 0.881      |
| Iteration               | 425        |
| ItrTime                 | 13.9       |
| LossAfter               | -0.860785  |
| LossBefore              | -0.833909  |
| MaxReturn               | 3.17e+03   |
| MeanKL                  | 0.00645288 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.54e+03   |
| NumTrajs                | 8          |
| Perplexity              | 8.49105    |
| PolicyExecTime          | 0.593      |
| ProcessExecTime         | 0.0661     |
| StdReturn               | 579        |
| Time                    | 5.74e+03   |
| dLoss                   | 0.0268755  |
----------------------------------------
itr #426 | 
Mem: 736.156250
Obtaining samples...
Obtaining samples for iteration 426...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5381, #subsample_inputs: 5381
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.728      |
| AbsLearnSignalNew       | 0.728      |
| AbsLearningOld          | 0.728      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 34.6907    |
| AveragePolicyStd        | 0.496458   |
| AverageReturn           | 2e+03      |
| Entropy                 | 2.13512    |
| EnvExecTime             | 2.3        |
| ExplainedVariance       | 0.857      |
| Iteration               | 426        |
| ItrTime                 | 13.9       |
| LossAfter               | -0.48404   |
| LossBefore              | -0.463796  |
| MaxReturn               | 3.12e+03   |
| MeanKL                  | 0.00644764 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.23e+03   |
| NumTrajs                | 9          |
| Perplexity              | 8.45803    |
| PolicyExecTime          | 0.589      |
| ProcessExecTime         | 0.0643     |
| StdReturn               | 668        |
| Time                    | 5.76e+03   |
| dLoss                   | 0.0202443  |
----------------------------------------
itr #427 | 
Mem: 736.156250
Obtaining samples...
Obtaining samples for iteration 427...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5458, #subsample_inputs: 5458
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.728      |
| AbsLearnSignalNew       | 0.728      |
| AbsLearningOld          | 0.728      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 37.3883    |
| AveragePolicyStd        | 0.496344   |
| AverageReturn           | 1.98e+03   |
| Entropy                 | 2.13345    |
| EnvExecTime             | 2.46       |
| ExplainedVariance       | 0.884      |
| Iteration               | 427        |
| ItrTime                 | 14.1       |
| LossAfter               | -0.119537  |
| LossBefore              | -0.0925136 |
| MaxReturn               | 3.22e+03   |
| MeanKL                  | 0.00997418 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.33e+03   |
| NumTrajs                | 9          |
| Perplexity              | 8.44396    |
| PolicyExecTime          | 0.616      |
| ProcessExecTime         | 0.0703     |
| StdReturn               | 605        |
| Time                    | 5.77e+03   |
| dLoss                   | 0.0270233  |
----------------------------------------
itr #428 | 
Mem: 736.156250
Obtaining samples...
Obtaining samples for iteration 428...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5521, #subsample_inputs: 5521
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.766      |
| AbsLearnSignalNew       | 0.766      |
| AbsLearningOld          | 0.766      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 38.4539    |
| AveragePolicyStd        | 0.496989   |
| AverageReturn           | 2.53e+03   |
| Entropy                 | 2.13703    |
| EnvExecTime             | 2.73       |
| ExplainedVariance       | 0.858      |
| Iteration               | 428        |
| ItrTime                 | 14.5       |
| LossAfter               | -1.48264   |
| LossBefore              | -1.4586    |
| MaxReturn               | 3.18e+03   |
| MeanKL                  | 0.00653389 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.22e+03   |
| NumTrajs                | 7          |
| Perplexity              | 8.4742     |
| PolicyExecTime          | 0.688      |
| ProcessExecTime         | 0.0752     |
| StdReturn               | 629        |
| Time                    | 5.79e+03   |
| dLoss                   | 0.0240407  |
----------------------------------------
itr #429 | 
Mem: 736.156250
Obtaining samples...
Obtaining samples for iteration 429...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5323, #subsample_inputs: 5323
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.653      |
| AbsLearnSignalNew       | 0.653      |
| AbsLearningOld          | 0.653      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 36.1863    |
| AveragePolicyStd        | 0.495849   |
| AverageReturn           | 1.98e+03   |
| Entropy                 | 2.13182    |
| EnvExecTime             | 1.96       |
| ExplainedVariance       | 0.826      |
| Iteration               | 429        |
| ItrTime                 | 13.4       |
| LossAfter               | 1.26198    |
| LossBefore              | 1.2911     |
| MaxReturn               | 2.94e+03   |
| MeanKL                  | 0.00981267 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.5e+03    |
| NumTrajs                | 9          |
| Perplexity              | 8.43023    |
| PolicyExecTime          | 0.5        |
| ProcessExecTime         | 0.0585     |
| StdReturn               | 474        |
| Time                    | 5.8e+03    |
| dLoss                   | 0.0291203  |
----------------------------------------
itr #430 | 
Mem: 736.156250
Obtaining samples...
Obtaining samples for iteration 430...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5380, #subsample_inputs: 5380
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.594      |
| AbsLearnSignalNew       | 0.594      |
| AbsLearningOld          | 0.594      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 44.1339    |
| AveragePolicyStd        | 0.497154   |
| AverageReturn           | 2.23e+03   |
| Entropy                 | 2.13881    |
| EnvExecTime             | 2.41       |
| ExplainedVariance       | 0.74       |
| Iteration               | 430        |
| ItrTime                 | 14         |
| LossAfter               | 0.564464   |
| LossBefore              | 0.589661   |
| MaxReturn               | 3.36e+03   |
| MeanKL                  | 0.00647805 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.24e+03   |
| NumTrajs                | 8          |
| Perplexity              | 8.48931    |
| PolicyExecTime          | 0.602      |
| ProcessExecTime         | 0.0697     |
| StdReturn               | 707        |
| Time                    | 5.81e+03   |
| dLoss                   | 0.0251974  |
----------------------------------------
itr #431 | 
Mem: 736.156250
Obtaining samples...
Obtaining samples for iteration 431...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5474, #subsample_inputs: 5474
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.743      |
| AbsLearnSignalNew       | 0.743      |
| AbsLearningOld          | 0.743      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 37.0082    |
| AveragePolicyStd        | 0.496153   |
| AverageReturn           | 2.27e+03   |
| Entropy                 | 2.13221    |
| EnvExecTime             | 2.32       |
| ExplainedVariance       | 0.886      |
| Iteration               | 431        |
| ItrTime                 | 13.8       |
| LossAfter               | 0.325615   |
| LossBefore              | 0.353456   |
| MaxReturn               | 3.11e+03   |
| MeanKL                  | 0.00986288 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.53e+03   |
| NumTrajs                | 8          |
| Perplexity              | 8.43348    |
| PolicyExecTime          | 0.594      |
| ProcessExecTime         | 0.0657     |
| StdReturn               | 452        |
| Time                    | 5.83e+03   |
| dLoss                   | 0.0278409  |
----------------------------------------
itr #432 | 
Mem: 736.156250
Obtaining samples...
Obtaining samples for iteration 432...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5158, #subsample_inputs: 5158
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.694     |
| AbsLearnSignalNew       | 0.694     |
| AbsLearningOld          | 0.694     |
| AverageDiscountedReturn | 249       |
| AveragePhiLoss          | 35.5043   |
| AveragePolicyStd        | 0.495841  |
| AverageReturn           | 2.78e+03  |
| Entropy                 | 2.1305    |
| EnvExecTime             | 2.3       |
| ExplainedVariance       | 0.825     |
| Iteration               | 432       |
| ItrTime                 | 13.3      |
| LossAfter               | -0.146471 |
| LossBefore              | -0.118589 |
| MaxReturn               | 3.36e+03  |
| MeanKL                  | 0.0097175 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 2e+03     |
| NumTrajs                | 6         |
| Perplexity              | 8.41911   |
| PolicyExecTime          | 0.572     |
| ProcessExecTime         | 0.066     |
| StdReturn               | 428       |
| Time                    | 5.84e+03  |
| dLoss                   | 0.0278813 |
---------------------------------------
itr #433 | 
Mem: 736.156250
Obtaining samples...
Obtaining samples for iteration 433...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5591, #subsample_inputs: 5591
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.599      |
| AbsLearnSignalNew       | 0.599      |
| AbsLearningOld          | 0.599      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 36.7262    |
| AveragePolicyStd        | 0.497106   |
| AverageReturn           | 1.89e+03   |
| Entropy                 | 2.13646    |
| EnvExecTime             | 2.38       |
| ExplainedVariance       | 0.791      |
| Iteration               | 433        |
| ItrTime                 | 14.1       |
| LossAfter               | 0.802459   |
| LossBefore              | 0.825064   |
| MaxReturn               | 3.06e+03   |
| MeanKL                  | 0.00651343 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.26e+03   |
| NumTrajs                | 10         |
| Perplexity              | 8.46939    |
| PolicyExecTime          | 0.588      |
| ProcessExecTime         | 0.0701     |
| StdReturn               | 576        |
| Time                    | 5.86e+03   |
| dLoss                   | 0.0226054  |
----------------------------------------
itr #434 | 
Mem: 736.273438
Obtaining samples...
Obtaining samples for iteration 434...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5200, #subsample_inputs: 5200
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.697      |
| AbsLearnSignalNew       | 0.697      |
| AbsLearningOld          | 0.697      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 37.6607    |
| AveragePolicyStd        | 0.495701   |
| AverageReturn           | 1.92e+03   |
| Entropy                 | 2.12766    |
| EnvExecTime             | 2.15       |
| ExplainedVariance       | 0.83       |
| Iteration               | 434        |
| ItrTime                 | 13.2       |
| LossAfter               | -1.87276   |
| LossBefore              | -1.84016   |
| MaxReturn               | 3.32e+03   |
| MeanKL                  | 0.00999153 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.04e+03   |
| NumTrajs                | 9          |
| Perplexity              | 8.39522    |
| PolicyExecTime          | 0.545      |
| ProcessExecTime         | 0.0619     |
| StdReturn               | 825        |
| Time                    | 5.87e+03   |
| dLoss                   | 0.0326064  |
----------------------------------------
itr #435 | 
Mem: 736.394531
Obtaining samples...
Obtaining samples for iteration 435...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5041, #subsample_inputs: 5041
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.591     |
| AbsLearnSignalNew       | 0.591     |
| AbsLearningOld          | 0.591     |
| AverageDiscountedReturn | 252       |
| AveragePhiLoss          | 48.8289   |
| AveragePolicyStd        | 0.496285  |
| AverageReturn           | 2.39e+03  |
| Entropy                 | 2.13158   |
| EnvExecTime             | 2.35      |
| ExplainedVariance       | 0.683     |
| Iteration               | 435       |
| ItrTime                 | 13.3      |
| LossAfter               | 1.66635   |
| LossBefore              | 1.69086   |
| MaxReturn               | 3.32e+03  |
| MeanKL                  | 0.0098867 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.56e+03  |
| NumTrajs                | 7         |
| Perplexity              | 8.42813   |
| PolicyExecTime          | 0.598     |
| ProcessExecTime         | 0.0646    |
| StdReturn               | 595       |
| Time                    | 5.88e+03  |
| dLoss                   | 0.0245063 |
---------------------------------------
itr #436 | 
Mem: 736.644531
Obtaining samples...
Obtaining samples for iteration 436...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5420, #subsample_inputs: 5420
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.661      |
| AbsLearnSignalNew       | 0.661      |
| AbsLearningOld          | 0.661      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 42.2012    |
| AveragePolicyStd        | 0.495774   |
| AverageReturn           | 2.27e+03   |
| Entropy                 | 2.12698    |
| EnvExecTime             | 2.37       |
| ExplainedVariance       | 0.818      |
| Iteration               | 436        |
| ItrTime                 | 14         |
| LossAfter               | -1.70681   |
| LossBefore              | -1.67285   |
| MaxReturn               | 3.34e+03   |
| MeanKL                  | 0.00971478 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.11e+03   |
| NumTrajs                | 8          |
| Perplexity              | 8.38946    |
| PolicyExecTime          | 0.588      |
| ProcessExecTime         | 0.0677     |
| StdReturn               | 719        |
| Time                    | 5.9e+03    |
| dLoss                   | 0.0339514  |
----------------------------------------
itr #437 | 
Mem: 736.644531
Obtaining samples...
Obtaining samples for iteration 437...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5330, #subsample_inputs: 5330
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.729      |
| AbsLearnSignalNew       | 0.729      |
| AbsLearningOld          | 0.729      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 42.5965    |
| AveragePolicyStd        | 0.494122   |
| AverageReturn           | 1.81e+03   |
| Entropy                 | 2.11849    |
| EnvExecTime             | 1.99       |
| ExplainedVariance       | 0.915      |
| Iteration               | 437        |
| ItrTime                 | 13.4       |
| LossAfter               | -1.84461   |
| LossBefore              | -1.81246   |
| MaxReturn               | 2.35e+03   |
| MeanKL                  | 0.00995715 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.23e+03   |
| NumTrajs                | 10         |
| Perplexity              | 8.31858    |
| PolicyExecTime          | 0.503      |
| ProcessExecTime         | 0.0584     |
| StdReturn               | 360        |
| Time                    | 5.91e+03   |
| dLoss                   | 0.0321531  |
----------------------------------------
itr #438 | 
Mem: 736.644531
Obtaining samples...
Obtaining samples for iteration 438...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5395, #subsample_inputs: 5395
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.756      |
| AbsLearnSignalNew       | 0.756      |
| AbsLearningOld          | 0.756      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 37.5251    |
| AveragePolicyStd        | 0.492585   |
| AverageReturn           | 2.28e+03   |
| Entropy                 | 2.1101     |
| EnvExecTime             | 2.47       |
| ExplainedVariance       | 0.905      |
| Iteration               | 438        |
| ItrTime                 | 14.1       |
| LossAfter               | -0.355115  |
| LossBefore              | -0.326868  |
| MaxReturn               | 3.21e+03   |
| MeanKL                  | 0.00993853 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.46e+03   |
| NumTrajs                | 8          |
| Perplexity              | 8.24903    |
| PolicyExecTime          | 0.62       |
| ProcessExecTime         | 0.0702     |
| StdReturn               | 570        |
| Time                    | 5.92e+03   |
| dLoss                   | 0.0282469  |
----------------------------------------
itr #439 | 
Mem: 736.644531
Obtaining samples...
Obtaining samples for iteration 439...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5049, #subsample_inputs: 5049
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.736      |
| AbsLearnSignalNew       | 0.736      |
| AbsLearningOld          | 0.736      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 37.525     |
| AveragePolicyStd        | 0.492651   |
| AverageReturn           | 2.15e+03   |
| Entropy                 | 2.11019    |
| EnvExecTime             | 2.02       |
| ExplainedVariance       | 0.922      |
| Iteration               | 439        |
| ItrTime                 | 12.8       |
| LossAfter               | -0.480776  |
| LossBefore              | -0.454046  |
| MaxReturn               | 3.29e+03   |
| MeanKL                  | 0.00989069 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.19e+03   |
| NumTrajs                | 8          |
| Perplexity              | 8.24984    |
| PolicyExecTime          | 0.515      |
| ProcessExecTime         | 0.0579     |
| StdReturn               | 662        |
| Time                    | 5.94e+03   |
| dLoss                   | 0.0267302  |
----------------------------------------
itr #440 | 
Mem: 736.644531
Obtaining samples...
Obtaining samples for iteration 440...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5604, #subsample_inputs: 5604
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.587     |
| AbsLearnSignalNew       | 0.587     |
| AbsLearningOld          | 0.587     |
| AverageDiscountedReturn | 252       |
| AveragePhiLoss          | 34.7532   |
| AveragePolicyStd        | 0.4956    |
| AverageReturn           | 2.1e+03   |
| Entropy                 | 2.12821   |
| EnvExecTime             | 2.41      |
| ExplainedVariance       | 0.786     |
| Iteration               | 440       |
| ItrTime                 | 14.2      |
| LossAfter               | 0.80352   |
| LossBefore              | 0.822626  |
| MaxReturn               | 3.21e+03  |
| MeanKL                  | 0.0064042 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.09e+03  |
| NumTrajs                | 9         |
| Perplexity              | 8.39985   |
| PolicyExecTime          | 0.602     |
| ProcessExecTime         | 0.0699    |
| StdReturn               | 580       |
| Time                    | 5.95e+03  |
| dLoss                   | 0.0191067 |
---------------------------------------
itr #441 | 
Mem: 736.644531
Obtaining samples...
Obtaining samples for iteration 441...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5148, #subsample_inputs: 5148
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.592     |
| AbsLearnSignalNew       | 0.592     |
| AbsLearningOld          | 0.592     |
| AverageDiscountedReturn | 251       |
| AveragePhiLoss          | 37.7622   |
| AveragePolicyStd        | 0.495374  |
| AverageReturn           | 2.16e+03  |
| Entropy                 | 2.12729   |
| EnvExecTime             | 2.29      |
| ExplainedVariance       | 0.832     |
| Iteration               | 441       |
| ItrTime                 | 13.4      |
| LossAfter               | 1.38878   |
| LossBefore              | 1.41312   |
| MaxReturn               | 3.02e+03  |
| MeanKL                  | 0.0065223 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.21e+03  |
| NumTrajs                | 8         |
| Perplexity              | 8.39213   |
| PolicyExecTime          | 0.58      |
| ProcessExecTime         | 0.0647    |
| StdReturn               | 636       |
| Time                    | 5.96e+03  |
| dLoss                   | 0.0243391 |
---------------------------------------
itr #442 | 
Mem: 736.644531
Obtaining samples...
Obtaining samples for iteration 442...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5085, #subsample_inputs: 5085
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.723     |
| AbsLearnSignalNew       | 0.723     |
| AbsLearningOld          | 0.723     |
| AverageDiscountedReturn | 253       |
| AveragePhiLoss          | 38.3947   |
| AveragePolicyStd        | 0.493517  |
| AverageReturn           | 2.15e+03  |
| Entropy                 | 2.11628   |
| EnvExecTime             | 2.22      |
| ExplainedVariance       | 0.879     |
| Iteration               | 442       |
| ItrTime                 | 13.1      |
| LossAfter               | 0.409298  |
| LossBefore              | 0.429255  |
| MaxReturn               | 3.28e+03  |
| MeanKL                  | 0.0064649 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.48e+03  |
| NumTrajs                | 8         |
| Perplexity              | 8.30022   |
| PolicyExecTime          | 0.55      |
| ProcessExecTime         | 0.0657    |
| StdReturn               | 545       |
| Time                    | 5.98e+03  |
| dLoss                   | 0.0199567 |
---------------------------------------
itr #443 | 
Mem: 736.644531
Obtaining samples...
Obtaining samples for iteration 443...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5742, #subsample_inputs: 5742
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.728      |
| AbsLearnSignalNew       | 0.728      |
| AbsLearningOld          | 0.728      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 42.6655    |
| AveragePolicyStd        | 0.492742   |
| AverageReturn           | 1.94e+03   |
| Entropy                 | 2.11184    |
| EnvExecTime             | 2.25       |
| ExplainedVariance       | 0.924      |
| Iteration               | 443        |
| ItrTime                 | 14.1       |
| LossAfter               | -0.729739  |
| LossBefore              | -0.702409  |
| MaxReturn               | 3.35e+03   |
| MeanKL                  | 0.00979235 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.25e+03   |
| NumTrajs                | 10         |
| Perplexity              | 8.2634     |
| PolicyExecTime          | 0.57       |
| ProcessExecTime         | 0.0662     |
| StdReturn               | 734        |
| Time                    | 5.99e+03   |
| dLoss                   | 0.0273298  |
----------------------------------------
itr #444 | 
Mem: 736.644531
Obtaining samples...
Obtaining samples for iteration 444...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5403, #subsample_inputs: 5403
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.647      |
| AbsLearnSignalNew       | 0.647      |
| AbsLearningOld          | 0.647      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 42.0525    |
| AveragePolicyStd        | 0.491394   |
| AverageReturn           | 2.02e+03   |
| Entropy                 | 2.10353    |
| EnvExecTime             | 2.43       |
| ExplainedVariance       | 0.844      |
| Iteration               | 444        |
| ItrTime                 | 14         |
| LossAfter               | 1.4479     |
| LossBefore              | 1.4805     |
| MaxReturn               | 3.11e+03   |
| MeanKL                  | 0.00989223 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1e+03      |
| NumTrajs                | 9          |
| Perplexity              | 8.19504    |
| PolicyExecTime          | 0.608      |
| ProcessExecTime         | 0.068      |
| StdReturn               | 731        |
| Time                    | 6.01e+03   |
| dLoss                   | 0.0326002  |
----------------------------------------
itr #445 | 
Mem: 736.644531
Obtaining samples...
Obtaining samples for iteration 445...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5410, #subsample_inputs: 5410
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.701      |
| AbsLearnSignalNew       | 0.701      |
| AbsLearningOld          | 0.701      |
| AverageDiscountedReturn | 255        |
| AveragePhiLoss          | 38.6493    |
| AveragePolicyStd        | 0.491514   |
| AverageReturn           | 1.85e+03   |
| Entropy                 | 2.10367    |
| EnvExecTime             | 2.23       |
| ExplainedVariance       | 0.918      |
| Iteration               | 445        |
| ItrTime                 | 13.9       |
| LossAfter               | -1.49491   |
| LossBefore              | -1.46501   |
| MaxReturn               | 2.91e+03   |
| MeanKL                  | 0.00952401 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.24e+03   |
| NumTrajs                | 10         |
| Perplexity              | 8.19618    |
| PolicyExecTime          | 0.571      |
| ProcessExecTime         | 0.0631     |
| StdReturn               | 504        |
| Time                    | 6.02e+03   |
| dLoss                   | 0.0298979  |
----------------------------------------
itr #446 | 
Mem: 736.644531
Obtaining samples...
Obtaining samples for iteration 446...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5511, #subsample_inputs: 5511
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.568      |
| AbsLearnSignalNew       | 0.568      |
| AbsLearningOld          | 0.568      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 32.142     |
| AveragePolicyStd        | 0.491157   |
| AverageReturn           | 2.29e+03   |
| Entropy                 | 2.10203    |
| EnvExecTime             | 2.26       |
| ExplainedVariance       | 0.709      |
| Iteration               | 446        |
| ItrTime                 | 13.8       |
| LossAfter               | 0.751811   |
| LossBefore              | 0.775653   |
| MaxReturn               | 3.3e+03    |
| MeanKL                  | 0.00970475 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.31e+03   |
| NumTrajs                | 8          |
| Perplexity              | 8.18275    |
| PolicyExecTime          | 0.579      |
| ProcessExecTime         | 0.0643     |
| StdReturn               | 738        |
| Time                    | 6.03e+03   |
| dLoss                   | 0.0238424  |
----------------------------------------
itr #447 | 
Mem: 736.687500
Obtaining samples...
Obtaining samples for iteration 447...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5419, #subsample_inputs: 5419
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.727      |
| AbsLearnSignalNew       | 0.727      |
| AbsLearningOld          | 0.727      |
| AverageDiscountedReturn | 254        |
| AveragePhiLoss          | 40.256     |
| AveragePolicyStd        | 0.493138   |
| AverageReturn           | 2.95e+03   |
| Entropy                 | 2.11414    |
| EnvExecTime             | 2.32       |
| ExplainedVariance       | 0.888      |
| Iteration               | 447        |
| ItrTime                 | 13.9       |
| LossAfter               | -0.199845  |
| LossBefore              | -0.173909  |
| MaxReturn               | 3.32e+03   |
| MeanKL                  | 0.00982686 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.44e+03   |
| NumTrajs                | 6          |
| Perplexity              | 8.28244    |
| PolicyExecTime          | 0.582      |
| ProcessExecTime         | 0.0676     |
| StdReturn               | 681        |
| Time                    | 6.05e+03   |
| dLoss                   | 0.025936   |
----------------------------------------
itr #448 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 448...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5909, #subsample_inputs: 5909
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.632      |
| AbsLearnSignalNew       | 0.632      |
| AbsLearningOld          | 0.632      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 45.43      |
| AveragePolicyStd        | 0.492637   |
| AverageReturn           | 2.79e+03   |
| Entropy                 | 2.11142    |
| EnvExecTime             | 2.43       |
| ExplainedVariance       | 0.83       |
| Iteration               | 448        |
| ItrTime                 | 14.7       |
| LossAfter               | 1.50668    |
| LossBefore              | 1.53591    |
| MaxReturn               | 3.31e+03   |
| MeanKL                  | 0.00994863 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.93e+03   |
| NumTrajs                | 7          |
| Perplexity              | 8.25995    |
| PolicyExecTime          | 0.621      |
| ProcessExecTime         | 0.0709     |
| StdReturn               | 572        |
| Time                    | 6.06e+03   |
| dLoss                   | 0.0292373  |
----------------------------------------
itr #449 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 449...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5347, #subsample_inputs: 5347
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.667     |
| AbsLearnSignalNew       | 0.667     |
| AbsLearningOld          | 0.667     |
| AverageDiscountedReturn | 253       |
| AveragePhiLoss          | 37.9366   |
| AveragePolicyStd        | 0.491648  |
| AverageReturn           | 2.51e+03  |
| Entropy                 | 2.10404   |
| EnvExecTime             | 2.88      |
| ExplainedVariance       | 0.889     |
| Iteration               | 449       |
| ItrTime                 | 14.6      |
| LossAfter               | 0.161542  |
| LossBefore              | 0.187008  |
| MaxReturn               | 3.23e+03  |
| MeanKL                  | 0.0064328 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.78e+03  |
| NumTrajs                | 7         |
| Perplexity              | 8.19925   |
| PolicyExecTime          | 0.717     |
| ProcessExecTime         | 0.0779    |
| StdReturn               | 469       |
| Time                    | 6.08e+03  |
| dLoss                   | 0.025466  |
---------------------------------------
itr #450 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 450...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5063, #subsample_inputs: 5063
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.609      |
| AbsLearnSignalNew       | 0.609      |
| AbsLearningOld          | 0.609      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 46.0285    |
| AveragePolicyStd        | 0.490625   |
| AverageReturn           | 2.73e+03   |
| Entropy                 | 2.09823    |
| EnvExecTime             | 2.46       |
| ExplainedVariance       | 0.836      |
| Iteration               | 450        |
| ItrTime                 | 13.4       |
| LossAfter               | 1.29633    |
| LossBefore              | 1.32554    |
| MaxReturn               | 3.25e+03   |
| MeanKL                  | 0.00654458 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.75e+03   |
| NumTrajs                | 6          |
| Perplexity              | 8.15173    |
| PolicyExecTime          | 0.62       |
| ProcessExecTime         | 0.0674     |
| StdReturn               | 673        |
| Time                    | 6.09e+03   |
| dLoss                   | 0.0292079  |
----------------------------------------
itr #451 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 451...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5583, #subsample_inputs: 5583
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.618     |
| AbsLearnSignalNew       | 0.618     |
| AbsLearningOld          | 0.618     |
| AverageDiscountedReturn | 251       |
| AveragePhiLoss          | 36.2888   |
| AveragePolicyStd        | 0.490443  |
| AverageReturn           | 2.62e+03  |
| Entropy                 | 2.09685   |
| EnvExecTime             | 2.31      |
| ExplainedVariance       | 0.741     |
| Iteration               | 451       |
| ItrTime                 | 14        |
| LossAfter               | 0.119125  |
| LossBefore              | 0.147259  |
| MaxReturn               | 3.29e+03  |
| MeanKL                  | 0.0099527 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.25e+03  |
| NumTrajs                | 7         |
| Perplexity              | 8.1405    |
| PolicyExecTime          | 0.579     |
| ProcessExecTime         | 0.0674    |
| StdReturn               | 874       |
| Time                    | 6.11e+03  |
| dLoss                   | 0.0281339 |
---------------------------------------
itr #452 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 452...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5522, #subsample_inputs: 5522
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.528      |
| AbsLearnSignalNew       | 0.528      |
| AbsLearningOld          | 0.528      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 39.2761    |
| AveragePolicyStd        | 0.491022   |
| AverageReturn           | 2.62e+03   |
| Entropy                 | 2.09985    |
| EnvExecTime             | 2.26       |
| ExplainedVariance       | 0.639      |
| Iteration               | 452        |
| ItrTime                 | 13.8       |
| LossAfter               | 2.07481    |
| LossBefore              | 2.1097     |
| MaxReturn               | 3.34e+03   |
| MeanKL                  | 0.00971036 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.77e+03   |
| NumTrajs                | 7          |
| Perplexity              | 8.16492    |
| PolicyExecTime          | 0.57       |
| ProcessExecTime         | 0.0658     |
| StdReturn               | 541        |
| Time                    | 6.12e+03   |
| dLoss                   | 0.0348902  |
----------------------------------------
itr #453 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 453...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5574, #subsample_inputs: 5574
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.689     |
| AbsLearnSignalNew       | 0.689     |
| AbsLearningOld          | 0.689     |
| AverageDiscountedReturn | 251       |
| AveragePhiLoss          | 38.1694   |
| AveragePolicyStd        | 0.492321  |
| AverageReturn           | 2.31e+03  |
| Entropy                 | 2.10716   |
| EnvExecTime             | 1.98      |
| ExplainedVariance       | 0.759     |
| Iteration               | 453       |
| ItrTime                 | 13.6      |
| LossAfter               | -0.256923 |
| LossBefore              | -0.22836  |
| MaxReturn               | 3.26e+03  |
| MeanKL                  | 0.0098468 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 871       |
| NumTrajs                | 8         |
| Perplexity              | 8.22484   |
| PolicyExecTime          | 0.506     |
| ProcessExecTime         | 0.0595    |
| StdReturn               | 792       |
| Time                    | 6.13e+03  |
| dLoss                   | 0.0285637 |
---------------------------------------
itr #454 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 454...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5340, #subsample_inputs: 5340
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.65       |
| AbsLearnSignalNew       | 0.65       |
| AbsLearningOld          | 0.65       |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 40.9735    |
| AveragePolicyStd        | 0.492667   |
| AverageReturn           | 1.81e+03   |
| Entropy                 | 2.10983    |
| EnvExecTime             | 2.34       |
| ExplainedVariance       | 0.781      |
| Iteration               | 454        |
| ItrTime                 | 13.8       |
| LossAfter               | -0.721826  |
| LossBefore              | -0.686174  |
| MaxReturn               | 2.89e+03   |
| MeanKL                  | 0.00989688 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 793        |
| NumTrajs                | 10         |
| Perplexity              | 8.24683    |
| PolicyExecTime          | 0.592      |
| ProcessExecTime         | 0.0662     |
| StdReturn               | 555        |
| Time                    | 6.15e+03   |
| dLoss                   | 0.0356528  |
----------------------------------------
itr #455 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 455...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5741, #subsample_inputs: 5741
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.575      |
| AbsLearnSignalNew       | 0.575      |
| AbsLearningOld          | 0.575      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 35.359     |
| AveragePolicyStd        | 0.494409   |
| AverageReturn           | 2.13e+03   |
| Entropy                 | 2.11947    |
| EnvExecTime             | 2.42       |
| ExplainedVariance       | 0.631      |
| Iteration               | 455        |
| ItrTime                 | 14.4       |
| LossAfter               | -0.451489  |
| LossBefore              | -0.425651  |
| MaxReturn               | 3.39e+03   |
| MeanKL                  | 0.00985689 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.22e+03   |
| NumTrajs                | 9          |
| Perplexity              | 8.32676    |
| PolicyExecTime          | 0.609      |
| ProcessExecTime         | 0.0693     |
| StdReturn               | 820        |
| Time                    | 6.16e+03   |
| dLoss                   | 0.0258381  |
----------------------------------------
itr #456 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 456...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5748, #subsample_inputs: 5748
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.624      |
| AbsLearnSignalNew       | 0.624      |
| AbsLearningOld          | 0.623      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 42.6137    |
| AveragePolicyStd        | 0.4957     |
| AverageReturn           | 2.1e+03    |
| Entropy                 | 2.12717    |
| EnvExecTime             | 2.11       |
| ExplainedVariance       | 0.792      |
| Iteration               | 456        |
| ItrTime                 | 14         |
| LossAfter               | -0.261273  |
| LossBefore              | -0.234304  |
| MaxReturn               | 3.28e+03   |
| MeanKL                  | 0.00992783 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 915        |
| NumTrajs                | 9          |
| Perplexity              | 8.39108    |
| PolicyExecTime          | 0.538      |
| ProcessExecTime         | 0.0637     |
| StdReturn               | 910        |
| Time                    | 6.18e+03   |
| dLoss                   | 0.0269688  |
----------------------------------------
itr #457 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 457...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5088, #subsample_inputs: 5088
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.751      |
| AbsLearnSignalNew       | 0.751      |
| AbsLearningOld          | 0.751      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 37.241     |
| AveragePolicyStd        | 0.497429   |
| AverageReturn           | 2.73e+03   |
| Entropy                 | 2.13722    |
| EnvExecTime             | 2.16       |
| ExplainedVariance       | 0.867      |
| Iteration               | 457        |
| ItrTime                 | 13.1       |
| LossAfter               | 0.44229    |
| LossBefore              | 0.46335    |
| MaxReturn               | 3.27e+03   |
| MeanKL                  | 0.00645566 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.05e+03   |
| NumTrajs                | 6          |
| Perplexity              | 8.4758     |
| PolicyExecTime          | 0.543      |
| ProcessExecTime         | 0.0617     |
| StdReturn               | 778        |
| Time                    | 6.19e+03   |
| dLoss                   | 0.0210595  |
----------------------------------------
itr #458 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 458...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5354, #subsample_inputs: 5354
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.584     |
| AbsLearnSignalNew       | 0.584     |
| AbsLearningOld          | 0.584     |
| AverageDiscountedReturn | 251       |
| AveragePhiLoss          | 40.3047   |
| AveragePolicyStd        | 0.497542  |
| AverageReturn           | 2.96e+03  |
| Entropy                 | 2.13728   |
| EnvExecTime             | 2.24      |
| ExplainedVariance       | 0.734     |
| Iteration               | 458       |
| ItrTime                 | 13.7      |
| LossAfter               | 3.13744   |
| LossBefore              | 3.16697   |
| MaxReturn               | 3.38e+03  |
| MeanKL                  | 0.0065603 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.44e+03  |
| NumTrajs                | 6         |
| Perplexity              | 8.47638   |
| PolicyExecTime          | 0.567     |
| ProcessExecTime         | 0.0712    |
| StdReturn               | 685       |
| Time                    | 6.2e+03   |
| dLoss                   | 0.0295241 |
---------------------------------------
itr #459 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 459...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5311, #subsample_inputs: 5311
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.594      |
| AbsLearnSignalNew       | 0.594      |
| AbsLearningOld          | 0.594      |
| AverageDiscountedReturn | 254        |
| AveragePhiLoss          | 37.5022    |
| AveragePolicyStd        | 0.496572   |
| AverageReturn           | 2.91e+03   |
| Entropy                 | 2.13207    |
| EnvExecTime             | 2.18       |
| ExplainedVariance       | 0.851      |
| Iteration               | 459        |
| ItrTime                 | 13.4       |
| LossAfter               | 0.101754   |
| LossBefore              | 0.130101   |
| MaxReturn               | 3.3e+03    |
| MeanKL                  | 0.00659828 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.62e+03   |
| NumTrajs                | 6          |
| Perplexity              | 8.43231    |
| PolicyExecTime          | 0.552      |
| ProcessExecTime         | 0.0627     |
| StdReturn               | 588        |
| Time                    | 6.22e+03   |
| dLoss                   | 0.0283477  |
----------------------------------------
itr #460 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 460...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5075, #subsample_inputs: 5075
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.585      |
| AbsLearnSignalNew       | 0.585      |
| AbsLearningOld          | 0.585      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 35.6885    |
| AveragePolicyStd        | 0.497015   |
| AverageReturn           | 2.34e+03   |
| Entropy                 | 2.1358     |
| EnvExecTime             | 2.18       |
| ExplainedVariance       | 0.767      |
| Iteration               | 460        |
| ItrTime                 | 13.1       |
| LossAfter               | 0.0976912  |
| LossBefore              | 0.119731   |
| MaxReturn               | 3.27e+03   |
| MeanKL                  | 0.00644589 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.23e+03   |
| NumTrajs                | 7          |
| Perplexity              | 8.46381    |
| PolicyExecTime          | 0.553      |
| ProcessExecTime         | 0.0634     |
| StdReturn               | 785        |
| Time                    | 6.23e+03   |
| dLoss                   | 0.0220402  |
----------------------------------------
itr #461 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 461...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5405, #subsample_inputs: 5405
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.609      |
| AbsLearnSignalNew       | 0.609      |
| AbsLearningOld          | 0.609      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 33.2474    |
| AveragePolicyStd        | 0.496816   |
| AverageReturn           | 1.83e+03   |
| Entropy                 | 2.13433    |
| EnvExecTime             | 2.26       |
| ExplainedVariance       | 0.882      |
| Iteration               | 461        |
| ItrTime                 | 13.9       |
| LossAfter               | -1.32933   |
| LossBefore              | -1.30508   |
| MaxReturn               | 2.66e+03   |
| MeanKL                  | 0.00642686 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.19e+03   |
| NumTrajs                | 10         |
| Perplexity              | 8.45134    |
| PolicyExecTime          | 0.576      |
| ProcessExecTime         | 0.0641     |
| StdReturn               | 557        |
| Time                    | 6.24e+03   |
| dLoss                   | 0.024256   |
----------------------------------------
itr #462 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 462...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5277, #subsample_inputs: 5277
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.698      |
| AbsLearnSignalNew       | 0.698      |
| AbsLearningOld          | 0.698      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 36.466     |
| AveragePolicyStd        | 0.496211   |
| AverageReturn           | 2.24e+03   |
| Entropy                 | 2.13167    |
| EnvExecTime             | 2.31       |
| ExplainedVariance       | 0.871      |
| Iteration               | 462        |
| ItrTime                 | 13.6       |
| LossAfter               | -0.626407  |
| LossBefore              | -0.603113  |
| MaxReturn               | 3.39e+03   |
| MeanKL                  | 0.00644687 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.48e+03   |
| NumTrajs                | 8          |
| Perplexity              | 8.42893    |
| PolicyExecTime          | 0.586      |
| ProcessExecTime         | 0.0657     |
| StdReturn               | 689        |
| Time                    | 6.26e+03   |
| dLoss                   | 0.0232944  |
----------------------------------------
itr #463 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 463...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5313, #subsample_inputs: 5313
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.611      |
| AbsLearnSignalNew       | 0.611      |
| AbsLearningOld          | 0.611      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 38.5982    |
| AveragePolicyStd        | 0.496713   |
| AverageReturn           | 2e+03      |
| Entropy                 | 2.13477    |
| EnvExecTime             | 2.02       |
| ExplainedVariance       | 0.889      |
| Iteration               | 463        |
| ItrTime                 | 13.2       |
| LossAfter               | -0.806319  |
| LossBefore              | -0.781353  |
| MaxReturn               | 3.22e+03   |
| MeanKL                  | 0.00997845 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.23e+03   |
| NumTrajs                | 9          |
| Perplexity              | 8.45508    |
| PolicyExecTime          | 0.511      |
| ProcessExecTime         | 0.0608     |
| StdReturn               | 703        |
| Time                    | 6.27e+03   |
| dLoss                   | 0.0249652  |
----------------------------------------
itr #464 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 464...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5256, #subsample_inputs: 5256
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.697      |
| AbsLearnSignalNew       | 0.697      |
| AbsLearningOld          | 0.697      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 36.6799    |
| AveragePolicyStd        | 0.497289   |
| AverageReturn           | 1.97e+03   |
| Entropy                 | 2.13711    |
| EnvExecTime             | 2.47       |
| ExplainedVariance       | 0.912      |
| Iteration               | 464        |
| ItrTime                 | 13.8       |
| LossAfter               | 0.953319   |
| LossBefore              | 0.976568   |
| MaxReturn               | 3.29e+03   |
| MeanKL                  | 0.00645391 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.3e+03    |
| NumTrajs                | 9          |
| Perplexity              | 8.47488    |
| PolicyExecTime          | 0.627      |
| ProcessExecTime         | 0.0678     |
| StdReturn               | 540        |
| Time                    | 6.28e+03   |
| dLoss                   | 0.0232483  |
----------------------------------------
itr #465 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 465...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5376, #subsample_inputs: 5376
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.709      |
| AbsLearnSignalNew       | 0.709      |
| AbsLearningOld          | 0.709      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 35.5469    |
| AveragePolicyStd        | 0.498317   |
| AverageReturn           | 2.59e+03   |
| Entropy                 | 2.14274    |
| EnvExecTime             | 2.41       |
| ExplainedVariance       | 0.892      |
| Iteration               | 465        |
| ItrTime                 | 14         |
| LossAfter               | 0.699388   |
| LossBefore              | 0.727731   |
| MaxReturn               | 3.27e+03   |
| MeanKL                  | 0.00647357 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.52e+03   |
| NumTrajs                | 7          |
| Perplexity              | 8.52274    |
| PolicyExecTime          | 0.609      |
| ProcessExecTime         | 0.0681     |
| StdReturn               | 524        |
| Time                    | 6.3e+03    |
| dLoss                   | 0.0283437  |
----------------------------------------
itr #466 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 466...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5164, #subsample_inputs: 5164
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.662      |
| AbsLearnSignalNew       | 0.662      |
| AbsLearningOld          | 0.662      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 33.9508    |
| AveragePolicyStd        | 0.497672   |
| AverageReturn           | 2.46e+03   |
| Entropy                 | 2.13869    |
| EnvExecTime             | 2.25       |
| ExplainedVariance       | 0.844      |
| Iteration               | 466        |
| ItrTime                 | 13.4       |
| LossAfter               | -3.21      |
| LossBefore              | -3.16764   |
| MaxReturn               | 3.32e+03   |
| MeanKL                  | 0.00982569 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.42e+03   |
| NumTrajs                | 7          |
| Perplexity              | 8.48834    |
| PolicyExecTime          | 0.572      |
| ProcessExecTime         | 0.0636     |
| StdReturn               | 722        |
| Time                    | 6.31e+03   |
| dLoss                   | 0.0423658  |
----------------------------------------
itr #467 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 467...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5159, #subsample_inputs: 5159
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.642     |
| AbsLearnSignalNew       | 0.642     |
| AbsLearningOld          | 0.641     |
| AverageDiscountedReturn | 251       |
| AveragePhiLoss          | 40.0571   |
| AveragePolicyStd        | 0.497983  |
| AverageReturn           | 2.43e+03  |
| Entropy                 | 2.13999   |
| EnvExecTime             | 2.48      |
| ExplainedVariance       | 0.865     |
| Iteration               | 467       |
| ItrTime                 | 13.6      |
| LossAfter               | -0.847883 |
| LossBefore              | -0.82215  |
| MaxReturn               | 3.28e+03  |
| MeanKL                  | 0.0098452 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.48e+03  |
| NumTrajs                | 7         |
| Perplexity              | 8.49937   |
| PolicyExecTime          | 0.609     |
| ProcessExecTime         | 0.0716    |
| StdReturn               | 695       |
| Time                    | 6.33e+03  |
| dLoss                   | 0.0257325 |
---------------------------------------
itr #468 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 468...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5201, #subsample_inputs: 5201
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.591      |
| AbsLearnSignalNew       | 0.591      |
| AbsLearningOld          | 0.59       |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 30.1414    |
| AveragePolicyStd        | 0.495035   |
| AverageReturn           | 2.45e+03   |
| Entropy                 | 2.1218     |
| EnvExecTime             | 2.18       |
| ExplainedVariance       | 0.869      |
| Iteration               | 468        |
| ItrTime                 | 13.3       |
| LossAfter               | -1.71091   |
| LossBefore              | -1.68833   |
| MaxReturn               | 3.33e+03   |
| MeanKL                  | 0.00934056 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.3e+03    |
| NumTrajs                | 7          |
| Perplexity              | 8.34619    |
| PolicyExecTime          | 0.556      |
| ProcessExecTime         | 0.0635     |
| StdReturn               | 864        |
| Time                    | 6.34e+03   |
| dLoss                   | 0.0225805  |
----------------------------------------
itr #469 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 469...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5162, #subsample_inputs: 5162
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.589      |
| AbsLearnSignalNew       | 0.589      |
| AbsLearningOld          | 0.588      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 33.1344    |
| AveragePolicyStd        | 0.495422   |
| AverageReturn           | 2.14e+03   |
| Entropy                 | 2.12445    |
| EnvExecTime             | 2.28       |
| ExplainedVariance       | 0.659      |
| Iteration               | 469        |
| ItrTime                 | 13.4       |
| LossAfter               | -1.09869   |
| LossBefore              | -1.07422   |
| MaxReturn               | 3.3e+03    |
| MeanKL                  | 0.00999859 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.13e+03   |
| NumTrajs                | 8          |
| Perplexity              | 8.36831    |
| PolicyExecTime          | 0.579      |
| ProcessExecTime         | 0.0658     |
| StdReturn               | 823        |
| Time                    | 6.35e+03   |
| dLoss                   | 0.0244761  |
----------------------------------------
itr #470 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 470...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5518, #subsample_inputs: 5518
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.718     |
| AbsLearnSignalNew       | 0.718     |
| AbsLearningOld          | 0.719     |
| AverageDiscountedReturn | 249       |
| AveragePhiLoss          | 35.9885   |
| AveragePolicyStd        | 0.495302  |
| AverageReturn           | 2.05e+03  |
| Entropy                 | 2.12292   |
| EnvExecTime             | 2.09      |
| ExplainedVariance       | 0.827     |
| Iteration               | 470       |
| ItrTime                 | 13.6      |
| LossAfter               | 0.497967  |
| LossBefore              | 0.519043  |
| MaxReturn               | 3.19e+03  |
| MeanKL                  | 0.0064011 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.21e+03  |
| NumTrajs                | 9         |
| Perplexity              | 8.35551   |
| PolicyExecTime          | 0.534     |
| ProcessExecTime         | 0.0607    |
| StdReturn               | 566       |
| Time                    | 6.37e+03  |
| dLoss                   | 0.0210755 |
---------------------------------------
itr #471 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 471...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5854, #subsample_inputs: 5854
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.711      |
| AbsLearnSignalNew       | 0.711      |
| AbsLearningOld          | 0.711      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 36.5608    |
| AveragePolicyStd        | 0.494753   |
| AverageReturn           | 2.2e+03    |
| Entropy                 | 2.12158    |
| EnvExecTime             | 2.68       |
| ExplainedVariance       | 0.914      |
| Iteration               | 471        |
| ItrTime                 | 14.9       |
| LossAfter               | 0.423588   |
| LossBefore              | 0.442585   |
| MaxReturn               | 3.35e+03   |
| MeanKL                  | 0.00647771 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.54e+03   |
| NumTrajs                | 9          |
| Perplexity              | 8.34429    |
| PolicyExecTime          | 0.681      |
| ProcessExecTime         | 0.0754     |
| StdReturn               | 525        |
| Time                    | 6.38e+03   |
| dLoss                   | 0.0189967  |
----------------------------------------
itr #472 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 472...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5244, #subsample_inputs: 5244
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.655      |
| AbsLearnSignalNew       | 0.655      |
| AbsLearningOld          | 0.655      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 43.5312    |
| AveragePolicyStd        | 0.496385   |
| AverageReturn           | 2.22e+03   |
| Entropy                 | 2.1316     |
| EnvExecTime             | 2.25       |
| ExplainedVariance       | 0.862      |
| Iteration               | 472        |
| ItrTime                 | 13.4       |
| LossAfter               | 0.628988   |
| LossBefore              | 0.66044    |
| MaxReturn               | 3.36e+03   |
| MeanKL                  | 0.00995836 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.47e+03   |
| NumTrajs                | 8          |
| Perplexity              | 8.42831    |
| PolicyExecTime          | 0.574      |
| ProcessExecTime         | 0.0622     |
| StdReturn               | 693        |
| Time                    | 6.39e+03   |
| dLoss                   | 0.0314519  |
----------------------------------------
itr #473 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 473...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5492, #subsample_inputs: 5492
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.667      |
| AbsLearnSignalNew       | 0.667      |
| AbsLearningOld          | 0.667      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 39.6716    |
| AveragePolicyStd        | 0.497211   |
| AverageReturn           | 2.33e+03   |
| Entropy                 | 2.1357     |
| EnvExecTime             | 2.05       |
| ExplainedVariance       | 0.872      |
| Iteration               | 473        |
| ItrTime                 | 13.5       |
| LossAfter               | 1.64486    |
| LossBefore              | 1.67553    |
| MaxReturn               | 3.2e+03    |
| MeanKL                  | 0.00989118 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.35e+03   |
| NumTrajs                | 8          |
| Perplexity              | 8.46301    |
| PolicyExecTime          | 0.522      |
| ProcessExecTime         | 0.0608     |
| StdReturn               | 545        |
| Time                    | 6.41e+03   |
| dLoss                   | 0.0306706  |
----------------------------------------
itr #474 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 474...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5753, #subsample_inputs: 5753
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.553      |
| AbsLearnSignalNew       | 0.553      |
| AbsLearningOld          | 0.553      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 43.8012    |
| AveragePolicyStd        | 0.496554   |
| AverageReturn           | 2.16e+03   |
| Entropy                 | 2.13252    |
| EnvExecTime             | 2.2        |
| ExplainedVariance       | 0.771      |
| Iteration               | 474        |
| ItrTime                 | 14.1       |
| LossAfter               | 0.305394   |
| LossBefore              | 0.331058   |
| MaxReturn               | 3.27e+03   |
| MeanKL                  | 0.00997496 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.22e+03   |
| NumTrajs                | 9          |
| Perplexity              | 8.43614    |
| PolicyExecTime          | 0.551      |
| ProcessExecTime         | 0.0669     |
| StdReturn               | 618        |
| Time                    | 6.42e+03   |
| dLoss                   | 0.0256633  |
----------------------------------------
itr #475 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 475...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5590, #subsample_inputs: 5590
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.598      |
| AbsLearnSignalNew       | 0.598      |
| AbsLearningOld          | 0.598      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 43.2219    |
| AveragePolicyStd        | 0.494355   |
| AverageReturn           | 2.68e+03   |
| Entropy                 | 2.11966    |
| EnvExecTime             | 2.42       |
| ExplainedVariance       | 0.665      |
| Iteration               | 475        |
| ItrTime                 | 14.1       |
| LossAfter               | -1.69428   |
| LossBefore              | -1.66382   |
| MaxReturn               | 3.36e+03   |
| MeanKL                  | 0.00959202 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.2e+03    |
| NumTrajs                | 7          |
| Perplexity              | 8.32829    |
| PolicyExecTime          | 0.618      |
| ProcessExecTime         | 0.0698     |
| StdReturn               | 793        |
| Time                    | 6.44e+03   |
| dLoss                   | 0.0304549  |
----------------------------------------
itr #476 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 476...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5223, #subsample_inputs: 5223
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.608      |
| AbsLearnSignalNew       | 0.608      |
| AbsLearningOld          | 0.608      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 43.019     |
| AveragePolicyStd        | 0.493873   |
| AverageReturn           | 2.5e+03    |
| Entropy                 | 2.11711    |
| EnvExecTime             | 2.29       |
| ExplainedVariance       | 0.769      |
| Iteration               | 476        |
| ItrTime                 | 13.4       |
| LossAfter               | 1.2394     |
| LossBefore              | 1.26434    |
| MaxReturn               | 3.23e+03   |
| MeanKL                  | 0.00644639 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.81e+03   |
| NumTrajs                | 7          |
| Perplexity              | 8.30713    |
| PolicyExecTime          | 0.576      |
| ProcessExecTime         | 0.064      |
| StdReturn               | 553        |
| Time                    | 6.45e+03   |
| dLoss                   | 0.0249374  |
----------------------------------------
itr #477 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 477...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5433, #subsample_inputs: 5433
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.645      |
| AbsLearnSignalNew       | 0.645      |
| AbsLearningOld          | 0.645      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 40.4437    |
| AveragePolicyStd        | 0.492991   |
| AverageReturn           | 3.02e+03   |
| Entropy                 | 2.11088    |
| EnvExecTime             | 2.52       |
| ExplainedVariance       | 0.811      |
| Iteration               | 477        |
| ItrTime                 | 14.3       |
| LossAfter               | -0.295578  |
| LossBefore              | -0.263273  |
| MaxReturn               | 3.43e+03   |
| MeanKL                  | 0.00989736 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.83e+03   |
| NumTrajs                | 6          |
| Perplexity              | 8.25549    |
| PolicyExecTime          | 0.638      |
| ProcessExecTime         | 0.071      |
| StdReturn               | 553        |
| Time                    | 6.46e+03   |
| dLoss                   | 0.0323046  |
----------------------------------------
itr #478 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 478...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5830, #subsample_inputs: 5830
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.642     |
| AbsLearnSignalNew       | 0.642     |
| AbsLearningOld          | 0.642     |
| AverageDiscountedReturn | 247       |
| AveragePhiLoss          | 44.4166   |
| AveragePolicyStd        | 0.493586  |
| AverageReturn           | 2.73e+03  |
| Entropy                 | 2.11407   |
| EnvExecTime             | 2.54      |
| ExplainedVariance       | 0.769     |
| Iteration               | 478       |
| ItrTime                 | 14.7      |
| LossAfter               | 1.769     |
| LossBefore              | 1.79603   |
| MaxReturn               | 3.38e+03  |
| MeanKL                  | 0.0065092 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 2.13e+03  |
| NumTrajs                | 7         |
| Perplexity              | 8.28186   |
| PolicyExecTime          | 0.644     |
| ProcessExecTime         | 0.0714    |
| StdReturn               | 449       |
| Time                    | 6.48e+03  |
| dLoss                   | 0.0270264 |
---------------------------------------
itr #479 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 479...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5413, #subsample_inputs: 5413
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.703     |
| AbsLearnSignalNew       | 0.703     |
| AbsLearningOld          | 0.703     |
| AverageDiscountedReturn | 250       |
| AveragePhiLoss          | 42.0678   |
| AveragePolicyStd        | 0.491818  |
| AverageReturn           | 2.27e+03  |
| Entropy                 | 2.10268   |
| EnvExecTime             | 2.38      |
| ExplainedVariance       | 0.884     |
| Iteration               | 479       |
| ItrTime                 | 14        |
| LossAfter               | 0.724058  |
| LossBefore              | 0.747488  |
| MaxReturn               | 2.72e+03  |
| MeanKL                  | 0.006521  |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.57e+03  |
| NumTrajs                | 8         |
| Perplexity              | 8.18806   |
| PolicyExecTime          | 0.606     |
| ProcessExecTime         | 0.0661    |
| StdReturn               | 337       |
| Time                    | 6.49e+03  |
| dLoss                   | 0.0234292 |
---------------------------------------
itr #480 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 480...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5811, #subsample_inputs: 5811
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.645      |
| AbsLearnSignalNew       | 0.645      |
| AbsLearningOld          | 0.645      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 37.4051    |
| AveragePolicyStd        | 0.488849   |
| AverageReturn           | 2.42e+03   |
| Entropy                 | 2.08499    |
| EnvExecTime             | 2.45       |
| ExplainedVariance       | 0.841      |
| Iteration               | 480        |
| ItrTime                 | 14.6       |
| LossAfter               | -0.449794  |
| LossBefore              | -0.426991  |
| MaxReturn               | 3.26e+03   |
| MeanKL                  | 0.00996204 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.8e+03    |
| NumTrajs                | 8          |
| Perplexity              | 8.04451    |
| PolicyExecTime          | 0.618      |
| ProcessExecTime         | 0.0705     |
| StdReturn               | 525        |
| Time                    | 6.51e+03   |
| dLoss                   | 0.0228034  |
----------------------------------------
itr #481 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 481...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5633, #subsample_inputs: 5633
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.673     |
| AbsLearnSignalNew       | 0.673     |
| AbsLearningOld          | 0.673     |
| AverageDiscountedReturn | 249       |
| AveragePhiLoss          | 38.6127   |
| AveragePolicyStd        | 0.491619  |
| AverageReturn           | 2.09e+03  |
| Entropy                 | 2.10327   |
| EnvExecTime             | 2.06      |
| ExplainedVariance       | 0.901     |
| Iteration               | 481       |
| ItrTime                 | 13.7      |
| LossAfter               | -0.324569 |
| LossBefore              | -0.298958 |
| MaxReturn               | 3.25e+03  |
| MeanKL                  | 0.009385  |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.59e+03  |
| NumTrajs                | 9         |
| Perplexity              | 8.19293   |
| PolicyExecTime          | 0.518     |
| ProcessExecTime         | 0.062     |
| StdReturn               | 510       |
| Time                    | 6.52e+03  |
| dLoss                   | 0.025611  |
---------------------------------------
itr #482 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 482...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5204, #subsample_inputs: 5204
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.728      |
| AbsLearnSignalNew       | 0.728      |
| AbsLearningOld          | 0.728      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 38.6464    |
| AveragePolicyStd        | 0.492286   |
| AverageReturn           | 2.46e+03   |
| Entropy                 | 2.10592    |
| EnvExecTime             | 2.12       |
| ExplainedVariance       | 0.906      |
| Iteration               | 482        |
| ItrTime                 | 13.2       |
| LossAfter               | -0.617211  |
| LossBefore              | -0.590971  |
| MaxReturn               | 3.34e+03   |
| MeanKL                  | 0.00642852 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.54e+03   |
| NumTrajs                | 7          |
| Perplexity              | 8.21462    |
| PolicyExecTime          | 0.53       |
| ProcessExecTime         | 0.0599     |
| StdReturn               | 639        |
| Time                    | 6.53e+03   |
| dLoss                   | 0.0262404  |
----------------------------------------
itr #483 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 483...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5386, #subsample_inputs: 5386
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.624      |
| AbsLearnSignalNew       | 0.624      |
| AbsLearningOld          | 0.624      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 36.505     |
| AveragePolicyStd        | 0.492406   |
| AverageReturn           | 2.58e+03   |
| Entropy                 | 2.10704    |
| EnvExecTime             | 2.25       |
| ExplainedVariance       | 0.908      |
| Iteration               | 483        |
| ItrTime                 | 13.8       |
| LossAfter               | 0.28714    |
| LossBefore              | 0.311818   |
| MaxReturn               | 3.29e+03   |
| MeanKL                  | 0.00939001 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.27e+03   |
| NumTrajs                | 7          |
| Perplexity              | 8.22385    |
| PolicyExecTime          | 0.573      |
| ProcessExecTime         | 0.0637     |
| StdReturn               | 662        |
| Time                    | 6.55e+03   |
| dLoss                   | 0.0246786  |
----------------------------------------
itr #484 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 484...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5572, #subsample_inputs: 5572
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.669      |
| AbsLearnSignalNew       | 0.669      |
| AbsLearningOld          | 0.669      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 42.6995    |
| AveragePolicyStd        | 0.492552   |
| AverageReturn           | 2.6e+03    |
| Entropy                 | 2.10824    |
| EnvExecTime             | 2.74       |
| ExplainedVariance       | 0.837      |
| Iteration               | 484        |
| ItrTime                 | 14.5       |
| LossAfter               | 1.62739    |
| LossBefore              | 1.64772    |
| MaxReturn               | 3.27e+03   |
| MeanKL                  | 0.00656794 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.88e+03   |
| NumTrajs                | 7          |
| Perplexity              | 8.2337     |
| PolicyExecTime          | 0.677      |
| ProcessExecTime         | 0.0775     |
| StdReturn               | 594        |
| Time                    | 6.56e+03   |
| dLoss                   | 0.0203323  |
----------------------------------------
itr #485 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 485...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5193, #subsample_inputs: 5193
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.637      |
| AbsLearnSignalNew       | 0.637      |
| AbsLearningOld          | 0.637      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 38.7348    |
| AveragePolicyStd        | 0.491194   |
| AverageReturn           | 2.46e+03   |
| Entropy                 | 2.10015    |
| EnvExecTime             | 2.32       |
| ExplainedVariance       | 0.855      |
| Iteration               | 485        |
| ItrTime                 | 13.5       |
| LossAfter               | -1.53127   |
| LossBefore              | -1.50327   |
| MaxReturn               | 3.21e+03   |
| MeanKL                  | 0.00990211 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.6e+03    |
| NumTrajs                | 7          |
| Perplexity              | 8.16742    |
| PolicyExecTime          | 0.592      |
| ProcessExecTime         | 0.0655     |
| StdReturn               | 646        |
| Time                    | 6.58e+03   |
| dLoss                   | 0.0280048  |
----------------------------------------
itr #486 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 486...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5411, #subsample_inputs: 5411
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.606     |
| AbsLearnSignalNew       | 0.606     |
| AbsLearningOld          | 0.606     |
| AverageDiscountedReturn | 246       |
| AveragePhiLoss          | 54.5781   |
| AveragePolicyStd        | 0.488541  |
| AverageReturn           | 2.54e+03  |
| Entropy                 | 2.08387   |
| EnvExecTime             | 2.36      |
| ExplainedVariance       | 0.706     |
| Iteration               | 486       |
| ItrTime                 | 13.9      |
| LossAfter               | -1.02062  |
| LossBefore              | -0.998329 |
| MaxReturn               | 3.34e+03  |
| MeanKL                  | 0.0066474 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.43e+03  |
| NumTrajs                | 7         |
| Perplexity              | 8.03548   |
| PolicyExecTime          | 0.598     |
| ProcessExecTime         | 0.0671    |
| StdReturn               | 848       |
| Time                    | 6.59e+03  |
| dLoss                   | 0.0222928 |
---------------------------------------
itr #487 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 487...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5022, #subsample_inputs: 5022
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.66       |
| AbsLearnSignalNew       | 0.66       |
| AbsLearningOld          | 0.66       |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 37.1454    |
| AveragePolicyStd        | 0.488235   |
| AverageReturn           | 2.39e+03   |
| Entropy                 | 2.08153    |
| EnvExecTime             | 2.07       |
| ExplainedVariance       | 0.816      |
| Iteration               | 487        |
| ItrTime                 | 12.9       |
| LossAfter               | 0.265453   |
| LossBefore              | 0.29477    |
| MaxReturn               | 3.14e+03   |
| MeanKL                  | 0.00998296 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.61e+03   |
| NumTrajs                | 7          |
| Perplexity              | 8.01674    |
| PolicyExecTime          | 0.525      |
| ProcessExecTime         | 0.0593     |
| StdReturn               | 515        |
| Time                    | 6.6e+03    |
| dLoss                   | 0.0293171  |
----------------------------------------
itr #488 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 488...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5569, #subsample_inputs: 5569
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.667      |
| AbsLearnSignalNew       | 0.667      |
| AbsLearningOld          | 0.667      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 38.043     |
| AveragePolicyStd        | 0.489051   |
| AverageReturn           | 2.63e+03   |
| Entropy                 | 2.08692    |
| EnvExecTime             | 2.23       |
| ExplainedVariance       | 0.793      |
| Iteration               | 488        |
| ItrTime                 | 13.9       |
| LossAfter               | -0.912139  |
| LossBefore              | -0.883503  |
| MaxReturn               | 3.2e+03    |
| MeanKL                  | 0.00985642 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.68e+03   |
| NumTrajs                | 7          |
| Perplexity              | 8.06003    |
| PolicyExecTime          | 0.576      |
| ProcessExecTime         | 0.0639     |
| StdReturn               | 605        |
| Time                    | 6.62e+03   |
| dLoss                   | 0.0286355  |
----------------------------------------
itr #489 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 489...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5080, #subsample_inputs: 5080
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.686      |
| AbsLearnSignalNew       | 0.686      |
| AbsLearningOld          | 0.686      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 34.0888    |
| AveragePolicyStd        | 0.488509   |
| AverageReturn           | 2.4e+03    |
| Entropy                 | 2.08394    |
| EnvExecTime             | 2.4        |
| ExplainedVariance       | 0.862      |
| Iteration               | 489        |
| ItrTime                 | 13.4       |
| LossAfter               | -0.461125  |
| LossBefore              | -0.423474  |
| MaxReturn               | 3.19e+03   |
| MeanKL                  | 0.00983691 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.49e+03   |
| NumTrajs                | 7          |
| Perplexity              | 8.0361     |
| PolicyExecTime          | 0.585      |
| ProcessExecTime         | 0.0682     |
| StdReturn               | 564        |
| Time                    | 6.63e+03   |
| dLoss                   | 0.0376507  |
----------------------------------------
itr #490 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 490...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5722, #subsample_inputs: 5722
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.682      |
| AbsLearnSignalNew       | 0.682      |
| AbsLearningOld          | 0.682      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 42.8216    |
| AveragePolicyStd        | 0.488341   |
| AverageReturn           | 2.39e+03   |
| Entropy                 | 2.08321    |
| EnvExecTime             | 2.19       |
| ExplainedVariance       | 0.886      |
| Iteration               | 490        |
| ItrTime                 | 14.1       |
| LossAfter               | 0.932976   |
| LossBefore              | 0.955961   |
| MaxReturn               | 3.22e+03   |
| MeanKL                  | 0.00996824 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.79e+03   |
| NumTrajs                | 8          |
| Perplexity              | 8.03022    |
| PolicyExecTime          | 0.558      |
| ProcessExecTime         | 0.064      |
| StdReturn               | 440        |
| Time                    | 6.65e+03   |
| dLoss                   | 0.0229847  |
----------------------------------------
itr #491 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 491...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5578, #subsample_inputs: 5578
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.66       |
| AbsLearnSignalNew       | 0.66       |
| AbsLearningOld          | 0.66       |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 46.3747    |
| AveragePolicyStd        | 0.486199   |
| AverageReturn           | 2.32e+03   |
| Entropy                 | 2.06898    |
| EnvExecTime             | 2.49       |
| ExplainedVariance       | 0.795      |
| Iteration               | 491        |
| ItrTime                 | 14.2       |
| LossAfter               | -2.22305   |
| LossBefore              | -2.19736   |
| MaxReturn               | 3.27e+03   |
| MeanKL                  | 0.00653988 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.35e+03   |
| NumTrajs                | 8          |
| Perplexity              | 7.91671    |
| PolicyExecTime          | 0.623      |
| ProcessExecTime         | 0.07       |
| StdReturn               | 647        |
| Time                    | 6.66e+03   |
| dLoss                   | 0.0256884  |
----------------------------------------
itr #492 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 492...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5683, #subsample_inputs: 5683
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.635      |
| AbsLearnSignalNew       | 0.635      |
| AbsLearningOld          | 0.635      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 40.9235    |
| AveragePolicyStd        | 0.485391   |
| AverageReturn           | 2.32e+03   |
| Entropy                 | 2.06396    |
| EnvExecTime             | 2.4        |
| ExplainedVariance       | 0.803      |
| Iteration               | 492        |
| ItrTime                 | 14.3       |
| LossAfter               | -1.0973    |
| LossBefore              | -1.07458   |
| MaxReturn               | 3.17e+03   |
| MeanKL                  | 0.00660929 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.66e+03   |
| NumTrajs                | 8          |
| Perplexity              | 7.87706    |
| PolicyExecTime          | 0.613      |
| ProcessExecTime         | 0.0679     |
| StdReturn               | 557        |
| Time                    | 6.67e+03   |
| dLoss                   | 0.0227197  |
----------------------------------------
itr #493 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 493...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5676, #subsample_inputs: 5676
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.642      |
| AbsLearnSignalNew       | 0.642      |
| AbsLearningOld          | 0.642      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 47.995     |
| AveragePolicyStd        | 0.485349   |
| AverageReturn           | 2.36e+03   |
| Entropy                 | 2.06292    |
| EnvExecTime             | 2.42       |
| ExplainedVariance       | 0.875      |
| Iteration               | 493        |
| ItrTime                 | 14.3       |
| LossAfter               | -0.354057  |
| LossBefore              | -0.322322  |
| MaxReturn               | 3.14e+03   |
| MeanKL                  | 0.00955798 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.77e+03   |
| NumTrajs                | 8          |
| Perplexity              | 7.86892    |
| PolicyExecTime          | 0.613      |
| ProcessExecTime         | 0.0686     |
| StdReturn               | 497        |
| Time                    | 6.69e+03   |
| dLoss                   | 0.031735   |
----------------------------------------
itr #494 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 494...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5222, #subsample_inputs: 5222
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.613     |
| AbsLearnSignalNew       | 0.613     |
| AbsLearningOld          | 0.613     |
| AverageDiscountedReturn | 247       |
| AveragePhiLoss          | 41.5748   |
| AveragePolicyStd        | 0.485474  |
| AverageReturn           | 2.85e+03  |
| Entropy                 | 2.06436   |
| EnvExecTime             | 2.58      |
| ExplainedVariance       | 0.811     |
| Iteration               | 494       |
| ItrTime                 | 13.8      |
| LossAfter               | 0.144502  |
| LossBefore              | 0.166493  |
| MaxReturn               | 3.26e+03  |
| MeanKL                  | 0.0064669 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 2.08e+03  |
| NumTrajs                | 6         |
| Perplexity              | 7.88022   |
| PolicyExecTime          | 0.657     |
| ProcessExecTime         | 0.072     |
| StdReturn               | 458       |
| Time                    | 6.7e+03   |
| dLoss                   | 0.0219907 |
---------------------------------------
itr #495 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 495...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5521, #subsample_inputs: 5521
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.632      |
| AbsLearnSignalNew       | 0.632      |
| AbsLearningOld          | 0.632      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 44.2671    |
| AveragePolicyStd        | 0.485209   |
| AverageReturn           | 2.56e+03   |
| Entropy                 | 2.06215    |
| EnvExecTime             | 2.34       |
| ExplainedVariance       | 0.861      |
| Iteration               | 495        |
| ItrTime                 | 14         |
| LossAfter               | -0.825589  |
| LossBefore              | -0.802006  |
| MaxReturn               | 3.27e+03   |
| MeanKL                  | 0.00648543 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.66e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.86282    |
| PolicyExecTime          | 0.596      |
| ProcessExecTime         | 0.0661     |
| StdReturn               | 646        |
| Time                    | 6.72e+03   |
| dLoss                   | 0.0235835  |
----------------------------------------
itr #496 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 496...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5078, #subsample_inputs: 5078
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.703      |
| AbsLearnSignalNew       | 0.703      |
| AbsLearningOld          | 0.703      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 42.9893    |
| AveragePolicyStd        | 0.484082   |
| AverageReturn           | 2.68e+03   |
| Entropy                 | 2.05541    |
| EnvExecTime             | 2.56       |
| ExplainedVariance       | 0.876      |
| Iteration               | 496        |
| ItrTime                 | 13.6       |
| LossAfter               | -0.472847  |
| LossBefore              | -0.441044  |
| MaxReturn               | 3.22e+03   |
| MeanKL                  | 0.00987359 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.8e+03    |
| NumTrajs                | 6          |
| Perplexity              | 7.81003    |
| PolicyExecTime          | 0.64       |
| ProcessExecTime         | 0.0697     |
| StdReturn               | 617        |
| Time                    | 6.73e+03   |
| dLoss                   | 0.0318031  |
----------------------------------------
itr #497 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 497...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5618, #subsample_inputs: 5618
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.529      |
| AbsLearnSignalNew       | 0.529      |
| AbsLearningOld          | 0.529      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 84.6302    |
| AveragePolicyStd        | 0.48438    |
| AverageReturn           | 2.97e+03   |
| Entropy                 | 2.05687    |
| EnvExecTime             | 2.99       |
| ExplainedVariance       | 0.792      |
| Iteration               | 497        |
| ItrTime                 | 14.8       |
| LossAfter               | -0.338554  |
| LossBefore              | -0.25899   |
| MaxReturn               | 3.2e+03    |
| MeanKL                  | 0.00943416 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 2.65e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.82144    |
| PolicyExecTime          | 0.75       |
| ProcessExecTime         | 0.0816     |
| StdReturn               | 176        |
| Time                    | 6.75e+03   |
| dLoss                   | 0.0795642  |
----------------------------------------
itr #498 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 498...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5411, #subsample_inputs: 5411
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.683     |
| AbsLearnSignalNew       | 0.683     |
| AbsLearningOld          | 0.683     |
| AverageDiscountedReturn | 244       |
| AveragePhiLoss          | 46.0389   |
| AveragePolicyStd        | 0.485903  |
| AverageReturn           | 2.9e+03   |
| Entropy                 | 2.06573   |
| EnvExecTime             | 2.47      |
| ExplainedVariance       | 0.872     |
| Iteration               | 498       |
| ItrTime                 | 14.1      |
| LossAfter               | 1.73553   |
| LossBefore              | 1.75787   |
| MaxReturn               | 3.22e+03  |
| MeanKL                  | 0.0064935 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 2.03e+03  |
| NumTrajs                | 6         |
| Perplexity              | 7.89105   |
| PolicyExecTime          | 0.635     |
| ProcessExecTime         | 0.0695    |
| StdReturn               | 426       |
| Time                    | 6.76e+03  |
| dLoss                   | 0.0223339 |
---------------------------------------
itr #499 | 
Mem: 737.148438
Obtaining samples...
Obtaining samples for iteration 499...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 6144, #subsample_inputs: 6144
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.585      |
| AbsLearnSignalNew       | 0.585      |
| AbsLearningOld          | 0.584      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 37.3083    |
| AveragePolicyStd        | 0.484118   |
| AverageReturn           | 2.86e+03   |
| Entropy                 | 2.0543     |
| EnvExecTime             | 2.53       |
| ExplainedVariance       | 0.823      |
| Iteration               | 499        |
| ItrTime                 | 15.1       |
| LossAfter               | 1.90699    |
| LossBefore              | 1.93289    |
| MaxReturn               | 3.3e+03    |
| MeanKL                  | 0.00995301 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 2.17e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.80136    |
| PolicyExecTime          | 0.653      |
| ProcessExecTime         | 0.0734     |
| StdReturn               | 469        |
| Time                    | 6.77e+03   |
| dLoss                   | 0.0258962  |
----------------------------------------
itr #500 | 
Mem: 737.714844
Obtaining samples...
Obtaining samples for iteration 500...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5293, #subsample_inputs: 5293
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.663      |
| AbsLearnSignalNew       | 0.663      |
| AbsLearningOld          | 0.663      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 44.0938    |
| AveragePolicyStd        | 0.484747   |
| AverageReturn           | 2.81e+03   |
| Entropy                 | 2.0586     |
| EnvExecTime             | 2.15       |
| ExplainedVariance       | 0.888      |
| Iteration               | 500        |
| ItrTime                 | 13.4       |
| LossAfter               | 1.42584    |
| LossBefore              | 1.44795    |
| MaxReturn               | 3.2e+03    |
| MeanKL                  | 0.00644286 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.51e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.83497    |
| PolicyExecTime          | 0.54       |
| ProcessExecTime         | 0.0632     |
| StdReturn               | 600        |
| Time                    | 6.79e+03   |
| dLoss                   | 0.0221145  |
----------------------------------------
itr #501 | 
Mem: 738.148438
Obtaining samples...
Obtaining samples for iteration 501...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5030, #subsample_inputs: 5030
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.533      |
| AbsLearnSignalNew       | 0.533      |
| AbsLearningOld          | 0.533      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 40.4754    |
| AveragePolicyStd        | 0.485139   |
| AverageReturn           | 2.38e+03   |
| Entropy                 | 2.06055    |
| EnvExecTime             | 2.21       |
| ExplainedVariance       | 0.734      |
| Iteration               | 501        |
| ItrTime                 | 13         |
| LossAfter               | -1.40029   |
| LossBefore              | -1.37027   |
| MaxReturn               | 3.24e+03   |
| MeanKL                  | 0.00661369 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.85e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.85031    |
| PolicyExecTime          | 0.545      |
| ProcessExecTime         | 0.0628     |
| StdReturn               | 448        |
| Time                    | 6.8e+03    |
| dLoss                   | 0.0300137  |
----------------------------------------
itr #502 | 
Mem: 738.148438
Obtaining samples...
Obtaining samples for iteration 502...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5456, #subsample_inputs: 5456
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.652      |
| AbsLearnSignalNew       | 0.652      |
| AbsLearningOld          | 0.651      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 48.6081    |
| AveragePolicyStd        | 0.485431   |
| AverageReturn           | 2.29e+03   |
| Entropy                 | 2.06184    |
| EnvExecTime             | 2.2        |
| ExplainedVariance       | 0.805      |
| Iteration               | 502        |
| ItrTime                 | 13.8       |
| LossAfter               | -0.718319  |
| LossBefore              | -0.684807  |
| MaxReturn               | 3.14e+03   |
| MeanKL                  | 0.00976744 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.72e+03   |
| NumTrajs                | 8          |
| Perplexity              | 7.8604     |
| PolicyExecTime          | 0.557      |
| ProcessExecTime         | 0.0638     |
| StdReturn               | 495        |
| Time                    | 6.82e+03   |
| dLoss                   | 0.0335125  |
----------------------------------------
itr #503 | 
Mem: 738.148438
Obtaining samples...
Obtaining samples for iteration 503...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5257, #subsample_inputs: 5257
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.665      |
| AbsLearnSignalNew       | 0.665      |
| AbsLearningOld          | 0.664      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 43.6273    |
| AveragePolicyStd        | 0.48624    |
| AverageReturn           | 2.21e+03   |
| Entropy                 | 2.06795    |
| EnvExecTime             | 2.02       |
| ExplainedVariance       | 0.852      |
| Iteration               | 503        |
| ItrTime                 | 13.1       |
| LossAfter               | 0.00372575 |
| LossBefore              | 0.0328091  |
| MaxReturn               | 3.3e+03    |
| MeanKL                  | 0.00983579 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.25e+03   |
| NumTrajs                | 8          |
| Perplexity              | 7.90859    |
| PolicyExecTime          | 0.51       |
| ProcessExecTime         | 0.0599     |
| StdReturn               | 767        |
| Time                    | 6.83e+03   |
| dLoss                   | 0.0290834  |
----------------------------------------
itr #504 | 
Mem: 738.148438
Obtaining samples...
Obtaining samples for iteration 504...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5920, #subsample_inputs: 5920
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.572      |
| AbsLearnSignalNew       | 0.572      |
| AbsLearningOld          | 0.572      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 44.9708    |
| AveragePolicyStd        | 0.487014   |
| AverageReturn           | 2.38e+03   |
| Entropy                 | 2.07154    |
| EnvExecTime             | 3.06       |
| ExplainedVariance       | 0.651      |
| Iteration               | 504        |
| ItrTime                 | 15.5       |
| LossAfter               | 0.191259   |
| LossBefore              | 0.209795   |
| MaxReturn               | 3.27e+03   |
| MeanKL                  | 0.00654028 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 988        |
| NumTrajs                | 8          |
| Perplexity              | 7.93703    |
| PolicyExecTime          | 0.786      |
| ProcessExecTime         | 0.0836     |
| StdReturn               | 839        |
| Time                    | 6.84e+03   |
| dLoss                   | 0.0185357  |
----------------------------------------
itr #505 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 505...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5335, #subsample_inputs: 5335
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.661      |
| AbsLearnSignalNew       | 0.661      |
| AbsLearningOld          | 0.661      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 43.2086    |
| AveragePolicyStd        | 0.486799   |
| AverageReturn           | 2.5e+03    |
| Entropy                 | 2.07073    |
| EnvExecTime             | 2.1        |
| ExplainedVariance       | 0.818      |
| Iteration               | 505        |
| ItrTime                 | 13.6       |
| LossAfter               | 0.374069   |
| LossBefore              | 0.397899   |
| MaxReturn               | 3.08e+03   |
| MeanKL                  | 0.00964301 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.57e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.93058    |
| PolicyExecTime          | 0.534      |
| ProcessExecTime         | 0.0617     |
| StdReturn               | 517        |
| Time                    | 6.86e+03   |
| dLoss                   | 0.0238302  |
----------------------------------------
itr #506 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 506...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5493, #subsample_inputs: 5493
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.508      |
| AbsLearnSignalNew       | 0.508      |
| AbsLearningOld          | 0.508      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 48.4561    |
| AveragePolicyStd        | 0.487035   |
| AverageReturn           | 2.6e+03    |
| Entropy                 | 2.07225    |
| EnvExecTime             | 2.28       |
| ExplainedVariance       | 0.718      |
| Iteration               | 506        |
| ItrTime                 | 13.8       |
| LossAfter               | 0.914398   |
| LossBefore              | 0.936087   |
| MaxReturn               | 3.29e+03   |
| MeanKL                  | 0.00690898 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.52e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.94266    |
| PolicyExecTime          | 0.586      |
| ProcessExecTime         | 0.065      |
| StdReturn               | 617        |
| Time                    | 6.87e+03   |
| dLoss                   | 0.0216892  |
----------------------------------------
itr #507 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 507...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5049, #subsample_inputs: 5049
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.66       |
| AbsLearnSignalNew       | 0.66       |
| AbsLearningOld          | 0.66       |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 42.5023    |
| AveragePolicyStd        | 0.486164   |
| AverageReturn           | 2.78e+03   |
| Entropy                 | 2.0668     |
| EnvExecTime             | 2.15       |
| ExplainedVariance       | 0.849      |
| Iteration               | 507        |
| ItrTime                 | 13         |
| LossAfter               | 0.935976   |
| LossBefore              | 0.963511   |
| MaxReturn               | 3.29e+03   |
| MeanKL                  | 0.00953266 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 2.12e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.89953    |
| PolicyExecTime          | 0.553      |
| ProcessExecTime         | 0.0611     |
| StdReturn               | 478        |
| Time                    | 6.88e+03   |
| dLoss                   | 0.0275352  |
----------------------------------------
itr #508 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 508...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5273, #subsample_inputs: 5273
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.58       |
| AbsLearnSignalNew       | 0.58       |
| AbsLearningOld          | 0.58       |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 41.6553    |
| AveragePolicyStd        | 0.487253   |
| AverageReturn           | 2.49e+03   |
| Entropy                 | 2.07349    |
| EnvExecTime             | 2.27       |
| ExplainedVariance       | 0.766      |
| Iteration               | 508        |
| ItrTime                 | 13.5       |
| LossAfter               | 0.562068   |
| LossBefore              | 0.602866   |
| MaxReturn               | 3.32e+03   |
| MeanKL                  | 0.00994905 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.71e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.95252    |
| PolicyExecTime          | 0.583      |
| ProcessExecTime         | 0.0637     |
| StdReturn               | 664        |
| Time                    | 6.9e+03    |
| dLoss                   | 0.0407982  |
----------------------------------------
itr #509 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 509...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5230, #subsample_inputs: 5230
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.582      |
| AbsLearnSignalNew       | 0.582      |
| AbsLearningOld          | 0.582      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 46.7155    |
| AveragePolicyStd        | 0.485734   |
| AverageReturn           | 2.48e+03   |
| Entropy                 | 2.06491    |
| EnvExecTime             | 2.32       |
| ExplainedVariance       | 0.776      |
| Iteration               | 509        |
| ItrTime                 | 13.5       |
| LossAfter               | -0.0673235 |
| LossBefore              | -0.0382542 |
| MaxReturn               | 3.12e+03   |
| MeanKL                  | 0.00649031 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.74e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.88457    |
| PolicyExecTime          | 0.596      |
| ProcessExecTime         | 0.0656     |
| StdReturn               | 536        |
| Time                    | 6.91e+03   |
| dLoss                   | 0.0290693  |
----------------------------------------
itr #510 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 510...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5804, #subsample_inputs: 5804
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.644      |
| AbsLearnSignalNew       | 0.644      |
| AbsLearningOld          | 0.644      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 42.855     |
| AveragePolicyStd        | 0.485459   |
| AverageReturn           | 2.42e+03   |
| Entropy                 | 2.06253    |
| EnvExecTime             | 2.56       |
| ExplainedVariance       | 0.865      |
| Iteration               | 510        |
| ItrTime                 | 14.6       |
| LossAfter               | 0.456366   |
| LossBefore              | 0.482946   |
| MaxReturn               | 3.27e+03   |
| MeanKL                  | 0.00986442 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.34e+03   |
| NumTrajs                | 8          |
| Perplexity              | 7.86585    |
| PolicyExecTime          | 0.648      |
| ProcessExecTime         | 0.072      |
| StdReturn               | 703        |
| Time                    | 6.93e+03   |
| dLoss                   | 0.0265802  |
----------------------------------------
itr #511 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 511...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5565, #subsample_inputs: 5565
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.64       |
| AbsLearnSignalNew       | 0.64       |
| AbsLearningOld          | 0.64       |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 37.9536    |
| AveragePolicyStd        | 0.486466   |
| AverageReturn           | 2.64e+03   |
| Entropy                 | 2.06831    |
| EnvExecTime             | 2.33       |
| ExplainedVariance       | 0.768      |
| Iteration               | 511        |
| ItrTime                 | 14         |
| LossAfter               | -0.317654  |
| LossBefore              | -0.270859  |
| MaxReturn               | 3.36e+03   |
| MeanKL                  | 0.00642224 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.35e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.91147    |
| PolicyExecTime          | 0.587      |
| ProcessExecTime         | 0.0689     |
| StdReturn               | 760        |
| Time                    | 6.94e+03   |
| dLoss                   | 0.046795   |
----------------------------------------
itr #512 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 512...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5245, #subsample_inputs: 5245
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.613      |
| AbsLearnSignalNew       | 0.613      |
| AbsLearningOld          | 0.613      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 38.6503    |
| AveragePolicyStd        | 0.486656   |
| AverageReturn           | 2.5e+03    |
| Entropy                 | 2.06835    |
| EnvExecTime             | 2.43       |
| ExplainedVariance       | 0.759      |
| Iteration               | 512        |
| ItrTime                 | 13.6       |
| LossAfter               | 0.359768   |
| LossBefore              | 0.3841     |
| MaxReturn               | 3.19e+03   |
| MeanKL                  | 0.00648744 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.83e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.91176    |
| PolicyExecTime          | 0.621      |
| ProcessExecTime         | 0.0677     |
| StdReturn               | 508        |
| Time                    | 6.95e+03   |
| dLoss                   | 0.0243318  |
----------------------------------------
itr #513 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 513...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5466, #subsample_inputs: 5466
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.635     |
| AbsLearnSignalNew       | 0.635     |
| AbsLearningOld          | 0.635     |
| AverageDiscountedReturn | 247       |
| AveragePhiLoss          | 39.216    |
| AveragePolicyStd        | 0.486695  |
| AverageReturn           | 2.51e+03  |
| Entropy                 | 2.06942   |
| EnvExecTime             | 2.24      |
| ExplainedVariance       | 0.828     |
| Iteration               | 513       |
| ItrTime                 | 13.7      |
| LossAfter               | -0.875978 |
| LossBefore              | -0.853141 |
| MaxReturn               | 3.12e+03  |
| MeanKL                  | 0.0097943 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.49e+03  |
| NumTrajs                | 7         |
| Perplexity              | 7.92021   |
| PolicyExecTime          | 0.57      |
| ProcessExecTime         | 0.064     |
| StdReturn               | 610       |
| Time                    | 6.97e+03  |
| dLoss                   | 0.0228372 |
---------------------------------------
itr #514 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 514...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5148, #subsample_inputs: 5148
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.618      |
| AbsLearnSignalNew       | 0.618      |
| AbsLearningOld          | 0.618      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 49.6839    |
| AveragePolicyStd        | 0.488023   |
| AverageReturn           | 2.79e+03   |
| Entropy                 | 2.07743    |
| EnvExecTime             | 2.28       |
| ExplainedVariance       | 0.776      |
| Iteration               | 514        |
| ItrTime                 | 13.4       |
| LossAfter               | -0.659941  |
| LossBefore              | -0.596305  |
| MaxReturn               | 3.36e+03   |
| MeanKL                  | 0.00651939 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.53e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.98393    |
| PolicyExecTime          | 0.584      |
| ProcessExecTime         | 0.0639     |
| StdReturn               | 652        |
| Time                    | 6.98e+03   |
| dLoss                   | 0.0636361  |
----------------------------------------
itr #515 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 515...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5570, #subsample_inputs: 5570
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.602      |
| AbsLearnSignalNew       | 0.602      |
| AbsLearningOld          | 0.602      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 39.538     |
| AveragePolicyStd        | 0.488998   |
| AverageReturn           | 2.31e+03   |
| Entropy                 | 2.08401    |
| EnvExecTime             | 2.2        |
| ExplainedVariance       | 0.703      |
| Iteration               | 515        |
| ItrTime                 | 13.8       |
| LossAfter               | -1.84566   |
| LossBefore              | -1.81217   |
| MaxReturn               | 3.14e+03   |
| MeanKL                  | 0.00990481 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.9e+03    |
| NumTrajs                | 8          |
| Perplexity              | 8.03659    |
| PolicyExecTime          | 0.554      |
| ProcessExecTime         | 0.0651     |
| StdReturn               | 368        |
| Time                    | 7e+03      |
| dLoss                   | 0.0334841  |
----------------------------------------
itr #516 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 516...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5231, #subsample_inputs: 5231
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.616      |
| AbsLearnSignalNew       | 0.616      |
| AbsLearningOld          | 0.616      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 41.1962    |
| AveragePolicyStd        | 0.489077   |
| AverageReturn           | 2.46e+03   |
| Entropy                 | 2.08469    |
| EnvExecTime             | 2.27       |
| ExplainedVariance       | 0.837      |
| Iteration               | 516        |
| ItrTime                 | 13.5       |
| LossAfter               | -0.691714  |
| LossBefore              | -0.662191  |
| MaxReturn               | 3.29e+03   |
| MeanKL                  | 0.00986056 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.65e+03   |
| NumTrajs                | 7          |
| Perplexity              | 8.04207    |
| PolicyExecTime          | 0.583      |
| ProcessExecTime         | 0.0634     |
| StdReturn               | 697        |
| Time                    | 7.01e+03   |
| dLoss                   | 0.0295222  |
----------------------------------------
itr #517 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 517...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5069, #subsample_inputs: 5069
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.744      |
| AbsLearnSignalNew       | 0.744      |
| AbsLearningOld          | 0.745      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 40.2063    |
| AveragePolicyStd        | 0.489103   |
| AverageReturn           | 2.34e+03   |
| Entropy                 | 2.08502    |
| EnvExecTime             | 1.97       |
| ExplainedVariance       | 0.853      |
| Iteration               | 517        |
| ItrTime                 | 12.8       |
| LossAfter               | -1.74177   |
| LossBefore              | -1.71977   |
| MaxReturn               | 2.88e+03   |
| MeanKL                  | 0.00641747 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 2.05e+03   |
| NumTrajs                | 7          |
| Perplexity              | 8.04475    |
| PolicyExecTime          | 0.507      |
| ProcessExecTime         | 0.0576     |
| StdReturn               | 326        |
| Time                    | 7.02e+03   |
| dLoss                   | 0.0220003  |
----------------------------------------
itr #518 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 518...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5326, #subsample_inputs: 5326
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.739      |
| AbsLearnSignalNew       | 0.739      |
| AbsLearningOld          | 0.739      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 38.2264    |
| AveragePolicyStd        | 0.488032   |
| AverageReturn           | 2.78e+03   |
| Entropy                 | 2.07838    |
| EnvExecTime             | 2.05       |
| ExplainedVariance       | 0.881      |
| Iteration               | 518        |
| ItrTime                 | 13.5       |
| LossAfter               | -0.507673  |
| LossBefore              | -0.48069   |
| MaxReturn               | 3.13e+03   |
| MeanKL                  | 0.00999191 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.82e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.99153    |
| PolicyExecTime          | 0.524      |
| ProcessExecTime         | 0.0607     |
| StdReturn               | 460        |
| Time                    | 7.04e+03   |
| dLoss                   | 0.0269828  |
----------------------------------------
itr #519 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 519...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5504, #subsample_inputs: 5504
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.669      |
| AbsLearnSignalNew       | 0.669      |
| AbsLearningOld          | 0.669      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 39.0157    |
| AveragePolicyStd        | 0.487038   |
| AverageReturn           | 2.93e+03   |
| Entropy                 | 2.07205    |
| EnvExecTime             | 2.67       |
| ExplainedVariance       | 0.875      |
| Iteration               | 519        |
| ItrTime                 | 14.3       |
| LossAfter               | -1.0881    |
| LossBefore              | -1.0576    |
| MaxReturn               | 3.22e+03   |
| MeanKL                  | 0.00967073 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 2.39e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.94106    |
| PolicyExecTime          | 0.683      |
| ProcessExecTime         | 0.0741     |
| StdReturn               | 285        |
| Time                    | 7.05e+03   |
| dLoss                   | 0.0304974  |
----------------------------------------
itr #520 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 520...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5880, #subsample_inputs: 5880
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.564      |
| AbsLearnSignalNew       | 0.564      |
| AbsLearningOld          | 0.564      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 38.4343    |
| AveragePolicyStd        | 0.486838   |
| AverageReturn           | 2.71e+03   |
| Entropy                 | 2.07121    |
| EnvExecTime             | 2.59       |
| ExplainedVariance       | 0.725      |
| Iteration               | 520        |
| ItrTime                 | 14.8       |
| LossAfter               | 0.0687751  |
| LossBefore              | 0.0903953  |
| MaxReturn               | 3.2e+03    |
| MeanKL                  | 0.00645335 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.66e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.93439    |
| PolicyExecTime          | 0.659      |
| ProcessExecTime         | 0.0722     |
| StdReturn               | 585        |
| Time                    | 7.07e+03   |
| dLoss                   | 0.0216201  |
----------------------------------------
itr #521 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 521...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5000, #subsample_inputs: 5000
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.639      |
| AbsLearnSignalNew       | 0.639      |
| AbsLearningOld          | 0.639      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 42.5982    |
| AveragePolicyStd        | 0.485478   |
| AverageReturn           | 3.06e+03   |
| Entropy                 | 2.06361    |
| EnvExecTime             | 1.53       |
| ExplainedVariance       | 0.879      |
| Iteration               | 521        |
| ItrTime                 | 12.2       |
| LossAfter               | 1.26962    |
| LossBefore              | 1.28429    |
| MaxReturn               | 3.16e+03   |
| MeanKL                  | 0.00640195 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 2.95e+03   |
| NumTrajs                | 5          |
| Perplexity              | 7.87433    |
| PolicyExecTime          | 0.395      |
| ProcessExecTime         | 0.0493     |
| StdReturn               | 76         |
| Time                    | 7.08e+03   |
| dLoss                   | 0.0146656  |
----------------------------------------
itr #522 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 522...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5582, #subsample_inputs: 5582
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.468      |
| AbsLearnSignalNew       | 0.468      |
| AbsLearningOld          | 0.468      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 36.0776    |
| AveragePolicyStd        | 0.485417   |
| AverageReturn           | 2.99e+03   |
| Entropy                 | 2.06264    |
| EnvExecTime             | 2.93       |
| ExplainedVariance       | 0.772      |
| Iteration               | 522        |
| ItrTime                 | 14.7       |
| LossAfter               | -0.0576444 |
| LossBefore              | -0.026835  |
| MaxReturn               | 3.22e+03   |
| MeanKL                  | 0.00973167 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 2.38e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.86668    |
| PolicyExecTime          | 0.73       |
| ProcessExecTime         | 0.0812     |
| StdReturn               | 290        |
| Time                    | 7.09e+03   |
| dLoss                   | 0.0308094  |
----------------------------------------
itr #523 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 523...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5920, #subsample_inputs: 5920
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.617     |
| AbsLearnSignalNew       | 0.617     |
| AbsLearningOld          | 0.617     |
| AverageDiscountedReturn | 248       |
| AveragePhiLoss          | 43.0421   |
| AveragePolicyStd        | 0.484065  |
| AverageReturn           | 2.76e+03  |
| Entropy                 | 2.05546   |
| EnvExecTime             | 2.61      |
| ExplainedVariance       | 0.749     |
| Iteration               | 523       |
| ItrTime                 | 15        |
| LossAfter               | -0.251992 |
| LossBefore              | -0.224248 |
| MaxReturn               | 3.32e+03  |
| MeanKL                  | 0.006424  |
| MeanKLBefore            | 0.0       |
| MinReturn               | 2.13e+03  |
| NumTrajs                | 7         |
| Perplexity              | 7.81043   |
| PolicyExecTime          | 0.664     |
| ProcessExecTime         | 0.0768    |
| StdReturn               | 531       |
| Time                    | 7.11e+03  |
| dLoss                   | 0.027744  |
---------------------------------------
itr #524 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 524...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5262, #subsample_inputs: 5262
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.549      |
| AbsLearnSignalNew       | 0.549      |
| AbsLearningOld          | 0.549      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 46.4677    |
| AveragePolicyStd        | 0.48491    |
| AverageReturn           | 2.52e+03   |
| Entropy                 | 2.06078    |
| EnvExecTime             | 2.24       |
| ExplainedVariance       | 0.726      |
| Iteration               | 524        |
| ItrTime                 | 13.6       |
| LossAfter               | 0.566373   |
| LossBefore              | 0.594493   |
| MaxReturn               | 3.27e+03   |
| MeanKL                  | 0.00648059 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.61e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.85212    |
| PolicyExecTime          | 0.573      |
| ProcessExecTime         | 0.0642     |
| StdReturn               | 539        |
| Time                    | 7.12e+03   |
| dLoss                   | 0.0281197  |
----------------------------------------
itr #525 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 525...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5137, #subsample_inputs: 5137
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.682      |
| AbsLearnSignalNew       | 0.682      |
| AbsLearningOld          | 0.682      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 44.845     |
| AveragePolicyStd        | 0.484168   |
| AverageReturn           | 2.75e+03   |
| Entropy                 | 2.05819    |
| EnvExecTime             | 2.5        |
| ExplainedVariance       | 0.806      |
| Iteration               | 525        |
| ItrTime                 | 13.6       |
| LossAfter               | 0.684785   |
| LossBefore              | 0.708108   |
| MaxReturn               | 3.15e+03   |
| MeanKL                  | 0.00643538 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.91e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.83182    |
| PolicyExecTime          | 0.63       |
| ProcessExecTime         | 0.0692     |
| StdReturn               | 458        |
| Time                    | 7.13e+03   |
| dLoss                   | 0.023323   |
----------------------------------------
itr #526 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 526...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5402, #subsample_inputs: 5402
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.568      |
| AbsLearnSignalNew       | 0.568      |
| AbsLearningOld          | 0.568      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 37.9028    |
| AveragePolicyStd        | 0.484497   |
| AverageReturn           | 2.56e+03   |
| Entropy                 | 2.05967    |
| EnvExecTime             | 2.37       |
| ExplainedVariance       | 0.717      |
| Iteration               | 526        |
| ItrTime                 | 14         |
| LossAfter               | 2.0173     |
| LossBefore              | 2.04549    |
| MaxReturn               | 3.21e+03   |
| MeanKL                  | 0.00644883 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.61e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.84339    |
| PolicyExecTime          | 0.601      |
| ProcessExecTime         | 0.0677     |
| StdReturn               | 624        |
| Time                    | 7.15e+03   |
| dLoss                   | 0.028192   |
----------------------------------------
itr #527 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 527...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5409, #subsample_inputs: 5409
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.594     |
| AbsLearnSignalNew       | 0.594     |
| AbsLearningOld          | 0.594     |
| AverageDiscountedReturn | 251       |
| AveragePhiLoss          | 35.4722   |
| AveragePolicyStd        | 0.484469  |
| AverageReturn           | 2.94e+03  |
| Entropy                 | 2.06022   |
| EnvExecTime             | 2.21      |
| ExplainedVariance       | 0.813     |
| Iteration               | 527       |
| ItrTime                 | 13.8      |
| LossAfter               | 1.55882   |
| LossBefore              | 1.58733   |
| MaxReturn               | 3.27e+03  |
| MeanKL                  | 0.006611  |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.73e+03  |
| NumTrajs                | 6         |
| Perplexity              | 7.84773   |
| PolicyExecTime          | 0.566     |
| ProcessExecTime         | 0.0645    |
| StdReturn               | 548       |
| Time                    | 7.16e+03  |
| dLoss                   | 0.0285139 |
---------------------------------------
itr #528 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 528...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5126, #subsample_inputs: 5126
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.706      |
| AbsLearnSignalNew       | 0.706      |
| AbsLearningOld          | 0.706      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 41.0062    |
| AveragePolicyStd        | 0.484363   |
| AverageReturn           | 2.81e+03   |
| Entropy                 | 2.05993    |
| EnvExecTime             | 2.08       |
| ExplainedVariance       | 0.854      |
| Iteration               | 528        |
| ItrTime                 | 13.1       |
| LossAfter               | 0.77949    |
| LossBefore              | 0.804891   |
| MaxReturn               | 3.27e+03   |
| MeanKL                  | 0.00644301 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.56e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.84543    |
| PolicyExecTime          | 0.515      |
| ProcessExecTime         | 0.0624     |
| StdReturn               | 594        |
| Time                    | 7.18e+03   |
| dLoss                   | 0.0254009  |
----------------------------------------
itr #529 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 529...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5351, #subsample_inputs: 5351
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.641      |
| AbsLearnSignalNew       | 0.641      |
| AbsLearningOld          | 0.641      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 39.5297    |
| AveragePolicyStd        | 0.485301   |
| AverageReturn           | 2.91e+03   |
| Entropy                 | 2.06567    |
| EnvExecTime             | 2.53       |
| ExplainedVariance       | 0.835      |
| Iteration               | 529        |
| ItrTime                 | 14.1       |
| LossAfter               | -0.793904  |
| LossBefore              | -0.762884  |
| MaxReturn               | 3.32e+03   |
| MeanKL                  | 0.00641403 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 2.19e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.89055    |
| PolicyExecTime          | 0.647      |
| ProcessExecTime         | 0.0706     |
| StdReturn               | 454        |
| Time                    | 7.19e+03   |
| dLoss                   | 0.0310197  |
----------------------------------------
itr #530 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 530...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5500, #subsample_inputs: 5500
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.612      |
| AbsLearnSignalNew       | 0.612      |
| AbsLearningOld          | 0.612      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 51.2957    |
| AveragePolicyStd        | 0.485724   |
| AverageReturn           | 2.57e+03   |
| Entropy                 | 2.06761    |
| EnvExecTime             | 2.36       |
| ExplainedVariance       | 0.797      |
| Iteration               | 530        |
| ItrTime                 | 14         |
| LossAfter               | 0.756409   |
| LossBefore              | 0.809146   |
| MaxReturn               | 3.18e+03   |
| MeanKL                  | 0.00976349 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.56e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.90592    |
| PolicyExecTime          | 0.611      |
| ProcessExecTime         | 0.0666     |
| StdReturn               | 534        |
| Time                    | 7.2e+03    |
| dLoss                   | 0.0527371  |
----------------------------------------
itr #531 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 531...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5472, #subsample_inputs: 5472
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.654      |
| AbsLearnSignalNew       | 0.654      |
| AbsLearningOld          | 0.654      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 44.5349    |
| AveragePolicyStd        | 0.486612   |
| AverageReturn           | 2.57e+03   |
| Entropy                 | 2.07364    |
| EnvExecTime             | 2.28       |
| ExplainedVariance       | 0.86       |
| Iteration               | 531        |
| ItrTime                 | 13.8       |
| LossAfter               | -0.579509  |
| LossBefore              | -0.554992  |
| MaxReturn               | 3.31e+03   |
| MeanKL                  | 0.00645396 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.26e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.95369    |
| PolicyExecTime          | 0.582      |
| ProcessExecTime         | 0.0655     |
| StdReturn               | 664        |
| Time                    | 7.22e+03   |
| dLoss                   | 0.0245168  |
----------------------------------------
itr #532 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 532...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5444, #subsample_inputs: 5444
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.692      |
| AbsLearnSignalNew       | 0.692      |
| AbsLearningOld          | 0.692      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 42.1129    |
| AveragePolicyStd        | 0.485884   |
| AverageReturn           | 2.87e+03   |
| Entropy                 | 2.06898    |
| EnvExecTime             | 2.31       |
| ExplainedVariance       | 0.899      |
| Iteration               | 532        |
| ItrTime                 | 13.9       |
| LossAfter               | 0.0421047  |
| LossBefore              | 0.0602731  |
| MaxReturn               | 3.18e+03   |
| MeanKL                  | 0.00640965 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.52e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.91674    |
| PolicyExecTime          | 0.586      |
| ProcessExecTime         | 0.0669     |
| StdReturn               | 602        |
| Time                    | 7.23e+03   |
| dLoss                   | 0.0181684  |
----------------------------------------
itr #533 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 533...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5049, #subsample_inputs: 5049
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.539      |
| AbsLearnSignalNew       | 0.539      |
| AbsLearningOld          | 0.539      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 38.0007    |
| AveragePolicyStd        | 0.485826   |
| AverageReturn           | 1.9e+03    |
| Entropy                 | 2.06945    |
| EnvExecTime             | 2.2        |
| ExplainedVariance       | 0.757      |
| Iteration               | 533        |
| ItrTime                 | 13.1       |
| LossAfter               | -0.151369  |
| LossBefore              | -0.122426  |
| MaxReturn               | 2.41e+03   |
| MeanKL                  | 0.00663667 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.28e+03   |
| NumTrajs                | 9          |
| Perplexity              | 7.9205     |
| PolicyExecTime          | 0.551      |
| ProcessExecTime         | 0.0613     |
| StdReturn               | 349        |
| Time                    | 7.25e+03   |
| dLoss                   | 0.0289437  |
----------------------------------------
itr #534 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 534...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5355, #subsample_inputs: 5355
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.689      |
| AbsLearnSignalNew       | 0.689      |
| AbsLearningOld          | 0.689      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 42.5299    |
| AveragePolicyStd        | 0.48432    |
| AverageReturn           | 2.23e+03   |
| Entropy                 | 2.06068    |
| EnvExecTime             | 2.07       |
| ExplainedVariance       | 0.776      |
| Iteration               | 534        |
| ItrTime                 | 13.4       |
| LossAfter               | -0.755816  |
| LossBefore              | -0.723961  |
| MaxReturn               | 3.25e+03   |
| MeanKL                  | 0.00977741 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.04e+03   |
| NumTrajs                | 8          |
| Perplexity              | 7.85134    |
| PolicyExecTime          | 0.528      |
| ProcessExecTime         | 0.0598     |
| StdReturn               | 811        |
| Time                    | 7.26e+03   |
| dLoss                   | 0.0318549  |
----------------------------------------
itr #535 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 535...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5208, #subsample_inputs: 5208
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.663      |
| AbsLearnSignalNew       | 0.663      |
| AbsLearningOld          | 0.663      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 45.7362    |
| AveragePolicyStd        | 0.484266   |
| AverageReturn           | 2.19e+03   |
| Entropy                 | 2.06059    |
| EnvExecTime             | 2.14       |
| ExplainedVariance       | 0.859      |
| Iteration               | 535        |
| ItrTime                 | 13.2       |
| LossAfter               | 0.155563   |
| LossBefore              | 0.190828   |
| MaxReturn               | 3.31e+03   |
| MeanKL                  | 0.00995437 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.39e+03   |
| NumTrajs                | 8          |
| Perplexity              | 7.85056    |
| PolicyExecTime          | 0.542      |
| ProcessExecTime         | 0.0624     |
| StdReturn               | 799        |
| Time                    | 7.27e+03   |
| dLoss                   | 0.0352649  |
----------------------------------------
itr #536 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 536...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5133, #subsample_inputs: 5133
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.685      |
| AbsLearnSignalNew       | 0.685      |
| AbsLearningOld          | 0.685      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 40.828     |
| AveragePolicyStd        | 0.486102   |
| AverageReturn           | 2.16e+03   |
| Entropy                 | 2.07258    |
| EnvExecTime             | 2.38       |
| ExplainedVariance       | 0.912      |
| Iteration               | 536        |
| ItrTime                 | 13.4       |
| LossAfter               | 0.313788   |
| LossBefore              | 0.343204   |
| MaxReturn               | 3.23e+03   |
| MeanKL                  | 0.00652822 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.38e+03   |
| NumTrajs                | 8          |
| Perplexity              | 7.94527    |
| PolicyExecTime          | 0.601      |
| ProcessExecTime         | 0.067      |
| StdReturn               | 549        |
| Time                    | 7.29e+03   |
| dLoss                   | 0.0294162  |
----------------------------------------
itr #537 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 537...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5063, #subsample_inputs: 5063
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.659      |
| AbsLearnSignalNew       | 0.659      |
| AbsLearningOld          | 0.659      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 39.6345    |
| AveragePolicyStd        | 0.484893   |
| AverageReturn           | 2.44e+03   |
| Entropy                 | 2.06588    |
| EnvExecTime             | 2.26       |
| ExplainedVariance       | 0.854      |
| Iteration               | 537        |
| ItrTime                 | 13.1       |
| LossAfter               | -0.552326  |
| LossBefore              | -0.512912  |
| MaxReturn               | 3.37e+03   |
| MeanKL                  | 0.00993211 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.57e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.89225    |
| PolicyExecTime          | 0.571      |
| ProcessExecTime         | 0.0643     |
| StdReturn               | 623        |
| Time                    | 7.3e+03    |
| dLoss                   | 0.0394142  |
----------------------------------------
itr #538 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 538...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5100, #subsample_inputs: 5100
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.682      |
| AbsLearnSignalNew       | 0.682      |
| AbsLearningOld          | 0.682      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 39.0549    |
| AveragePolicyStd        | 0.484182   |
| AverageReturn           | 2.15e+03   |
| Entropy                 | 2.06209    |
| EnvExecTime             | 2.02       |
| ExplainedVariance       | 0.897      |
| Iteration               | 538        |
| ItrTime                 | 12.9       |
| LossAfter               | 0.436907   |
| LossBefore              | 0.459737   |
| MaxReturn               | 3.21e+03   |
| MeanKL                  | 0.00646374 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.24e+03   |
| NumTrajs                | 8          |
| Perplexity              | 7.86242    |
| PolicyExecTime          | 0.508      |
| ProcessExecTime         | 0.0591     |
| StdReturn               | 552        |
| Time                    | 7.31e+03   |
| dLoss                   | 0.0228297  |
----------------------------------------
itr #539 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 539...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5585, #subsample_inputs: 5585
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.52       |
| AbsLearnSignalNew       | 0.52       |
| AbsLearningOld          | 0.52       |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 34.4739    |
| AveragePolicyStd        | 0.483267   |
| AverageReturn           | 2.64e+03   |
| Entropy                 | 2.05652    |
| EnvExecTime             | 2.71       |
| ExplainedVariance       | 0.58       |
| Iteration               | 539        |
| ItrTime                 | 14.5       |
| LossAfter               | -1.24153   |
| LossBefore              | -1.22285   |
| MaxReturn               | 3.23e+03   |
| MeanKL                  | 0.00656922 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.64e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.81869    |
| PolicyExecTime          | 0.682      |
| ProcessExecTime         | 0.0755     |
| StdReturn               | 561        |
| Time                    | 7.33e+03   |
| dLoss                   | 0.0186772  |
----------------------------------------
itr #540 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 540...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5169, #subsample_inputs: 5169
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.659      |
| AbsLearnSignalNew       | 0.659      |
| AbsLearningOld          | 0.659      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 40.6269    |
| AveragePolicyStd        | 0.483749   |
| AverageReturn           | 2.44e+03   |
| Entropy                 | 2.0593     |
| EnvExecTime             | 2.09       |
| ExplainedVariance       | 0.806      |
| Iteration               | 540        |
| ItrTime                 | 13.2       |
| LossAfter               | 0.458016   |
| LossBefore              | 0.489615   |
| MaxReturn               | 3.12e+03   |
| MeanKL                  | 0.00649759 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.9e+03    |
| NumTrajs                | 7          |
| Perplexity              | 7.84052    |
| PolicyExecTime          | 0.528      |
| ProcessExecTime         | 0.063      |
| StdReturn               | 428        |
| Time                    | 7.34e+03   |
| dLoss                   | 0.0315988  |
----------------------------------------
itr #541 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 541...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5071, #subsample_inputs: 5071
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
-----------------------------------------
| AbsLearnSignal          | 0.676       |
| AbsLearnSignalNew       | 0.676       |
| AbsLearningOld          | 0.676       |
| AverageDiscountedReturn | 250         |
| AveragePhiLoss          | 40.0067     |
| AveragePolicyStd        | 0.483715    |
| AverageReturn           | 2.8e+03     |
| Entropy                 | 2.05928     |
| EnvExecTime             | 2.42        |
| ExplainedVariance       | 0.837       |
| Iteration               | 541         |
| ItrTime                 | 13.5        |
| LossAfter               | -0.0467768  |
| LossBefore              | -0.00911179 |
| MaxReturn               | 3.29e+03    |
| MeanKL                  | 0.00984693  |
| MeanKLBefore            | 0.0         |
| MinReturn               | 2.1e+03     |
| NumTrajs                | 6           |
| Perplexity              | 7.84031     |
| PolicyExecTime          | 0.609       |
| ProcessExecTime         | 0.0678      |
| StdReturn               | 496         |
| Time                    | 7.35e+03    |
| dLoss                   | 0.037665    |
-----------------------------------------
itr #542 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 542...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5620, #subsample_inputs: 5620
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.607      |
| AbsLearnSignalNew       | 0.607      |
| AbsLearningOld          | 0.607      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 34.3973    |
| AveragePolicyStd        | 0.482982   |
| AverageReturn           | 3.07e+03   |
| Entropy                 | 2.05384    |
| EnvExecTime             | 2.57       |
| ExplainedVariance       | 0.88       |
| Iteration               | 542        |
| ItrTime                 | 14.4       |
| LossAfter               | -0.0431569 |
| LossBefore              | -0.0224447 |
| MaxReturn               | 3.3e+03    |
| MeanKL                  | 0.00992234 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 2.38e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.79781    |
| PolicyExecTime          | 0.653      |
| ProcessExecTime         | 0.0727     |
| StdReturn               | 324        |
| Time                    | 7.37e+03   |
| dLoss                   | 0.0207121  |
----------------------------------------
itr #543 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 543...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5191, #subsample_inputs: 5191
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.642      |
| AbsLearnSignalNew       | 0.642      |
| AbsLearningOld          | 0.642      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 41.5579    |
| AveragePolicyStd        | 0.482411   |
| AverageReturn           | 2.83e+03   |
| Entropy                 | 2.05004    |
| EnvExecTime             | 2.52       |
| ExplainedVariance       | 0.826      |
| Iteration               | 543        |
| ItrTime                 | 13.8       |
| LossAfter               | -0.16219   |
| LossBefore              | -0.121136  |
| MaxReturn               | 3.29e+03   |
| MeanKL                  | 0.00998667 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 2.13e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.76822    |
| PolicyExecTime          | 0.654      |
| ProcessExecTime         | 0.069      |
| StdReturn               | 446        |
| Time                    | 7.38e+03   |
| dLoss                   | 0.0410533  |
----------------------------------------
itr #544 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 544...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5913, #subsample_inputs: 5913
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.648     |
| AbsLearnSignalNew       | 0.648     |
| AbsLearningOld          | 0.648     |
| AverageDiscountedReturn | 247       |
| AveragePhiLoss          | 35.5382   |
| AveragePolicyStd        | 0.483195  |
| AverageReturn           | 3.17e+03  |
| Entropy                 | 2.05455   |
| EnvExecTime             | 2.95      |
| ExplainedVariance       | 0.822     |
| Iteration               | 544       |
| ItrTime                 | 15.4      |
| LossAfter               | 0.829541  |
| LossBefore              | 0.851532  |
| MaxReturn               | 3.21e+03  |
| MeanKL                  | 0.0064394 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 3.12e+03  |
| NumTrajs                | 6         |
| Perplexity              | 7.80334   |
| PolicyExecTime          | 0.76      |
| ProcessExecTime         | 0.0811    |
| StdReturn               | 34        |
| Time                    | 7.4e+03   |
| dLoss                   | 0.0219912 |
---------------------------------------
itr #545 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 545...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5176, #subsample_inputs: 5176
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.386      |
| AbsLearnSignalNew       | 0.386      |
| AbsLearningOld          | 0.386      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 68.8774    |
| AveragePolicyStd        | 0.483055   |
| AverageReturn           | 2.81e+03   |
| Entropy                 | 2.0523     |
| EnvExecTime             | 1.97       |
| ExplainedVariance       | 0.753      |
| Iteration               | 545        |
| ItrTime                 | 13         |
| LossAfter               | -0.0266672 |
| LossBefore              | 0.0413213  |
| MaxReturn               | 3.26e+03   |
| MeanKL                  | 0.00647821 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.62e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.78579    |
| PolicyExecTime          | 0.49       |
| ProcessExecTime         | 0.0605     |
| StdReturn               | 641        |
| Time                    | 7.41e+03   |
| dLoss                   | 0.0679886  |
----------------------------------------
itr #546 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 546...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5225, #subsample_inputs: 5225
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.649      |
| AbsLearnSignalNew       | 0.649      |
| AbsLearningOld          | 0.649      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 42.8661    |
| AveragePolicyStd        | 0.482911   |
| AverageReturn           | 2.86e+03   |
| Entropy                 | 2.05103    |
| EnvExecTime             | 2.01       |
| ExplainedVariance       | 0.805      |
| Iteration               | 546        |
| ItrTime                 | 13.1       |
| LossAfter               | -0.977982  |
| LossBefore              | -0.94989   |
| MaxReturn               | 3.35e+03   |
| MeanKL                  | 0.00974339 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.88e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.7759     |
| PolicyExecTime          | 0.509      |
| ProcessExecTime         | 0.0598     |
| StdReturn               | 598        |
| Time                    | 7.42e+03   |
| dLoss                   | 0.0280915  |
----------------------------------------
itr #547 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 547...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5527, #subsample_inputs: 5527
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.634      |
| AbsLearnSignalNew       | 0.634      |
| AbsLearningOld          | 0.634      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 40.2287    |
| AveragePolicyStd        | 0.480965   |
| AverageReturn           | 2.53e+03   |
| Entropy                 | 2.04069    |
| EnvExecTime             | 2.41       |
| ExplainedVariance       | 0.843      |
| Iteration               | 547        |
| ItrTime                 | 14         |
| LossAfter               | 0.0344535  |
| LossBefore              | 0.0687513  |
| MaxReturn               | 3.22e+03   |
| MeanKL                  | 0.00988217 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.29e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.6959     |
| PolicyExecTime          | 0.617      |
| ProcessExecTime         | 0.0682     |
| StdReturn               | 758        |
| Time                    | 7.44e+03   |
| dLoss                   | 0.0342978  |
----------------------------------------
itr #548 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 548...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5186, #subsample_inputs: 5186
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.683      |
| AbsLearnSignalNew       | 0.683      |
| AbsLearningOld          | 0.683      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 46.3141    |
| AveragePolicyStd        | 0.480986   |
| AverageReturn           | 2.8e+03    |
| Entropy                 | 2.04068    |
| EnvExecTime             | 2.17       |
| ExplainedVariance       | 0.905      |
| Iteration               | 548        |
| ItrTime                 | 13.3       |
| LossAfter               | 0.32713    |
| LossBefore              | 0.349617   |
| MaxReturn               | 3.22e+03   |
| MeanKL                  | 0.00641362 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.24e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.69581    |
| PolicyExecTime          | 0.553      |
| ProcessExecTime         | 0.0624     |
| StdReturn               | 714        |
| Time                    | 7.45e+03   |
| dLoss                   | 0.0224875  |
----------------------------------------
itr #549 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 549...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5629, #subsample_inputs: 5629
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.512      |
| AbsLearnSignalNew       | 0.512      |
| AbsLearningOld          | 0.512      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 46.4825    |
| AveragePolicyStd        | 0.480183   |
| AverageReturn           | 2.31e+03   |
| Entropy                 | 2.03499    |
| EnvExecTime             | 2.39       |
| ExplainedVariance       | 0.629      |
| Iteration               | 549        |
| ItrTime                 | 14.2       |
| LossAfter               | 0.0749895  |
| LossBefore              | 0.095436   |
| MaxReturn               | 3.3e+03    |
| MeanKL                  | 0.00647098 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 868        |
| NumTrajs                | 8          |
| Perplexity              | 7.65215    |
| PolicyExecTime          | 0.615      |
| ProcessExecTime         | 0.0681     |
| StdReturn               | 760        |
| Time                    | 7.47e+03   |
| dLoss                   | 0.0204465  |
----------------------------------------
itr #550 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 550...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5848, #subsample_inputs: 5848
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.726      |
| AbsLearnSignalNew       | 0.726      |
| AbsLearningOld          | 0.726      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 41.7763    |
| AveragePolicyStd        | 0.480418   |
| AverageReturn           | 3.16e+03   |
| Entropy                 | 2.03645    |
| EnvExecTime             | 2.96       |
| ExplainedVariance       | 0.861      |
| Iteration               | 550        |
| ItrTime                 | 15.2       |
| LossAfter               | 0.169568   |
| LossBefore              | 0.203044   |
| MaxReturn               | 3.29e+03   |
| MeanKL                  | 0.00998465 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 2.94e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.66339    |
| PolicyExecTime          | 0.748      |
| ProcessExecTime         | 0.0812     |
| StdReturn               | 117        |
| Time                    | 7.48e+03   |
| dLoss                   | 0.0334761  |
----------------------------------------
itr #551 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 551...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5100, #subsample_inputs: 5100
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.592      |
| AbsLearnSignalNew       | 0.592      |
| AbsLearningOld          | 0.592      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 43.3584    |
| AveragePolicyStd        | 0.480217   |
| AverageReturn           | 2.77e+03   |
| Entropy                 | 2.03535    |
| EnvExecTime             | 2.02       |
| ExplainedVariance       | 0.783      |
| Iteration               | 551        |
| ItrTime                 | 12.9       |
| LossAfter               | 0.48098    |
| LossBefore              | 0.529156   |
| MaxReturn               | 3.37e+03   |
| MeanKL                  | 0.00994687 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.23e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.65492    |
| PolicyExecTime          | 0.503      |
| ProcessExecTime         | 0.0588     |
| StdReturn               | 725        |
| Time                    | 7.49e+03   |
| dLoss                   | 0.0481758  |
----------------------------------------
itr #552 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 552...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5391, #subsample_inputs: 5391
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.59       |
| AbsLearnSignalNew       | 0.59       |
| AbsLearningOld          | 0.59       |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 45.9997    |
| AveragePolicyStd        | 0.480096   |
| AverageReturn           | 2.93e+03   |
| Entropy                 | 2.03556    |
| EnvExecTime             | 2.81       |
| ExplainedVariance       | 0.851      |
| Iteration               | 552        |
| ItrTime                 | 14.5       |
| LossAfter               | 0.621966   |
| LossBefore              | 0.686229   |
| MaxReturn               | 3.26e+03   |
| MeanKL                  | 0.00921235 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.91e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.65655    |
| PolicyExecTime          | 0.7        |
| ProcessExecTime         | 0.0793     |
| StdReturn               | 500        |
| Time                    | 7.51e+03   |
| dLoss                   | 0.0642633  |
----------------------------------------
itr #553 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 553...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5027, #subsample_inputs: 5027
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.628      |
| AbsLearnSignalNew       | 0.628      |
| AbsLearningOld          | 0.628      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 42.5151    |
| AveragePolicyStd        | 0.47955    |
| AverageReturn           | 2.05e+03   |
| Entropy                 | 2.03249    |
| EnvExecTime             | 1.98       |
| ExplainedVariance       | 0.691      |
| Iteration               | 553        |
| ItrTime                 | 12.8       |
| LossAfter               | 0.460892   |
| LossBefore              | 0.489427   |
| MaxReturn               | 3.29e+03   |
| MeanKL                  | 0.00653488 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.06e+03   |
| NumTrajs                | 8          |
| Perplexity              | 7.63311    |
| PolicyExecTime          | 0.509      |
| ProcessExecTime         | 0.0573     |
| StdReturn               | 588        |
| Time                    | 7.52e+03   |
| dLoss                   | 0.0285352  |
----------------------------------------
itr #554 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 554...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5208, #subsample_inputs: 5208
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.159      |
| AbsLearnSignalNew       | 0.159      |
| AbsLearningOld          | 0.159      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 94.2927    |
| AveragePolicyStd        | 0.478835   |
| AverageReturn           | 2.43e+03   |
| Entropy                 | 2.02793    |
| EnvExecTime             | 2.52       |
| ExplainedVariance       | -5.71      |
| Iteration               | 554        |
| ItrTime                 | 13.7       |
| LossAfter               | 0.09776    |
| LossBefore              | 0.156836   |
| MaxReturn               | 3.26e+03   |
| MeanKL                  | 0.00671381 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.27e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.59836    |
| PolicyExecTime          | 0.627      |
| ProcessExecTime         | 0.0703     |
| StdReturn               | 809        |
| Time                    | 7.53e+03   |
| dLoss                   | 0.0590758  |
----------------------------------------
itr #555 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 555...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5333, #subsample_inputs: 5333
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.613      |
| AbsLearnSignalNew       | 0.613      |
| AbsLearningOld          | 0.612      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 48.8516    |
| AveragePolicyStd        | 0.478075   |
| AverageReturn           | 2.88e+03   |
| Entropy                 | 2.02403    |
| EnvExecTime             | 2.31       |
| ExplainedVariance       | 0.685      |
| Iteration               | 555        |
| ItrTime                 | 13.8       |
| LossAfter               | -0.561016  |
| LossBefore              | -0.539984  |
| MaxReturn               | 3.27e+03   |
| MeanKL                  | 0.00656211 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.43e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.56873    |
| PolicyExecTime          | 0.591      |
| ProcessExecTime         | 0.0661     |
| StdReturn               | 654        |
| Time                    | 7.55e+03   |
| dLoss                   | 0.0210326  |
----------------------------------------
itr #556 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 556...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5381, #subsample_inputs: 5381
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.592      |
| AbsLearnSignalNew       | 0.592      |
| AbsLearningOld          | 0.592      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 44.0873    |
| AveragePolicyStd        | 0.477045   |
| AverageReturn           | 2e+03      |
| Entropy                 | 2.01771    |
| EnvExecTime             | 2.33       |
| ExplainedVariance       | 0.639      |
| Iteration               | 556        |
| ItrTime                 | 13.9       |
| LossAfter               | -0.303318  |
| LossBefore              | -0.280312  |
| MaxReturn               | 3.31e+03   |
| MeanKL                  | 0.00644675 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 910        |
| NumTrajs                | 9          |
| Perplexity              | 7.52105    |
| PolicyExecTime          | 0.593      |
| ProcessExecTime         | 0.0685     |
| StdReturn               | 819        |
| Time                    | 7.56e+03   |
| dLoss                   | 0.0230063  |
----------------------------------------
itr #557 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 557...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5168, #subsample_inputs: 5168
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.7        |
| AbsLearnSignalNew       | 0.7        |
| AbsLearningOld          | 0.7        |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 51.6475    |
| AveragePolicyStd        | 0.475962   |
| AverageReturn           | 2.14e+03   |
| Entropy                 | 2.01128    |
| EnvExecTime             | 2.18       |
| ExplainedVariance       | 0.837      |
| Iteration               | 557        |
| ItrTime                 | 13.2       |
| LossAfter               | 1.52862    |
| LossBefore              | 1.56089    |
| MaxReturn               | 3.25e+03   |
| MeanKL                  | 0.00996764 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.09e+03   |
| NumTrajs                | 8          |
| Perplexity              | 7.47287    |
| PolicyExecTime          | 0.553      |
| ProcessExecTime         | 0.0641     |
| StdReturn               | 750        |
| Time                    | 7.58e+03   |
| dLoss                   | 0.0322695  |
----------------------------------------
itr #558 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 558...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5533, #subsample_inputs: 5533
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.659      |
| AbsLearnSignalNew       | 0.659      |
| AbsLearningOld          | 0.659      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 47.1456    |
| AveragePolicyStd        | 0.47642    |
| AverageReturn           | 2.62e+03   |
| Entropy                 | 2.0131     |
| EnvExecTime             | 2.48       |
| ExplainedVariance       | 0.621      |
| Iteration               | 558        |
| ItrTime                 | 14.2       |
| LossAfter               | 1.57481    |
| LossBefore              | 1.61648    |
| MaxReturn               | 3.35e+03   |
| MeanKL                  | 0.00979338 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.46e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.4865     |
| PolicyExecTime          | 0.627      |
| ProcessExecTime         | 0.0715     |
| StdReturn               | 729        |
| Time                    | 7.59e+03   |
| dLoss                   | 0.0416776  |
----------------------------------------
itr #559 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 559...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5191, #subsample_inputs: 5191
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.587      |
| AbsLearnSignalNew       | 0.587      |
| AbsLearningOld          | 0.587      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 46.0252    |
| AveragePolicyStd        | 0.476754   |
| AverageReturn           | 2.47e+03   |
| Entropy                 | 2.01584    |
| EnvExecTime             | 2.62       |
| ExplainedVariance       | 0.75       |
| Iteration               | 559        |
| ItrTime                 | 13.8       |
| LossAfter               | 0.0681036  |
| LossBefore              | 0.0907119  |
| MaxReturn               | 3.3e+03    |
| MeanKL                  | 0.00647295 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.56e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.50702    |
| PolicyExecTime          | 0.651      |
| ProcessExecTime         | 0.0738     |
| StdReturn               | 603        |
| Time                    | 7.6e+03    |
| dLoss                   | 0.0226083  |
----------------------------------------
itr #560 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 560...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5408, #subsample_inputs: 5408
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.729      |
| AbsLearnSignalNew       | 0.729      |
| AbsLearningOld          | 0.729      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 43.3128    |
| AveragePolicyStd        | 0.476299   |
| AverageReturn           | 2.26e+03   |
| Entropy                 | 2.01357    |
| EnvExecTime             | 2.17       |
| ExplainedVariance       | 0.862      |
| Iteration               | 560        |
| ItrTime                 | 13.6       |
| LossAfter               | 0.533627   |
| LossBefore              | 0.564836   |
| MaxReturn               | 3.23e+03   |
| MeanKL                  | 0.00970977 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.7e+03    |
| NumTrajs                | 8          |
| Perplexity              | 7.49       |
| PolicyExecTime          | 0.552      |
| ProcessExecTime         | 0.0633     |
| StdReturn               | 424        |
| Time                    | 7.62e+03   |
| dLoss                   | 0.0312093  |
----------------------------------------
itr #561 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 561...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5208, #subsample_inputs: 5208
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.517      |
| AbsLearnSignalNew       | 0.517      |
| AbsLearningOld          | 0.518      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 51.6527    |
| AveragePolicyStd        | 0.4775     |
| AverageReturn           | 2.45e+03   |
| Entropy                 | 2.02111    |
| EnvExecTime             | 2.33       |
| ExplainedVariance       | 0.662      |
| Iteration               | 561        |
| ItrTime                 | 13.5       |
| LossAfter               | 0.813854   |
| LossBefore              | 0.846235   |
| MaxReturn               | 3.25e+03   |
| MeanKL                  | 0.00650077 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.74e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.5467     |
| PolicyExecTime          | 0.585      |
| ProcessExecTime         | 0.0672     |
| StdReturn               | 632        |
| Time                    | 7.63e+03   |
| dLoss                   | 0.0323816  |
----------------------------------------
itr #562 | 
Mem: 738.394531
Obtaining samples...
Obtaining samples for iteration 562...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5915, #subsample_inputs: 5915
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.536      |
| AbsLearnSignalNew       | 0.536      |
| AbsLearningOld          | 0.535      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 38.1908    |
| AveragePolicyStd        | 0.475896   |
| AverageReturn           | 2.82e+03   |
| Entropy                 | 2.01179    |
| EnvExecTime             | 2.68       |
| ExplainedVariance       | 0.629      |
| Iteration               | 562        |
| ItrTime                 | 15         |
| LossAfter               | 0.217156   |
| LossBefore              | 0.26358    |
| MaxReturn               | 3.33e+03   |
| MeanKL                  | 0.00966838 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.51e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.4767     |
| PolicyExecTime          | 0.663      |
| ProcessExecTime         | 0.0768     |
| StdReturn               | 747        |
| Time                    | 7.65e+03   |
| dLoss                   | 0.0464235  |
----------------------------------------
itr #563 | 
Mem: 739.957031
Obtaining samples...
Obtaining samples for iteration 563...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5190, #subsample_inputs: 5190
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.566      |
| AbsLearnSignalNew       | 0.566      |
| AbsLearningOld          | 0.566      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 44.6045    |
| AveragePolicyStd        | 0.474491   |
| AverageReturn           | 2.86e+03   |
| Entropy                 | 2.00289    |
| EnvExecTime             | 2.16       |
| ExplainedVariance       | 0.736      |
| Iteration               | 563        |
| ItrTime                 | 13.3       |
| LossAfter               | 1.65434    |
| LossBefore              | 1.69089    |
| MaxReturn               | 3.34e+03   |
| MeanKL                  | 0.00652462 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 2.19e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.41046    |
| PolicyExecTime          | 0.549      |
| ProcessExecTime         | 0.0619     |
| StdReturn               | 449        |
| Time                    | 7.66e+03   |
| dLoss                   | 0.0365436  |
----------------------------------------
itr #564 | 
Mem: 739.957031
Obtaining samples...
Obtaining samples for iteration 564...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5815, #subsample_inputs: 5815
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.712      |
| AbsLearnSignalNew       | 0.712      |
| AbsLearningOld          | 0.712      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 43.2699    |
| AveragePolicyStd        | 0.473026   |
| AverageReturn           | 2.4e+03    |
| Entropy                 | 1.99373    |
| EnvExecTime             | 2.02       |
| ExplainedVariance       | 0.891      |
| Iteration               | 564        |
| ItrTime                 | 14         |
| LossAfter               | 0.520368   |
| LossBefore              | 0.541464   |
| MaxReturn               | 3.24e+03   |
| MeanKL                  | 0.00643359 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.54e+03   |
| NumTrajs                | 8          |
| Perplexity              | 7.3429     |
| PolicyExecTime          | 0.515      |
| ProcessExecTime         | 0.0615     |
| StdReturn               | 584        |
| Time                    | 7.67e+03   |
| dLoss                   | 0.0210959  |
----------------------------------------
itr #565 | 
Mem: 739.957031
Obtaining samples...
Obtaining samples for iteration 565...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5945, #subsample_inputs: 5945
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.698      |
| AbsLearnSignalNew       | 0.698      |
| AbsLearningOld          | 0.698      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 43.7881    |
| AveragePolicyStd        | 0.471311   |
| AverageReturn           | 2.44e+03   |
| Entropy                 | 1.98253    |
| EnvExecTime             | 2.37       |
| ExplainedVariance       | 0.879      |
| Iteration               | 565        |
| ItrTime                 | 14.7       |
| LossAfter               | 0.85352    |
| LossBefore              | 0.888464   |
| MaxReturn               | 3.26e+03   |
| MeanKL                  | 0.00655111 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.29e+03   |
| NumTrajs                | 8          |
| Perplexity              | 7.26107    |
| PolicyExecTime          | 0.601      |
| ProcessExecTime         | 0.0695     |
| StdReturn               | 820        |
| Time                    | 7.69e+03   |
| dLoss                   | 0.0349441  |
----------------------------------------
itr #566 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 566...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5568, #subsample_inputs: 5568
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.683      |
| AbsLearnSignalNew       | 0.683      |
| AbsLearningOld          | 0.683      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 41.1045    |
| AveragePolicyStd        | 0.472229   |
| AverageReturn           | 2.66e+03   |
| Entropy                 | 1.98847    |
| EnvExecTime             | 2.33       |
| ExplainedVariance       | 0.842      |
| Iteration               | 566        |
| ItrTime                 | 14         |
| LossAfter               | -0.88006   |
| LossBefore              | -0.85502   |
| MaxReturn               | 3.38e+03   |
| MeanKL                  | 0.00642977 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.36e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.30432    |
| PolicyExecTime          | 0.596      |
| ProcessExecTime         | 0.0666     |
| StdReturn               | 766        |
| Time                    | 7.7e+03    |
| dLoss                   | 0.0250401  |
----------------------------------------
itr #567 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 567...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5801, #subsample_inputs: 5801
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.582      |
| AbsLearnSignalNew       | 0.582      |
| AbsLearningOld          | 0.582      |
| AverageDiscountedReturn | 254        |
| AveragePhiLoss          | 41.6709    |
| AveragePolicyStd        | 0.472226   |
| AverageReturn           | 2.13e+03   |
| Entropy                 | 1.9878     |
| EnvExecTime             | 2.27       |
| ExplainedVariance       | 0.737      |
| Iteration               | 567        |
| ItrTime                 | 14.3       |
| LossAfter               | -1.18629   |
| LossBefore              | -1.15543   |
| MaxReturn               | 3.25e+03   |
| MeanKL                  | 0.00948815 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.27e+03   |
| NumTrajs                | 9          |
| Perplexity              | 7.29948    |
| PolicyExecTime          | 0.575      |
| ProcessExecTime         | 0.0669     |
| StdReturn               | 742        |
| Time                    | 7.72e+03   |
| dLoss                   | 0.0308573  |
----------------------------------------
itr #568 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 568...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5358, #subsample_inputs: 5358
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.685      |
| AbsLearnSignalNew       | 0.685      |
| AbsLearningOld          | 0.685      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 42.2015    |
| AveragePolicyStd        | 0.473041   |
| AverageReturn           | 2.91e+03   |
| Entropy                 | 1.99289    |
| EnvExecTime             | 2.14       |
| ExplainedVariance       | 0.734      |
| Iteration               | 568        |
| ItrTime                 | 13.6       |
| LossAfter               | -0.129947  |
| LossBefore              | -0.103327  |
| MaxReturn               | 3.26e+03   |
| MeanKL                  | 0.00997976 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 2.19e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.33674    |
| PolicyExecTime          | 0.551      |
| ProcessExecTime         | 0.0624     |
| StdReturn               | 435        |
| Time                    | 7.73e+03   |
| dLoss                   | 0.0266203  |
----------------------------------------
itr #569 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 569...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5271, #subsample_inputs: 5271
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.714      |
| AbsLearnSignalNew       | 0.714      |
| AbsLearningOld          | 0.714      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 41.9821    |
| AveragePolicyStd        | 0.47378    |
| AverageReturn           | 2.41e+03   |
| Entropy                 | 1.99863    |
| EnvExecTime             | 2.07       |
| ExplainedVariance       | 0.874      |
| Iteration               | 569        |
| ItrTime                 | 13.2       |
| LossAfter               | 0.295548   |
| LossBefore              | 0.322941   |
| MaxReturn               | 3.17e+03   |
| MeanKL                  | 0.00988912 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 888        |
| NumTrajs                | 7          |
| Perplexity              | 7.37891    |
| PolicyExecTime          | 0.522      |
| ProcessExecTime         | 0.063      |
| StdReturn               | 874        |
| Time                    | 7.74e+03   |
| dLoss                   | 0.0273936  |
----------------------------------------
itr #570 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 570...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5718, #subsample_inputs: 5718
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.534      |
| AbsLearnSignalNew       | 0.534      |
| AbsLearningOld          | 0.534      |
| AverageDiscountedReturn | 254        |
| AveragePhiLoss          | 40.5941    |
| AveragePolicyStd        | 0.472502   |
| AverageReturn           | 2.71e+03   |
| Entropy                 | 1.9908     |
| EnvExecTime             | 2.56       |
| ExplainedVariance       | 0.808      |
| Iteration               | 570        |
| ItrTime                 | 14.5       |
| LossAfter               | 1.44692    |
| LossBefore              | 1.47038    |
| MaxReturn               | 3.32e+03   |
| MeanKL                  | 0.00652401 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.08e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.32139    |
| PolicyExecTime          | 0.649      |
| ProcessExecTime         | 0.0735     |
| StdReturn               | 721        |
| Time                    | 7.76e+03   |
| dLoss                   | 0.0234681  |
----------------------------------------
itr #571 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 571...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5582, #subsample_inputs: 5582
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.723      |
| AbsLearnSignalNew       | 0.723      |
| AbsLearningOld          | 0.722      |
| AverageDiscountedReturn | 255        |
| AveragePhiLoss          | 42.9734    |
| AveragePolicyStd        | 0.472311   |
| AverageReturn           | 1.58e+03   |
| Entropy                 | 1.98943    |
| EnvExecTime             | 2.22       |
| ExplainedVariance       | 0.869      |
| Iteration               | 571        |
| ItrTime                 | 13.8       |
| LossAfter               | -0.286065  |
| LossBefore              | -0.252285  |
| MaxReturn               | 2.76e+03   |
| MeanKL                  | 0.00986275 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 850        |
| NumTrajs                | 12         |
| Perplexity              | 7.31137    |
| PolicyExecTime          | 0.567      |
| ProcessExecTime         | 0.0648     |
| StdReturn               | 705        |
| Time                    | 7.77e+03   |
| dLoss                   | 0.0337805  |
----------------------------------------
itr #572 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 572...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5349, #subsample_inputs: 5349
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.707      |
| AbsLearnSignalNew       | 0.707      |
| AbsLearningOld          | 0.707      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 49.5424    |
| AveragePolicyStd        | 0.472453   |
| AverageReturn           | 1.62e+03   |
| Entropy                 | 1.99113    |
| EnvExecTime             | 1.94       |
| ExplainedVariance       | 0.837      |
| Iteration               | 572        |
| ItrTime                 | 13.3       |
| LossAfter               | 0.131456   |
| LossBefore              | 0.157829   |
| MaxReturn               | 3.14e+03   |
| MeanKL                  | 0.00644687 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 829        |
| NumTrajs                | 11         |
| Perplexity              | 7.32384    |
| PolicyExecTime          | 0.497      |
| ProcessExecTime         | 0.0591     |
| StdReturn               | 773        |
| Time                    | 7.79e+03   |
| dLoss                   | 0.0263721  |
----------------------------------------
itr #573 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 573...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5686, #subsample_inputs: 5686
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.736      |
| AbsLearnSignalNew       | 0.736      |
| AbsLearningOld          | 0.736      |
| AverageDiscountedReturn | 254        |
| AveragePhiLoss          | 41.3423    |
| AveragePolicyStd        | 0.472224   |
| AverageReturn           | 1.91e+03   |
| Entropy                 | 1.9892     |
| EnvExecTime             | 2.43       |
| ExplainedVariance       | 0.878      |
| Iteration               | 573        |
| ItrTime                 | 14.3       |
| LossAfter               | 0.404004   |
| LossBefore              | 0.42995    |
| MaxReturn               | 3.3e+03    |
| MeanKL                  | 0.00654247 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 911        |
| NumTrajs                | 10         |
| Perplexity              | 7.30972    |
| PolicyExecTime          | 0.613      |
| ProcessExecTime         | 0.0696     |
| StdReturn               | 855        |
| Time                    | 7.8e+03    |
| dLoss                   | 0.0259453  |
----------------------------------------
itr #574 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 574...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5841, #subsample_inputs: 5841
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.668      |
| AbsLearnSignalNew       | 0.668      |
| AbsLearningOld          | 0.669      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 45.2357    |
| AveragePolicyStd        | 0.472354   |
| AverageReturn           | 1.94e+03   |
| Entropy                 | 1.9895     |
| EnvExecTime             | 2.1        |
| ExplainedVariance       | 0.846      |
| Iteration               | 574        |
| ItrTime                 | 14.1       |
| LossAfter               | -0.489651  |
| LossBefore              | -0.457892  |
| MaxReturn               | 3.43e+03   |
| MeanKL                  | 0.00976254 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 606        |
| NumTrajs                | 10         |
| Perplexity              | 7.31186    |
| PolicyExecTime          | 0.537      |
| ProcessExecTime         | 0.0642     |
| StdReturn               | 1.16e+03   |
| Time                    | 7.82e+03   |
| dLoss                   | 0.0317592  |
----------------------------------------
itr #575 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 575...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5580, #subsample_inputs: 5580
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.59       |
| AbsLearnSignalNew       | 0.59       |
| AbsLearningOld          | 0.59       |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 43.9593    |
| AveragePolicyStd        | 0.472614   |
| AverageReturn           | 1.69e+03   |
| Entropy                 | 1.9918     |
| EnvExecTime             | 2.05       |
| ExplainedVariance       | 0.73       |
| Iteration               | 575        |
| ItrTime                 | 13.6       |
| LossAfter               | -1.44924   |
| LossBefore              | -1.42313   |
| MaxReturn               | 3.3e+03    |
| MeanKL                  | 0.00993377 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 836        |
| NumTrajs                | 11         |
| Perplexity              | 7.32874    |
| PolicyExecTime          | 0.527      |
| ProcessExecTime         | 0.0609     |
| StdReturn               | 873        |
| Time                    | 7.83e+03   |
| dLoss                   | 0.0261129  |
----------------------------------------
itr #576 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 576...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5108, #subsample_inputs: 5108
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.727      |
| AbsLearnSignalNew       | 0.727      |
| AbsLearningOld          | 0.727      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 51.9349    |
| AveragePolicyStd        | 0.472756   |
| AverageReturn           | 2.75e+03   |
| Entropy                 | 1.9922     |
| EnvExecTime             | 1.76       |
| ExplainedVariance       | 0.868      |
| Iteration               | 576        |
| ItrTime                 | 12.6       |
| LossAfter               | 0.560508   |
| LossBefore              | 0.589132   |
| MaxReturn               | 3.29e+03   |
| MeanKL                  | 0.00649004 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 903        |
| NumTrajs                | 6          |
| Perplexity              | 7.33164    |
| PolicyExecTime          | 0.444      |
| ProcessExecTime         | 0.0539     |
| StdReturn               | 849        |
| Time                    | 7.84e+03   |
| dLoss                   | 0.0286235  |
----------------------------------------
itr #577 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 577...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5119, #subsample_inputs: 5119
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.691      |
| AbsLearnSignalNew       | 0.691      |
| AbsLearningOld          | 0.691      |
| AverageDiscountedReturn | 254        |
| AveragePhiLoss          | 43.6613    |
| AveragePolicyStd        | 0.472901   |
| AverageReturn           | 1.92e+03   |
| Entropy                 | 1.99365    |
| EnvExecTime             | 1.95       |
| ExplainedVariance       | 0.877      |
| Iteration               | 577        |
| ItrTime                 | 12.9       |
| LossAfter               | 1.31315    |
| LossBefore              | 1.34863    |
| MaxReturn               | 3.25e+03   |
| MeanKL                  | 0.00990308 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.28e+03   |
| NumTrajs                | 9          |
| Perplexity              | 7.34228    |
| PolicyExecTime          | 0.5        |
| ProcessExecTime         | 0.0566     |
| StdReturn               | 732        |
| Time                    | 7.85e+03   |
| dLoss                   | 0.0354803  |
----------------------------------------
itr #578 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 578...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5446, #subsample_inputs: 5446
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.692      |
| AbsLearnSignalNew       | 0.692      |
| AbsLearningOld          | 0.692      |
| AverageDiscountedReturn | 254        |
| AveragePhiLoss          | 39.3559    |
| AveragePolicyStd        | 0.473139   |
| AverageReturn           | 1.84e+03   |
| Entropy                 | 1.99484    |
| EnvExecTime             | 2.29       |
| ExplainedVariance       | 0.878      |
| Iteration               | 578        |
| ItrTime                 | 13.9       |
| LossAfter               | -0.797918  |
| LossBefore              | -0.767396  |
| MaxReturn               | 3.3e+03    |
| MeanKL                  | 0.00973399 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.19e+03   |
| NumTrajs                | 10         |
| Perplexity              | 7.35102    |
| PolicyExecTime          | 0.57       |
| ProcessExecTime         | 0.0665     |
| StdReturn               | 712        |
| Time                    | 7.87e+03   |
| dLoss                   | 0.0305222  |
----------------------------------------
itr #579 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 579...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5001, #subsample_inputs: 5001
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.736      |
| AbsLearnSignalNew       | 0.736      |
| AbsLearningOld          | 0.736      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 42.3999    |
| AveragePolicyStd        | 0.47533    |
| AverageReturn           | 1.69e+03   |
| Entropy                 | 2.00903    |
| EnvExecTime             | 1.86       |
| ExplainedVariance       | 0.886      |
| Iteration               | 579        |
| ItrTime                 | 12.6       |
| LossAfter               | 1.28651    |
| LossBefore              | 1.31322    |
| MaxReturn               | 3.3e+03    |
| MeanKL                  | 0.00989566 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 672        |
| NumTrajs                | 10         |
| Perplexity              | 7.45605    |
| PolicyExecTime          | 0.466      |
| ProcessExecTime         | 0.0558     |
| StdReturn               | 754        |
| Time                    | 7.88e+03   |
| dLoss                   | 0.0267013  |
----------------------------------------
itr #580 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 580...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5138, #subsample_inputs: 5138
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.68       |
| AbsLearnSignalNew       | 0.68       |
| AbsLearningOld          | 0.68       |
| AverageDiscountedReturn | 256        |
| AveragePhiLoss          | 39.2088    |
| AveragePolicyStd        | 0.474359   |
| AverageReturn           | 1.74e+03   |
| Entropy                 | 2.00204    |
| EnvExecTime             | 2.02       |
| ExplainedVariance       | 0.807      |
| Iteration               | 580        |
| ItrTime                 | 12.9       |
| LossAfter               | -0.77739   |
| LossBefore              | -0.750194  |
| MaxReturn               | 3.25e+03   |
| MeanKL                  | 0.00999642 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 772        |
| NumTrajs                | 10         |
| Perplexity              | 7.40413    |
| PolicyExecTime          | 0.511      |
| ProcessExecTime         | 0.0591     |
| StdReturn               | 772        |
| Time                    | 7.89e+03   |
| dLoss                   | 0.027196   |
----------------------------------------
itr #581 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 581...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5450, #subsample_inputs: 5450
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.611      |
| AbsLearnSignalNew       | 0.611      |
| AbsLearningOld          | 0.611      |
| AverageDiscountedReturn | 255        |
| AveragePhiLoss          | 38.1566    |
| AveragePolicyStd        | 0.473943   |
| AverageReturn           | 2.3e+03    |
| Entropy                 | 1.99984    |
| EnvExecTime             | 2.15       |
| ExplainedVariance       | 0.704      |
| Iteration               | 581        |
| ItrTime                 | 13.7       |
| LossAfter               | 0.601433   |
| LossBefore              | 0.625032   |
| MaxReturn               | 3.37e+03   |
| MeanKL                  | 0.00999042 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.03e+03   |
| NumTrajs                | 8          |
| Perplexity              | 7.38786    |
| PolicyExecTime          | 0.551      |
| ProcessExecTime         | 0.0639     |
| StdReturn               | 958        |
| Time                    | 7.91e+03   |
| dLoss                   | 0.0235983  |
----------------------------------------
itr #582 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 582...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5591, #subsample_inputs: 5591
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.672      |
| AbsLearnSignalNew       | 0.672      |
| AbsLearningOld          | 0.672      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 46.4431    |
| AveragePolicyStd        | 0.471719   |
| AverageReturn           | 2.35e+03   |
| Entropy                 | 1.98617    |
| EnvExecTime             | 2.44       |
| ExplainedVariance       | 0.877      |
| Iteration               | 582        |
| ItrTime                 | 14.1       |
| LossAfter               | -2.63984   |
| LossBefore              | -2.60566   |
| MaxReturn               | 3.34e+03   |
| MeanKL                  | 0.00986056 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.56e+03   |
| NumTrajs                | 8          |
| Perplexity              | 7.28755    |
| PolicyExecTime          | 0.617      |
| ProcessExecTime         | 0.0697     |
| StdReturn               | 604        |
| Time                    | 7.92e+03   |
| dLoss                   | 0.0341823  |
----------------------------------------
itr #583 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 583...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5164, #subsample_inputs: 5164
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.746      |
| AbsLearnSignalNew       | 0.746      |
| AbsLearningOld          | 0.746      |
| AverageDiscountedReturn | 257        |
| AveragePhiLoss          | 42.5839    |
| AveragePolicyStd        | 0.472813   |
| AverageReturn           | 1.6e+03    |
| Entropy                 | 1.99287    |
| EnvExecTime             | 1.91       |
| ExplainedVariance       | 0.878      |
| Iteration               | 583        |
| ItrTime                 | 12.9       |
| LossAfter               | 0.851675   |
| LossBefore              | 0.872926   |
| MaxReturn               | 2.48e+03   |
| MeanKL                  | 0.00648971 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 910        |
| NumTrajs                | 11         |
| Perplexity              | 7.33658    |
| PolicyExecTime          | 0.493      |
| ProcessExecTime         | 0.058      |
| StdReturn               | 373        |
| Time                    | 7.94e+03   |
| dLoss                   | 0.0212513  |
----------------------------------------
itr #584 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 584...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5096, #subsample_inputs: 5096
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.737     |
| AbsLearnSignalNew       | 0.737     |
| AbsLearningOld          | 0.737     |
| AverageDiscountedReturn | 253       |
| AveragePhiLoss          | 41.8238   |
| AveragePolicyStd        | 0.472998  |
| AverageReturn           | 1.44e+03  |
| Entropy                 | 1.9945    |
| EnvExecTime             | 1.84      |
| ExplainedVariance       | 0.868     |
| Iteration               | 584       |
| ItrTime                 | 12.7      |
| LossAfter               | 0.246755  |
| LossBefore              | 0.273855  |
| MaxReturn               | 2.93e+03  |
| MeanKL                  | 0.0064477 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 790       |
| NumTrajs                | 12        |
| Perplexity              | 7.34851   |
| PolicyExecTime          | 0.472     |
| ProcessExecTime         | 0.0569    |
| StdReturn               | 703       |
| Time                    | 7.95e+03  |
| dLoss                   | 0.0271008 |
---------------------------------------
itr #585 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 585...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5513, #subsample_inputs: 5513
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.764      |
| AbsLearnSignalNew       | 0.764      |
| AbsLearningOld          | 0.764      |
| AverageDiscountedReturn | 256        |
| AveragePhiLoss          | 44.0497    |
| AveragePolicyStd        | 0.473218   |
| AverageReturn           | 1.89e+03   |
| Entropy                 | 1.99584    |
| EnvExecTime             | 2.53       |
| ExplainedVariance       | 0.899      |
| Iteration               | 585        |
| ItrTime                 | 14.2       |
| LossAfter               | -1.80579   |
| LossBefore              | -1.77459   |
| MaxReturn               | 3.44e+03   |
| MeanKL                  | 0.00997274 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 941        |
| NumTrajs                | 10         |
| Perplexity              | 7.35837    |
| PolicyExecTime          | 0.65       |
| ProcessExecTime         | 0.0706     |
| StdReturn               | 760        |
| Time                    | 7.96e+03   |
| dLoss                   | 0.0311935  |
----------------------------------------
itr #586 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 586...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5770, #subsample_inputs: 5770
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.657      |
| AbsLearnSignalNew       | 0.657      |
| AbsLearningOld          | 0.657      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 43.4242    |
| AveragePolicyStd        | 0.472878   |
| AverageReturn           | 1.94e+03   |
| Entropy                 | 1.99386    |
| EnvExecTime             | 2.15       |
| ExplainedVariance       | 0.838      |
| Iteration               | 586        |
| ItrTime                 | 14.1       |
| LossAfter               | -1.31605   |
| LossBefore              | -1.28606   |
| MaxReturn               | 3.32e+03   |
| MeanKL                  | 0.00999814 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 800        |
| NumTrajs                | 10         |
| Perplexity              | 7.34384    |
| PolicyExecTime          | 0.546      |
| ProcessExecTime         | 0.0636     |
| StdReturn               | 889        |
| Time                    | 7.98e+03   |
| dLoss                   | 0.0299909  |
----------------------------------------
itr #587 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 587...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5247, #subsample_inputs: 5247
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.712      |
| AbsLearnSignalNew       | 0.712      |
| AbsLearningOld          | 0.712      |
| AverageDiscountedReturn | 255        |
| AveragePhiLoss          | 41.8912    |
| AveragePolicyStd        | 0.472218   |
| AverageReturn           | 1.78e+03   |
| Entropy                 | 1.99024    |
| EnvExecTime             | 1.99       |
| ExplainedVariance       | 0.912      |
| Iteration               | 587        |
| ItrTime                 | 13.1       |
| LossAfter               | 0.0348281  |
| LossBefore              | 0.0633469  |
| MaxReturn               | 3.22e+03   |
| MeanKL                  | 0.00989727 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 796        |
| NumTrajs                | 10         |
| Perplexity              | 7.31731    |
| PolicyExecTime          | 0.507      |
| ProcessExecTime         | 0.0597     |
| StdReturn               | 923        |
| Time                    | 7.99e+03   |
| dLoss                   | 0.0285188  |
----------------------------------------
itr #588 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 588...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5124, #subsample_inputs: 5124
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.537      |
| AbsLearnSignalNew       | 0.537      |
| AbsLearningOld          | 0.537      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 39.4721    |
| AveragePolicyStd        | 0.472264   |
| AverageReturn           | 1.68e+03   |
| Entropy                 | 1.99015    |
| EnvExecTime             | 2.19       |
| ExplainedVariance       | 0.384      |
| Iteration               | 588        |
| ItrTime                 | 13.2       |
| LossAfter               | 0.396039   |
| LossBefore              | 0.414189   |
| MaxReturn               | 3.29e+03   |
| MeanKL                  | 0.00644033 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 302        |
| NumTrajs                | 10         |
| Perplexity              | 7.3166     |
| PolicyExecTime          | 0.555      |
| ProcessExecTime         | 0.0618     |
| StdReturn               | 893        |
| Time                    | 8e+03      |
| dLoss                   | 0.0181496  |
----------------------------------------
itr #589 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 589...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5252, #subsample_inputs: 5252
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.679      |
| AbsLearnSignalNew       | 0.679      |
| AbsLearningOld          | 0.679      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 42.7975    |
| AveragePolicyStd        | 0.473738   |
| AverageReturn           | 2.51e+03   |
| Entropy                 | 2.00029    |
| EnvExecTime             | 1.9        |
| ExplainedVariance       | 0.486      |
| Iteration               | 589        |
| ItrTime                 | 13         |
| LossAfter               | 0.0190371  |
| LossBefore              | 0.0494907  |
| MaxReturn               | 3.3e+03    |
| MeanKL                  | 0.00979966 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.61e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.39117    |
| PolicyExecTime          | 0.491      |
| ProcessExecTime         | 0.0567     |
| StdReturn               | 717        |
| Time                    | 8.02e+03   |
| dLoss                   | 0.0304536  |
----------------------------------------
itr #590 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 590...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5486, #subsample_inputs: 5486
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.625      |
| AbsLearnSignalNew       | 0.625      |
| AbsLearningOld          | 0.625      |
| AverageDiscountedReturn | 256        |
| AveragePhiLoss          | 43.6371    |
| AveragePolicyStd        | 0.474188   |
| AverageReturn           | 2.65e+03   |
| Entropy                 | 2.00316    |
| EnvExecTime             | 2.35       |
| ExplainedVariance       | 0.795      |
| Iteration               | 590        |
| ItrTime                 | 14         |
| LossAfter               | 1.47905    |
| LossBefore              | 1.50808    |
| MaxReturn               | 3.38e+03   |
| MeanKL                  | 0.00643792 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.08e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.41242    |
| PolicyExecTime          | 0.587      |
| ProcessExecTime         | 0.0687     |
| StdReturn               | 887        |
| Time                    | 8.03e+03   |
| dLoss                   | 0.0290283  |
----------------------------------------
itr #591 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 591...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5180, #subsample_inputs: 5180
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.589      |
| AbsLearnSignalNew       | 0.589      |
| AbsLearningOld          | 0.589      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 44.4828    |
| AveragePolicyStd        | 0.474753   |
| AverageReturn           | 1.91e+03   |
| Entropy                 | 2.00715    |
| EnvExecTime             | 2.07       |
| ExplainedVariance       | 0.63       |
| Iteration               | 591        |
| ItrTime                 | 13.1       |
| LossAfter               | 0.602508   |
| LossBefore              | 0.625751   |
| MaxReturn               | 3.28e+03   |
| MeanKL                  | 0.00640415 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 895        |
| NumTrajs                | 9          |
| Perplexity              | 7.44205    |
| PolicyExecTime          | 0.524      |
| ProcessExecTime         | 0.0603     |
| StdReturn               | 751        |
| Time                    | 8.04e+03   |
| dLoss                   | 0.0232424  |
----------------------------------------
itr #592 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 592...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5214, #subsample_inputs: 5214
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.691     |
| AbsLearnSignalNew       | 0.691     |
| AbsLearningOld          | 0.691     |
| AverageDiscountedReturn | 242       |
| AveragePhiLoss          | 47.3342   |
| AveragePolicyStd        | 0.473224  |
| AverageReturn           | 2.8e+03   |
| Entropy                 | 1.99812   |
| EnvExecTime             | 2.17      |
| ExplainedVariance       | 0.771     |
| Iteration               | 592       |
| ItrTime                 | 13.3      |
| LossAfter               | 1.50015   |
| LossBefore              | 1.53397   |
| MaxReturn               | 3.2e+03   |
| MeanKL                  | 0.0099956 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.74e+03  |
| NumTrajs                | 6         |
| Perplexity              | 7.37516   |
| PolicyExecTime          | 0.543     |
| ProcessExecTime         | 0.0641    |
| StdReturn               | 516       |
| Time                    | 8.06e+03  |
| dLoss                   | 0.0338199 |
---------------------------------------
itr #593 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 593...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5294, #subsample_inputs: 5294
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.569      |
| AbsLearnSignalNew       | 0.569      |
| AbsLearningOld          | 0.569      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 45.9261    |
| AveragePolicyStd        | 0.474521   |
| AverageReturn           | 2.21e+03   |
| Entropy                 | 2.00694    |
| EnvExecTime             | 2.16       |
| ExplainedVariance       | 0.74       |
| Iteration               | 593        |
| ItrTime                 | 13.4       |
| LossAfter               | -2.1905    |
| LossBefore              | -2.16692   |
| MaxReturn               | 3.29e+03   |
| MeanKL                  | 0.00714128 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.3e+03    |
| NumTrajs                | 8          |
| Perplexity              | 7.44049    |
| PolicyExecTime          | 0.551      |
| ProcessExecTime         | 0.0623     |
| StdReturn               | 697        |
| Time                    | 8.07e+03   |
| dLoss                   | 0.0235789  |
----------------------------------------
itr #594 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 594...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5136, #subsample_inputs: 5136
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.617      |
| AbsLearnSignalNew       | 0.617      |
| AbsLearningOld          | 0.617      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 42.631     |
| AveragePolicyStd        | 0.474256   |
| AverageReturn           | 2.43e+03   |
| Entropy                 | 2.00552    |
| EnvExecTime             | 2.05       |
| ExplainedVariance       | 0.794      |
| Iteration               | 594        |
| ItrTime                 | 13         |
| LossAfter               | -0.384168  |
| LossBefore              | -0.363559  |
| MaxReturn               | 3.17e+03   |
| MeanKL                  | 0.00640289 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.43e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.42996    |
| PolicyExecTime          | 0.525      |
| ProcessExecTime         | 0.0591     |
| StdReturn               | 532        |
| Time                    | 8.08e+03   |
| dLoss                   | 0.0206086  |
----------------------------------------
itr #595 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 595...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5130, #subsample_inputs: 5130
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.681      |
| AbsLearnSignalNew       | 0.681      |
| AbsLearningOld          | 0.681      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 43.386     |
| AveragePolicyStd        | 0.47469    |
| AverageReturn           | 2.44e+03   |
| Entropy                 | 2.00803    |
| EnvExecTime             | 1.93       |
| ExplainedVariance       | 0.852      |
| Iteration               | 595        |
| ItrTime                 | 12.9       |
| LossAfter               | -0.620137  |
| LossBefore              | -0.585548  |
| MaxReturn               | 3.26e+03   |
| MeanKL                  | 0.00998581 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.22e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.44866    |
| PolicyExecTime          | 0.485      |
| ProcessExecTime         | 0.0598     |
| StdReturn               | 809        |
| Time                    | 8.1e+03    |
| dLoss                   | 0.0345891  |
----------------------------------------
itr #596 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 596...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5748, #subsample_inputs: 5748
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.683      |
| AbsLearnSignalNew       | 0.683      |
| AbsLearningOld          | 0.683      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 45.3879    |
| AveragePolicyStd        | 0.474431   |
| AverageReturn           | 1.94e+03   |
| Entropy                 | 2.0074     |
| EnvExecTime             | 2.41       |
| ExplainedVariance       | 0.869      |
| Iteration               | 596        |
| ItrTime                 | 14.4       |
| LossAfter               | 0.249509   |
| LossBefore              | 0.274367   |
| MaxReturn               | 3.26e+03   |
| MeanKL                  | 0.00640281 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 904        |
| NumTrajs                | 10         |
| Perplexity              | 7.44391    |
| PolicyExecTime          | 0.617      |
| ProcessExecTime         | 0.0684     |
| StdReturn               | 709        |
| Time                    | 8.11e+03   |
| dLoss                   | 0.0248582  |
----------------------------------------
itr #597 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 597...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5771, #subsample_inputs: 5771
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.668      |
| AbsLearnSignalNew       | 0.668      |
| AbsLearningOld          | 0.668      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 42.6473    |
| AveragePolicyStd        | 0.474322   |
| AverageReturn           | 2.72e+03   |
| Entropy                 | 2.00646    |
| EnvExecTime             | 2.43       |
| ExplainedVariance       | 0.752      |
| Iteration               | 597        |
| ItrTime                 | 14.4       |
| LossAfter               | 0.453115   |
| LossBefore              | 0.493733   |
| MaxReturn               | 3.36e+03   |
| MeanKL                  | 0.00985573 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.85e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.43694    |
| PolicyExecTime          | 0.618      |
| ProcessExecTime         | 0.0695     |
| StdReturn               | 636        |
| Time                    | 8.13e+03   |
| dLoss                   | 0.040618   |
----------------------------------------
itr #598 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 598...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5757, #subsample_inputs: 5757
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.655     |
| AbsLearnSignalNew       | 0.655     |
| AbsLearningOld          | 0.655     |
| AverageDiscountedReturn | 249       |
| AveragePhiLoss          | 43.1842   |
| AveragePolicyStd        | 0.473087  |
| AverageReturn           | 2.4e+03   |
| Entropy                 | 1.99842   |
| EnvExecTime             | 2.54      |
| ExplainedVariance       | 0.811     |
| Iteration               | 598       |
| ItrTime                 | 14.6      |
| LossAfter               | 0.423904  |
| LossBefore              | 0.448001  |
| MaxReturn               | 3.23e+03  |
| MeanKL                  | 0.0064899 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.82e+03  |
| NumTrajs                | 8         |
| Perplexity              | 7.37738   |
| PolicyExecTime          | 0.648     |
| ProcessExecTime         | 0.0725    |
| StdReturn               | 381       |
| Time                    | 8.14e+03  |
| dLoss                   | 0.0240967 |
---------------------------------------
itr #599 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 599...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5057, #subsample_inputs: 5057
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.743      |
| AbsLearnSignalNew       | 0.743      |
| AbsLearningOld          | 0.743      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 42.9396    |
| AveragePolicyStd        | 0.472727   |
| AverageReturn           | 2.09e+03   |
| Entropy                 | 1.99556    |
| EnvExecTime             | 2.04       |
| ExplainedVariance       | 0.89       |
| Iteration               | 599        |
| ItrTime                 | 12.9       |
| LossAfter               | 0.955427   |
| LossBefore              | 0.986911   |
| MaxReturn               | 3.2e+03    |
| MeanKL                  | 0.00997877 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.07e+03   |
| NumTrajs                | 8          |
| Perplexity              | 7.35634    |
| PolicyExecTime          | 0.526      |
| ProcessExecTime         | 0.0593     |
| StdReturn               | 771        |
| Time                    | 8.15e+03   |
| dLoss                   | 0.0314832  |
----------------------------------------
itr #600 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 600...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5235, #subsample_inputs: 5235
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.739      |
| AbsLearnSignalNew       | 0.739      |
| AbsLearningOld          | 0.739      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 41.8062    |
| AveragePolicyStd        | 0.47392    |
| AverageReturn           | 2.79e+03   |
| Entropy                 | 2.00281    |
| EnvExecTime             | 2.4        |
| ExplainedVariance       | 0.907      |
| Iteration               | 600        |
| ItrTime                 | 13.6       |
| LossAfter               | 0.196735   |
| LossBefore              | 0.222887   |
| MaxReturn               | 3.23e+03   |
| MeanKL                  | 0.00646755 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.48e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.40986    |
| PolicyExecTime          | 0.605      |
| ProcessExecTime         | 0.0683     |
| StdReturn               | 621        |
| Time                    | 8.17e+03   |
| dLoss                   | 0.0261521  |
----------------------------------------
itr #601 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 601...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5378, #subsample_inputs: 5378
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.705     |
| AbsLearnSignalNew       | 0.705     |
| AbsLearningOld          | 0.706     |
| AverageDiscountedReturn | 243       |
| AveragePhiLoss          | 42.1226   |
| AveragePolicyStd        | 0.474662  |
| AverageReturn           | 2.48e+03  |
| Entropy                 | 2.00837   |
| EnvExecTime             | 2.56      |
| ExplainedVariance       | 0.883     |
| Iteration               | 601       |
| ItrTime                 | 14.1      |
| LossAfter               | -1.09674  |
| LossBefore              | -1.06472  |
| MaxReturn               | 3.24e+03  |
| MeanKL                  | 0.0099363 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.54e+03  |
| NumTrajs                | 7         |
| Perplexity              | 7.45118   |
| PolicyExecTime          | 0.648     |
| ProcessExecTime         | 0.0727    |
| StdReturn               | 686       |
| Time                    | 8.18e+03  |
| dLoss                   | 0.0320206 |
---------------------------------------
itr #602 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 602...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5509, #subsample_inputs: 5509
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.641      |
| AbsLearnSignalNew       | 0.641      |
| AbsLearningOld          | 0.641      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 38.2466    |
| AveragePolicyStd        | 0.472661   |
| AverageReturn           | 2.56e+03   |
| Entropy                 | 1.99484    |
| EnvExecTime             | 2.72       |
| ExplainedVariance       | 0.752      |
| Iteration               | 602        |
| ItrTime                 | 14.4       |
| LossAfter               | -0.528473  |
| LossBefore              | -0.502306  |
| MaxReturn               | 3.26e+03   |
| MeanKL                  | 0.00988682 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.87e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.35104    |
| PolicyExecTime          | 0.679      |
| ProcessExecTime         | 0.0751     |
| StdReturn               | 569        |
| Time                    | 8.2e+03    |
| dLoss                   | 0.0261674  |
----------------------------------------
itr #603 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 603...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5138, #subsample_inputs: 5138
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.655      |
| AbsLearnSignalNew       | 0.655      |
| AbsLearningOld          | 0.655      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 38.9311    |
| AveragePolicyStd        | 0.473807   |
| AverageReturn           | 2.85e+03   |
| Entropy                 | 2.00186    |
| EnvExecTime             | 2.29       |
| ExplainedVariance       | 0.839      |
| Iteration               | 603        |
| ItrTime                 | 13.3       |
| LossAfter               | 0.604353   |
| LossBefore              | 0.634847   |
| MaxReturn               | 3.33e+03   |
| MeanKL                  | 0.00971713 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 2.33e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.40281    |
| PolicyExecTime          | 0.581      |
| ProcessExecTime         | 0.0664     |
| StdReturn               | 387        |
| Time                    | 8.21e+03   |
| dLoss                   | 0.0304935  |
----------------------------------------
itr #604 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 604...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5212, #subsample_inputs: 5212
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.559      |
| AbsLearnSignalNew       | 0.559      |
| AbsLearningOld          | 0.559      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 35.4215    |
| AveragePolicyStd        | 0.474003   |
| AverageReturn           | 2.48e+03   |
| Entropy                 | 2.00362    |
| EnvExecTime             | 2.16       |
| ExplainedVariance       | 0.768      |
| Iteration               | 604        |
| ItrTime                 | 13.3       |
| LossAfter               | 0.471254   |
| LossBefore              | 0.494928   |
| MaxReturn               | 3.24e+03   |
| MeanKL                  | 0.00991398 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 956        |
| NumTrajs                | 7          |
| Perplexity              | 7.41588    |
| PolicyExecTime          | 0.556      |
| ProcessExecTime         | 0.0623     |
| StdReturn               | 717        |
| Time                    | 8.22e+03   |
| dLoss                   | 0.0236734  |
----------------------------------------
itr #605 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 605...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5555, #subsample_inputs: 5555
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.654      |
| AbsLearnSignalNew       | 0.654      |
| AbsLearningOld          | 0.654      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 44.6774    |
| AveragePolicyStd        | 0.475737   |
| AverageReturn           | 2.96e+03   |
| Entropy                 | 2.01531    |
| EnvExecTime             | 2.5        |
| ExplainedVariance       | 0.878      |
| Iteration               | 605        |
| ItrTime                 | 14.2       |
| LossAfter               | 2.14361    |
| LossBefore              | 2.16867    |
| MaxReturn               | 3.23e+03   |
| MeanKL                  | 0.00998896 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.85e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.50304    |
| PolicyExecTime          | 0.633      |
| ProcessExecTime         | 0.0743     |
| StdReturn               | 500        |
| Time                    | 8.24e+03   |
| dLoss                   | 0.0250692  |
----------------------------------------
itr #606 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 606...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5127, #subsample_inputs: 5127
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.57       |
| AbsLearnSignalNew       | 0.57       |
| AbsLearningOld          | 0.569      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 38.6273    |
| AveragePolicyStd        | 0.474831   |
| AverageReturn           | 2.77e+03   |
| Entropy                 | 2.00996    |
| EnvExecTime             | 2.46       |
| ExplainedVariance       | 0.774      |
| Iteration               | 606        |
| ItrTime                 | 13.5       |
| LossAfter               | -0.86009   |
| LossBefore              | -0.817443  |
| MaxReturn               | 3.26e+03   |
| MeanKL                  | 0.00984988 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.52e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.46299    |
| PolicyExecTime          | 0.618      |
| ProcessExecTime         | 0.0704     |
| StdReturn               | 654        |
| Time                    | 8.25e+03   |
| dLoss                   | 0.042647   |
----------------------------------------
itr #607 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 607...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5000, #subsample_inputs: 5000
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.668      |
| AbsLearnSignalNew       | 0.668      |
| AbsLearningOld          | 0.668      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 45.3952    |
| AveragePolicyStd        | 0.474313   |
| AverageReturn           | 3.19e+03   |
| Entropy                 | 2.00615    |
| EnvExecTime             | 1.61       |
| ExplainedVariance       | 0.898      |
| Iteration               | 607        |
| ItrTime                 | 12.2       |
| LossAfter               | -0.789289  |
| LossBefore              | -0.765696  |
| MaxReturn               | 3.25e+03   |
| MeanKL                  | 0.00659138 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 3.12e+03   |
| NumTrajs                | 5          |
| Perplexity              | 7.4346     |
| PolicyExecTime          | 0.408      |
| ProcessExecTime         | 0.0508     |
| StdReturn               | 49.5       |
| Time                    | 8.26e+03   |
| dLoss                   | 0.0235927  |
----------------------------------------
itr #608 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 608...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5272, #subsample_inputs: 5272
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.44       |
| AbsLearnSignalNew       | 0.44       |
| AbsLearningOld          | 0.44       |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 36.3817    |
| AveragePolicyStd        | 0.473469   |
| AverageReturn           | 2.45e+03   |
| Entropy                 | 2.00071    |
| EnvExecTime             | 1.98       |
| ExplainedVariance       | 0.437      |
| Iteration               | 608        |
| ItrTime                 | 13.1       |
| LossAfter               | -1.50025   |
| LossBefore              | -1.46585   |
| MaxReturn               | 3.23e+03   |
| MeanKL                  | 0.00952619 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.29e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.39433    |
| PolicyExecTime          | 0.507      |
| ProcessExecTime         | 0.0596     |
| StdReturn               | 695        |
| Time                    | 8.28e+03   |
| dLoss                   | 0.0343997  |
----------------------------------------
itr #609 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 609...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5408, #subsample_inputs: 5408
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.644      |
| AbsLearnSignalNew       | 0.644      |
| AbsLearningOld          | 0.644      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 50.7693    |
| AveragePolicyStd        | 0.474036   |
| AverageReturn           | 2.53e+03   |
| Entropy                 | 2.00521    |
| EnvExecTime             | 2.44       |
| ExplainedVariance       | 0.926      |
| Iteration               | 609        |
| ItrTime                 | 14         |
| LossAfter               | -0.890015  |
| LossBefore              | -0.859236  |
| MaxReturn               | 3.17e+03   |
| MeanKL                  | 0.00980839 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.69e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.42763    |
| PolicyExecTime          | 0.614      |
| ProcessExecTime         | 0.0677     |
| StdReturn               | 511        |
| Time                    | 8.29e+03   |
| dLoss                   | 0.0307795  |
----------------------------------------
itr #610 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 610...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5186, #subsample_inputs: 5186
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.703      |
| AbsLearnSignalNew       | 0.703      |
| AbsLearningOld          | 0.703      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 41.9082    |
| AveragePolicyStd        | 0.47249    |
| AverageReturn           | 2.81e+03   |
| Entropy                 | 1.9948     |
| EnvExecTime             | 2.61       |
| ExplainedVariance       | 0.9        |
| Iteration               | 610        |
| ItrTime                 | 13.8       |
| LossAfter               | 0.0560808  |
| LossBefore              | 0.0819561  |
| MaxReturn               | 3.27e+03   |
| MeanKL                  | 0.00995221 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.95e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.35071    |
| PolicyExecTime          | 0.657      |
| ProcessExecTime         | 0.0712     |
| StdReturn               | 573        |
| Time                    | 8.3e+03    |
| dLoss                   | 0.0258753  |
----------------------------------------
itr #611 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 611...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5235, #subsample_inputs: 5235
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.685     |
| AbsLearnSignalNew       | 0.685     |
| AbsLearningOld          | 0.685     |
| AverageDiscountedReturn | 243       |
| AveragePhiLoss          | 41.415    |
| AveragePolicyStd        | 0.473309  |
| AverageReturn           | 2.82e+03  |
| Entropy                 | 2.00053   |
| EnvExecTime             | 2.72      |
| ExplainedVariance       | 0.912     |
| Iteration               | 611       |
| ItrTime                 | 14.1      |
| LossAfter               | 0.398748  |
| LossBefore              | 0.432227  |
| MaxReturn               | 3.28e+03  |
| MeanKL                  | 0.0099432 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.9e+03   |
| NumTrajs                | 6         |
| Perplexity              | 7.39295   |
| PolicyExecTime          | 0.675     |
| ProcessExecTime         | 0.0755    |
| StdReturn               | 556       |
| Time                    | 8.32e+03  |
| dLoss                   | 0.0334787 |
---------------------------------------
itr #612 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 612...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5009, #subsample_inputs: 5009
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.712      |
| AbsLearnSignalNew       | 0.712      |
| AbsLearningOld          | 0.712      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 39.2135    |
| AveragePolicyStd        | 0.473787   |
| AverageReturn           | 2.75e+03   |
| Entropy                 | 2.00392    |
| EnvExecTime             | 2.04       |
| ExplainedVariance       | 0.871      |
| Iteration               | 612        |
| ItrTime                 | 12.8       |
| LossAfter               | 0.183528   |
| LossBefore              | 0.209229   |
| MaxReturn               | 3.3e+03    |
| MeanKL                  | 0.00645637 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 2.18e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.41809    |
| PolicyExecTime          | 0.521      |
| ProcessExecTime         | 0.0594     |
| StdReturn               | 508        |
| Time                    | 8.33e+03   |
| dLoss                   | 0.0257012  |
----------------------------------------
itr #613 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 613...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5187, #subsample_inputs: 5187
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.653      |
| AbsLearnSignalNew       | 0.653      |
| AbsLearningOld          | 0.653      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 43.2516    |
| AveragePolicyStd        | 0.474262   |
| AverageReturn           | 2.44e+03   |
| Entropy                 | 2.00662    |
| EnvExecTime             | 2.34       |
| ExplainedVariance       | 0.889      |
| Iteration               | 613        |
| ItrTime                 | 13.5       |
| LossAfter               | -1.82384   |
| LossBefore              | -1.78777   |
| MaxReturn               | 3.19e+03   |
| MeanKL                  | 0.00990963 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.91e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.43812    |
| PolicyExecTime          | 0.584      |
| ProcessExecTime         | 0.0662     |
| StdReturn               | 416        |
| Time                    | 8.35e+03   |
| dLoss                   | 0.0360689  |
----------------------------------------
itr #614 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 614...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5365, #subsample_inputs: 5365
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.574      |
| AbsLearnSignalNew       | 0.574      |
| AbsLearningOld          | 0.574      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 41.6446    |
| AveragePolicyStd        | 0.473806   |
| AverageReturn           | 2.98e+03   |
| Entropy                 | 2.00421    |
| EnvExecTime             | 2.31       |
| ExplainedVariance       | 0.728      |
| Iteration               | 614        |
| ItrTime                 | 13.8       |
| LossAfter               | -0.77334   |
| LossBefore              | -0.749164  |
| MaxReturn               | 3.39e+03   |
| MeanKL                  | 0.00643809 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 2.23e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.42023    |
| PolicyExecTime          | 0.578      |
| ProcessExecTime         | 0.0662     |
| StdReturn               | 476        |
| Time                    | 8.36e+03   |
| dLoss                   | 0.0241758  |
----------------------------------------
itr #615 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 615...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5000, #subsample_inputs: 5000
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.597      |
| AbsLearnSignalNew       | 0.597      |
| AbsLearningOld          | 0.597      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 41.4322    |
| AveragePolicyStd        | 0.473876   |
| AverageReturn           | 3.23e+03   |
| Entropy                 | 2.00424    |
| EnvExecTime             | 1.6        |
| ExplainedVariance       | 0.873      |
| Iteration               | 615        |
| ItrTime                 | 12.2       |
| LossAfter               | 0.200568   |
| LossBefore              | 0.231413   |
| MaxReturn               | 3.3e+03    |
| MeanKL                  | 0.00992083 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 3.15e+03   |
| NumTrajs                | 5          |
| Perplexity              | 7.42042    |
| PolicyExecTime          | 0.404      |
| ProcessExecTime         | 0.0534     |
| StdReturn               | 46.8       |
| Time                    | 8.37e+03   |
| dLoss                   | 0.0308442  |
----------------------------------------
itr #616 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 616...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5642, #subsample_inputs: 5642
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.227     |
| AbsLearnSignalNew       | 0.227     |
| AbsLearningOld          | 0.227     |
| AverageDiscountedReturn | 245       |
| AveragePhiLoss          | 38.8713   |
| AveragePolicyStd        | 0.474449  |
| AverageReturn           | 2.64e+03  |
| Entropy                 | 2.00757   |
| EnvExecTime             | 2.58      |
| ExplainedVariance       | -0.518    |
| Iteration               | 616       |
| ItrTime                 | 14.4      |
| LossAfter               | -0.549184 |
| LossBefore              | -0.488293 |
| MaxReturn               | 3.29e+03  |
| MeanKL                  | 0.0099881 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.71e+03  |
| NumTrajs                | 7         |
| Perplexity              | 7.44523   |
| PolicyExecTime          | 0.643     |
| ProcessExecTime         | 0.0743    |
| StdReturn               | 621       |
| Time                    | 8.39e+03  |
| dLoss                   | 0.0608913 |
---------------------------------------
itr #617 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 617...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5735, #subsample_inputs: 5735
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.495      |
| AbsLearnSignalNew       | 0.495      |
| AbsLearningOld          | 0.495      |
| AverageDiscountedReturn | 232        |
| AveragePhiLoss          | 33.1938    |
| AveragePolicyStd        | 0.474959   |
| AverageReturn           | 2.62e+03   |
| Entropy                 | 2.01084    |
| EnvExecTime             | 2.86       |
| ExplainedVariance       | 0.627      |
| Iteration               | 617        |
| ItrTime                 | 14.9       |
| LossAfter               | 1.11442    |
| LossBefore              | 1.1369     |
| MaxReturn               | 3.26e+03   |
| MeanKL                  | 0.00640494 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 293        |
| NumTrajs                | 7          |
| Perplexity              | 7.46957    |
| PolicyExecTime          | 0.725      |
| ProcessExecTime         | 0.0779     |
| StdReturn               | 990        |
| Time                    | 8.4e+03    |
| dLoss                   | 0.0224791  |
----------------------------------------
itr #618 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 618...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5605, #subsample_inputs: 5605
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.68       |
| AbsLearnSignalNew       | 0.68       |
| AbsLearningOld          | 0.68       |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 43.753     |
| AveragePolicyStd        | 0.475713   |
| AverageReturn           | 3.02e+03   |
| Entropy                 | 2.01581    |
| EnvExecTime             | 2.83       |
| ExplainedVariance       | 0.879      |
| Iteration               | 618        |
| ItrTime                 | 14.7       |
| LossAfter               | 2.12647    |
| LossBefore              | 2.14803    |
| MaxReturn               | 3.26e+03   |
| MeanKL                  | 0.00641928 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 2.45e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.50683    |
| PolicyExecTime          | 0.713      |
| ProcessExecTime         | 0.0776     |
| StdReturn               | 275        |
| Time                    | 8.42e+03   |
| dLoss                   | 0.021558   |
----------------------------------------
itr #619 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 619...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5649, #subsample_inputs: 5649
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.641      |
| AbsLearnSignalNew       | 0.641      |
| AbsLearningOld          | 0.641      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 37.0333    |
| AveragePolicyStd        | 0.472807   |
| AverageReturn           | 3.09e+03   |
| Entropy                 | 1.99846    |
| EnvExecTime             | 2.84       |
| ExplainedVariance       | 0.902      |
| Iteration               | 619        |
| ItrTime                 | 14.7       |
| LossAfter               | 1.39144    |
| LossBefore              | 1.42369    |
| MaxReturn               | 3.26e+03   |
| MeanKL                  | 0.00983042 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 2.82e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.3777     |
| PolicyExecTime          | 0.726      |
| ProcessExecTime         | 0.0782     |
| StdReturn               | 187        |
| Time                    | 8.43e+03   |
| dLoss                   | 0.0322475  |
----------------------------------------
itr #620 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 620...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5539, #subsample_inputs: 5539
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.483      |
| AbsLearnSignalNew       | 0.483      |
| AbsLearningOld          | 0.483      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 38.4614    |
| AveragePolicyStd        | 0.473557   |
| AverageReturn           | 2.58e+03   |
| Entropy                 | 2.00272    |
| EnvExecTime             | 2.08       |
| ExplainedVariance       | 0.629      |
| Iteration               | 620        |
| ItrTime                 | 13.6       |
| LossAfter               | 0.633928   |
| LossBefore              | 0.665087   |
| MaxReturn               | 3.28e+03   |
| MeanKL                  | 0.00995125 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.09e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.40918    |
| PolicyExecTime          | 0.53       |
| ProcessExecTime         | 0.0618     |
| StdReturn               | 764        |
| Time                    | 8.44e+03   |
| dLoss                   | 0.0311594  |
----------------------------------------
itr #621 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 621...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5691, #subsample_inputs: 5691
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.672      |
| AbsLearnSignalNew       | 0.672      |
| AbsLearningOld          | 0.672      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 41.3596    |
| AveragePolicyStd        | 0.474503   |
| AverageReturn           | 2.38e+03   |
| Entropy                 | 2.00884    |
| EnvExecTime             | 2.47       |
| ExplainedVariance       | 0.836      |
| Iteration               | 621        |
| ItrTime                 | 14.4       |
| LossAfter               | 0.471078   |
| LossBefore              | 0.497765   |
| MaxReturn               | 3.33e+03   |
| MeanKL                  | 0.00970963 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 940        |
| NumTrajs                | 8          |
| Perplexity              | 7.45468    |
| PolicyExecTime          | 0.626      |
| ProcessExecTime         | 0.0727     |
| StdReturn               | 751        |
| Time                    | 8.46e+03   |
| dLoss                   | 0.0266871  |
----------------------------------------
itr #622 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 622...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5485, #subsample_inputs: 5485
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.598      |
| AbsLearnSignalNew       | 0.598      |
| AbsLearningOld          | 0.598      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 40.6703    |
| AveragePolicyStd        | 0.477098   |
| AverageReturn           | 2.61e+03   |
| Entropy                 | 2.02509    |
| EnvExecTime             | 2.65       |
| ExplainedVariance       | 0.806      |
| Iteration               | 622        |
| ItrTime                 | 14.3       |
| LossAfter               | -1.29601   |
| LossBefore              | -1.2686    |
| MaxReturn               | 3.33e+03   |
| MeanKL                  | 0.00992482 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.83e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.57681    |
| PolicyExecTime          | 0.67       |
| ProcessExecTime         | 0.0753     |
| StdReturn               | 576        |
| Time                    | 8.47e+03   |
| dLoss                   | 0.0274099  |
----------------------------------------
itr #623 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 623...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5264, #subsample_inputs: 5264
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.573      |
| AbsLearnSignalNew       | 0.573      |
| AbsLearningOld          | 0.573      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 58.1267    |
| AveragePolicyStd        | 0.475904   |
| AverageReturn           | 2.46e+03   |
| Entropy                 | 2.01732    |
| EnvExecTime             | 2.32       |
| ExplainedVariance       | 0.806      |
| Iteration               | 623        |
| ItrTime                 | 13.5       |
| LossAfter               | -2.84148   |
| LossBefore              | -2.80672   |
| MaxReturn               | 3.29e+03   |
| MeanKL                  | 0.00991084 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 905        |
| NumTrajs                | 7          |
| Perplexity              | 7.51814    |
| PolicyExecTime          | 0.587      |
| ProcessExecTime         | 0.065      |
| StdReturn               | 935        |
| Time                    | 8.49e+03   |
| dLoss                   | 0.0347643  |
----------------------------------------
itr #624 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 624...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5169, #subsample_inputs: 5169
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.654      |
| AbsLearnSignalNew       | 0.654      |
| AbsLearningOld          | 0.655      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 40.8007    |
| AveragePolicyStd        | 0.476529   |
| AverageReturn           | 2.83e+03   |
| Entropy                 | 2.02109    |
| EnvExecTime             | 2.41       |
| ExplainedVariance       | 0.835      |
| Iteration               | 624        |
| ItrTime                 | 13.6       |
| LossAfter               | -0.502684  |
| LossBefore              | -0.465801  |
| MaxReturn               | 3.25e+03   |
| MeanKL                  | 0.00987812 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.8e+03    |
| NumTrajs                | 6          |
| Perplexity              | 7.54657    |
| PolicyExecTime          | 0.611      |
| ProcessExecTime         | 0.0673     |
| StdReturn               | 548        |
| Time                    | 8.5e+03    |
| dLoss                   | 0.0368835  |
----------------------------------------
itr #625 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 625...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5453, #subsample_inputs: 5453
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.509      |
| AbsLearnSignalNew       | 0.509      |
| AbsLearningOld          | 0.509      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 47.3118    |
| AveragePolicyStd        | 0.476063   |
| AverageReturn           | 2.58e+03   |
| Entropy                 | 2.01792    |
| EnvExecTime             | 2.09       |
| ExplainedVariance       | 0.757      |
| Iteration               | 625        |
| ItrTime                 | 13.6       |
| LossAfter               | -0.322308  |
| LossBefore              | -0.277114  |
| MaxReturn               | 3.34e+03   |
| MeanKL                  | 0.00984664 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.34e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.52263    |
| PolicyExecTime          | 0.539      |
| ProcessExecTime         | 0.0617     |
| StdReturn               | 818        |
| Time                    | 8.51e+03   |
| dLoss                   | 0.0451936  |
----------------------------------------
itr #626 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 626...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5340, #subsample_inputs: 5340
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.496      |
| AbsLearnSignalNew       | 0.496      |
| AbsLearningOld          | 0.496      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 45.0226    |
| AveragePolicyStd        | 0.475851   |
| AverageReturn           | 2.46e+03   |
| Entropy                 | 2.0171     |
| EnvExecTime             | 2.94       |
| ExplainedVariance       | 0.511      |
| Iteration               | 626        |
| ItrTime                 | 14.6       |
| LossAfter               | 0.478503   |
| LossBefore              | 0.503143   |
| MaxReturn               | 3.24e+03   |
| MeanKL                  | 0.00671363 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 833        |
| NumTrajs                | 7          |
| Perplexity              | 7.51652    |
| PolicyExecTime          | 0.729      |
| ProcessExecTime         | 0.0784     |
| StdReturn               | 838        |
| Time                    | 8.53e+03   |
| dLoss                   | 0.0246399  |
----------------------------------------
itr #627 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 627...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5376, #subsample_inputs: 5376
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.698      |
| AbsLearnSignalNew       | 0.698      |
| AbsLearningOld          | 0.698      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 47.5283    |
| AveragePolicyStd        | 0.475044   |
| AverageReturn           | 2.9e+03    |
| Entropy                 | 2.01205    |
| EnvExecTime             | 2.49       |
| ExplainedVariance       | 0.855      |
| Iteration               | 627        |
| ItrTime                 | 14.1       |
| LossAfter               | 0.36658    |
| LossBefore              | 0.39179    |
| MaxReturn               | 3.24e+03   |
| MeanKL                  | 0.00650655 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.64e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.47866    |
| PolicyExecTime          | 0.624      |
| ProcessExecTime         | 0.0697     |
| StdReturn               | 575        |
| Time                    | 8.54e+03   |
| dLoss                   | 0.0252092  |
----------------------------------------
itr #628 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 628...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5326, #subsample_inputs: 5326
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.701      |
| AbsLearnSignalNew       | 0.701      |
| AbsLearningOld          | 0.701      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 46.4762    |
| AveragePolicyStd        | 0.476224   |
| AverageReturn           | 2.88e+03   |
| Entropy                 | 2.01942    |
| EnvExecTime             | 2.48       |
| ExplainedVariance       | 0.895      |
| Iteration               | 628        |
| ItrTime                 | 14         |
| LossAfter               | -0.487164  |
| LossBefore              | -0.459166  |
| MaxReturn               | 3.27e+03   |
| MeanKL                  | 0.00646122 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 2.03e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.53396    |
| PolicyExecTime          | 0.633      |
| ProcessExecTime         | 0.0688     |
| StdReturn               | 498        |
| Time                    | 8.56e+03   |
| dLoss                   | 0.027998   |
----------------------------------------
itr #629 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 629...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5201, #subsample_inputs: 5201
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.571      |
| AbsLearnSignalNew       | 0.571      |
| AbsLearningOld          | 0.571      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 54.1768    |
| AveragePolicyStd        | 0.474645   |
| AverageReturn           | 2.48e+03   |
| Entropy                 | 2.00873    |
| EnvExecTime             | 2.32       |
| ExplainedVariance       | 0.815      |
| Iteration               | 629        |
| ItrTime                 | 13.5       |
| LossAfter               | 0.16425    |
| LossBefore              | 0.210585   |
| MaxReturn               | 3.26e+03   |
| MeanKL                  | 0.00984398 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.6e+03    |
| NumTrajs                | 7          |
| Perplexity              | 7.45388    |
| PolicyExecTime          | 0.583      |
| ProcessExecTime         | 0.0663     |
| StdReturn               | 653        |
| Time                    | 8.57e+03   |
| dLoss                   | 0.0463353  |
----------------------------------------
itr #630 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 630...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5017, #subsample_inputs: 5017
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.644      |
| AbsLearnSignalNew       | 0.644      |
| AbsLearningOld          | 0.644      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 36.8612    |
| AveragePolicyStd        | 0.476386   |
| AverageReturn           | 2.41e+03   |
| Entropy                 | 2.02023    |
| EnvExecTime             | 2.57       |
| ExplainedVariance       | 0.852      |
| Iteration               | 630        |
| ItrTime                 | 13.5       |
| LossAfter               | -0.399962  |
| LossBefore              | -0.378501  |
| MaxReturn               | 3.22e+03   |
| MeanKL                  | 0.00641202 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.19e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.54009    |
| PolicyExecTime          | 0.65       |
| ProcessExecTime         | 0.0699     |
| StdReturn               | 714        |
| Time                    | 8.58e+03   |
| dLoss                   | 0.0214615  |
----------------------------------------
itr #631 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 631...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5194, #subsample_inputs: 5194
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.66       |
| AbsLearnSignalNew       | 0.66       |
| AbsLearningOld          | 0.66       |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 37.5039    |
| AveragePolicyStd        | 0.477173   |
| AverageReturn           | 2.45e+03   |
| Entropy                 | 2.02538    |
| EnvExecTime             | 2.17       |
| ExplainedVariance       | 0.867      |
| Iteration               | 631        |
| ItrTime                 | 13.2       |
| LossAfter               | 0.0688466  |
| LossBefore              | 0.0988615  |
| MaxReturn               | 3.28e+03   |
| MeanKL                  | 0.00989249 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 971        |
| NumTrajs                | 7          |
| Perplexity              | 7.57897    |
| PolicyExecTime          | 0.543      |
| ProcessExecTime         | 0.0626     |
| StdReturn               | 953        |
| Time                    | 8.6e+03    |
| dLoss                   | 0.0300149  |
----------------------------------------
itr #632 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 632...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5226, #subsample_inputs: 5226
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.695      |
| AbsLearnSignalNew       | 0.695      |
| AbsLearningOld          | 0.695      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 43.1864    |
| AveragePolicyStd        | 0.476897   |
| AverageReturn           | 2.45e+03   |
| Entropy                 | 2.02394    |
| EnvExecTime             | 2.05       |
| ExplainedVariance       | 0.883      |
| Iteration               | 632        |
| ItrTime                 | 13.1       |
| LossAfter               | 0.431511   |
| LossBefore              | 0.457891   |
| MaxReturn               | 3.28e+03   |
| MeanKL                  | 0.00981718 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.19e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.56809    |
| PolicyExecTime          | 0.529      |
| ProcessExecTime         | 0.0597     |
| StdReturn               | 913        |
| Time                    | 8.61e+03   |
| dLoss                   | 0.0263793  |
----------------------------------------
itr #633 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 633...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5237, #subsample_inputs: 5237
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.735      |
| AbsLearnSignalNew       | 0.735      |
| AbsLearningOld          | 0.735      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 41.4666    |
| AveragePolicyStd        | 0.479105   |
| AverageReturn           | 2.49e+03   |
| Entropy                 | 2.03855    |
| EnvExecTime             | 2.7        |
| ExplainedVariance       | 0.873      |
| Iteration               | 633        |
| ItrTime                 | 14         |
| LossAfter               | -0.638418  |
| LossBefore              | -0.606749  |
| MaxReturn               | 3.28e+03   |
| MeanKL                  | 0.00990259 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.72e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.67948    |
| PolicyExecTime          | 0.684      |
| ProcessExecTime         | 0.0735     |
| StdReturn               | 543        |
| Time                    | 8.62e+03   |
| dLoss                   | 0.0316697  |
----------------------------------------
itr #634 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 634...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5654, #subsample_inputs: 5654
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.529      |
| AbsLearnSignalNew       | 0.529      |
| AbsLearningOld          | 0.529      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 34.9253    |
| AveragePolicyStd        | 0.479084   |
| AverageReturn           | 2.32e+03   |
| Entropy                 | 2.03907    |
| EnvExecTime             | 2.53       |
| ExplainedVariance       | 0.622      |
| Iteration               | 634        |
| ItrTime                 | 14.4       |
| LossAfter               | -0.31694   |
| LossBefore              | -0.290073  |
| MaxReturn               | 3.25e+03   |
| MeanKL                  | 0.00988947 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.46e+03   |
| NumTrajs                | 8          |
| Perplexity              | 7.68344    |
| PolicyExecTime          | 0.649      |
| ProcessExecTime         | 0.0722     |
| StdReturn               | 715        |
| Time                    | 8.64e+03   |
| dLoss                   | 0.0268678  |
----------------------------------------
itr #635 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 635...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5126, #subsample_inputs: 5126
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.702      |
| AbsLearnSignalNew       | 0.702      |
| AbsLearningOld          | 0.702      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 37.4067    |
| AveragePolicyStd        | 0.478947   |
| AverageReturn           | 2.79e+03   |
| Entropy                 | 2.03893    |
| EnvExecTime             | 1.96       |
| ExplainedVariance       | 0.814      |
| Iteration               | 635        |
| ItrTime                 | 12.9       |
| LossAfter               | 0.393432   |
| LossBefore              | 0.42262    |
| MaxReturn               | 3.22e+03   |
| MeanKL                  | 0.00997556 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 2.05e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.68241    |
| PolicyExecTime          | 0.499      |
| ProcessExecTime         | 0.0588     |
| StdReturn               | 496        |
| Time                    | 8.65e+03   |
| dLoss                   | 0.0291882  |
----------------------------------------
itr #636 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 636...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5337, #subsample_inputs: 5337
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.637      |
| AbsLearnSignalNew       | 0.637      |
| AbsLearningOld          | 0.637      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 42.2338    |
| AveragePolicyStd        | 0.478114   |
| AverageReturn           | 2.54e+03   |
| Entropy                 | 2.03352    |
| EnvExecTime             | 2.19       |
| ExplainedVariance       | 0.816      |
| Iteration               | 636        |
| ItrTime                 | 13.6       |
| LossAfter               | 0.0197426  |
| LossBefore              | 0.0486596  |
| MaxReturn               | 3.34e+03   |
| MeanKL                  | 0.00646998 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.26e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.64092    |
| PolicyExecTime          | 0.552      |
| ProcessExecTime         | 0.0641     |
| StdReturn               | 784        |
| Time                    | 8.67e+03   |
| dLoss                   | 0.0289171  |
----------------------------------------
itr #637 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 637...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5374, #subsample_inputs: 5374
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.541      |
| AbsLearnSignalNew       | 0.541      |
| AbsLearningOld          | 0.541      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 44.4518    |
| AveragePolicyStd        | 0.47692    |
| AverageReturn           | 2.93e+03   |
| Entropy                 | 2.02536    |
| EnvExecTime             | 2.35       |
| ExplainedVariance       | 0.854      |
| Iteration               | 637        |
| ItrTime                 | 13.9       |
| LossAfter               | 1.79673    |
| LossBefore              | 1.82426    |
| MaxReturn               | 3.27e+03   |
| MeanKL                  | 0.00990301 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.53e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.57885    |
| PolicyExecTime          | 0.596      |
| ProcessExecTime         | 0.0692     |
| StdReturn               | 633        |
| Time                    | 8.68e+03   |
| dLoss                   | 0.0275367  |
----------------------------------------
itr #638 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 638...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5519, #subsample_inputs: 5519
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.637     |
| AbsLearnSignalNew       | 0.637     |
| AbsLearningOld          | 0.638     |
| AverageDiscountedReturn | 250       |
| AveragePhiLoss          | 41.3541   |
| AveragePolicyStd        | 0.476501  |
| AverageReturn           | 3.04e+03  |
| Entropy                 | 2.02328   |
| EnvExecTime             | 3.04      |
| ExplainedVariance       | 0.897     |
| Iteration               | 638       |
| ItrTime                 | 14.8      |
| LossAfter               | 0.344458  |
| LossBefore              | 0.376079  |
| MaxReturn               | 3.31e+03  |
| MeanKL                  | 0.0097661 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 2.27e+03  |
| NumTrajs                | 6         |
| Perplexity              | 7.56307   |
| PolicyExecTime          | 0.743     |
| ProcessExecTime         | 0.0825    |
| StdReturn               | 379       |
| Time                    | 8.69e+03  |
| dLoss                   | 0.0316212 |
---------------------------------------
itr #639 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 639...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5602, #subsample_inputs: 5602
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.601      |
| AbsLearnSignalNew       | 0.601      |
| AbsLearningOld          | 0.601      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 38.9603    |
| AveragePolicyStd        | 0.478041   |
| AverageReturn           | 2.66e+03   |
| Entropy                 | 2.03246    |
| EnvExecTime             | 2.56       |
| ExplainedVariance       | 0.79       |
| Iteration               | 639        |
| ItrTime                 | 14.3       |
| LossAfter               | 1.31148    |
| LossBefore              | 1.3426     |
| MaxReturn               | 3.3e+03    |
| MeanKL                  | 0.00644861 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.86e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.63285    |
| PolicyExecTime          | 0.64       |
| ProcessExecTime         | 0.0716     |
| StdReturn               | 560        |
| Time                    | 8.71e+03   |
| dLoss                   | 0.0311184  |
----------------------------------------
itr #640 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 640...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5457, #subsample_inputs: 5457
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.594     |
| AbsLearnSignalNew       | 0.594     |
| AbsLearningOld          | 0.594     |
| AverageDiscountedReturn | 248       |
| AveragePhiLoss          | 38.204    |
| AveragePolicyStd        | 0.477863  |
| AverageReturn           | 2.58e+03  |
| Entropy                 | 2.03146   |
| EnvExecTime             | 2.26      |
| ExplainedVariance       | 0.851     |
| Iteration               | 640       |
| ItrTime                 | 13.9      |
| LossAfter               | 1.64025   |
| LossBefore              | 1.6715    |
| MaxReturn               | 3.25e+03  |
| MeanKL                  | 0.0099545 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.8e+03   |
| NumTrajs                | 7         |
| Perplexity              | 7.6252    |
| PolicyExecTime          | 0.568     |
| ProcessExecTime         | 0.0662    |
| StdReturn               | 560       |
| Time                    | 8.72e+03  |
| dLoss                   | 0.0312524 |
---------------------------------------
itr #641 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 641...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5470, #subsample_inputs: 5470
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.558      |
| AbsLearnSignalNew       | 0.558      |
| AbsLearningOld          | 0.558      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 44.3582    |
| AveragePolicyStd        | 0.477296   |
| AverageReturn           | 2.63e+03   |
| Entropy                 | 2.0277     |
| EnvExecTime             | 2.31       |
| ExplainedVariance       | 0.666      |
| Iteration               | 641        |
| ItrTime                 | 13.8       |
| LossAfter               | -1.91078   |
| LossBefore              | -1.86728   |
| MaxReturn               | 3.39e+03   |
| MeanKL                  | 0.00993135 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.45e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.59658    |
| PolicyExecTime          | 0.581      |
| ProcessExecTime         | 0.0736     |
| StdReturn               | 716        |
| Time                    | 8.74e+03   |
| dLoss                   | 0.043504   |
----------------------------------------
itr #642 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 642...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5339, #subsample_inputs: 5339
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.651      |
| AbsLearnSignalNew       | 0.651      |
| AbsLearningOld          | 0.651      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 38.2264    |
| AveragePolicyStd        | 0.479248   |
| AverageReturn           | 2.01e+03   |
| Entropy                 | 2.03874    |
| EnvExecTime             | 2.06       |
| ExplainedVariance       | 0.886      |
| Iteration               | 642        |
| ItrTime                 | 13.4       |
| LossAfter               | -0.840976  |
| LossBefore              | -0.81575   |
| MaxReturn               | 2.99e+03   |
| MeanKL                  | 0.00961344 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.48e+03   |
| NumTrajs                | 9          |
| Perplexity              | 7.68091    |
| PolicyExecTime          | 0.52       |
| ProcessExecTime         | 0.0601     |
| StdReturn               | 425        |
| Time                    | 8.75e+03   |
| dLoss                   | 0.0252251  |
----------------------------------------
itr #643 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 643...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5245, #subsample_inputs: 5245
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.45       |
| AbsLearnSignalNew       | 0.45       |
| AbsLearningOld          | 0.45       |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 39.6381    |
| AveragePolicyStd        | 0.479947   |
| AverageReturn           | 2.89e+03   |
| Entropy                 | 2.04295    |
| EnvExecTime             | 2.01       |
| ExplainedVariance       | 0.208      |
| Iteration               | 643        |
| ItrTime                 | 13.2       |
| LossAfter               | 0.760554   |
| LossBefore              | 0.778966   |
| MaxReturn               | 3.3e+03    |
| MeanKL                  | 0.00644764 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.88e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.71333    |
| PolicyExecTime          | 0.509      |
| ProcessExecTime         | 0.06       |
| StdReturn               | 569        |
| Time                    | 8.76e+03   |
| dLoss                   | 0.018412   |
----------------------------------------
itr #644 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 644...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5772, #subsample_inputs: 5772
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.688      |
| AbsLearnSignalNew       | 0.688      |
| AbsLearningOld          | 0.688      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 38.7495    |
| AveragePolicyStd        | 0.480286   |
| AverageReturn           | 2.41e+03   |
| Entropy                 | 2.04436    |
| EnvExecTime             | 2.28       |
| ExplainedVariance       | 0.836      |
| Iteration               | 644        |
| ItrTime                 | 14.3       |
| LossAfter               | 1.77997    |
| LossBefore              | 1.80425    |
| MaxReturn               | 3.37e+03   |
| MeanKL                  | 0.00641494 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.27e+03   |
| NumTrajs                | 8          |
| Perplexity              | 7.72421    |
| PolicyExecTime          | 0.582      |
| ProcessExecTime         | 0.0655     |
| StdReturn               | 639        |
| Time                    | 8.78e+03   |
| dLoss                   | 0.0242813  |
----------------------------------------
itr #645 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 645...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5802, #subsample_inputs: 5802
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.707      |
| AbsLearnSignalNew       | 0.707      |
| AbsLearningOld          | 0.707      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 42.2196    |
| AveragePolicyStd        | 0.480197   |
| AverageReturn           | 2.14e+03   |
| Entropy                 | 2.04426    |
| EnvExecTime             | 2.39       |
| ExplainedVariance       | 0.852      |
| Iteration               | 645        |
| ItrTime                 | 14.5       |
| LossAfter               | -0.43655   |
| LossBefore              | -0.412034  |
| MaxReturn               | 3.37e+03   |
| MeanKL                  | 0.00644295 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 927        |
| NumTrajs                | 9          |
| Perplexity              | 7.72346    |
| PolicyExecTime          | 0.605      |
| ProcessExecTime         | 0.0719     |
| StdReturn               | 876        |
| Time                    | 8.79e+03   |
| dLoss                   | 0.0245157  |
----------------------------------------
itr #646 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 646...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5297, #subsample_inputs: 5297
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.663      |
| AbsLearnSignalNew       | 0.663      |
| AbsLearningOld          | 0.663      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 39.8481    |
| AveragePolicyStd        | 0.478986   |
| AverageReturn           | 2.21e+03   |
| Entropy                 | 2.03637    |
| EnvExecTime             | 2.39       |
| ExplainedVariance       | 0.878      |
| Iteration               | 646        |
| ItrTime                 | 13.7       |
| LossAfter               | 0.994956   |
| LossBefore              | 1.0174     |
| MaxReturn               | 3.24e+03   |
| MeanKL                  | 0.00640796 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.56e+03   |
| NumTrajs                | 8          |
| Perplexity              | 7.66271    |
| PolicyExecTime          | 0.606      |
| ProcessExecTime         | 0.066      |
| StdReturn               | 607        |
| Time                    | 8.81e+03   |
| dLoss                   | 0.0224458  |
----------------------------------------
itr #647 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 647...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5074, #subsample_inputs: 5074
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.631      |
| AbsLearnSignalNew       | 0.631      |
| AbsLearningOld          | 0.631      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 35.4902    |
| AveragePolicyStd        | 0.479228   |
| AverageReturn           | 2.4e+03    |
| Entropy                 | 2.03743    |
| EnvExecTime             | 2.25       |
| ExplainedVariance       | 0.874      |
| Iteration               | 647        |
| ItrTime                 | 13.2       |
| LossAfter               | -0.591797  |
| LossBefore              | -0.562425  |
| MaxReturn               | 3.29e+03   |
| MeanKL                  | 0.00647359 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.15e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.67087    |
| PolicyExecTime          | 0.566      |
| ProcessExecTime         | 0.0653     |
| StdReturn               | 800        |
| Time                    | 8.82e+03   |
| dLoss                   | 0.0293718  |
----------------------------------------
itr #648 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 648...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5268, #subsample_inputs: 5268
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.701      |
| AbsLearnSignalNew       | 0.701      |
| AbsLearningOld          | 0.701      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 42.1444    |
| AveragePolicyStd        | 0.478376   |
| AverageReturn           | 2.92e+03   |
| Entropy                 | 2.03209    |
| EnvExecTime             | 2.39       |
| ExplainedVariance       | 0.871      |
| Iteration               | 648        |
| ItrTime                 | 13.7       |
| LossAfter               | -0.702842  |
| LossBefore              | -0.681734  |
| MaxReturn               | 3.38e+03   |
| MeanKL                  | 0.00643868 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.52e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.62999    |
| PolicyExecTime          | 0.6        |
| ProcessExecTime         | 0.0702     |
| StdReturn               | 653        |
| Time                    | 8.83e+03   |
| dLoss                   | 0.0211082  |
----------------------------------------
itr #649 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 649...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5042, #subsample_inputs: 5042
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.544     |
| AbsLearnSignalNew       | 0.544     |
| AbsLearningOld          | 0.544     |
| AverageDiscountedReturn | 254       |
| AveragePhiLoss          | 36.3726   |
| AveragePolicyStd        | 0.477557  |
| AverageReturn           | 2.38e+03  |
| Entropy                 | 2.02642   |
| EnvExecTime             | 2.59      |
| ExplainedVariance       | 0.66      |
| Iteration               | 649       |
| ItrTime                 | 13.6      |
| LossAfter               | 1.17971   |
| LossBefore              | 1.20793   |
| MaxReturn               | 3.33e+03  |
| MeanKL                  | 0.0099725 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.08e+03  |
| NumTrajs                | 7         |
| Perplexity              | 7.5869    |
| PolicyExecTime          | 0.647     |
| ProcessExecTime         | 0.0715    |
| StdReturn               | 824       |
| Time                    | 8.85e+03  |
| dLoss                   | 0.028219  |
---------------------------------------
itr #650 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 650...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5227, #subsample_inputs: 5227
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.72       |
| AbsLearnSignalNew       | 0.72       |
| AbsLearningOld          | 0.72       |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 39.4171    |
| AveragePolicyStd        | 0.477628   |
| AverageReturn           | 2.2e+03    |
| Entropy                 | 2.02672    |
| EnvExecTime             | 2.44       |
| ExplainedVariance       | 0.868      |
| Iteration               | 650        |
| ItrTime                 | 13.7       |
| LossAfter               | -0.477041  |
| LossBefore              | -0.450689  |
| MaxReturn               | 3.3e+03    |
| MeanKL                  | 0.00644934 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.29e+03   |
| NumTrajs                | 8          |
| Perplexity              | 7.58912    |
| PolicyExecTime          | 0.606      |
| ProcessExecTime         | 0.0716     |
| StdReturn               | 626        |
| Time                    | 8.86e+03   |
| dLoss                   | 0.0263521  |
----------------------------------------
itr #651 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 651...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5344, #subsample_inputs: 5344
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.599      |
| AbsLearnSignalNew       | 0.599      |
| AbsLearningOld          | 0.598      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 46.5367    |
| AveragePolicyStd        | 0.476687   |
| AverageReturn           | 2.03e+03   |
| Entropy                 | 2.02085    |
| EnvExecTime             | 2.31       |
| ExplainedVariance       | 0.823      |
| Iteration               | 651        |
| ItrTime                 | 13.8       |
| LossAfter               | 0.328121   |
| LossBefore              | 0.353447   |
| MaxReturn               | 3.32e+03   |
| MeanKL                  | 0.00643352 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.23e+03   |
| NumTrajs                | 9          |
| Perplexity              | 7.54477    |
| PolicyExecTime          | 0.592      |
| ProcessExecTime         | 0.0648     |
| StdReturn               | 636        |
| Time                    | 8.88e+03   |
| dLoss                   | 0.0253257  |
----------------------------------------
itr #652 | 
Mem: 740.734375
Obtaining samples...
Obtaining samples for iteration 652...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5957, #subsample_inputs: 5957
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.451      |
| AbsLearnSignalNew       | 0.451      |
| AbsLearningOld          | 0.451      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 38.5411    |
| AveragePolicyStd        | 0.476365   |
| AverageReturn           | 2.46e+03   |
| Entropy                 | 2.01876    |
| EnvExecTime             | 2.28       |
| ExplainedVariance       | 0.356      |
| Iteration               | 652        |
| ItrTime                 | 14.6       |
| LossAfter               | 0.121683   |
| LossBefore              | 0.14255    |
| MaxReturn               | 3.3e+03    |
| MeanKL                  | 0.00996703 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.25e+03   |
| NumTrajs                | 8          |
| Perplexity              | 7.52895    |
| PolicyExecTime          | 0.577      |
| ProcessExecTime         | 0.0664     |
| StdReturn               | 812        |
| Time                    | 8.89e+03   |
| dLoss                   | 0.0208666  |
----------------------------------------
itr #653 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 653...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5295, #subsample_inputs: 5295
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.631      |
| AbsLearnSignalNew       | 0.631      |
| AbsLearningOld          | 0.631      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 37.953     |
| AveragePolicyStd        | 0.476759   |
| AverageReturn           | 2.23e+03   |
| Entropy                 | 2.02106    |
| EnvExecTime             | 2.48       |
| ExplainedVariance       | 0.773      |
| Iteration               | 653        |
| ItrTime                 | 13.9       |
| LossAfter               | -1.04816   |
| LossBefore              | -1.02407   |
| MaxReturn               | 3.3e+03    |
| MeanKL                  | 0.00645423 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.77e+03   |
| NumTrajs                | 8          |
| Perplexity              | 7.54631    |
| PolicyExecTime          | 0.621      |
| ProcessExecTime         | 0.0693     |
| StdReturn               | 575        |
| Time                    | 8.9e+03    |
| dLoss                   | 0.0240929  |
----------------------------------------
itr #654 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 654...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5001, #subsample_inputs: 5001
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.51       |
| AbsLearnSignalNew       | 0.51       |
| AbsLearningOld          | 0.51       |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 35.4162    |
| AveragePolicyStd        | 0.475761   |
| AverageReturn           | 2.41e+03   |
| Entropy                 | 2.01505    |
| EnvExecTime             | 2.27       |
| ExplainedVariance       | 0.699      |
| Iteration               | 654        |
| ItrTime                 | 13.1       |
| LossAfter               | 0.800673   |
| LossBefore              | 0.826219   |
| MaxReturn               | 3.23e+03   |
| MeanKL                  | 0.00994437 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.35e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.50107    |
| PolicyExecTime          | 0.565      |
| ProcessExecTime         | 0.0659     |
| StdReturn               | 710        |
| Time                    | 8.92e+03   |
| dLoss                   | 0.025546   |
----------------------------------------
itr #655 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 655...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5164, #subsample_inputs: 5164
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.666      |
| AbsLearnSignalNew       | 0.666      |
| AbsLearningOld          | 0.665      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 39.753     |
| AveragePolicyStd        | 0.476686   |
| AverageReturn           | 2.15e+03   |
| Entropy                 | 2.02031    |
| EnvExecTime             | 2.18       |
| ExplainedVariance       | 0.883      |
| Iteration               | 655        |
| ItrTime                 | 13.3       |
| LossAfter               | -0.308202  |
| LossBefore              | -0.283885  |
| MaxReturn               | 3.24e+03   |
| MeanKL                  | 0.00645114 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.5e+03    |
| NumTrajs                | 8          |
| Perplexity              | 7.54069    |
| PolicyExecTime          | 0.56       |
| ProcessExecTime         | 0.0621     |
| StdReturn               | 631        |
| Time                    | 8.93e+03   |
| dLoss                   | 0.0243168  |
----------------------------------------
itr #656 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 656...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5051, #subsample_inputs: 5051
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.656      |
| AbsLearnSignalNew       | 0.656      |
| AbsLearningOld          | 0.656      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 38.6443    |
| AveragePolicyStd        | 0.476226   |
| AverageReturn           | 1.88e+03   |
| Entropy                 | 2.01706    |
| EnvExecTime             | 2.09       |
| ExplainedVariance       | 0.826      |
| Iteration               | 656        |
| ItrTime                 | 13         |
| LossAfter               | 0.6415     |
| LossBefore              | 0.666156   |
| MaxReturn               | 2.32e+03   |
| MeanKL                  | 0.00651035 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.46e+03   |
| NumTrajs                | 9          |
| Perplexity              | 7.51616    |
| PolicyExecTime          | 0.527      |
| ProcessExecTime         | 0.0631     |
| StdReturn               | 272        |
| Time                    | 8.94e+03   |
| dLoss                   | 0.0246556  |
----------------------------------------
itr #657 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 657...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5243, #subsample_inputs: 5243
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.728      |
| AbsLearnSignalNew       | 0.728      |
| AbsLearningOld          | 0.728      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 40.0537    |
| AveragePolicyStd        | 0.476124   |
| AverageReturn           | 1.76e+03   |
| Entropy                 | 2.01592    |
| EnvExecTime             | 2.13       |
| ExplainedVariance       | 0.912      |
| Iteration               | 657        |
| ItrTime                 | 13.3       |
| LossAfter               | -0.736204  |
| LossBefore              | -0.700342  |
| MaxReturn               | 2.56e+03   |
| MeanKL                  | 0.00985555 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.43e+03   |
| NumTrajs                | 10         |
| Perplexity              | 7.50762    |
| PolicyExecTime          | 0.538      |
| ProcessExecTime         | 0.0607     |
| StdReturn               | 314        |
| Time                    | 8.96e+03   |
| dLoss                   | 0.0358626  |
----------------------------------------
itr #658 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 658...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5040, #subsample_inputs: 5040
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.508     |
| AbsLearnSignalNew       | 0.508     |
| AbsLearningOld          | 0.508     |
| AverageDiscountedReturn | 252       |
| AveragePhiLoss          | 79.9699   |
| AveragePolicyStd        | 0.475498  |
| AverageReturn           | 1.89e+03  |
| Entropy                 | 2.01214   |
| EnvExecTime             | 2.15      |
| ExplainedVariance       | 0.638     |
| Iteration               | 658       |
| ItrTime                 | 13        |
| LossAfter               | 1.08345   |
| LossBefore              | 1.10887   |
| MaxReturn               | 3.32e+03  |
| MeanKL                  | 0.0099605 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.08e+03  |
| NumTrajs                | 9         |
| Perplexity              | 7.47928   |
| PolicyExecTime          | 0.536     |
| ProcessExecTime         | 0.0629    |
| StdReturn               | 700       |
| Time                    | 8.97e+03  |
| dLoss                   | 0.0254159 |
---------------------------------------
itr #659 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 659...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5197, #subsample_inputs: 5197
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.684      |
| AbsLearnSignalNew       | 0.684      |
| AbsLearningOld          | 0.684      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 39.6289    |
| AveragePolicyStd        | 0.472795   |
| AverageReturn           | 1.61e+03   |
| Entropy                 | 1.99475    |
| EnvExecTime             | 2.13       |
| ExplainedVariance       | 0.896      |
| Iteration               | 659        |
| ItrTime                 | 13.3       |
| LossAfter               | 1.71073    |
| LossBefore              | 1.74059    |
| MaxReturn               | 2.09e+03   |
| MeanKL                  | 0.00996112 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 984        |
| NumTrajs                | 11         |
| Perplexity              | 7.35037    |
| PolicyExecTime          | 0.539      |
| ProcessExecTime         | 0.0618     |
| StdReturn               | 252        |
| Time                    | 8.98e+03   |
| dLoss                   | 0.029857   |
----------------------------------------
itr #660 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 660...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5211, #subsample_inputs: 5211
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.727      |
| AbsLearnSignalNew       | 0.727      |
| AbsLearningOld          | 0.727      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 46.5376    |
| AveragePolicyStd        | 0.471455   |
| AverageReturn           | 1.77e+03   |
| Entropy                 | 1.98632    |
| EnvExecTime             | 2.29       |
| ExplainedVariance       | 0.851      |
| Iteration               | 660        |
| ItrTime                 | 13.4       |
| LossAfter               | -0.606472  |
| LossBefore              | -0.573093  |
| MaxReturn               | 2.77e+03   |
| MeanKL                  | 0.00647478 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.22e+03   |
| NumTrajs                | 10         |
| Perplexity              | 7.28866    |
| PolicyExecTime          | 0.574      |
| ProcessExecTime         | 0.0643     |
| StdReturn               | 414        |
| Time                    | 9e+03      |
| dLoss                   | 0.0333792  |
----------------------------------------
itr #661 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 661...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5089, #subsample_inputs: 5089
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.721      |
| AbsLearnSignalNew       | 0.721      |
| AbsLearningOld          | 0.721      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 41.5717    |
| AveragePolicyStd        | 0.471176   |
| AverageReturn           | 1.72e+03   |
| Entropy                 | 1.98493    |
| EnvExecTime             | 1.94       |
| ExplainedVariance       | 0.918      |
| Iteration               | 661        |
| ItrTime                 | 12.8       |
| LossAfter               | -2.09346   |
| LossBefore              | -2.06405   |
| MaxReturn               | 2.55e+03   |
| MeanKL                  | 0.00998341 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.31e+03   |
| NumTrajs                | 10         |
| Perplexity              | 7.27852    |
| PolicyExecTime          | 0.488      |
| ProcessExecTime         | 0.0575     |
| StdReturn               | 350        |
| Time                    | 9.01e+03   |
| dLoss                   | 0.0294039  |
----------------------------------------
itr #662 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 662...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5736, #subsample_inputs: 5736
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.455      |
| AbsLearnSignalNew       | 0.455      |
| AbsLearningOld          | 0.455      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 46.9603    |
| AveragePolicyStd        | 0.472896   |
| AverageReturn           | 2.16e+03   |
| Entropy                 | 1.99533    |
| EnvExecTime             | 2.36       |
| ExplainedVariance       | 0.468      |
| Iteration               | 662        |
| ItrTime                 | 14.3       |
| LossAfter               | -2.03392   |
| LossBefore              | -2.00956   |
| MaxReturn               | 3.28e+03   |
| MeanKL                  | 0.00999704 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.2e+03    |
| NumTrajs                | 9          |
| Perplexity              | 7.35463    |
| PolicyExecTime          | 0.599      |
| ProcessExecTime         | 0.067      |
| StdReturn               | 574        |
| Time                    | 9.02e+03   |
| dLoss                   | 0.0243657  |
----------------------------------------
itr #663 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 663...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5124, #subsample_inputs: 5124
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.699      |
| AbsLearnSignalNew       | 0.699      |
| AbsLearningOld          | 0.699      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 39.5081    |
| AveragePolicyStd        | 0.472673   |
| AverageReturn           | 2.46e+03   |
| Entropy                 | 1.99491    |
| EnvExecTime             | 2.11       |
| ExplainedVariance       | 0.899      |
| Iteration               | 663        |
| ItrTime                 | 13.1       |
| LossAfter               | -1.84974   |
| LossBefore              | -1.82383   |
| MaxReturn               | 3.27e+03   |
| MeanKL                  | 0.00640534 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.52e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.35153    |
| PolicyExecTime          | 0.527      |
| ProcessExecTime         | 0.064      |
| StdReturn               | 569        |
| Time                    | 9.04e+03   |
| dLoss                   | 0.0259147  |
----------------------------------------
itr #664 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 664...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5775, #subsample_inputs: 5775
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.691     |
| AbsLearnSignalNew       | 0.691     |
| AbsLearningOld          | 0.691     |
| AverageDiscountedReturn | 250       |
| AveragePhiLoss          | 43.0127   |
| AveragePolicyStd        | 0.472086  |
| AverageReturn           | 1.96e+03  |
| Entropy                 | 1.9913    |
| EnvExecTime             | 2.48      |
| ExplainedVariance       | 0.898     |
| Iteration               | 664       |
| ItrTime                 | 14.5      |
| LossAfter               | 0.312702  |
| LossBefore              | 0.340589  |
| MaxReturn               | 2.91e+03  |
| MeanKL                  | 0.0064409 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.49e+03  |
| NumTrajs                | 10        |
| Perplexity              | 7.32507   |
| PolicyExecTime          | 0.625     |
| ProcessExecTime         | 0.0735    |
| StdReturn               | 441       |
| Time                    | 9.05e+03  |
| dLoss                   | 0.0278877 |
---------------------------------------
itr #665 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 665...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5568, #subsample_inputs: 5568
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.472      |
| AbsLearnSignalNew       | 0.472      |
| AbsLearningOld          | 0.472      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 46.222     |
| AveragePolicyStd        | 0.471516   |
| AverageReturn           | 2.06e+03   |
| Entropy                 | 1.98739    |
| EnvExecTime             | 2.23       |
| ExplainedVariance       | 0.647      |
| Iteration               | 665        |
| ItrTime                 | 13.9       |
| LossAfter               | -1.17257   |
| LossBefore              | -1.14585   |
| MaxReturn               | 3.25e+03   |
| MeanKL                  | 0.00656203 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.51e+03   |
| NumTrajs                | 9          |
| Perplexity              | 7.29647    |
| PolicyExecTime          | 0.571      |
| ProcessExecTime         | 0.0644     |
| StdReturn               | 658        |
| Time                    | 9.07e+03   |
| dLoss                   | 0.0267155  |
----------------------------------------
itr #666 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 666...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5254, #subsample_inputs: 5254
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.558      |
| AbsLearnSignalNew       | 0.558      |
| AbsLearningOld          | 0.558      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 51.0845    |
| AveragePolicyStd        | 0.47119    |
| AverageReturn           | 2.21e+03   |
| Entropy                 | 1.98532    |
| EnvExecTime             | 2.19       |
| ExplainedVariance       | 0.853      |
| Iteration               | 666        |
| ItrTime                 | 13.4       |
| LossAfter               | -1.90519   |
| LossBefore              | -1.86516   |
| MaxReturn               | 3.28e+03   |
| MeanKL                  | 0.00981044 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.5e+03    |
| NumTrajs                | 8          |
| Perplexity              | 7.28136    |
| PolicyExecTime          | 0.561      |
| ProcessExecTime         | 0.0622     |
| StdReturn               | 628        |
| Time                    | 9.08e+03   |
| dLoss                   | 0.0400256  |
----------------------------------------
itr #667 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 667...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5387, #subsample_inputs: 5387
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.659      |
| AbsLearnSignalNew       | 0.659      |
| AbsLearningOld          | 0.659      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 41.103     |
| AveragePolicyStd        | 0.472215   |
| AverageReturn           | 2.27e+03   |
| Entropy                 | 1.99155    |
| EnvExecTime             | 2.25       |
| ExplainedVariance       | 0.852      |
| Iteration               | 667        |
| ItrTime                 | 13.8       |
| LossAfter               | 1.51693    |
| LossBefore              | 1.55015    |
| MaxReturn               | 3.13e+03   |
| MeanKL                  | 0.00988516 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.5e+03    |
| NumTrajs                | 8          |
| Perplexity              | 7.32688    |
| PolicyExecTime          | 0.567      |
| ProcessExecTime         | 0.0659     |
| StdReturn               | 554        |
| Time                    | 9.09e+03   |
| dLoss                   | 0.0332109  |
----------------------------------------
itr #668 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 668...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5498, #subsample_inputs: 5498
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.694      |
| AbsLearnSignalNew       | 0.694      |
| AbsLearningOld          | 0.694      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 41.328     |
| AveragePolicyStd        | 0.472143   |
| AverageReturn           | 2.06e+03   |
| Entropy                 | 1.99122    |
| EnvExecTime             | 2.29       |
| ExplainedVariance       | 0.922      |
| Iteration               | 668        |
| ItrTime                 | 13.8       |
| LossAfter               | -0.104695  |
| LossBefore              | -0.074278  |
| MaxReturn               | 2.63e+03   |
| MeanKL                  | 0.00992391 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.59e+03   |
| NumTrajs                | 9          |
| Perplexity              | 7.32448    |
| PolicyExecTime          | 0.579      |
| ProcessExecTime         | 0.0662     |
| StdReturn               | 347        |
| Time                    | 9.11e+03   |
| dLoss                   | 0.0304171  |
----------------------------------------
itr #669 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 669...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5555, #subsample_inputs: 5555
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.555      |
| AbsLearnSignalNew       | 0.555      |
| AbsLearningOld          | 0.555      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 40.8446    |
| AveragePolicyStd        | 0.472723   |
| AverageReturn           | 2.08e+03   |
| Entropy                 | 1.99459    |
| EnvExecTime             | 2.35       |
| ExplainedVariance       | 0.834      |
| Iteration               | 669        |
| ItrTime                 | 14         |
| LossAfter               | -0.123238  |
| LossBefore              | -0.0929253 |
| MaxReturn               | 3.32e+03   |
| MeanKL                  | 0.00989644 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.44e+03   |
| NumTrajs                | 9          |
| Perplexity              | 7.34917    |
| PolicyExecTime          | 0.588      |
| ProcessExecTime         | 0.0655     |
| StdReturn               | 532        |
| Time                    | 9.12e+03   |
| dLoss                   | 0.0303127  |
----------------------------------------
itr #670 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 670...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5010, #subsample_inputs: 5010
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.645      |
| AbsLearnSignalNew       | 0.645      |
| AbsLearningOld          | 0.645      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 41.5835    |
| AveragePolicyStd        | 0.472299   |
| AverageReturn           | 2.08e+03   |
| Entropy                 | 1.99219    |
| EnvExecTime             | 2.34       |
| ExplainedVariance       | 0.853      |
| Iteration               | 670        |
| ItrTime                 | 13.2       |
| LossAfter               | 0.368289   |
| LossBefore              | 0.392589   |
| MaxReturn               | 3.16e+03   |
| MeanKL                  | 0.00645115 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.44e+03   |
| NumTrajs                | 8          |
| Perplexity              | 7.33155    |
| PolicyExecTime          | 0.582      |
| ProcessExecTime         | 0.0655     |
| StdReturn               | 726        |
| Time                    | 9.13e+03   |
| dLoss                   | 0.0242999  |
----------------------------------------
itr #671 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 671...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5423, #subsample_inputs: 5423
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.668      |
| AbsLearnSignalNew       | 0.668      |
| AbsLearningOld          | 0.668      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 39.6767    |
| AveragePolicyStd        | 0.471326   |
| AverageReturn           | 2.56e+03   |
| Entropy                 | 1.98648    |
| EnvExecTime             | 2.17       |
| ExplainedVariance       | 0.891      |
| Iteration               | 671        |
| ItrTime                 | 13.7       |
| LossAfter               | 0.26943    |
| LossBefore              | 0.297777   |
| MaxReturn               | 3.28e+03   |
| MeanKL                  | 0.00985778 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.61e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.28985    |
| PolicyExecTime          | 0.553      |
| ProcessExecTime         | 0.0631     |
| StdReturn               | 564        |
| Time                    | 9.15e+03   |
| dLoss                   | 0.0283472  |
----------------------------------------
itr #672 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 672...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5126, #subsample_inputs: 5126
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.576      |
| AbsLearnSignalNew       | 0.576      |
| AbsLearningOld          | 0.576      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 45.3697    |
| AveragePolicyStd        | 0.470829   |
| AverageReturn           | 2.8e+03    |
| Entropy                 | 1.98395    |
| EnvExecTime             | 2.47       |
| ExplainedVariance       | 0.863      |
| Iteration               | 672        |
| ItrTime                 | 13.5       |
| LossAfter               | -0.926328  |
| LossBefore              | -0.899765  |
| MaxReturn               | 3.32e+03   |
| MeanKL                  | 0.00971425 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.77e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.27143    |
| PolicyExecTime          | 0.631      |
| ProcessExecTime         | 0.0692     |
| StdReturn               | 576        |
| Time                    | 9.16e+03   |
| dLoss                   | 0.0265623  |
----------------------------------------
itr #673 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 673...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5496, #subsample_inputs: 5496
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.53       |
| AbsLearnSignalNew       | 0.53       |
| AbsLearningOld          | 0.53       |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 48.3581    |
| AveragePolicyStd        | 0.471636   |
| AverageReturn           | 2.03e+03   |
| Entropy                 | 1.98851    |
| EnvExecTime             | 2.57       |
| ExplainedVariance       | 0.63       |
| Iteration               | 673        |
| ItrTime                 | 14.2       |
| LossAfter               | -0.229084  |
| LossBefore              | -0.210256  |
| MaxReturn               | 3.27e+03   |
| MeanKL                  | 0.00653158 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.23e+03   |
| NumTrajs                | 9          |
| Perplexity              | 7.30464    |
| PolicyExecTime          | 0.634      |
| ProcessExecTime         | 0.0725     |
| StdReturn               | 623        |
| Time                    | 9.18e+03   |
| dLoss                   | 0.018828   |
----------------------------------------
itr #674 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 674...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5286, #subsample_inputs: 5286
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.696      |
| AbsLearnSignalNew       | 0.696      |
| AbsLearningOld          | 0.696      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 47.3226    |
| AveragePolicyStd        | 0.471257   |
| AverageReturn           | 2.21e+03   |
| Entropy                 | 1.98594    |
| EnvExecTime             | 2.07       |
| ExplainedVariance       | 0.866      |
| Iteration               | 674        |
| ItrTime                 | 13.3       |
| LossAfter               | -0.0201595 |
| LossBefore              | 0.0021334  |
| MaxReturn               | 3.27e+03   |
| MeanKL                  | 0.00652558 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.49e+03   |
| NumTrajs                | 8          |
| Perplexity              | 7.28589    |
| PolicyExecTime          | 0.521      |
| ProcessExecTime         | 0.0602     |
| StdReturn               | 577        |
| Time                    | 9.19e+03   |
| dLoss                   | 0.0222929  |
----------------------------------------
itr #675 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 675...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5290, #subsample_inputs: 5290
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.628      |
| AbsLearnSignalNew       | 0.628      |
| AbsLearningOld          | 0.628      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 43.791     |
| AveragePolicyStd        | 0.470669   |
| AverageReturn           | 2.23e+03   |
| Entropy                 | 1.98211    |
| EnvExecTime             | 1.92       |
| ExplainedVariance       | 0.836      |
| Iteration               | 675        |
| ItrTime                 | 13.1       |
| LossAfter               | -0.968442  |
| LossBefore              | -0.941981  |
| MaxReturn               | 3.31e+03   |
| MeanKL                  | 0.00642678 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.45e+03   |
| NumTrajs                | 8          |
| Perplexity              | 7.25807    |
| PolicyExecTime          | 0.486      |
| ProcessExecTime         | 0.0577     |
| StdReturn               | 570        |
| Time                    | 9.2e+03    |
| dLoss                   | 0.0264618  |
----------------------------------------
itr #676 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 676...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5225, #subsample_inputs: 5225
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.628      |
| AbsLearnSignalNew       | 0.628      |
| AbsLearningOld          | 0.628      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 37.6748    |
| AveragePolicyStd        | 0.469798   |
| AverageReturn           | 1.95e+03   |
| Entropy                 | 1.97671    |
| EnvExecTime             | 2.08       |
| ExplainedVariance       | 0.862      |
| Iteration               | 676        |
| ItrTime                 | 13.2       |
| LossAfter               | -0.88482   |
| LossBefore              | -0.863969  |
| MaxReturn               | 3.22e+03   |
| MeanKL                  | 0.00645966 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 983        |
| NumTrajs                | 9          |
| Perplexity              | 7.21899    |
| PolicyExecTime          | 0.526      |
| ProcessExecTime         | 0.0595     |
| StdReturn               | 643        |
| Time                    | 9.22e+03   |
| dLoss                   | 0.020851   |
----------------------------------------
itr #677 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 677...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5207, #subsample_inputs: 5207
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.61       |
| AbsLearnSignalNew       | 0.61       |
| AbsLearningOld          | 0.61       |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 45.8025    |
| AveragePolicyStd        | 0.470248   |
| AverageReturn           | 2.2e+03    |
| Entropy                 | 1.97971    |
| EnvExecTime             | 1.97       |
| ExplainedVariance       | 0.816      |
| Iteration               | 677        |
| ItrTime                 | 13.1       |
| LossAfter               | 1.31476    |
| LossBefore              | 1.34921    |
| MaxReturn               | 3.25e+03   |
| MeanKL                  | 0.00643872 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.5e+03    |
| NumTrajs                | 8          |
| Perplexity              | 7.24061    |
| PolicyExecTime          | 0.502      |
| ProcessExecTime         | 0.057      |
| StdReturn               | 489        |
| Time                    | 9.23e+03   |
| dLoss                   | 0.0344424  |
----------------------------------------
itr #678 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 678...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5170, #subsample_inputs: 5170
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.69       |
| AbsLearnSignalNew       | 0.69       |
| AbsLearningOld          | 0.691      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 40.9066    |
| AveragePolicyStd        | 0.469287   |
| AverageReturn           | 1.94e+03   |
| Entropy                 | 1.97414    |
| EnvExecTime             | 2.14       |
| ExplainedVariance       | 0.892      |
| Iteration               | 678        |
| ItrTime                 | 13.2       |
| LossAfter               | 0.571449   |
| LossBefore              | 0.60222    |
| MaxReturn               | 2.84e+03   |
| MeanKL                  | 0.00989555 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.3e+03    |
| NumTrajs                | 9          |
| Perplexity              | 7.20042    |
| PolicyExecTime          | 0.54       |
| ProcessExecTime         | 0.0607     |
| StdReturn               | 473        |
| Time                    | 9.24e+03   |
| dLoss                   | 0.0307709  |
----------------------------------------
itr #679 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 679...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5111, #subsample_inputs: 5111
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.533      |
| AbsLearnSignalNew       | 0.533      |
| AbsLearningOld          | 0.533      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 34.3787    |
| AveragePolicyStd        | 0.469975   |
| AverageReturn           | 2.43e+03   |
| Entropy                 | 1.97767    |
| EnvExecTime             | 1.92       |
| ExplainedVariance       | 0.628      |
| Iteration               | 679        |
| ItrTime                 | 12.9       |
| LossAfter               | -1.77543   |
| LossBefore              | -1.75149   |
| MaxReturn               | 3.24e+03   |
| MeanKL                  | 0.00984824 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.51e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.22588    |
| PolicyExecTime          | 0.487      |
| ProcessExecTime         | 0.0567     |
| StdReturn               | 615        |
| Time                    | 9.26e+03   |
| dLoss                   | 0.023939   |
----------------------------------------
itr #680 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 680...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5532, #subsample_inputs: 5532
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.595      |
| AbsLearnSignalNew       | 0.595      |
| AbsLearningOld          | 0.595      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 35.9436    |
| AveragePolicyStd        | 0.471051   |
| AverageReturn           | 2.3e+03    |
| Entropy                 | 1.98597    |
| EnvExecTime             | 2.4        |
| ExplainedVariance       | 0.823      |
| Iteration               | 680        |
| ItrTime                 | 14         |
| LossAfter               | -1.99983   |
| LossBefore              | -1.97109   |
| MaxReturn               | 3.28e+03   |
| MeanKL                  | 0.00962963 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.44e+03   |
| NumTrajs                | 8          |
| Perplexity              | 7.28609    |
| PolicyExecTime          | 0.614      |
| ProcessExecTime         | 0.0675     |
| StdReturn               | 633        |
| Time                    | 9.27e+03   |
| dLoss                   | 0.0287445  |
----------------------------------------
itr #681 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 681...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5162, #subsample_inputs: 5162
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.612      |
| AbsLearnSignalNew       | 0.612      |
| AbsLearningOld          | 0.612      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 40.2808    |
| AveragePolicyStd        | 0.472603   |
| AverageReturn           | 1.92e+03   |
| Entropy                 | 1.99581    |
| EnvExecTime             | 1.95       |
| ExplainedVariance       | 0.886      |
| Iteration               | 681        |
| ItrTime                 | 12.9       |
| LossAfter               | 1.977      |
| LossBefore              | 2.00451    |
| MaxReturn               | 3.29e+03   |
| MeanKL                  | 0.00643911 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.42e+03   |
| NumTrajs                | 9          |
| Perplexity              | 7.35816    |
| PolicyExecTime          | 0.478      |
| ProcessExecTime         | 0.0575     |
| StdReturn               | 546        |
| Time                    | 9.28e+03   |
| dLoss                   | 0.0275161  |
----------------------------------------
itr #682 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 682...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5200, #subsample_inputs: 5200
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.633      |
| AbsLearnSignalNew       | 0.633      |
| AbsLearningOld          | 0.633      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 38.8405    |
| AveragePolicyStd        | 0.472001   |
| AverageReturn           | 2.49e+03   |
| Entropy                 | 1.99209    |
| EnvExecTime             | 2.3        |
| ExplainedVariance       | 0.807      |
| Iteration               | 682        |
| ItrTime                 | 13.4       |
| LossAfter               | -0.211351  |
| LossBefore              | -0.177369  |
| MaxReturn               | 3.36e+03   |
| MeanKL                  | 0.00999975 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.47e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.33085    |
| PolicyExecTime          | 0.583      |
| ProcessExecTime         | 0.0649     |
| StdReturn               | 717        |
| Time                    | 9.3e+03    |
| dLoss                   | 0.0339818  |
----------------------------------------
itr #683 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 683...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5074, #subsample_inputs: 5074
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.636      |
| AbsLearnSignalNew       | 0.636      |
| AbsLearningOld          | 0.636      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 45.6366    |
| AveragePolicyStd        | 0.472485   |
| AverageReturn           | 2.4e+03    |
| Entropy                 | 1.99563    |
| EnvExecTime             | 2.51       |
| ExplainedVariance       | 0.886      |
| Iteration               | 683        |
| ItrTime                 | 13.5       |
| LossAfter               | 0.130761   |
| LossBefore              | 0.156432   |
| MaxReturn               | 3.16e+03   |
| MeanKL                  | 0.00640629 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.45e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.35686    |
| PolicyExecTime          | 0.647      |
| ProcessExecTime         | 0.0679     |
| StdReturn               | 500        |
| Time                    | 9.31e+03   |
| dLoss                   | 0.0256711  |
----------------------------------------
itr #684 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 684...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5463, #subsample_inputs: 5463
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.633      |
| AbsLearnSignalNew       | 0.633      |
| AbsLearningOld          | 0.633      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 39.6036    |
| AveragePolicyStd        | 0.472128   |
| AverageReturn           | 2.26e+03   |
| Entropy                 | 1.99388    |
| EnvExecTime             | 2.36       |
| ExplainedVariance       | 0.778      |
| Iteration               | 684        |
| ItrTime                 | 13.9       |
| LossAfter               | -1.82989   |
| LossBefore              | -1.80225   |
| MaxReturn               | 3.25e+03   |
| MeanKL                  | 0.00640508 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.5e+03    |
| NumTrajs                | 8          |
| Perplexity              | 7.34399    |
| PolicyExecTime          | 0.601      |
| ProcessExecTime         | 0.0667     |
| StdReturn               | 729        |
| Time                    | 9.32e+03   |
| dLoss                   | 0.0276316  |
----------------------------------------
itr #685 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 685...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5876, #subsample_inputs: 5876
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.643      |
| AbsLearnSignalNew       | 0.643      |
| AbsLearningOld          | 0.643      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 44.447     |
| AveragePolicyStd        | 0.472202   |
| AverageReturn           | 2.18e+03   |
| Entropy                 | 1.99388    |
| EnvExecTime             | 2.46       |
| ExplainedVariance       | 0.856      |
| Iteration               | 685        |
| ItrTime                 | 14.7       |
| LossAfter               | 0.440079   |
| LossBefore              | 0.465472   |
| MaxReturn               | 3.25e+03   |
| MeanKL                  | 0.00648758 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.37e+03   |
| NumTrajs                | 9          |
| Perplexity              | 7.34395    |
| PolicyExecTime          | 0.614      |
| ProcessExecTime         | 0.0725     |
| StdReturn               | 639        |
| Time                    | 9.34e+03   |
| dLoss                   | 0.0253923  |
----------------------------------------
itr #686 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 686...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5203, #subsample_inputs: 5203
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.543      |
| AbsLearnSignalNew       | 0.543      |
| AbsLearningOld          | 0.543      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 34.5093    |
| AveragePolicyStd        | 0.471688   |
| AverageReturn           | 2.5e+03    |
| Entropy                 | 1.99005    |
| EnvExecTime             | 2.12       |
| ExplainedVariance       | 0.707      |
| Iteration               | 686        |
| ItrTime                 | 13.2       |
| LossAfter               | -1.38693   |
| LossBefore              | -1.35915   |
| MaxReturn               | 3.35e+03   |
| MeanKL                  | 0.00684303 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.56e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.31592    |
| PolicyExecTime          | 0.541      |
| ProcessExecTime         | 0.0608     |
| StdReturn               | 694        |
| Time                    | 9.35e+03   |
| dLoss                   | 0.0277814  |
----------------------------------------
itr #687 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 687...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5460, #subsample_inputs: 5460
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.644      |
| AbsLearnSignalNew       | 0.644      |
| AbsLearningOld          | 0.644      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 38.1267    |
| AveragePolicyStd        | 0.469996   |
| AverageReturn           | 2.28e+03   |
| Entropy                 | 1.97904    |
| EnvExecTime             | 2.41       |
| ExplainedVariance       | 0.897      |
| Iteration               | 687        |
| ItrTime                 | 14         |
| LossAfter               | -1.41274   |
| LossBefore              | -1.38835   |
| MaxReturn               | 3.28e+03   |
| MeanKL                  | 0.00643283 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.51e+03   |
| NumTrajs                | 8          |
| Perplexity              | 7.23578    |
| PolicyExecTime          | 0.603      |
| ProcessExecTime         | 0.0684     |
| StdReturn               | 638        |
| Time                    | 9.37e+03   |
| dLoss                   | 0.0243914  |
----------------------------------------
itr #688 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 688...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5326, #subsample_inputs: 5326
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.451      |
| AbsLearnSignalNew       | 0.451      |
| AbsLearningOld          | 0.451      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 56.759     |
| AveragePolicyStd        | 0.469288   |
| AverageReturn           | 2.93e+03   |
| Entropy                 | 1.97473    |
| EnvExecTime             | 2.23       |
| ExplainedVariance       | 0.448      |
| Iteration               | 688        |
| ItrTime                 | 13.7       |
| LossAfter               | -0.529841  |
| LossBefore              | -0.504574  |
| MaxReturn               | 3.34e+03   |
| MeanKL                  | 0.00970347 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.59e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.20466    |
| PolicyExecTime          | 0.574      |
| ProcessExecTime         | 0.0639     |
| StdReturn               | 616        |
| Time                    | 9.38e+03   |
| dLoss                   | 0.0252676  |
----------------------------------------
itr #689 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 689...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5118, #subsample_inputs: 5118
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.646      |
| AbsLearnSignalNew       | 0.646      |
| AbsLearningOld          | 0.646      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 44.3593    |
| AveragePolicyStd        | 0.469015   |
| AverageReturn           | 2.38e+03   |
| Entropy                 | 1.97259    |
| EnvExecTime             | 2.31       |
| ExplainedVariance       | 0.912      |
| Iteration               | 689        |
| ItrTime                 | 13.4       |
| LossAfter               | -1.2831    |
| LossBefore              | -1.24313   |
| MaxReturn               | 3.23e+03   |
| MeanKL                  | 0.00981521 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.44e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.18927    |
| PolicyExecTime          | 0.585      |
| ProcessExecTime         | 0.0648     |
| StdReturn               | 765        |
| Time                    | 9.39e+03   |
| dLoss                   | 0.0399684  |
----------------------------------------
itr #690 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 690...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5000, #subsample_inputs: 5000
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.699      |
| AbsLearnSignalNew       | 0.699      |
| AbsLearningOld          | 0.699      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 40.6823    |
| AveragePolicyStd        | 0.468567   |
| AverageReturn           | 3.2e+03    |
| Entropy                 | 1.97007    |
| EnvExecTime             | 1.58       |
| ExplainedVariance       | 0.917      |
| Iteration               | 690        |
| ItrTime                 | 12.2       |
| LossAfter               | 2.61306    |
| LossBefore              | 2.6363     |
| MaxReturn               | 3.25e+03   |
| MeanKL                  | 0.00988758 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 3.13e+03   |
| NumTrajs                | 5          |
| Perplexity              | 7.17118    |
| PolicyExecTime          | 0.402      |
| ProcessExecTime         | 0.0503     |
| StdReturn               | 46.2       |
| Time                    | 9.41e+03   |
| dLoss                   | 0.023248   |
----------------------------------------
itr #691 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 691...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5448, #subsample_inputs: 5448
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.381     |
| AbsLearnSignalNew       | 0.381     |
| AbsLearningOld          | 0.381     |
| AverageDiscountedReturn | 244       |
| AveragePhiLoss          | 40.3839   |
| AveragePolicyStd        | 0.467211  |
| AverageReturn           | 2.93e+03  |
| Entropy                 | 1.96207   |
| EnvExecTime             | 2.55      |
| ExplainedVariance       | 0.721     |
| Iteration               | 691       |
| ItrTime                 | 14.2      |
| LossAfter               | -0.930497 |
| LossBefore              | -0.899765 |
| MaxReturn               | 3.26e+03  |
| MeanKL                  | 0.0096997 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.85e+03  |
| NumTrajs                | 6         |
| Perplexity              | 7.11404   |
| PolicyExecTime          | 0.641     |
| ProcessExecTime         | 0.0737    |
| StdReturn               | 499       |
| Time                    | 9.42e+03  |
| dLoss                   | 0.0307326 |
---------------------------------------
itr #692 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 692...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5000, #subsample_inputs: 5000
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.535      |
| AbsLearnSignalNew       | 0.535      |
| AbsLearningOld          | 0.535      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 41.3617    |
| AveragePolicyStd        | 0.467078   |
| AverageReturn           | 3.25e+03   |
| Entropy                 | 1.96094    |
| EnvExecTime             | 1.65       |
| ExplainedVariance       | 0.809      |
| Iteration               | 692        |
| ItrTime                 | 12.4       |
| LossAfter               | -0.082518  |
| LossBefore              | -0.051376  |
| MaxReturn               | 3.37e+03   |
| MeanKL                  | 0.00643944 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 3.2e+03    |
| NumTrajs                | 5          |
| Perplexity              | 7.10602    |
| PolicyExecTime          | 0.413      |
| ProcessExecTime         | 0.0516     |
| StdReturn               | 61.5       |
| Time                    | 9.43e+03   |
| dLoss                   | 0.031142   |
----------------------------------------
itr #693 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 693...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5067, #subsample_inputs: 5067
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.425      |
| AbsLearnSignalNew       | 0.425      |
| AbsLearningOld          | 0.425      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 45.9663    |
| AveragePolicyStd        | 0.466507   |
| AverageReturn           | 2.76e+03   |
| Entropy                 | 1.95709    |
| EnvExecTime             | 1.73       |
| ExplainedVariance       | 0.698      |
| Iteration               | 693        |
| ItrTime                 | 12.5       |
| LossAfter               | 0.664235   |
| LossBefore              | 0.696922   |
| MaxReturn               | 3.3e+03    |
| MeanKL                  | 0.00980707 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.54e+03   |
| NumTrajs                | 6          |
| Perplexity              | 7.07867    |
| PolicyExecTime          | 0.434      |
| ProcessExecTime         | 0.0551     |
| StdReturn               | 690        |
| Time                    | 9.45e+03   |
| dLoss                   | 0.0326866  |
----------------------------------------
itr #694 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 694...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5765, #subsample_inputs: 5765
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.587      |
| AbsLearnSignalNew       | 0.587      |
| AbsLearningOld          | 0.587      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 50.6403    |
| AveragePolicyStd        | 0.466119   |
| AverageReturn           | 2.74e+03   |
| Entropy                 | 1.95497    |
| EnvExecTime             | 2.64       |
| ExplainedVariance       | 0.827      |
| Iteration               | 694        |
| ItrTime                 | 14.7       |
| LossAfter               | 0.417121   |
| LossBefore              | 0.441864   |
| MaxReturn               | 3.35e+03   |
| MeanKL                  | 0.00643716 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 2.17e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.06374    |
| PolicyExecTime          | 0.658      |
| ProcessExecTime         | 0.0761     |
| StdReturn               | 410        |
| Time                    | 9.46e+03   |
| dLoss                   | 0.0247429  |
----------------------------------------
itr #695 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 695...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5358, #subsample_inputs: 5358
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.502      |
| AbsLearnSignalNew       | 0.502      |
| AbsLearningOld          | 0.502      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 45.9782    |
| AveragePolicyStd        | 0.46656    |
| AverageReturn           | 2.49e+03   |
| Entropy                 | 1.9582     |
| EnvExecTime             | 2.23       |
| ExplainedVariance       | 0.802      |
| Iteration               | 695        |
| ItrTime                 | 13.7       |
| LossAfter               | -0.855684  |
| LossBefore              | -0.816413  |
| MaxReturn               | 3.23e+03   |
| MeanKL                  | 0.00974326 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.41e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.08659    |
| PolicyExecTime          | 0.569      |
| ProcessExecTime         | 0.0644     |
| StdReturn               | 831        |
| Time                    | 9.47e+03   |
| dLoss                   | 0.0392707  |
----------------------------------------
itr #696 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 696...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5667, #subsample_inputs: 5667
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.64       |
| AbsLearnSignalNew       | 0.64       |
| AbsLearningOld          | 0.64       |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 45.7141    |
| AveragePolicyStd        | 0.467627   |
| AverageReturn           | 2.66e+03   |
| Entropy                 | 1.96559    |
| EnvExecTime             | 2.24       |
| ExplainedVariance       | 0.891      |
| Iteration               | 696        |
| ItrTime                 | 14.1       |
| LossAfter               | 1.08938    |
| LossBefore              | 1.11833    |
| MaxReturn               | 3.28e+03   |
| MeanKL                  | 0.00640278 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.49e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.13914    |
| PolicyExecTime          | 0.571      |
| ProcessExecTime         | 0.065      |
| StdReturn               | 628        |
| Time                    | 9.49e+03   |
| dLoss                   | 0.0289553  |
----------------------------------------
itr #697 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 697...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5453, #subsample_inputs: 5453
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.686      |
| AbsLearnSignalNew       | 0.686      |
| AbsLearningOld          | 0.686      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 41.9909    |
| AveragePolicyStd        | 0.466378   |
| AverageReturn           | 2.59e+03   |
| Entropy                 | 1.95739    |
| EnvExecTime             | 2.31       |
| ExplainedVariance       | 0.905      |
| Iteration               | 697        |
| ItrTime                 | 13.9       |
| LossAfter               | 1.89989    |
| LossBefore              | 1.9267     |
| MaxReturn               | 3.29e+03   |
| MeanKL                  | 0.00643897 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.57e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.0808     |
| PolicyExecTime          | 0.579      |
| ProcessExecTime         | 0.068      |
| StdReturn               | 534        |
| Time                    | 9.5e+03    |
| dLoss                   | 0.0268179  |
----------------------------------------
itr #698 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 698...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5335, #subsample_inputs: 5335
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.693      |
| AbsLearnSignalNew       | 0.693      |
| AbsLearningOld          | 0.693      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 50.5636    |
| AveragePolicyStd        | 0.465789   |
| AverageReturn           | 2.52e+03   |
| Entropy                 | 1.95321    |
| EnvExecTime             | 2.17       |
| ExplainedVariance       | 0.916      |
| Iteration               | 698        |
| ItrTime                 | 13.7       |
| LossAfter               | -0.18647   |
| LossBefore              | -0.154513  |
| MaxReturn               | 3.31e+03   |
| MeanKL                  | 0.00987155 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.34e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.05128    |
| PolicyExecTime          | 0.553      |
| ProcessExecTime         | 0.0649     |
| StdReturn               | 871        |
| Time                    | 9.52e+03   |
| dLoss                   | 0.0319561  |
----------------------------------------
itr #699 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 699...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5574, #subsample_inputs: 5574
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.589      |
| AbsLearnSignalNew       | 0.589      |
| AbsLearningOld          | 0.589      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 43.5518    |
| AveragePolicyStd        | 0.46551    |
| AverageReturn           | 2.63e+03   |
| Entropy                 | 1.95132    |
| EnvExecTime             | 2.5        |
| ExplainedVariance       | 0.864      |
| Iteration               | 699        |
| ItrTime                 | 14.2       |
| LossAfter               | 0.0541124  |
| LossBefore              | 0.0838891  |
| MaxReturn               | 3.27e+03   |
| MeanKL                  | 0.00646867 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.53e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.03794    |
| PolicyExecTime          | 0.64       |
| ProcessExecTime         | 0.0709     |
| StdReturn               | 618        |
| Time                    | 9.53e+03   |
| dLoss                   | 0.0297767  |
----------------------------------------
itr #700 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 700...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5890, #subsample_inputs: 5890
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.404      |
| AbsLearnSignalNew       | 0.404      |
| AbsLearningOld          | 0.404      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 64.4035    |
| AveragePolicyStd        | 0.4646     |
| AverageReturn           | 2.79e+03   |
| Entropy                 | 1.94548    |
| EnvExecTime             | 2.72       |
| ExplainedVariance       | 0.684      |
| Iteration               | 700        |
| ItrTime                 | 15         |
| LossAfter               | -2.25336   |
| LossBefore              | -2.21213   |
| MaxReturn               | 3.31e+03   |
| MeanKL                  | 0.00989218 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.42e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.99701    |
| PolicyExecTime          | 0.671      |
| ProcessExecTime         | 0.0837     |
| StdReturn               | 674        |
| Time                    | 9.55e+03   |
| dLoss                   | 0.0412309  |
----------------------------------------
itr #701 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 701...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5747, #subsample_inputs: 5747
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.592      |
| AbsLearnSignalNew       | 0.592      |
| AbsLearningOld          | 0.592      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 42.8342    |
| AveragePolicyStd        | 0.465678   |
| AverageReturn           | 2.72e+03   |
| Entropy                 | 1.95171    |
| EnvExecTime             | 2.87       |
| ExplainedVariance       | 0.846      |
| Iteration               | 701        |
| ItrTime                 | 15         |
| LossAfter               | 2.37836    |
| LossBefore              | 2.39913    |
| MaxReturn               | 3.27e+03   |
| MeanKL                  | 0.00643003 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.88e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.04071    |
| PolicyExecTime          | 0.711      |
| ProcessExecTime         | 0.0785     |
| StdReturn               | 544        |
| Time                    | 9.56e+03   |
| dLoss                   | 0.0207708  |
----------------------------------------
itr #702 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 702...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5164, #subsample_inputs: 5164
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.586      |
| AbsLearnSignalNew       | 0.586      |
| AbsLearningOld          | 0.586      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 50.322     |
| AveragePolicyStd        | 0.465767   |
| AverageReturn           | 2.46e+03   |
| Entropy                 | 1.9518     |
| EnvExecTime             | 2.24       |
| ExplainedVariance       | 0.79       |
| Iteration               | 702        |
| ItrTime                 | 13.3       |
| LossAfter               | -3.85917   |
| LossBefore              | -3.81198   |
| MaxReturn               | 3.35e+03   |
| MeanKL                  | 0.00642226 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.35e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.04138    |
| PolicyExecTime          | 0.568      |
| ProcessExecTime         | 0.0635     |
| StdReturn               | 813        |
| Time                    | 9.57e+03   |
| dLoss                   | 0.0471897  |
----------------------------------------
itr #703 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 703...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5453, #subsample_inputs: 5453
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.588      |
| AbsLearnSignalNew       | 0.588      |
| AbsLearningOld          | 0.588      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 37.0294    |
| AveragePolicyStd        | 0.465757   |
| AverageReturn           | 2.64e+03   |
| Entropy                 | 1.95161    |
| EnvExecTime             | 2.5        |
| ExplainedVariance       | 0.782      |
| Iteration               | 703        |
| ItrTime                 | 14.2       |
| LossAfter               | -0.665393  |
| LossBefore              | -0.628436  |
| MaxReturn               | 3.33e+03   |
| MeanKL                  | 0.00997191 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.49e+03   |
| NumTrajs                | 7          |
| Perplexity              | 7.04003    |
| PolicyExecTime          | 0.647      |
| ProcessExecTime         | 0.0701     |
| StdReturn               | 649        |
| Time                    | 9.59e+03   |
| dLoss                   | 0.0369568  |
----------------------------------------
itr #704 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 704...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5892, #subsample_inputs: 5892
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.625      |
| AbsLearnSignalNew       | 0.625      |
| AbsLearningOld          | 0.625      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 43.4965    |
| AveragePolicyStd        | 0.464965   |
| AverageReturn           | 2.19e+03   |
| Entropy                 | 1.94592    |
| EnvExecTime             | 2.39       |
| ExplainedVariance       | 0.838      |
| Iteration               | 704        |
| ItrTime                 | 14.7       |
| LossAfter               | -1.78585   |
| LossBefore              | -1.76082   |
| MaxReturn               | 3.22e+03   |
| MeanKL                  | 0.00644645 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.47e+03   |
| NumTrajs                | 9          |
| Perplexity              | 7.00008    |
| PolicyExecTime          | 0.609      |
| ProcessExecTime         | 0.0707     |
| StdReturn               | 506        |
| Time                    | 9.6e+03    |
| dLoss                   | 0.0250276  |
----------------------------------------
itr #705 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 705...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5327, #subsample_inputs: 5327
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.566      |
| AbsLearnSignalNew       | 0.566      |
| AbsLearningOld          | 0.566      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 43.952     |
| AveragePolicyStd        | 0.465539   |
| AverageReturn           | 2.24e+03   |
| Entropy                 | 1.94907    |
| EnvExecTime             | 2.52       |
| ExplainedVariance       | 0.788      |
| Iteration               | 705        |
| ItrTime                 | 14.1       |
| LossAfter               | -0.987647  |
| LossBefore              | -0.960137  |
| MaxReturn               | 3.37e+03   |
| MeanKL                  | 0.00646188 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.5e+03    |
| NumTrajs                | 8          |
| Perplexity              | 7.02212    |
| PolicyExecTime          | 0.634      |
| ProcessExecTime         | 0.0701     |
| StdReturn               | 655        |
| Time                    | 9.62e+03   |
| dLoss                   | 0.0275096  |
----------------------------------------
itr #706 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 706...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5518, #subsample_inputs: 5518
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.632      |
| AbsLearnSignalNew       | 0.632      |
| AbsLearningOld          | 0.632      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 50.2613    |
| AveragePolicyStd        | 0.464175   |
| AverageReturn           | 2.32e+03   |
| Entropy                 | 1.94063    |
| EnvExecTime             | 2.2        |
| ExplainedVariance       | 0.882      |
| Iteration               | 706        |
| ItrTime                 | 13.8       |
| LossAfter               | 0.804737   |
| LossBefore              | 0.837635   |
| MaxReturn               | 3.37e+03   |
| MeanKL                  | 0.00993397 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.05e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.96313    |
| PolicyExecTime          | 0.559      |
| ProcessExecTime         | 0.0632     |
| StdReturn               | 755        |
| Time                    | 9.63e+03   |
| dLoss                   | 0.0328981  |
----------------------------------------
itr #707 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 707...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5906, #subsample_inputs: 5906
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.579     |
| AbsLearnSignalNew       | 0.579     |
| AbsLearningOld          | 0.579     |
| AverageDiscountedReturn | 247       |
| AveragePhiLoss          | 47.8745   |
| AveragePolicyStd        | 0.464113  |
| AverageReturn           | 2.43e+03  |
| Entropy                 | 1.94038   |
| EnvExecTime             | 2.42      |
| ExplainedVariance       | 0.776     |
| Iteration               | 707       |
| ItrTime                 | 14.7      |
| LossAfter               | 0.396977  |
| LossBefore              | 0.42455   |
| MaxReturn               | 3.39e+03  |
| MeanKL                  | 0.0099564 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 950       |
| NumTrajs                | 8         |
| Perplexity              | 6.9614    |
| PolicyExecTime          | 0.617     |
| ProcessExecTime         | 0.0702    |
| StdReturn               | 934       |
| Time                    | 9.65e+03  |
| dLoss                   | 0.0275732 |
---------------------------------------
itr #708 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 708...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5416, #subsample_inputs: 5416
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.627      |
| AbsLearnSignalNew       | 0.627      |
| AbsLearningOld          | 0.627      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 41.3547    |
| AveragePolicyStd        | 0.463243   |
| AverageReturn           | 2.55e+03   |
| Entropy                 | 1.93503    |
| EnvExecTime             | 2.14       |
| ExplainedVariance       | 0.841      |
| Iteration               | 708        |
| ItrTime                 | 13.7       |
| LossAfter               | -0.915807  |
| LossBefore              | -0.886575  |
| MaxReturn               | 3.26e+03   |
| MeanKL                  | 0.00989689 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.54e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.92424    |
| PolicyExecTime          | 0.532      |
| ProcessExecTime         | 0.0632     |
| StdReturn               | 673        |
| Time                    | 9.66e+03   |
| dLoss                   | 0.0292325  |
----------------------------------------
itr #709 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 709...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5834, #subsample_inputs: 5834
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.521      |
| AbsLearnSignalNew       | 0.521      |
| AbsLearningOld          | 0.521      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 48.345     |
| AveragePolicyStd        | 0.463765   |
| AverageReturn           | 2.15e+03   |
| Entropy                 | 1.93818    |
| EnvExecTime             | 2.56       |
| ExplainedVariance       | 0.705      |
| Iteration               | 709        |
| ItrTime                 | 14.8       |
| LossAfter               | -0.0117774 |
| LossBefore              | 0.00966541 |
| MaxReturn               | 3.28e+03   |
| MeanKL                  | 0.00646381 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 868        |
| NumTrajs                | 9          |
| Perplexity              | 6.94613    |
| PolicyExecTime          | 0.646      |
| ProcessExecTime         | 0.0746     |
| StdReturn               | 716        |
| Time                    | 9.67e+03   |
| dLoss                   | 0.0214428  |
----------------------------------------
itr #710 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 710...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5028, #subsample_inputs: 5028
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.589      |
| AbsLearnSignalNew       | 0.589      |
| AbsLearningOld          | 0.589      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 49.4554    |
| AveragePolicyStd        | 0.462625   |
| AverageReturn           | 2.37e+03   |
| Entropy                 | 1.93126    |
| EnvExecTime             | 2.32       |
| ExplainedVariance       | 0.669      |
| Iteration               | 710        |
| ItrTime                 | 13.2       |
| LossAfter               | -1.53932   |
| LossBefore              | -1.5193    |
| MaxReturn               | 3.28e+03   |
| MeanKL                  | 0.00645889 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.61e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.8982     |
| PolicyExecTime          | 0.592      |
| ProcessExecTime         | 0.0638     |
| StdReturn               | 593        |
| Time                    | 9.69e+03   |
| dLoss                   | 0.0200191  |
----------------------------------------
itr #711 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 711...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5283, #subsample_inputs: 5283
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.645      |
| AbsLearnSignalNew       | 0.645      |
| AbsLearningOld          | 0.645      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 53.3945    |
| AveragePolicyStd        | 0.461823   |
| AverageReturn           | 2.9e+03    |
| Entropy                 | 1.92632    |
| EnvExecTime             | 2.35       |
| ExplainedVariance       | 0.859      |
| Iteration               | 711        |
| ItrTime                 | 13.6       |
| LossAfter               | -0.542517  |
| LossBefore              | -0.521623  |
| MaxReturn               | 3.29e+03   |
| MeanKL                  | 0.00646424 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.52e+03   |
| NumTrajs                | 6          |
| Perplexity              | 6.86417    |
| PolicyExecTime          | 0.594      |
| ProcessExecTime         | 0.0687     |
| StdReturn               | 645        |
| Time                    | 9.7e+03    |
| dLoss                   | 0.0208944  |
----------------------------------------
itr #712 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 712...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5732, #subsample_inputs: 5732
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.559      |
| AbsLearnSignalNew       | 0.559      |
| AbsLearningOld          | 0.559      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 43.3492    |
| AveragePolicyStd        | 0.461057   |
| AverageReturn           | 2.41e+03   |
| Entropy                 | 1.92092    |
| EnvExecTime             | 2.53       |
| ExplainedVariance       | 0.746      |
| Iteration               | 712        |
| ItrTime                 | 14.5       |
| LossAfter               | -0.0319798 |
| LossBefore              | 0.00845408 |
| MaxReturn               | 3.42e+03   |
| MeanKL                  | 0.00997423 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.52e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.82722    |
| PolicyExecTime          | 0.639      |
| ProcessExecTime         | 0.0721     |
| StdReturn               | 735        |
| Time                    | 9.72e+03   |
| dLoss                   | 0.0404338  |
----------------------------------------
itr #713 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 713...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5067, #subsample_inputs: 5067
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.635      |
| AbsLearnSignalNew       | 0.635      |
| AbsLearningOld          | 0.635      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 42.2942    |
| AveragePolicyStd        | 0.461227   |
| AverageReturn           | 2.42e+03   |
| Entropy                 | 1.92192    |
| EnvExecTime             | 2          |
| ExplainedVariance       | 0.867      |
| Iteration               | 713        |
| ItrTime                 | 12.9       |
| LossAfter               | 0.440781   |
| LossBefore              | 0.469037   |
| MaxReturn               | 3.37e+03   |
| MeanKL                  | 0.00644055 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.52e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.83407    |
| PolicyExecTime          | 0.504      |
| ProcessExecTime         | 0.0581     |
| StdReturn               | 703        |
| Time                    | 9.73e+03   |
| dLoss                   | 0.0282561  |
----------------------------------------
itr #714 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 714...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5426, #subsample_inputs: 5426
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.545     |
| AbsLearnSignalNew       | 0.545     |
| AbsLearningOld          | 0.545     |
| AverageDiscountedReturn | 247       |
| AveragePhiLoss          | 44.3136   |
| AveragePolicyStd        | 0.460535  |
| AverageReturn           | 2.59e+03  |
| Entropy                 | 1.91774   |
| EnvExecTime             | 2.32      |
| ExplainedVariance       | 0.824     |
| Iteration               | 714       |
| ItrTime                 | 13.9      |
| LossAfter               | 0.358339  |
| LossBefore              | 0.383723  |
| MaxReturn               | 3.4e+03   |
| MeanKL                  | 0.0064104 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.44e+03  |
| NumTrajs                | 7         |
| Perplexity              | 6.80557   |
| PolicyExecTime          | 0.587     |
| ProcessExecTime         | 0.0657    |
| StdReturn               | 765       |
| Time                    | 9.74e+03  |
| dLoss                   | 0.0253842 |
---------------------------------------
itr #715 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 715...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5518, #subsample_inputs: 5518
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.563      |
| AbsLearnSignalNew       | 0.563      |
| AbsLearningOld          | 0.563      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 51.1853    |
| AveragePolicyStd        | 0.459412   |
| AverageReturn           | 2.33e+03   |
| Entropy                 | 1.91053    |
| EnvExecTime             | 2.27       |
| ExplainedVariance       | 0.803      |
| Iteration               | 715        |
| ItrTime                 | 13.9       |
| LossAfter               | -0.260212  |
| LossBefore              | -0.226671  |
| MaxReturn               | 3.42e+03   |
| MeanKL                  | 0.00990549 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.49e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.75665    |
| PolicyExecTime          | 0.581      |
| ProcessExecTime         | 0.0644     |
| StdReturn               | 799        |
| Time                    | 9.76e+03   |
| dLoss                   | 0.0335417  |
----------------------------------------
itr #716 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 716...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5936, #subsample_inputs: 5936
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.602      |
| AbsLearnSignalNew       | 0.602      |
| AbsLearningOld          | 0.601      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 47.5848    |
| AveragePolicyStd        | 0.459      |
| AverageReturn           | 2.46e+03   |
| Entropy                 | 1.90767    |
| EnvExecTime             | 2.48       |
| ExplainedVariance       | 0.813      |
| Iteration               | 716        |
| ItrTime                 | 14.8       |
| LossAfter               | -0.199738  |
| LossBefore              | -0.171347  |
| MaxReturn               | 3.27e+03   |
| MeanKL                  | 0.00987672 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.82e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.73737    |
| PolicyExecTime          | 0.625      |
| ProcessExecTime         | 0.0718     |
| StdReturn               | 624        |
| Time                    | 9.77e+03   |
| dLoss                   | 0.0283903  |
----------------------------------------
itr #717 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 717...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5238, #subsample_inputs: 5238
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.647      |
| AbsLearnSignalNew       | 0.647      |
| AbsLearningOld          | 0.647      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 41.2254    |
| AveragePolicyStd        | 0.458651   |
| AverageReturn           | 2.88e+03   |
| Entropy                 | 1.90517    |
| EnvExecTime             | 2.93       |
| ExplainedVariance       | 0.893      |
| Iteration               | 717        |
| ItrTime                 | 14.3       |
| LossAfter               | 0.235507   |
| LossBefore              | 0.268808   |
| MaxReturn               | 3.28e+03   |
| MeanKL                  | 0.00998667 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.95e+03   |
| NumTrajs                | 6          |
| Perplexity              | 6.72057    |
| PolicyExecTime          | 0.719      |
| ProcessExecTime         | 0.0803     |
| StdReturn               | 460        |
| Time                    | 9.79e+03   |
| dLoss                   | 0.0333008  |
----------------------------------------
itr #718 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 718...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5861, #subsample_inputs: 5861
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.627      |
| AbsLearnSignalNew       | 0.627      |
| AbsLearningOld          | 0.627      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 46.7539    |
| AveragePolicyStd        | 0.459334   |
| AverageReturn           | 2.77e+03   |
| Entropy                 | 1.90946    |
| EnvExecTime             | 2.41       |
| ExplainedVariance       | 0.893      |
| Iteration               | 718        |
| ItrTime                 | 14.5       |
| LossAfter               | -0.75396   |
| LossBefore              | -0.729076  |
| MaxReturn               | 3.25e+03   |
| MeanKL                  | 0.00640247 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.75e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.74941    |
| PolicyExecTime          | 0.613      |
| ProcessExecTime         | 0.0692     |
| StdReturn               | 541        |
| Time                    | 9.8e+03    |
| dLoss                   | 0.0248843  |
----------------------------------------
itr #719 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 719...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5285, #subsample_inputs: 5285
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.512      |
| AbsLearnSignalNew       | 0.512      |
| AbsLearningOld          | 0.512      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 44.829     |
| AveragePolicyStd        | 0.458917   |
| AverageReturn           | 2.18e+03   |
| Entropy                 | 1.90656    |
| EnvExecTime             | 2.21       |
| ExplainedVariance       | 0.684      |
| Iteration               | 719        |
| ItrTime                 | 13.5       |
| LossAfter               | 1.89223    |
| LossBefore              | 1.9217     |
| MaxReturn               | 3.27e+03   |
| MeanKL                  | 0.00981776 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 847        |
| NumTrajs                | 8          |
| Perplexity              | 6.72989    |
| PolicyExecTime          | 0.565      |
| ProcessExecTime         | 0.063      |
| StdReturn               | 845        |
| Time                    | 9.81e+03   |
| dLoss                   | 0.0294695  |
----------------------------------------
itr #720 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 720...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5365, #subsample_inputs: 5365
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.51      |
| AbsLearnSignalNew       | 0.51      |
| AbsLearningOld          | 0.51      |
| AverageDiscountedReturn | 245       |
| AveragePhiLoss          | 65.3982   |
| AveragePolicyStd        | 0.458779  |
| AverageReturn           | 2.51e+03  |
| Entropy                 | 1.90608   |
| EnvExecTime             | 2.38      |
| ExplainedVariance       | 0.658     |
| Iteration               | 720       |
| ItrTime                 | 13.9      |
| LossAfter               | 1.46432   |
| LossBefore              | 1.49428   |
| MaxReturn               | 3.27e+03  |
| MeanKL                  | 0.0098502 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.69e+03  |
| NumTrajs                | 7         |
| Perplexity              | 6.72665   |
| PolicyExecTime          | 0.606     |
| ProcessExecTime         | 0.0664    |
| StdReturn               | 673       |
| Time                    | 9.83e+03  |
| dLoss                   | 0.0299609 |
---------------------------------------
itr #721 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 721...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5737, #subsample_inputs: 5737
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.605      |
| AbsLearnSignalNew       | 0.605      |
| AbsLearningOld          | 0.605      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 44.3409    |
| AveragePolicyStd        | 0.458074   |
| AverageReturn           | 2.72e+03   |
| Entropy                 | 1.90158    |
| EnvExecTime             | 2.32       |
| ExplainedVariance       | 0.753      |
| Iteration               | 721        |
| ItrTime                 | 14.3       |
| LossAfter               | -0.584607  |
| LossBefore              | -0.55122   |
| MaxReturn               | 3.33e+03   |
| MeanKL                  | 0.00644933 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.54e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.6965     |
| PolicyExecTime          | 0.597      |
| ProcessExecTime         | 0.0674     |
| StdReturn               | 702        |
| Time                    | 9.84e+03   |
| dLoss                   | 0.0333878  |
----------------------------------------
itr #722 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 722...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5303, #subsample_inputs: 5303
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.609      |
| AbsLearnSignalNew       | 0.609      |
| AbsLearningOld          | 0.61       |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 43.5239    |
| AveragePolicyStd        | 0.457914   |
| AverageReturn           | 2.21e+03   |
| Entropy                 | 1.90088    |
| EnvExecTime             | 2.27       |
| ExplainedVariance       | 0.812      |
| Iteration               | 722        |
| ItrTime                 | 13.6       |
| LossAfter               | -1.07732   |
| LossBefore              | -1.05235   |
| MaxReturn               | 3.25e+03   |
| MeanKL                  | 0.00649301 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.44e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.69176    |
| PolicyExecTime          | 0.578      |
| ProcessExecTime         | 0.0638     |
| StdReturn               | 746        |
| Time                    | 9.86e+03   |
| dLoss                   | 0.0249707  |
----------------------------------------
itr #723 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 723...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5460, #subsample_inputs: 5460
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.582      |
| AbsLearnSignalNew       | 0.582      |
| AbsLearningOld          | 0.582      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 41.7291    |
| AveragePolicyStd        | 0.457371   |
| AverageReturn           | 2.61e+03   |
| Entropy                 | 1.89648    |
| EnvExecTime             | 2.25       |
| ExplainedVariance       | 0.834      |
| Iteration               | 723        |
| ItrTime                 | 13.9       |
| LossAfter               | 0.249604   |
| LossBefore              | 0.276455   |
| MaxReturn               | 3.3e+03    |
| MeanKL                  | 0.00643622 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.53e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.66243    |
| PolicyExecTime          | 0.563      |
| ProcessExecTime         | 0.0667     |
| StdReturn               | 671        |
| Time                    | 9.87e+03   |
| dLoss                   | 0.0268503  |
----------------------------------------
itr #724 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 724...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5019, #subsample_inputs: 5019
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.674      |
| AbsLearnSignalNew       | 0.674      |
| AbsLearningOld          | 0.673      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 45.4612    |
| AveragePolicyStd        | 0.457292   |
| AverageReturn           | 1.89e+03   |
| Entropy                 | 1.89601    |
| EnvExecTime             | 2.65       |
| ExplainedVariance       | 0.903      |
| Iteration               | 724        |
| ItrTime                 | 13.6       |
| LossAfter               | -1.75156   |
| LossBefore              | -1.72417   |
| MaxReturn               | 3.32e+03   |
| MeanKL                  | 0.00640323 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.36e+03   |
| NumTrajs                | 9          |
| Perplexity              | 6.65928    |
| PolicyExecTime          | 0.657      |
| ProcessExecTime         | 0.0721     |
| StdReturn               | 578        |
| Time                    | 9.88e+03   |
| dLoss                   | 0.0273834  |
----------------------------------------
itr #725 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 725...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5396, #subsample_inputs: 5396
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.648      |
| AbsLearnSignalNew       | 0.648      |
| AbsLearningOld          | 0.648      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 50.8429    |
| AveragePolicyStd        | 0.457418   |
| AverageReturn           | 2.02e+03   |
| Entropy                 | 1.89702    |
| EnvExecTime             | 2.11       |
| ExplainedVariance       | 0.863      |
| Iteration               | 725        |
| ItrTime                 | 13.6       |
| LossAfter               | 2.04732    |
| LossBefore              | 2.08193    |
| MaxReturn               | 3.1e+03    |
| MeanKL                  | 0.00643234 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.43e+03   |
| NumTrajs                | 9          |
| Perplexity              | 6.66599    |
| PolicyExecTime          | 0.538      |
| ProcessExecTime         | 0.0604     |
| StdReturn               | 609        |
| Time                    | 9.9e+03    |
| dLoss                   | 0.0346079  |
----------------------------------------
itr #726 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 726...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5978, #subsample_inputs: 5978
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.472      |
| AbsLearnSignalNew       | 0.472      |
| AbsLearningOld          | 0.472      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 46.1115    |
| AveragePolicyStd        | 0.458099   |
| AverageReturn           | 2.23e+03   |
| Entropy                 | 1.90172    |
| EnvExecTime             | 2.27       |
| ExplainedVariance       | 0.664      |
| Iteration               | 726        |
| ItrTime                 | 14.6       |
| LossAfter               | -1.6745    |
| LossBefore              | -1.65868   |
| MaxReturn               | 3.32e+03   |
| MeanKL                  | 0.00640697 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.37e+03   |
| NumTrajs                | 9          |
| Perplexity              | 6.6974     |
| PolicyExecTime          | 0.581      |
| ProcessExecTime         | 0.0659     |
| StdReturn               | 730        |
| Time                    | 9.91e+03   |
| dLoss                   | 0.015812   |
----------------------------------------
itr #727 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 727...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5604, #subsample_inputs: 5604
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.664      |
| AbsLearnSignalNew       | 0.664      |
| AbsLearningOld          | 0.664      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 41.9591    |
| AveragePolicyStd        | 0.457522   |
| AverageReturn           | 2.62e+03   |
| Entropy                 | 1.89805    |
| EnvExecTime             | 2.54       |
| ExplainedVariance       | 0.858      |
| Iteration               | 727        |
| ItrTime                 | 14.3       |
| LossAfter               | 1.09354    |
| LossBefore              | 1.12058    |
| MaxReturn               | 3.21e+03   |
| MeanKL                  | 0.00646268 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.78e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.67287    |
| PolicyExecTime          | 0.65       |
| ProcessExecTime         | 0.0706     |
| StdReturn               | 625        |
| Time                    | 9.93e+03   |
| dLoss                   | 0.0270426  |
----------------------------------------
itr #728 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 728...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5055, #subsample_inputs: 5055
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.519      |
| AbsLearnSignalNew       | 0.519      |
| AbsLearningOld          | 0.519      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 40.0104    |
| AveragePolicyStd        | 0.457647   |
| AverageReturn           | 2.81e+03   |
| Entropy                 | 1.89885    |
| EnvExecTime             | 2.48       |
| ExplainedVariance       | 0.723      |
| Iteration               | 728        |
| ItrTime                 | 13.4       |
| LossAfter               | 1.01187    |
| LossBefore              | 1.04534    |
| MaxReturn               | 3.33e+03   |
| MeanKL                  | 0.00990376 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.81e+03   |
| NumTrajs                | 6          |
| Perplexity              | 6.67821    |
| PolicyExecTime          | 0.619      |
| ProcessExecTime         | 0.068      |
| StdReturn               | 509        |
| Time                    | 9.94e+03   |
| dLoss                   | 0.0334663  |
----------------------------------------
itr #729 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 729...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5758, #subsample_inputs: 5758
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.553     |
| AbsLearnSignalNew       | 0.553     |
| AbsLearningOld          | 0.553     |
| AverageDiscountedReturn | 247       |
| AveragePhiLoss          | 53.5684   |
| AveragePolicyStd        | 0.456899  |
| AverageReturn           | 2.73e+03  |
| Entropy                 | 1.8936    |
| EnvExecTime             | 2.14      |
| ExplainedVariance       | 0.852     |
| Iteration               | 729       |
| ItrTime                 | 14.1      |
| LossAfter               | -2.53346  |
| LossBefore              | -2.49788  |
| MaxReturn               | 3.28e+03  |
| MeanKL                  | 0.009893  |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.53e+03  |
| NumTrajs                | 7         |
| Perplexity              | 6.64322   |
| PolicyExecTime          | 0.55      |
| ProcessExecTime         | 0.0639    |
| StdReturn               | 634       |
| Time                    | 9.96e+03  |
| dLoss                   | 0.0355847 |
---------------------------------------
itr #730 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 730...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5434, #subsample_inputs: 5434
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.583      |
| AbsLearnSignalNew       | 0.583      |
| AbsLearningOld          | 0.583      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 39.2286    |
| AveragePolicyStd        | 0.456911   |
| AverageReturn           | 2.55e+03   |
| Entropy                 | 1.89334    |
| EnvExecTime             | 2.33       |
| ExplainedVariance       | 0.8        |
| Iteration               | 730        |
| ItrTime                 | 13.9       |
| LossAfter               | -0.408822  |
| LossBefore              | -0.382121  |
| MaxReturn               | 3.36e+03   |
| MeanKL                  | 0.00649353 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.67e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.64153    |
| PolicyExecTime          | 0.598      |
| ProcessExecTime         | 0.066      |
| StdReturn               | 717        |
| Time                    | 9.97e+03   |
| dLoss                   | 0.0267009  |
----------------------------------------
itr #731 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 731...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5358, #subsample_inputs: 5358
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.469      |
| AbsLearnSignalNew       | 0.469      |
| AbsLearningOld          | 0.468      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 37.2142    |
| AveragePolicyStd        | 0.456219   |
| AverageReturn           | 2.95e+03   |
| Entropy                 | 1.88882    |
| EnvExecTime             | 2.24       |
| ExplainedVariance       | 0.786      |
| Iteration               | 731        |
| ItrTime                 | 13.8       |
| LossAfter               | -0.745598  |
| LossBefore              | -0.720684  |
| MaxReturn               | 3.34e+03   |
| MeanKL                  | 0.00647181 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.45e+03   |
| NumTrajs                | 6          |
| Perplexity              | 6.61155    |
| PolicyExecTime          | 0.571      |
| ProcessExecTime         | 0.067      |
| StdReturn               | 671        |
| Time                    | 9.98e+03   |
| dLoss                   | 0.0249141  |
----------------------------------------
itr #732 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 732...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5740, #subsample_inputs: 5740
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.458      |
| AbsLearnSignalNew       | 0.458      |
| AbsLearningOld          | 0.458      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 41.4859    |
| AveragePolicyStd        | 0.455522   |
| AverageReturn           | 2.38e+03   |
| Entropy                 | 1.88448    |
| EnvExecTime             | 2.47       |
| ExplainedVariance       | 0.425      |
| Iteration               | 732        |
| ItrTime                 | 14.5       |
| LossAfter               | -0.132674  |
| LossBefore              | -0.106111  |
| MaxReturn               | 3.37e+03   |
| MeanKL                  | 0.00984375 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 575        |
| NumTrajs                | 8          |
| Perplexity              | 6.58291    |
| PolicyExecTime          | 0.621      |
| ProcessExecTime         | 0.0713     |
| StdReturn               | 817        |
| Time                    | 1e+04      |
| dLoss                   | 0.0265629  |
----------------------------------------
itr #733 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 733...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5843, #subsample_inputs: 5843
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.592     |
| AbsLearnSignalNew       | 0.592     |
| AbsLearningOld          | 0.592     |
| AverageDiscountedReturn | 247       |
| AveragePhiLoss          | 55.3746   |
| AveragePolicyStd        | 0.455636  |
| AverageReturn           | 2.75e+03  |
| Entropy                 | 1.88534   |
| EnvExecTime             | 2.54      |
| ExplainedVariance       | 0.774     |
| Iteration               | 733       |
| ItrTime                 | 14.8      |
| LossAfter               | 1.3603    |
| LossBefore              | 1.39347   |
| MaxReturn               | 3.3e+03   |
| MeanKL                  | 0.0099483 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.46e+03  |
| NumTrajs                | 7         |
| Perplexity              | 6.58857   |
| PolicyExecTime          | 0.638     |
| ProcessExecTime         | 0.0728    |
| StdReturn               | 710       |
| Time                    | 1e+04     |
| dLoss                   | 0.0331788 |
---------------------------------------
itr #734 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 734...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5328, #subsample_inputs: 5328
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.671      |
| AbsLearnSignalNew       | 0.671      |
| AbsLearningOld          | 0.671      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 44.9884    |
| AveragePolicyStd        | 0.45467    |
| AverageReturn           | 2.22e+03   |
| Entropy                 | 1.87917    |
| EnvExecTime             | 2.34       |
| ExplainedVariance       | 0.843      |
| Iteration               | 734        |
| ItrTime                 | 13.8       |
| LossAfter               | -1.36307   |
| LossBefore              | -1.32589   |
| MaxReturn               | 3.26e+03   |
| MeanKL                  | 0.00986483 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.56e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.5481     |
| PolicyExecTime          | 0.585      |
| ProcessExecTime         | 0.0666     |
| StdReturn               | 487        |
| Time                    | 1e+04      |
| dLoss                   | 0.0371835  |
----------------------------------------
itr #735 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 735...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5435, #subsample_inputs: 5435
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.639      |
| AbsLearnSignalNew       | 0.639      |
| AbsLearningOld          | 0.639      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 46.2146    |
| AveragePolicyStd        | 0.456522   |
| AverageReturn           | 2.59e+03   |
| Entropy                 | 1.89144    |
| EnvExecTime             | 2.31       |
| ExplainedVariance       | 0.858      |
| Iteration               | 735        |
| ItrTime                 | 13.9       |
| LossAfter               | 0.70988    |
| LossBefore              | 0.742791   |
| MaxReturn               | 3.29e+03   |
| MeanKL                  | 0.00988437 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.68e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.62892    |
| PolicyExecTime          | 0.589      |
| ProcessExecTime         | 0.0645     |
| StdReturn               | 620        |
| Time                    | 1e+04      |
| dLoss                   | 0.0329116  |
----------------------------------------
itr #736 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 736...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5240, #subsample_inputs: 5240
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.537      |
| AbsLearnSignalNew       | 0.537      |
| AbsLearningOld          | 0.536      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 48.0076    |
| AveragePolicyStd        | 0.457248   |
| AverageReturn           | 2.21e+03   |
| Entropy                 | 1.89678    |
| EnvExecTime             | 2.24       |
| ExplainedVariance       | 0.749      |
| Iteration               | 736        |
| ItrTime                 | 13.5       |
| LossAfter               | 1.68201    |
| LossBefore              | 1.70897    |
| MaxReturn               | 3.31e+03   |
| MeanKL                  | 0.00640582 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.52e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.66443    |
| PolicyExecTime          | 0.561      |
| ProcessExecTime         | 0.063      |
| StdReturn               | 528        |
| Time                    | 1.01e+04   |
| dLoss                   | 0.0269663  |
----------------------------------------
itr #737 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 737...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5043, #subsample_inputs: 5043
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.493      |
| AbsLearnSignalNew       | 0.493      |
| AbsLearningOld          | 0.493      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 101.209    |
| AveragePolicyStd        | 0.455421   |
| AverageReturn           | 2.12e+03   |
| Entropy                 | 1.8852     |
| EnvExecTime             | 1.82       |
| ExplainedVariance       | 0.701      |
| Iteration               | 737        |
| ItrTime                 | 12.6       |
| LossAfter               | -0.268341  |
| LossBefore              | -0.244554  |
| MaxReturn               | 3.37e+03   |
| MeanKL                  | 0.00646799 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.46e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.58765    |
| PolicyExecTime          | 0.456      |
| ProcessExecTime         | 0.0569     |
| StdReturn               | 735        |
| Time                    | 1.01e+04   |
| dLoss                   | 0.023787   |
----------------------------------------
itr #738 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 738...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5615, #subsample_inputs: 5615
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.623      |
| AbsLearnSignalNew       | 0.623      |
| AbsLearningOld          | 0.623      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 50.2306    |
| AveragePolicyStd        | 0.454209   |
| AverageReturn           | 2.36e+03   |
| Entropy                 | 1.87627    |
| EnvExecTime             | 2.38       |
| ExplainedVariance       | 0.865      |
| Iteration               | 738        |
| ItrTime                 | 14.1       |
| LossAfter               | 0.339279   |
| LossBefore              | 0.366869   |
| MaxReturn               | 3.34e+03   |
| MeanKL                  | 0.00646681 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.58e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.5291     |
| PolicyExecTime          | 0.59       |
| ProcessExecTime         | 0.0685     |
| StdReturn               | 557        |
| Time                    | 1.01e+04   |
| dLoss                   | 0.0275899  |
----------------------------------------
itr #739 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 739...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5093, #subsample_inputs: 5093
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.667     |
| AbsLearnSignalNew       | 0.667     |
| AbsLearningOld          | 0.667     |
| AverageDiscountedReturn | 248       |
| AveragePhiLoss          | 49.9896   |
| AveragePolicyStd        | 0.455146  |
| AverageReturn           | 2.16e+03  |
| Entropy                 | 1.88206   |
| EnvExecTime             | 2.09      |
| ExplainedVariance       | 0.915     |
| Iteration               | 739       |
| ItrTime                 | 13        |
| LossAfter               | 0.105342  |
| LossBefore              | 0.134377  |
| MaxReturn               | 3.36e+03  |
| MeanKL                  | 0.0098368 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.59e+03  |
| NumTrajs                | 8         |
| Perplexity              | 6.56699   |
| PolicyExecTime          | 0.526     |
| ProcessExecTime         | 0.062     |
| StdReturn               | 533       |
| Time                    | 1.01e+04  |
| dLoss                   | 0.0290354 |
---------------------------------------
itr #740 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 740...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5239, #subsample_inputs: 5239
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.487      |
| AbsLearnSignalNew       | 0.487      |
| AbsLearningOld          | 0.487      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 41.3736    |
| AveragePolicyStd        | 0.454815   |
| AverageReturn           | 2.48e+03   |
| Entropy                 | 1.87952    |
| EnvExecTime             | 2.11       |
| ExplainedVariance       | 0.653      |
| Iteration               | 740        |
| ItrTime                 | 13.3       |
| LossAfter               | 0.636369   |
| LossBefore              | 0.657013   |
| MaxReturn               | 3.36e+03   |
| MeanKL                  | 0.00641535 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.26e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.55037    |
| PolicyExecTime          | 0.539      |
| ProcessExecTime         | 0.0608     |
| StdReturn               | 959        |
| Time                    | 1.01e+04   |
| dLoss                   | 0.0206448  |
----------------------------------------
itr #741 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 741...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5799, #subsample_inputs: 5799
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.647      |
| AbsLearnSignalNew       | 0.647      |
| AbsLearningOld          | 0.646      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 51.8474    |
| AveragePolicyStd        | 0.455606   |
| AverageReturn           | 2.71e+03   |
| Entropy                 | 1.88503    |
| EnvExecTime             | 2.29       |
| ExplainedVariance       | 0.838      |
| Iteration               | 741        |
| ItrTime                 | 14.3       |
| LossAfter               | -2.03074   |
| LossBefore              | -1.99011   |
| MaxReturn               | 3.3e+03    |
| MeanKL                  | 0.00989981 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.75e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.58656    |
| PolicyExecTime          | 0.582      |
| ProcessExecTime         | 0.0677     |
| StdReturn               | 610        |
| Time                    | 1.01e+04   |
| dLoss                   | 0.0406388  |
----------------------------------------
itr #742 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 742...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5183, #subsample_inputs: 5183
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.67       |
| AbsLearnSignalNew       | 0.67       |
| AbsLearningOld          | 0.67       |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 48.3569    |
| AveragePolicyStd        | 0.456446   |
| AverageReturn           | 2.83e+03   |
| Entropy                 | 1.89101    |
| EnvExecTime             | 1.89       |
| ExplainedVariance       | 0.841      |
| Iteration               | 742        |
| ItrTime                 | 12.9       |
| LossAfter               | 3.28166    |
| LossBefore              | 3.31005    |
| MaxReturn               | 3.36e+03   |
| MeanKL                  | 0.00640009 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.87e+03   |
| NumTrajs                | 6          |
| Perplexity              | 6.62607    |
| PolicyExecTime          | 0.475      |
| ProcessExecTime         | 0.0563     |
| StdReturn               | 596        |
| Time                    | 1.01e+04   |
| dLoss                   | 0.0283885  |
----------------------------------------
itr #743 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 743...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5017, #subsample_inputs: 5017
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.515      |
| AbsLearnSignalNew       | 0.515      |
| AbsLearningOld          | 0.515      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 59.6412    |
| AveragePolicyStd        | 0.455639   |
| AverageReturn           | 2.38e+03   |
| Entropy                 | 1.88569    |
| EnvExecTime             | 2.17       |
| ExplainedVariance       | 0.843      |
| Iteration               | 743        |
| ItrTime                 | 13         |
| LossAfter               | 1.52084    |
| LossBefore              | 1.56229    |
| MaxReturn               | 3.23e+03   |
| MeanKL                  | 0.00972762 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.42e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.59089    |
| PolicyExecTime          | 0.552      |
| ProcessExecTime         | 0.0612     |
| StdReturn               | 623        |
| Time                    | 1.01e+04   |
| dLoss                   | 0.0414473  |
----------------------------------------
itr #744 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 744...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5281, #subsample_inputs: 5281
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.644     |
| AbsLearnSignalNew       | 0.644     |
| AbsLearningOld          | 0.644     |
| AverageDiscountedReturn | 246       |
| AveragePhiLoss          | 40.1947   |
| AveragePolicyStd        | 0.45663   |
| AverageReturn           | 2.92e+03  |
| Entropy                 | 1.89189   |
| EnvExecTime             | 2.3       |
| ExplainedVariance       | 0.871     |
| Iteration               | 744       |
| ItrTime                 | 13.5      |
| LossAfter               | -0.436725 |
| LossBefore              | -0.404131 |
| MaxReturn               | 3.28e+03  |
| MeanKL                  | 0.0097923 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.77e+03  |
| NumTrajs                | 6         |
| Perplexity              | 6.63187   |
| PolicyExecTime          | 0.589     |
| ProcessExecTime         | 0.0648    |
| StdReturn               | 528       |
| Time                    | 1.02e+04  |
| dLoss                   | 0.0325943 |
---------------------------------------
itr #745 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 745...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5000, #subsample_inputs: 5000
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.638      |
| AbsLearnSignalNew       | 0.638      |
| AbsLearningOld          | 0.638      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 44.5292    |
| AveragePolicyStd        | 0.456931   |
| AverageReturn           | 3.22e+03   |
| Entropy                 | 1.89424    |
| EnvExecTime             | 1.58       |
| ExplainedVariance       | 0.917      |
| Iteration               | 745        |
| ItrTime                 | 12.3       |
| LossAfter               | -1.68259   |
| LossBefore              | -1.65518   |
| MaxReturn               | 3.31e+03   |
| MeanKL                  | 0.00977859 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 3.15e+03   |
| NumTrajs                | 5          |
| Perplexity              | 6.64747    |
| PolicyExecTime          | 0.401      |
| ProcessExecTime         | 0.0504     |
| StdReturn               | 61.5       |
| Time                    | 1.02e+04   |
| dLoss                   | 0.0274068  |
----------------------------------------
itr #746 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 746...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5324, #subsample_inputs: 5324
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.179      |
| AbsLearnSignalNew       | 0.179      |
| AbsLearningOld          | 0.179      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 32.1928    |
| AveragePolicyStd        | 0.455873   |
| AverageReturn           | 2.53e+03   |
| Entropy                 | 1.88789    |
| EnvExecTime             | 2.3        |
| ExplainedVariance       | -10.5      |
| Iteration               | 746        |
| ItrTime                 | 13.8       |
| LossAfter               | -1.76776   |
| LossBefore              | -1.73353   |
| MaxReturn               | 3.37e+03   |
| MeanKL                  | 0.00998197 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.62e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.60543    |
| PolicyExecTime          | 0.591      |
| ProcessExecTime         | 0.0645     |
| StdReturn               | 710        |
| Time                    | 1.02e+04   |
| dLoss                   | 0.0342301  |
----------------------------------------
itr #747 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 747...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5767, #subsample_inputs: 5767
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.52       |
| AbsLearnSignalNew       | 0.52       |
| AbsLearningOld          | 0.52       |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 48.1943    |
| AveragePolicyStd        | 0.456515   |
| AverageReturn           | 2.72e+03   |
| Entropy                 | 1.89232    |
| EnvExecTime             | 2.24       |
| ExplainedVariance       | 0.863      |
| Iteration               | 747        |
| ItrTime                 | 14.2       |
| LossAfter               | 2.10702    |
| LossBefore              | 2.21419    |
| MaxReturn               | 3.32e+03   |
| MeanKL                  | 0.00987558 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.12e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.63475    |
| PolicyExecTime          | 0.57       |
| ProcessExecTime         | 0.0653     |
| StdReturn               | 797        |
| Time                    | 1.02e+04   |
| dLoss                   | 0.107172   |
----------------------------------------
itr #748 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 748...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5852, #subsample_inputs: 5852
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.619      |
| AbsLearnSignalNew       | 0.619      |
| AbsLearningOld          | 0.619      |
| AverageDiscountedReturn | 254        |
| AveragePhiLoss          | 46.3287    |
| AveragePolicyStd        | 0.457962   |
| AverageReturn           | 2.46e+03   |
| Entropy                 | 1.90141    |
| EnvExecTime             | 2.43       |
| ExplainedVariance       | 0.903      |
| Iteration               | 748        |
| ItrTime                 | 14.6       |
| LossAfter               | -1.95344   |
| LossBefore              | -1.9163    |
| MaxReturn               | 3.26e+03   |
| MeanKL                  | 0.00999179 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 983        |
| NumTrajs                | 8          |
| Perplexity              | 6.69533    |
| PolicyExecTime          | 0.623      |
| ProcessExecTime         | 0.0705     |
| StdReturn               | 704        |
| Time                    | 1.02e+04   |
| dLoss                   | 0.0371346  |
----------------------------------------
itr #749 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 749...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5629, #subsample_inputs: 5629
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.554      |
| AbsLearnSignalNew       | 0.554      |
| AbsLearningOld          | 0.554      |
| AverageDiscountedReturn | 254        |
| AveragePhiLoss          | 57.1654    |
| AveragePolicyStd        | 0.458503   |
| AverageReturn           | 2.69e+03   |
| Entropy                 | 1.90509    |
| EnvExecTime             | 2.21       |
| ExplainedVariance       | 0.771      |
| Iteration               | 749        |
| ItrTime                 | 14         |
| LossAfter               | 2.98779    |
| LossBefore              | 3.04194    |
| MaxReturn               | 3.31e+03   |
| MeanKL                  | 0.00646847 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.19e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.72003    |
| PolicyExecTime          | 0.559      |
| ProcessExecTime         | 0.0638     |
| StdReturn               | 912        |
| Time                    | 1.02e+04   |
| dLoss                   | 0.0541477  |
----------------------------------------
itr #750 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 750...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5675, #subsample_inputs: 5675
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.557      |
| AbsLearnSignalNew       | 0.557      |
| AbsLearningOld          | 0.557      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 42.4228    |
| AveragePolicyStd        | 0.459027   |
| AverageReturn           | 2.12e+03   |
| Entropy                 | 1.90811    |
| EnvExecTime             | 2.24       |
| ExplainedVariance       | 0.732      |
| Iteration               | 750        |
| ItrTime                 | 14         |
| LossAfter               | 0.721331   |
| LossBefore              | 0.745729   |
| MaxReturn               | 3.22e+03   |
| MeanKL                  | 0.00640757 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.28e+03   |
| NumTrajs                | 9          |
| Perplexity              | 6.74031    |
| PolicyExecTime          | 0.569      |
| ProcessExecTime         | 0.0649     |
| StdReturn               | 577        |
| Time                    | 1.02e+04   |
| dLoss                   | 0.0243974  |
----------------------------------------
itr #751 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 751...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5881, #subsample_inputs: 5881
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.665      |
| AbsLearnSignalNew       | 0.665      |
| AbsLearningOld          | 0.665      |
| AverageDiscountedReturn | 254        |
| AveragePhiLoss          | 46.8391    |
| AveragePolicyStd        | 0.459244   |
| AverageReturn           | 2.43e+03   |
| Entropy                 | 1.90936    |
| EnvExecTime             | 2.28       |
| ExplainedVariance       | 0.837      |
| Iteration               | 751        |
| ItrTime                 | 14.5       |
| LossAfter               | 0.989924   |
| LossBefore              | 1.02216    |
| MaxReturn               | 3.4e+03    |
| MeanKL                  | 0.00995515 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.08e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.74875    |
| PolicyExecTime          | 0.578      |
| ProcessExecTime         | 0.0683     |
| StdReturn               | 875        |
| Time                    | 1.03e+04   |
| dLoss                   | 0.0322315  |
----------------------------------------
itr #752 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 752...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5373, #subsample_inputs: 5373
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.674      |
| AbsLearnSignalNew       | 0.674      |
| AbsLearningOld          | 0.674      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 48.8026    |
| AveragePolicyStd        | 0.45828    |
| AverageReturn           | 2.22e+03   |
| Entropy                 | 1.90348    |
| EnvExecTime             | 2.43       |
| ExplainedVariance       | 0.889      |
| Iteration               | 752        |
| ItrTime                 | 14         |
| LossAfter               | -0.289782  |
| LossBefore              | -0.265978  |
| MaxReturn               | 3.25e+03   |
| MeanKL                  | 0.00641378 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.37e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.70917    |
| PolicyExecTime          | 0.609      |
| ProcessExecTime         | 0.0698     |
| StdReturn               | 820        |
| Time                    | 1.03e+04   |
| dLoss                   | 0.0238041  |
----------------------------------------
itr #753 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 753...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5763, #subsample_inputs: 5763
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.475      |
| AbsLearnSignalNew       | 0.475      |
| AbsLearningOld          | 0.475      |
| AverageDiscountedReturn | 225        |
| AveragePhiLoss          | 41.9333    |
| AveragePolicyStd        | 0.458586   |
| AverageReturn           | 2.4e+03    |
| Entropy                 | 1.90539    |
| EnvExecTime             | 2.78       |
| ExplainedVariance       | 0.764      |
| Iteration               | 753        |
| ItrTime                 | 14.9       |
| LossAfter               | 0.50494    |
| LossBefore              | 0.534866   |
| MaxReturn               | 3.3e+03    |
| MeanKL                  | 0.00645548 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 51.4       |
| NumTrajs                | 8          |
| Perplexity              | 6.72205    |
| PolicyExecTime          | 0.7        |
| ProcessExecTime         | 0.078      |
| StdReturn               | 1.01e+03   |
| Time                    | 1.03e+04   |
| dLoss                   | 0.0299265  |
----------------------------------------
itr #754 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 754...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5173, #subsample_inputs: 5173
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.53       |
| AbsLearnSignalNew       | 0.53       |
| AbsLearningOld          | 0.53       |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 84.6201    |
| AveragePolicyStd        | 0.458444   |
| AverageReturn           | 2.9e+03    |
| Entropy                 | 1.9045     |
| EnvExecTime             | 2.55       |
| ExplainedVariance       | 0.697      |
| Iteration               | 754        |
| ItrTime                 | 13.7       |
| LossAfter               | -1.39366   |
| LossBefore              | -1.33863   |
| MaxReturn               | 3.41e+03   |
| MeanKL                  | 0.00967106 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.53e+03   |
| NumTrajs                | 6          |
| Perplexity              | 6.71605    |
| PolicyExecTime          | 0.624      |
| ProcessExecTime         | 0.0759     |
| StdReturn               | 661        |
| Time                    | 1.03e+04   |
| dLoss                   | 0.0550368  |
----------------------------------------
itr #755 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 755...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5867, #subsample_inputs: 5867
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.514      |
| AbsLearnSignalNew       | 0.514      |
| AbsLearningOld          | 0.515      |
| AverageDiscountedReturn | 211        |
| AveragePhiLoss          | 42.3388    |
| AveragePolicyStd        | 0.459288   |
| AverageReturn           | 1.78e+03   |
| Entropy                 | 1.90992    |
| EnvExecTime             | 2.49       |
| ExplainedVariance       | 0.686      |
| Iteration               | 755        |
| ItrTime                 | 14.7       |
| LossAfter               | -1.83566   |
| LossBefore              | -1.79379   |
| MaxReturn               | 3.21e+03   |
| MeanKL                  | 0.00993672 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 47         |
| NumTrajs                | 11         |
| Perplexity              | 6.75252    |
| PolicyExecTime          | 0.629      |
| ProcessExecTime         | 0.0713     |
| StdReturn               | 1.03e+03   |
| Time                    | 1.03e+04   |
| dLoss                   | 0.0418713  |
----------------------------------------
itr #756 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 756...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5149, #subsample_inputs: 5149
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.478      |
| AbsLearnSignalNew       | 0.478      |
| AbsLearningOld          | 0.478      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 52.3119    |
| AveragePolicyStd        | 0.459884   |
| AverageReturn           | 2.44e+03   |
| Entropy                 | 1.91392    |
| EnvExecTime             | 1.95       |
| ExplainedVariance       | 0.546      |
| Iteration               | 756        |
| ItrTime                 | 13         |
| LossAfter               | -1.31308   |
| LossBefore              | -1.28753   |
| MaxReturn               | 3.24e+03   |
| MeanKL                  | 0.00642872 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 586        |
| NumTrajs                | 7          |
| Perplexity              | 6.77959    |
| PolicyExecTime          | 0.496      |
| ProcessExecTime         | 0.0581     |
| StdReturn               | 887        |
| Time                    | 1.03e+04   |
| dLoss                   | 0.0255454  |
----------------------------------------
itr #757 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 757...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5245, #subsample_inputs: 5245
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.597      |
| AbsLearnSignalNew       | 0.597      |
| AbsLearningOld          | 0.597      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 49.1804    |
| AveragePolicyStd        | 0.459954   |
| AverageReturn           | 2.18e+03   |
| Entropy                 | 1.91442    |
| EnvExecTime             | 2.49       |
| ExplainedVariance       | 0.788      |
| Iteration               | 757        |
| ItrTime                 | 13.7       |
| LossAfter               | -0.976121  |
| LossBefore              | -0.948648  |
| MaxReturn               | 3.28e+03   |
| MeanKL                  | 0.00995813 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.49e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.78302    |
| PolicyExecTime          | 0.62       |
| ProcessExecTime         | 0.0711     |
| StdReturn               | 750        |
| Time                    | 1.03e+04   |
| dLoss                   | 0.027473   |
----------------------------------------
itr #758 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 758...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5160, #subsample_inputs: 5160
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.672      |
| AbsLearnSignalNew       | 0.672      |
| AbsLearningOld          | 0.672      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 58.4025    |
| AveragePolicyStd        | 0.45863    |
| AverageReturn           | 2.17e+03   |
| Entropy                 | 1.90573    |
| EnvExecTime             | 2.29       |
| ExplainedVariance       | 0.87       |
| Iteration               | 758        |
| ItrTime                 | 13.4       |
| LossAfter               | 1.32133    |
| LossBefore              | 1.35492    |
| MaxReturn               | 3.2e+03    |
| MeanKL                  | 0.00988277 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.4e+03    |
| NumTrajs                | 8          |
| Perplexity              | 6.7243     |
| PolicyExecTime          | 0.585      |
| ProcessExecTime         | 0.0647     |
| StdReturn               | 613        |
| Time                    | 1.04e+04   |
| dLoss                   | 0.0335912  |
----------------------------------------
itr #759 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 759...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5258, #subsample_inputs: 5258
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.581      |
| AbsLearnSignalNew       | 0.581      |
| AbsLearningOld          | 0.58       |
| AverageDiscountedReturn | 257        |
| AveragePhiLoss          | 41.6325    |
| AveragePolicyStd        | 0.456635   |
| AverageReturn           | 2.52e+03   |
| Entropy                 | 1.89214    |
| EnvExecTime             | 2.02       |
| ExplainedVariance       | 0.818      |
| Iteration               | 759        |
| ItrTime                 | 13.2       |
| LossAfter               | 1.03443    |
| LossBefore              | 1.06331    |
| MaxReturn               | 3.3e+03    |
| MeanKL                  | 0.00990882 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.33e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.63357    |
| PolicyExecTime          | 0.518      |
| ProcessExecTime         | 0.0593     |
| StdReturn               | 767        |
| Time                    | 1.04e+04   |
| dLoss                   | 0.0288835  |
----------------------------------------
itr #760 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 760...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5557, #subsample_inputs: 5557
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.51       |
| AbsLearnSignalNew       | 0.51       |
| AbsLearningOld          | 0.51       |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 47.1293    |
| AveragePolicyStd        | 0.455654   |
| AverageReturn           | 1.86e+03   |
| Entropy                 | 1.88587    |
| EnvExecTime             | 2.43       |
| ExplainedVariance       | 0.565      |
| Iteration               | 760        |
| ItrTime                 | 14.1       |
| LossAfter               | -2.35995   |
| LossBefore              | -2.33104   |
| MaxReturn               | 3.25e+03   |
| MeanKL                  | 0.00647949 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.06e+03   |
| NumTrajs                | 10         |
| Perplexity              | 6.59209    |
| PolicyExecTime          | 0.607      |
| ProcessExecTime         | 0.0715     |
| StdReturn               | 768        |
| Time                    | 1.04e+04   |
| dLoss                   | 0.0289171  |
----------------------------------------
itr #761 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 761...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5490, #subsample_inputs: 5490
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.53       |
| AbsLearnSignalNew       | 0.53       |
| AbsLearningOld          | 0.53       |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 44.2176    |
| AveragePolicyStd        | 0.455375   |
| AverageReturn           | 1.82e+03   |
| Entropy                 | 1.8839     |
| EnvExecTime             | 2.15       |
| ExplainedVariance       | 0.561      |
| Iteration               | 761        |
| ItrTime                 | 13.6       |
| LossAfter               | 1.67734    |
| LossBefore              | 1.69778    |
| MaxReturn               | 3.25e+03   |
| MeanKL                  | 0.00645506 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 844        |
| NumTrajs                | 10         |
| Perplexity              | 6.57913    |
| PolicyExecTime          | 0.547      |
| ProcessExecTime         | 0.0645     |
| StdReturn               | 766        |
| Time                    | 1.04e+04   |
| dLoss                   | 0.0204378  |
----------------------------------------
itr #762 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 762...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5599, #subsample_inputs: 5599
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
--------------------------------------
| AbsLearnSignal          | 0.673    |
| AbsLearnSignalNew       | 0.673    |
| AbsLearningOld          | 0.673    |
| AverageDiscountedReturn | 249      |
| AveragePhiLoss          | 48.3109  |
| AveragePolicyStd        | 0.454713 |
| AverageReturn           | 2.07e+03 |
| Entropy                 | 1.87986  |
| EnvExecTime             | 2.36     |
| ExplainedVariance       | 0.82     |
| Iteration               | 762      |
| ItrTime                 | 14       |
| LossAfter               | -1.75953 |
| LossBefore              | -1.70059 |
| MaxReturn               | 3.28e+03 |
| MeanKL                  | 0.009782 |
| MeanKLBefore            | 0.0      |
| MinReturn               | 1.11e+03 |
| NumTrajs                | 9        |
| Perplexity              | 6.55258  |
| PolicyExecTime          | 0.591    |
| ProcessExecTime         | 0.0673   |
| StdReturn               | 862      |
| Time                    | 1.04e+04 |
| dLoss                   | 0.058947 |
--------------------------------------
itr #763 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 763...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5430, #subsample_inputs: 5430
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.571      |
| AbsLearnSignalNew       | 0.571      |
| AbsLearningOld          | 0.571      |
| AverageDiscountedReturn | 254        |
| AveragePhiLoss          | 41.8855    |
| AveragePolicyStd        | 0.455355   |
| AverageReturn           | 2.62e+03   |
| Entropy                 | 1.88432    |
| EnvExecTime             | 2.47       |
| ExplainedVariance       | 0.802      |
| Iteration               | 763        |
| ItrTime                 | 14.1       |
| LossAfter               | 1.47087    |
| LossBefore              | 1.50505    |
| MaxReturn               | 3.39e+03   |
| MeanKL                  | 0.00995711 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.52e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.58186    |
| PolicyExecTime          | 0.622      |
| ProcessExecTime         | 0.0708     |
| StdReturn               | 826        |
| Time                    | 1.04e+04   |
| dLoss                   | 0.0341827  |
----------------------------------------
itr #764 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 764...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5329, #subsample_inputs: 5329
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.559      |
| AbsLearnSignalNew       | 0.559      |
| AbsLearningOld          | 0.559      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 54.0384    |
| AveragePolicyStd        | 0.454451   |
| AverageReturn           | 2.19e+03   |
| Entropy                 | 1.87864    |
| EnvExecTime             | 2.21       |
| ExplainedVariance       | 0.652      |
| Iteration               | 764        |
| ItrTime                 | 13.7       |
| LossAfter               | 1.33329    |
| LossBefore              | 1.35371    |
| MaxReturn               | 3.37e+03   |
| MeanKL                  | 0.00646185 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.12e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.54457    |
| PolicyExecTime          | 0.559      |
| ProcessExecTime         | 0.0643     |
| StdReturn               | 814        |
| Time                    | 1.04e+04   |
| dLoss                   | 0.0204237  |
----------------------------------------
itr #765 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 765...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5880, #subsample_inputs: 5880
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.707      |
| AbsLearnSignalNew       | 0.707      |
| AbsLearningOld          | 0.707      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 47.8649    |
| AveragePolicyStd        | 0.453887   |
| AverageReturn           | 2.42e+03   |
| Entropy                 | 1.87471    |
| EnvExecTime             | 2.48       |
| ExplainedVariance       | 0.821      |
| Iteration               | 765        |
| ItrTime                 | 14.7       |
| LossAfter               | 0.946157   |
| LossBefore              | 0.967848   |
| MaxReturn               | 3.3e+03    |
| MeanKL                  | 0.00644435 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.5e+03    |
| NumTrajs                | 8          |
| Perplexity              | 6.5189     |
| PolicyExecTime          | 0.615      |
| ProcessExecTime         | 0.0731     |
| StdReturn               | 774        |
| Time                    | 1.05e+04   |
| dLoss                   | 0.0216905  |
----------------------------------------
itr #766 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 766...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5193, #subsample_inputs: 5193
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.575     |
| AbsLearnSignalNew       | 0.575     |
| AbsLearningOld          | 0.575     |
| AverageDiscountedReturn | 254       |
| AveragePhiLoss          | 41.1697   |
| AveragePolicyStd        | 0.454041  |
| AverageReturn           | 1.96e+03  |
| Entropy                 | 1.87596   |
| EnvExecTime             | 2.33      |
| ExplainedVariance       | 0.802     |
| Iteration               | 766       |
| ItrTime                 | 13.5      |
| LossAfter               | 0.173757  |
| LossBefore              | 0.197174  |
| MaxReturn               | 3.28e+03  |
| MeanKL                  | 0.0064406 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 892       |
| NumTrajs                | 9         |
| Perplexity              | 6.5271    |
| PolicyExecTime          | 0.584     |
| ProcessExecTime         | 0.0653    |
| StdReturn               | 878       |
| Time                    | 1.05e+04  |
| dLoss                   | 0.0234164 |
---------------------------------------
itr #767 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 767...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5444, #subsample_inputs: 5444
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.661      |
| AbsLearnSignalNew       | 0.661      |
| AbsLearningOld          | 0.661      |
| AverageDiscountedReturn | 255        |
| AveragePhiLoss          | 48.7659    |
| AveragePolicyStd        | 0.453577   |
| AverageReturn           | 2.63e+03   |
| Entropy                 | 1.87312    |
| EnvExecTime             | 2.32       |
| ExplainedVariance       | 0.859      |
| Iteration               | 767        |
| ItrTime                 | 13.9       |
| LossAfter               | 0.80605    |
| LossBefore              | 0.831269   |
| MaxReturn               | 3.34e+03   |
| MeanKL                  | 0.00645614 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.21e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.50858    |
| PolicyExecTime          | 0.582      |
| ProcessExecTime         | 0.0676     |
| StdReturn               | 695        |
| Time                    | 1.05e+04   |
| dLoss                   | 0.0252196  |
----------------------------------------
itr #768 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 768...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5466, #subsample_inputs: 5466
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.603      |
| AbsLearnSignalNew       | 0.603      |
| AbsLearningOld          | 0.603      |
| AverageDiscountedReturn | 256        |
| AveragePhiLoss          | 51.5908    |
| AveragePolicyStd        | 0.45409    |
| AverageReturn           | 2.59e+03   |
| Entropy                 | 1.87597    |
| EnvExecTime             | 2.45       |
| ExplainedVariance       | 0.838      |
| Iteration               | 768        |
| ItrTime                 | 14         |
| LossAfter               | 0.67989    |
| LossBefore              | 0.709195   |
| MaxReturn               | 3.35e+03   |
| MeanKL                  | 0.00994791 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.52e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.52714    |
| PolicyExecTime          | 0.61       |
| ProcessExecTime         | 0.0711     |
| StdReturn               | 803        |
| Time                    | 1.05e+04   |
| dLoss                   | 0.0293056  |
----------------------------------------
itr #769 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 769...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5552, #subsample_inputs: 5552
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.498      |
| AbsLearnSignalNew       | 0.498      |
| AbsLearningOld          | 0.498      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 48.4671    |
| AveragePolicyStd        | 0.453079   |
| AverageReturn           | 2.25e+03   |
| Entropy                 | 1.86886    |
| EnvExecTime             | 2.22       |
| ExplainedVariance       | 0.585      |
| Iteration               | 769        |
| ItrTime                 | 13.8       |
| LossAfter               | 1.18024    |
| LossBefore              | 1.20315    |
| MaxReturn               | 3.21e+03   |
| MeanKL                  | 0.00640351 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.42e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.4809     |
| PolicyExecTime          | 0.557      |
| ProcessExecTime         | 0.0664     |
| StdReturn               | 731        |
| Time                    | 1.05e+04   |
| dLoss                   | 0.0229125  |
----------------------------------------
itr #770 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 770...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5675, #subsample_inputs: 5675
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.714      |
| AbsLearnSignalNew       | 0.714      |
| AbsLearningOld          | 0.714      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 45.9864    |
| AveragePolicyStd        | 0.45343    |
| AverageReturn           | 2.7e+03    |
| Entropy                 | 1.87141    |
| EnvExecTime             | 2.56       |
| ExplainedVariance       | 0.783      |
| Iteration               | 770        |
| ItrTime                 | 14.4       |
| LossAfter               | -2.60042   |
| LossBefore              | -2.56319   |
| MaxReturn               | 3.25e+03   |
| MeanKL                  | 0.00993876 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.94e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.49744    |
| PolicyExecTime          | 0.646      |
| ProcessExecTime         | 0.0716     |
| StdReturn               | 555        |
| Time                    | 1.05e+04   |
| dLoss                   | 0.0372293  |
----------------------------------------
itr #771 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 771...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5581, #subsample_inputs: 5581
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.658      |
| AbsLearnSignalNew       | 0.658      |
| AbsLearningOld          | 0.658      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 46.6441    |
| AveragePolicyStd        | 0.453874   |
| AverageReturn           | 2.3e+03    |
| Entropy                 | 1.8739     |
| EnvExecTime             | 2.52       |
| ExplainedVariance       | 0.873      |
| Iteration               | 771        |
| ItrTime                 | 14.3       |
| LossAfter               | -1.0873    |
| LossBefore              | -1.06144   |
| MaxReturn               | 3.23e+03   |
| MeanKL                  | 0.00646447 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.34e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.51367    |
| PolicyExecTime          | 0.637      |
| ProcessExecTime         | 0.0703     |
| StdReturn               | 738        |
| Time                    | 1.05e+04   |
| dLoss                   | 0.025865   |
----------------------------------------
itr #772 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 772...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5746, #subsample_inputs: 5746
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.66       |
| AbsLearnSignalNew       | 0.66       |
| AbsLearningOld          | 0.66       |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 49.0776    |
| AveragePolicyStd        | 0.454018   |
| AverageReturn           | 2.69e+03   |
| Entropy                 | 1.87487    |
| EnvExecTime             | 2.38       |
| ExplainedVariance       | 0.864      |
| Iteration               | 772        |
| ItrTime                 | 14.3       |
| LossAfter               | -2.62149   |
| LossBefore              | -2.59344   |
| MaxReturn               | 3.32e+03   |
| MeanKL                  | 0.00997756 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.71e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.52       |
| PolicyExecTime          | 0.604      |
| ProcessExecTime         | 0.0695     |
| StdReturn               | 639        |
| Time                    | 1.06e+04   |
| dLoss                   | 0.0280433  |
----------------------------------------
itr #773 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 773...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5951, #subsample_inputs: 5951
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.544      |
| AbsLearnSignalNew       | 0.544      |
| AbsLearningOld          | 0.545      |
| AverageDiscountedReturn | 224        |
| AveragePhiLoss          | 56.0497    |
| AveragePolicyStd        | 0.453521   |
| AverageReturn           | 2.19e+03   |
| Entropy                 | 1.87149    |
| EnvExecTime             | 2.41       |
| ExplainedVariance       | 0.826      |
| Iteration               | 773        |
| ItrTime                 | 14.7       |
| LossAfter               | -0.44013   |
| LossBefore              | -0.401073  |
| MaxReturn               | 3.26e+03   |
| MeanKL                  | 0.00992129 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 49.2       |
| NumTrajs                | 9          |
| Perplexity              | 6.49797    |
| PolicyExecTime          | 0.617      |
| ProcessExecTime         | 0.0693     |
| StdReturn               | 918        |
| Time                    | 1.06e+04   |
| dLoss                   | 0.0390568  |
----------------------------------------
itr #774 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 774...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5036, #subsample_inputs: 5036
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.675      |
| AbsLearnSignalNew       | 0.675      |
| AbsLearningOld          | 0.675      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 52.864     |
| AveragePolicyStd        | 0.453389   |
| AverageReturn           | 2.41e+03   |
| Entropy                 | 1.87091    |
| EnvExecTime             | 2.39       |
| ExplainedVariance       | 0.875      |
| Iteration               | 774        |
| ItrTime                 | 13.3       |
| LossAfter               | -1.90814   |
| LossBefore              | -1.88105   |
| MaxReturn               | 3.26e+03   |
| MeanKL                  | 0.00640717 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.47e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.49422    |
| PolicyExecTime          | 0.605      |
| ProcessExecTime         | 0.0649     |
| StdReturn               | 667        |
| Time                    | 1.06e+04   |
| dLoss                   | 0.0270817  |
----------------------------------------
itr #775 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 775...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5308, #subsample_inputs: 5308
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.56       |
| AbsLearnSignalNew       | 0.56       |
| AbsLearningOld          | 0.56       |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 46.8424    |
| AveragePolicyStd        | 0.453535   |
| AverageReturn           | 2e+03      |
| Entropy                 | 1.87089    |
| EnvExecTime             | 2.42       |
| ExplainedVariance       | 0.776      |
| Iteration               | 775        |
| ItrTime                 | 13.8       |
| LossAfter               | -0.737208  |
| LossBefore              | -0.70118   |
| MaxReturn               | 3.36e+03   |
| MeanKL                  | 0.00995121 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.52e+03   |
| NumTrajs                | 9          |
| Perplexity              | 6.49406    |
| PolicyExecTime          | 0.615      |
| ProcessExecTime         | 0.067      |
| StdReturn               | 522        |
| Time                    | 1.06e+04   |
| dLoss                   | 0.0360284  |
----------------------------------------
itr #776 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 776...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5242, #subsample_inputs: 5242
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.45      |
| AbsLearnSignalNew       | 0.45      |
| AbsLearningOld          | 0.45      |
| AverageDiscountedReturn | 249       |
| AveragePhiLoss          | 42.8943   |
| AveragePolicyStd        | 0.453565  |
| AverageReturn           | 2.49e+03  |
| Entropy                 | 1.87094   |
| EnvExecTime             | 2.3       |
| ExplainedVariance       | 0.47      |
| Iteration               | 776       |
| ItrTime                 | 13.5      |
| LossAfter               | -2.82865  |
| LossBefore              | -2.79996  |
| MaxReturn               | 3.26e+03  |
| MeanKL                  | 0.0099777 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.54e+03  |
| NumTrajs                | 7         |
| Perplexity              | 6.49442   |
| PolicyExecTime          | 0.569     |
| ProcessExecTime         | 0.0687    |
| StdReturn               | 685       |
| Time                    | 1.06e+04  |
| dLoss                   | 0.0286863 |
---------------------------------------
itr #777 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 777...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5694, #subsample_inputs: 5694
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.571      |
| AbsLearnSignalNew       | 0.571      |
| AbsLearningOld          | 0.571      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 38.5628    |
| AveragePolicyStd        | 0.454279   |
| AverageReturn           | 1.94e+03   |
| Entropy                 | 1.87551    |
| EnvExecTime             | 2.06       |
| ExplainedVariance       | 0.793      |
| Iteration               | 777        |
| ItrTime                 | 13.9       |
| LossAfter               | 0.483246   |
| LossBefore              | 0.505362   |
| MaxReturn               | 3.39e+03   |
| MeanKL                  | 0.00643128 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.17e+03   |
| NumTrajs                | 10         |
| Perplexity              | 6.52416    |
| PolicyExecTime          | 0.526      |
| ProcessExecTime         | 0.0614     |
| StdReturn               | 641        |
| Time                    | 1.06e+04   |
| dLoss                   | 0.0221161  |
----------------------------------------
itr #778 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 778...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5056, #subsample_inputs: 5056
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.444      |
| AbsLearnSignalNew       | 0.444      |
| AbsLearningOld          | 0.444      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 45.3913    |
| AveragePolicyStd        | 0.453025   |
| AverageReturn           | 2.75e+03   |
| Entropy                 | 1.86738    |
| EnvExecTime             | 1.69       |
| ExplainedVariance       | 0.148      |
| Iteration               | 778        |
| ItrTime                 | 12.4       |
| LossAfter               | -0.11886   |
| LossBefore              | -0.0944989 |
| MaxReturn               | 3.28e+03   |
| MeanKL                  | 0.00991595 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.63e+03   |
| NumTrajs                | 6          |
| Perplexity              | 6.47134    |
| PolicyExecTime          | 0.431      |
| ProcessExecTime         | 0.0545     |
| StdReturn               | 691        |
| Time                    | 1.06e+04   |
| dLoss                   | 0.0243611  |
----------------------------------------
itr #779 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 779...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5443, #subsample_inputs: 5443
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.492      |
| AbsLearnSignalNew       | 0.492      |
| AbsLearningOld          | 0.492      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 33.4571    |
| AveragePolicyStd        | 0.455035   |
| AverageReturn           | 2.62e+03   |
| Entropy                 | 1.87978    |
| EnvExecTime             | 2.4        |
| ExplainedVariance       | 0.655      |
| Iteration               | 779        |
| ItrTime                 | 14.1       |
| LossAfter               | -1.3031    |
| LossBefore              | -1.28101   |
| MaxReturn               | 3.3e+03    |
| MeanKL                  | 0.00646382 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.93e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.55209    |
| PolicyExecTime          | 0.606      |
| ProcessExecTime         | 0.0676     |
| StdReturn               | 454        |
| Time                    | 1.07e+04   |
| dLoss                   | 0.0220832  |
----------------------------------------
itr #780 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 780...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5168, #subsample_inputs: 5168
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.446      |
| AbsLearnSignalNew       | 0.446      |
| AbsLearningOld          | 0.446      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 51.5353    |
| AveragePolicyStd        | 0.453087   |
| AverageReturn           | 2.4e+03    |
| Entropy                 | 1.86647    |
| EnvExecTime             | 1.97       |
| ExplainedVariance       | 0.379      |
| Iteration               | 780        |
| ItrTime                 | 13.1       |
| LossAfter               | -0.351844  |
| LossBefore              | -0.322746  |
| MaxReturn               | 3.3e+03    |
| MeanKL                  | 0.00993326 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 571        |
| NumTrajs                | 7          |
| Perplexity              | 6.46544    |
| PolicyExecTime          | 0.504      |
| ProcessExecTime         | 0.0595     |
| StdReturn               | 989        |
| Time                    | 1.07e+04   |
| dLoss                   | 0.0290985  |
----------------------------------------
itr #781 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 781...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5815, #subsample_inputs: 5815
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.565      |
| AbsLearnSignalNew       | 0.565      |
| AbsLearningOld          | 0.565      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 49.0517    |
| AveragePolicyStd        | 0.452853   |
| AverageReturn           | 2.38e+03   |
| Entropy                 | 1.86465    |
| EnvExecTime             | 2.32       |
| ExplainedVariance       | 0.725      |
| Iteration               | 781        |
| ItrTime                 | 14.4       |
| LossAfter               | 1.41387    |
| LossBefore              | 1.43779    |
| MaxReturn               | 3.25e+03   |
| MeanKL                  | 0.00646204 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.16e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.45369    |
| PolicyExecTime          | 0.581      |
| ProcessExecTime         | 0.0691     |
| StdReturn               | 732        |
| Time                    | 1.07e+04   |
| dLoss                   | 0.0239191  |
----------------------------------------
itr #782 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 782...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5055, #subsample_inputs: 5055
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.634      |
| AbsLearnSignalNew       | 0.634      |
| AbsLearningOld          | 0.634      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 50.8362    |
| AveragePolicyStd        | 0.452923   |
| AverageReturn           | 2.12e+03   |
| Entropy                 | 1.86479    |
| EnvExecTime             | 1.82       |
| ExplainedVariance       | 0.724      |
| Iteration               | 782        |
| ItrTime                 | 12.7       |
| LossAfter               | -2.652     |
| LossBefore              | -2.62264   |
| MaxReturn               | 3.3e+03    |
| MeanKL                  | 0.00640919 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.54e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.45461    |
| PolicyExecTime          | 0.467      |
| ProcessExecTime         | 0.0549     |
| StdReturn               | 546        |
| Time                    | 1.07e+04   |
| dLoss                   | 0.029357   |
----------------------------------------
itr #783 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 783...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5446, #subsample_inputs: 5446
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.538      |
| AbsLearnSignalNew       | 0.538      |
| AbsLearningOld          | 0.538      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 39.0758    |
| AveragePolicyStd        | 0.453087   |
| AverageReturn           | 2.27e+03   |
| Entropy                 | 1.86662    |
| EnvExecTime             | 2.24       |
| ExplainedVariance       | 0.761      |
| Iteration               | 783        |
| ItrTime                 | 13.8       |
| LossAfter               | -0.501673  |
| LossBefore              | -0.485201  |
| MaxReturn               | 3.23e+03   |
| MeanKL                  | 0.00647554 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.58e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.46638    |
| PolicyExecTime          | 0.563      |
| ProcessExecTime         | 0.0647     |
| StdReturn               | 532        |
| Time                    | 1.07e+04   |
| dLoss                   | 0.0164727  |
----------------------------------------
itr #784 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 784...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5715, #subsample_inputs: 5715
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.543      |
| AbsLearnSignalNew       | 0.543      |
| AbsLearningOld          | 0.543      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 45.9751    |
| AveragePolicyStd        | 0.453158   |
| AverageReturn           | 2.39e+03   |
| Entropy                 | 1.86769    |
| EnvExecTime             | 2.42       |
| ExplainedVariance       | 0.699      |
| Iteration               | 784        |
| ItrTime                 | 14.4       |
| LossAfter               | -1.97849   |
| LossBefore              | -1.95274   |
| MaxReturn               | 3.25e+03   |
| MeanKL                  | 0.00641414 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.62e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.4733     |
| PolicyExecTime          | 0.62       |
| ProcessExecTime         | 0.069      |
| StdReturn               | 582        |
| Time                    | 1.07e+04   |
| dLoss                   | 0.0257497  |
----------------------------------------
itr #785 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 785...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5385, #subsample_inputs: 5385
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.711      |
| AbsLearnSignalNew       | 0.711      |
| AbsLearningOld          | 0.711      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 45.1552    |
| AveragePolicyStd        | 0.452876   |
| AverageReturn           | 2.27e+03   |
| Entropy                 | 1.86677    |
| EnvExecTime             | 2.56       |
| ExplainedVariance       | 0.923      |
| Iteration               | 785        |
| ItrTime                 | 14.1       |
| LossAfter               | -0.466033  |
| LossBefore              | -0.435981  |
| MaxReturn               | 2.92e+03   |
| MeanKL                  | 0.00984721 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.72e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.46738    |
| PolicyExecTime          | 0.637      |
| ProcessExecTime         | 0.0721     |
| StdReturn               | 473        |
| Time                    | 1.07e+04   |
| dLoss                   | 0.0300522  |
----------------------------------------
itr #786 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 786...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5694, #subsample_inputs: 5694
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.476      |
| AbsLearnSignalNew       | 0.476      |
| AbsLearningOld          | 0.476      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 68.4737    |
| AveragePolicyStd        | 0.453094   |
| AverageReturn           | 2.35e+03   |
| Entropy                 | 1.86807    |
| EnvExecTime             | 2.27       |
| ExplainedVariance       | 0.639      |
| Iteration               | 786        |
| ItrTime                 | 14.1       |
| LossAfter               | -0.639614  |
| LossBefore              | -0.598884  |
| MaxReturn               | 3.28e+03   |
| MeanKL                  | 0.00963835 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.24e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.47576    |
| PolicyExecTime          | 0.582      |
| ProcessExecTime         | 0.065      |
| StdReturn               | 664        |
| Time                    | 1.07e+04   |
| dLoss                   | 0.04073    |
----------------------------------------
itr #787 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 787...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5055, #subsample_inputs: 5055
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.625      |
| AbsLearnSignalNew       | 0.625      |
| AbsLearningOld          | 0.625      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 50.3966    |
| AveragePolicyStd        | 0.453302   |
| AverageReturn           | 2.12e+03   |
| Entropy                 | 1.86968    |
| EnvExecTime             | 2.26       |
| ExplainedVariance       | 0.822      |
| Iteration               | 787        |
| ItrTime                 | 13.1       |
| LossAfter               | -3.24042   |
| LossBefore              | -3.21686   |
| MaxReturn               | 3.24e+03   |
| MeanKL                  | 0.00640216 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.24e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.48624    |
| PolicyExecTime          | 0.57       |
| ProcessExecTime         | 0.0642     |
| StdReturn               | 616        |
| Time                    | 1.08e+04   |
| dLoss                   | 0.023562   |
----------------------------------------
itr #788 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 788...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5286, #subsample_inputs: 5286
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.707      |
| AbsLearnSignalNew       | 0.707      |
| AbsLearningOld          | 0.707      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 48.7711    |
| AveragePolicyStd        | 0.452956   |
| AverageReturn           | 2.21e+03   |
| Entropy                 | 1.86714    |
| EnvExecTime             | 2.71       |
| ExplainedVariance       | 0.927      |
| Iteration               | 788        |
| ItrTime                 | 14.1       |
| LossAfter               | -3.91039   |
| LossBefore              | -3.87683   |
| MaxReturn               | 3.21e+03   |
| MeanKL                  | 0.00997541 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.42e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.46975    |
| PolicyExecTime          | 0.672      |
| ProcessExecTime         | 0.0749     |
| StdReturn               | 529        |
| Time                    | 1.08e+04   |
| dLoss                   | 0.0335536  |
----------------------------------------
itr #789 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 789...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5116, #subsample_inputs: 5116
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.642      |
| AbsLearnSignalNew       | 0.642      |
| AbsLearningOld          | 0.642      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 49.4941    |
| AveragePolicyStd        | 0.451351   |
| AverageReturn           | 2.4e+03    |
| Entropy                 | 1.8564     |
| EnvExecTime             | 1.94       |
| ExplainedVariance       | 0.891      |
| Iteration               | 789        |
| ItrTime                 | 12.8       |
| LossAfter               | -2.6363    |
| LossBefore              | -2.59807   |
| MaxReturn               | 3.25e+03   |
| MeanKL                  | 0.00986255 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.79e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.40063    |
| PolicyExecTime          | 0.5        |
| ProcessExecTime         | 0.0564     |
| StdReturn               | 539        |
| Time                    | 1.08e+04   |
| dLoss                   | 0.0382376  |
----------------------------------------
itr #790 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 790...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5700, #subsample_inputs: 5700
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.685      |
| AbsLearnSignalNew       | 0.685      |
| AbsLearningOld          | 0.685      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 49.1566    |
| AveragePolicyStd        | 0.450723   |
| AverageReturn           | 2.36e+03   |
| Entropy                 | 1.85134    |
| EnvExecTime             | 2.65       |
| ExplainedVariance       | 0.893      |
| Iteration               | 790        |
| ItrTime                 | 14.6       |
| LossAfter               | 1.89959    |
| LossBefore              | 1.9336     |
| MaxReturn               | 3.32e+03   |
| MeanKL                  | 0.00999366 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.45e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.36833    |
| PolicyExecTime          | 0.668      |
| ProcessExecTime         | 0.0741     |
| StdReturn               | 734        |
| Time                    | 1.08e+04   |
| dLoss                   | 0.0340159  |
----------------------------------------
itr #791 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 791...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5480, #subsample_inputs: 5480
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.64       |
| AbsLearnSignalNew       | 0.64       |
| AbsLearningOld          | 0.64       |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 46.3067    |
| AveragePolicyStd        | 0.450307   |
| AverageReturn           | 2.59e+03   |
| Entropy                 | 1.84875    |
| EnvExecTime             | 2.55       |
| ExplainedVariance       | 0.852      |
| Iteration               | 791        |
| ItrTime                 | 14.1       |
| LossAfter               | 0.119443   |
| LossBefore              | 0.148338   |
| MaxReturn               | 3.27e+03   |
| MeanKL                  | 0.00996509 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.8e+03    |
| NumTrajs                | 7          |
| Perplexity              | 6.3519     |
| PolicyExecTime          | 0.639      |
| ProcessExecTime         | 0.0702     |
| StdReturn               | 602        |
| Time                    | 1.08e+04   |
| dLoss                   | 0.0288956  |
----------------------------------------
itr #792 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 792...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5039, #subsample_inputs: 5039
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.62       |
| AbsLearnSignalNew       | 0.62       |
| AbsLearningOld          | 0.62       |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 45.7309    |
| AveragePolicyStd        | 0.450554   |
| AverageReturn           | 2.72e+03   |
| Entropy                 | 1.84962    |
| EnvExecTime             | 1.67       |
| ExplainedVariance       | 0.898      |
| Iteration               | 792        |
| ItrTime                 | 12.4       |
| LossAfter               | -1.59534   |
| LossBefore              | -1.56393   |
| MaxReturn               | 3.24e+03   |
| MeanKL                  | 0.00999561 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.53e+03   |
| NumTrajs                | 6          |
| Perplexity              | 6.35739    |
| PolicyExecTime          | 0.425      |
| ProcessExecTime         | 0.0524     |
| StdReturn               | 709        |
| Time                    | 1.08e+04   |
| dLoss                   | 0.0314118  |
----------------------------------------
itr #793 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 793...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5053, #subsample_inputs: 5053
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.537      |
| AbsLearnSignalNew       | 0.537      |
| AbsLearningOld          | 0.537      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 66.1922    |
| AveragePolicyStd        | 0.450592   |
| AverageReturn           | 2.4e+03    |
| Entropy                 | 1.84991    |
| EnvExecTime             | 2.18       |
| ExplainedVariance       | 0.848      |
| Iteration               | 793        |
| ItrTime                 | 13         |
| LossAfter               | -1.28574   |
| LossBefore              | -1.23983   |
| MaxReturn               | 3.36e+03   |
| MeanKL                  | 0.00968916 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.35e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.35924    |
| PolicyExecTime          | 0.558      |
| ProcessExecTime         | 0.0618     |
| StdReturn               | 873        |
| Time                    | 1.08e+04   |
| dLoss                   | 0.0459142  |
----------------------------------------
itr #794 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 794...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5603, #subsample_inputs: 5603
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.639      |
| AbsLearnSignalNew       | 0.639      |
| AbsLearningOld          | 0.639      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 45.446     |
| AveragePolicyStd        | 0.45039    |
| AverageReturn           | 2.65e+03   |
| Entropy                 | 1.84901    |
| EnvExecTime             | 2.31       |
| ExplainedVariance       | 0.87       |
| Iteration               | 794        |
| ItrTime                 | 14         |
| LossAfter               | 1.4548     |
| LossBefore              | 1.48455    |
| MaxReturn               | 3.23e+03   |
| MeanKL                  | 0.00643593 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.79e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.35352    |
| PolicyExecTime          | 0.584      |
| ProcessExecTime         | 0.0668     |
| StdReturn               | 509        |
| Time                    | 1.09e+04   |
| dLoss                   | 0.0297543  |
----------------------------------------
itr #795 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 795...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5043, #subsample_inputs: 5043
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.609      |
| AbsLearnSignalNew       | 0.609      |
| AbsLearningOld          | 0.609      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 47.5882    |
| AveragePolicyStd        | 0.450221   |
| AverageReturn           | 2.39e+03   |
| Entropy                 | 1.84732    |
| EnvExecTime             | 2.18       |
| ExplainedVariance       | 0.883      |
| Iteration               | 795        |
| ItrTime                 | 13         |
| LossAfter               | -0.322046  |
| LossBefore              | -0.300226  |
| MaxReturn               | 3.24e+03   |
| MeanKL                  | 0.00650315 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.58e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.34281    |
| PolicyExecTime          | 0.556      |
| ProcessExecTime         | 0.0624     |
| StdReturn               | 675        |
| Time                    | 1.09e+04   |
| dLoss                   | 0.0218199  |
----------------------------------------
itr #796 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 796...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5431, #subsample_inputs: 5431
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.664      |
| AbsLearnSignalNew       | 0.664      |
| AbsLearningOld          | 0.664      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 42.2459    |
| AveragePolicyStd        | 0.450116   |
| AverageReturn           | 2.91e+03   |
| Entropy                 | 1.84712    |
| EnvExecTime             | 2.24       |
| ExplainedVariance       | 0.888      |
| Iteration               | 796        |
| ItrTime                 | 13.8       |
| LossAfter               | -3.41094   |
| LossBefore              | -3.39113   |
| MaxReturn               | 3.25e+03   |
| MeanKL                  | 0.00649104 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.43e+03   |
| NumTrajs                | 6          |
| Perplexity              | 6.3415     |
| PolicyExecTime          | 0.571      |
| ProcessExecTime         | 0.065      |
| StdReturn               | 662        |
| Time                    | 1.09e+04   |
| dLoss                   | 0.0198028  |
----------------------------------------
itr #797 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 797...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5206, #subsample_inputs: 5206
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.66       |
| AbsLearnSignalNew       | 0.66       |
| AbsLearningOld          | 0.66       |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 41.1009    |
| AveragePolicyStd        | 0.450745   |
| AverageReturn           | 2.46e+03   |
| Entropy                 | 1.85053    |
| EnvExecTime             | 2.4        |
| ExplainedVariance       | 0.86       |
| Iteration               | 797        |
| ItrTime                 | 13.6       |
| LossAfter               | 2.73462    |
| LossBefore              | 2.76661    |
| MaxReturn               | 3.28e+03   |
| MeanKL                  | 0.00977423 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.49e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.3632     |
| PolicyExecTime          | 0.601      |
| ProcessExecTime         | 0.0667     |
| StdReturn               | 582        |
| Time                    | 1.09e+04   |
| dLoss                   | 0.0319881  |
----------------------------------------
itr #798 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 798...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5352, #subsample_inputs: 5352
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.605      |
| AbsLearnSignalNew       | 0.605      |
| AbsLearningOld          | 0.604      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 49.6093    |
| AveragePolicyStd        | 0.451916   |
| AverageReturn           | 2.57e+03   |
| Entropy                 | 1.85766    |
| EnvExecTime             | 2.29       |
| ExplainedVariance       | 0.876      |
| Iteration               | 798        |
| ItrTime                 | 13.7       |
| LossAfter               | -2.96616   |
| LossBefore              | -2.9184    |
| MaxReturn               | 3.39e+03   |
| MeanKL                  | 0.00994928 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.63e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.4087     |
| PolicyExecTime          | 0.569      |
| ProcessExecTime         | 0.0666     |
| StdReturn               | 604        |
| Time                    | 1.09e+04   |
| dLoss                   | 0.0477588  |
----------------------------------------
itr #799 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 799...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5031, #subsample_inputs: 5031
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.627     |
| AbsLearnSignalNew       | 0.627     |
| AbsLearningOld          | 0.628     |
| AverageDiscountedReturn | 252       |
| AveragePhiLoss          | 44.3412   |
| AveragePolicyStd        | 0.452201  |
| AverageReturn           | 2.42e+03  |
| Entropy                 | 1.8595    |
| EnvExecTime             | 2.03      |
| ExplainedVariance       | 0.9       |
| Iteration               | 799       |
| ItrTime                 | 12.9      |
| LossAfter               | 4.12172   |
| LossBefore              | 4.15025   |
| MaxReturn               | 3.24e+03  |
| MeanKL                  | 0.0098854 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.81e+03  |
| NumTrajs                | 7         |
| Perplexity              | 6.42052   |
| PolicyExecTime          | 0.52      |
| ProcessExecTime         | 0.0589    |
| StdReturn               | 516       |
| Time                    | 1.09e+04  |
| dLoss                   | 0.0285296 |
---------------------------------------
itr #800 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 800...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5730, #subsample_inputs: 5730
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.711      |
| AbsLearnSignalNew       | 0.711      |
| AbsLearningOld          | 0.711      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 51.7764    |
| AveragePolicyStd        | 0.452971   |
| AverageReturn           | 1.93e+03   |
| Entropy                 | 1.86425    |
| EnvExecTime             | 2.61       |
| ExplainedVariance       | 0.879      |
| Iteration               | 800        |
| ItrTime                 | 14.6       |
| LossAfter               | 2.97678    |
| LossBefore              | 3.00339    |
| MaxReturn               | 3.09e+03   |
| MeanKL                  | 0.00647193 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.39e+03   |
| NumTrajs                | 10         |
| Perplexity              | 6.45107    |
| PolicyExecTime          | 0.654      |
| ProcessExecTime         | 0.0742     |
| StdReturn               | 493        |
| Time                    | 1.09e+04   |
| dLoss                   | 0.0266192  |
----------------------------------------
itr #801 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 801...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5456, #subsample_inputs: 5456
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.74      |
| AbsLearnSignalNew       | 0.74      |
| AbsLearningOld          | 0.74      |
| AverageDiscountedReturn | 248       |
| AveragePhiLoss          | 49.0707   |
| AveragePolicyStd        | 0.453028  |
| AverageReturn           | 2.04e+03  |
| Entropy                 | 1.86509   |
| EnvExecTime             | 2.3       |
| ExplainedVariance       | 0.934     |
| Iteration               | 801       |
| ItrTime                 | 14        |
| LossAfter               | 1.47498   |
| LossBefore              | 1.50734   |
| MaxReturn               | 3.13e+03  |
| MeanKL                  | 0.0099169 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.01e+03  |
| NumTrajs                | 9         |
| Perplexity              | 6.4565    |
| PolicyExecTime          | 0.58      |
| ProcessExecTime         | 0.0662    |
| StdReturn               | 627       |
| Time                    | 1.1e+04   |
| dLoss                   | 0.0323547 |
---------------------------------------
itr #802 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 802...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5521, #subsample_inputs: 5521
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.695      |
| AbsLearnSignalNew       | 0.695      |
| AbsLearningOld          | 0.694      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 47.0906    |
| AveragePolicyStd        | 0.452949   |
| AverageReturn           | 1.87e+03   |
| Entropy                 | 1.8635     |
| EnvExecTime             | 2.22       |
| ExplainedVariance       | 0.92       |
| Iteration               | 802        |
| ItrTime                 | 13.8       |
| LossAfter               | 2.8083     |
| LossBefore              | 2.83725    |
| MaxReturn               | 3.31e+03   |
| MeanKL                  | 0.00982372 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.04e+03   |
| NumTrajs                | 10         |
| Perplexity              | 6.44626    |
| PolicyExecTime          | 0.567      |
| ProcessExecTime         | 0.0637     |
| StdReturn               | 647        |
| Time                    | 1.1e+04    |
| dLoss                   | 0.0289433  |
----------------------------------------
itr #803 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 803...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5047, #subsample_inputs: 5047
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.5        |
| AbsLearnSignalNew       | 0.5        |
| AbsLearningOld          | 0.5        |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 53.5105    |
| AveragePolicyStd        | 0.453263   |
| AverageReturn           | 2.09e+03   |
| Entropy                 | 1.86495    |
| EnvExecTime             | 2.41       |
| ExplainedVariance       | 0.7        |
| Iteration               | 803        |
| ItrTime                 | 13.4       |
| LossAfter               | -1.06847   |
| LossBefore              | -1.03668   |
| MaxReturn               | 3.23e+03   |
| MeanKL                  | 0.00999241 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.06e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.45559    |
| PolicyExecTime          | 0.61       |
| ProcessExecTime         | 0.0672     |
| StdReturn               | 781        |
| Time                    | 1.1e+04    |
| dLoss                   | 0.0317922  |
----------------------------------------
itr #804 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 804...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5254, #subsample_inputs: 5254
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.563      |
| AbsLearnSignalNew       | 0.563      |
| AbsLearningOld          | 0.563      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 49.5795    |
| AveragePolicyStd        | 0.452388   |
| AverageReturn           | 2.48e+03   |
| Entropy                 | 1.85977    |
| EnvExecTime             | 1.92       |
| ExplainedVariance       | 0.758      |
| Iteration               | 804        |
| ItrTime                 | 13         |
| LossAfter               | -2.68336   |
| LossBefore              | -2.63527   |
| MaxReturn               | 3.27e+03   |
| MeanKL                  | 0.00996505 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 958        |
| NumTrajs                | 7          |
| Perplexity              | 6.42223    |
| PolicyExecTime          | 0.482      |
| ProcessExecTime         | 0.0575     |
| StdReturn               | 829        |
| Time                    | 1.1e+04    |
| dLoss                   | 0.048089   |
----------------------------------------
itr #805 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 805...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5130, #subsample_inputs: 5130
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.615     |
| AbsLearnSignalNew       | 0.615     |
| AbsLearningOld          | 0.615     |
| AverageDiscountedReturn | 252       |
| AveragePhiLoss          | 47.3389   |
| AveragePolicyStd        | 0.452141  |
| AverageReturn           | 2.14e+03  |
| Entropy                 | 1.85795   |
| EnvExecTime             | 2.64      |
| ExplainedVariance       | 0.84      |
| Iteration               | 805       |
| ItrTime                 | 13.7      |
| LossAfter               | 0.745624  |
| LossBefore              | 0.770832  |
| MaxReturn               | 3.29e+03  |
| MeanKL                  | 0.0064029 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.24e+03  |
| NumTrajs                | 8         |
| Perplexity              | 6.41058   |
| PolicyExecTime          | 0.661     |
| ProcessExecTime         | 0.0732    |
| StdReturn               | 716       |
| Time                    | 1.1e+04   |
| dLoss                   | 0.0252077 |
---------------------------------------
itr #806 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 806...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5818, #subsample_inputs: 5818
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.655     |
| AbsLearnSignalNew       | 0.655     |
| AbsLearningOld          | 0.655     |
| AverageDiscountedReturn | 248       |
| AveragePhiLoss          | 47.4952   |
| AveragePolicyStd        | 0.451985  |
| AverageReturn           | 2.14e+03  |
| Entropy                 | 1.85657   |
| EnvExecTime             | 2.92      |
| ExplainedVariance       | 0.86      |
| Iteration               | 806       |
| ItrTime                 | 15.1      |
| LossAfter               | 0.328959  |
| LossBefore              | 0.35634   |
| MaxReturn               | 3.26e+03  |
| MeanKL                  | 0.0098552 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.53e+03  |
| NumTrajs                | 9         |
| Perplexity              | 6.40177   |
| PolicyExecTime          | 0.715     |
| ProcessExecTime         | 0.0823    |
| StdReturn               | 636       |
| Time                    | 1.1e+04   |
| dLoss                   | 0.0273811 |
---------------------------------------
itr #807 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 807...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5427, #subsample_inputs: 5427
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.685      |
| AbsLearnSignalNew       | 0.685      |
| AbsLearningOld          | 0.685      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 49.5691    |
| AveragePolicyStd        | 0.450971   |
| AverageReturn           | 2.03e+03   |
| Entropy                 | 1.849      |
| EnvExecTime             | 2.52       |
| ExplainedVariance       | 0.92       |
| Iteration               | 807        |
| ItrTime                 | 14.2       |
| LossAfter               | -1.29188   |
| LossBefore              | -1.26407   |
| MaxReturn               | 3.27e+03   |
| MeanKL                  | 0.00643102 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.5e+03    |
| NumTrajs                | 9          |
| Perplexity              | 6.35348    |
| PolicyExecTime          | 0.626      |
| ProcessExecTime         | 0.0736     |
| StdReturn               | 504        |
| Time                    | 1.1e+04    |
| dLoss                   | 0.0278081  |
----------------------------------------
itr #808 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 808...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5244, #subsample_inputs: 5244
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.52       |
| AbsLearnSignalNew       | 0.52       |
| AbsLearningOld          | 0.52       |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 45.6595    |
| AveragePolicyStd        | 0.450512   |
| AverageReturn           | 2.12e+03   |
| Entropy                 | 1.84584    |
| EnvExecTime             | 2.58       |
| ExplainedVariance       | 0.635      |
| Iteration               | 808        |
| ItrTime                 | 13.9       |
| LossAfter               | 0.55099    |
| LossBefore              | 0.572077   |
| MaxReturn               | 3.27e+03   |
| MeanKL                  | 0.00649207 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.07e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.33344    |
| PolicyExecTime          | 0.631      |
| ProcessExecTime         | 0.0756     |
| StdReturn               | 864        |
| Time                    | 1.11e+04   |
| dLoss                   | 0.0210875  |
----------------------------------------
itr #809 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 809...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5097, #subsample_inputs: 5097
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.619      |
| AbsLearnSignalNew       | 0.619      |
| AbsLearningOld          | 0.619      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 46.8601    |
| AveragePolicyStd        | 0.451615   |
| AverageReturn           | 2.11e+03   |
| Entropy                 | 1.85386    |
| EnvExecTime             | 2.17       |
| ExplainedVariance       | 0.56       |
| Iteration               | 809        |
| ItrTime                 | 13.1       |
| LossAfter               | 0.66157    |
| LossBefore              | 0.694263   |
| MaxReturn               | 3.11e+03   |
| MeanKL                  | 0.00640618 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 561        |
| NumTrajs                | 8          |
| Perplexity              | 6.38444    |
| PolicyExecTime          | 0.533      |
| ProcessExecTime         | 0.0643     |
| StdReturn               | 722        |
| Time                    | 1.11e+04   |
| dLoss                   | 0.0326934  |
----------------------------------------
itr #810 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 810...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5183, #subsample_inputs: 5183
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.622      |
| AbsLearnSignalNew       | 0.622      |
| AbsLearningOld          | 0.622      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 53.5301    |
| AveragePolicyStd        | 0.452168   |
| AverageReturn           | 2.16e+03   |
| Entropy                 | 1.85777    |
| EnvExecTime             | 2.29       |
| ExplainedVariance       | 0.637      |
| Iteration               | 810        |
| ItrTime                 | 13.4       |
| LossAfter               | -1.67565   |
| LossBefore              | -1.64792   |
| MaxReturn               | 3.29e+03   |
| MeanKL                  | 0.00998193 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.21e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.40945    |
| PolicyExecTime          | 0.585      |
| ProcessExecTime         | 0.0645     |
| StdReturn               | 724        |
| Time                    | 1.11e+04   |
| dLoss                   | 0.0277234  |
----------------------------------------
itr #811 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 811...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5729, #subsample_inputs: 5729
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.686      |
| AbsLearnSignalNew       | 0.686      |
| AbsLearningOld          | 0.685      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 44.9536    |
| AveragePolicyStd        | 0.452189   |
| AverageReturn           | 2.11e+03   |
| Entropy                 | 1.85743    |
| EnvExecTime             | 2.32       |
| ExplainedVariance       | 0.872      |
| Iteration               | 811        |
| ItrTime                 | 14.3       |
| LossAfter               | -2.52116   |
| LossBefore              | -2.49633   |
| MaxReturn               | 3.25e+03   |
| MeanKL                  | 0.00997873 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.34e+03   |
| NumTrajs                | 9          |
| Perplexity              | 6.40725    |
| PolicyExecTime          | 0.588      |
| ProcessExecTime         | 0.067      |
| StdReturn               | 723        |
| Time                    | 1.11e+04   |
| dLoss                   | 0.0248265  |
----------------------------------------
itr #812 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 812...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5473, #subsample_inputs: 5473
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.66       |
| AbsLearnSignalNew       | 0.66       |
| AbsLearningOld          | 0.66       |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 49.1455    |
| AveragePolicyStd        | 0.451175   |
| AverageReturn           | 2.04e+03   |
| Entropy                 | 1.8511     |
| EnvExecTime             | 2.08       |
| ExplainedVariance       | 0.861      |
| Iteration               | 812        |
| ItrTime                 | 13.6       |
| LossAfter               | -1.19421   |
| LossBefore              | -1.17039   |
| MaxReturn               | 3.32e+03   |
| MeanKL                  | 0.00650163 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.03e+03   |
| NumTrajs                | 9          |
| Perplexity              | 6.36685    |
| PolicyExecTime          | 0.531      |
| ProcessExecTime         | 0.0639     |
| StdReturn               | 679        |
| Time                    | 1.11e+04   |
| dLoss                   | 0.0238179  |
----------------------------------------
itr #813 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 813...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5592, #subsample_inputs: 5592
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.638      |
| AbsLearnSignalNew       | 0.638      |
| AbsLearningOld          | 0.638      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 48.6612    |
| AveragePolicyStd        | 0.450985   |
| AverageReturn           | 2.34e+03   |
| Entropy                 | 1.85044    |
| EnvExecTime             | 2.36       |
| ExplainedVariance       | 0.848      |
| Iteration               | 813        |
| ItrTime                 | 14.1       |
| LossAfter               | -1.5158    |
| LossBefore              | -1.4821    |
| MaxReturn               | 3.08e+03   |
| MeanKL                  | 0.00648057 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.49e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.36265    |
| PolicyExecTime          | 0.594      |
| ProcessExecTime         | 0.0688     |
| StdReturn               | 501        |
| Time                    | 1.11e+04   |
| dLoss                   | 0.0336938  |
----------------------------------------
itr #814 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 814...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5113, #subsample_inputs: 5113
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.582     |
| AbsLearnSignalNew       | 0.582     |
| AbsLearningOld          | 0.582     |
| AverageDiscountedReturn | 250       |
| AveragePhiLoss          | 38.8755   |
| AveragePolicyStd        | 0.45123   |
| AverageReturn           | 2.12e+03  |
| Entropy                 | 1.85214   |
| EnvExecTime             | 2.29      |
| ExplainedVariance       | 0.777     |
| Iteration               | 814       |
| ItrTime                 | 13.3      |
| LossAfter               | 1.27404   |
| LossBefore              | 1.29497   |
| MaxReturn               | 3.34e+03  |
| MeanKL                  | 0.0064582 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.05e+03  |
| NumTrajs                | 8         |
| Perplexity              | 6.37343   |
| PolicyExecTime          | 0.565     |
| ProcessExecTime         | 0.0659    |
| StdReturn               | 852       |
| Time                    | 1.11e+04  |
| dLoss                   | 0.0209256 |
---------------------------------------
itr #815 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 815...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5393, #subsample_inputs: 5393
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.626     |
| AbsLearnSignalNew       | 0.626     |
| AbsLearningOld          | 0.626     |
| AverageDiscountedReturn | 250       |
| AveragePhiLoss          | 57.3853   |
| AveragePolicyStd        | 0.452521  |
| AverageReturn           | 2.25e+03  |
| Entropy                 | 1.86022   |
| EnvExecTime             | 2.28      |
| ExplainedVariance       | 0.84      |
| Iteration               | 815       |
| ItrTime                 | 13.8      |
| LossAfter               | -0.543024 |
| LossBefore              | -0.507029 |
| MaxReturn               | 3.29e+03  |
| MeanKL                  | 0.0097522 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.29e+03  |
| NumTrajs                | 8         |
| Perplexity              | 6.42518   |
| PolicyExecTime          | 0.577     |
| ProcessExecTime         | 0.0647    |
| StdReturn               | 793       |
| Time                    | 1.11e+04  |
| dLoss                   | 0.0359957 |
---------------------------------------
itr #816 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 816...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5334, #subsample_inputs: 5334
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.652      |
| AbsLearnSignalNew       | 0.652      |
| AbsLearningOld          | 0.653      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 48.16      |
| AveragePolicyStd        | 0.452341   |
| AverageReturn           | 1.97e+03   |
| Entropy                 | 1.85827    |
| EnvExecTime             | 2.09       |
| ExplainedVariance       | 0.899      |
| Iteration               | 816        |
| ItrTime                 | 13.5       |
| LossAfter               | 2.78876    |
| LossBefore              | 2.81028    |
| MaxReturn               | 3.23e+03   |
| MeanKL                  | 0.00641465 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 951        |
| NumTrajs                | 9          |
| Perplexity              | 6.41261    |
| PolicyExecTime          | 0.528      |
| ProcessExecTime         | 0.0613     |
| StdReturn               | 798        |
| Time                    | 1.12e+04   |
| dLoss                   | 0.0215113  |
----------------------------------------
itr #817 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 817...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5574, #subsample_inputs: 5574
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.701      |
| AbsLearnSignalNew       | 0.701      |
| AbsLearningOld          | 0.701      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 46.9503    |
| AveragePolicyStd        | 0.4521     |
| AverageReturn           | 2.28e+03   |
| Entropy                 | 1.85632    |
| EnvExecTime             | 2.31       |
| ExplainedVariance       | 0.891      |
| Iteration               | 817        |
| ItrTime                 | 14         |
| LossAfter               | -2.15874   |
| LossBefore              | -2.13521   |
| MaxReturn               | 3.13e+03   |
| MeanKL                  | 0.00644874 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 835        |
| NumTrajs                | 8          |
| Perplexity              | 6.40015    |
| PolicyExecTime          | 0.592      |
| ProcessExecTime         | 0.0662     |
| StdReturn               | 694        |
| Time                    | 1.12e+04   |
| dLoss                   | 0.023526   |
----------------------------------------
itr #818 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 818...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5307, #subsample_inputs: 5307
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.689      |
| AbsLearnSignalNew       | 0.689      |
| AbsLearningOld          | 0.689      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 50.0682    |
| AveragePolicyStd        | 0.451708   |
| AverageReturn           | 2.23e+03   |
| Entropy                 | 1.85411    |
| EnvExecTime             | 2.16       |
| ExplainedVariance       | 0.863      |
| Iteration               | 818        |
| ItrTime                 | 13.4       |
| LossAfter               | -0.230258  |
| LossBefore              | -0.201068  |
| MaxReturn               | 3.31e+03   |
| MeanKL                  | 0.00652645 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.62e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.38601    |
| PolicyExecTime          | 0.544      |
| ProcessExecTime         | 0.0624     |
| StdReturn               | 506        |
| Time                    | 1.12e+04   |
| dLoss                   | 0.0291898  |
----------------------------------------
itr #819 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 819...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5279, #subsample_inputs: 5279
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.574      |
| AbsLearnSignalNew       | 0.574      |
| AbsLearningOld          | 0.574      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 53.8537    |
| AveragePolicyStd        | 0.451184   |
| AverageReturn           | 2.48e+03   |
| Entropy                 | 1.85011    |
| EnvExecTime             | 2.26       |
| ExplainedVariance       | 0.792      |
| Iteration               | 819        |
| ItrTime                 | 13.5       |
| LossAfter               | 0.488371   |
| LossBefore              | 0.510304   |
| MaxReturn               | 3.26e+03   |
| MeanKL                  | 0.00641416 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.33e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.36052    |
| PolicyExecTime          | 0.569      |
| ProcessExecTime         | 0.0649     |
| StdReturn               | 724        |
| Time                    | 1.12e+04   |
| dLoss                   | 0.0219333  |
----------------------------------------
itr #820 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 820...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5908, #subsample_inputs: 5908
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.567      |
| AbsLearnSignalNew       | 0.567      |
| AbsLearningOld          | 0.567      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 49.1257    |
| AveragePolicyStd        | 0.450033   |
| AverageReturn           | 2.44e+03   |
| Entropy                 | 1.84229    |
| EnvExecTime             | 2.45       |
| ExplainedVariance       | 0.875      |
| Iteration               | 820        |
| ItrTime                 | 14.7       |
| LossAfter               | -1.19461   |
| LossBefore              | -1.15884   |
| MaxReturn               | 3.21e+03   |
| MeanKL                  | 0.00997705 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.73e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.31098    |
| PolicyExecTime          | 0.621      |
| ProcessExecTime         | 0.071      |
| StdReturn               | 520        |
| Time                    | 1.12e+04   |
| dLoss                   | 0.035773   |
----------------------------------------
itr #821 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 821...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5826, #subsample_inputs: 5826
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.611      |
| AbsLearnSignalNew       | 0.611      |
| AbsLearningOld          | 0.611      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 50.3046    |
| AveragePolicyStd        | 0.45018    |
| AverageReturn           | 2.4e+03    |
| Entropy                 | 1.84344    |
| EnvExecTime             | 2.52       |
| ExplainedVariance       | 0.833      |
| Iteration               | 821        |
| ItrTime                 | 14.6       |
| LossAfter               | -0.196755  |
| LossBefore              | -0.159729  |
| MaxReturn               | 3.27e+03   |
| MeanKL                  | 0.00645139 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.24e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.31825    |
| PolicyExecTime          | 0.644      |
| ProcessExecTime         | 0.0708     |
| StdReturn               | 662        |
| Time                    | 1.12e+04   |
| dLoss                   | 0.0370253  |
----------------------------------------
itr #822 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 822...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5215, #subsample_inputs: 5215
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.674      |
| AbsLearnSignalNew       | 0.674      |
| AbsLearningOld          | 0.673      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 47.8698    |
| AveragePolicyStd        | 0.449537   |
| AverageReturn           | 2.48e+03   |
| Entropy                 | 1.83879    |
| EnvExecTime             | 1.97       |
| ExplainedVariance       | 0.899      |
| Iteration               | 822        |
| ItrTime                 | 13         |
| LossAfter               | -0.151135  |
| LossBefore              | -0.128972  |
| MaxReturn               | 3.26e+03   |
| MeanKL                  | 0.00640689 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 960        |
| NumTrajs                | 7          |
| Perplexity              | 6.2889     |
| PolicyExecTime          | 0.504      |
| ProcessExecTime         | 0.0579     |
| StdReturn               | 743        |
| Time                    | 1.12e+04   |
| dLoss                   | 0.0221629  |
----------------------------------------
itr #823 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 823...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5337, #subsample_inputs: 5337
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.642      |
| AbsLearnSignalNew       | 0.642      |
| AbsLearningOld          | 0.642      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 51.3567    |
| AveragePolicyStd        | 0.449082   |
| AverageReturn           | 2.51e+03   |
| Entropy                 | 1.83617    |
| EnvExecTime             | 2.48       |
| ExplainedVariance       | 0.879      |
| Iteration               | 823        |
| ItrTime                 | 14         |
| LossAfter               | -0.865851  |
| LossBefore              | -0.830084  |
| MaxReturn               | 3.33e+03   |
| MeanKL                  | 0.00989795 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.22e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.27245    |
| PolicyExecTime          | 0.638      |
| ProcessExecTime         | 0.0705     |
| StdReturn               | 733        |
| Time                    | 1.13e+04   |
| dLoss                   | 0.0357665  |
----------------------------------------
itr #824 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 824...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5773, #subsample_inputs: 5773
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.684      |
| AbsLearnSignalNew       | 0.684      |
| AbsLearningOld          | 0.684      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 52.2705    |
| AveragePolicyStd        | 0.448811   |
| AverageReturn           | 2.35e+03   |
| Entropy                 | 1.8343     |
| EnvExecTime             | 2.24       |
| ExplainedVariance       | 0.859      |
| Iteration               | 824        |
| ItrTime                 | 14.3       |
| LossAfter               | 0.786276   |
| LossBefore              | 0.811567   |
| MaxReturn               | 3.27e+03   |
| MeanKL                  | 0.00996798 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.11e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.26077    |
| PolicyExecTime          | 0.579      |
| ProcessExecTime         | 0.0671     |
| StdReturn               | 903        |
| Time                    | 1.13e+04   |
| dLoss                   | 0.0252912  |
----------------------------------------
itr #825 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 825...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5006, #subsample_inputs: 5006
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.569      |
| AbsLearnSignalNew       | 0.569      |
| AbsLearningOld          | 0.569      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 47.1124    |
| AveragePolicyStd        | 0.447481   |
| AverageReturn           | 2.1e+03    |
| Entropy                 | 1.82594    |
| EnvExecTime             | 2.22       |
| ExplainedVariance       | 0.858      |
| Iteration               | 825        |
| ItrTime                 | 13         |
| LossAfter               | -1.14849   |
| LossBefore              | -1.1117    |
| MaxReturn               | 3.25e+03   |
| MeanKL                  | 0.00991037 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.15e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.20861    |
| PolicyExecTime          | 0.553      |
| ProcessExecTime         | 0.0634     |
| StdReturn               | 777        |
| Time                    | 1.13e+04   |
| dLoss                   | 0.0367962  |
----------------------------------------
itr #826 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 826...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5282, #subsample_inputs: 5282
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.601      |
| AbsLearnSignalNew       | 0.601      |
| AbsLearningOld          | 0.601      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 51.3366    |
| AveragePolicyStd        | 0.448323   |
| AverageReturn           | 2.86e+03   |
| Entropy                 | 1.83162    |
| EnvExecTime             | 2.31       |
| ExplainedVariance       | 0.789      |
| Iteration               | 826        |
| ItrTime                 | 13.7       |
| LossAfter               | 1.97642    |
| LossBefore              | 2.0125     |
| MaxReturn               | 3.24e+03   |
| MeanKL                  | 0.00641236 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.55e+03   |
| NumTrajs                | 6          |
| Perplexity              | 6.24398    |
| PolicyExecTime          | 0.588      |
| ProcessExecTime         | 0.0654     |
| StdReturn               | 601        |
| Time                    | 1.13e+04   |
| dLoss                   | 0.0360844  |
----------------------------------------
itr #827 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 827...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5668, #subsample_inputs: 5668
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.251      |
| AbsLearnSignalNew       | 0.251      |
| AbsLearningOld          | 0.251      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 70.6292    |
| AveragePolicyStd        | 0.447879   |
| AverageReturn           | 2.31e+03   |
| Entropy                 | 1.82843    |
| EnvExecTime             | 2.71       |
| ExplainedVariance       | 0.185      |
| Iteration               | 827        |
| ItrTime                 | 14.6       |
| LossAfter               | 3.22066    |
| LossBefore              | 3.26918    |
| MaxReturn               | 3.21e+03   |
| MeanKL                  | 0.00987218 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 612        |
| NumTrajs                | 8          |
| Perplexity              | 6.22411    |
| PolicyExecTime          | 0.683      |
| ProcessExecTime         | 0.0752     |
| StdReturn               | 825        |
| Time                    | 1.13e+04   |
| dLoss                   | 0.0485191  |
----------------------------------------
itr #828 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 828...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5685, #subsample_inputs: 5685
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.565      |
| AbsLearnSignalNew       | 0.565      |
| AbsLearningOld          | 0.566      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 43.9661    |
| AveragePolicyStd        | 0.447417   |
| AverageReturn           | 2.38e+03   |
| Entropy                 | 1.82432    |
| EnvExecTime             | 2.37       |
| ExplainedVariance       | 0.781      |
| Iteration               | 828        |
| ItrTime                 | 14.3       |
| LossAfter               | 0.743105   |
| LossBefore              | 0.77087    |
| MaxReturn               | 3.24e+03   |
| MeanKL                  | 0.00643918 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.47e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.19855    |
| PolicyExecTime          | 0.605      |
| ProcessExecTime         | 0.0682     |
| StdReturn               | 663        |
| Time                    | 1.13e+04   |
| dLoss                   | 0.0277643  |
----------------------------------------
itr #829 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 829...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5100, #subsample_inputs: 5100
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.49       |
| AbsLearnSignalNew       | 0.49       |
| AbsLearningOld          | 0.49       |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 55.5988    |
| AveragePolicyStd        | 0.447193   |
| AverageReturn           | 2.69e+03   |
| Entropy                 | 1.82281    |
| EnvExecTime             | 2.22       |
| ExplainedVariance       | 0.467      |
| Iteration               | 829        |
| ItrTime                 | 13.3       |
| LossAfter               | 0.626361   |
| LossBefore              | 0.648369   |
| MaxReturn               | 3.19e+03   |
| MeanKL                  | 0.00984073 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.56e+03   |
| NumTrajs                | 6          |
| Perplexity              | 6.18921    |
| PolicyExecTime          | 0.575      |
| ProcessExecTime         | 0.0628     |
| StdReturn               | 619        |
| Time                    | 1.13e+04   |
| dLoss                   | 0.0220073  |
----------------------------------------
itr #830 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 830...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5000, #subsample_inputs: 5000
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.708      |
| AbsLearnSignalNew       | 0.708      |
| AbsLearningOld          | 0.708      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 49.2021    |
| AveragePolicyStd        | 0.447379   |
| AverageReturn           | 3.1e+03    |
| Entropy                 | 1.82343    |
| EnvExecTime             | 1.63       |
| ExplainedVariance       | 0.922      |
| Iteration               | 830        |
| ItrTime                 | 12.3       |
| LossAfter               | -1.14132   |
| LossBefore              | -1.12037   |
| MaxReturn               | 3.21e+03   |
| MeanKL                  | 0.00650381 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 2.9e+03    |
| NumTrajs                | 5          |
| Perplexity              | 6.19304    |
| PolicyExecTime          | 0.413      |
| ProcessExecTime         | 0.0518     |
| StdReturn               | 104        |
| Time                    | 1.14e+04   |
| dLoss                   | 0.0209441  |
----------------------------------------
itr #831 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 831...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5432, #subsample_inputs: 5432
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.0951     |
| AbsLearnSignalNew       | 0.0951     |
| AbsLearningOld          | 0.0951     |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 27.8965    |
| AveragePolicyStd        | 0.446786   |
| AverageReturn           | 2.8e+03    |
| Entropy                 | 1.81849    |
| EnvExecTime             | 2.23       |
| ExplainedVariance       | -16.4      |
| Iteration               | 831        |
| ItrTime                 | 13.8       |
| LossAfter               | -0.848113  |
| LossBefore              | -0.808657  |
| MaxReturn               | 3.18e+03   |
| MeanKL                  | 0.00650544 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.43e+03   |
| NumTrajs                | 6          |
| Perplexity              | 6.16256    |
| PolicyExecTime          | 0.569      |
| ProcessExecTime         | 0.0656     |
| StdReturn               | 614        |
| Time                    | 1.14e+04   |
| dLoss                   | 0.039456   |
----------------------------------------
itr #832 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 832...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5547, #subsample_inputs: 5547
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.666      |
| AbsLearnSignalNew       | 0.666      |
| AbsLearningOld          | 0.666      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 57.0089    |
| AveragePolicyStd        | 0.447671   |
| AverageReturn           | 2.85e+03   |
| Entropy                 | 1.82434    |
| EnvExecTime             | 2.47       |
| ExplainedVariance       | 0.908      |
| Iteration               | 832        |
| ItrTime                 | 14.2       |
| LossAfter               | 0.176944   |
| LossBefore              | 0.223191   |
| MaxReturn               | 3.09e+03   |
| MeanKL                  | 0.00990824 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 2.47e+03   |
| NumTrajs                | 6          |
| Perplexity              | 6.1987     |
| PolicyExecTime          | 0.63       |
| ProcessExecTime         | 0.0706     |
| StdReturn               | 251        |
| Time                    | 1.14e+04   |
| dLoss                   | 0.0462478  |
----------------------------------------
itr #833 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 833...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5164, #subsample_inputs: 5164
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.63       |
| AbsLearnSignalNew       | 0.63       |
| AbsLearningOld          | 0.63       |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 44.9379    |
| AveragePolicyStd        | 0.448194   |
| AverageReturn           | 2.76e+03   |
| Entropy                 | 1.82805    |
| EnvExecTime             | 1.92       |
| ExplainedVariance       | 0.869      |
| Iteration               | 833        |
| ItrTime                 | 12.9       |
| LossAfter               | -1.55088   |
| LossBefore              | -1.51473   |
| MaxReturn               | 3.24e+03   |
| MeanKL                  | 0.00973118 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.85e+03   |
| NumTrajs                | 6          |
| Perplexity              | 6.22175    |
| PolicyExecTime          | 0.48       |
| ProcessExecTime         | 0.0591     |
| StdReturn               | 603        |
| Time                    | 1.14e+04   |
| dLoss                   | 0.0361494  |
----------------------------------------
itr #834 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 834...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5119, #subsample_inputs: 5119
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.525     |
| AbsLearnSignalNew       | 0.525     |
| AbsLearningOld          | 0.525     |
| AverageDiscountedReturn | 244       |
| AveragePhiLoss          | 41.2634   |
| AveragePolicyStd        | 0.449649  |
| AverageReturn           | 2.75e+03  |
| Entropy                 | 1.83952   |
| EnvExecTime             | 2.29      |
| ExplainedVariance       | 0.686     |
| Iteration               | 834       |
| ItrTime                 | 13.3      |
| LossAfter               | -0.236314 |
| LossBefore              | -0.20561  |
| MaxReturn               | 3.3e+03   |
| MeanKL                  | 0.0099886 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.64e+03  |
| NumTrajs                | 6         |
| Perplexity              | 6.29351   |
| PolicyExecTime          | 0.584     |
| ProcessExecTime         | 0.0636    |
| StdReturn               | 552       |
| Time                    | 1.14e+04  |
| dLoss                   | 0.030704  |
---------------------------------------
itr #835 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 835...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5486, #subsample_inputs: 5486
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.58       |
| AbsLearnSignalNew       | 0.58       |
| AbsLearningOld          | 0.58       |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 51.1165    |
| AveragePolicyStd        | 0.449677   |
| AverageReturn           | 2.54e+03   |
| Entropy                 | 1.84024    |
| EnvExecTime             | 2.08       |
| ExplainedVariance       | 0.854      |
| Iteration               | 835        |
| ItrTime                 | 13.6       |
| LossAfter               | 2.63506    |
| LossBefore              | 2.66195    |
| MaxReturn               | 3.19e+03   |
| MeanKL                  | 0.00650963 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.22e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.29807    |
| PolicyExecTime          | 0.536      |
| ProcessExecTime         | 0.0615     |
| StdReturn               | 819        |
| Time                    | 1.14e+04   |
| dLoss                   | 0.0268898  |
----------------------------------------
itr #836 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 836...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5530, #subsample_inputs: 5530
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.722      |
| AbsLearnSignalNew       | 0.722      |
| AbsLearningOld          | 0.722      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 48.1342    |
| AveragePolicyStd        | 0.448908   |
| AverageReturn           | 2.24e+03   |
| Entropy                 | 1.83495    |
| EnvExecTime             | 2.35       |
| ExplainedVariance       | 0.844      |
| Iteration               | 836        |
| ItrTime                 | 13.9       |
| LossAfter               | 0.770638   |
| LossBefore              | 0.802312   |
| MaxReturn               | 3.23e+03   |
| MeanKL                  | 0.00985119 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.21e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.26484    |
| PolicyExecTime          | 0.608      |
| ProcessExecTime         | 0.0678     |
| StdReturn               | 755        |
| Time                    | 1.14e+04   |
| dLoss                   | 0.0316745  |
----------------------------------------
itr #837 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 837...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5568, #subsample_inputs: 5568
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.54       |
| AbsLearnSignalNew       | 0.54       |
| AbsLearningOld          | 0.54       |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 55.3774    |
| AveragePolicyStd        | 0.449123   |
| AverageReturn           | 2.07e+03   |
| Entropy                 | 1.83568    |
| EnvExecTime             | 2.29       |
| ExplainedVariance       | 0.746      |
| Iteration               | 837        |
| ItrTime                 | 14         |
| LossAfter               | -2.90073   |
| LossBefore              | -2.86514   |
| MaxReturn               | 3.32e+03   |
| MeanKL                  | 0.00642146 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 690        |
| NumTrajs                | 9          |
| Perplexity              | 6.26938    |
| PolicyExecTime          | 0.588      |
| ProcessExecTime         | 0.0658     |
| StdReturn               | 962        |
| Time                    | 1.15e+04   |
| dLoss                   | 0.0355849  |
----------------------------------------
itr #838 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 838...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5788, #subsample_inputs: 5788
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.694      |
| AbsLearnSignalNew       | 0.694      |
| AbsLearningOld          | 0.694      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 52.4794    |
| AveragePolicyStd        | 0.450334   |
| AverageReturn           | 2.39e+03   |
| Entropy                 | 1.84261    |
| EnvExecTime             | 2.29       |
| ExplainedVariance       | 0.85       |
| Iteration               | 838        |
| ItrTime                 | 14.3       |
| LossAfter               | -0.623814  |
| LossBefore              | -0.588974  |
| MaxReturn               | 3.24e+03   |
| MeanKL                  | 0.00991572 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.06e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.31299    |
| PolicyExecTime          | 0.581      |
| ProcessExecTime         | 0.0662     |
| StdReturn               | 746        |
| Time                    | 1.15e+04   |
| dLoss                   | 0.03484    |
----------------------------------------
itr #839 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 839...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5185, #subsample_inputs: 5185
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.621      |
| AbsLearnSignalNew       | 0.621      |
| AbsLearningOld          | 0.621      |
| AverageDiscountedReturn | 254        |
| AveragePhiLoss          | 51.0229    |
| AveragePolicyStd        | 0.451183   |
| AverageReturn           | 2.1e+03    |
| Entropy                 | 1.84905    |
| EnvExecTime             | 2.13       |
| ExplainedVariance       | 0.85       |
| Iteration               | 839        |
| ItrTime                 | 13.3       |
| LossAfter               | 1.60892    |
| LossBefore              | 1.64203    |
| MaxReturn               | 3.23e+03   |
| MeanKL                  | 0.00988147 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 925        |
| NumTrajs                | 8          |
| Perplexity              | 6.35378    |
| PolicyExecTime          | 0.543      |
| ProcessExecTime         | 0.0616     |
| StdReturn               | 1.09e+03   |
| Time                    | 1.15e+04   |
| dLoss                   | 0.0331171  |
----------------------------------------
itr #840 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 840...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5537, #subsample_inputs: 5537
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.223      |
| AbsLearnSignalNew       | 0.223      |
| AbsLearningOld          | 0.223      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 30.7252    |
| AveragePolicyStd        | 0.45131    |
| AverageReturn           | 2.23e+03   |
| Entropy                 | 1.85015    |
| EnvExecTime             | 2.23       |
| ExplainedVariance       | -0.0453    |
| Iteration               | 840        |
| ItrTime                 | 13.9       |
| LossAfter               | 0.512649   |
| LossBefore              | 0.529165   |
| MaxReturn               | 3.16e+03   |
| MeanKL                  | 0.00651822 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 818        |
| NumTrajs                | 8          |
| Perplexity              | 6.36079    |
| PolicyExecTime          | 0.567      |
| ProcessExecTime         | 0.0638     |
| StdReturn               | 818        |
| Time                    | 1.15e+04   |
| dLoss                   | 0.0165153  |
----------------------------------------
itr #841 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 841...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5167, #subsample_inputs: 5167
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.591      |
| AbsLearnSignalNew       | 0.591      |
| AbsLearningOld          | 0.591      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 54.7203    |
| AveragePolicyStd        | 0.452213   |
| AverageReturn           | 2.32e+03   |
| Entropy                 | 1.85674    |
| EnvExecTime             | 1.97       |
| ExplainedVariance       | 0.643      |
| Iteration               | 841        |
| ItrTime                 | 13         |
| LossAfter               | 1.01695    |
| LossBefore              | 1.06022    |
| MaxReturn               | 3.33e+03   |
| MeanKL                  | 0.00642113 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 643        |
| NumTrajs                | 7          |
| Perplexity              | 6.40281    |
| PolicyExecTime          | 0.494      |
| ProcessExecTime         | 0.0586     |
| StdReturn               | 1.04e+03   |
| Time                    | 1.15e+04   |
| dLoss                   | 0.0432682  |
----------------------------------------
itr #842 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 842...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5541, #subsample_inputs: 5541
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.584      |
| AbsLearnSignalNew       | 0.584      |
| AbsLearningOld          | 0.584      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 53.7746    |
| AveragePolicyStd        | 0.452272   |
| AverageReturn           | 2.54e+03   |
| Entropy                 | 1.85736    |
| EnvExecTime             | 2.69       |
| ExplainedVariance       | 0.825      |
| Iteration               | 842        |
| ItrTime                 | 14.4       |
| LossAfter               | -0.460422  |
| LossBefore              | -0.436933  |
| MaxReturn               | 3.17e+03   |
| MeanKL                  | 0.00641461 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.34e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.4068     |
| PolicyExecTime          | 0.67       |
| ProcessExecTime         | 0.0763     |
| StdReturn               | 656        |
| Time                    | 1.15e+04   |
| dLoss                   | 0.0234883  |
----------------------------------------
itr #843 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 843...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5377, #subsample_inputs: 5377
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.65       |
| AbsLearnSignalNew       | 0.65       |
| AbsLearningOld          | 0.65       |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 61.676     |
| AveragePolicyStd        | 0.451214   |
| AverageReturn           | 1.8e+03    |
| Entropy                 | 1.84971    |
| EnvExecTime             | 2.12       |
| ExplainedVariance       | 0.823      |
| Iteration               | 843        |
| ItrTime                 | 13.6       |
| LossAfter               | 3.22284    |
| LossBefore              | 3.26986    |
| MaxReturn               | 2.87e+03   |
| MeanKL                  | 0.00964372 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 871        |
| NumTrajs                | 10         |
| Perplexity              | 6.35799    |
| PolicyExecTime          | 0.545      |
| ProcessExecTime         | 0.0617     |
| StdReturn               | 731        |
| Time                    | 1.15e+04   |
| dLoss                   | 0.0470173  |
----------------------------------------
itr #844 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 844...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5732, #subsample_inputs: 5732
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.608      |
| AbsLearnSignalNew       | 0.608      |
| AbsLearningOld          | 0.608      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 45.7801    |
| AveragePolicyStd        | 0.44986    |
| AverageReturn           | 2.1e+03    |
| Entropy                 | 1.84117    |
| EnvExecTime             | 2.25       |
| ExplainedVariance       | 0.758      |
| Iteration               | 844        |
| ItrTime                 | 14.1       |
| LossAfter               | 1.6664     |
| LossBefore              | 1.69504    |
| MaxReturn               | 3.32e+03   |
| MeanKL                  | 0.00983836 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 897        |
| NumTrajs                | 9          |
| Perplexity              | 6.30393    |
| PolicyExecTime          | 0.567      |
| ProcessExecTime         | 0.0659     |
| StdReturn               | 818        |
| Time                    | 1.15e+04   |
| dLoss                   | 0.0286354  |
----------------------------------------
itr #845 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 845...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5765, #subsample_inputs: 5765
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.703      |
| AbsLearnSignalNew       | 0.703      |
| AbsLearningOld          | 0.703      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 52.0659    |
| AveragePolicyStd        | 0.447981   |
| AverageReturn           | 2.36e+03   |
| Entropy                 | 1.82937    |
| EnvExecTime             | 2.43       |
| ExplainedVariance       | 0.823      |
| Iteration               | 845        |
| ItrTime                 | 14.5       |
| LossAfter               | 2.92216    |
| LossBefore              | 2.95239    |
| MaxReturn               | 3.01e+03   |
| MeanKL                  | 0.00997639 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.64e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.22998    |
| PolicyExecTime          | 0.616      |
| ProcessExecTime         | 0.0709     |
| StdReturn               | 538        |
| Time                    | 1.16e+04   |
| dLoss                   | 0.0302336  |
----------------------------------------
itr #846 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 846...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5116, #subsample_inputs: 5116
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.624      |
| AbsLearnSignalNew       | 0.624      |
| AbsLearningOld          | 0.624      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 41.2675    |
| AveragePolicyStd        | 0.447462   |
| AverageReturn           | 2.36e+03   |
| Entropy                 | 1.82659    |
| EnvExecTime             | 2.09       |
| ExplainedVariance       | 0.822      |
| Iteration               | 846        |
| ItrTime                 | 13         |
| LossAfter               | 3.53442    |
| LossBefore              | 3.56592    |
| MaxReturn               | 3.06e+03   |
| MeanKL                  | 0.00644704 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.38e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.21266    |
| PolicyExecTime          | 0.535      |
| ProcessExecTime         | 0.0593     |
| StdReturn               | 643        |
| Time                    | 1.16e+04   |
| dLoss                   | 0.0314989  |
----------------------------------------
itr #847 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 847...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5419, #subsample_inputs: 5419
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.558      |
| AbsLearnSignalNew       | 0.558      |
| AbsLearningOld          | 0.558      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 51.622     |
| AveragePolicyStd        | 0.4458     |
| AverageReturn           | 2.5e+03    |
| Entropy                 | 1.81545    |
| EnvExecTime             | 2.13       |
| ExplainedVariance       | 0.753      |
| Iteration               | 847        |
| ItrTime                 | 13.7       |
| LossAfter               | 0.794248   |
| LossBefore              | 0.822547   |
| MaxReturn               | 3.24e+03   |
| MeanKL                  | 0.00996395 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.07e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.14381    |
| PolicyExecTime          | 0.539      |
| ProcessExecTime         | 0.0626     |
| StdReturn               | 769        |
| Time                    | 1.16e+04   |
| dLoss                   | 0.0282987  |
----------------------------------------
itr #848 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 848...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5359, #subsample_inputs: 5359
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.656      |
| AbsLearnSignalNew       | 0.656      |
| AbsLearningOld          | 0.656      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 48.0609    |
| AveragePolicyStd        | 0.444812   |
| AverageReturn           | 2.48e+03   |
| Entropy                 | 1.80959    |
| EnvExecTime             | 2.45       |
| ExplainedVariance       | 0.856      |
| Iteration               | 848        |
| ItrTime                 | 14         |
| LossAfter               | 1.06104    |
| LossBefore              | 1.09862    |
| MaxReturn               | 3e+03      |
| MeanKL                  | 0.00999475 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.8e+03    |
| NumTrajs                | 7          |
| Perplexity              | 6.10795    |
| PolicyExecTime          | 0.619      |
| ProcessExecTime         | 0.0689     |
| StdReturn               | 344        |
| Time                    | 1.16e+04   |
| dLoss                   | 0.0375851  |
----------------------------------------
itr #849 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 849...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5308, #subsample_inputs: 5308
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.582      |
| AbsLearnSignalNew       | 0.582      |
| AbsLearningOld          | 0.582      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 43.7602    |
| AveragePolicyStd        | 0.44693    |
| AverageReturn           | 2.46e+03   |
| Entropy                 | 1.82421    |
| EnvExecTime             | 2.39       |
| ExplainedVariance       | 0.795      |
| Iteration               | 849        |
| ItrTime                 | 13.7       |
| LossAfter               | 2.8328     |
| LossBefore              | 2.86285    |
| MaxReturn               | 3.2e+03    |
| MeanKL                  | 0.00991249 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.58e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.19787    |
| PolicyExecTime          | 0.595      |
| ProcessExecTime         | 0.0671     |
| StdReturn               | 584        |
| Time                    | 1.16e+04   |
| dLoss                   | 0.0300479  |
----------------------------------------
itr #850 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 850...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5571, #subsample_inputs: 5571
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.563      |
| AbsLearnSignalNew       | 0.563      |
| AbsLearningOld          | 0.563      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 57.5146    |
| AveragePolicyStd        | 0.446439   |
| AverageReturn           | 2.26e+03   |
| Entropy                 | 1.82047    |
| EnvExecTime             | 2.26       |
| ExplainedVariance       | 0.684      |
| Iteration               | 850        |
| ItrTime                 | 13.9       |
| LossAfter               | 3.40322    |
| LossBefore              | 3.44121    |
| MaxReturn               | 3.19e+03   |
| MeanKL                  | 0.00998525 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 890        |
| NumTrajs                | 8          |
| Perplexity              | 6.17477    |
| PolicyExecTime          | 0.582      |
| ProcessExecTime         | 0.0641     |
| StdReturn               | 716        |
| Time                    | 1.16e+04   |
| dLoss                   | 0.0379958  |
----------------------------------------
itr #851 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 851...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5088, #subsample_inputs: 5088
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.641      |
| AbsLearnSignalNew       | 0.641      |
| AbsLearningOld          | 0.642      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 46.1638    |
| AveragePolicyStd        | 0.445714   |
| AverageReturn           | 2.12e+03   |
| Entropy                 | 1.81724    |
| EnvExecTime             | 2.33       |
| ExplainedVariance       | 0.848      |
| Iteration               | 851        |
| ItrTime                 | 13.3       |
| LossAfter               | -0.655379  |
| LossBefore              | -0.626209  |
| MaxReturn               | 3.01e+03   |
| MeanKL                  | 0.00651011 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.65e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.15485    |
| PolicyExecTime          | 0.589      |
| ProcessExecTime         | 0.0652     |
| StdReturn               | 469        |
| Time                    | 1.16e+04   |
| dLoss                   | 0.0291696  |
----------------------------------------
itr #852 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 852...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5231, #subsample_inputs: 5231
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.558     |
| AbsLearnSignalNew       | 0.558     |
| AbsLearningOld          | 0.557     |
| AverageDiscountedReturn | 248       |
| AveragePhiLoss          | 56.2235   |
| AveragePolicyStd        | 0.44488   |
| AverageReturn           | 2.16e+03  |
| Entropy                 | 1.81139   |
| EnvExecTime             | 2.33      |
| ExplainedVariance       | 0.781     |
| Iteration               | 852       |
| ItrTime                 | 13.5      |
| LossAfter               | -0.398229 |
| LossBefore              | -0.37191  |
| MaxReturn               | 3.38e+03  |
| MeanKL                  | 0.0099872 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 740       |
| NumTrajs                | 8         |
| Perplexity              | 6.11895   |
| PolicyExecTime          | 0.585     |
| ProcessExecTime         | 0.0682    |
| StdReturn               | 922       |
| Time                    | 1.17e+04  |
| dLoss                   | 0.0263186 |
---------------------------------------
itr #853 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 853...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5007, #subsample_inputs: 5007
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.67       |
| AbsLearnSignalNew       | 0.67       |
| AbsLearningOld          | 0.67       |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 58.3361    |
| AveragePolicyStd        | 0.443533   |
| AverageReturn           | 2.31e+03   |
| Entropy                 | 1.80243    |
| EnvExecTime             | 2.22       |
| ExplainedVariance       | 0.844      |
| Iteration               | 853        |
| ItrTime                 | 13.1       |
| LossAfter               | 0.230677   |
| LossBefore              | 0.25577    |
| MaxReturn               | 3.18e+03   |
| MeanKL                  | 0.00645965 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.17e+03   |
| NumTrajs                | 7          |
| Perplexity              | 6.06436    |
| PolicyExecTime          | 0.559      |
| ProcessExecTime         | 0.0654     |
| StdReturn               | 604        |
| Time                    | 1.17e+04   |
| dLoss                   | 0.0250929  |
----------------------------------------
itr #854 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 854...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5616, #subsample_inputs: 5616
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.687      |
| AbsLearnSignalNew       | 0.687      |
| AbsLearningOld          | 0.687      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 48.0172    |
| AveragePolicyStd        | 0.442484   |
| AverageReturn           | 1.86e+03   |
| Entropy                 | 1.79625    |
| EnvExecTime             | 2.02       |
| ExplainedVariance       | 0.868      |
| Iteration               | 854        |
| ItrTime                 | 13.7       |
| LossAfter               | -0.276697  |
| LossBefore              | -0.249766  |
| MaxReturn               | 2.54e+03   |
| MeanKL                  | 0.00641422 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 941        |
| NumTrajs                | 10         |
| Perplexity              | 6.02698    |
| PolicyExecTime          | 0.515      |
| ProcessExecTime         | 0.0612     |
| StdReturn               | 426        |
| Time                    | 1.17e+04   |
| dLoss                   | 0.0269312  |
----------------------------------------
itr #855 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 855...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5386, #subsample_inputs: 5386
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.539      |
| AbsLearnSignalNew       | 0.539      |
| AbsLearningOld          | 0.539      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 55.9071    |
| AveragePolicyStd        | 0.44296    |
| AverageReturn           | 2e+03      |
| Entropy                 | 1.79939    |
| EnvExecTime             | 2.13       |
| ExplainedVariance       | 0.78       |
| Iteration               | 855        |
| ItrTime                 | 13.6       |
| LossAfter               | 1.86364    |
| LossBefore              | 1.88554    |
| MaxReturn               | 3.23e+03   |
| MeanKL                  | 0.00640276 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.59e+03   |
| NumTrajs                | 9          |
| Perplexity              | 6.04595    |
| PolicyExecTime          | 0.536      |
| ProcessExecTime         | 0.0629     |
| StdReturn               | 503        |
| Time                    | 1.17e+04   |
| dLoss                   | 0.0218946  |
----------------------------------------
itr #856 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 856...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5068, #subsample_inputs: 5068
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.641      |
| AbsLearnSignalNew       | 0.641      |
| AbsLearningOld          | 0.641      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 56.096     |
| AveragePolicyStd        | 0.443345   |
| AverageReturn           | 2.09e+03   |
| Entropy                 | 1.80192    |
| EnvExecTime             | 2.34       |
| ExplainedVariance       | 0.83       |
| Iteration               | 856        |
| ItrTime                 | 13.3       |
| LossAfter               | 0.600679   |
| LossBefore              | 0.634595   |
| MaxReturn               | 2.91e+03   |
| MeanKL                  | 0.00651743 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.33e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.06125    |
| PolicyExecTime          | 0.586      |
| ProcessExecTime         | 0.0668     |
| StdReturn               | 467        |
| Time                    | 1.17e+04   |
| dLoss                   | 0.0339158  |
----------------------------------------
itr #857 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 857...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5464, #subsample_inputs: 5464
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.587      |
| AbsLearnSignalNew       | 0.587      |
| AbsLearningOld          | 0.587      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 48.8399    |
| AveragePolicyStd        | 0.442983   |
| AverageReturn           | 2e+03      |
| Entropy                 | 1.79898    |
| EnvExecTime             | 2.2        |
| ExplainedVariance       | 0.797      |
| Iteration               | 857        |
| ItrTime                 | 13.7       |
| LossAfter               | -0.564995  |
| LossBefore              | -0.535132  |
| MaxReturn               | 3.25e+03   |
| MeanKL                  | 0.00998992 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 832        |
| NumTrajs                | 9          |
| Perplexity              | 6.0435     |
| PolicyExecTime          | 0.556      |
| ProcessExecTime         | 0.0651     |
| StdReturn               | 750        |
| Time                    | 1.17e+04   |
| dLoss                   | 0.0298622  |
----------------------------------------
itr #858 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 858...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5411, #subsample_inputs: 5411
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.68       |
| AbsLearnSignalNew       | 0.68       |
| AbsLearningOld          | 0.68       |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 49.2107    |
| AveragePolicyStd        | 0.443662   |
| AverageReturn           | 1.99e+03   |
| Entropy                 | 1.80388    |
| EnvExecTime             | 2.38       |
| ExplainedVariance       | 0.839      |
| Iteration               | 858        |
| ItrTime                 | 14         |
| LossAfter               | 0.846901   |
| LossBefore              | 0.870198   |
| MaxReturn               | 3.28e+03   |
| MeanKL                  | 0.00640892 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 954        |
| NumTrajs                | 9          |
| Perplexity              | 6.07317    |
| PolicyExecTime          | 0.607      |
| ProcessExecTime         | 0.0667     |
| StdReturn               | 664        |
| Time                    | 1.17e+04   |
| dLoss                   | 0.0232965  |
----------------------------------------
itr #859 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 859...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5585, #subsample_inputs: 5585
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.499      |
| AbsLearnSignalNew       | 0.499      |
| AbsLearningOld          | 0.499      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 44.6603    |
| AveragePolicyStd        | 0.44484    |
| AverageReturn           | 2.32e+03   |
| Entropy                 | 1.81159    |
| EnvExecTime             | 2.58       |
| ExplainedVariance       | 0.763      |
| Iteration               | 859        |
| ItrTime                 | 14.3       |
| LossAfter               | 0.0334996  |
| LossBefore              | 0.0596588  |
| MaxReturn               | 3.24e+03   |
| MeanKL                  | 0.00992518 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.69e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.12018    |
| PolicyExecTime          | 0.658      |
| ProcessExecTime         | 0.0716     |
| StdReturn               | 490        |
| Time                    | 1.18e+04   |
| dLoss                   | 0.0261592  |
----------------------------------------
itr #860 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 860...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5370, #subsample_inputs: 5370
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.712      |
| AbsLearnSignalNew       | 0.712      |
| AbsLearningOld          | 0.712      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 49.1482    |
| AveragePolicyStd        | 0.446519   |
| AverageReturn           | 2.23e+03   |
| Entropy                 | 1.82049    |
| EnvExecTime             | 2.38       |
| ExplainedVariance       | 0.871      |
| Iteration               | 860        |
| ItrTime                 | 13.9       |
| LossAfter               | -0.93773   |
| LossBefore              | -0.908832  |
| MaxReturn               | 3.31e+03   |
| MeanKL                  | 0.00644489 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.28e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.1749     |
| PolicyExecTime          | 0.605      |
| ProcessExecTime         | 0.0674     |
| StdReturn               | 626        |
| Time                    | 1.18e+04   |
| dLoss                   | 0.0288984  |
----------------------------------------
itr #861 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 861...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5145, #subsample_inputs: 5145
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.697      |
| AbsLearnSignalNew       | 0.697      |
| AbsLearningOld          | 0.697      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 49.9578    |
| AveragePolicyStd        | 0.446737   |
| AverageReturn           | 1.9e+03    |
| Entropy                 | 1.82277    |
| EnvExecTime             | 2.3        |
| ExplainedVariance       | 0.897      |
| Iteration               | 861        |
| ItrTime                 | 13.4       |
| LossAfter               | 3.22794    |
| LossBefore              | 3.25954    |
| MaxReturn               | 2.37e+03   |
| MeanKL                  | 0.00981112 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.26e+03   |
| NumTrajs                | 9          |
| Perplexity              | 6.18895    |
| PolicyExecTime          | 0.58       |
| ProcessExecTime         | 0.0651     |
| StdReturn               | 347        |
| Time                    | 1.18e+04   |
| dLoss                   | 0.0315995  |
----------------------------------------
itr #862 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 862...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5229, #subsample_inputs: 5229
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.503      |
| AbsLearnSignalNew       | 0.503      |
| AbsLearningOld          | 0.503      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 49.617     |
| AveragePolicyStd        | 0.446282   |
| AverageReturn           | 2.44e+03   |
| Entropy                 | 1.81956    |
| EnvExecTime             | 2.35       |
| ExplainedVariance       | 0.464      |
| Iteration               | 862        |
| ItrTime                 | 13.7       |
| LossAfter               | 0.0986493  |
| LossBefore              | 0.132274   |
| MaxReturn               | 3.23e+03   |
| MeanKL                  | 0.00997701 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 838        |
| NumTrajs                | 7          |
| Perplexity              | 6.16916    |
| PolicyExecTime          | 0.601      |
| ProcessExecTime         | 0.0658     |
| StdReturn               | 784        |
| Time                    | 1.18e+04   |
| dLoss                   | 0.0336248  |
----------------------------------------
itr #863 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 863...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5189, #subsample_inputs: 5189
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.628      |
| AbsLearnSignalNew       | 0.628      |
| AbsLearningOld          | 0.627      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 61.1012    |
| AveragePolicyStd        | 0.446055   |
| AverageReturn           | 1.89e+03   |
| Entropy                 | 1.81837    |
| EnvExecTime             | 2.41       |
| ExplainedVariance       | 0.726      |
| Iteration               | 863        |
| ItrTime                 | 13.6       |
| LossAfter               | -1.15085   |
| LossBefore              | -1.12372   |
| MaxReturn               | 2.61e+03   |
| MeanKL                  | 0.00649892 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.51e+03   |
| NumTrajs                | 9          |
| Perplexity              | 6.16179    |
| PolicyExecTime          | 0.619      |
| ProcessExecTime         | 0.0672     |
| StdReturn               | 346        |
| Time                    | 1.18e+04   |
| dLoss                   | 0.0271219  |
----------------------------------------
itr #864 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 864...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5480, #subsample_inputs: 5480
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.549      |
| AbsLearnSignalNew       | 0.549      |
| AbsLearningOld          | 0.549      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 44.402     |
| AveragePolicyStd        | 0.444757   |
| AverageReturn           | 2.25e+03   |
| Entropy                 | 1.80927    |
| EnvExecTime             | 2.2        |
| ExplainedVariance       | 0.753      |
| Iteration               | 864        |
| ItrTime                 | 13.7       |
| LossAfter               | 1.52375    |
| LossBefore              | 1.54917    |
| MaxReturn               | 3.29e+03   |
| MeanKL                  | 0.00996383 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.27e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.10599    |
| PolicyExecTime          | 0.557      |
| ProcessExecTime         | 0.0638     |
| StdReturn               | 708        |
| Time                    | 1.18e+04   |
| dLoss                   | 0.0254236  |
----------------------------------------
itr #865 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 865...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5239, #subsample_inputs: 5239
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.667     |
| AbsLearnSignalNew       | 0.667     |
| AbsLearningOld          | 0.667     |
| AverageDiscountedReturn | 242       |
| AveragePhiLoss          | 54.5249   |
| AveragePolicyStd        | 0.446125  |
| AverageReturn           | 2.13e+03  |
| Entropy                 | 1.8188    |
| EnvExecTime             | 2.07      |
| ExplainedVariance       | 0.862     |
| Iteration               | 865       |
| ItrTime                 | 13.2      |
| LossAfter               | -0.577638 |
| LossBefore              | -0.544709 |
| MaxReturn               | 3.17e+03  |
| MeanKL                  | 0.0099645 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 976       |
| NumTrajs                | 8         |
| Perplexity              | 6.16449   |
| PolicyExecTime          | 0.526     |
| ProcessExecTime         | 0.0602    |
| StdReturn               | 712       |
| Time                    | 1.18e+04  |
| dLoss                   | 0.0329291 |
---------------------------------------
itr #866 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 866...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5164, #subsample_inputs: 5164
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.659      |
| AbsLearnSignalNew       | 0.659      |
| AbsLearningOld          | 0.659      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 51.9116    |
| AveragePolicyStd        | 0.445651   |
| AverageReturn           | 1.71e+03   |
| Entropy                 | 1.81602    |
| EnvExecTime             | 2.09       |
| ExplainedVariance       | 0.884      |
| Iteration               | 866        |
| ItrTime                 | 13.1       |
| LossAfter               | 0.430305   |
| LossBefore              | 0.464076   |
| MaxReturn               | 2.68e+03   |
| MeanKL                  | 0.00978395 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 877        |
| NumTrajs                | 10         |
| Perplexity              | 6.14734    |
| PolicyExecTime          | 0.529      |
| ProcessExecTime         | 0.0605     |
| StdReturn               | 447        |
| Time                    | 1.19e+04   |
| dLoss                   | 0.0337705  |
----------------------------------------
itr #867 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 867...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5545, #subsample_inputs: 5545
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.746      |
| AbsLearnSignalNew       | 0.746      |
| AbsLearningOld          | 0.746      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 54.2546    |
| AveragePolicyStd        | 0.444849   |
| AverageReturn           | 2.28e+03   |
| Entropy                 | 1.81068    |
| EnvExecTime             | 2.43       |
| ExplainedVariance       | 0.892      |
| Iteration               | 867        |
| ItrTime                 | 14.1       |
| LossAfter               | -1.209     |
| LossBefore              | -1.18095   |
| MaxReturn               | 3.2e+03    |
| MeanKL                  | 0.00990511 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.22e+03   |
| NumTrajs                | 8          |
| Perplexity              | 6.11459    |
| PolicyExecTime          | 0.615      |
| ProcessExecTime         | 0.0688     |
| StdReturn               | 650        |
| Time                    | 1.19e+04   |
| dLoss                   | 0.028043   |
----------------------------------------
itr #868 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 868...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5613, #subsample_inputs: 5613
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.573      |
| AbsLearnSignalNew       | 0.573      |
| AbsLearningOld          | 0.573      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 48.8263    |
| AveragePolicyStd        | 0.443925   |
| AverageReturn           | 1.86e+03   |
| Entropy                 | 1.8049     |
| EnvExecTime             | 2.49       |
| ExplainedVariance       | 0.823      |
| Iteration               | 868        |
| ItrTime                 | 14.3       |
| LossAfter               | 0.0783873  |
| LossBefore              | 0.113874   |
| MaxReturn               | 2.64e+03   |
| MeanKL                  | 0.00966971 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.15e+03   |
| NumTrajs                | 10         |
| Perplexity              | 6.07936    |
| PolicyExecTime          | 0.628      |
| ProcessExecTime         | 0.0709     |
| StdReturn               | 461        |
| Time                    | 1.19e+04   |
| dLoss                   | 0.0354863  |
----------------------------------------
itr #869 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 869...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5776, #subsample_inputs: 5776
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.605      |
| AbsLearnSignalNew       | 0.605      |
| AbsLearningOld          | 0.605      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 51.2814    |
| AveragePolicyStd        | 0.44341    |
| AverageReturn           | 2.09e+03   |
| Entropy                 | 1.80081    |
| EnvExecTime             | 2.35       |
| ExplainedVariance       | 0.753      |
| Iteration               | 869        |
| ItrTime                 | 14.3       |
| LossAfter               | 0.265789   |
| LossBefore              | 0.293313   |
| MaxReturn               | 3.2e+03    |
| MeanKL                  | 0.00983621 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 726        |
| NumTrajs                | 9          |
| Perplexity              | 6.05452    |
| PolicyExecTime          | 0.6        |
| ProcessExecTime         | 0.0681     |
| StdReturn               | 743        |
| Time                    | 1.19e+04   |
| dLoss                   | 0.027524   |
----------------------------------------
itr #870 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 870...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5610, #subsample_inputs: 5610
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.653     |
| AbsLearnSignalNew       | 0.653     |
| AbsLearningOld          | 0.653     |
| AverageDiscountedReturn | 251       |
| AveragePhiLoss          | 51.7442   |
| AveragePolicyStd        | 0.443881  |
| AverageReturn           | 1.85e+03  |
| Entropy                 | 1.80432   |
| EnvExecTime             | 2.55      |
| ExplainedVariance       | 0.826     |
| Iteration               | 870       |
| ItrTime                 | 14.3      |
| LossAfter               | 3.10745   |
| LossBefore              | 3.13364   |
| MaxReturn               | 3.27e+03  |
| MeanKL                  | 0.0064058 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 895       |
| NumTrajs                | 10        |
| Perplexity              | 6.07582   |
| PolicyExecTime          | 0.651     |
| ProcessExecTime         | 0.0707    |
| StdReturn               | 856       |
| Time                    | 1.19e+04  |
| dLoss                   | 0.0261822 |
---------------------------------------
itr #871 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 871...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5214, #subsample_inputs: 5214
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.737      |
| AbsLearnSignalNew       | 0.737      |
| AbsLearningOld          | 0.737      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 52.4417    |
| AveragePolicyStd        | 0.442734   |
| AverageReturn           | 1.91e+03   |
| Entropy                 | 1.796      |
| EnvExecTime             | 2.36       |
| ExplainedVariance       | 0.853      |
| Iteration               | 871        |
| ItrTime                 | 13.6       |
| LossAfter               | -1.59647   |
| LossBefore              | -1.5603    |
| MaxReturn               | 3.15e+03   |
| MeanKL                  | 0.00995178 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 730        |
| NumTrajs                | 9          |
| Perplexity              | 6.02551    |
| PolicyExecTime          | 0.601      |
| ProcessExecTime         | 0.0652     |
| StdReturn               | 774        |
| Time                    | 1.19e+04   |
| dLoss                   | 0.0361786  |
----------------------------------------
itr #872 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 872...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5507, #subsample_inputs: 5507
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.663      |
| AbsLearnSignalNew       | 0.663      |
| AbsLearningOld          | 0.663      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 48.1086    |
| AveragePolicyStd        | 0.442282   |
| AverageReturn           | 1.53e+03   |
| Entropy                 | 1.79314    |
| EnvExecTime             | 2.27       |
| ExplainedVariance       | 0.805      |
| Iteration               | 872        |
| ItrTime                 | 13.8       |
| LossAfter               | 2.13328    |
| LossBefore              | 2.15987    |
| MaxReturn               | 3.24e+03   |
| MeanKL                  | 0.00640919 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 716        |
| NumTrajs                | 12         |
| Perplexity              | 6.0083     |
| PolicyExecTime          | 0.575      |
| ProcessExecTime         | 0.0659     |
| StdReturn               | 757        |
| Time                    | 1.19e+04   |
| dLoss                   | 0.0265846  |
----------------------------------------
itr #873 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 873...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5352, #subsample_inputs: 5352
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.496      |
| AbsLearnSignalNew       | 0.496      |
| AbsLearningOld          | 0.496      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 47.3512    |
| AveragePolicyStd        | 0.441615   |
| AverageReturn           | 1.94e+03   |
| Entropy                 | 1.78884    |
| EnvExecTime             | 1.87       |
| ExplainedVariance       | 0.427      |
| Iteration               | 873        |
| ItrTime                 | 13.3       |
| LossAfter               | 1.81747    |
| LossBefore              | 1.83749    |
| MaxReturn               | 3.24e+03   |
| MeanKL                  | 0.00644417 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 626        |
| NumTrajs                | 9          |
| Perplexity              | 5.98253    |
| PolicyExecTime          | 0.48       |
| ProcessExecTime         | 0.0565     |
| StdReturn               | 915        |
| Time                    | 1.19e+04   |
| dLoss                   | 0.0200119  |
----------------------------------------
itr #874 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 874...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5411, #subsample_inputs: 5411
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.65       |
| AbsLearnSignalNew       | 0.65       |
| AbsLearningOld          | 0.65       |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 51.3863    |
| AveragePolicyStd        | 0.44186    |
| AverageReturn           | 1.62e+03   |
| Entropy                 | 1.79091    |
| EnvExecTime             | 2.1        |
| ExplainedVariance       | 0.749      |
| Iteration               | 874        |
| ItrTime                 | 13.6       |
| LossAfter               | -1.65592   |
| LossBefore              | -1.62685   |
| MaxReturn               | 3.35e+03   |
| MeanKL                  | 0.00644299 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 649        |
| NumTrajs                | 11         |
| Perplexity              | 5.99489    |
| PolicyExecTime          | 0.536      |
| ProcessExecTime         | 0.0613     |
| StdReturn               | 858        |
| Time                    | 1.2e+04    |
| dLoss                   | 0.0290681  |
----------------------------------------
itr #875 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 875...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5087, #subsample_inputs: 5087
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.697     |
| AbsLearnSignalNew       | 0.697     |
| AbsLearningOld          | 0.697     |
| AverageDiscountedReturn | 247       |
| AveragePhiLoss          | 52.7081   |
| AveragePolicyStd        | 0.440487  |
| AverageReturn           | 1.89e+03  |
| Entropy                 | 1.78287   |
| EnvExecTime             | 1.85      |
| ExplainedVariance       | 0.868     |
| Iteration               | 875       |
| ItrTime                 | 12.7      |
| LossAfter               | -1.48694  |
| LossBefore              | -1.46262  |
| MaxReturn               | 3.36e+03  |
| MeanKL                  | 0.0065561 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 512       |
| NumTrajs                | 9         |
| Perplexity              | 5.94687   |
| PolicyExecTime          | 0.475     |
| ProcessExecTime         | 0.0552    |
| StdReturn               | 867       |
| Time                    | 1.2e+04   |
| dLoss                   | 0.0243187 |
---------------------------------------
itr #876 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 876...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5561, #subsample_inputs: 5561
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.711      |
| AbsLearnSignalNew       | 0.711      |
| AbsLearningOld          | 0.711      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 59.1652    |
| AveragePolicyStd        | 0.43939    |
| AverageReturn           | 1.53e+03   |
| Entropy                 | 1.77543    |
| EnvExecTime             | 2.24       |
| ExplainedVariance       | 0.861      |
| Iteration               | 876        |
| ItrTime                 | 13.9       |
| LossAfter               | -1.80362   |
| LossBefore              | -1.76753   |
| MaxReturn               | 3.37e+03   |
| MeanKL                  | 0.00997194 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 498        |
| NumTrajs                | 12         |
| Perplexity              | 5.90284    |
| PolicyExecTime          | 0.566      |
| ProcessExecTime         | 0.0643     |
| StdReturn               | 980        |
| Time                    | 1.2e+04    |
| dLoss                   | 0.03609    |
----------------------------------------
itr #877 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 877...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5861, #subsample_inputs: 5861
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.67       |
| AbsLearnSignalNew       | 0.67       |
| AbsLearningOld          | 0.67       |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 54.433     |
| AveragePolicyStd        | 0.438925   |
| AverageReturn           | 2.16e+03   |
| Entropy                 | 1.77271    |
| EnvExecTime             | 2.5        |
| ExplainedVariance       | 0.849      |
| Iteration               | 877        |
| ItrTime                 | 14.7       |
| LossAfter               | -0.386566  |
| LossBefore              | -0.354353  |
| MaxReturn               | 3.21e+03   |
| MeanKL                  | 0.00984012 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 921        |
| NumTrajs                | 9          |
| Perplexity              | 5.88681    |
| PolicyExecTime          | 0.628      |
| ProcessExecTime         | 0.0716     |
| StdReturn               | 827        |
| Time                    | 1.2e+04    |
| dLoss                   | 0.0322127  |
----------------------------------------
itr #878 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 878...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5119, #subsample_inputs: 5119
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.613     |
| AbsLearnSignalNew       | 0.613     |
| AbsLearningOld          | 0.613     |
| AverageDiscountedReturn | 245       |
| AveragePhiLoss          | 41.0029   |
| AveragePolicyStd        | 0.439029  |
| AverageReturn           | 2.08e+03  |
| Entropy                 | 1.77459   |
| EnvExecTime             | 2         |
| ExplainedVariance       | 0.806     |
| Iteration               | 878       |
| ItrTime                 | 13        |
| LossAfter               | -2.85811  |
| LossBefore              | -2.82067  |
| MaxReturn               | 3.21e+03  |
| MeanKL                  | 0.0064562 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 695       |
| NumTrajs                | 8         |
| Perplexity              | 5.89785   |
| PolicyExecTime          | 0.517     |
| ProcessExecTime         | 0.0583    |
| StdReturn               | 955       |
| Time                    | 1.2e+04   |
| dLoss                   | 0.0374403 |
---------------------------------------
itr #879 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 879...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5248, #subsample_inputs: 5248
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.618      |
| AbsLearnSignalNew       | 0.618      |
| AbsLearningOld          | 0.617      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 49.1489    |
| AveragePolicyStd        | 0.439279   |
| AverageReturn           | 2.39e+03   |
| Entropy                 | 1.77631    |
| EnvExecTime             | 2.5        |
| ExplainedVariance       | 0.856      |
| Iteration               | 879        |
| ItrTime                 | 13.9       |
| LossAfter               | -1.38826   |
| LossBefore              | -1.35842   |
| MaxReturn               | 3.17e+03   |
| MeanKL                  | 0.00992342 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 705        |
| NumTrajs                | 7          |
| Perplexity              | 5.90802    |
| PolicyExecTime          | 0.622      |
| ProcessExecTime         | 0.0702     |
| StdReturn               | 880        |
| Time                    | 1.2e+04    |
| dLoss                   | 0.0298357  |
----------------------------------------
itr #880 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 880...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5255, #subsample_inputs: 5255
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.665      |
| AbsLearnSignalNew       | 0.665      |
| AbsLearningOld          | 0.665      |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 45.8913    |
| AveragePolicyStd        | 0.439628   |
| AverageReturn           | 2.38e+03   |
| Entropy                 | 1.77938    |
| EnvExecTime             | 2.05       |
| ExplainedVariance       | 0.809      |
| Iteration               | 880        |
| ItrTime                 | 13.2       |
| LossAfter               | 0.320013   |
| LossBefore              | 0.350444   |
| MaxReturn               | 3.21e+03   |
| MeanKL                  | 0.00644864 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.27e+03   |
| NumTrajs                | 7          |
| Perplexity              | 5.92615    |
| PolicyExecTime          | 0.526      |
| ProcessExecTime         | 0.0589     |
| StdReturn               | 699        |
| Time                    | 1.2e+04    |
| dLoss                   | 0.03043    |
----------------------------------------
itr #881 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 881...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5413, #subsample_inputs: 5413
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.698      |
| AbsLearnSignalNew       | 0.698      |
| AbsLearningOld          | 0.698      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 55.7289    |
| AveragePolicyStd        | 0.439352   |
| AverageReturn           | 2.15e+03   |
| Entropy                 | 1.77793    |
| EnvExecTime             | 2.63       |
| ExplainedVariance       | 0.858      |
| Iteration               | 881        |
| ItrTime                 | 14.3       |
| LossAfter               | -0.683071  |
| LossBefore              | -0.656898  |
| MaxReturn               | 3.2e+03    |
| MeanKL                  | 0.00988333 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 740        |
| NumTrajs                | 8          |
| Perplexity              | 5.91761    |
| PolicyExecTime          | 0.662      |
| ProcessExecTime         | 0.0733     |
| StdReturn               | 1.04e+03   |
| Time                    | 1.21e+04   |
| dLoss                   | 0.0261722  |
----------------------------------------
itr #882 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 882...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5956, #subsample_inputs: 5956
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.693     |
| AbsLearnSignalNew       | 0.693     |
| AbsLearningOld          | 0.693     |
| AverageDiscountedReturn | 247       |
| AveragePhiLoss          | 53.2435   |
| AveragePolicyStd        | 0.438842  |
| AverageReturn           | 2.66e+03  |
| Entropy                 | 1.77421   |
| EnvExecTime             | 2.63      |
| ExplainedVariance       | 0.87      |
| Iteration               | 882       |
| ItrTime                 | 15        |
| LossAfter               | -4.38556  |
| LossBefore              | -4.35473  |
| MaxReturn               | 3.22e+03  |
| MeanKL                  | 0.0099904 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.26e+03  |
| NumTrajs                | 7         |
| Perplexity              | 5.89561   |
| PolicyExecTime          | 0.664     |
| ProcessExecTime         | 0.0757    |
| StdReturn               | 697       |
| Time                    | 1.21e+04  |
| dLoss                   | 0.0308261 |
---------------------------------------
itr #883 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 883...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5053, #subsample_inputs: 5053
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.616      |
| AbsLearnSignalNew       | 0.616      |
| AbsLearningOld          | 0.616      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 54.5128    |
| AveragePolicyStd        | 0.43971    |
| AverageReturn           | 2.66e+03   |
| Entropy                 | 1.7801     |
| EnvExecTime             | 1.85       |
| ExplainedVariance       | 0.826      |
| Iteration               | 883        |
| ItrTime                 | 12.6       |
| LossAfter               | -1.89507   |
| LossBefore              | -1.86045   |
| MaxReturn               | 3.22e+03   |
| MeanKL                  | 0.00976058 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.74e+03   |
| NumTrajs                | 6          |
| Perplexity              | 5.93047    |
| PolicyExecTime          | 0.46       |
| ProcessExecTime         | 0.0556     |
| StdReturn               | 644        |
| Time                    | 1.21e+04   |
| dLoss                   | 0.0346138  |
----------------------------------------
itr #884 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 884...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5015, #subsample_inputs: 5015
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.684      |
| AbsLearnSignalNew       | 0.684      |
| AbsLearningOld          | 0.684      |
| AverageDiscountedReturn | 233        |
| AveragePhiLoss          | 52.0182    |
| AveragePolicyStd        | 0.440371   |
| AverageReturn           | 1.23e+03   |
| Entropy                 | 1.78354    |
| EnvExecTime             | 2.21       |
| ExplainedVariance       | 0.728      |
| Iteration               | 884        |
| ItrTime                 | 13         |
| LossAfter               | -1.4836    |
| LossBefore              | -1.44652   |
| MaxReturn               | 3.05e+03   |
| MeanKL                  | 0.00983868 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 260        |
| NumTrajs                | 13         |
| Perplexity              | 5.95089    |
| PolicyExecTime          | 0.557      |
| ProcessExecTime         | 0.0637     |
| StdReturn               | 779        |
| Time                    | 1.21e+04   |
| dLoss                   | 0.0370804  |
----------------------------------------
itr #885 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 885...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5690, #subsample_inputs: 5690
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.716      |
| AbsLearnSignalNew       | 0.716      |
| AbsLearningOld          | 0.716      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 53.6724    |
| AveragePolicyStd        | 0.439987   |
| AverageReturn           | 1.24e+03   |
| Entropy                 | 1.78088    |
| EnvExecTime             | 2.67       |
| ExplainedVariance       | 0.805      |
| Iteration               | 885        |
| ItrTime                 | 14.7       |
| LossAfter               | -2.82658   |
| LossBefore              | -2.79947   |
| MaxReturn               | 2.86e+03   |
| MeanKL                  | 0.00657533 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 500        |
| NumTrajs                | 15         |
| Perplexity              | 5.93505    |
| PolicyExecTime          | 0.652      |
| ProcessExecTime         | 0.0803     |
| StdReturn               | 785        |
| Time                    | 1.21e+04   |
| dLoss                   | 0.0271132  |
----------------------------------------
itr #886 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 886...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5106, #subsample_inputs: 5106
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.734      |
| AbsLearnSignalNew       | 0.734      |
| AbsLearningOld          | 0.733      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 61.3586    |
| AveragePolicyStd        | 0.440411   |
| AverageReturn           | 1.2e+03    |
| Entropy                 | 1.78314    |
| EnvExecTime             | 1.82       |
| ExplainedVariance       | 0.819      |
| Iteration               | 886        |
| ItrTime                 | 12.7       |
| LossAfter               | 0.536297   |
| LossBefore              | 0.55704    |
| MaxReturn               | 3.18e+03   |
| MeanKL                  | 0.00650318 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 505        |
| NumTrajs                | 14         |
| Perplexity              | 5.94848    |
| PolicyExecTime          | 0.462      |
| ProcessExecTime         | 0.0546     |
| StdReturn               | 747        |
| Time                    | 1.21e+04   |
| dLoss                   | 0.0207437  |
----------------------------------------
itr #887 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 887...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5060, #subsample_inputs: 5060
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.606      |
| AbsLearnSignalNew       | 0.606      |
| AbsLearningOld          | 0.606      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 46.8961    |
| AveragePolicyStd        | 0.438428   |
| AverageReturn           | 1.5e+03    |
| Entropy                 | 1.76905    |
| EnvExecTime             | 2.28       |
| ExplainedVariance       | 0.558      |
| Iteration               | 887        |
| ItrTime                 | 13.2       |
| LossAfter               | -0.62481   |
| LossBefore              | -0.599908  |
| MaxReturn               | 2.71e+03   |
| MeanKL                  | 0.00979661 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 300        |
| NumTrajs                | 11         |
| Perplexity              | 5.86526    |
| PolicyExecTime          | 0.564      |
| ProcessExecTime         | 0.0656     |
| StdReturn               | 733        |
| Time                    | 1.21e+04   |
| dLoss                   | 0.0249022  |
----------------------------------------
itr #888 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 888...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5375, #subsample_inputs: 5375
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.724      |
| AbsLearnSignalNew       | 0.724      |
| AbsLearningOld          | 0.724      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 56.1432    |
| AveragePolicyStd        | 0.44108    |
| AverageReturn           | 1.95e+03   |
| Entropy                 | 1.78785    |
| EnvExecTime             | 2.16       |
| ExplainedVariance       | 0.538      |
| Iteration               | 888        |
| ItrTime                 | 13.6       |
| LossAfter               | -2.76067   |
| LossBefore              | -2.73046   |
| MaxReturn               | 3.2e+03    |
| MeanKL                  | 0.00996801 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 964        |
| NumTrajs                | 9          |
| Perplexity              | 5.97661    |
| PolicyExecTime          | 0.553      |
| ProcessExecTime         | 0.0627     |
| StdReturn               | 952        |
| Time                    | 1.22e+04   |
| dLoss                   | 0.0302126  |
----------------------------------------
itr #889 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 889...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5260, #subsample_inputs: 5260
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.638      |
| AbsLearnSignalNew       | 0.638      |
| AbsLearningOld          | 0.638      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 52.7632    |
| AveragePolicyStd        | 0.442552   |
| AverageReturn           | 1.34e+03   |
| Entropy                 | 1.79848    |
| EnvExecTime             | 1.9        |
| ExplainedVariance       | 0.839      |
| Iteration               | 889        |
| ItrTime                 | 13         |
| LossAfter               | 0.156992   |
| LossBefore              | 0.191176   |
| MaxReturn               | 3.28e+03   |
| MeanKL                  | 0.00982341 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 614        |
| NumTrajs                | 13         |
| Perplexity              | 6.04047    |
| PolicyExecTime          | 0.48       |
| ProcessExecTime         | 0.058      |
| StdReturn               | 911        |
| Time                    | 1.22e+04   |
| dLoss                   | 0.0341841  |
----------------------------------------
itr #890 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 890...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5233, #subsample_inputs: 5233
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.749      |
| AbsLearnSignalNew       | 0.749      |
| AbsLearningOld          | 0.749      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 48.491     |
| AveragePolicyStd        | 0.443313   |
| AverageReturn           | 1.09e+03   |
| Entropy                 | 1.80345    |
| EnvExecTime             | 2.18       |
| ExplainedVariance       | 0.877      |
| Iteration               | 890        |
| ItrTime                 | 13.4       |
| LossAfter               | 2.35175    |
| LossBefore              | 2.38138    |
| MaxReturn               | 2.54e+03   |
| MeanKL                  | 0.00985335 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 652        |
| NumTrajs                | 16         |
| Perplexity              | 6.07058    |
| PolicyExecTime          | 0.549      |
| ProcessExecTime         | 0.0632     |
| StdReturn               | 559        |
| Time                    | 1.22e+04   |
| dLoss                   | 0.0296309  |
----------------------------------------
itr #891 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 891...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5319, #subsample_inputs: 5319
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.642      |
| AbsLearnSignalNew       | 0.642      |
| AbsLearningOld          | 0.642      |
| AverageDiscountedReturn | 234        |
| AveragePhiLoss          | 51.2517    |
| AveragePolicyStd        | 0.443442   |
| AverageReturn           | 1.03e+03   |
| Entropy                 | 1.80333    |
| EnvExecTime             | 2.1        |
| ExplainedVariance       | 0.697      |
| Iteration               | 891        |
| ItrTime                 | 13.4       |
| LossAfter               | 0.772064   |
| LossBefore              | 0.798992   |
| MaxReturn               | 3.03e+03   |
| MeanKL                  | 0.00644015 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 256        |
| NumTrajs                | 17         |
| Perplexity              | 6.0698     |
| PolicyExecTime          | 0.524      |
| ProcessExecTime         | 0.0629     |
| StdReturn               | 659        |
| Time                    | 1.22e+04   |
| dLoss                   | 0.0269281  |
----------------------------------------
itr #892 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 892...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5570, #subsample_inputs: 5570
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.734      |
| AbsLearnSignalNew       | 0.734      |
| AbsLearningOld          | 0.734      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 48.9952    |
| AveragePolicyStd        | 0.444845   |
| AverageReturn           | 1.45e+03   |
| Entropy                 | 1.81282    |
| EnvExecTime             | 2.14       |
| ExplainedVariance       | 0.849      |
| Iteration               | 892        |
| ItrTime                 | 13.7       |
| LossAfter               | 0.379437   |
| LossBefore              | 0.414014   |
| MaxReturn               | 2.84e+03   |
| MeanKL                  | 0.00994853 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 753        |
| NumTrajs                | 13         |
| Perplexity              | 6.12769    |
| PolicyExecTime          | 0.541      |
| ProcessExecTime         | 0.0635     |
| StdReturn               | 623        |
| Time                    | 1.22e+04   |
| dLoss                   | 0.0345772  |
----------------------------------------
itr #893 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 893...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5525, #subsample_inputs: 5525
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.598      |
| AbsLearnSignalNew       | 0.598      |
| AbsLearningOld          | 0.598      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 50.9223    |
| AveragePolicyStd        | 0.445475   |
| AverageReturn           | 1.48e+03   |
| Entropy                 | 1.81827    |
| EnvExecTime             | 2.11       |
| ExplainedVariance       | 0.586      |
| Iteration               | 893        |
| ItrTime                 | 13.6       |
| LossAfter               | -0.480051  |
| LossBefore              | -0.459607  |
| MaxReturn               | 3.29e+03   |
| MeanKL                  | 0.00646674 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 502        |
| NumTrajs                | 12         |
| Perplexity              | 6.16119    |
| PolicyExecTime          | 0.53       |
| ProcessExecTime         | 0.0619     |
| StdReturn               | 1.04e+03   |
| Time                    | 1.22e+04   |
| dLoss                   | 0.020444   |
----------------------------------------
itr #894 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 894...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5082, #subsample_inputs: 5082
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.607      |
| AbsLearnSignalNew       | 0.607      |
| AbsLearningOld          | 0.607      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 52.2182    |
| AveragePolicyStd        | 0.44406    |
| AverageReturn           | 1.65e+03   |
| Entropy                 | 1.80894    |
| EnvExecTime             | 2.34       |
| ExplainedVariance       | 0.639      |
| Iteration               | 894        |
| ItrTime                 | 13.4       |
| LossAfter               | -1.67954   |
| LossBefore              | -1.65379   |
| MaxReturn               | 3.15e+03   |
| MeanKL                  | 0.00641091 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 291        |
| NumTrajs                | 10         |
| Perplexity              | 6.10396    |
| PolicyExecTime          | 0.6        |
| ProcessExecTime         | 0.0645     |
| StdReturn               | 924        |
| Time                    | 1.22e+04   |
| dLoss                   | 0.0257518  |
----------------------------------------
itr #895 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 895...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5642, #subsample_inputs: 5642
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.663     |
| AbsLearnSignalNew       | 0.663     |
| AbsLearningOld          | 0.663     |
| AverageDiscountedReturn | 250       |
| AveragePhiLoss          | 61.7141   |
| AveragePolicyStd        | 0.443414  |
| AverageReturn           | 1.83e+03  |
| Entropy                 | 1.80463   |
| EnvExecTime             | 2.36      |
| ExplainedVariance       | 0.825     |
| Iteration               | 895       |
| ItrTime                 | 14.2      |
| LossAfter               | 0.461315  |
| LossBefore              | 0.516571  |
| MaxReturn               | 3.23e+03  |
| MeanKL                  | 0.0098625 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 739       |
| NumTrajs                | 10        |
| Perplexity              | 6.0777    |
| PolicyExecTime          | 0.605     |
| ProcessExecTime         | 0.0681    |
| StdReturn               | 1.03e+03  |
| Time                    | 1.23e+04  |
| dLoss                   | 0.0552565 |
---------------------------------------
itr #896 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 896...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5001, #subsample_inputs: 5001
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.651      |
| AbsLearnSignalNew       | 0.651      |
| AbsLearningOld          | 0.651      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 53.7358    |
| AveragePolicyStd        | 0.444282   |
| AverageReturn           | 1.82e+03   |
| Entropy                 | 1.81059    |
| EnvExecTime             | 1.95       |
| ExplainedVariance       | 0.831      |
| Iteration               | 896        |
| ItrTime                 | 12.7       |
| LossAfter               | -0.965836  |
| LossBefore              | -0.926635  |
| MaxReturn               | 3.29e+03   |
| MeanKL                  | 0.00968613 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 483        |
| NumTrajs                | 9          |
| Perplexity              | 6.11404    |
| PolicyExecTime          | 0.5        |
| ProcessExecTime         | 0.0571     |
| StdReturn               | 1.02e+03   |
| Time                    | 1.23e+04   |
| dLoss                   | 0.0392001  |
----------------------------------------
itr #897 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 897...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5427, #subsample_inputs: 5427
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.64       |
| AbsLearnSignalNew       | 0.64       |
| AbsLearningOld          | 0.64       |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 52.1177    |
| AveragePolicyStd        | 0.442652   |
| AverageReturn           | 2e+03      |
| Entropy                 | 1.79914    |
| EnvExecTime             | 2.22       |
| ExplainedVariance       | 0.793      |
| Iteration               | 897        |
| ItrTime                 | 13.8       |
| LossAfter               | 1.0825     |
| LossBefore              | 1.11388    |
| MaxReturn               | 3.31e+03   |
| MeanKL                  | 0.00994667 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 532        |
| NumTrajs                | 9          |
| Perplexity              | 6.04446    |
| PolicyExecTime          | 0.55       |
| ProcessExecTime         | 0.0659     |
| StdReturn               | 998        |
| Time                    | 1.23e+04   |
| dLoss                   | 0.0313793  |
----------------------------------------
itr #898 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 898...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5188, #subsample_inputs: 5188
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.717      |
| AbsLearnSignalNew       | 0.717      |
| AbsLearningOld          | 0.717      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 50.1451    |
| AveragePolicyStd        | 0.44351    |
| AverageReturn           | 1.64e+03   |
| Entropy                 | 1.80542    |
| EnvExecTime             | 2.08       |
| ExplainedVariance       | 0.825      |
| Iteration               | 898        |
| ItrTime                 | 13.2       |
| LossAfter               | -0.190163  |
| LossBefore              | -0.158146  |
| MaxReturn               | 3.11e+03   |
| MeanKL                  | 0.00991862 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 680        |
| NumTrajs                | 10         |
| Perplexity              | 6.08254    |
| PolicyExecTime          | 0.527      |
| ProcessExecTime         | 0.0613     |
| StdReturn               | 972        |
| Time                    | 1.23e+04   |
| dLoss                   | 0.0320166  |
----------------------------------------
itr #899 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 899...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5671, #subsample_inputs: 5671
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.734      |
| AbsLearnSignalNew       | 0.734      |
| AbsLearningOld          | 0.734      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 54.8667    |
| AveragePolicyStd        | 0.444205   |
| AverageReturn           | 1.5e+03    |
| Entropy                 | 1.80947    |
| EnvExecTime             | 1.9        |
| ExplainedVariance       | 0.86       |
| Iteration               | 899        |
| ItrTime                 | 13.6       |
| LossAfter               | 0.175053   |
| LossBefore              | 0.211246   |
| MaxReturn               | 3.21e+03   |
| MeanKL                  | 0.00988318 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 410        |
| NumTrajs                | 12         |
| Perplexity              | 6.10723    |
| PolicyExecTime          | 0.487      |
| ProcessExecTime         | 0.059      |
| StdReturn               | 1.16e+03   |
| Time                    | 1.23e+04   |
| dLoss                   | 0.036193   |
----------------------------------------
itr #900 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 900...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5255, #subsample_inputs: 5255
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.632      |
| AbsLearnSignalNew       | 0.632      |
| AbsLearningOld          | 0.631      |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 44.5309    |
| AveragePolicyStd        | 0.443952   |
| AverageReturn           | 1.52e+03   |
| Entropy                 | 1.80856    |
| EnvExecTime             | 2.06       |
| ExplainedVariance       | 0.689      |
| Iteration               | 900        |
| ItrTime                 | 13.2       |
| LossAfter               | -0.732926  |
| LossBefore              | -0.705274  |
| MaxReturn               | 3.17e+03   |
| MeanKL                  | 0.00647769 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 285        |
| NumTrajs                | 11         |
| Perplexity              | 6.10167    |
| PolicyExecTime          | 0.509      |
| ProcessExecTime         | 0.0604     |
| StdReturn               | 1.03e+03   |
| Time                    | 1.23e+04   |
| dLoss                   | 0.0276521  |
----------------------------------------
itr #901 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 901...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5197, #subsample_inputs: 5197
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
-----------------------------------------
| AbsLearnSignal          | 0.727       |
| AbsLearnSignalNew       | 0.727       |
| AbsLearningOld          | 0.727       |
| AverageDiscountedReturn | 246         |
| AveragePhiLoss          | 53.0754     |
| AveragePolicyStd        | 0.444653    |
| AverageReturn           | 1.15e+03    |
| Entropy                 | 1.81334     |
| EnvExecTime             | 2.21        |
| ExplainedVariance       | 0.786       |
| Iteration               | 901         |
| ItrTime                 | 13.3        |
| LossAfter               | -0.0297952  |
| LossBefore              | -0.00558033 |
| MaxReturn               | 3.2e+03     |
| MeanKL                  | 0.00641992  |
| MeanKLBefore            | 0.0         |
| MinReturn               | 545         |
| NumTrajs                | 15          |
| Perplexity              | 6.13088     |
| PolicyExecTime          | 0.566       |
| ProcessExecTime         | 0.0628      |
| StdReturn               | 708         |
| Time                    | 1.23e+04    |
| dLoss                   | 0.0242148   |
-----------------------------------------
itr #902 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 902...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5104, #subsample_inputs: 5104
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.718      |
| AbsLearnSignalNew       | 0.718      |
| AbsLearningOld          | 0.718      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 54.7629    |
| AveragePolicyStd        | 0.443617   |
| AverageReturn           | 1.01e+03   |
| Entropy                 | 1.80615    |
| EnvExecTime             | 2.43       |
| ExplainedVariance       | 0.846      |
| Iteration               | 902        |
| ItrTime                 | 13.4       |
| LossAfter               | -0.918048  |
| LossBefore              | -0.879605  |
| MaxReturn               | 2.12e+03   |
| MeanKL                  | 0.00996871 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 479        |
| NumTrajs                | 17         |
| Perplexity              | 6.08697    |
| PolicyExecTime          | 0.602      |
| ProcessExecTime         | 0.0684     |
| StdReturn               | 463        |
| Time                    | 1.23e+04   |
| dLoss                   | 0.0384434  |
----------------------------------------
itr #903 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 903...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5494, #subsample_inputs: 5494
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.562      |
| AbsLearnSignalNew       | 0.562      |
| AbsLearningOld          | 0.562      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 51.5694    |
| AveragePolicyStd        | 0.443494   |
| AverageReturn           | 1.3e+03    |
| Entropy                 | 1.8042     |
| EnvExecTime             | 2.12       |
| ExplainedVariance       | 0.164      |
| Iteration               | 903        |
| ItrTime                 | 13.6       |
| LossAfter               | 0.812341   |
| LossBefore              | 0.840703   |
| MaxReturn               | 3.26e+03   |
| MeanKL                  | 0.00995618 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 704        |
| NumTrajs                | 14         |
| Perplexity              | 6.07508    |
| PolicyExecTime          | 0.534      |
| ProcessExecTime         | 0.0665     |
| StdReturn               | 843        |
| Time                    | 1.24e+04   |
| dLoss                   | 0.0283617  |
----------------------------------------
itr #904 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 904...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5144, #subsample_inputs: 5144
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.731      |
| AbsLearnSignalNew       | 0.731      |
| AbsLearningOld          | 0.731      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 51.0683    |
| AveragePolicyStd        | 0.443596   |
| AverageReturn           | 1.16e+03   |
| Entropy                 | 1.80469    |
| EnvExecTime             | 2.33       |
| ExplainedVariance       | 0.87       |
| Iteration               | 904        |
| ItrTime                 | 13.4       |
| LossAfter               | -1.60266   |
| LossBefore              | -1.57046   |
| MaxReturn               | 2.39e+03   |
| MeanKL                  | 0.00994546 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 565        |
| NumTrajs                | 15         |
| Perplexity              | 6.07806    |
| PolicyExecTime          | 0.587      |
| ProcessExecTime         | 0.0652     |
| StdReturn               | 542        |
| Time                    | 1.24e+04   |
| dLoss                   | 0.0321995  |
----------------------------------------
itr #905 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 905...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5313, #subsample_inputs: 5313
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.734      |
| AbsLearnSignalNew       | 0.734      |
| AbsLearningOld          | 0.734      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 50.4105    |
| AveragePolicyStd        | 0.443308   |
| AverageReturn           | 1.33e+03   |
| Entropy                 | 1.80192    |
| EnvExecTime             | 2.48       |
| ExplainedVariance       | 0.792      |
| Iteration               | 905        |
| ItrTime                 | 13.9       |
| LossAfter               | -0.269838  |
| LossBefore              | -0.246     |
| MaxReturn               | 3.14e+03   |
| MeanKL                  | 0.00642232 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 517        |
| NumTrajs                | 13         |
| Perplexity              | 6.06126    |
| PolicyExecTime          | 0.63       |
| ProcessExecTime         | 0.0713     |
| StdReturn               | 920        |
| Time                    | 1.24e+04   |
| dLoss                   | 0.0238387  |
----------------------------------------
itr #906 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 906...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5527, #subsample_inputs: 5527
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.746      |
| AbsLearnSignalNew       | 0.746      |
| AbsLearningOld          | 0.746      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 55.1687    |
| AveragePolicyStd        | 0.443812   |
| AverageReturn           | 1.3e+03    |
| Entropy                 | 1.80553    |
| EnvExecTime             | 2.24       |
| ExplainedVariance       | 0.839      |
| Iteration               | 906        |
| ItrTime                 | 13.9       |
| LossAfter               | -1.5494    |
| LossBefore              | -1.51368   |
| MaxReturn               | 3.26e+03   |
| MeanKL                  | 0.00987658 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 475        |
| NumTrajs                | 14         |
| Perplexity              | 6.08317    |
| PolicyExecTime          | 0.564      |
| ProcessExecTime         | 0.0672     |
| StdReturn               | 861        |
| Time                    | 1.24e+04   |
| dLoss                   | 0.0357206  |
----------------------------------------
itr #907 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 907...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5083, #subsample_inputs: 5083
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.749      |
| AbsLearnSignalNew       | 0.749      |
| AbsLearningOld          | 0.749      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 51.9122    |
| AveragePolicyStd        | 0.443639   |
| AverageReturn           | 1.11e+03   |
| Entropy                 | 1.80371    |
| EnvExecTime             | 2.09       |
| ExplainedVariance       | 0.835      |
| Iteration               | 907        |
| ItrTime                 | 13         |
| LossAfter               | 0.467895   |
| LossBefore              | 0.501232   |
| MaxReturn               | 3.1e+03    |
| MeanKL                  | 0.00995147 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 549        |
| NumTrajs                | 15         |
| Perplexity              | 6.07214    |
| PolicyExecTime          | 0.516      |
| ProcessExecTime         | 0.0611     |
| StdReturn               | 770        |
| Time                    | 1.24e+04   |
| dLoss                   | 0.0333368  |
----------------------------------------
itr #908 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 908...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5008, #subsample_inputs: 5008
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.6        |
| AbsLearnSignalNew       | 0.6        |
| AbsLearningOld          | 0.6        |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 59.2071    |
| AveragePolicyStd        | 0.44372    |
| AverageReturn           | 1.83e+03   |
| Entropy                 | 1.80466    |
| EnvExecTime             | 1.91       |
| ExplainedVariance       | 0.591      |
| Iteration               | 908        |
| ItrTime                 | 12.6       |
| LossAfter               | 2.19471    |
| LossBefore              | 2.22278    |
| MaxReturn               | 3.15e+03   |
| MeanKL                  | 0.00641351 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 535        |
| NumTrajs                | 9          |
| Perplexity              | 6.07789    |
| PolicyExecTime          | 0.477      |
| ProcessExecTime         | 0.0567     |
| StdReturn               | 955        |
| Time                    | 1.24e+04   |
| dLoss                   | 0.0280647  |
----------------------------------------
itr #909 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 909...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5070, #subsample_inputs: 5070
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.676      |
| AbsLearnSignalNew       | 0.676      |
| AbsLearningOld          | 0.676      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 49.0945    |
| AveragePolicyStd        | 0.444132   |
| AverageReturn           | 1.19e+03   |
| Entropy                 | 1.80745    |
| EnvExecTime             | 2.14       |
| ExplainedVariance       | 0.718      |
| Iteration               | 909        |
| ItrTime                 | 13.1       |
| LossAfter               | 0.602437   |
| LossBefore              | 0.628927   |
| MaxReturn               | 3.07e+03   |
| MeanKL                  | 0.00641637 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 511        |
| NumTrajs                | 14         |
| Perplexity              | 6.09486    |
| PolicyExecTime          | 0.547      |
| ProcessExecTime         | 0.0603     |
| StdReturn               | 725        |
| Time                    | 1.24e+04   |
| dLoss                   | 0.0264902  |
----------------------------------------
itr #910 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 910...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5151, #subsample_inputs: 5151
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.714      |
| AbsLearnSignalNew       | 0.714      |
| AbsLearningOld          | 0.714      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 53.1495    |
| AveragePolicyStd        | 0.44473    |
| AverageReturn           | 1.52e+03   |
| Entropy                 | 1.81129    |
| EnvExecTime             | 2.15       |
| ExplainedVariance       | 0.771      |
| Iteration               | 910        |
| ItrTime                 | 13.2       |
| LossAfter               | 0.442336   |
| LossBefore              | 0.472254   |
| MaxReturn               | 3.3e+03    |
| MeanKL                  | 0.00640935 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 543        |
| NumTrajs                | 11         |
| Perplexity              | 6.11833    |
| PolicyExecTime          | 0.536      |
| ProcessExecTime         | 0.0623     |
| StdReturn               | 1.09e+03   |
| Time                    | 1.25e+04   |
| dLoss                   | 0.0299172  |
----------------------------------------
itr #911 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 911...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5457, #subsample_inputs: 5457
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.683      |
| AbsLearnSignalNew       | 0.683      |
| AbsLearningOld          | 0.683      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 53.4763    |
| AveragePolicyStd        | 0.445339   |
| AverageReturn           | 2.18e+03   |
| Entropy                 | 1.8152     |
| EnvExecTime             | 2.15       |
| ExplainedVariance       | 0.792      |
| Iteration               | 911        |
| ItrTime                 | 13.9       |
| LossAfter               | 0.280684   |
| LossBefore              | 0.303619   |
| MaxReturn               | 3.2e+03    |
| MeanKL                  | 0.00660087 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 547        |
| NumTrajs                | 8          |
| Perplexity              | 6.14231    |
| PolicyExecTime          | 0.536      |
| ProcessExecTime         | 0.0723     |
| StdReturn               | 1.1e+03    |
| Time                    | 1.25e+04   |
| dLoss                   | 0.0229349  |
----------------------------------------
itr #912 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 912...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5072, #subsample_inputs: 5072
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.592      |
| AbsLearnSignalNew       | 0.592      |
| AbsLearningOld          | 0.592      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 50.2452    |
| AveragePolicyStd        | 0.4451     |
| AverageReturn           | 1.46e+03   |
| Entropy                 | 1.81313    |
| EnvExecTime             | 2.07       |
| ExplainedVariance       | 0.68       |
| Iteration               | 912        |
| ItrTime                 | 12.9       |
| LossAfter               | -0.306072  |
| LossBefore              | -0.273672  |
| MaxReturn               | 3.18e+03   |
| MeanKL                  | 0.00979015 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 262        |
| NumTrajs                | 11         |
| Perplexity              | 6.1296     |
| PolicyExecTime          | 0.531      |
| ProcessExecTime         | 0.0602     |
| StdReturn               | 1.04e+03   |
| Time                    | 1.25e+04   |
| dLoss                   | 0.0323996  |
----------------------------------------
itr #913 | 
Mem: 742.343750
Obtaining samples...
Obtaining samples for iteration 913...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5685, #subsample_inputs: 5685
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.741      |
| AbsLearnSignalNew       | 0.741      |
| AbsLearningOld          | 0.741      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 55.2647    |
| AveragePolicyStd        | 0.444563   |
| AverageReturn           | 2.24e+03   |
| Entropy                 | 1.80938    |
| EnvExecTime             | 2.25       |
| ExplainedVariance       | 0.872      |
| Iteration               | 913        |
| ItrTime                 | 14.1       |
| LossAfter               | 2.3213     |
| LossBefore              | 2.36038    |
| MaxReturn               | 3.21e+03   |
| MeanKL                  | 0.00991589 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 679        |
| NumTrajs                | 8          |
| Perplexity              | 6.10667    |
| PolicyExecTime          | 0.57       |
| ProcessExecTime         | 0.0656     |
| StdReturn               | 1.11e+03   |
| Time                    | 1.25e+04   |
| dLoss                   | 0.0390851  |
----------------------------------------
itr #914 | 
Mem: 742.515625
Obtaining samples...
Obtaining samples for iteration 914...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5199, #subsample_inputs: 5199
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.69       |
| AbsLearnSignalNew       | 0.69       |
| AbsLearningOld          | 0.69       |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 59.0391    |
| AveragePolicyStd        | 0.44329    |
| AverageReturn           | 2.35e+03   |
| Entropy                 | 1.80107    |
| EnvExecTime             | 2.28       |
| ExplainedVariance       | 0.897      |
| Iteration               | 914        |
| ItrTime                 | 13.4       |
| LossAfter               | 1.54291    |
| LossBefore              | 1.57788    |
| MaxReturn               | 3.16e+03   |
| MeanKL                  | 0.00996215 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 739        |
| NumTrajs                | 7          |
| Perplexity              | 6.0561     |
| PolicyExecTime          | 0.58       |
| ProcessExecTime         | 0.0652     |
| StdReturn               | 939        |
| Time                    | 1.25e+04   |
| dLoss                   | 0.0349669  |
----------------------------------------
itr #915 | 
Mem: 742.515625
Obtaining samples...
Obtaining samples for iteration 915...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5191, #subsample_inputs: 5191
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
-----------------------------------------
| AbsLearnSignal          | 0.69        |
| AbsLearnSignalNew       | 0.69        |
| AbsLearningOld          | 0.69        |
| AverageDiscountedReturn | 251         |
| AveragePhiLoss          | 49.6876     |
| AveragePolicyStd        | 0.442838    |
| AverageReturn           | 2.7e+03     |
| Entropy                 | 1.79811     |
| EnvExecTime             | 2.07        |
| ExplainedVariance       | 0.908       |
| Iteration               | 915         |
| ItrTime                 | 13.1        |
| LossAfter               | -0.0308929  |
| LossBefore              | -0.00500697 |
| MaxReturn               | 3.17e+03    |
| MeanKL                  | 0.00646735  |
| MeanKLBefore            | 0.0         |
| MinReturn               | 616         |
| NumTrajs                | 6           |
| Perplexity              | 6.0382      |
| PolicyExecTime          | 0.515       |
| ProcessExecTime         | 0.0614      |
| StdReturn               | 935         |
| Time                    | 1.25e+04    |
| dLoss                   | 0.0258859   |
-----------------------------------------
itr #916 | 
Mem: 742.515625
Obtaining samples...
Obtaining samples for iteration 916...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5000, #subsample_inputs: 5000
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.71       |
| AbsLearnSignalNew       | 0.71       |
| AbsLearningOld          | 0.71       |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 49.5243    |
| AveragePolicyStd        | 0.443378   |
| AverageReturn           | 3.09e+03   |
| Entropy                 | 1.80154    |
| EnvExecTime             | 1.61       |
| ExplainedVariance       | 0.932      |
| Iteration               | 916        |
| ItrTime                 | 12.3       |
| LossAfter               | -2.66051   |
| LossBefore              | -2.63268   |
| MaxReturn               | 3.18e+03   |
| MeanKL                  | 0.00993802 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 3.04e+03   |
| NumTrajs                | 5          |
| Perplexity              | 6.05897    |
| PolicyExecTime          | 0.407      |
| ProcessExecTime         | 0.057      |
| StdReturn               | 49.9       |
| Time                    | 1.25e+04   |
| dLoss                   | 0.0278301  |
----------------------------------------
itr #917 | 
Mem: 742.515625
Obtaining samples...
Obtaining samples for iteration 917...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5572, #subsample_inputs: 5572
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.418      |
| AbsLearnSignalNew       | 0.418      |
| AbsLearningOld          | 0.418      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 48.0349    |
| AveragePolicyStd        | 0.442507   |
| AverageReturn           | 2.49e+03   |
| Entropy                 | 1.79566    |
| EnvExecTime             | 2.19       |
| ExplainedVariance       | 0.658      |
| Iteration               | 917        |
| ItrTime                 | 13.8       |
| LossAfter               | 1.55383    |
| LossBefore              | 1.59587    |
| MaxReturn               | 3.24e+03   |
| MeanKL                  | 0.00991323 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 701        |
| NumTrajs                | 7          |
| Perplexity              | 6.02343    |
| PolicyExecTime          | 0.548      |
| ProcessExecTime         | 0.0687     |
| StdReturn               | 1.03e+03   |
| Time                    | 1.25e+04   |
| dLoss                   | 0.0420327  |
----------------------------------------
itr #918 | 
Mem: 742.515625
Obtaining samples...
Obtaining samples for iteration 918...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5076, #subsample_inputs: 5076
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.343      |
| AbsLearnSignalNew       | 0.343      |
| AbsLearningOld          | 0.342      |
| AverageDiscountedReturn | 226        |
| AveragePhiLoss          | 36.8898    |
| AveragePolicyStd        | 0.442399   |
| AverageReturn           | 2.25e+03   |
| Entropy                 | 1.79523    |
| EnvExecTime             | 2.25       |
| ExplainedVariance       | 0.383      |
| Iteration               | 918        |
| ItrTime                 | 13.2       |
| LossAfter               | 3.41966    |
| LossBefore              | 3.65604    |
| MaxReturn               | 3.22e+03   |
| MeanKL                  | 0.00977622 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 285        |
| NumTrajs                | 7          |
| Perplexity              | 6.02084    |
| PolicyExecTime          | 0.565      |
| ProcessExecTime         | 0.0649     |
| StdReturn               | 1.09e+03   |
| Time                    | 1.26e+04   |
| dLoss                   | 0.236378   |
----------------------------------------
itr #919 | 
Mem: 742.515625
Obtaining samples...
Obtaining samples for iteration 919...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5392, #subsample_inputs: 5392
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.677      |
| AbsLearnSignalNew       | 0.677      |
| AbsLearningOld          | 0.677      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 50.3995    |
| AveragePolicyStd        | 0.441691   |
| AverageReturn           | 2.39e+03   |
| Entropy                 | 1.78971    |
| EnvExecTime             | 2.43       |
| ExplainedVariance       | 0.81       |
| Iteration               | 919        |
| ItrTime                 | 14         |
| LossAfter               | 0.247225   |
| LossBefore              | 0.273687   |
| MaxReturn               | 3.17e+03   |
| MeanKL                  | 0.00645793 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.27e+03   |
| NumTrajs                | 7          |
| Perplexity              | 5.98774    |
| PolicyExecTime          | 0.613      |
| ProcessExecTime         | 0.0683     |
| StdReturn               | 738        |
| Time                    | 1.26e+04   |
| dLoss                   | 0.0264614  |
----------------------------------------
itr #920 | 
Mem: 742.515625
Obtaining samples...
Obtaining samples for iteration 920...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5237, #subsample_inputs: 5237
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.661      |
| AbsLearnSignalNew       | 0.661      |
| AbsLearningOld          | 0.661      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 55.5468    |
| AveragePolicyStd        | 0.439994   |
| AverageReturn           | 1.87e+03   |
| Entropy                 | 1.77897    |
| EnvExecTime             | 2.04       |
| ExplainedVariance       | 0.803      |
| Iteration               | 920        |
| ItrTime                 | 13.2       |
| LossAfter               | -1.58589   |
| LossBefore              | -1.56072   |
| MaxReturn               | 3.16e+03   |
| MeanKL                  | 0.00651557 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 870        |
| NumTrajs                | 9          |
| Perplexity              | 5.92376    |
| PolicyExecTime          | 0.524      |
| ProcessExecTime         | 0.0588     |
| StdReturn               | 894        |
| Time                    | 1.26e+04   |
| dLoss                   | 0.0251669  |
----------------------------------------
itr #921 | 
Mem: 742.515625
Obtaining samples...
Obtaining samples for iteration 921...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5101, #subsample_inputs: 5101
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.688      |
| AbsLearnSignalNew       | 0.688      |
| AbsLearningOld          | 0.688      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 50.801     |
| AveragePolicyStd        | 0.439931   |
| AverageReturn           | 2.05e+03   |
| Entropy                 | 1.77824    |
| EnvExecTime             | 2.09       |
| ExplainedVariance       | 0.793      |
| Iteration               | 921        |
| ItrTime                 | 13.1       |
| LossAfter               | 0.80764    |
| LossBefore              | 0.835397   |
| MaxReturn               | 3.34e+03   |
| MeanKL                  | 0.00998714 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 526        |
| NumTrajs                | 8          |
| Perplexity              | 5.91942    |
| PolicyExecTime          | 0.526      |
| ProcessExecTime         | 0.0643     |
| StdReturn               | 1.16e+03   |
| Time                    | 1.26e+04   |
| dLoss                   | 0.027757   |
----------------------------------------
itr #922 | 
Mem: 742.515625
Obtaining samples...
Obtaining samples for iteration 922...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5283, #subsample_inputs: 5283
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.59       |
| AbsLearnSignalNew       | 0.59       |
| AbsLearningOld          | 0.59       |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 63.7796    |
| AveragePolicyStd        | 0.440112   |
| AverageReturn           | 1.93e+03   |
| Entropy                 | 1.77988    |
| EnvExecTime             | 2.1        |
| ExplainedVariance       | 0.656      |
| Iteration               | 922        |
| ItrTime                 | 13.4       |
| LossAfter               | -3.06043   |
| LossBefore              | -3.02747   |
| MaxReturn               | 3.13e+03   |
| MeanKL                  | 0.00656459 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 811        |
| NumTrajs                | 9          |
| Perplexity              | 5.92915    |
| PolicyExecTime          | 0.534      |
| ProcessExecTime         | 0.0615     |
| StdReturn               | 704        |
| Time                    | 1.26e+04   |
| dLoss                   | 0.0329564  |
----------------------------------------
itr #923 | 
Mem: 742.515625
Obtaining samples...
Obtaining samples for iteration 923...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5130, #subsample_inputs: 5130
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.733      |
| AbsLearnSignalNew       | 0.733      |
| AbsLearningOld          | 0.733      |
| AverageDiscountedReturn | 253        |
| AveragePhiLoss          | 56.5639    |
| AveragePolicyStd        | 0.439555   |
| AverageReturn           | 1.56e+03   |
| Entropy                 | 1.7772     |
| EnvExecTime             | 2.12       |
| ExplainedVariance       | 0.86       |
| Iteration               | 923        |
| ItrTime                 | 13.1       |
| LossAfter               | 0.638193   |
| LossBefore              | 0.665458   |
| MaxReturn               | 2.69e+03   |
| MeanKL                  | 0.00660876 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1e+03      |
| NumTrajs                | 11         |
| Perplexity              | 5.91327    |
| PolicyExecTime          | 0.538      |
| ProcessExecTime         | 0.0607     |
| StdReturn               | 519        |
| Time                    | 1.26e+04   |
| dLoss                   | 0.0272648  |
----------------------------------------
itr #924 | 
Mem: 742.515625
Obtaining samples...
Obtaining samples for iteration 924...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5383, #subsample_inputs: 5383
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.614      |
| AbsLearnSignalNew       | 0.614      |
| AbsLearningOld          | 0.614      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 56.5856    |
| AveragePolicyStd        | 0.438647   |
| AverageReturn           | 2.52e+03   |
| Entropy                 | 1.76993    |
| EnvExecTime             | 2.16       |
| ExplainedVariance       | 0.733      |
| Iteration               | 924        |
| ItrTime                 | 13.6       |
| LossAfter               | 0.577814   |
| LossBefore              | 0.604254   |
| MaxReturn               | 3.12e+03   |
| MeanKL                  | 0.00989993 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.44e+03   |
| NumTrajs                | 7          |
| Perplexity              | 5.87042    |
| PolicyExecTime          | 0.539      |
| ProcessExecTime         | 0.0639     |
| StdReturn               | 630        |
| Time                    | 1.26e+04   |
| dLoss                   | 0.0264393  |
----------------------------------------
itr #925 | 
Mem: 742.515625
Obtaining samples...
Obtaining samples for iteration 925...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5495, #subsample_inputs: 5495
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.659      |
| AbsLearnSignalNew       | 0.659      |
| AbsLearningOld          | 0.659      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 55.4973    |
| AveragePolicyStd        | 0.438093   |
| AverageReturn           | 2.01e+03   |
| Entropy                 | 1.76593    |
| EnvExecTime             | 2.49       |
| ExplainedVariance       | 0.777      |
| Iteration               | 925        |
| ItrTime                 | 14.1       |
| LossAfter               | 1.34048    |
| LossBefore              | 1.37111    |
| MaxReturn               | 3.26e+03   |
| MeanKL                  | 0.00642088 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 776        |
| NumTrajs                | 9          |
| Perplexity              | 5.84698    |
| PolicyExecTime          | 0.626      |
| ProcessExecTime         | 0.0702     |
| StdReturn               | 889        |
| Time                    | 1.27e+04   |
| dLoss                   | 0.0306325  |
----------------------------------------
itr #926 | 
Mem: 742.515625
Obtaining samples...
Obtaining samples for iteration 926...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5096, #subsample_inputs: 5096
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.694      |
| AbsLearnSignalNew       | 0.694      |
| AbsLearningOld          | 0.693      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 57.102     |
| AveragePolicyStd        | 0.438009   |
| AverageReturn           | 2.1e+03    |
| Entropy                 | 1.76485    |
| EnvExecTime             | 2.01       |
| ExplainedVariance       | 0.794      |
| Iteration               | 926        |
| ItrTime                 | 12.9       |
| LossAfter               | 0.616112   |
| LossBefore              | 0.649879   |
| MaxReturn               | 3.2e+03    |
| MeanKL                  | 0.00989271 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 910        |
| NumTrajs                | 8          |
| Perplexity              | 5.84068    |
| PolicyExecTime          | 0.514      |
| ProcessExecTime         | 0.0577     |
| StdReturn               | 811        |
| Time                    | 1.27e+04   |
| dLoss                   | 0.0337667  |
----------------------------------------
itr #927 | 
Mem: 742.515625
Obtaining samples...
Obtaining samples for iteration 927...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5259, #subsample_inputs: 5259
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.691      |
| AbsLearnSignalNew       | 0.691      |
| AbsLearningOld          | 0.69       |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 59.5963    |
| AveragePolicyStd        | 0.438967   |
| AverageReturn           | 1.46e+03   |
| Entropy                 | 1.77113    |
| EnvExecTime             | 2.05       |
| ExplainedVariance       | 0.788      |
| Iteration               | 927        |
| ItrTime                 | 13.3       |
| LossAfter               | 0.826689   |
| LossBefore              | 0.85225    |
| MaxReturn               | 3.08e+03   |
| MeanKL                  | 0.00644753 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 946        |
| NumTrajs                | 12         |
| Perplexity              | 5.87748    |
| PolicyExecTime          | 0.519      |
| ProcessExecTime         | 0.06       |
| StdReturn               | 619        |
| Time                    | 1.27e+04   |
| dLoss                   | 0.0255605  |
----------------------------------------
itr #928 | 
Mem: 742.515625
Obtaining samples...
Obtaining samples for iteration 928...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5074, #subsample_inputs: 5074
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.73       |
| AbsLearnSignalNew       | 0.73       |
| AbsLearningOld          | 0.73       |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 50.985     |
| AveragePolicyStd        | 0.438902   |
| AverageReturn           | 1.19e+03   |
| Entropy                 | 1.77067    |
| EnvExecTime             | 2.18       |
| ExplainedVariance       | 0.862      |
| Iteration               | 928        |
| ItrTime                 | 13.1       |
| LossAfter               | -0.056694  |
| LossBefore              | -0.0274291 |
| MaxReturn               | 2.33e+03   |
| MeanKL                  | 0.00984001 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 643        |
| NumTrajs                | 14         |
| Perplexity              | 5.87479    |
| PolicyExecTime          | 0.549      |
| ProcessExecTime         | 0.0622     |
| StdReturn               | 445        |
| Time                    | 1.27e+04   |
| dLoss                   | 0.0292649  |
----------------------------------------
itr #929 | 
Mem: 742.515625
Obtaining samples...
Obtaining samples for iteration 929...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5049, #subsample_inputs: 5049
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.729      |
| AbsLearnSignalNew       | 0.729      |
| AbsLearningOld          | 0.729      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 56.2087    |
| AveragePolicyStd        | 0.439775   |
| AverageReturn           | 1.27e+03   |
| Entropy                 | 1.77627    |
| EnvExecTime             | 2.1        |
| ExplainedVariance       | 0.797      |
| Iteration               | 929        |
| ItrTime                 | 12.9       |
| LossAfter               | 1.43335    |
| LossBefore              | 1.46199    |
| MaxReturn               | 3.23e+03   |
| MeanKL                  | 0.00641037 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 476        |
| NumTrajs                | 13         |
| Perplexity              | 5.90776    |
| PolicyExecTime          | 0.536      |
| ProcessExecTime         | 0.0593     |
| StdReturn               | 831        |
| Time                    | 1.27e+04   |
| dLoss                   | 0.028634   |
----------------------------------------
itr #930 | 
Mem: 742.515625
Obtaining samples...
Obtaining samples for iteration 930...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5120, #subsample_inputs: 5120
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.662      |
| AbsLearnSignalNew       | 0.662      |
| AbsLearningOld          | 0.662      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 53.8705    |
| AveragePolicyStd        | 0.439652   |
| AverageReturn           | 1.43e+03   |
| Entropy                 | 1.77432    |
| EnvExecTime             | 2.16       |
| ExplainedVariance       | 0.781      |
| Iteration               | 930        |
| ItrTime                 | 13.1       |
| LossAfter               | -1.55555   |
| LossBefore              | -1.51969   |
| MaxReturn               | 3.1e+03    |
| MeanKL                  | 0.00642376 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 808        |
| NumTrajs                | 12         |
| Perplexity              | 5.89628    |
| PolicyExecTime          | 0.544      |
| ProcessExecTime         | 0.0611     |
| StdReturn               | 643        |
| Time                    | 1.27e+04   |
| dLoss                   | 0.0358626  |
----------------------------------------
itr #931 | 
Mem: 742.515625
Obtaining samples...
Obtaining samples for iteration 931...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5188, #subsample_inputs: 5188
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.742      |
| AbsLearnSignalNew       | 0.742      |
| AbsLearningOld          | 0.742      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 54.9839    |
| AveragePolicyStd        | 0.438599   |
| AverageReturn           | 1.09e+03   |
| Entropy                 | 1.76719    |
| EnvExecTime             | 2.21       |
| ExplainedVariance       | 0.848      |
| Iteration               | 931        |
| ItrTime                 | 13.3       |
| LossAfter               | -1.97316   |
| LossBefore              | -1.94024   |
| MaxReturn               | 2.37e+03   |
| MeanKL                  | 0.00996978 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 631        |
| NumTrajs                | 16         |
| Perplexity              | 5.85441    |
| PolicyExecTime          | 0.56       |
| ProcessExecTime         | 0.0634     |
| StdReturn               | 517        |
| Time                    | 1.27e+04   |
| dLoss                   | 0.0329213  |
----------------------------------------
itr #932 | 
Mem: 742.515625
Obtaining samples...
Obtaining samples for iteration 932...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5069, #subsample_inputs: 5069
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.655      |
| AbsLearnSignalNew       | 0.655      |
| AbsLearningOld          | 0.655      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 64.5151    |
| AveragePolicyStd        | 0.438563   |
| AverageReturn           | 1.67e+03   |
| Entropy                 | 1.76654    |
| EnvExecTime             | 2.24       |
| ExplainedVariance       | 0.561      |
| Iteration               | 932        |
| ItrTime                 | 13.2       |
| LossAfter               | -0.605629  |
| LossBefore              | -0.579607  |
| MaxReturn               | 3.23e+03   |
| MeanKL                  | 0.00657486 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 794        |
| NumTrajs                | 10         |
| Perplexity              | 5.85056    |
| PolicyExecTime          | 0.559      |
| ProcessExecTime         | 0.0626     |
| StdReturn               | 796        |
| Time                    | 1.27e+04   |
| dLoss                   | 0.0260217  |
----------------------------------------
itr #933 | 
Mem: 742.515625
Obtaining samples...
Obtaining samples for iteration 933...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5440, #subsample_inputs: 5440
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.731      |
| AbsLearnSignalNew       | 0.731      |
| AbsLearningOld          | 0.731      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 60.6267    |
| AveragePolicyStd        | 0.438894   |
| AverageReturn           | 2.16e+03   |
| Entropy                 | 1.76793    |
| EnvExecTime             | 2.26       |
| ExplainedVariance       | 0.864      |
| Iteration               | 933        |
| ItrTime                 | 13.8       |
| LossAfter               | 0.0253332  |
| LossBefore              | 0.054389   |
| MaxReturn               | 3.09e+03   |
| MeanKL                  | 0.00999884 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 718        |
| NumTrajs                | 8          |
| Perplexity              | 5.85869    |
| PolicyExecTime          | 0.578      |
| ProcessExecTime         | 0.0646     |
| StdReturn               | 913        |
| Time                    | 1.28e+04   |
| dLoss                   | 0.0290558  |
----------------------------------------
itr #934 | 
Mem: 742.515625
Obtaining samples...
Obtaining samples for iteration 934...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5759, #subsample_inputs: 5759
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.708      |
| AbsLearnSignalNew       | 0.708      |
| AbsLearningOld          | 0.708      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 67.379     |
| AveragePolicyStd        | 0.437701   |
| AverageReturn           | 2.25e+03   |
| Entropy                 | 1.75954    |
| EnvExecTime             | 2.06       |
| ExplainedVariance       | 0.878      |
| Iteration               | 934        |
| ItrTime                 | 14         |
| LossAfter               | -0.352271  |
| LossBefore              | -0.32349   |
| MaxReturn               | 3.21e+03   |
| MeanKL                  | 0.00995563 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 784        |
| NumTrajs                | 8          |
| Perplexity              | 5.80979    |
| PolicyExecTime          | 0.521      |
| ProcessExecTime         | 0.0622     |
| StdReturn               | 1.09e+03   |
| Time                    | 1.28e+04   |
| dLoss                   | 0.0287806  |
----------------------------------------
itr #935 | 
Mem: 742.515625
Obtaining samples...
Obtaining samples for iteration 935...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5211, #subsample_inputs: 5211
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.711      |
| AbsLearnSignalNew       | 0.711      |
| AbsLearningOld          | 0.71       |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 55.9686    |
| AveragePolicyStd        | 0.43561    |
| AverageReturn           | 1.67e+03   |
| Entropy                 | 1.7453     |
| EnvExecTime             | 2.1        |
| ExplainedVariance       | 0.846      |
| Iteration               | 935        |
| ItrTime                 | 13.3       |
| LossAfter               | 1.18256    |
| LossBefore              | 1.21169    |
| MaxReturn               | 3.17e+03   |
| MeanKL                  | 0.00640414 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 688        |
| NumTrajs                | 10         |
| Perplexity              | 5.72763    |
| PolicyExecTime          | 0.526      |
| ProcessExecTime         | 0.0601     |
| StdReturn               | 1.01e+03   |
| Time                    | 1.28e+04   |
| dLoss                   | 0.0291282  |
----------------------------------------
itr #936 | 
Mem: 742.515625
Obtaining samples...
Obtaining samples for iteration 936...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5138, #subsample_inputs: 5138
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.628      |
| AbsLearnSignalNew       | 0.628      |
| AbsLearningOld          | 0.628      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 63.2268    |
| AveragePolicyStd        | 0.43515    |
| AverageReturn           | 1.64e+03   |
| Entropy                 | 1.74154    |
| EnvExecTime             | 2.17       |
| ExplainedVariance       | 0.654      |
| Iteration               | 936        |
| ItrTime                 | 13.2       |
| LossAfter               | -3.25818   |
| LossBefore              | -3.23028   |
| MaxReturn               | 3.16e+03   |
| MeanKL                  | 0.00644187 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 537        |
| NumTrajs                | 10         |
| Perplexity              | 5.7061     |
| PolicyExecTime          | 0.551      |
| ProcessExecTime         | 0.061      |
| StdReturn               | 1.03e+03   |
| Time                    | 1.28e+04   |
| dLoss                   | 0.0278995  |
----------------------------------------
itr #937 | 
Mem: 742.515625
Obtaining samples...
Obtaining samples for iteration 937...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5000, #subsample_inputs: 5000
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.679      |
| AbsLearnSignalNew       | 0.679      |
| AbsLearningOld          | 0.679      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 64.8028    |
| AveragePolicyStd        | 0.435058   |
| AverageReturn           | 3.1e+03    |
| Entropy                 | 1.74121    |
| EnvExecTime             | 1.59       |
| ExplainedVariance       | 0.808      |
| Iteration               | 937        |
| ItrTime                 | 12.2       |
| LossAfter               | 1.35474    |
| LossBefore              | 1.37702    |
| MaxReturn               | 3.17e+03   |
| MeanKL                  | 0.00646493 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 3.05e+03   |
| NumTrajs                | 5          |
| Perplexity              | 5.70425    |
| PolicyExecTime          | 0.406      |
| ProcessExecTime         | 0.0521     |
| StdReturn               | 43.2       |
| Time                    | 1.28e+04   |
| dLoss                   | 0.02228    |
----------------------------------------
itr #938 | 
Mem: 742.515625
Obtaining samples...
Obtaining samples for iteration 938...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5692, #subsample_inputs: 5692
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.437     |
| AbsLearnSignalNew       | 0.437     |
| AbsLearningOld          | 0.436     |
| AverageDiscountedReturn | 249       |
| AveragePhiLoss          | 58.7028   |
| AveragePolicyStd        | 0.433637  |
| AverageReturn           | 2.96e+03  |
| Entropy                 | 1.73169   |
| EnvExecTime             | 2.66      |
| ExplainedVariance       | 0.808     |
| Iteration               | 938       |
| ItrTime                 | 14.6      |
| LossAfter               | -2.37131  |
| LossBefore              | -2.34261  |
| MaxReturn               | 3.14e+03  |
| MeanKL                  | 0.0099819 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 2.3e+03   |
| NumTrajs                | 6         |
| Perplexity              | 5.65017   |
| PolicyExecTime          | 0.682     |
| ProcessExecTime         | 0.0746    |
| StdReturn               | 296       |
| Time                    | 1.28e+04  |
| dLoss                   | 0.0287008 |
---------------------------------------
itr #939 | 
Mem: 742.515625
Obtaining samples...
Obtaining samples for iteration 939...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5093, #subsample_inputs: 5093
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.139      |
| AbsLearnSignalNew       | 0.139      |
| AbsLearningOld          | 0.139      |
| AverageDiscountedReturn | 248        |
| AveragePhiLoss          | 29.2264    |
| AveragePolicyStd        | 0.433488   |
| AverageReturn           | 1.67e+03   |
| Entropy                 | 1.73032    |
| EnvExecTime             | 2.05       |
| ExplainedVariance       | -12.5      |
| Iteration               | 939        |
| ItrTime                 | 13         |
| LossAfter               | 0.416056   |
| LossBefore              | 0.500899   |
| MaxReturn               | 3.2e+03    |
| MeanKL                  | 0.00997774 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 583        |
| NumTrajs                | 10         |
| Perplexity              | 5.64244    |
| PolicyExecTime          | 0.514      |
| ProcessExecTime         | 0.0614     |
| StdReturn               | 893        |
| Time                    | 1.28e+04   |
| dLoss                   | 0.0848426  |
----------------------------------------
itr #940 | 
Mem: 742.515625
Obtaining samples...
Obtaining samples for iteration 940...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5129, #subsample_inputs: 5129
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.794      |
| AbsLearnSignalNew       | 0.794      |
| AbsLearningOld          | 0.794      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 57.6505    |
| AveragePolicyStd        | 0.43307    |
| AverageReturn           | 2.31e+03   |
| Entropy                 | 1.72695    |
| EnvExecTime             | 2.15       |
| ExplainedVariance       | 0.868      |
| Iteration               | 940        |
| ItrTime                 | 13.2       |
| LossAfter               | -0.0751751 |
| LossBefore              | -0.0456997 |
| MaxReturn               | 3.2e+03    |
| MeanKL                  | 0.00988216 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.01e+03   |
| NumTrajs                | 7          |
| Perplexity              | 5.62345    |
| PolicyExecTime          | 0.549      |
| ProcessExecTime         | 0.0608     |
| StdReturn               | 937        |
| Time                    | 1.29e+04   |
| dLoss                   | 0.0294754  |
----------------------------------------
itr #941 | 
Mem: 742.515625
Obtaining samples...
Obtaining samples for iteration 941...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5957, #subsample_inputs: 5957
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.69       |
| AbsLearnSignalNew       | 0.69       |
| AbsLearningOld          | 0.69       |
| AverageDiscountedReturn | 249        |
| AveragePhiLoss          | 58.7994    |
| AveragePolicyStd        | 0.432546   |
| AverageReturn           | 2.14e+03   |
| Entropy                 | 1.7241     |
| EnvExecTime             | 2.22       |
| ExplainedVariance       | 0.892      |
| Iteration               | 941        |
| ItrTime                 | 14.5       |
| LossAfter               | 2.57646    |
| LossBefore              | 2.60444    |
| MaxReturn               | 3.23e+03   |
| MeanKL                  | 0.00643652 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 781        |
| NumTrajs                | 9          |
| Perplexity              | 5.60749    |
| PolicyExecTime          | 0.557      |
| ProcessExecTime         | 0.0692     |
| StdReturn               | 1.06e+03   |
| Time                    | 1.29e+04   |
| dLoss                   | 0.0279841  |
----------------------------------------
itr #942 | 
Mem: 744.277344
Obtaining samples...
Obtaining samples for iteration 942...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5318, #subsample_inputs: 5318
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.683      |
| AbsLearnSignalNew       | 0.683      |
| AbsLearningOld          | 0.683      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 59.7051    |
| AveragePolicyStd        | 0.432678   |
| AverageReturn           | 1.73e+03   |
| Entropy                 | 1.72447    |
| EnvExecTime             | 2.52       |
| ExplainedVariance       | 0.85       |
| Iteration               | 942        |
| ItrTime                 | 13.9       |
| LossAfter               | 0.19211    |
| LossBefore              | 0.244263   |
| MaxReturn               | 3.24e+03   |
| MeanKL                  | 0.00650687 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 610        |
| NumTrajs                | 10         |
| Perplexity              | 5.60954    |
| PolicyExecTime          | 0.641      |
| ProcessExecTime         | 0.0698     |
| StdReturn               | 938        |
| Time                    | 1.29e+04   |
| dLoss                   | 0.0521531  |
----------------------------------------
itr #943 | 
Mem: 744.277344
Obtaining samples...
Obtaining samples for iteration 943...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5228, #subsample_inputs: 5228
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.601      |
| AbsLearnSignalNew       | 0.601      |
| AbsLearningOld          | 0.601      |
| AverageDiscountedReturn | 250        |
| AveragePhiLoss          | 63.0612    |
| AveragePolicyStd        | 0.433214   |
| AverageReturn           | 2.39e+03   |
| Entropy                 | 1.72816    |
| EnvExecTime             | 2.13       |
| ExplainedVariance       | 0.798      |
| Iteration               | 943        |
| ItrTime                 | 13.3       |
| LossAfter               | 0.762897   |
| LossBefore              | 0.798505   |
| MaxReturn               | 3.23e+03   |
| MeanKL                  | 0.00955522 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 837        |
| NumTrajs                | 7          |
| Perplexity              | 5.63026    |
| PolicyExecTime          | 0.528      |
| ProcessExecTime         | 0.0631     |
| StdReturn               | 952        |
| Time                    | 1.29e+04   |
| dLoss                   | 0.0356085  |
----------------------------------------
itr #944 | 
Mem: 744.277344
Obtaining samples...
Obtaining samples for iteration 944...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5908, #subsample_inputs: 5908
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.697      |
| AbsLearnSignalNew       | 0.697      |
| AbsLearningOld          | 0.697      |
| AverageDiscountedReturn | 252        |
| AveragePhiLoss          | 53.3957    |
| AveragePolicyStd        | 0.432532   |
| AverageReturn           | 2.35e+03   |
| Entropy                 | 1.72369    |
| EnvExecTime             | 2.45       |
| ExplainedVariance       | 0.871      |
| Iteration               | 944        |
| ItrTime                 | 14.8       |
| LossAfter               | 0.125701   |
| LossBefore              | 0.15221    |
| MaxReturn               | 3.15e+03   |
| MeanKL                  | 0.00999648 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.22e+03   |
| NumTrajs                | 8          |
| Perplexity              | 5.60515    |
| PolicyExecTime          | 0.621      |
| ProcessExecTime         | 0.0711     |
| StdReturn               | 776        |
| Time                    | 1.29e+04   |
| dLoss                   | 0.026509   |
----------------------------------------
itr #945 | 
Mem: 744.277344
Obtaining samples...
Obtaining samples for iteration 945...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5985, #subsample_inputs: 5985
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.685      |
| AbsLearnSignalNew       | 0.685      |
| AbsLearningOld          | 0.685      |
| AverageDiscountedReturn | 254        |
| AveragePhiLoss          | 58.9426    |
| AveragePolicyStd        | 0.433242   |
| AverageReturn           | 1.96e+03   |
| Entropy                 | 1.7285     |
| EnvExecTime             | 2.33       |
| ExplainedVariance       | 0.891      |
| Iteration               | 945        |
| ItrTime                 | 14.7       |
| LossAfter               | -1.09345   |
| LossBefore              | -1.06073   |
| MaxReturn               | 3.17e+03   |
| MeanKL                  | 0.00992123 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 878        |
| NumTrajs                | 10         |
| Perplexity              | 5.63218    |
| PolicyExecTime          | 0.589      |
| ProcessExecTime         | 0.0703     |
| StdReturn               | 868        |
| Time                    | 1.29e+04   |
| dLoss                   | 0.0327147  |
----------------------------------------
itr #946 | 
Mem: 744.277344
Obtaining samples...
Obtaining samples for iteration 946...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5363, #subsample_inputs: 5363
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.704      |
| AbsLearnSignalNew       | 0.704      |
| AbsLearningOld          | 0.704      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 59.8786    |
| AveragePolicyStd        | 0.43379    |
| AverageReturn           | 1.73e+03   |
| Entropy                 | 1.73137    |
| EnvExecTime             | 1.95       |
| ExplainedVariance       | 0.848      |
| Iteration               | 946        |
| ItrTime                 | 13.4       |
| LossAfter               | 0.862384   |
| LossBefore              | 0.899415   |
| MaxReturn               | 3.3e+03    |
| MeanKL                  | 0.00997553 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 556        |
| NumTrajs                | 10         |
| Perplexity              | 5.64836    |
| PolicyExecTime          | 0.5        |
| ProcessExecTime         | 0.0583     |
| StdReturn               | 1.05e+03   |
| Time                    | 1.29e+04   |
| dLoss                   | 0.0370312  |
----------------------------------------
itr #947 | 
Mem: 744.277344
Obtaining samples...
Obtaining samples for iteration 947...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5648, #subsample_inputs: 5648
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.672      |
| AbsLearnSignalNew       | 0.672      |
| AbsLearningOld          | 0.672      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 58.4654    |
| AveragePolicyStd        | 0.4334     |
| AverageReturn           | 1.88e+03   |
| Entropy                 | 1.72968    |
| EnvExecTime             | 2.44       |
| ExplainedVariance       | 0.817      |
| Iteration               | 947        |
| ItrTime                 | 14.3       |
| LossAfter               | -1.28241   |
| LossBefore              | -1.25518   |
| MaxReturn               | 2.94e+03   |
| MeanKL                  | 0.00642026 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 990        |
| NumTrajs                | 10         |
| Perplexity              | 5.63884    |
| PolicyExecTime          | 0.621      |
| ProcessExecTime         | 0.0707     |
| StdReturn               | 697        |
| Time                    | 1.3e+04    |
| dLoss                   | 0.0272278  |
----------------------------------------
itr #948 | 
Mem: 744.277344
Obtaining samples...
Obtaining samples for iteration 948...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5032, #subsample_inputs: 5032
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.682      |
| AbsLearnSignalNew       | 0.682      |
| AbsLearningOld          | 0.682      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 55.4981    |
| AveragePolicyStd        | 0.432996   |
| AverageReturn           | 1.51e+03   |
| Entropy                 | 1.72658    |
| EnvExecTime             | 1.93       |
| ExplainedVariance       | 0.833      |
| Iteration               | 948        |
| ItrTime                 | 12.7       |
| LossAfter               | -1.41467   |
| LossBefore              | -1.37548   |
| MaxReturn               | 3.2e+03    |
| MeanKL                  | 0.00997212 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 546        |
| NumTrajs                | 11         |
| Perplexity              | 5.62138    |
| PolicyExecTime          | 0.487      |
| ProcessExecTime         | 0.0576     |
| StdReturn               | 727        |
| Time                    | 1.3e+04    |
| dLoss                   | 0.0391958  |
----------------------------------------
itr #949 | 
Mem: 744.277344
Obtaining samples...
Obtaining samples for iteration 949...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5835, #subsample_inputs: 5835
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.716      |
| AbsLearnSignalNew       | 0.716      |
| AbsLearningOld          | 0.716      |
| AverageDiscountedReturn | 251        |
| AveragePhiLoss          | 57.1867    |
| AveragePolicyStd        | 0.433703   |
| AverageReturn           | 2.09e+03   |
| Entropy                 | 1.73083    |
| EnvExecTime             | 2.59       |
| ExplainedVariance       | 0.884      |
| Iteration               | 949        |
| ItrTime                 | 14.7       |
| LossAfter               | -2.42011   |
| LossBefore              | -2.39583   |
| MaxReturn               | 3.18e+03   |
| MeanKL                  | 0.00645065 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 736        |
| NumTrajs                | 9          |
| Perplexity              | 5.64534    |
| PolicyExecTime          | 0.65       |
| ProcessExecTime         | 0.074      |
| StdReturn               | 1.03e+03   |
| Time                    | 1.3e+04    |
| dLoss                   | 0.0242801  |
----------------------------------------
itr #950 | 
Mem: 744.277344
Obtaining samples...
Obtaining samples for iteration 950...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5151, #subsample_inputs: 5151
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.751      |
| AbsLearnSignalNew       | 0.751      |
| AbsLearningOld          | 0.751      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 61.8378    |
| AveragePolicyStd        | 0.432768   |
| AverageReturn           | 1.82e+03   |
| Entropy                 | 1.72416    |
| EnvExecTime             | 1.98       |
| ExplainedVariance       | 0.84       |
| Iteration               | 950        |
| ItrTime                 | 13         |
| LossAfter               | 0.823402   |
| LossBefore              | 0.847982   |
| MaxReturn               | 3.14e+03   |
| MeanKL                  | 0.00642992 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 888        |
| NumTrajs                | 9          |
| Perplexity              | 5.60784    |
| PolicyExecTime          | 0.507      |
| ProcessExecTime         | 0.0599     |
| StdReturn               | 950        |
| Time                    | 1.3e+04    |
| dLoss                   | 0.0245803  |
----------------------------------------
itr #951 | 
Mem: 744.277344
Obtaining samples...
Obtaining samples for iteration 951...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5447, #subsample_inputs: 5447
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.669      |
| AbsLearnSignalNew       | 0.669      |
| AbsLearningOld          | 0.669      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 60.4871    |
| AveragePolicyStd        | 0.43278    |
| AverageReturn           | 2.88e+03   |
| Entropy                 | 1.7235     |
| EnvExecTime             | 2.9        |
| ExplainedVariance       | 0.903      |
| Iteration               | 951        |
| ItrTime                 | 14.7       |
| LossAfter               | 2.00609    |
| LossBefore              | 2.03578    |
| MaxReturn               | 3.18e+03   |
| MeanKL                  | 0.00655058 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 2.27e+03   |
| NumTrajs                | 6          |
| Perplexity              | 5.60412    |
| PolicyExecTime          | 0.725      |
| ProcessExecTime         | 0.0812     |
| StdReturn               | 364        |
| Time                    | 1.3e+04    |
| dLoss                   | 0.0296872  |
----------------------------------------
itr #952 | 
Mem: 744.277344
Obtaining samples...
Obtaining samples for iteration 952...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5078, #subsample_inputs: 5078
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.585      |
| AbsLearnSignalNew       | 0.585      |
| AbsLearningOld          | 0.586      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 48.3463    |
| AveragePolicyStd        | 0.432613   |
| AverageReturn           | 2.61e+03   |
| Entropy                 | 1.72156    |
| EnvExecTime             | 2.08       |
| ExplainedVariance       | 0.897      |
| Iteration               | 952        |
| ItrTime                 | 13         |
| LossAfter               | 0.935224   |
| LossBefore              | 0.96089    |
| MaxReturn               | 3.13e+03   |
| MeanKL                  | 0.00986488 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.03e+03   |
| NumTrajs                | 6          |
| Perplexity              | 5.59323    |
| PolicyExecTime          | 0.533      |
| ProcessExecTime         | 0.0606     |
| StdReturn               | 758        |
| Time                    | 1.3e+04    |
| dLoss                   | 0.0256653  |
----------------------------------------
itr #953 | 
Mem: 744.277344
Obtaining samples...
Obtaining samples for iteration 953...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5186, #subsample_inputs: 5186
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.631      |
| AbsLearnSignalNew       | 0.631      |
| AbsLearningOld          | 0.631      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 55.9694    |
| AveragePolicyStd        | 0.432786   |
| AverageReturn           | 2.33e+03   |
| Entropy                 | 1.7224     |
| EnvExecTime             | 1.93       |
| ExplainedVariance       | 0.773      |
| Iteration               | 953        |
| ItrTime                 | 12.9       |
| LossAfter               | 0.433485   |
| LossBefore              | 0.469052   |
| MaxReturn               | 3.1e+03    |
| MeanKL                  | 0.00984682 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.19e+03   |
| NumTrajs                | 7          |
| Perplexity              | 5.59797    |
| PolicyExecTime          | 0.493      |
| ProcessExecTime         | 0.0579     |
| StdReturn               | 820        |
| Time                    | 1.3e+04    |
| dLoss                   | 0.0355672  |
----------------------------------------
itr #954 | 
Mem: 744.277344
Obtaining samples...
Obtaining samples for iteration 954...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
