output_formats ['stdout', 'log', 'json', 'tensorboard']
Logging to exp_ec2/cfpo-Hopper-v1-1-batch_size=5000-learning_rate=0.001-max_length=1000-pf_phi_lam_option=ones-pf_iter=400-baseline=linear-pf_lr=0.001-pf_cls=Qprop-seed=1-use_gradient_vr=True-vs_form=None-pf_hidden_sizes=100x100
Setting seed to 1
Setting seed to 2
Setting seed to 3
Setting seed to 4
observation space: Box(11,)
action space: Box(3,)
use_gradient_vr is True
pf_learning_rate is 0.001
observation space: Box(11,)
action space: Box(3,)
observation space: Box(11,)
action space: Box(3,)
observation space: Box(11,)
action space: Box(3,)
observation space: Box(11,)
action space: Box(3,)
observation space: Box(11,)
action space: Box(3,)
qf is None
using gradient as variance reduction
parameter of phi Phinet/obs_h0/W:0, shape=(11, 100)
parameter of phi Phinet/obs_h0/b:0, shape=(100,)
parameter of phi Phinet/act_h0/W:0, shape=(3, 100)
parameter of phi Phinet/act_h0/b:0, shape=(100,)
parameter of phi Phinet/h1/W:0, shape=(100, 100)
parameter of phi Phinet/h1/b:0, shape=(100,)
parameter of phi Phinet/output/W:0, shape=(100, 1)
parameter of phi Phinet/output/b:0, shape=(1,)
No checkpoint exp_ec2/cfpo-Hopper-v1-1-batch_size=5000-learning_rate=0.001-max_length=1000-pf_phi_lam_option=ones-pf_iter=400-baseline=linear-pf_lr=0.001-pf_cls=Qprop-seed=1-use_gradient_vr=True-vs_form=None-pf_hidden_sizes=100x100/params.chk
itr #0 | 
Mem: 269.058594
Obtaining samples...
Obtaining samples for iteration 0...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5004, #subsample_inputs: 5004
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.854      |
| AbsLearnSignalNew       | 0.854      |
| AbsLearningOld          | 0.854      |
| AverageDiscountedReturn | 12.5       |
| AveragePhiLoss          | 4.04078    |
| AveragePolicyStd        | 1.0        |
| AverageReturn           | 14.1       |
| Entropy                 | 4.25682    |
| EnvExecTime             | 1.82       |
| ExplainedVariance       | 4.01e-11   |
| Iteration               | 0          |
| ItrTime                 | 8.04       |
| LossAfter               | 0.230088   |
| LossBefore              | 0.276173   |
| MaxReturn               | 83.3       |
| MeanKL                  | 0.00943645 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 0.563      |
| NumTrajs                | 335        |
| Perplexity              | 70.5848    |
| PolicyExecTime          | 0.431      |
| ProcessExecTime         | 0.0657     |
| StdReturn               | 18.9       |
| Time                    | 8.04       |
| dLoss                   | 0.0460856  |
----------------------------------------
itr #1 | 
Mem: 583.296875
Obtaining samples...
Obtaining samples for iteration 1...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5026, #subsample_inputs: 5026
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.735      |
| AbsLearnSignalNew       | 0.735      |
| AbsLearningOld          | 0.734      |
| AverageDiscountedReturn | 18.6       |
| AveragePhiLoss          | 3.77771    |
| AveragePolicyStd        | 1.00161    |
| AverageReturn           | 21.4       |
| Entropy                 | 4.26161    |
| EnvExecTime             | 1.86       |
| ExplainedVariance       | 0.592      |
| Iteration               | 1          |
| ItrTime                 | 7.93       |
| LossAfter               | 0.694726   |
| LossBefore              | 0.771453   |
| MaxReturn               | 66.7       |
| MeanKL                  | 0.00979315 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.32       |
| NumTrajs                | 278        |
| Perplexity              | 70.924     |
| PolicyExecTime          | 0.438      |
| ProcessExecTime         | 0.0662     |
| StdReturn               | 22.4       |
| Time                    | 16         |
| dLoss                   | 0.0767267  |
----------------------------------------
itr #2 | 
Mem: 596.097656
Obtaining samples...
Obtaining samples for iteration 2...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5000, #subsample_inputs: 5000
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.775      |
| AbsLearnSignalNew       | 0.775      |
| AbsLearningOld          | 0.774      |
| AverageDiscountedReturn | 27.3       |
| AveragePhiLoss          | 4.11448    |
| AveragePolicyStd        | 0.99891    |
| AverageReturn           | 31.9       |
| Entropy                 | 4.25349    |
| EnvExecTime             | 1.77       |
| ExplainedVariance       | 0.567      |
| Iteration               | 2          |
| ItrTime                 | 7.76       |
| LossAfter               | -0.127322  |
| LossBefore              | -0.0621719 |
| MaxReturn               | 76.5       |
| MeanKL                  | 0.00990317 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.94       |
| NumTrajs                | 219        |
| Perplexity              | 70.3505    |
| PolicyExecTime          | 0.424      |
| ProcessExecTime         | 0.0608     |
| StdReturn               | 24.1       |
| Time                    | 23.9       |
| dLoss                   | 0.0651499  |
----------------------------------------
itr #3 | 
Mem: 605.867188
Obtaining samples...
Obtaining samples for iteration 3...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5013, #subsample_inputs: 5013
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.732      |
| AbsLearnSignalNew       | 0.732      |
| AbsLearningOld          | 0.732      |
| AverageDiscountedReturn | 37.5       |
| AveragePhiLoss          | 4.27232    |
| AveragePolicyStd        | 0.994691   |
| AverageReturn           | 44.3       |
| Entropy                 | 4.24077    |
| EnvExecTime             | 1.77       |
| ExplainedVariance       | 0.601      |
| Iteration               | 3          |
| ItrTime                 | 7.78       |
| LossAfter               | 0.78423    |
| LossBefore              | 0.828925   |
| MaxReturn               | 108        |
| MeanKL                  | 0.00641957 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 2.53       |
| NumTrajs                | 176        |
| Perplexity              | 69.4612    |
| PolicyExecTime          | 0.43       |
| ProcessExecTime         | 0.0602     |
| StdReturn               | 21.9       |
| Time                    | 31.6       |
| dLoss                   | 0.0446947  |
----------------------------------------
itr #4 | 
Mem: 608.183594
Obtaining samples...
Obtaining samples for iteration 4...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5021, #subsample_inputs: 5021
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.722      |
| AbsLearnSignalNew       | 0.722      |
| AbsLearningOld          | 0.722      |
| AverageDiscountedReturn | 41.7       |
| AveragePhiLoss          | 4.52001    |
| AveragePolicyStd        | 0.992935   |
| AverageReturn           | 49.3       |
| Entropy                 | 4.23545    |
| EnvExecTime             | 1.71       |
| ExplainedVariance       | 0.687      |
| Iteration               | 4          |
| ItrTime                 | 7.73       |
| LossAfter               | -1.03597   |
| LossBefore              | -0.998766  |
| MaxReturn               | 107        |
| MeanKL                  | 0.00646454 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 3.48       |
| NumTrajs                | 165        |
| Perplexity              | 69.093     |
| PolicyExecTime          | 0.42       |
| ProcessExecTime         | 0.0581     |
| StdReturn               | 17.3       |
| Time                    | 39.5       |
| dLoss                   | 0.0371991  |
----------------------------------------
itr #5 | 
Mem: 611.535156
Obtaining samples...
Obtaining samples for iteration 5...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5061, #subsample_inputs: 5061
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.596      |
| AbsLearnSignalNew       | 0.596      |
| AbsLearningOld          | 0.597      |
| AverageDiscountedReturn | 48.8       |
| AveragePhiLoss          | 4.58527    |
| AveragePolicyStd        | 0.987652   |
| AverageReturn           | 58.6       |
| Entropy                 | 4.21941    |
| EnvExecTime             | 1.76       |
| ExplainedVariance       | 0.465      |
| Iteration               | 5          |
| ItrTime                 | 7.79       |
| LossAfter               | -1.02805   |
| LossBefore              | -0.97723   |
| MaxReturn               | 168        |
| MeanKL                  | 0.00661197 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 4.95       |
| NumTrajs                | 144        |
| Perplexity              | 67.9936    |
| PolicyExecTime          | 0.431      |
| ProcessExecTime         | 0.0589     |
| StdReturn               | 16.2       |
| Time                    | 47.3       |
| dLoss                   | 0.0508205  |
----------------------------------------
itr #6 | 
Mem: 619.261719
Obtaining samples...
Obtaining samples for iteration 6...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5019, #subsample_inputs: 5019
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.725      |
| AbsLearnSignalNew       | 0.725      |
| AbsLearningOld          | 0.725      |
| AverageDiscountedReturn | 51.1       |
| AveragePhiLoss          | 4.19555    |
| AveragePolicyStd        | 0.98778    |
| AverageReturn           | 62.2       |
| Entropy                 | 4.2198     |
| EnvExecTime             | 1.74       |
| ExplainedVariance       | 0.522      |
| Iteration               | 6          |
| ItrTime                 | 7.78       |
| LossAfter               | -1.48841   |
| LossBefore              | -1.44955   |
| MaxReturn               | 163        |
| MeanKL                  | 0.00654055 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 4.74       |
| NumTrajs                | 136        |
| Perplexity              | 68.0196    |
| PolicyExecTime          | 0.431      |
| ProcessExecTime         | 0.0584     |
| StdReturn               | 20.3       |
| Time                    | 55.1       |
| dLoss                   | 0.0388582  |
----------------------------------------
itr #7 | 
Mem: 623.125000
Obtaining samples...
Obtaining samples for iteration 7...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5035, #subsample_inputs: 5035
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.793      |
| AbsLearnSignalNew       | 0.793      |
| AbsLearningOld          | 0.794      |
| AverageDiscountedReturn | 56.5       |
| AveragePhiLoss          | 4.18922    |
| AveragePolicyStd        | 0.983398   |
| AverageReturn           | 70.9       |
| Entropy                 | 4.20645    |
| EnvExecTime             | 1.9        |
| ExplainedVariance       | 0.405      |
| Iteration               | 7          |
| ItrTime                 | 7.92       |
| LossAfter               | -0.387985  |
| LossBefore              | -0.350262  |
| MaxReturn               | 172        |
| MeanKL                  | 0.00649721 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 6.71       |
| NumTrajs                | 122        |
| Perplexity              | 67.118     |
| PolicyExecTime          | 0.459      |
| ProcessExecTime         | 0.0626     |
| StdReturn               | 28.5       |
| Time                    | 63.1       |
| dLoss                   | 0.0377223  |
----------------------------------------
itr #8 | 
Mem: 625.433594
Obtaining samples...
Obtaining samples for iteration 8...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5055, #subsample_inputs: 5055
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.835      |
| AbsLearnSignalNew       | 0.835      |
| AbsLearningOld          | 0.835      |
| AverageDiscountedReturn | 65.9       |
| AveragePhiLoss          | 4.44249    |
| AveragePolicyStd        | 0.98121    |
| AverageReturn           | 86.3       |
| Entropy                 | 4.19973    |
| EnvExecTime             | 1.71       |
| ExplainedVariance       | 0.369      |
| Iteration               | 8          |
| ItrTime                 | 7.73       |
| LossAfter               | -1.03041   |
| LossBefore              | -0.996319  |
| MaxReturn               | 183        |
| MeanKL                  | 0.00652731 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 38.6       |
| NumTrajs                | 105        |
| Perplexity              | 66.668     |
| PolicyExecTime          | 0.426      |
| ProcessExecTime         | 0.0564     |
| StdReturn               | 35.9       |
| Time                    | 70.9       |
| dLoss                   | 0.0340924  |
----------------------------------------
itr #9 | 
Mem: 629.546875
Obtaining samples...
Obtaining samples for iteration 9...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5027, #subsample_inputs: 5027
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.841      |
| AbsLearnSignalNew       | 0.841      |
| AbsLearningOld          | 0.841      |
| AverageDiscountedReturn | 68.9       |
| AveragePhiLoss          | 4.44923    |
| AveragePolicyStd        | 0.979793   |
| AverageReturn           | 91.2       |
| Entropy                 | 4.19548    |
| EnvExecTime             | 1.87       |
| ExplainedVariance       | 0.348      |
| Iteration               | 9          |
| ItrTime                 | 7.91       |
| LossAfter               | -0.137598  |
| LossBefore              | -0.104216  |
| MaxReturn               | 186        |
| MeanKL                  | 0.00648179 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 41.6       |
| NumTrajs                | 99         |
| Perplexity              | 66.3854    |
| PolicyExecTime          | 0.458      |
| ProcessExecTime         | 0.0614     |
| StdReturn               | 35.9       |
| Time                    | 78.8       |
| dLoss                   | 0.033382   |
----------------------------------------
itr #10 | 
Mem: 630.320312
Obtaining samples...
Obtaining samples for iteration 10...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5023, #subsample_inputs: 5023
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.824      |
| AbsLearnSignalNew       | 0.824      |
| AbsLearningOld          | 0.824      |
| AverageDiscountedReturn | 82.5       |
| AveragePhiLoss          | 4.48841    |
| AveragePolicyStd        | 0.976318   |
| AverageReturn           | 116        |
| Entropy                 | 4.18481    |
| EnvExecTime             | 1.75       |
| ExplainedVariance       | 0.411      |
| Iteration               | 10         |
| ItrTime                 | 7.77       |
| LossAfter               | 0.0241919  |
| LossBefore              | 0.0593364  |
| MaxReturn               | 183        |
| MeanKL                  | 0.00665335 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 42.7       |
| NumTrajs                | 81         |
| Perplexity              | 65.6812    |
| PolicyExecTime          | 0.436      |
| ProcessExecTime         | 0.0575     |
| StdReturn               | 41         |
| Time                    | 86.7       |
| dLoss                   | 0.0351445  |
----------------------------------------
itr #11 | 
Mem: 633.152344
Obtaining samples...
Obtaining samples for iteration 11...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5015, #subsample_inputs: 5015
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.765      |
| AbsLearnSignalNew       | 0.765      |
| AbsLearningOld          | 0.765      |
| AverageDiscountedReturn | 93.3       |
| AveragePhiLoss          | 4.84942    |
| AveragePolicyStd        | 0.975562   |
| AverageReturn           | 137        |
| Entropy                 | 4.18251    |
| EnvExecTime             | 1.77       |
| ExplainedVariance       | 0.544      |
| Iteration               | 11         |
| ItrTime                 | 7.83       |
| LossAfter               | -1.14732   |
| LossBefore              | -1.11577   |
| MaxReturn               | 181        |
| MeanKL                  | 0.00881051 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 48.8       |
| NumTrajs                | 70         |
| Perplexity              | 65.5299    |
| PolicyExecTime          | 0.439      |
| ProcessExecTime         | 0.0566     |
| StdReturn               | 41.1       |
| Time                    | 94.5       |
| dLoss                   | 0.0315485  |
----------------------------------------
itr #12 | 
Mem: 633.152344
Obtaining samples...
Obtaining samples for iteration 12...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5084, #subsample_inputs: 5084
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.683      |
| AbsLearnSignalNew       | 0.683      |
| AbsLearningOld          | 0.682      |
| AverageDiscountedReturn | 99.8       |
| AveragePhiLoss          | 4.7876     |
| AveragePolicyStd        | 0.967618   |
| AverageReturn           | 149        |
| Entropy                 | 4.15801    |
| EnvExecTime             | 1.69       |
| ExplainedVariance       | 0.733      |
| Iteration               | 12         |
| ItrTime                 | 7.76       |
| LossAfter               | -0.567442  |
| LossBefore              | -0.522468  |
| MaxReturn               | 185        |
| MeanKL                  | 0.00951194 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 47.8       |
| NumTrajs                | 66         |
| Perplexity              | 63.9441    |
| PolicyExecTime          | 0.428      |
| ProcessExecTime         | 0.0537     |
| StdReturn               | 33.5       |
| Time                    | 102        |
| dLoss                   | 0.0449741  |
----------------------------------------
itr #13 | 
Mem: 634.957031
Obtaining samples...
Obtaining samples for iteration 13...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5054, #subsample_inputs: 5054
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.664      |
| AbsLearnSignalNew       | 0.664      |
| AbsLearningOld          | 0.664      |
| AverageDiscountedReturn | 102        |
| AveragePhiLoss          | 5.43824    |
| AveragePolicyStd        | 0.962427   |
| AverageReturn           | 153        |
| Entropy                 | 4.14188    |
| EnvExecTime             | 1.69       |
| ExplainedVariance       | 0.761      |
| Iteration               | 13         |
| ItrTime                 | 7.71       |
| LossAfter               | -0.926767  |
| LossBefore              | -0.898827  |
| MaxReturn               | 185        |
| MeanKL                  | 0.00641585 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 42.7       |
| NumTrajs                | 64         |
| Perplexity              | 62.921     |
| PolicyExecTime          | 0.427      |
| ProcessExecTime         | 0.0534     |
| StdReturn               | 27.7       |
| Time                    | 110        |
| dLoss                   | 0.0279403  |
----------------------------------------
itr #14 | 
Mem: 636.761719
Obtaining samples...
Obtaining samples for iteration 14...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5024, #subsample_inputs: 5024
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.614      |
| AbsLearnSignalNew       | 0.614      |
| AbsLearningOld          | 0.613      |
| AverageDiscountedReturn | 106        |
| AveragePhiLoss          | 4.74002    |
| AveragePolicyStd        | 0.956102   |
| AverageReturn           | 162        |
| Entropy                 | 4.12214    |
| EnvExecTime             | 1.74       |
| ExplainedVariance       | 0.864      |
| Iteration               | 14         |
| ItrTime                 | 7.7        |
| LossAfter               | 0.267672   |
| LossBefore              | 0.303576   |
| MaxReturn               | 179        |
| MeanKL                  | 0.00887671 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 80.6       |
| NumTrajs                | 61         |
| Perplexity              | 61.6913    |
| PolicyExecTime          | 0.429      |
| ProcessExecTime         | 0.0546     |
| StdReturn               | 20.8       |
| Time                    | 118        |
| dLoss                   | 0.035904   |
----------------------------------------
itr #15 | 
Mem: 638.050781
Obtaining samples...
Obtaining samples for iteration 15...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5019, #subsample_inputs: 5019
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.539      |
| AbsLearnSignalNew       | 0.539      |
| AbsLearningOld          | 0.539      |
| AverageDiscountedReturn | 106        |
| AveragePhiLoss          | 5.61712    |
| AveragePolicyStd        | 0.954709   |
| AverageReturn           | 160        |
| Entropy                 | 4.11777    |
| EnvExecTime             | 1.82       |
| ExplainedVariance       | 0.833      |
| Iteration               | 15         |
| ItrTime                 | 7.81       |
| LossAfter               | 0.542231   |
| LossBefore              | 0.568824   |
| MaxReturn               | 189        |
| MeanKL                  | 0.00654611 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 40         |
| NumTrajs                | 62         |
| Perplexity              | 61.4221    |
| PolicyExecTime          | 0.446      |
| ProcessExecTime         | 0.0567     |
| StdReturn               | 25.6       |
| Time                    | 126        |
| dLoss                   | 0.0265936  |
----------------------------------------
itr #16 | 
Mem: 638.566406
Obtaining samples...
Obtaining samples for iteration 16...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5025, #subsample_inputs: 5025
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.719      |
| AbsLearnSignalNew       | 0.719      |
| AbsLearningOld          | 0.719      |
| AverageDiscountedReturn | 108        |
| AveragePhiLoss          | 5.3615     |
| AveragePolicyStd        | 0.946765   |
| AverageReturn           | 165        |
| Entropy                 | 4.09258    |
| EnvExecTime             | 1.85       |
| ExplainedVariance       | 0.945      |
| Iteration               | 16         |
| ItrTime                 | 7.89       |
| LossAfter               | 0.100963   |
| LossBefore              | 0.133475   |
| MaxReturn               | 181        |
| MeanKL                  | 0.00985137 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 111        |
| NumTrajs                | 60         |
| Perplexity              | 59.8944    |
| PolicyExecTime          | 0.45       |
| ProcessExecTime         | 0.0589     |
| StdReturn               | 11.3       |
| Time                    | 134        |
| dLoss                   | 0.0325125  |
----------------------------------------
itr #17 | 
Mem: 639.593750
Obtaining samples...
Obtaining samples for iteration 17...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5072, #subsample_inputs: 5072
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.741      |
| AbsLearnSignalNew       | 0.741      |
| AbsLearningOld          | 0.742      |
| AverageDiscountedReturn | 110        |
| AveragePhiLoss          | 4.94654    |
| AveragePolicyStd        | 0.941984   |
| AverageReturn           | 168        |
| Entropy                 | 4.07703    |
| EnvExecTime             | 1.79       |
| ExplainedVariance       | 0.982      |
| Iteration               | 17         |
| ItrTime                 | 7.85       |
| LossAfter               | -0.666813  |
| LossBefore              | -0.625619  |
| MaxReturn               | 183        |
| MeanKL                  | 0.00953644 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 145        |
| NumTrajs                | 60         |
| Perplexity              | 58.9701    |
| PolicyExecTime          | 0.44       |
| ProcessExecTime         | 0.0556     |
| StdReturn               | 7.58       |
| Time                    | 142        |
| dLoss                   | 0.0411947  |
----------------------------------------
itr #18 | 
Mem: 639.593750
Obtaining samples...
Obtaining samples for iteration 18...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5068, #subsample_inputs: 5068
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.723      |
| AbsLearnSignalNew       | 0.723      |
| AbsLearningOld          | 0.724      |
| AverageDiscountedReturn | 113        |
| AveragePhiLoss          | 5.27138    |
| AveragePolicyStd        | 0.94247    |
| AverageReturn           | 175        |
| Entropy                 | 4.07825    |
| EnvExecTime             | 1.74       |
| ExplainedVariance       | 0.987      |
| Iteration               | 18         |
| ItrTime                 | 7.8        |
| LossAfter               | -0.589956  |
| LossBefore              | -0.561118  |
| MaxReturn               | 190        |
| MeanKL                  | 0.00641725 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 159        |
| NumTrajs                | 59         |
| Perplexity              | 59.0423    |
| PolicyExecTime          | 0.432      |
| ProcessExecTime         | 0.0556     |
| StdReturn               | 5.95       |
| Time                    | 149        |
| dLoss                   | 0.0288382  |
----------------------------------------
itr #19 | 
Mem: 643.972656
Obtaining samples...
Obtaining samples for iteration 19...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5035, #subsample_inputs: 5035
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.495      |
| AbsLearnSignalNew       | 0.495      |
| AbsLearningOld          | 0.495      |
| AverageDiscountedReturn | 113        |
| AveragePhiLoss          | 4.73955    |
| AveragePolicyStd        | 0.942837   |
| AverageReturn           | 176        |
| Entropy                 | 4.07931    |
| EnvExecTime             | 1.66       |
| ExplainedVariance       | 0.916      |
| Iteration               | 19         |
| ItrTime                 | 7.67       |
| LossAfter               | -0.415636  |
| LossBefore              | -0.393572  |
| MaxReturn               | 218        |
| MeanKL                  | 0.00655829 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 88.4       |
| NumTrajs                | 59         |
| Perplexity              | 59.1044    |
| PolicyExecTime          | 0.417      |
| ProcessExecTime         | 0.0523     |
| StdReturn               | 18.7       |
| Time                    | 157        |
| dLoss                   | 0.0220633  |
----------------------------------------
itr #20 | 
Mem: 643.972656
Obtaining samples...
Obtaining samples for iteration 20...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5026, #subsample_inputs: 5026
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.712      |
| AbsLearnSignalNew       | 0.712      |
| AbsLearningOld          | 0.711      |
| AverageDiscountedReturn | 114        |
| AveragePhiLoss          | 4.79554    |
| AveragePolicyStd        | 0.944483   |
| AverageReturn           | 179        |
| Entropy                 | 4.08449    |
| EnvExecTime             | 1.7        |
| ExplainedVariance       | 0.958      |
| Iteration               | 20         |
| ItrTime                 | 7.74       |
| LossAfter               | -0.668058  |
| LossBefore              | -0.638732  |
| MaxReturn               | 216        |
| MeanKL                  | 0.00655853 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 134        |
| NumTrajs                | 58         |
| Perplexity              | 59.4118    |
| PolicyExecTime          | 0.422      |
| ProcessExecTime         | 0.0531     |
| StdReturn               | 11.9       |
| Time                    | 165        |
| dLoss                   | 0.0293255  |
----------------------------------------
itr #21 | 
Mem: 646.035156
Obtaining samples...
Obtaining samples for iteration 21...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5077, #subsample_inputs: 5077
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.594      |
| AbsLearnSignalNew       | 0.594      |
| AbsLearningOld          | 0.594      |
| AverageDiscountedReturn | 117        |
| AveragePhiLoss          | 4.81855    |
| AveragePolicyStd        | 0.947022   |
| AverageReturn           | 185        |
| Entropy                 | 4.09204    |
| EnvExecTime             | 1.75       |
| ExplainedVariance       | 0.917      |
| Iteration               | 21         |
| ItrTime                 | 7.79       |
| LossAfter               | -0.433496  |
| LossBefore              | -0.406744  |
| MaxReturn               | 224        |
| MeanKL                  | 0.00661315 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 107        |
| NumTrajs                | 58         |
| Perplexity              | 59.8618    |
| PolicyExecTime          | 0.434      |
| ProcessExecTime         | 0.0551     |
| StdReturn               | 17.6       |
| Time                    | 173        |
| dLoss                   | 0.026752   |
----------------------------------------
itr #22 | 
Mem: 646.550781
Obtaining samples...
Obtaining samples for iteration 22...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5019, #subsample_inputs: 5019
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.596      |
| AbsLearnSignalNew       | 0.596      |
| AbsLearningOld          | 0.596      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 5.15107    |
| AveragePolicyStd        | 0.942456   |
| AverageReturn           | 194        |
| Entropy                 | 4.07773    |
| EnvExecTime             | 1.69       |
| ExplainedVariance       | 0.895      |
| Iteration               | 22         |
| ItrTime                 | 7.65       |
| LossAfter               | 0.0741444  |
| LossBefore              | 0.111429   |
| MaxReturn               | 240        |
| MeanKL                  | 0.00919283 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 99.4       |
| NumTrajs                | 56         |
| Perplexity              | 59.0113    |
| PolicyExecTime          | 0.419      |
| ProcessExecTime         | 0.0523     |
| StdReturn               | 19.5       |
| Time                    | 181        |
| dLoss                   | 0.0372842  |
----------------------------------------
itr #23 | 
Mem: 646.550781
Obtaining samples...
Obtaining samples for iteration 23...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5025, #subsample_inputs: 5025
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.636      |
| AbsLearnSignalNew       | 0.636      |
| AbsLearningOld          | 0.636      |
| AverageDiscountedReturn | 123        |
| AveragePhiLoss          | 5.90245    |
| AveragePolicyStd        | 0.939613   |
| AverageReturn           | 199        |
| Entropy                 | 4.06872    |
| EnvExecTime             | 1.66       |
| ExplainedVariance       | 0.894      |
| Iteration               | 23         |
| ItrTime                 | 7.62       |
| LossAfter               | 0.0618325  |
| LossBefore              | 0.0931777  |
| MaxReturn               | 236        |
| MeanKL                  | 0.00966146 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 100        |
| NumTrajs                | 55         |
| Perplexity              | 58.4823    |
| PolicyExecTime          | 0.413      |
| ProcessExecTime         | 0.052      |
| StdReturn               | 20         |
| Time                    | 188        |
| dLoss                   | 0.0313452  |
----------------------------------------
itr #24 | 
Mem: 646.550781
Obtaining samples...
Obtaining samples for iteration 24...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5048, #subsample_inputs: 5048
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.679      |
| AbsLearnSignalNew       | 0.679      |
| AbsLearningOld          | 0.679      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 5.68618    |
| AveragePolicyStd        | 0.934678   |
| AverageReturn           | 207        |
| Entropy                 | 4.05293    |
| EnvExecTime             | 1.79       |
| ExplainedVariance       | 0.89       |
| Iteration               | 24         |
| ItrTime                 | 7.82       |
| LossAfter               | 0.449213   |
| LossBefore              | 0.482871   |
| MaxReturn               | 248        |
| MeanKL                  | 0.00936801 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 146        |
| NumTrajs                | 54         |
| Perplexity              | 57.5656    |
| PolicyExecTime          | 0.443      |
| ProcessExecTime         | 0.057      |
| StdReturn               | 21.1       |
| Time                    | 196        |
| dLoss                   | 0.0336579  |
----------------------------------------
itr #25 | 
Mem: 646.550781
Obtaining samples...
Obtaining samples for iteration 25...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5019, #subsample_inputs: 5019
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.681      |
| AbsLearnSignalNew       | 0.681      |
| AbsLearningOld          | 0.681      |
| AverageDiscountedReturn | 131        |
| AveragePhiLoss          | 5.0743     |
| AveragePolicyStd        | 0.929216   |
| AverageReturn           | 219        |
| Entropy                 | 4.03517    |
| EnvExecTime             | 1.83       |
| ExplainedVariance       | 0.912      |
| Iteration               | 25         |
| ItrTime                 | 7.87       |
| LossAfter               | -0.808712  |
| LossBefore              | -0.779676  |
| MaxReturn               | 258        |
| MeanKL                  | 0.00667998 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 151        |
| NumTrajs                | 52         |
| Perplexity              | 56.5524    |
| PolicyExecTime          | 0.451      |
| ProcessExecTime         | 0.0565     |
| StdReturn               | 19         |
| Time                    | 204        |
| dLoss                   | 0.0290359  |
----------------------------------------
itr #26 | 
Mem: 646.550781
Obtaining samples...
Obtaining samples for iteration 26...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5029, #subsample_inputs: 5029
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.649      |
| AbsLearnSignalNew       | 0.649      |
| AbsLearningOld          | 0.649      |
| AverageDiscountedReturn | 133        |
| AveragePhiLoss          | 5.9392     |
| AveragePolicyStd        | 0.928726   |
| AverageReturn           | 226        |
| Entropy                 | 4.03406    |
| EnvExecTime             | 1.64       |
| ExplainedVariance       | 0.861      |
| Iteration               | 26         |
| ItrTime                 | 7.63       |
| LossAfter               | -0.120396  |
| LossBefore              | -0.0960172 |
| MaxReturn               | 279        |
| MeanKL                  | 0.00911102 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 145        |
| NumTrajs                | 51         |
| Perplexity              | 56.4897    |
| PolicyExecTime          | 0.414      |
| ProcessExecTime         | 0.0512     |
| StdReturn               | 26.3       |
| Time                    | 212        |
| dLoss                   | 0.0243787  |
----------------------------------------
itr #27 | 
Mem: 646.550781
Obtaining samples...
Obtaining samples for iteration 27...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5093, #subsample_inputs: 5093
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.644      |
| AbsLearnSignalNew       | 0.644      |
| AbsLearningOld          | 0.644      |
| AverageDiscountedReturn | 135        |
| AveragePhiLoss          | 5.46597    |
| AveragePolicyStd        | 0.921561   |
| AverageReturn           | 231        |
| Entropy                 | 4.01104    |
| EnvExecTime             | 1.84       |
| ExplainedVariance       | 0.907      |
| Iteration               | 27         |
| ItrTime                 | 7.96       |
| LossAfter               | -0.708949  |
| LossBefore              | -0.678106  |
| MaxReturn               | 279        |
| MeanKL                  | 0.00665432 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 117        |
| NumTrajs                | 51         |
| Perplexity              | 55.2042    |
| PolicyExecTime          | 0.452      |
| ProcessExecTime         | 0.0578     |
| StdReturn               | 24.6       |
| Time                    | 220        |
| dLoss                   | 0.0308434  |
----------------------------------------
itr #28 | 
Mem: 647.410156
Obtaining samples...
Obtaining samples for iteration 28...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5057, #subsample_inputs: 5057
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.726      |
| AbsLearnSignalNew       | 0.726      |
| AbsLearningOld          | 0.725      |
| AverageDiscountedReturn | 142        |
| AveragePhiLoss          | 5.5042     |
| AveragePolicyStd        | 0.917352   |
| AverageReturn           | 250        |
| Entropy                 | 3.9966     |
| EnvExecTime             | 1.76       |
| ExplainedVariance       | 0.929      |
| Iteration               | 28         |
| ItrTime                 | 7.79       |
| LossAfter               | -1.07583   |
| LossBefore              | -1.04036   |
| MaxReturn               | 298        |
| MeanKL                  | 0.00972906 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 207        |
| NumTrajs                | 48         |
| Perplexity              | 54.413     |
| PolicyExecTime          | 0.438      |
| ProcessExecTime         | 0.0563     |
| StdReturn               | 24.3       |
| Time                    | 228        |
| dLoss                   | 0.0354704  |
----------------------------------------
itr #29 | 
Mem: 647.667969
Obtaining samples...
Obtaining samples for iteration 29...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5088, #subsample_inputs: 5088
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.769      |
| AbsLearnSignalNew       | 0.769      |
| AbsLearningOld          | 0.769      |
| AverageDiscountedReturn | 147        |
| AveragePhiLoss          | 5.25485    |
| AveragePolicyStd        | 0.9143     |
| AverageReturn           | 265        |
| Entropy                 | 3.98557    |
| EnvExecTime             | 1.79       |
| ExplainedVariance       | 0.963      |
| Iteration               | 29         |
| ItrTime                 | 7.87       |
| LossAfter               | -0.732948  |
| LossBefore              | -0.689644  |
| MaxReturn               | 307        |
| MeanKL                  | 0.00988378 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 228        |
| NumTrajs                | 46         |
| Perplexity              | 53.8158    |
| PolicyExecTime          | 0.445      |
| ProcessExecTime         | 0.0555     |
| StdReturn               | 21.6       |
| Time                    | 235        |
| dLoss                   | 0.0433038  |
----------------------------------------
itr #30 | 
Mem: 647.667969
Obtaining samples...
Obtaining samples for iteration 30...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5056, #subsample_inputs: 5056
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
-----------------------------------------
| AbsLearnSignal          | 0.747       |
| AbsLearnSignalNew       | 0.747       |
| AbsLearningOld          | 0.748       |
| AverageDiscountedReturn | 151         |
| AveragePhiLoss          | 5.13021     |
| AveragePolicyStd        | 0.913167    |
| AverageReturn           | 278         |
| Entropy                 | 3.98125     |
| EnvExecTime             | 1.73        |
| ExplainedVariance       | 0.976       |
| Iteration               | 30          |
| ItrTime                 | 7.74        |
| LossAfter               | -0.00720687 |
| LossBefore              | 0.0221235   |
| MaxReturn               | 312         |
| MeanKL                  | 0.00665275  |
| MeanKLBefore            | 0.0         |
| MinReturn               | 230         |
| NumTrajs                | 44          |
| Perplexity              | 53.5841     |
| PolicyExecTime          | 0.436       |
| ProcessExecTime         | 0.0539      |
| StdReturn               | 17.6        |
| Time                    | 243         |
| dLoss                   | 0.0293303   |
-----------------------------------------
itr #31 | 
Mem: 647.925781
Obtaining samples...
Obtaining samples for iteration 31...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5026, #subsample_inputs: 5026
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.733      |
| AbsLearnSignalNew       | 0.733      |
| AbsLearningOld          | 0.733      |
| AverageDiscountedReturn | 155        |
| AveragePhiLoss          | 5.05917    |
| AveragePolicyStd        | 0.912782   |
| AverageReturn           | 292        |
| Entropy                 | 3.97977    |
| EnvExecTime             | 1.77       |
| ExplainedVariance       | 0.986      |
| Iteration               | 31         |
| ItrTime                 | 7.75       |
| LossAfter               | 0.194361   |
| LossBefore              | 0.221727   |
| MaxReturn               | 328        |
| MeanKL                  | 0.00973132 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 258        |
| NumTrajs                | 42         |
| Perplexity              | 53.505     |
| PolicyExecTime          | 0.439      |
| ProcessExecTime         | 0.0538     |
| StdReturn               | 14.1       |
| Time                    | 251        |
| dLoss                   | 0.0273668  |
----------------------------------------
itr #32 | 
Mem: 647.925781
Obtaining samples...
Obtaining samples for iteration 32...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5093, #subsample_inputs: 5093
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.521      |
| AbsLearnSignalNew       | 0.521      |
| AbsLearningOld          | 0.521      |
| AverageDiscountedReturn | 157        |
| AveragePhiLoss          | 5.71564    |
| AveragePolicyStd        | 0.905579   |
| AverageReturn           | 301        |
| Entropy                 | 3.95654    |
| EnvExecTime             | 1.9        |
| ExplainedVariance       | 0.962      |
| Iteration               | 32         |
| ItrTime                 | 7.99       |
| LossAfter               | -0.343827  |
| LossBefore              | -0.321393  |
| MaxReturn               | 330        |
| MeanKL                  | 0.00645901 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 215        |
| NumTrajs                | 41         |
| Perplexity              | 52.2761    |
| PolicyExecTime          | 0.47       |
| ProcessExecTime         | 0.0578     |
| StdReturn               | 17.8       |
| Time                    | 259        |
| dLoss                   | 0.022434   |
----------------------------------------
itr #33 | 
Mem: 648.183594
Obtaining samples...
Obtaining samples for iteration 33...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5065, #subsample_inputs: 5065
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.716      |
| AbsLearnSignalNew       | 0.716      |
| AbsLearningOld          | 0.715      |
| AverageDiscountedReturn | 159        |
| AveragePhiLoss          | 5.70296    |
| AveragePolicyStd        | 0.901237   |
| AverageReturn           | 309        |
| Entropy                 | 3.94162    |
| EnvExecTime             | 1.75       |
| ExplainedVariance       | 0.984      |
| Iteration               | 33         |
| ItrTime                 | 7.82       |
| LossAfter               | 0.140215   |
| LossBefore              | 0.16914    |
| MaxReturn               | 340        |
| MeanKL                  | 0.00968664 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 283        |
| NumTrajs                | 40         |
| Perplexity              | 51.5019    |
| PolicyExecTime          | 0.434      |
| ProcessExecTime         | 0.0531     |
| StdReturn               | 11.1       |
| Time                    | 267        |
| dLoss                   | 0.0289248  |
----------------------------------------
itr #34 | 
Mem: 648.183594
Obtaining samples...
Obtaining samples for iteration 34...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5099, #subsample_inputs: 5099
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.328      |
| AbsLearnSignalNew       | 0.328      |
| AbsLearningOld          | 0.328      |
| AverageDiscountedReturn | 156        |
| AveragePhiLoss          | 5.70307    |
| AveragePolicyStd        | 0.900974   |
| AverageReturn           | 303        |
| Entropy                 | 3.93927    |
| EnvExecTime             | 1.81       |
| ExplainedVariance       | 0.939      |
| Iteration               | 34         |
| ItrTime                 | 7.92       |
| LossAfter               | 0.126179   |
| LossBefore              | 0.145241   |
| MaxReturn               | 335        |
| MeanKL                  | 0.00700351 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 50.8       |
| NumTrajs                | 41         |
| Perplexity              | 51.381     |
| PolicyExecTime          | 0.442      |
| ProcessExecTime         | 0.0557     |
| StdReturn               | 41.8       |
| Time                    | 275        |
| dLoss                   | 0.0190614  |
----------------------------------------
itr #35 | 
Mem: 648.699219
Obtaining samples...
Obtaining samples for iteration 35...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5116, #subsample_inputs: 5116
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.693      |
| AbsLearnSignalNew       | 0.693      |
| AbsLearningOld          | 0.693      |
| AverageDiscountedReturn | 160        |
| AveragePhiLoss          | 5.78313    |
| AveragePolicyStd        | 0.897391   |
| AverageReturn           | 311        |
| Entropy                 | 3.9277     |
| EnvExecTime             | 1.66       |
| ExplainedVariance       | 0.983      |
| Iteration               | 35         |
| ItrTime                 | 7.82       |
| LossAfter               | -0.486698  |
| LossBefore              | -0.463345  |
| MaxReturn               | 335        |
| MeanKL                  | 0.00958399 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 287        |
| NumTrajs                | 40         |
| Perplexity              | 50.7899    |
| PolicyExecTime          | 0.417      |
| ProcessExecTime         | 0.052      |
| StdReturn               | 11.7       |
| Time                    | 283        |
| dLoss                   | 0.0233536  |
----------------------------------------
itr #36 | 
Mem: 648.699219
Obtaining samples...
Obtaining samples for iteration 36...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5043, #subsample_inputs: 5043
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.649      |
| AbsLearnSignalNew       | 0.649      |
| AbsLearningOld          | 0.649      |
| AverageDiscountedReturn | 161        |
| AveragePhiLoss          | 5.56829    |
| AveragePolicyStd        | 0.901394   |
| AverageReturn           | 315        |
| Entropy                 | 3.94134    |
| EnvExecTime             | 1.93       |
| ExplainedVariance       | 0.98       |
| Iteration               | 36         |
| ItrTime                 | 8.03       |
| LossAfter               | -0.0559947 |
| LossBefore              | -0.0302673 |
| MaxReturn               | 354        |
| MeanKL                  | 0.00993153 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 292        |
| NumTrajs                | 39         |
| Perplexity              | 51.4873    |
| PolicyExecTime          | 0.464      |
| ProcessExecTime         | 0.0588     |
| StdReturn               | 14.1       |
| Time                    | 291        |
| dLoss                   | 0.0257274  |
----------------------------------------
itr #37 | 
Mem: 648.699219
Obtaining samples...
Obtaining samples for iteration 37...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5117, #subsample_inputs: 5117
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.742      |
| AbsLearnSignalNew       | 0.742      |
| AbsLearningOld          | 0.742      |
| AverageDiscountedReturn | 162        |
| AveragePhiLoss          | 6.22081    |
| AveragePolicyStd        | 0.894123   |
| AverageReturn           | 321        |
| Entropy                 | 3.91714    |
| EnvExecTime             | 1.76       |
| ExplainedVariance       | 0.981      |
| Iteration               | 37         |
| ItrTime                 | 7.84       |
| LossAfter               | -0.172302  |
| LossBefore              | -0.154034  |
| MaxReturn               | 347        |
| MeanKL                  | 0.00652387 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 280        |
| NumTrajs                | 39         |
| Perplexity              | 50.2564    |
| PolicyExecTime          | 0.435      |
| ProcessExecTime         | 0.0532     |
| StdReturn               | 15         |
| Time                    | 299        |
| dLoss                   | 0.0182686  |
----------------------------------------
itr #38 | 
Mem: 649.464844
Obtaining samples...
Obtaining samples for iteration 38...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5018, #subsample_inputs: 5018
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.458      |
| AbsLearnSignalNew       | 0.458      |
| AbsLearningOld          | 0.459      |
| AverageDiscountedReturn | 160        |
| AveragePhiLoss          | 6.37188    |
| AveragePolicyStd        | 0.890847   |
| AverageReturn           | 314        |
| Entropy                 | 3.90748    |
| EnvExecTime             | 1.73       |
| ExplainedVariance       | 0.91       |
| Iteration               | 38         |
| ItrTime                 | 7.68       |
| LossAfter               | 0.0900456  |
| LossBefore              | 0.112028   |
| MaxReturn               | 368        |
| MeanKL                  | 0.00960325 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 184        |
| NumTrajs                | 39         |
| Perplexity              | 49.7732    |
| PolicyExecTime          | 0.427      |
| ProcessExecTime         | 0.0526     |
| StdReturn               | 30.6       |
| Time                    | 306        |
| dLoss                   | 0.0219823  |
----------------------------------------
itr #39 | 
Mem: 649.464844
Obtaining samples...
Obtaining samples for iteration 39...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5031, #subsample_inputs: 5031
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.578      |
| AbsLearnSignalNew       | 0.578      |
| AbsLearningOld          | 0.578      |
| AverageDiscountedReturn | 163        |
| AveragePhiLoss          | 5.78413    |
| AveragePolicyStd        | 0.886403   |
| AverageReturn           | 326        |
| Entropy                 | 3.89287    |
| EnvExecTime             | 1.74       |
| ExplainedVariance       | 0.932      |
| Iteration               | 39         |
| ItrTime                 | 7.71       |
| LossAfter               | -0.0638738 |
| LossBefore              | -0.0375218 |
| MaxReturn               | 392        |
| MeanKL                  | 0.00672289 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 192        |
| NumTrajs                | 38         |
| Perplexity              | 49.0513    |
| PolicyExecTime          | 0.432      |
| ProcessExecTime         | 0.0532     |
| StdReturn               | 28         |
| Time                    | 314        |
| dLoss                   | 0.026352   |
----------------------------------------
itr #40 | 
Mem: 651.523438
Obtaining samples...
Obtaining samples for iteration 40...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5124, #subsample_inputs: 5124
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.455     |
| AbsLearnSignalNew       | 0.455     |
| AbsLearningOld          | 0.455     |
| AverageDiscountedReturn | 162       |
| AveragePhiLoss          | 7.45299   |
| AveragePolicyStd        | 0.885876  |
| AverageReturn           | 326       |
| Entropy                 | 3.89158   |
| EnvExecTime             | 1.88      |
| ExplainedVariance       | 0.901     |
| Iteration               | 40        |
| ItrTime                 | 8.03      |
| LossAfter               | 0.475972  |
| LossBefore              | 0.503202  |
| MaxReturn               | 378       |
| MeanKL                  | 0.0066205 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 61.1      |
| NumTrajs                | 39        |
| Perplexity              | 48.9882   |
| PolicyExecTime          | 0.458     |
| ProcessExecTime         | 0.0566    |
| StdReturn               | 47.5      |
| Time                    | 322       |
| dLoss                   | 0.0272307 |
---------------------------------------
itr #41 | 
Mem: 651.777344
Obtaining samples...
Obtaining samples for iteration 41...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5136, #subsample_inputs: 5136
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.782     |
| AbsLearnSignalNew       | 0.782     |
| AbsLearningOld          | 0.782     |
| AverageDiscountedReturn | 166       |
| AveragePhiLoss          | 6.4028    |
| AveragePolicyStd        | 0.879774  |
| AverageReturn           | 336       |
| Entropy                 | 3.87044   |
| EnvExecTime             | 1.95      |
| ExplainedVariance       | 0.974     |
| Iteration               | 41        |
| ItrTime                 | 8.11      |
| LossAfter               | -0.126574 |
| LossBefore              | -0.107309 |
| MaxReturn               | 393       |
| MeanKL                  | 0.0064792 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 308       |
| NumTrajs                | 38        |
| Perplexity              | 47.9636   |
| PolicyExecTime          | 0.471     |
| ProcessExecTime         | 0.0593    |
| StdReturn               | 18.6      |
| Time                    | 330       |
| dLoss                   | 0.0192654 |
---------------------------------------
itr #42 | 
Mem: 652.035156
Obtaining samples...
Obtaining samples for iteration 42...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5053, #subsample_inputs: 5053
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.59       |
| AbsLearnSignalNew       | 0.59       |
| AbsLearningOld          | 0.59       |
| AverageDiscountedReturn | 167        |
| AveragePhiLoss          | 5.99833    |
| AveragePolicyStd        | 0.874107   |
| AverageReturn           | 343        |
| Entropy                 | 3.85145    |
| EnvExecTime             | 1.75       |
| ExplainedVariance       | 0.932      |
| Iteration               | 42         |
| ItrTime                 | 7.77       |
| LossAfter               | 0.232177   |
| LossBefore              | 0.262491   |
| MaxReturn               | 393        |
| MeanKL                  | 0.00924365 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 229        |
| NumTrajs                | 37         |
| Perplexity              | 47.0614    |
| PolicyExecTime          | 0.437      |
| ProcessExecTime         | 0.0532     |
| StdReturn               | 28.8       |
| Time                    | 338        |
| dLoss                   | 0.0303144  |
----------------------------------------
itr #43 | 
Mem: 652.035156
Obtaining samples...
Obtaining samples for iteration 43...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5126, #subsample_inputs: 5126
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.585      |
| AbsLearnSignalNew       | 0.585      |
| AbsLearningOld          | 0.585      |
| AverageDiscountedReturn | 170        |
| AveragePhiLoss          | 6.11098    |
| AveragePolicyStd        | 0.86916    |
| AverageReturn           | 353        |
| Entropy                 | 3.83406    |
| EnvExecTime             | 2          |
| ExplainedVariance       | 0.889      |
| Iteration               | 43         |
| ItrTime                 | 8.12       |
| LossAfter               | -0.152768  |
| LossBefore              | -0.127462  |
| MaxReturn               | 424        |
| MeanKL                  | 0.00663588 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 288        |
| NumTrajs                | 37         |
| Perplexity              | 46.2498    |
| PolicyExecTime          | 0.481      |
| ProcessExecTime         | 0.0613     |
| StdReturn               | 32.1       |
| Time                    | 346        |
| dLoss                   | 0.0253054  |
----------------------------------------
itr #44 | 
Mem: 652.035156
Obtaining samples...
Obtaining samples for iteration 44...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5065, #subsample_inputs: 5065
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.757      |
| AbsLearnSignalNew       | 0.757      |
| AbsLearningOld          | 0.758      |
| AverageDiscountedReturn | 175        |
| AveragePhiLoss          | 6.48535    |
| AveragePolicyStd        | 0.863931   |
| AverageReturn           | 376        |
| Entropy                 | 3.81606    |
| EnvExecTime             | 1.84       |
| ExplainedVariance       | 0.901      |
| Iteration               | 44         |
| ItrTime                 | 7.88       |
| LossAfter               | 0.178489   |
| LossBefore              | 0.201269   |
| MaxReturn               | 433        |
| MeanKL                  | 0.00643362 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 319        |
| NumTrajs                | 35         |
| Perplexity              | 45.4248    |
| PolicyExecTime          | 0.446      |
| ProcessExecTime         | 0.0577     |
| StdReturn               | 35.5       |
| Time                    | 354        |
| dLoss                   | 0.0227798  |
----------------------------------------
itr #45 | 
Mem: 652.550781
Obtaining samples...
Obtaining samples for iteration 45...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5091, #subsample_inputs: 5091
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.534      |
| AbsLearnSignalNew       | 0.534      |
| AbsLearningOld          | 0.534      |
| AverageDiscountedReturn | 172        |
| AveragePhiLoss          | 8.06562    |
| AveragePolicyStd        | 0.863043   |
| AverageReturn           | 367        |
| Entropy                 | 3.81299    |
| EnvExecTime             | 1.92       |
| ExplainedVariance       | 0.752      |
| Iteration               | 45         |
| ItrTime                 | 8.05       |
| LossAfter               | -0.0912123 |
| LossBefore              | -0.0645606 |
| MaxReturn               | 512        |
| MeanKL                  | 0.00663818 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 186        |
| NumTrajs                | 36         |
| Perplexity              | 45.2856    |
| PolicyExecTime          | 0.471      |
| ProcessExecTime         | 0.059      |
| StdReturn               | 70         |
| Time                    | 362        |
| dLoss                   | 0.0266518  |
----------------------------------------
itr #46 | 
Mem: 652.550781
Obtaining samples...
Obtaining samples for iteration 46...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5044, #subsample_inputs: 5044
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.727      |
| AbsLearnSignalNew       | 0.727      |
| AbsLearningOld          | 0.727      |
| AverageDiscountedReturn | 177        |
| AveragePhiLoss          | 6.90544    |
| AveragePolicyStd        | 0.856739   |
| AverageReturn           | 378        |
| Entropy                 | 3.79054    |
| EnvExecTime             | 1.78       |
| ExplainedVariance       | 0.909      |
| Iteration               | 46         |
| ItrTime                 | 7.83       |
| LossAfter               | 0.0823988  |
| LossBefore              | 0.105889   |
| MaxReturn               | 493        |
| MeanKL                  | 0.00651416 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 317        |
| NumTrajs                | 35         |
| Perplexity              | 44.2802    |
| PolicyExecTime          | 0.437      |
| ProcessExecTime         | 0.0543     |
| StdReturn               | 36.5       |
| Time                    | 370        |
| dLoss                   | 0.0234905  |
----------------------------------------
itr #47 | 
Mem: 652.550781
Obtaining samples...
Obtaining samples for iteration 47...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5034, #subsample_inputs: 5034
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.589      |
| AbsLearnSignalNew       | 0.589      |
| AbsLearningOld          | 0.589      |
| AverageDiscountedReturn | 176        |
| AveragePhiLoss          | 6.96558    |
| AveragePolicyStd        | 0.852538   |
| AverageReturn           | 376        |
| Entropy                 | 3.77655    |
| EnvExecTime             | 1.63       |
| ExplainedVariance       | 0.812      |
| Iteration               | 47         |
| ItrTime                 | 7.6        |
| LossAfter               | -0.223031  |
| LossBefore              | -0.196221  |
| MaxReturn               | 468        |
| MeanKL                  | 0.00649213 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 296        |
| NumTrajs                | 35         |
| Perplexity              | 43.6653    |
| PolicyExecTime          | 0.408      |
| ProcessExecTime         | 0.0505     |
| StdReturn               | 47.7       |
| Time                    | 378        |
| dLoss                   | 0.0268096  |
----------------------------------------
itr #48 | 
Mem: 652.550781
Obtaining samples...
Obtaining samples for iteration 48...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5138, #subsample_inputs: 5138
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.68       |
| AbsLearnSignalNew       | 0.68       |
| AbsLearningOld          | 0.68       |
| AverageDiscountedReturn | 179        |
| AveragePhiLoss          | 7.52912    |
| AveragePolicyStd        | 0.842694   |
| AverageReturn           | 390        |
| Entropy                 | 3.74157    |
| EnvExecTime             | 1.71       |
| ExplainedVariance       | 0.823      |
| Iteration               | 48         |
| ItrTime                 | 7.79       |
| LossAfter               | -0.439313  |
| LossBefore              | -0.416619  |
| MaxReturn               | 488        |
| MeanKL                  | 0.00959525 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 248        |
| NumTrajs                | 35         |
| Perplexity              | 42.1641    |
| PolicyExecTime          | 0.43       |
| ProcessExecTime         | 0.0525     |
| StdReturn               | 50.8       |
| Time                    | 386        |
| dLoss                   | 0.0226931  |
----------------------------------------
itr #49 | 
Mem: 652.550781
Obtaining samples...
Obtaining samples for iteration 49...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5059, #subsample_inputs: 5059
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.576      |
| AbsLearnSignalNew       | 0.576      |
| AbsLearningOld          | 0.576      |
| AverageDiscountedReturn | 180        |
| AveragePhiLoss          | 7.84883    |
| AveragePolicyStd        | 0.8352     |
| AverageReturn           | 397        |
| Entropy                 | 3.71428    |
| EnvExecTime             | 1.78       |
| ExplainedVariance       | 0.807      |
| Iteration               | 49         |
| ItrTime                 | 7.82       |
| LossAfter               | -0.198021  |
| LossBefore              | -0.174403  |
| MaxReturn               | 498        |
| MeanKL                  | 0.00948437 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 204        |
| NumTrajs                | 34         |
| Perplexity              | 41.0288    |
| PolicyExecTime          | 0.441      |
| ProcessExecTime         | 0.0541     |
| StdReturn               | 64.9       |
| Time                    | 394        |
| dLoss                   | 0.0236186  |
----------------------------------------
itr #50 | 
Mem: 652.550781
Obtaining samples...
Obtaining samples for iteration 50...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5023, #subsample_inputs: 5023
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.634      |
| AbsLearnSignalNew       | 0.634      |
| AbsLearningOld          | 0.634      |
| AverageDiscountedReturn | 182        |
| AveragePhiLoss          | 6.32315    |
| AveragePolicyStd        | 0.836309   |
| AverageReturn           | 407        |
| Entropy                 | 3.71814    |
| EnvExecTime             | 1.91       |
| ExplainedVariance       | 0.853      |
| Iteration               | 50         |
| ItrTime                 | 7.98       |
| LossAfter               | -0.0668692 |
| LossBefore              | -0.0461496 |
| MaxReturn               | 493        |
| MeanKL                  | 0.00640306 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 200        |
| NumTrajs                | 33         |
| Perplexity              | 41.1876    |
| PolicyExecTime          | 0.463      |
| ProcessExecTime         | 0.0582     |
| StdReturn               | 57.2       |
| Time                    | 402        |
| dLoss                   | 0.0207196  |
----------------------------------------
itr #51 | 
Mem: 652.550781
Obtaining samples...
Obtaining samples for iteration 51...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5022, #subsample_inputs: 5022
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.548      |
| AbsLearnSignalNew       | 0.548      |
| AbsLearningOld          | 0.548      |
| AverageDiscountedReturn | 182        |
| AveragePhiLoss          | 7.73241    |
| AveragePolicyStd        | 0.838701   |
| AverageReturn           | 408        |
| Entropy                 | 3.72543    |
| EnvExecTime             | 1.76       |
| ExplainedVariance       | 0.786      |
| Iteration               | 51         |
| ItrTime                 | 7.77       |
| LossAfter               | -0.0737409 |
| LossBefore              | -0.0465344 |
| MaxReturn               | 494        |
| MeanKL                  | 0.00935925 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 214        |
| NumTrajs                | 33         |
| Perplexity              | 41.4889    |
| PolicyExecTime          | 0.443      |
| ProcessExecTime         | 0.0539     |
| StdReturn               | 56.4       |
| Time                    | 410        |
| dLoss                   | 0.0272064  |
----------------------------------------
itr #52 | 
Mem: 652.550781
Obtaining samples...
Obtaining samples for iteration 52...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5021, #subsample_inputs: 5021
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.726      |
| AbsLearnSignalNew       | 0.726      |
| AbsLearningOld          | 0.726      |
| AverageDiscountedReturn | 190        |
| AveragePhiLoss          | 7.05268    |
| AveragePolicyStd        | 0.835656   |
| AverageReturn           | 445        |
| Entropy                 | 3.71308    |
| EnvExecTime             | 2.01       |
| ExplainedVariance       | 0.859      |
| Iteration               | 52         |
| ItrTime                 | 8.12       |
| LossAfter               | 0.25893    |
| LossBefore              | 0.279515   |
| MaxReturn               | 564        |
| MeanKL                  | 0.00644619 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 324        |
| NumTrajs                | 31         |
| Perplexity              | 40.98      |
| PolicyExecTime          | 0.488      |
| ProcessExecTime         | 0.0596     |
| StdReturn               | 57.6       |
| Time                    | 418        |
| dLoss                   | 0.0205851  |
----------------------------------------
itr #53 | 
Mem: 652.550781
Obtaining samples...
Obtaining samples for iteration 53...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5143, #subsample_inputs: 5143
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.606      |
| AbsLearnSignalNew       | 0.606      |
| AbsLearningOld          | 0.606      |
| AverageDiscountedReturn | 192        |
| AveragePhiLoss          | 7.24803    |
| AveragePolicyStd        | 0.835483   |
| AverageReturn           | 461        |
| Entropy                 | 3.7127     |
| EnvExecTime             | 1.94       |
| ExplainedVariance       | 0.826      |
| Iteration               | 53         |
| ItrTime                 | 8.05       |
| LossAfter               | -0.518686  |
| LossBefore              | -0.492024  |
| MaxReturn               | 669        |
| MeanKL                  | 0.00990978 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 203        |
| NumTrajs                | 31         |
| Perplexity              | 40.9643    |
| PolicyExecTime          | 0.477      |
| ProcessExecTime         | 0.0601     |
| StdReturn               | 79.6       |
| Time                    | 426        |
| dLoss                   | 0.0266619  |
----------------------------------------
itr #54 | 
Mem: 654.867188
Obtaining samples...
Obtaining samples for iteration 54...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5010, #subsample_inputs: 5010
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.774      |
| AbsLearnSignalNew       | 0.774      |
| AbsLearningOld          | 0.774      |
| AverageDiscountedReturn | 194        |
| AveragePhiLoss          | 7.32119    |
| AveragePolicyStd        | 0.838098   |
| AverageReturn           | 468        |
| Entropy                 | 3.72277    |
| EnvExecTime             | 1.8        |
| ExplainedVariance       | 0.923      |
| Iteration               | 54         |
| ItrTime                 | 7.84       |
| LossAfter               | -0.576762  |
| LossBefore              | -0.552217  |
| MaxReturn               | 551        |
| MeanKL                  | 0.00935823 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 356        |
| NumTrajs                | 30         |
| Perplexity              | 41.379     |
| PolicyExecTime          | 0.443      |
| ProcessExecTime         | 0.056      |
| StdReturn               | 49         |
| Time                    | 434        |
| dLoss                   | 0.0245451  |
----------------------------------------
itr #55 | 
Mem: 654.867188
Obtaining samples...
Obtaining samples for iteration 55...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5035, #subsample_inputs: 5035
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.759      |
| AbsLearnSignalNew       | 0.759      |
| AbsLearningOld          | 0.759      |
| AverageDiscountedReturn | 199        |
| AveragePhiLoss          | 7.49043    |
| AveragePolicyStd        | 0.836446   |
| AverageReturn           | 494        |
| Entropy                 | 3.71737    |
| EnvExecTime             | 1.89       |
| ExplainedVariance       | 0.943      |
| Iteration               | 55         |
| ItrTime                 | 7.9        |
| LossAfter               | 0.190109   |
| LossBefore              | 0.216528   |
| MaxReturn               | 589        |
| MeanKL                  | 0.00985677 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 415        |
| NumTrajs                | 29         |
| Perplexity              | 41.156     |
| PolicyExecTime          | 0.461      |
| ProcessExecTime         | 0.0575     |
| StdReturn               | 44.9       |
| Time                    | 442        |
| dLoss                   | 0.0264187  |
----------------------------------------
itr #56 | 
Mem: 656.921875
Obtaining samples...
Obtaining samples for iteration 56...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5011, #subsample_inputs: 5011
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.571      |
| AbsLearnSignalNew       | 0.571      |
| AbsLearningOld          | 0.571      |
| AverageDiscountedReturn | 198        |
| AveragePhiLoss          | 7.65864    |
| AveragePolicyStd        | 0.827766   |
| AverageReturn           | 494        |
| Entropy                 | 3.68748    |
| EnvExecTime             | 1.81       |
| ExplainedVariance       | 0.821      |
| Iteration               | 56         |
| ItrTime                 | 7.81       |
| LossAfter               | 0.288274   |
| LossBefore              | 0.306261   |
| MaxReturn               | 573        |
| MeanKL                  | 0.00643303 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 195        |
| NumTrajs                | 29         |
| Perplexity              | 39.9439    |
| PolicyExecTime          | 0.452      |
| ProcessExecTime         | 0.0541     |
| StdReturn               | 77.9       |
| Time                    | 450        |
| dLoss                   | 0.017987   |
----------------------------------------
itr #57 | 
Mem: 656.921875
Obtaining samples...
Obtaining samples for iteration 57...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5085, #subsample_inputs: 5085
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.623     |
| AbsLearnSignalNew       | 0.623     |
| AbsLearningOld          | 0.623     |
| AverageDiscountedReturn | 201       |
| AveragePhiLoss          | 9.3757    |
| AveragePolicyStd        | 0.827755  |
| AverageReturn           | 505       |
| Entropy                 | 3.68621   |
| EnvExecTime             | 1.8       |
| ExplainedVariance       | 0.846     |
| Iteration               | 57        |
| ItrTime                 | 7.91      |
| LossAfter               | 0.0519011 |
| LossBefore              | 0.0854123 |
| MaxReturn               | 579       |
| MeanKL                  | 0.0068063 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 380       |
| NumTrajs                | 29        |
| Perplexity              | 39.8933   |
| PolicyExecTime          | 0.448     |
| ProcessExecTime         | 0.0561    |
| StdReturn               | 55.5      |
| Time                    | 458       |
| dLoss                   | 0.0335112 |
---------------------------------------
itr #58 | 
Mem: 656.921875
Obtaining samples...
Obtaining samples for iteration 58...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5025, #subsample_inputs: 5025
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.815      |
| AbsLearnSignalNew       | 0.815      |
| AbsLearningOld          | 0.815      |
| AverageDiscountedReturn | 204        |
| AveragePhiLoss          | 7.62347    |
| AveragePolicyStd        | 0.823708   |
| AverageReturn           | 521        |
| Entropy                 | 3.67115    |
| EnvExecTime             | 1.72       |
| ExplainedVariance       | 0.934      |
| Iteration               | 58         |
| ItrTime                 | 7.74       |
| LossAfter               | 0.17868    |
| LossBefore              | 0.200554   |
| MaxReturn               | 594        |
| MeanKL                  | 0.00649565 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 422        |
| NumTrajs                | 28         |
| Perplexity              | 39.2972    |
| PolicyExecTime          | 0.433      |
| ProcessExecTime         | 0.0526     |
| StdReturn               | 44.8       |
| Time                    | 465        |
| dLoss                   | 0.021874   |
----------------------------------------
itr #59 | 
Mem: 656.921875
Obtaining samples...
Obtaining samples for iteration 59...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5022, #subsample_inputs: 5022
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.575      |
| AbsLearnSignalNew       | 0.575      |
| AbsLearningOld          | 0.575      |
| AverageDiscountedReturn | 204        |
| AveragePhiLoss          | 8.14361    |
| AveragePolicyStd        | 0.819079   |
| AverageReturn           | 525        |
| Entropy                 | 3.65457    |
| EnvExecTime             | 1.82       |
| ExplainedVariance       | 0.878      |
| Iteration               | 59         |
| ItrTime                 | 7.88       |
| LossAfter               | -0.193333  |
| LossBefore              | -0.171632  |
| MaxReturn               | 631        |
| MeanKL                  | 0.00645354 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 215        |
| NumTrajs                | 28         |
| Perplexity              | 38.6511    |
| PolicyExecTime          | 0.453      |
| ProcessExecTime         | 0.0553     |
| StdReturn               | 73.9       |
| Time                    | 473        |
| dLoss                   | 0.0217009  |
----------------------------------------
itr #60 | 
Mem: 656.921875
Obtaining samples...
Obtaining samples for iteration 60...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5093, #subsample_inputs: 5093
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.555      |
| AbsLearnSignalNew       | 0.555      |
| AbsLearningOld          | 0.555      |
| AverageDiscountedReturn | 205        |
| AveragePhiLoss          | 7.85761    |
| AveragePolicyStd        | 0.819373   |
| AverageReturn           | 531        |
| Entropy                 | 3.65557    |
| EnvExecTime             | 1.91       |
| ExplainedVariance       | 0.851      |
| Iteration               | 60         |
| ItrTime                 | 8.04       |
| LossAfter               | -0.523518  |
| LossBefore              | -0.496353  |
| MaxReturn               | 652        |
| MeanKL                  | 0.00963057 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 225        |
| NumTrajs                | 28         |
| Perplexity              | 38.6896    |
| PolicyExecTime          | 0.469      |
| ProcessExecTime         | 0.0575     |
| StdReturn               | 72.9       |
| Time                    | 481        |
| dLoss                   | 0.0271654  |
----------------------------------------
itr #61 | 
Mem: 656.921875
Obtaining samples...
Obtaining samples for iteration 61...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5077, #subsample_inputs: 5077
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.771      |
| AbsLearnSignalNew       | 0.771      |
| AbsLearningOld          | 0.772      |
| AverageDiscountedReturn | 210        |
| AveragePhiLoss          | 7.15263    |
| AveragePolicyStd        | 0.821579   |
| AverageReturn           | 558        |
| Entropy                 | 3.66325    |
| EnvExecTime             | 1.77       |
| ExplainedVariance       | 0.928      |
| Iteration               | 61         |
| ItrTime                 | 7.85       |
| LossAfter               | -0.530167  |
| LossBefore              | -0.49963   |
| MaxReturn               | 727        |
| MeanKL                  | 0.00994704 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 438        |
| NumTrajs                | 27         |
| Perplexity              | 38.9877    |
| PolicyExecTime          | 0.444      |
| ProcessExecTime         | 0.0531     |
| StdReturn               | 60.4       |
| Time                    | 489        |
| dLoss                   | 0.0305367  |
----------------------------------------
itr #62 | 
Mem: 656.921875
Obtaining samples...
Obtaining samples for iteration 62...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5168, #subsample_inputs: 5168
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.768      |
| AbsLearnSignalNew       | 0.768      |
| AbsLearningOld          | 0.768      |
| AverageDiscountedReturn | 215        |
| AveragePhiLoss          | 7.81125    |
| AveragePolicyStd        | 0.81525    |
| AverageReturn           | 595        |
| Entropy                 | 3.63995    |
| EnvExecTime             | 1.85       |
| ExplainedVariance       | 0.937      |
| Iteration               | 62         |
| ItrTime                 | 8.08       |
| LossAfter               | -0.472957  |
| LossBefore              | -0.452726  |
| MaxReturn               | 683        |
| MeanKL                  | 0.00651561 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 483        |
| NumTrajs                | 26         |
| Perplexity              | 38.0898    |
| PolicyExecTime          | 0.47       |
| ProcessExecTime         | 0.0567     |
| StdReturn               | 52.7       |
| Time                    | 497        |
| dLoss                   | 0.0202306  |
----------------------------------------
itr #63 | 
Mem: 657.695312
Obtaining samples...
Obtaining samples for iteration 63...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5042, #subsample_inputs: 5042
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.66       |
| AbsLearnSignalNew       | 0.66       |
| AbsLearningOld          | 0.66       |
| AverageDiscountedReturn | 215        |
| AveragePhiLoss          | 9.03501    |
| AveragePolicyStd        | 0.809687   |
| AverageReturn           | 603        |
| Entropy                 | 3.61692    |
| EnvExecTime             | 1.71       |
| ExplainedVariance       | 0.901      |
| Iteration               | 63         |
| ItrTime                 | 7.7        |
| LossAfter               | -0.705089  |
| LossBefore              | -0.678613  |
| MaxReturn               | 690        |
| MeanKL                  | 0.00999317 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 400        |
| NumTrajs                | 25         |
| Perplexity              | 37.2227    |
| PolicyExecTime          | 0.433      |
| ProcessExecTime         | 0.0531     |
| StdReturn               | 66.7       |
| Time                    | 505        |
| dLoss                   | 0.0264757  |
----------------------------------------
itr #64 | 
Mem: 657.695312
Obtaining samples...
Obtaining samples for iteration 64...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5054, #subsample_inputs: 5054
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.778     |
| AbsLearnSignalNew       | 0.778     |
| AbsLearningOld          | 0.778     |
| AverageDiscountedReturn | 219       |
| AveragePhiLoss          | 7.89686   |
| AveragePolicyStd        | 0.805358  |
| AverageReturn           | 638       |
| Entropy                 | 3.59915   |
| EnvExecTime             | 1.72      |
| ExplainedVariance       | 0.939     |
| Iteration               | 64        |
| ItrTime                 | 7.7       |
| LossAfter               | 0.099857  |
| LossBefore              | 0.125208  |
| MaxReturn               | 804       |
| MeanKL                  | 0.0098945 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 493       |
| NumTrajs                | 24        |
| Perplexity              | 36.5672   |
| PolicyExecTime          | 0.428     |
| ProcessExecTime         | 0.0526    |
| StdReturn               | 75        |
| Time                    | 513       |
| dLoss                   | 0.025351  |
---------------------------------------
itr #65 | 
Mem: 657.695312
Obtaining samples...
Obtaining samples for iteration 65...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5151, #subsample_inputs: 5151
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.789     |
| AbsLearnSignalNew       | 0.789     |
| AbsLearningOld          | 0.789     |
| AverageDiscountedReturn | 221       |
| AveragePhiLoss          | 7.55152   |
| AveragePolicyStd        | 0.808129  |
| AverageReturn           | 657       |
| Entropy                 | 3.60851   |
| EnvExecTime             | 1.84      |
| ExplainedVariance       | 0.956     |
| Iteration               | 65        |
| ItrTime                 | 7.97      |
| LossAfter               | -0.725585 |
| LossBefore              | -0.699064 |
| MaxReturn               | 781       |
| MeanKL                  | 0.0096864 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 539       |
| NumTrajs                | 24        |
| Perplexity              | 36.9108   |
| PolicyExecTime          | 0.459     |
| ProcessExecTime         | 0.059     |
| StdReturn               | 63.4      |
| Time                    | 521       |
| dLoss                   | 0.0265203 |
---------------------------------------
itr #66 | 
Mem: 658.468750
Obtaining samples...
Obtaining samples for iteration 66...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5045, #subsample_inputs: 5045
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.567      |
| AbsLearnSignalNew       | 0.567      |
| AbsLearningOld          | 0.568      |
| AverageDiscountedReturn | 213        |
| AveragePhiLoss          | 9.20587    |
| AveragePolicyStd        | 0.807153   |
| AverageReturn           | 600        |
| Entropy                 | 3.60328    |
| EnvExecTime             | 1.93       |
| ExplainedVariance       | 0.783      |
| Iteration               | 66         |
| ItrTime                 | 7.99       |
| LossAfter               | 0.12963    |
| LossBefore              | 0.156823   |
| MaxReturn               | 778        |
| MeanKL                  | 0.00650629 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 389        |
| NumTrajs                | 25         |
| Perplexity              | 36.7184    |
| PolicyExecTime          | 0.47       |
| ProcessExecTime         | 0.0595     |
| StdReturn               | 98.9       |
| Time                    | 529        |
| dLoss                   | 0.0271922  |
----------------------------------------
itr #67 | 
Mem: 658.468750
Obtaining samples...
Obtaining samples for iteration 67...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5195, #subsample_inputs: 5195
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.781      |
| AbsLearnSignalNew       | 0.781      |
| AbsLearningOld          | 0.781      |
| AverageDiscountedReturn | 219        |
| AveragePhiLoss          | 8.10216    |
| AveragePolicyStd        | 0.803384   |
| AverageReturn           | 655        |
| Entropy                 | 3.58764    |
| EnvExecTime             | 1.81       |
| ExplainedVariance       | 0.904      |
| Iteration               | 67         |
| ItrTime                 | 7.99       |
| LossAfter               | -0.0825272 |
| LossBefore              | -0.0586213 |
| MaxReturn               | 776        |
| MeanKL                  | 0.00960049 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 457        |
| NumTrajs                | 24         |
| Perplexity              | 36.1487    |
| PolicyExecTime          | 0.456      |
| ProcessExecTime         | 0.0559     |
| StdReturn               | 74         |
| Time                    | 537        |
| dLoss                   | 0.0239059  |
----------------------------------------
itr #68 | 
Mem: 658.468750
Obtaining samples...
Obtaining samples for iteration 68...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5112, #subsample_inputs: 5112
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.677      |
| AbsLearnSignalNew       | 0.677      |
| AbsLearningOld          | 0.677      |
| AverageDiscountedReturn | 223        |
| AveragePhiLoss          | 9.65495    |
| AveragePolicyStd        | 0.801854   |
| AverageReturn           | 685        |
| Entropy                 | 3.58436    |
| EnvExecTime             | 1.77       |
| ExplainedVariance       | 0.895      |
| Iteration               | 68         |
| ItrTime                 | 7.86       |
| LossAfter               | 0.344958   |
| LossBefore              | 0.371089   |
| MaxReturn               | 807        |
| MeanKL                  | 0.00925244 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 346        |
| NumTrajs                | 23         |
| Perplexity              | 36.0302    |
| PolicyExecTime          | 0.451      |
| ProcessExecTime         | 0.0542     |
| StdReturn               | 85.1       |
| Time                    | 545        |
| dLoss                   | 0.026131   |
----------------------------------------
itr #69 | 
Mem: 658.468750
Obtaining samples...
Obtaining samples for iteration 69...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5450, #subsample_inputs: 5450
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.502      |
| AbsLearnSignalNew       | 0.502      |
| AbsLearningOld          | 0.503      |
| AverageDiscountedReturn | 214        |
| AveragePhiLoss          | 9.37563    |
| AveragePolicyStd        | 0.798046   |
| AverageReturn           | 641        |
| Entropy                 | 3.57152    |
| EnvExecTime             | 1.93       |
| ExplainedVariance       | 0.696      |
| Iteration               | 69         |
| ItrTime                 | 8.39       |
| LossAfter               | -0.528313  |
| LossBefore              | -0.496472  |
| MaxReturn               | 809        |
| MeanKL                  | 0.00973019 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 199        |
| NumTrajs                | 26         |
| Perplexity              | 35.5707    |
| PolicyExecTime          | 0.476      |
| ProcessExecTime         | 0.0593     |
| StdReturn               | 162        |
| Time                    | 553        |
| dLoss                   | 0.0318406  |
----------------------------------------
itr #70 | 
Mem: 660.527344
Obtaining samples...
Obtaining samples for iteration 70...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5042, #subsample_inputs: 5042
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.649      |
| AbsLearnSignalNew       | 0.649      |
| AbsLearningOld          | 0.649      |
| AverageDiscountedReturn | 221        |
| AveragePhiLoss          | 8.1246     |
| AveragePolicyStd        | 0.797456   |
| AverageReturn           | 672        |
| Entropy                 | 3.56781    |
| EnvExecTime             | 1.88       |
| ExplainedVariance       | 0.836      |
| Iteration               | 70         |
| ItrTime                 | 7.93       |
| LossAfter               | -0.303303  |
| LossBefore              | -0.283157  |
| MaxReturn               | 810        |
| MeanKL                  | 0.00660717 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 300        |
| NumTrajs                | 23         |
| Perplexity              | 35.4388    |
| PolicyExecTime          | 0.468      |
| ProcessExecTime         | 0.0559     |
| StdReturn               | 97.3       |
| Time                    | 561        |
| dLoss                   | 0.0201456  |
----------------------------------------
itr #71 | 
Mem: 660.527344
Obtaining samples...
Obtaining samples for iteration 71...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5007, #subsample_inputs: 5007
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.564      |
| AbsLearnSignalNew       | 0.564      |
| AbsLearningOld          | 0.564      |
| AverageDiscountedReturn | 221        |
| AveragePhiLoss          | 11.1581    |
| AveragePolicyStd        | 0.800985   |
| AverageReturn           | 672        |
| Entropy                 | 3.57689    |
| EnvExecTime             | 1.87       |
| ExplainedVariance       | 0.856      |
| Iteration               | 71         |
| ItrTime                 | 7.85       |
| LossAfter               | 0.294115   |
| LossBefore              | 0.327387   |
| MaxReturn               | 809        |
| MeanKL                  | 0.00952253 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 221        |
| NumTrajs                | 23         |
| Perplexity              | 35.7622    |
| PolicyExecTime          | 0.465      |
| ProcessExecTime         | 0.0573     |
| StdReturn               | 109        |
| Time                    | 569        |
| dLoss                   | 0.0332724  |
----------------------------------------
itr #72 | 
Mem: 660.527344
Obtaining samples...
Obtaining samples for iteration 72...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5090, #subsample_inputs: 5090
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.749      |
| AbsLearnSignalNew       | 0.749      |
| AbsLearningOld          | 0.749      |
| AverageDiscountedReturn | 227        |
| AveragePhiLoss          | 9.12023    |
| AveragePolicyStd        | 0.794917   |
| AverageReturn           | 721        |
| Entropy                 | 3.55162    |
| EnvExecTime             | 1.82       |
| ExplainedVariance       | 0.948      |
| Iteration               | 72         |
| ItrTime                 | 7.89       |
| LossAfter               | 0.026634   |
| LossBefore              | 0.0534841  |
| MaxReturn               | 990        |
| MeanKL                  | 0.00999889 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 611        |
| NumTrajs                | 22         |
| Perplexity              | 34.8697    |
| PolicyExecTime          | 0.458      |
| ProcessExecTime         | 0.0552     |
| StdReturn               | 68.7       |
| Time                    | 577        |
| dLoss                   | 0.0268501  |
----------------------------------------
itr #73 | 
Mem: 660.527344
Obtaining samples...
Obtaining samples for iteration 73...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5030, #subsample_inputs: 5030
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.785      |
| AbsLearnSignalNew       | 0.785      |
| AbsLearningOld          | 0.785      |
| AverageDiscountedReturn | 228        |
| AveragePhiLoss          | 8.61186    |
| AveragePolicyStd        | 0.803296   |
| AverageReturn           | 718        |
| Entropy                 | 3.58459    |
| EnvExecTime             | 1.87       |
| ExplainedVariance       | 0.967      |
| Iteration               | 73         |
| ItrTime                 | 7.94       |
| LossAfter               | -0.399871  |
| LossBefore              | -0.378303  |
| MaxReturn               | 878        |
| MeanKL                  | 0.00641671 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 607        |
| NumTrajs                | 22         |
| Perplexity              | 36.0384    |
| PolicyExecTime          | 0.468      |
| ProcessExecTime         | 0.0564     |
| StdReturn               | 55.2       |
| Time                    | 585        |
| dLoss                   | 0.0215684  |
----------------------------------------
itr #74 | 
Mem: 662.070312
Obtaining samples...
Obtaining samples for iteration 74...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5055, #subsample_inputs: 5055
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.794      |
| AbsLearnSignalNew       | 0.794      |
| AbsLearningOld          | 0.794      |
| AverageDiscountedReturn | 227        |
| AveragePhiLoss          | 8.85884    |
| AveragePolicyStd        | 0.796497   |
| AverageReturn           | 721        |
| Entropy                 | 3.55869    |
| EnvExecTime             | 2.04       |
| ExplainedVariance       | 0.948      |
| Iteration               | 74         |
| ItrTime                 | 8.15       |
| LossAfter               | -0.333217  |
| LossBefore              | -0.313621  |
| MaxReturn               | 853        |
| MeanKL                  | 0.00666273 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 572        |
| NumTrajs                | 22         |
| Perplexity              | 35.117     |
| PolicyExecTime          | 0.503      |
| ProcessExecTime         | 0.0628     |
| StdReturn               | 79.4       |
| Time                    | 593        |
| dLoss                   | 0.019596   |
----------------------------------------
itr #75 | 
Mem: 662.070312
Obtaining samples...
Obtaining samples for iteration 75...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5093, #subsample_inputs: 5093
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.788      |
| AbsLearnSignalNew       | 0.788      |
| AbsLearningOld          | 0.788      |
| AverageDiscountedReturn | 226        |
| AveragePhiLoss          | 8.82898    |
| AveragePolicyStd        | 0.785697   |
| AverageReturn           | 720        |
| Entropy                 | 3.52134    |
| EnvExecTime             | 1.91       |
| ExplainedVariance       | 0.964      |
| Iteration               | 75         |
| ItrTime                 | 8.03       |
| LossAfter               | -0.708957  |
| LossBefore              | -0.684427  |
| MaxReturn               | 910        |
| MeanKL                  | 0.00970926 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 648        |
| NumTrajs                | 22         |
| Perplexity              | 33.8296    |
| PolicyExecTime          | 0.478      |
| ProcessExecTime         | 0.0594     |
| StdReturn               | 54.4       |
| Time                    | 601        |
| dLoss                   | 0.02453    |
----------------------------------------
itr #76 | 
Mem: 662.328125
Obtaining samples...
Obtaining samples for iteration 76...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5097, #subsample_inputs: 5097
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.753     |
| AbsLearnSignalNew       | 0.753     |
| AbsLearningOld          | 0.753     |
| AverageDiscountedReturn | 230       |
| AveragePhiLoss          | 8.43522   |
| AveragePolicyStd        | 0.781205  |
| AverageReturn           | 768       |
| Entropy                 | 3.5086    |
| EnvExecTime             | 1.94      |
| ExplainedVariance       | 0.953     |
| Iteration               | 76        |
| ItrTime                 | 8.09      |
| LossAfter               | -0.86497  |
| LossBefore              | -0.8374   |
| MaxReturn               | 1e+03     |
| MeanKL                  | 0.0096718 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 604       |
| NumTrajs                | 21        |
| Perplexity              | 33.4014   |
| PolicyExecTime          | 0.489     |
| ProcessExecTime         | 0.0578    |
| StdReturn               | 88.8      |
| Time                    | 610       |
| dLoss                   | 0.0275705 |
---------------------------------------
itr #77 | 
Mem: 662.609375
Obtaining samples...
Obtaining samples for iteration 77...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5229, #subsample_inputs: 5229
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.542      |
| AbsLearnSignalNew       | 0.542      |
| AbsLearningOld          | 0.542      |
| AverageDiscountedReturn | 227        |
| AveragePhiLoss          | 7.81667    |
| AveragePolicyStd        | 0.789264   |
| AverageReturn           | 743        |
| Entropy                 | 3.53931    |
| EnvExecTime             | 1.97       |
| ExplainedVariance       | 0.838      |
| Iteration               | 77         |
| ItrTime                 | 8.21       |
| LossAfter               | -0.394905  |
| LossBefore              | -0.365331  |
| MaxReturn               | 901        |
| MeanKL                  | 0.00887786 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 392        |
| NumTrajs                | 22         |
| Perplexity              | 34.443     |
| PolicyExecTime          | 0.49       |
| ProcessExecTime         | 0.0594     |
| StdReturn               | 111        |
| Time                    | 618        |
| dLoss                   | 0.0295739  |
----------------------------------------
itr #78 | 
Mem: 662.867188
Obtaining samples...
Obtaining samples for iteration 78...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5041, #subsample_inputs: 5041
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.627      |
| AbsLearnSignalNew       | 0.627      |
| AbsLearningOld          | 0.626      |
| AverageDiscountedReturn | 223        |
| AveragePhiLoss          | 9.51897    |
| AveragePolicyStd        | 0.790087   |
| AverageReturn           | 704        |
| Entropy                 | 3.54193    |
| EnvExecTime             | 1.83       |
| ExplainedVariance       | 0.884      |
| Iteration               | 78         |
| ItrTime                 | 7.86       |
| LossAfter               | 0.0108333  |
| LossBefore              | 0.0324894  |
| MaxReturn               | 810        |
| MeanKL                  | 0.00962662 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 600        |
| NumTrajs                | 22         |
| Perplexity              | 34.5335    |
| PolicyExecTime          | 0.46       |
| ProcessExecTime         | 0.0548     |
| StdReturn               | 54.3       |
| Time                    | 626        |
| dLoss                   | 0.0216561  |
----------------------------------------
itr #79 | 
Mem: 662.867188
Obtaining samples...
Obtaining samples for iteration 79...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5000, #subsample_inputs: 5000
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.663      |
| AbsLearnSignalNew       | 0.663      |
| AbsLearningOld          | 0.663      |
| AverageDiscountedReturn | 231        |
| AveragePhiLoss          | 8.11331    |
| AveragePolicyStd        | 0.788781   |
| AverageReturn           | 792        |
| Entropy                 | 3.53759    |
| EnvExecTime             | 1.74       |
| ExplainedVariance       | 0.802      |
| Iteration               | 79         |
| ItrTime                 | 7.72       |
| LossAfter               | 0.594539   |
| LossBefore              | 0.618078   |
| MaxReturn               | 997        |
| MeanKL                  | 0.00684918 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 657        |
| NumTrajs                | 20         |
| Perplexity              | 34.3838    |
| PolicyExecTime          | 0.445      |
| ProcessExecTime         | 0.0532     |
| StdReturn               | 99.4       |
| Time                    | 634        |
| dLoss                   | 0.0235396  |
----------------------------------------
itr #80 | 
Mem: 662.867188
Obtaining samples...
Obtaining samples for iteration 80...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5027, #subsample_inputs: 5027
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.788      |
| AbsLearnSignalNew       | 0.788      |
| AbsLearningOld          | 0.788      |
| AverageDiscountedReturn | 230        |
| AveragePhiLoss          | 8.4978     |
| AveragePolicyStd        | 0.789521   |
| AverageReturn           | 757        |
| Entropy                 | 3.53849    |
| EnvExecTime             | 2          |
| ExplainedVariance       | 0.969      |
| Iteration               | 80         |
| ItrTime                 | 8.09       |
| LossAfter               | -0.369     |
| LossBefore              | -0.34828   |
| MaxReturn               | 842        |
| MeanKL                  | 0.00640136 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 688        |
| NumTrajs                | 21         |
| Perplexity              | 34.4148    |
| PolicyExecTime          | 0.499      |
| ProcessExecTime         | 0.0597     |
| StdReturn               | 50.1       |
| Time                    | 642        |
| dLoss                   | 0.0207204  |
----------------------------------------
itr #81 | 
Mem: 662.867188
Obtaining samples...
Obtaining samples for iteration 81...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5242, #subsample_inputs: 5242
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.433      |
| AbsLearnSignalNew       | 0.433      |
| AbsLearningOld          | 0.433      |
| AverageDiscountedReturn | 220        |
| AveragePhiLoss          | 9.53975    |
| AveragePolicyStd        | 0.784361   |
| AverageReturn           | 707        |
| Entropy                 | 3.5183     |
| EnvExecTime             | 1.89       |
| ExplainedVariance       | 0.669      |
| Iteration               | 81         |
| ItrTime                 | 8.2        |
| LossAfter               | -0.843976  |
| LossBefore              | -0.819403  |
| MaxReturn               | 885        |
| MeanKL                  | 0.00646302 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 121        |
| NumTrajs                | 23         |
| Perplexity              | 33.7271    |
| PolicyExecTime          | 0.474      |
| ProcessExecTime         | 0.0572     |
| StdReturn               | 164        |
| Time                    | 650        |
| dLoss                   | 0.024573   |
----------------------------------------
itr #82 | 
Mem: 662.867188
Obtaining samples...
Obtaining samples for iteration 82...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5157, #subsample_inputs: 5157
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.705      |
| AbsLearnSignalNew       | 0.705      |
| AbsLearningOld          | 0.705      |
| AverageDiscountedReturn | 230        |
| AveragePhiLoss          | 9.01633    |
| AveragePolicyStd        | 0.783765   |
| AverageReturn           | 775        |
| Entropy                 | 3.51578    |
| EnvExecTime             | 1.88       |
| ExplainedVariance       | 0.851      |
| Iteration               | 82         |
| ItrTime                 | 8.04       |
| LossAfter               | 0.678141   |
| LossBefore              | 0.701024   |
| MaxReturn               | 989        |
| MeanKL                  | 0.00982638 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 599        |
| NumTrajs                | 21         |
| Perplexity              | 33.642     |
| PolicyExecTime          | 0.475      |
| ProcessExecTime         | 0.0562     |
| StdReturn               | 98.1       |
| Time                    | 658        |
| dLoss                   | 0.0228831  |
----------------------------------------
itr #83 | 
Mem: 663.382812
Obtaining samples...
Obtaining samples for iteration 83...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5280, #subsample_inputs: 5280
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.501      |
| AbsLearnSignalNew       | 0.501      |
| AbsLearningOld          | 0.501      |
| AverageDiscountedReturn | 226        |
| AveragePhiLoss          | 8.29992    |
| AveragePolicyStd        | 0.792886   |
| AverageReturn           | 789        |
| Entropy                 | 3.54628    |
| EnvExecTime             | 2.05       |
| ExplainedVariance       | 0.713      |
| Iteration               | 83         |
| ItrTime                 | 8.33       |
| LossAfter               | 0.392624   |
| LossBefore              | 0.412923   |
| MaxReturn               | 1.1e+03    |
| MeanKL                  | 0.00933714 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 190        |
| NumTrajs                | 21         |
| Perplexity              | 34.6842    |
| PolicyExecTime          | 0.507      |
| ProcessExecTime         | 0.0628     |
| StdReturn               | 174        |
| Time                    | 666        |
| dLoss                   | 0.0202989  |
----------------------------------------
itr #84 | 
Mem: 664.664062
Obtaining samples...
Obtaining samples for iteration 84...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5019, #subsample_inputs: 5019
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.508     |
| AbsLearnSignalNew       | 0.508     |
| AbsLearningOld          | 0.508     |
| AverageDiscountedReturn | 225       |
| AveragePhiLoss          | 8.11461   |
| AveragePolicyStd        | 0.794425  |
| AverageReturn           | 783       |
| Entropy                 | 3.55519   |
| EnvExecTime             | 1.82      |
| ExplainedVariance       | 0.637     |
| Iteration               | 84        |
| ItrTime                 | 7.87      |
| LossAfter               | 0.348881  |
| LossBefore              | 0.36953   |
| MaxReturn               | 1.1e+03   |
| MeanKL                  | 0.0065013 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 205       |
| NumTrajs                | 20        |
| Perplexity              | 34.9944   |
| PolicyExecTime          | 0.462     |
| ProcessExecTime         | 0.0547    |
| StdReturn               | 182       |
| Time                    | 674       |
| dLoss                   | 0.0206491 |
---------------------------------------
itr #85 | 
Mem: 664.664062
Obtaining samples...
Obtaining samples for iteration 85...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5209, #subsample_inputs: 5209
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.623      |
| AbsLearnSignalNew       | 0.623      |
| AbsLearningOld          | 0.624      |
| AverageDiscountedReturn | 227        |
| AveragePhiLoss          | 9.39678    |
| AveragePolicyStd        | 0.793159   |
| AverageReturn           | 777        |
| Entropy                 | 3.55272    |
| EnvExecTime             | 2.02       |
| ExplainedVariance       | 0.752      |
| Iteration               | 85         |
| ItrTime                 | 8.26       |
| LossAfter               | 0.333355   |
| LossBefore              | 0.353588   |
| MaxReturn               | 949        |
| MeanKL                  | 0.00676783 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 378        |
| NumTrajs                | 21         |
| Perplexity              | 34.9081    |
| PolicyExecTime          | 0.505      |
| ProcessExecTime         | 0.0626     |
| StdReturn               | 134        |
| Time                    | 683        |
| dLoss                   | 0.0202329  |
----------------------------------------
itr #86 | 
Mem: 664.921875
Obtaining samples...
Obtaining samples for iteration 86...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5176, #subsample_inputs: 5176
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.605      |
| AbsLearnSignalNew       | 0.605      |
| AbsLearningOld          | 0.605      |
| AverageDiscountedReturn | 223        |
| AveragePhiLoss          | 11.1783    |
| AveragePolicyStd        | 0.78656    |
| AverageReturn           | 773        |
| Entropy                 | 3.5269     |
| EnvExecTime             | 1.81       |
| ExplainedVariance       | 0.793      |
| Iteration               | 86         |
| ItrTime                 | 7.99       |
| LossAfter               | 0.385443   |
| LossBefore              | 0.411103   |
| MaxReturn               | 992        |
| MeanKL                  | 0.00966892 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 107        |
| NumTrajs                | 21         |
| Perplexity              | 34.0183    |
| PolicyExecTime          | 0.46       |
| ProcessExecTime         | 0.0547     |
| StdReturn               | 186        |
| Time                    | 691        |
| dLoss                   | 0.0256605  |
----------------------------------------
itr #87 | 
Mem: 664.921875
Obtaining samples...
Obtaining samples for iteration 87...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5024, #subsample_inputs: 5024
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.494      |
| AbsLearnSignalNew       | 0.494      |
| AbsLearningOld          | 0.494      |
| AverageDiscountedReturn | 227        |
| AveragePhiLoss          | 8.66316    |
| AveragePolicyStd        | 0.79069    |
| AverageReturn           | 788        |
| Entropy                 | 3.54058    |
| EnvExecTime             | 1.76       |
| ExplainedVariance       | 0.514      |
| Iteration               | 87         |
| ItrTime                 | 7.8        |
| LossAfter               | -0.483644  |
| LossBefore              | -0.459892  |
| MaxReturn               | 1.17e+03   |
| MeanKL                  | 0.00977357 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 246        |
| NumTrajs                | 20         |
| Perplexity              | 34.487     |
| PolicyExecTime          | 0.444      |
| ProcessExecTime         | 0.0544     |
| StdReturn               | 174        |
| Time                    | 699        |
| dLoss                   | 0.0237515  |
----------------------------------------
itr #88 | 
Mem: 672.921875
Obtaining samples...
Obtaining samples for iteration 88...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5218, #subsample_inputs: 5218
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.727      |
| AbsLearnSignalNew       | 0.727      |
| AbsLearningOld          | 0.727      |
| AverageDiscountedReturn | 232        |
| AveragePhiLoss          | 9.65205    |
| AveragePolicyStd        | 0.789131   |
| AverageReturn           | 826        |
| Entropy                 | 3.53151    |
| EnvExecTime             | 2.24       |
| ExplainedVariance       | 0.788      |
| Iteration               | 88         |
| ItrTime                 | 8.55       |
| LossAfter               | -0.37866   |
| LossBefore              | -0.354645  |
| MaxReturn               | 1.17e+03   |
| MeanKL                  | 0.00960517 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 635        |
| NumTrajs                | 20         |
| Perplexity              | 34.1754    |
| PolicyExecTime          | 0.545      |
| ProcessExecTime         | 0.0658     |
| StdReturn               | 124        |
| Time                    | 707        |
| dLoss                   | 0.0240142  |
----------------------------------------
itr #89 | 
Mem: 672.921875
Obtaining samples...
Obtaining samples for iteration 89...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5073, #subsample_inputs: 5073
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.557      |
| AbsLearnSignalNew       | 0.557      |
| AbsLearningOld          | 0.557      |
| AverageDiscountedReturn | 232        |
| AveragePhiLoss          | 9.75762    |
| AveragePolicyStd        | 0.774986   |
| AverageReturn           | 800        |
| Entropy                 | 3.47644    |
| EnvExecTime             | 1.72       |
| ExplainedVariance       | 0.807      |
| Iteration               | 89         |
| ItrTime                 | 7.8        |
| LossAfter               | -0.0160408 |
| LossBefore              | 0.0133955  |
| MaxReturn               | 997        |
| MeanKL                  | 0.00968275 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 617        |
| NumTrajs                | 20         |
| Perplexity              | 32.3445    |
| PolicyExecTime          | 0.441      |
| ProcessExecTime         | 0.0535     |
| StdReturn               | 103        |
| Time                    | 715        |
| dLoss                   | 0.0294363  |
----------------------------------------
itr #90 | 
Mem: 675.238281
Obtaining samples...
Obtaining samples for iteration 90...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5002, #subsample_inputs: 5002
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.75       |
| AbsLearnSignalNew       | 0.75       |
| AbsLearningOld          | 0.75       |
| AverageDiscountedReturn | 233        |
| AveragePhiLoss          | 9.39401    |
| AveragePolicyStd        | 0.768308   |
| AverageReturn           | 840        |
| Entropy                 | 3.45011    |
| EnvExecTime             | 1.64       |
| ExplainedVariance       | 0.831      |
| Iteration               | 90         |
| ItrTime                 | 7.62       |
| LossAfter               | 0.539665   |
| LossBefore              | 0.56347    |
| MaxReturn               | 1.05e+03   |
| MeanKL                  | 0.00982568 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 623        |
| NumTrajs                | 19         |
| Perplexity              | 31.504     |
| PolicyExecTime          | 0.424      |
| ProcessExecTime         | 0.0517     |
| StdReturn               | 125        |
| Time                    | 723        |
| dLoss                   | 0.0238041  |
----------------------------------------
itr #91 | 
Mem: 675.238281
Obtaining samples...
Obtaining samples for iteration 91...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5089, #subsample_inputs: 5089
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.44       |
| AbsLearnSignalNew       | 0.44       |
| AbsLearningOld          | 0.44       |
| AverageDiscountedReturn | 231        |
| AveragePhiLoss          | 14.2226    |
| AveragePolicyStd        | 0.763094   |
| AverageReturn           | 842        |
| Entropy                 | 3.42925    |
| EnvExecTime             | 2          |
| ExplainedVariance       | 0.39       |
| Iteration               | 91         |
| ItrTime                 | 8.21       |
| LossAfter               | 0.265744   |
| LossBefore              | 0.283531   |
| MaxReturn               | 1.34e+03   |
| MeanKL                  | 0.00671912 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 597        |
| NumTrajs                | 19         |
| Perplexity              | 30.8536    |
| PolicyExecTime          | 0.503      |
| ProcessExecTime         | 0.0605     |
| StdReturn               | 178        |
| Time                    | 731        |
| dLoss                   | 0.0177865  |
----------------------------------------
itr #92 | 
Mem: 675.238281
Obtaining samples...
Obtaining samples for iteration 92...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5174, #subsample_inputs: 5174
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.739      |
| AbsLearnSignalNew       | 0.739      |
| AbsLearningOld          | 0.739      |
| AverageDiscountedReturn | 232        |
| AveragePhiLoss          | 10.7705    |
| AveragePolicyStd        | 0.761375   |
| AverageReturn           | 825        |
| Entropy                 | 3.41835    |
| EnvExecTime             | 1.71       |
| ExplainedVariance       | 0.864      |
| Iteration               | 92         |
| ItrTime                 | 7.88       |
| LossAfter               | -0.42692   |
| LossBefore              | -0.410753  |
| MaxReturn               | 1.17e+03   |
| MeanKL                  | 0.00658088 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 653        |
| NumTrajs                | 20         |
| Perplexity              | 30.519     |
| PolicyExecTime          | 0.434      |
| ProcessExecTime         | 0.0525     |
| StdReturn               | 139        |
| Time                    | 739        |
| dLoss                   | 0.0161668  |
----------------------------------------
itr #93 | 
Mem: 675.238281
Obtaining samples...
Obtaining samples for iteration 93...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5230, #subsample_inputs: 5230
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
-----------------------------------------
| AbsLearnSignal          | 0.791       |
| AbsLearnSignalNew       | 0.791       |
| AbsLearningOld          | 0.791       |
| AverageDiscountedReturn | 235         |
| AveragePhiLoss          | 10.6711     |
| AveragePolicyStd        | 0.761101    |
| AverageReturn           | 839         |
| Entropy                 | 3.41359     |
| EnvExecTime             | 1.94        |
| ExplainedVariance       | 0.939       |
| Iteration               | 93          |
| ItrTime                 | 8.2         |
| LossAfter               | -0.00947423 |
| LossBefore              | 0.0157565   |
| MaxReturn               | 1.03e+03    |
| MeanKL                  | 0.00980727  |
| MeanKLBefore            | 0.0         |
| MinReturn               | 696         |
| NumTrajs                | 20          |
| Perplexity              | 30.3741     |
| PolicyExecTime          | 0.49        |
| ProcessExecTime         | 0.0593      |
| StdReturn               | 92          |
| Time                    | 747         |
| dLoss                   | 0.0252307   |
-----------------------------------------
itr #94 | 
Mem: 675.753906
Obtaining samples...
Obtaining samples for iteration 94...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5153, #subsample_inputs: 5153
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.539     |
| AbsLearnSignalNew       | 0.539     |
| AbsLearningOld          | 0.539     |
| AverageDiscountedReturn | 222       |
| AveragePhiLoss          | 10.9883   |
| AveragePolicyStd        | 0.761061  |
| AverageReturn           | 775       |
| Entropy                 | 3.41248   |
| EnvExecTime             | 1.88      |
| ExplainedVariance       | 0.85      |
| Iteration               | 94        |
| ItrTime                 | 8         |
| LossAfter               | -0.326771 |
| LossBefore              | -0.302186 |
| MaxReturn               | 1.11e+03  |
| MeanKL                  | 0.0098151 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 67.8      |
| NumTrajs                | 21        |
| Perplexity              | 30.3404   |
| PolicyExecTime          | 0.47      |
| ProcessExecTime         | 0.0576    |
| StdReturn               | 198       |
| Time                    | 755       |
| dLoss                   | 0.0245845 |
---------------------------------------
itr #95 | 
Mem: 675.753906
Obtaining samples...
Obtaining samples for iteration 95...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5198, #subsample_inputs: 5198
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.783      |
| AbsLearnSignalNew       | 0.783      |
| AbsLearningOld          | 0.783      |
| AverageDiscountedReturn | 236        |
| AveragePhiLoss          | 10.3768    |
| AveragePolicyStd        | 0.759203   |
| AverageReturn           | 880        |
| Entropy                 | 3.40196    |
| EnvExecTime             | 1.84       |
| ExplainedVariance       | 0.954      |
| Iteration               | 95         |
| ItrTime                 | 8          |
| LossAfter               | 0.0670448  |
| LossBefore              | 0.0921984  |
| MaxReturn               | 1.04e+03   |
| MeanKL                  | 0.00911382 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 695        |
| NumTrajs                | 19         |
| Perplexity              | 30.0229    |
| PolicyExecTime          | 0.464      |
| ProcessExecTime         | 0.0552     |
| StdReturn               | 102        |
| Time                    | 763        |
| dLoss                   | 0.0251536  |
----------------------------------------
itr #96 | 
Mem: 675.753906
Obtaining samples...
Obtaining samples for iteration 96...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5111, #subsample_inputs: 5111
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.573      |
| AbsLearnSignalNew       | 0.573      |
| AbsLearningOld          | 0.572      |
| AverageDiscountedReturn | 233        |
| AveragePhiLoss          | 12.2743    |
| AveragePolicyStd        | 0.756802   |
| AverageReturn           | 858        |
| Entropy                 | 3.39506    |
| EnvExecTime             | 1.75       |
| ExplainedVariance       | 0.83       |
| Iteration               | 96         |
| ItrTime                 | 7.82       |
| LossAfter               | -0.499616  |
| LossBefore              | -0.479563  |
| MaxReturn               | 1.12e+03   |
| MeanKL                  | 0.00687985 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 666        |
| NumTrajs                | 19         |
| Perplexity              | 29.8164    |
| PolicyExecTime          | 0.448      |
| ProcessExecTime         | 0.0539     |
| StdReturn               | 131        |
| Time                    | 771        |
| dLoss                   | 0.0200531  |
----------------------------------------
itr #97 | 
Mem: 675.753906
Obtaining samples...
Obtaining samples for iteration 97...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5054, #subsample_inputs: 5054
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.697      |
| AbsLearnSignalNew       | 0.697      |
| AbsLearningOld          | 0.698      |
| AverageDiscountedReturn | 235        |
| AveragePhiLoss          | 10.9583    |
| AveragePolicyStd        | 0.756697   |
| AverageReturn           | 901        |
| Entropy                 | 3.3935     |
| EnvExecTime             | 1.78       |
| ExplainedVariance       | 0.89       |
| Iteration               | 97         |
| ItrTime                 | 7.83       |
| LossAfter               | -0.274319  |
| LossBefore              | -0.252996  |
| MaxReturn               | 1.26e+03   |
| MeanKL                  | 0.00679367 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 683        |
| NumTrajs                | 18         |
| Perplexity              | 29.7701    |
| PolicyExecTime          | 0.449      |
| ProcessExecTime         | 0.0553     |
| StdReturn               | 164        |
| Time                    | 779        |
| dLoss                   | 0.0213231  |
----------------------------------------
itr #98 | 
Mem: 675.753906
Obtaining samples...
Obtaining samples for iteration 98...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5054, #subsample_inputs: 5054
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.588      |
| AbsLearnSignalNew       | 0.588      |
| AbsLearningOld          | 0.588      |
| AverageDiscountedReturn | 234        |
| AveragePhiLoss          | 12.2604    |
| AveragePolicyStd        | 0.752049   |
| AverageReturn           | 849        |
| Entropy                 | 3.3757     |
| EnvExecTime             | 1.83       |
| ExplainedVariance       | 0.78       |
| Iteration               | 98         |
| ItrTime                 | 7.88       |
| LossAfter               | 0.00963471 |
| LossBefore              | 0.0391391  |
| MaxReturn               | 1.04e+03   |
| MeanKL                  | 0.0096314  |
| MeanKLBefore            | 0.0        |
| MinReturn               | 605        |
| NumTrajs                | 19         |
| Perplexity              | 29.2446    |
| PolicyExecTime          | 0.46       |
| ProcessExecTime         | 0.0571     |
| StdReturn               | 138        |
| Time                    | 787        |
| dLoss                   | 0.0295044  |
----------------------------------------
itr #99 | 
Mem: 675.753906
Obtaining samples...
Obtaining samples for iteration 99...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5048, #subsample_inputs: 5048
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.595      |
| AbsLearnSignalNew       | 0.595      |
| AbsLearningOld          | 0.595      |
| AverageDiscountedReturn | 232        |
| AveragePhiLoss          | 12.8719    |
| AveragePolicyStd        | 0.743577   |
| AverageReturn           | 834        |
| Entropy                 | 3.34064    |
| EnvExecTime             | 1.82       |
| ExplainedVariance       | 0.744      |
| Iteration               | 99         |
| ItrTime                 | 7.87       |
| LossAfter               | -0.282406  |
| LossBefore              | -0.258105  |
| MaxReturn               | 1.01e+03   |
| MeanKL                  | 0.00650951 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 598        |
| NumTrajs                | 19         |
| Perplexity              | 28.2372    |
| PolicyExecTime          | 0.459      |
| ProcessExecTime         | 0.0553     |
| StdReturn               | 117        |
| Time                    | 795        |
| dLoss                   | 0.0243006  |
----------------------------------------
itr #100 | 
Mem: 675.753906
Obtaining samples...
Obtaining samples for iteration 100...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5231, #subsample_inputs: 5231
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.666      |
| AbsLearnSignalNew       | 0.666      |
| AbsLearningOld          | 0.666      |
| AverageDiscountedReturn | 236        |
| AveragePhiLoss          | 10.4801    |
| AveragePolicyStd        | 0.741289   |
| AverageReturn           | 924        |
| Entropy                 | 3.33281    |
| EnvExecTime             | 1.77       |
| ExplainedVariance       | 0.627      |
| Iteration               | 100        |
| ItrTime                 | 8.01       |
| LossAfter               | 0.190827   |
| LossBefore              | 0.211171   |
| MaxReturn               | 1.23e+03   |
| MeanKL                  | 0.00647255 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 675        |
| NumTrajs                | 18         |
| Perplexity              | 28.0171    |
| PolicyExecTime          | 0.457      |
| ProcessExecTime         | 0.0546     |
| StdReturn               | 127        |
| Time                    | 803        |
| dLoss                   | 0.0203444  |
----------------------------------------
itr #101 | 
Mem: 676.011719
Obtaining samples...
Obtaining samples for iteration 101...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5237, #subsample_inputs: 5237
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.635      |
| AbsLearnSignalNew       | 0.635      |
| AbsLearningOld          | 0.635      |
| AverageDiscountedReturn | 236        |
| AveragePhiLoss          | 9.9455     |
| AveragePolicyStd        | 0.739371   |
| AverageReturn           | 981        |
| Entropy                 | 3.32583    |
| EnvExecTime             | 1.98       |
| ExplainedVariance       | 0.772      |
| Iteration               | 101        |
| ItrTime                 | 8.27       |
| LossAfter               | 0.406113   |
| LossBefore              | 0.431381   |
| MaxReturn               | 1.31e+03   |
| MeanKL                  | 0.00984202 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 586        |
| NumTrajs                | 17         |
| Perplexity              | 27.8222    |
| PolicyExecTime          | 0.503      |
| ProcessExecTime         | 0.0596     |
| StdReturn               | 181        |
| Time                    | 811        |
| dLoss                   | 0.0252686  |
----------------------------------------
itr #102 | 
Mem: 676.011719
Obtaining samples...
Obtaining samples for iteration 102...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5066, #subsample_inputs: 5066
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.762      |
| AbsLearnSignalNew       | 0.762      |
| AbsLearningOld          | 0.762      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 11.1132    |
| AveragePolicyStd        | 0.737021   |
| AverageReturn           | 1.02e+03   |
| Entropy                 | 3.3158     |
| EnvExecTime             | 1.78       |
| ExplainedVariance       | 0.865      |
| Iteration               | 102        |
| ItrTime                 | 7.82       |
| LossAfter               | 0.305161   |
| LossBefore              | 0.327706   |
| MaxReturn               | 1.57e+03   |
| MeanKL                  | 0.00642953 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 736        |
| NumTrajs                | 16         |
| Perplexity              | 27.5445    |
| PolicyExecTime          | 0.452      |
| ProcessExecTime         | 0.0543     |
| StdReturn               | 237        |
| Time                    | 819        |
| dLoss                   | 0.0225455  |
----------------------------------------
itr #103 | 
Mem: 677.558594
Obtaining samples...
Obtaining samples for iteration 103...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5007, #subsample_inputs: 5007
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.592      |
| AbsLearnSignalNew       | 0.592      |
| AbsLearningOld          | 0.592      |
| AverageDiscountedReturn | 236        |
| AveragePhiLoss          | 12.095     |
| AveragePolicyStd        | 0.737022   |
| AverageReturn           | 943        |
| Entropy                 | 3.31586    |
| EnvExecTime             | 1.97       |
| ExplainedVariance       | 0.789      |
| Iteration               | 103        |
| ItrTime                 | 8.05       |
| LossAfter               | -0.0733881 |
| LossBefore              | -0.0444694 |
| MaxReturn               | 1.57e+03   |
| MeanKL                  | 0.00900139 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 699        |
| NumTrajs                | 17         |
| Perplexity              | 27.5459    |
| PolicyExecTime          | 0.493      |
| ProcessExecTime         | 0.0605     |
| StdReturn               | 219        |
| Time                    | 827        |
| dLoss                   | 0.0289187  |
----------------------------------------
itr #104 | 
Mem: 677.558594
Obtaining samples...
Obtaining samples for iteration 104...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5229, #subsample_inputs: 5229
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.733     |
| AbsLearnSignalNew       | 0.733     |
| AbsLearningOld          | 0.733     |
| AverageDiscountedReturn | 236       |
| AveragePhiLoss          | 11.006    |
| AveragePolicyStd        | 0.733587  |
| AverageReturn           | 884       |
| Entropy                 | 3.30344   |
| EnvExecTime             | 1.95      |
| ExplainedVariance       | 0.926     |
| Iteration               | 104       |
| ItrTime                 | 8.21      |
| LossAfter               | -0.220598 |
| LossBefore              | -0.196387 |
| MaxReturn               | 1.09e+03  |
| MeanKL                  | 0.0097086 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 691       |
| NumTrajs                | 19        |
| Perplexity              | 27.2062   |
| PolicyExecTime          | 0.499     |
| ProcessExecTime         | 0.059     |
| StdReturn               | 110       |
| Time                    | 836       |
| dLoss                   | 0.024211  |
---------------------------------------
itr #105 | 
Mem: 678.074219
Obtaining samples...
Obtaining samples for iteration 105...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5265, #subsample_inputs: 5265
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.542      |
| AbsLearnSignalNew       | 0.542      |
| AbsLearningOld          | 0.542      |
| AverageDiscountedReturn | 236        |
| AveragePhiLoss          | 10.7244    |
| AveragePolicyStd        | 0.733569   |
| AverageReturn           | 936        |
| Entropy                 | 3.30412    |
| EnvExecTime             | 1.97       |
| ExplainedVariance       | 0.851      |
| Iteration               | 105        |
| ItrTime                 | 8.28       |
| LossAfter               | 0.121042   |
| LossBefore              | 0.145422   |
| MaxReturn               | 1.37e+03   |
| MeanKL                  | 0.00932755 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 686        |
| NumTrajs                | 18         |
| Perplexity              | 27.2245    |
| PolicyExecTime          | 0.496      |
| ProcessExecTime         | 0.0599     |
| StdReturn               | 162        |
| Time                    | 844        |
| dLoss                   | 0.0243802  |
----------------------------------------
itr #106 | 
Mem: 678.589844
Obtaining samples...
Obtaining samples for iteration 106...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5083, #subsample_inputs: 5083
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.554      |
| AbsLearnSignalNew       | 0.554      |
| AbsLearningOld          | 0.554      |
| AverageDiscountedReturn | 236        |
| AveragePhiLoss          | 12.4101    |
| AveragePolicyStd        | 0.737098   |
| AverageReturn           | 1.02e+03   |
| Entropy                 | 3.31975    |
| EnvExecTime             | 1.96       |
| ExplainedVariance       | 0.797      |
| Iteration               | 106        |
| ItrTime                 | 8.12       |
| LossAfter               | 0.386361   |
| LossBefore              | 0.419363   |
| MaxReturn               | 1.47e+03   |
| MeanKL                  | 0.00995605 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 440        |
| NumTrajs                | 16         |
| Perplexity              | 27.6534    |
| PolicyExecTime          | 0.485      |
| ProcessExecTime         | 0.0608     |
| StdReturn               | 251        |
| Time                    | 852        |
| dLoss                   | 0.0330026  |
----------------------------------------
itr #107 | 
Mem: 678.589844
Obtaining samples...
Obtaining samples for iteration 107...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5164, #subsample_inputs: 5164
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.527      |
| AbsLearnSignalNew       | 0.527      |
| AbsLearningOld          | 0.527      |
| AverageDiscountedReturn | 235        |
| AveragePhiLoss          | 7.47714    |
| AveragePolicyStd        | 0.735812   |
| AverageReturn           | 922        |
| Entropy                 | 3.31383    |
| EnvExecTime             | 1.95       |
| ExplainedVariance       | 0.865      |
| Iteration               | 107        |
| ItrTime                 | 8.17       |
| LossAfter               | 0.200877   |
| LossBefore              | 0.218393   |
| MaxReturn               | 1.3e+03    |
| MeanKL                  | 0.00649321 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 589        |
| NumTrajs                | 18         |
| Perplexity              | 27.4903    |
| PolicyExecTime          | 0.496      |
| ProcessExecTime         | 0.0596     |
| StdReturn               | 182        |
| Time                    | 860        |
| dLoss                   | 0.0175161  |
----------------------------------------
itr #108 | 
Mem: 678.589844
Obtaining samples...
Obtaining samples for iteration 108...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5112, #subsample_inputs: 5112
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.556      |
| AbsLearnSignalNew       | 0.556      |
| AbsLearningOld          | 0.556      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 10.5019    |
| AveragePolicyStd        | 0.730239   |
| AverageReturn           | 1.02e+03   |
| Entropy                 | 3.28969    |
| EnvExecTime             | 2.07       |
| ExplainedVariance       | 0.714      |
| Iteration               | 108        |
| ItrTime                 | 8.28       |
| LossAfter               | -1.17591   |
| LossBefore              | -1.15229   |
| MaxReturn               | 1.45e+03   |
| MeanKL                  | 0.00997121 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 649        |
| NumTrajs                | 16         |
| Perplexity              | 26.8346    |
| PolicyExecTime          | 0.527      |
| ProcessExecTime         | 0.0623     |
| StdReturn               | 219        |
| Time                    | 869        |
| dLoss                   | 0.0236177  |
----------------------------------------
itr #109 | 
Mem: 678.589844
Obtaining samples...
Obtaining samples for iteration 109...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5213, #subsample_inputs: 5213
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.78       |
| AbsLearnSignalNew       | 0.78       |
| AbsLearningOld          | 0.779      |
| AverageDiscountedReturn | 235        |
| AveragePhiLoss          | 11.4725    |
| AveragePolicyStd        | 0.732615   |
| AverageReturn           | 974        |
| Entropy                 | 3.30078    |
| EnvExecTime             | 1.91       |
| ExplainedVariance       | 0.926      |
| Iteration               | 109        |
| ItrTime                 | 8.19       |
| LossAfter               | 0.397922   |
| LossBefore              | 0.421964   |
| MaxReturn               | 1.35e+03   |
| MeanKL                  | 0.00656348 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 708        |
| NumTrajs                | 17         |
| Perplexity              | 27.1337    |
| PolicyExecTime          | 0.488      |
| ProcessExecTime         | 0.0569     |
| StdReturn               | 172        |
| Time                    | 877        |
| dLoss                   | 0.0240421  |
----------------------------------------
itr #110 | 
Mem: 678.847656
Obtaining samples...
Obtaining samples for iteration 110...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5018, #subsample_inputs: 5018
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.789      |
| AbsLearnSignalNew       | 0.789      |
| AbsLearningOld          | 0.789      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 10.9616    |
| AveragePolicyStd        | 0.732671   |
| AverageReturn           | 951        |
| Entropy                 | 3.30271    |
| EnvExecTime             | 2.06       |
| ExplainedVariance       | 0.944      |
| Iteration               | 110        |
| ItrTime                 | 8.3        |
| LossAfter               | 0.0965152  |
| LossBefore              | 0.121784   |
| MaxReturn               | 1.29e+03   |
| MeanKL                  | 0.00935556 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 755        |
| NumTrajs                | 17         |
| Perplexity              | 27.1862    |
| PolicyExecTime          | 0.511      |
| ProcessExecTime         | 0.0626     |
| StdReturn               | 153        |
| Time                    | 885        |
| dLoss                   | 0.0252692  |
----------------------------------------
itr #111 | 
Mem: 678.847656
Obtaining samples...
Obtaining samples for iteration 111...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5242, #subsample_inputs: 5242
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.791      |
| AbsLearnSignalNew       | 0.791      |
| AbsLearningOld          | 0.791      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 10.9538    |
| AveragePolicyStd        | 0.736155   |
| AverageReturn           | 937        |
| Entropy                 | 3.31577    |
| EnvExecTime             | 1.9        |
| ExplainedVariance       | 0.946      |
| Iteration               | 111        |
| ItrTime                 | 8.11       |
| LossAfter               | 0.333399   |
| LossBefore              | 0.358276   |
| MaxReturn               | 1.1e+03    |
| MeanKL                  | 0.00937064 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 748        |
| NumTrajs                | 18         |
| Perplexity              | 27.5436    |
| PolicyExecTime          | 0.483      |
| ProcessExecTime         | 0.0585     |
| StdReturn               | 115        |
| Time                    | 893        |
| dLoss                   | 0.0248767  |
----------------------------------------
itr #112 | 
Mem: 678.847656
Obtaining samples...
Obtaining samples for iteration 112...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5313, #subsample_inputs: 5313
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.48       |
| AbsLearnSignalNew       | 0.48       |
| AbsLearningOld          | 0.48       |
| AverageDiscountedReturn | 233        |
| AveragePhiLoss          | 12.3543    |
| AveragePolicyStd        | 0.745939   |
| AverageReturn           | 979        |
| Entropy                 | 3.35726    |
| EnvExecTime             | 1.97       |
| ExplainedVariance       | 0.463      |
| Iteration               | 112        |
| ItrTime                 | 8.34       |
| LossAfter               | 0.20553    |
| LossBefore              | 0.228702   |
| MaxReturn               | 1.51e+03   |
| MeanKL                  | 0.00690695 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 635        |
| NumTrajs                | 17         |
| Perplexity              | 28.7105    |
| PolicyExecTime          | 0.502      |
| ProcessExecTime         | 0.0605     |
| StdReturn               | 215        |
| Time                    | 902        |
| dLoss                   | 0.0231729  |
----------------------------------------
itr #113 | 
Mem: 679.363281
Obtaining samples...
Obtaining samples for iteration 113...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5016, #subsample_inputs: 5016
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.635      |
| AbsLearnSignalNew       | 0.635      |
| AbsLearningOld          | 0.634      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 10.0862    |
| AveragePolicyStd        | 0.745991   |
| AverageReturn           | 943        |
| Entropy                 | 3.35512    |
| EnvExecTime             | 1.95       |
| ExplainedVariance       | 0.814      |
| Iteration               | 113        |
| ItrTime                 | 7.99       |
| LossAfter               | -0.105296  |
| LossBefore              | -0.0800673 |
| MaxReturn               | 1.19e+03   |
| MeanKL                  | 0.00986439 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 636        |
| NumTrajs                | 17         |
| Perplexity              | 28.6491    |
| PolicyExecTime          | 0.488      |
| ProcessExecTime         | 0.059      |
| StdReturn               | 140        |
| Time                    | 910        |
| dLoss                   | 0.0252287  |
----------------------------------------
itr #114 | 
Mem: 679.363281
Obtaining samples...
Obtaining samples for iteration 114...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5196, #subsample_inputs: 5196
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.677     |
| AbsLearnSignalNew       | 0.677     |
| AbsLearningOld          | 0.678     |
| AverageDiscountedReturn | 238       |
| AveragePhiLoss          | 10.2262   |
| AveragePolicyStd        | 0.749957  |
| AverageReturn           | 1.05e+03  |
| Entropy                 | 3.36939   |
| EnvExecTime             | 2.02      |
| ExplainedVariance       | 0.793     |
| Iteration               | 114       |
| ItrTime                 | 8.33      |
| LossAfter               | 0.0913311 |
| LossBefore              | 0.116065  |
| MaxReturn               | 1.54e+03  |
| MeanKL                  | 0.0064469 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 672       |
| NumTrajs                | 16        |
| Perplexity              | 29.0609   |
| PolicyExecTime          | 0.512     |
| ProcessExecTime         | 0.0608    |
| StdReturn               | 240       |
| Time                    | 918       |
| dLoss                   | 0.0247339 |
---------------------------------------
itr #115 | 
Mem: 679.617188
Obtaining samples...
Obtaining samples for iteration 115...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5302, #subsample_inputs: 5302
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.793      |
| AbsLearnSignalNew       | 0.793      |
| AbsLearningOld          | 0.793      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 10.5345    |
| AveragePolicyStd        | 0.750927   |
| AverageReturn           | 1e+03      |
| Entropy                 | 3.37325    |
| EnvExecTime             | 2.02       |
| ExplainedVariance       | 0.937      |
| Iteration               | 115        |
| ItrTime                 | 8.35       |
| LossAfter               | -0.380221  |
| LossBefore              | -0.360166  |
| MaxReturn               | 1.31e+03   |
| MeanKL                  | 0.00672923 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 756        |
| NumTrajs                | 17         |
| Perplexity              | 29.1732    |
| PolicyExecTime          | 0.509      |
| ProcessExecTime         | 0.0618     |
| StdReturn               | 170        |
| Time                    | 927        |
| dLoss                   | 0.0200544  |
----------------------------------------
itr #116 | 
Mem: 679.617188
Obtaining samples...
Obtaining samples for iteration 116...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5196, #subsample_inputs: 5196
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.574      |
| AbsLearnSignalNew       | 0.574      |
| AbsLearningOld          | 0.574      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 10.5289    |
| AveragePolicyStd        | 0.749961   |
| AverageReturn           | 1.04e+03   |
| Entropy                 | 3.36883    |
| EnvExecTime             | 1.93       |
| ExplainedVariance       | 0.797      |
| Iteration               | 116        |
| ItrTime                 | 8.22       |
| LossAfter               | -0.146796  |
| LossBefore              | -0.126507  |
| MaxReturn               | 1.59e+03   |
| MeanKL                  | 0.00656527 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 794        |
| NumTrajs                | 16         |
| Perplexity              | 29.0444    |
| PolicyExecTime          | 0.488      |
| ProcessExecTime         | 0.0608     |
| StdReturn               | 207        |
| Time                    | 935        |
| dLoss                   | 0.0202885  |
----------------------------------------
itr #117 | 
Mem: 679.617188
Obtaining samples...
Obtaining samples for iteration 117...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5095, #subsample_inputs: 5095
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.789      |
| AbsLearnSignalNew       | 0.789      |
| AbsLearningOld          | 0.789      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 10.4057    |
| AveragePolicyStd        | 0.750178   |
| AverageReturn           | 1.03e+03   |
| Entropy                 | 3.37064    |
| EnvExecTime             | 1.98       |
| ExplainedVariance       | 0.941      |
| Iteration               | 117        |
| ItrTime                 | 8.12       |
| LossAfter               | 0.158388   |
| LossBefore              | 0.179895   |
| MaxReturn               | 1.4e+03    |
| MeanKL                  | 0.00647755 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 776        |
| NumTrajs                | 16         |
| Perplexity              | 29.0972    |
| PolicyExecTime          | 0.496      |
| ProcessExecTime         | 0.0599     |
| StdReturn               | 170        |
| Time                    | 943        |
| dLoss                   | 0.0215073  |
----------------------------------------
itr #118 | 
Mem: 679.617188
Obtaining samples...
Obtaining samples for iteration 118...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5220, #subsample_inputs: 5220
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.778      |
| AbsLearnSignalNew       | 0.778      |
| AbsLearningOld          | 0.778      |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 9.87802    |
| AveragePolicyStd        | 0.749123   |
| AverageReturn           | 1.05e+03   |
| Entropy                 | 3.36839    |
| EnvExecTime             | 2.1        |
| ExplainedVariance       | 0.939      |
| Iteration               | 118        |
| ItrTime                 | 8.46       |
| LossAfter               | -0.896927  |
| LossBefore              | -0.865097  |
| MaxReturn               | 1.46e+03   |
| MeanKL                  | 0.00969739 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 781        |
| NumTrajs                | 16         |
| Perplexity              | 29.0318    |
| PolicyExecTime          | 0.53       |
| ProcessExecTime         | 0.0616     |
| StdReturn               | 206        |
| Time                    | 952        |
| dLoss                   | 0.0318301  |
----------------------------------------
itr #119 | 
Mem: 679.617188
Obtaining samples...
Obtaining samples for iteration 119...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5180, #subsample_inputs: 5180
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.407      |
| AbsLearnSignalNew       | 0.407      |
| AbsLearningOld          | 0.408      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 13.6615    |
| AveragePolicyStd        | 0.750341   |
| AverageReturn           | 1.26e+03   |
| Entropy                 | 3.37404    |
| EnvExecTime             | 1.78       |
| ExplainedVariance       | -0.314     |
| Iteration               | 119        |
| ItrTime                 | 8.04       |
| LossAfter               | -0.571438  |
| LossBefore              | -0.540758  |
| MaxReturn               | 1.97e+03   |
| MeanKL                  | 0.00961716 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 825        |
| NumTrajs                | 13         |
| Perplexity              | 29.1963    |
| PolicyExecTime          | 0.454      |
| ProcessExecTime         | 0.0551     |
| StdReturn               | 341        |
| Time                    | 960        |
| dLoss                   | 0.0306797  |
----------------------------------------
itr #120 | 
Mem: 679.617188
Obtaining samples...
Obtaining samples for iteration 120...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5198, #subsample_inputs: 5198
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.606      |
| AbsLearnSignalNew       | 0.606      |
| AbsLearningOld          | 0.606      |
| AverageDiscountedReturn | 235        |
| AveragePhiLoss          | 9.98592    |
| AveragePolicyStd        | 0.746908   |
| AverageReturn           | 1.03e+03   |
| Entropy                 | 3.36167    |
| EnvExecTime             | 1.87       |
| ExplainedVariance       | 0.764      |
| Iteration               | 120        |
| ItrTime                 | 8.1        |
| LossAfter               | 0.0305891  |
| LossBefore              | 0.0537253  |
| MaxReturn               | 1.7e+03    |
| MeanKL                  | 0.00982081 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 694        |
| NumTrajs                | 16         |
| Perplexity              | 28.8372    |
| PolicyExecTime          | 0.478      |
| ProcessExecTime         | 0.0584     |
| StdReturn               | 241        |
| Time                    | 968        |
| dLoss                   | 0.0231362  |
----------------------------------------
itr #121 | 
Mem: 679.617188
Obtaining samples...
Obtaining samples for iteration 121...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5291, #subsample_inputs: 5291
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.665      |
| AbsLearnSignalNew       | 0.665      |
| AbsLearningOld          | 0.665      |
| AverageDiscountedReturn | 235        |
| AveragePhiLoss          | 10.1022    |
| AveragePolicyStd        | 0.747564   |
| AverageReturn           | 1.04e+03   |
| Entropy                 | 3.36165    |
| EnvExecTime             | 1.95       |
| ExplainedVariance       | 0.795      |
| Iteration               | 121        |
| ItrTime                 | 8.25       |
| LossAfter               | 0.416903   |
| LossBefore              | 0.437774   |
| MaxReturn               | 1.85e+03   |
| MeanKL                  | 0.00676166 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 651        |
| NumTrajs                | 16         |
| Perplexity              | 28.8367    |
| PolicyExecTime          | 0.489      |
| ProcessExecTime         | 0.0594     |
| StdReturn               | 300        |
| Time                    | 976        |
| dLoss                   | 0.0208709  |
----------------------------------------
itr #122 | 
Mem: 679.617188
Obtaining samples...
Obtaining samples for iteration 122...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5303, #subsample_inputs: 5303
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.644      |
| AbsLearnSignalNew       | 0.644      |
| AbsLearningOld          | 0.644      |
| AverageDiscountedReturn | 230        |
| AveragePhiLoss          | 11.759     |
| AveragePolicyStd        | 0.747895   |
| AverageReturn           | 1.06e+03   |
| Entropy                 | 3.36253    |
| EnvExecTime             | 1.83       |
| ExplainedVariance       | 0.777      |
| Iteration               | 122        |
| ItrTime                 | 8.18       |
| LossAfter               | 0.214175   |
| LossBefore              | 0.235669   |
| MaxReturn               | 1.61e+03   |
| MeanKL                  | 0.00649159 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 195        |
| NumTrajs                | 16         |
| Perplexity              | 28.8621    |
| PolicyExecTime          | 0.47       |
| ProcessExecTime         | 0.0559     |
| StdReturn               | 340        |
| Time                    | 984        |
| dLoss                   | 0.0214937  |
----------------------------------------
itr #123 | 
Mem: 679.617188
Obtaining samples...
Obtaining samples for iteration 123...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5066, #subsample_inputs: 5066
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.786     |
| AbsLearnSignalNew       | 0.786     |
| AbsLearningOld          | 0.786     |
| AverageDiscountedReturn | 239       |
| AveragePhiLoss          | 10.9372   |
| AveragePolicyStd        | 0.745629  |
| AverageReturn           | 1.15e+03  |
| Entropy                 | 3.35191   |
| EnvExecTime             | 1.7       |
| ExplainedVariance       | 0.901     |
| Iteration               | 123       |
| ItrTime                 | 7.76      |
| LossAfter               | 0.736082  |
| LossBefore              | 0.761181  |
| MaxReturn               | 1.73e+03  |
| MeanKL                  | 0.0094971 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 893       |
| NumTrajs                | 14        |
| Perplexity              | 28.5573   |
| PolicyExecTime          | 0.437     |
| ProcessExecTime         | 0.0535    |
| StdReturn               | 225       |
| Time                    | 992       |
| dLoss                   | 0.0250994 |
---------------------------------------
itr #124 | 
Mem: 679.617188
Obtaining samples...
Obtaining samples for iteration 124...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5187, #subsample_inputs: 5187
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.808     |
| AbsLearnSignalNew       | 0.808     |
| AbsLearningOld          | 0.808     |
| AverageDiscountedReturn | 238       |
| AveragePhiLoss          | 11.1804   |
| AveragePolicyStd        | 0.741697  |
| AverageReturn           | 1.04e+03  |
| Entropy                 | 3.33399   |
| EnvExecTime             | 2         |
| ExplainedVariance       | 0.926     |
| Iteration               | 124       |
| ItrTime                 | 8.26      |
| LossAfter               | -0.411901 |
| LossBefore              | -0.38935  |
| MaxReturn               | 1.28e+03  |
| MeanKL                  | 0.0098637 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 816       |
| NumTrajs                | 16        |
| Perplexity              | 28.05     |
| PolicyExecTime          | 0.506     |
| ProcessExecTime         | 0.0603    |
| StdReturn               | 113       |
| Time                    | 1e+03     |
| dLoss                   | 0.0225504 |
---------------------------------------
itr #125 | 
Mem: 679.617188
Obtaining samples...
Obtaining samples for iteration 125...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5335, #subsample_inputs: 5335
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.724      |
| AbsLearnSignalNew       | 0.724      |
| AbsLearningOld          | 0.724      |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 10.8663    |
| AveragePolicyStd        | 0.741045   |
| AverageReturn           | 1.14e+03   |
| Entropy                 | 3.3406     |
| EnvExecTime             | 1.89       |
| ExplainedVariance       | 0.913      |
| Iteration               | 125        |
| ItrTime                 | 8.27       |
| LossAfter               | 0.0202977  |
| LossBefore              | 0.0492957  |
| MaxReturn               | 1.58e+03   |
| MeanKL                  | 0.00983252 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 897        |
| NumTrajs                | 15         |
| Perplexity              | 28.2359    |
| PolicyExecTime          | 0.479      |
| ProcessExecTime         | 0.0586     |
| StdReturn               | 195        |
| Time                    | 1.01e+03   |
| dLoss                   | 0.028998   |
----------------------------------------
itr #126 | 
Mem: 679.617188
Obtaining samples...
Obtaining samples for iteration 126...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5164, #subsample_inputs: 5164
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.373      |
| AbsLearnSignalNew       | 0.373      |
| AbsLearningOld          | 0.373      |
| AverageDiscountedReturn | 235        |
| AveragePhiLoss          | 10.5161    |
| AveragePolicyStd        | 0.744991   |
| AverageReturn           | 1.33e+03   |
| Entropy                 | 3.35951    |
| EnvExecTime             | 2          |
| ExplainedVariance       | -1.94      |
| Iteration               | 126        |
| ItrTime                 | 8.23       |
| LossAfter               | 0.176184   |
| LossBefore              | 0.197482   |
| MaxReturn               | 2.79e+03   |
| MeanKL                  | 0.00665494 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 978        |
| NumTrajs                | 12         |
| Perplexity              | 28.7752    |
| PolicyExecTime          | 0.517      |
| ProcessExecTime         | 0.0587     |
| StdReturn               | 514        |
| Time                    | 1.02e+03   |
| dLoss                   | 0.0212981  |
----------------------------------------
itr #127 | 
Mem: 680.113281
Obtaining samples...
Obtaining samples for iteration 127...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5321, #subsample_inputs: 5321
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.563      |
| AbsLearnSignalNew       | 0.563      |
| AbsLearningOld          | 0.563      |
| AverageDiscountedReturn | 236        |
| AveragePhiLoss          | 11.3561    |
| AveragePolicyStd        | 0.742215   |
| AverageReturn           | 1.11e+03   |
| Entropy                 | 3.34798    |
| EnvExecTime             | 2.1        |
| ExplainedVariance       | 0.639      |
| Iteration               | 127        |
| ItrTime                 | 8.52       |
| LossAfter               | -0.396229  |
| LossBefore              | -0.367862  |
| MaxReturn               | 1.64e+03   |
| MeanKL                  | 0.00983905 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 427        |
| NumTrajs                | 15         |
| Perplexity              | 28.4453    |
| PolicyExecTime          | 0.524      |
| ProcessExecTime         | 0.062      |
| StdReturn               | 282        |
| Time                    | 1.03e+03   |
| dLoss                   | 0.0283667  |
----------------------------------------
itr #128 | 
Mem: 680.398438
Obtaining samples...
Obtaining samples for iteration 128...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5141, #subsample_inputs: 5141
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.707      |
| AbsLearnSignalNew       | 0.707      |
| AbsLearningOld          | 0.707      |
| AverageDiscountedReturn | 236        |
| AveragePhiLoss          | 10.6725    |
| AveragePolicyStd        | 0.737294   |
| AverageReturn           | 1.07e+03   |
| Entropy                 | 3.32907    |
| EnvExecTime             | 2.02       |
| ExplainedVariance       | 0.79       |
| Iteration               | 128        |
| ItrTime                 | 8.24       |
| LossAfter               | 0.210087   |
| LossBefore              | 0.227902   |
| MaxReturn               | 1.97e+03   |
| MeanKL                  | 0.00651572 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 768        |
| NumTrajs                | 15         |
| Perplexity              | 27.9124    |
| PolicyExecTime          | 0.508      |
| ProcessExecTime         | 0.0606     |
| StdReturn               | 297        |
| Time                    | 1.03e+03   |
| dLoss                   | 0.0178156  |
----------------------------------------
itr #129 | 
Mem: 680.398438
Obtaining samples...
Obtaining samples for iteration 129...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5370, #subsample_inputs: 5370
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.789      |
| AbsLearnSignalNew       | 0.789      |
| AbsLearningOld          | 0.789      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 11.0616    |
| AveragePolicyStd        | 0.735967   |
| AverageReturn           | 1.14e+03   |
| Entropy                 | 3.322      |
| EnvExecTime             | 1.83       |
| ExplainedVariance       | 0.872      |
| Iteration               | 129        |
| ItrTime                 | 8.22       |
| LossAfter               | -0.31089   |
| LossBefore              | -0.279855  |
| MaxReturn               | 1.97e+03   |
| MeanKL                  | 0.00985226 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 773        |
| NumTrajs                | 15         |
| Perplexity              | 27.7158    |
| PolicyExecTime          | 0.472      |
| ProcessExecTime         | 0.057      |
| StdReturn               | 351        |
| Time                    | 1.04e+03   |
| dLoss                   | 0.0310347  |
----------------------------------------
itr #130 | 
Mem: 680.398438
Obtaining samples...
Obtaining samples for iteration 130...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5330, #subsample_inputs: 5330
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.776      |
| AbsLearnSignalNew       | 0.776      |
| AbsLearningOld          | 0.776      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 10.9735    |
| AveragePolicyStd        | 0.73452    |
| AverageReturn           | 1.07e+03   |
| Entropy                 | 3.31605    |
| EnvExecTime             | 2.04       |
| ExplainedVariance       | 0.92       |
| Iteration               | 130        |
| ItrTime                 | 8.48       |
| LossAfter               | -0.54152   |
| LossBefore              | -0.520843  |
| MaxReturn               | 1.53e+03   |
| MeanKL                  | 0.00967116 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 735        |
| NumTrajs                | 16         |
| Perplexity              | 27.5512    |
| PolicyExecTime          | 0.519      |
| ProcessExecTime         | 0.0618     |
| StdReturn               | 230        |
| Time                    | 1.05e+03   |
| dLoss                   | 0.0206764  |
----------------------------------------
itr #131 | 
Mem: 680.636719
Obtaining samples...
Obtaining samples for iteration 131...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5061, #subsample_inputs: 5061
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.623      |
| AbsLearnSignalNew       | 0.623      |
| AbsLearningOld          | 0.623      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 9.15638    |
| AveragePolicyStd        | 0.737746   |
| AverageReturn           | 1.08e+03   |
| Entropy                 | 3.33162    |
| EnvExecTime             | 1.83       |
| ExplainedVariance       | 0.792      |
| Iteration               | 131        |
| ItrTime                 | 7.97       |
| LossAfter               | -0.390149  |
| LossBefore              | -0.365781  |
| MaxReturn               | 1.56e+03   |
| MeanKL                  | 0.00950532 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 780        |
| NumTrajs                | 15         |
| Perplexity              | 27.9836    |
| PolicyExecTime          | 0.467      |
| ProcessExecTime         | 0.0558     |
| StdReturn               | 200        |
| Time                    | 1.06e+03   |
| dLoss                   | 0.0243674  |
----------------------------------------
itr #132 | 
Mem: 680.636719
Obtaining samples...
Obtaining samples for iteration 132...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5487, #subsample_inputs: 5487
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.78       |
| AbsLearnSignalNew       | 0.78       |
| AbsLearningOld          | 0.78       |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 10.1477    |
| AveragePolicyStd        | 0.748298   |
| AverageReturn           | 1.17e+03   |
| Entropy                 | 3.37082    |
| EnvExecTime             | 1.94       |
| ExplainedVariance       | 0.893      |
| Iteration               | 132        |
| ItrTime                 | 8.36       |
| LossAfter               | 0.297438   |
| LossBefore              | 0.314149   |
| MaxReturn               | 1.73e+03   |
| MeanKL                  | 0.00644448 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 802        |
| NumTrajs                | 15         |
| Perplexity              | 29.1025    |
| PolicyExecTime          | 0.493      |
| ProcessExecTime         | 0.0598     |
| StdReturn               | 249        |
| Time                    | 1.07e+03   |
| dLoss                   | 0.016711   |
----------------------------------------
itr #133 | 
Mem: 680.902344
Obtaining samples...
Obtaining samples for iteration 133...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5103, #subsample_inputs: 5103
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.625      |
| AbsLearnSignalNew       | 0.625      |
| AbsLearningOld          | 0.625      |
| AverageDiscountedReturn | 236        |
| AveragePhiLoss          | 11.9169    |
| AveragePolicyStd        | 0.746326   |
| AverageReturn           | 961        |
| Entropy                 | 3.3632     |
| EnvExecTime             | 1.93       |
| ExplainedVariance       | 0.78       |
| Iteration               | 133        |
| ItrTime                 | 8.09       |
| LossAfter               | -0.0735854 |
| LossBefore              | -0.0487416 |
| MaxReturn               | 1.33e+03   |
| MeanKL                  | 0.00664581 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 474        |
| NumTrajs                | 17         |
| Perplexity              | 28.8813    |
| PolicyExecTime          | 0.487      |
| ProcessExecTime         | 0.0572     |
| StdReturn               | 200        |
| Time                    | 1.08e+03   |
| dLoss                   | 0.0248439  |
----------------------------------------
itr #134 | 
Mem: 680.902344
Obtaining samples...
Obtaining samples for iteration 134...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5016, #subsample_inputs: 5016
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.557      |
| AbsLearnSignalNew       | 0.557      |
| AbsLearningOld          | 0.557      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 10.0209    |
| AveragePolicyStd        | 0.741086   |
| AverageReturn           | 1.24e+03   |
| Entropy                 | 3.34253    |
| EnvExecTime             | 1.79       |
| ExplainedVariance       | 0.597      |
| Iteration               | 134        |
| ItrTime                 | 7.82       |
| LossAfter               | -0.0628004 |
| LossBefore              | -0.0449945 |
| MaxReturn               | 1.82e+03   |
| MeanKL                  | 0.00654988 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 826        |
| NumTrajs                | 13         |
| Perplexity              | 28.2905    |
| PolicyExecTime          | 0.462      |
| ProcessExecTime         | 0.0537     |
| StdReturn               | 247        |
| Time                    | 1.08e+03   |
| dLoss                   | 0.0178059  |
----------------------------------------
itr #135 | 
Mem: 680.902344
Obtaining samples...
Obtaining samples for iteration 135...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5240, #subsample_inputs: 5240
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
-----------------------------------------
| AbsLearnSignal          | 0.77        |
| AbsLearnSignalNew       | 0.77        |
| AbsLearningOld          | 0.77        |
| AverageDiscountedReturn | 239         |
| AveragePhiLoss          | 10.8699     |
| AveragePolicyStd        | 0.741179    |
| AverageReturn           | 992         |
| Entropy                 | 3.34222     |
| EnvExecTime             | 2.12        |
| ExplainedVariance       | 0.935       |
| Iteration               | 135         |
| ItrTime                 | 8.46        |
| LossAfter               | -0.00441717 |
| LossBefore              | 0.0153571   |
| MaxReturn               | 1.3e+03     |
| MeanKL                  | 0.00657073  |
| MeanKLBefore            | 0.0         |
| MinReturn               | 778         |
| NumTrajs                | 17          |
| Perplexity              | 28.282      |
| PolicyExecTime          | 0.53        |
| ProcessExecTime         | 0.064       |
| StdReturn               | 120         |
| Time                    | 1.09e+03    |
| dLoss                   | 0.0197743   |
-----------------------------------------
itr #136 | 
Mem: 680.902344
Obtaining samples...
Obtaining samples for iteration 136...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5305, #subsample_inputs: 5305
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.711      |
| AbsLearnSignalNew       | 0.711      |
| AbsLearningOld          | 0.711      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 18.6935    |
| AveragePolicyStd        | 0.737019   |
| AverageReturn           | 1.01e+03   |
| Entropy                 | 3.32422    |
| EnvExecTime             | 2.04       |
| ExplainedVariance       | 0.916      |
| Iteration               | 136        |
| ItrTime                 | 8.42       |
| LossAfter               | 0.609402   |
| LossBefore              | 0.640642   |
| MaxReturn               | 1.61e+03   |
| MeanKL                  | 0.00978518 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 697        |
| NumTrajs                | 17         |
| Perplexity              | 27.7774    |
| PolicyExecTime          | 0.51       |
| ProcessExecTime         | 0.0631     |
| StdReturn               | 212        |
| Time                    | 1.1e+03    |
| dLoss                   | 0.0312403  |
----------------------------------------
itr #137 | 
Mem: 681.160156
Obtaining samples...
Obtaining samples for iteration 137...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5360, #subsample_inputs: 5360
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.698      |
| AbsLearnSignalNew       | 0.698      |
| AbsLearningOld          | 0.698      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 10.6664    |
| AveragePolicyStd        | 0.731854   |
| AverageReturn           | 1.14e+03   |
| Entropy                 | 3.30277    |
| EnvExecTime             | 2          |
| ExplainedVariance       | 0.86       |
| Iteration               | 137        |
| ItrTime                 | 8.44       |
| LossAfter               | 0.509459   |
| LossBefore              | 0.528966   |
| MaxReturn               | 1.78e+03   |
| MeanKL                  | 0.00645853 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 827        |
| NumTrajs                | 15         |
| Perplexity              | 27.1877    |
| PolicyExecTime          | 0.509      |
| ProcessExecTime         | 0.0594     |
| StdReturn               | 263        |
| Time                    | 1.11e+03   |
| dLoss                   | 0.0195073  |
----------------------------------------
itr #138 | 
Mem: 681.933594
Obtaining samples...
Obtaining samples for iteration 138...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5024, #subsample_inputs: 5024
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.787      |
| AbsLearnSignalNew       | 0.787      |
| AbsLearningOld          | 0.787      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 10.7611    |
| AveragePolicyStd        | 0.730219   |
| AverageReturn           | 1.15e+03   |
| Entropy                 | 3.29831    |
| EnvExecTime             | 1.88       |
| ExplainedVariance       | 0.93       |
| Iteration               | 138        |
| ItrTime                 | 8          |
| LossAfter               | 0.304334   |
| LossBefore              | 0.329922   |
| MaxReturn               | 1.67e+03   |
| MeanKL                  | 0.00994791 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 820        |
| NumTrajs                | 14         |
| Perplexity              | 27.0667    |
| PolicyExecTime          | 0.485      |
| ProcessExecTime         | 0.0567     |
| StdReturn               | 211        |
| Time                    | 1.12e+03   |
| dLoss                   | 0.0255883  |
----------------------------------------
itr #139 | 
Mem: 681.933594
Obtaining samples...
Obtaining samples for iteration 139...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5154, #subsample_inputs: 5154
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.626      |
| AbsLearnSignalNew       | 0.626      |
| AbsLearningOld          | 0.625      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 11.5419    |
| AveragePolicyStd        | 0.731866   |
| AverageReturn           | 1.07e+03   |
| Entropy                 | 3.30785    |
| EnvExecTime             | 1.99       |
| ExplainedVariance       | 0.74       |
| Iteration               | 139        |
| ItrTime                 | 8.2        |
| LossAfter               | 0.266259   |
| LossBefore              | 0.28471    |
| MaxReturn               | 1.6e+03    |
| MeanKL                  | 0.00642178 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 855        |
| NumTrajs                | 15         |
| Perplexity              | 27.3262    |
| PolicyExecTime          | 0.501      |
| ProcessExecTime         | 0.06       |
| StdReturn               | 180        |
| Time                    | 1.12e+03   |
| dLoss                   | 0.0184508  |
----------------------------------------
itr #140 | 
Mem: 681.933594
Obtaining samples...
Obtaining samples for iteration 140...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5039, #subsample_inputs: 5039
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.453      |
| AbsLearnSignalNew       | 0.453      |
| AbsLearningOld          | 0.453      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 10.0667    |
| AveragePolicyStd        | 0.733193   |
| AverageReturn           | 1.31e+03   |
| Entropy                 | 3.31288    |
| EnvExecTime             | 1.85       |
| ExplainedVariance       | -0.145     |
| Iteration               | 140        |
| ItrTime                 | 7.93       |
| LossAfter               | 0.321522   |
| LossBefore              | 0.343662   |
| MaxReturn               | 2.14e+03   |
| MeanKL                  | 0.00643638 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 822        |
| NumTrajs                | 12         |
| Perplexity              | 27.4642    |
| PolicyExecTime          | 0.47       |
| ProcessExecTime         | 0.057      |
| StdReturn               | 360        |
| Time                    | 1.13e+03   |
| dLoss                   | 0.0221398  |
----------------------------------------
itr #141 | 
Mem: 682.183594
Obtaining samples...
Obtaining samples for iteration 141...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5190, #subsample_inputs: 5190
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.79       |
| AbsLearnSignalNew       | 0.79       |
| AbsLearningOld          | 0.79       |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 10.9315    |
| AveragePolicyStd        | 0.730381   |
| AverageReturn           | 1.11e+03   |
| Entropy                 | 3.30273    |
| EnvExecTime             | 1.88       |
| ExplainedVariance       | 0.929      |
| Iteration               | 141        |
| ItrTime                 | 8.07       |
| LossAfter               | 0.023962   |
| LossBefore              | 0.0446503  |
| MaxReturn               | 1.65e+03   |
| MeanKL                  | 0.00641876 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 898        |
| NumTrajs                | 15         |
| Perplexity              | 27.1866    |
| PolicyExecTime          | 0.483      |
| ProcessExecTime         | 0.0565     |
| StdReturn               | 214        |
| Time                    | 1.14e+03   |
| dLoss                   | 0.0206883  |
----------------------------------------
itr #142 | 
Mem: 682.183594
Obtaining samples...
Obtaining samples for iteration 142...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5022, #subsample_inputs: 5022
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.556      |
| AbsLearnSignalNew       | 0.556      |
| AbsLearningOld          | 0.556      |
| AverageDiscountedReturn | 233        |
| AveragePhiLoss          | 9.71199    |
| AveragePolicyStd        | 0.725155   |
| AverageReturn           | 1.21e+03   |
| Entropy                 | 3.27974    |
| EnvExecTime             | 1.96       |
| ExplainedVariance       | 0.572      |
| Iteration               | 142        |
| ItrTime                 | 8.05       |
| LossAfter               | 0.162939   |
| LossBefore              | 0.18695    |
| MaxReturn               | 1.82e+03   |
| MeanKL                  | 0.00930526 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 407        |
| NumTrajs                | 13         |
| Perplexity              | 26.5689    |
| PolicyExecTime          | 0.498      |
| ProcessExecTime         | 0.0583     |
| StdReturn               | 362        |
| Time                    | 1.15e+03   |
| dLoss                   | 0.0240113  |
----------------------------------------
itr #143 | 
Mem: 682.183594
Obtaining samples...
Obtaining samples for iteration 143...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5358, #subsample_inputs: 5358
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.755      |
| AbsLearnSignalNew       | 0.755      |
| AbsLearningOld          | 0.755      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 10.396     |
| AveragePolicyStd        | 0.733288   |
| AverageReturn           | 1.2e+03    |
| Entropy                 | 3.31225    |
| EnvExecTime             | 1.93       |
| ExplainedVariance       | 0.858      |
| Iteration               | 143        |
| ItrTime                 | 8.35       |
| LossAfter               | 0.0406204  |
| LossBefore              | 0.0635358  |
| MaxReturn               | 1.68e+03   |
| MeanKL                  | 0.00650284 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 872        |
| NumTrajs                | 14         |
| Perplexity              | 27.4467    |
| PolicyExecTime          | 0.495      |
| ProcessExecTime         | 0.0585     |
| StdReturn               | 223        |
| Time                    | 1.16e+03   |
| dLoss                   | 0.0229154  |
----------------------------------------
itr #144 | 
Mem: 682.183594
Obtaining samples...
Obtaining samples for iteration 144...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5040, #subsample_inputs: 5040
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.773      |
| AbsLearnSignalNew       | 0.773      |
| AbsLearningOld          | 0.773      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 11.2517    |
| AveragePolicyStd        | 0.730418   |
| AverageReturn           | 1.14e+03   |
| Entropy                 | 3.2991     |
| EnvExecTime             | 2.08       |
| ExplainedVariance       | 0.912      |
| Iteration               | 144        |
| ItrTime                 | 8.28       |
| LossAfter               | -0.308308  |
| LossBefore              | -0.280835  |
| MaxReturn               | 1.6e+03    |
| MeanKL                  | 0.00999084 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 906        |
| NumTrajs                | 14         |
| Perplexity              | 27.0884    |
| PolicyExecTime          | 0.528      |
| ProcessExecTime         | 0.0598     |
| StdReturn               | 201        |
| Time                    | 1.17e+03   |
| dLoss                   | 0.0274731  |
----------------------------------------
itr #145 | 
Mem: 682.183594
Obtaining samples...
Obtaining samples for iteration 145...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5167, #subsample_inputs: 5167
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.782      |
| AbsLearnSignalNew       | 0.782      |
| AbsLearningOld          | 0.782      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 10.752     |
| AveragePolicyStd        | 0.729706   |
| AverageReturn           | 1.1e+03    |
| Entropy                 | 3.29793    |
| EnvExecTime             | 2.01       |
| ExplainedVariance       | 0.909      |
| Iteration               | 145        |
| ItrTime                 | 8.3        |
| LossAfter               | 0.227775   |
| LossBefore              | 0.251434   |
| MaxReturn               | 1.64e+03   |
| MeanKL                  | 0.00646431 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 851        |
| NumTrajs                | 15         |
| Perplexity              | 27.0567    |
| PolicyExecTime          | 0.506      |
| ProcessExecTime         | 0.0625     |
| StdReturn               | 220        |
| Time                    | 1.17e+03   |
| dLoss                   | 0.0236586  |
----------------------------------------
itr #146 | 
Mem: 682.183594
Obtaining samples...
Obtaining samples for iteration 146...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5064, #subsample_inputs: 5064
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.794      |
| AbsLearnSignalNew       | 0.794      |
| AbsLearningOld          | 0.795      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 10.739     |
| AveragePolicyStd        | 0.728599   |
| AverageReturn           | 1.03e+03   |
| Entropy                 | 3.29349    |
| EnvExecTime             | 1.92       |
| ExplainedVariance       | 0.932      |
| Iteration               | 146        |
| ItrTime                 | 8.05       |
| LossAfter               | -0.511917  |
| LossBefore              | -0.486408  |
| MaxReturn               | 1.33e+03   |
| MeanKL                  | 0.00970739 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 813        |
| NumTrajs                | 16         |
| Perplexity              | 26.9367    |
| PolicyExecTime          | 0.495      |
| ProcessExecTime         | 0.0571     |
| StdReturn               | 144        |
| Time                    | 1.18e+03   |
| dLoss                   | 0.0255087  |
----------------------------------------
itr #147 | 
Mem: 682.183594
Obtaining samples...
Obtaining samples for iteration 147...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5190, #subsample_inputs: 5190
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.506      |
| AbsLearnSignalNew       | 0.506      |
| AbsLearningOld          | 0.506      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 12.9377    |
| AveragePolicyStd        | 0.725182   |
| AverageReturn           | 1.17e+03   |
| Entropy                 | 3.28128    |
| EnvExecTime             | 2.18       |
| ExplainedVariance       | 0.502      |
| Iteration               | 147        |
| ItrTime                 | 8.5        |
| LossAfter               | 0.160053   |
| LossBefore              | 0.178704   |
| MaxReturn               | 1.93e+03   |
| MeanKL                  | 0.00652526 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 827        |
| NumTrajs                | 14         |
| Perplexity              | 26.6099    |
| PolicyExecTime          | 0.547      |
| ProcessExecTime         | 0.0647     |
| StdReturn               | 267        |
| Time                    | 1.19e+03   |
| dLoss                   | 0.0186512  |
----------------------------------------
itr #148 | 
Mem: 682.183594
Obtaining samples...
Obtaining samples for iteration 148...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5289, #subsample_inputs: 5289
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.738     |
| AbsLearnSignalNew       | 0.738     |
| AbsLearningOld          | 0.738     |
| AverageDiscountedReturn | 238       |
| AveragePhiLoss          | 11.8311   |
| AveragePolicyStd        | 0.727471  |
| AverageReturn           | 1.19e+03  |
| Entropy                 | 3.28792   |
| EnvExecTime             | 1.99      |
| ExplainedVariance       | 0.851     |
| Iteration               | 148       |
| ItrTime                 | 8.31      |
| LossAfter               | -0.211187 |
| LossBefore              | -0.183049 |
| MaxReturn               | 2.18e+03  |
| MeanKL                  | 0.0098615 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 698       |
| NumTrajs                | 14        |
| Perplexity              | 26.787    |
| PolicyExecTime          | 0.516     |
| ProcessExecTime         | 0.0591    |
| StdReturn               | 348       |
| Time                    | 1.2e+03   |
| dLoss                   | 0.0281382 |
---------------------------------------
itr #149 | 
Mem: 682.183594
Obtaining samples...
Obtaining samples for iteration 149...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5261, #subsample_inputs: 5261
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.787      |
| AbsLearnSignalNew       | 0.787      |
| AbsLearningOld          | 0.787      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 11.1219    |
| AveragePolicyStd        | 0.727728   |
| AverageReturn           | 1.07e+03   |
| Entropy                 | 3.28945    |
| EnvExecTime             | 2.15       |
| ExplainedVariance       | 0.933      |
| Iteration               | 149        |
| ItrTime                 | 8.51       |
| LossAfter               | -0.60214   |
| LossBefore              | -0.579437  |
| MaxReturn               | 1.61e+03   |
| MeanKL                  | 0.00645212 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 886        |
| NumTrajs                | 16         |
| Perplexity              | 26.828     |
| PolicyExecTime          | 0.538      |
| ProcessExecTime         | 0.0637     |
| StdReturn               | 167        |
| Time                    | 1.21e+03   |
| dLoss                   | 0.0227035  |
----------------------------------------
itr #150 | 
Mem: 682.183594
Obtaining samples...
Obtaining samples for iteration 150...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5098, #subsample_inputs: 5098
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.567      |
| AbsLearnSignalNew       | 0.567      |
| AbsLearningOld          | 0.567      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 10.5997    |
| AveragePolicyStd        | 0.72457    |
| AverageReturn           | 1.16e+03   |
| Entropy                 | 3.27565    |
| EnvExecTime             | 2.05       |
| ExplainedVariance       | 0.704      |
| Iteration               | 150        |
| ItrTime                 | 8.25       |
| LossAfter               | -0.397696  |
| LossBefore              | -0.364464  |
| MaxReturn               | 2.14e+03   |
| MeanKL                  | 0.00988628 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 861        |
| NumTrajs                | 14         |
| Perplexity              | 26.4603    |
| PolicyExecTime          | 0.515      |
| ProcessExecTime         | 0.0636     |
| StdReturn               | 317        |
| Time                    | 1.22e+03   |
| dLoss                   | 0.0332322  |
----------------------------------------
itr #151 | 
Mem: 682.183594
Obtaining samples...
Obtaining samples for iteration 151...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5088, #subsample_inputs: 5088
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.773      |
| AbsLearnSignalNew       | 0.773      |
| AbsLearningOld          | 0.773      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 11.4064    |
| AveragePolicyStd        | 0.723257   |
| AverageReturn           | 1.04e+03   |
| Entropy                 | 3.2689     |
| EnvExecTime             | 1.96       |
| ExplainedVariance       | 0.923      |
| Iteration               | 151        |
| ItrTime                 | 8.13       |
| LossAfter               | 0.103202   |
| LossBefore              | 0.122934   |
| MaxReturn               | 1.29e+03   |
| MeanKL                  | 0.00644724 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 847        |
| NumTrajs                | 16         |
| Perplexity              | 26.2825    |
| PolicyExecTime          | 0.492      |
| ProcessExecTime         | 0.0593     |
| StdReturn               | 133        |
| Time                    | 1.22e+03   |
| dLoss                   | 0.019732   |
----------------------------------------
itr #152 | 
Mem: 682.183594
Obtaining samples...
Obtaining samples for iteration 152...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5306, #subsample_inputs: 5306
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.787      |
| AbsLearnSignalNew       | 0.787      |
| AbsLearningOld          | 0.787      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 11.5936    |
| AveragePolicyStd        | 0.722089   |
| AverageReturn           | 1.02e+03   |
| Entropy                 | 3.26547    |
| EnvExecTime             | 2.1        |
| ExplainedVariance       | 0.942      |
| Iteration               | 152        |
| ItrTime                 | 8.46       |
| LossAfter               | 0.169847   |
| LossBefore              | 0.198041   |
| MaxReturn               | 1.41e+03   |
| MeanKL                  | 0.00946364 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 832        |
| NumTrajs                | 17         |
| Perplexity              | 26.1924    |
| PolicyExecTime          | 0.534      |
| ProcessExecTime         | 0.0639     |
| StdReturn               | 142        |
| Time                    | 1.23e+03   |
| dLoss                   | 0.0281937  |
----------------------------------------
itr #153 | 
Mem: 682.183594
Obtaining samples...
Obtaining samples for iteration 153...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5253, #subsample_inputs: 5253
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.715      |
| AbsLearnSignalNew       | 0.715      |
| AbsLearningOld          | 0.715      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 12.0854    |
| AveragePolicyStd        | 0.73011    |
| AverageReturn           | 1.12e+03   |
| Entropy                 | 3.29762    |
| EnvExecTime             | 1.82       |
| ExplainedVariance       | 0.893      |
| Iteration               | 153        |
| ItrTime                 | 8.15       |
| LossAfter               | 0.376695   |
| LossBefore              | 0.3949     |
| MaxReturn               | 1.73e+03   |
| MeanKL                  | 0.00641033 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 882        |
| NumTrajs                | 15         |
| Perplexity              | 27.0483    |
| PolicyExecTime          | 0.465      |
| ProcessExecTime         | 0.0561     |
| StdReturn               | 247        |
| Time                    | 1.24e+03   |
| dLoss                   | 0.0182047  |
----------------------------------------
itr #154 | 
Mem: 682.183594
Obtaining samples...
Obtaining samples for iteration 154...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5075, #subsample_inputs: 5075
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.708     |
| AbsLearnSignalNew       | 0.708     |
| AbsLearningOld          | 0.708     |
| AverageDiscountedReturn | 240       |
| AveragePhiLoss          | 11.6197   |
| AveragePolicyStd        | 0.729644  |
| AverageReturn           | 1.04e+03  |
| Entropy                 | 3.29511   |
| EnvExecTime             | 1.84      |
| ExplainedVariance       | 0.821     |
| Iteration               | 154       |
| ItrTime                 | 7.94      |
| LossAfter               | 0.0754855 |
| LossBefore              | 0.100164  |
| MaxReturn               | 2.47e+03  |
| MeanKL                  | 0.0097994 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 818       |
| NumTrajs                | 15        |
| Perplexity              | 26.9804   |
| PolicyExecTime          | 0.477     |
| ProcessExecTime         | 0.0559    |
| StdReturn               | 390       |
| Time                    | 1.25e+03  |
| dLoss                   | 0.0246783 |
---------------------------------------
itr #155 | 
Mem: 682.183594
Obtaining samples...
Obtaining samples for iteration 155...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5221, #subsample_inputs: 5221
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.728      |
| AbsLearnSignalNew       | 0.728      |
| AbsLearningOld          | 0.728      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 11.3961    |
| AveragePolicyStd        | 0.728375   |
| AverageReturn           | 1.26e+03   |
| Entropy                 | 3.2899     |
| EnvExecTime             | 1.92       |
| ExplainedVariance       | 0.835      |
| Iteration               | 155        |
| ItrTime                 | 8.17       |
| LossAfter               | 0.0609514  |
| LossBefore              | 0.0840457  |
| MaxReturn               | 2.55e+03   |
| MeanKL                  | 0.00649069 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 876        |
| NumTrajs                | 13         |
| Perplexity              | 26.8403    |
| PolicyExecTime          | 0.497      |
| ProcessExecTime         | 0.0577     |
| StdReturn               | 459        |
| Time                    | 1.26e+03   |
| dLoss                   | 0.0230943  |
----------------------------------------
itr #156 | 
Mem: 682.183594
Obtaining samples...
Obtaining samples for iteration 156...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5188, #subsample_inputs: 5188
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.692     |
| AbsLearnSignalNew       | 0.692     |
| AbsLearningOld          | 0.692     |
| AverageDiscountedReturn | 240       |
| AveragePhiLoss          | 10.5785   |
| AveragePolicyStd        | 0.725581  |
| AverageReturn           | 1.18e+03  |
| Entropy                 | 3.27832   |
| EnvExecTime             | 2.17      |
| ExplainedVariance       | 0.85      |
| Iteration               | 156       |
| ItrTime                 | 8.46      |
| LossAfter               | 0.113365  |
| LossBefore              | 0.139581  |
| MaxReturn               | 1.72e+03  |
| MeanKL                  | 0.0098858 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 865       |
| NumTrajs                | 14        |
| Perplexity              | 26.5312   |
| PolicyExecTime          | 0.557     |
| ProcessExecTime         | 0.0625    |
| StdReturn               | 217       |
| Time                    | 1.27e+03  |
| dLoss                   | 0.0262158 |
---------------------------------------
itr #157 | 
Mem: 682.183594
Obtaining samples...
Obtaining samples for iteration 157...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5128, #subsample_inputs: 5128
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.724      |
| AbsLearnSignalNew       | 0.724      |
| AbsLearningOld          | 0.723      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 11.7436    |
| AveragePolicyStd        | 0.730436   |
| AverageReturn           | 1.16e+03   |
| Entropy                 | 3.30064    |
| EnvExecTime             | 2          |
| ExplainedVariance       | 0.849      |
| Iteration               | 157        |
| ItrTime                 | 8.18       |
| LossAfter               | -0.267302  |
| LossBefore              | -0.240157  |
| MaxReturn               | 2.27e+03   |
| MeanKL                  | 0.00960355 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 855        |
| NumTrajs                | 14         |
| Perplexity              | 27.1301    |
| PolicyExecTime          | 0.509      |
| ProcessExecTime         | 0.0597     |
| StdReturn               | 354        |
| Time                    | 1.27e+03   |
| dLoss                   | 0.0271449  |
----------------------------------------
itr #158 | 
Mem: 682.183594
Obtaining samples...
Obtaining samples for iteration 158...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5086, #subsample_inputs: 5086
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.757      |
| AbsLearnSignalNew       | 0.757      |
| AbsLearningOld          | 0.757      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 10.8615    |
| AveragePolicyStd        | 0.731011   |
| AverageReturn           | 1.17e+03   |
| Entropy                 | 3.3049     |
| EnvExecTime             | 1.89       |
| ExplainedVariance       | 0.91       |
| Iteration               | 158        |
| ItrTime                 | 8.08       |
| LossAfter               | -0.154221  |
| LossBefore              | -0.129566  |
| MaxReturn               | 1.75e+03   |
| MeanKL                  | 0.00996397 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 823        |
| NumTrajs                | 14         |
| Perplexity              | 27.2459    |
| PolicyExecTime          | 0.488      |
| ProcessExecTime         | 0.0562     |
| StdReturn               | 263        |
| Time                    | 1.28e+03   |
| dLoss                   | 0.024655   |
----------------------------------------
itr #159 | 
Mem: 682.183594
Obtaining samples...
Obtaining samples for iteration 159...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5125, #subsample_inputs: 5125
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.632      |
| AbsLearnSignalNew       | 0.632      |
| AbsLearningOld          | 0.632      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 11.1581    |
| AveragePolicyStd        | 0.734206   |
| AverageReturn           | 1.21e+03   |
| Entropy                 | 3.31996    |
| EnvExecTime             | 2.07       |
| ExplainedVariance       | 0.697      |
| Iteration               | 159        |
| ItrTime                 | 8.34       |
| LossAfter               | -0.0155345 |
| LossBefore              | 0.00537547 |
| MaxReturn               | 2.09e+03   |
| MeanKL                  | 0.00661513 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 992        |
| NumTrajs                | 13         |
| Perplexity              | 27.6592    |
| PolicyExecTime          | 0.52       |
| ProcessExecTime         | 0.0618     |
| StdReturn               | 321        |
| Time                    | 1.29e+03   |
| dLoss                   | 0.0209099  |
----------------------------------------
itr #160 | 
Mem: 682.183594
Obtaining samples...
Obtaining samples for iteration 160...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5003, #subsample_inputs: 5003
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.734      |
| AbsLearnSignalNew       | 0.734      |
| AbsLearningOld          | 0.734      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 10.8557    |
| AveragePolicyStd        | 0.732576   |
| AverageReturn           | 1.32e+03   |
| Entropy                 | 3.31109    |
| EnvExecTime             | 1.84       |
| ExplainedVariance       | 0.852      |
| Iteration               | 160        |
| ItrTime                 | 7.96       |
| LossAfter               | -0.567207  |
| LossBefore              | -0.544062  |
| MaxReturn               | 2.02e+03   |
| MeanKL                  | 0.00980533 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 917        |
| NumTrajs                | 12         |
| Perplexity              | 27.415     |
| PolicyExecTime          | 0.465      |
| ProcessExecTime         | 0.0552     |
| StdReturn               | 319        |
| Time                    | 1.3e+03    |
| dLoss                   | 0.0231445  |
----------------------------------------
itr #161 | 
Mem: 682.183594
Obtaining samples...
Obtaining samples for iteration 161...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5169, #subsample_inputs: 5169
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.731      |
| AbsLearnSignalNew       | 0.731      |
| AbsLearningOld          | 0.731      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 10.7142    |
| AveragePolicyStd        | 0.733317   |
| AverageReturn           | 1.11e+03   |
| Entropy                 | 3.31451    |
| EnvExecTime             | 1.89       |
| ExplainedVariance       | 0.887      |
| Iteration               | 161        |
| ItrTime                 | 8.13       |
| LossAfter               | -0.368086  |
| LossBefore              | -0.347498  |
| MaxReturn               | 1.55e+03   |
| MeanKL                  | 0.00649228 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 831        |
| NumTrajs                | 15         |
| Perplexity              | 27.5089    |
| PolicyExecTime          | 0.482      |
| ProcessExecTime         | 0.0573     |
| StdReturn               | 177        |
| Time                    | 1.31e+03   |
| dLoss                   | 0.0205881  |
----------------------------------------
itr #162 | 
Mem: 682.183594
Obtaining samples...
Obtaining samples for iteration 162...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5084, #subsample_inputs: 5084
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.572      |
| AbsLearnSignalNew       | 0.572      |
| AbsLearningOld          | 0.572      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 8.27072    |
| AveragePolicyStd        | 0.735137   |
| AverageReturn           | 1.17e+03   |
| Entropy                 | 3.32262    |
| EnvExecTime             | 1.98       |
| ExplainedVariance       | 0.663      |
| Iteration               | 162        |
| ItrTime                 | 8.15       |
| LossAfter               | -0.373196  |
| LossBefore              | -0.347878  |
| MaxReturn               | 2.2e+03    |
| MeanKL                  | 0.00650817 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 864        |
| NumTrajs                | 14         |
| Perplexity              | 27.7331    |
| PolicyExecTime          | 0.491      |
| ProcessExecTime         | 0.0605     |
| StdReturn               | 313        |
| Time                    | 1.31e+03   |
| dLoss                   | 0.0253184  |
----------------------------------------
itr #163 | 
Mem: 682.183594
Obtaining samples...
Obtaining samples for iteration 163...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5341, #subsample_inputs: 5341
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.727      |
| AbsLearnSignalNew       | 0.727      |
| AbsLearningOld          | 0.727      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 10.6474    |
| AveragePolicyStd        | 0.738227   |
| AverageReturn           | 1.13e+03   |
| Entropy                 | 3.33541    |
| EnvExecTime             | 1.9        |
| ExplainedVariance       | 0.862      |
| Iteration               | 163        |
| ItrTime                 | 8.29       |
| LossAfter               | -0.226175  |
| LossBefore              | -0.200274  |
| MaxReturn               | 1.41e+03   |
| MeanKL                  | 0.00976506 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 880        |
| NumTrajs                | 15         |
| Perplexity              | 28.0898    |
| PolicyExecTime          | 0.478      |
| ProcessExecTime         | 0.0581     |
| StdReturn               | 131        |
| Time                    | 1.32e+03   |
| dLoss                   | 0.025901   |
----------------------------------------
itr #164 | 
Mem: 682.183594
Obtaining samples...
Obtaining samples for iteration 164...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5156, #subsample_inputs: 5156
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.765      |
| AbsLearnSignalNew       | 0.765      |
| AbsLearningOld          | 0.765      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 10.7498    |
| AveragePolicyStd        | 0.740207   |
| AverageReturn           | 1.18e+03   |
| Entropy                 | 3.34218    |
| EnvExecTime             | 1.85       |
| ExplainedVariance       | 0.899      |
| Iteration               | 164        |
| ItrTime                 | 8.07       |
| LossAfter               | -0.0170516 |
| LossBefore              | 0.00998564 |
| MaxReturn               | 1.6e+03    |
| MeanKL                  | 0.00987581 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 860        |
| NumTrajs                | 14         |
| Perplexity              | 28.2808    |
| PolicyExecTime          | 0.479      |
| ProcessExecTime         | 0.0555     |
| StdReturn               | 202        |
| Time                    | 1.33e+03   |
| dLoss                   | 0.0270372  |
----------------------------------------
itr #165 | 
Mem: 682.183594
Obtaining samples...
Obtaining samples for iteration 165...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5180, #subsample_inputs: 5180
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.73       |
| AbsLearnSignalNew       | 0.73       |
| AbsLearningOld          | 0.73       |
| AverageDiscountedReturn | 236        |
| AveragePhiLoss          | 10.0639    |
| AveragePolicyStd        | 0.744583   |
| AverageReturn           | 1.22e+03   |
| Entropy                 | 3.36207    |
| EnvExecTime             | 2.06       |
| ExplainedVariance       | 0.791      |
| Iteration               | 165        |
| ItrTime                 | 8.32       |
| LossAfter               | 0.707423   |
| LossBefore              | 0.730843   |
| MaxReturn               | 2.1e+03    |
| MeanKL                  | 0.00640477 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 750        |
| NumTrajs                | 13         |
| Perplexity              | 28.8488    |
| PolicyExecTime          | 0.529      |
| ProcessExecTime         | 0.0608     |
| StdReturn               | 390        |
| Time                    | 1.34e+03   |
| dLoss                   | 0.0234193  |
----------------------------------------
itr #166 | 
Mem: 682.183594
Obtaining samples...
Obtaining samples for iteration 166...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5074, #subsample_inputs: 5074
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
-----------------------------------------
| AbsLearnSignal          | 0.692       |
| AbsLearnSignalNew       | 0.692       |
| AbsLearningOld          | 0.692       |
| AverageDiscountedReturn | 237         |
| AveragePhiLoss          | 10.5634     |
| AveragePolicyStd        | 0.743138    |
| AverageReturn           | 1.12e+03    |
| Entropy                 | 3.35656     |
| EnvExecTime             | 1.92        |
| ExplainedVariance       | 0.751       |
| Iteration               | 166         |
| ItrTime                 | 8.09        |
| LossAfter               | -0.00297462 |
| LossBefore              | 0.0192333   |
| MaxReturn               | 1.63e+03    |
| MeanKL                  | 0.00670471  |
| MeanKLBefore            | 0.0         |
| MinReturn               | 658         |
| NumTrajs                | 14          |
| Perplexity              | 28.6904     |
| PolicyExecTime          | 0.481       |
| ProcessExecTime         | 0.0586      |
| StdReturn               | 231         |
| Time                    | 1.35e+03    |
| dLoss                   | 0.0222079   |
-----------------------------------------
itr #167 | 
Mem: 682.183594
Obtaining samples...
Obtaining samples for iteration 167...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5139, #subsample_inputs: 5139
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.755      |
| AbsLearnSignalNew       | 0.755      |
| AbsLearningOld          | 0.755      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 10.6476    |
| AveragePolicyStd        | 0.738801   |
| AverageReturn           | 1.11e+03   |
| Entropy                 | 3.33895    |
| EnvExecTime             | 1.93       |
| ExplainedVariance       | 0.887      |
| Iteration               | 167        |
| ItrTime                 | 8.12       |
| LossAfter               | 0.0290099  |
| LossBefore              | 0.0481629  |
| MaxReturn               | 1.6e+03    |
| MeanKL                  | 0.00647315 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 809        |
| NumTrajs                | 15         |
| Perplexity              | 28.1894    |
| PolicyExecTime          | 0.495      |
| ProcessExecTime         | 0.0585     |
| StdReturn               | 223        |
| Time                    | 1.36e+03   |
| dLoss                   | 0.019153   |
----------------------------------------
itr #168 | 
Mem: 682.183594
Obtaining samples...
Obtaining samples for iteration 168...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5022, #subsample_inputs: 5022
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.594      |
| AbsLearnSignalNew       | 0.594      |
| AbsLearningOld          | 0.594      |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 9.98032    |
| AveragePolicyStd        | 0.732205   |
| AverageReturn           | 1.2e+03    |
| Entropy                 | 3.3118     |
| EnvExecTime             | 1.96       |
| ExplainedVariance       | 0.535      |
| Iteration               | 168        |
| ItrTime                 | 8.1        |
| LossAfter               | 0.448426   |
| LossBefore              | 0.466526   |
| MaxReturn               | 1.7e+03    |
| MeanKL                  | 0.00649147 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 790        |
| NumTrajs                | 13         |
| Perplexity              | 27.4343    |
| PolicyExecTime          | 0.498      |
| ProcessExecTime         | 0.059      |
| StdReturn               | 295        |
| Time                    | 1.36e+03   |
| dLoss                   | 0.0180998  |
----------------------------------------
itr #169 | 
Mem: 682.183594
Obtaining samples...
Obtaining samples for iteration 169...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5457, #subsample_inputs: 5457
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.682      |
| AbsLearnSignalNew       | 0.682      |
| AbsLearningOld          | 0.682      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 10.3145    |
| AveragePolicyStd        | 0.733529   |
| AverageReturn           | 1.14e+03   |
| Entropy                 | 3.31696    |
| EnvExecTime             | 2.06       |
| ExplainedVariance       | 0.85       |
| Iteration               | 169        |
| ItrTime                 | 8.61       |
| LossAfter               | -0.0928162 |
| LossBefore              | -0.0677055 |
| MaxReturn               | 2.07e+03   |
| MeanKL                  | 0.00968048 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 863        |
| NumTrajs                | 15         |
| Perplexity              | 27.5764    |
| PolicyExecTime          | 0.531      |
| ProcessExecTime         | 0.062      |
| StdReturn               | 308        |
| Time                    | 1.37e+03   |
| dLoss                   | 0.0251107  |
----------------------------------------
itr #170 | 
Mem: 682.445312
Obtaining samples...
Obtaining samples for iteration 170...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5045, #subsample_inputs: 5045
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.762      |
| AbsLearnSignalNew       | 0.762      |
| AbsLearningOld          | 0.762      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 11.3522    |
| AveragePolicyStd        | 0.730199   |
| AverageReturn           | 1.16e+03   |
| Entropy                 | 3.30253    |
| EnvExecTime             | 1.81       |
| ExplainedVariance       | 0.918      |
| Iteration               | 170        |
| ItrTime                 | 7.91       |
| LossAfter               | -0.337463  |
| LossBefore              | -0.308263  |
| MaxReturn               | 1.7e+03    |
| MeanKL                  | 0.00997756 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 780        |
| NumTrajs                | 14         |
| Perplexity              | 27.1813    |
| PolicyExecTime          | 0.458      |
| ProcessExecTime         | 0.056      |
| StdReturn               | 230        |
| Time                    | 1.38e+03   |
| dLoss                   | 0.0292006  |
----------------------------------------
itr #171 | 
Mem: 682.445312
Obtaining samples...
Obtaining samples for iteration 171...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5159, #subsample_inputs: 5159
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.733      |
| AbsLearnSignalNew       | 0.733      |
| AbsLearningOld          | 0.733      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 11.525     |
| AveragePolicyStd        | 0.732228   |
| AverageReturn           | 1.04e+03   |
| Entropy                 | 3.31301    |
| EnvExecTime             | 1.87       |
| ExplainedVariance       | 0.904      |
| Iteration               | 171        |
| ItrTime                 | 8.05       |
| LossAfter               | -0.599166  |
| LossBefore              | -0.571337  |
| MaxReturn               | 1.64e+03   |
| MeanKL                  | 0.00999644 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 769        |
| NumTrajs                | 16         |
| Perplexity              | 27.4677    |
| PolicyExecTime          | 0.475      |
| ProcessExecTime         | 0.058      |
| StdReturn               | 206        |
| Time                    | 1.39e+03   |
| dLoss                   | 0.0278293  |
----------------------------------------
itr #172 | 
Mem: 682.445312
Obtaining samples...
Obtaining samples for iteration 172...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5136, #subsample_inputs: 5136
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.76       |
| AbsLearnSignalNew       | 0.76       |
| AbsLearningOld          | 0.76       |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 11.1345    |
| AveragePolicyStd        | 0.734195   |
| AverageReturn           | 933        |
| Entropy                 | 3.31885    |
| EnvExecTime             | 1.84       |
| ExplainedVariance       | 0.94       |
| Iteration               | 172        |
| ItrTime                 | 7.99       |
| LossAfter               | 0.0679026  |
| LossBefore              | 0.092739   |
| MaxReturn               | 1.13e+03   |
| MeanKL                  | 0.00654967 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 747        |
| NumTrajs                | 18         |
| Perplexity              | 27.6285    |
| PolicyExecTime          | 0.468      |
| ProcessExecTime         | 0.0552     |
| StdReturn               | 106        |
| Time                    | 1.4e+03    |
| dLoss                   | 0.0248364  |
----------------------------------------
itr #173 | 
Mem: 682.445312
Obtaining samples...
Obtaining samples for iteration 173...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5234, #subsample_inputs: 5234
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.739      |
| AbsLearnSignalNew       | 0.739      |
| AbsLearningOld          | 0.739      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 10.4422    |
| AveragePolicyStd        | 0.73408    |
| AverageReturn           | 954        |
| Entropy                 | 3.31752    |
| EnvExecTime             | 1.86       |
| ExplainedVariance       | 0.942      |
| Iteration               | 173        |
| ItrTime                 | 8.14       |
| LossAfter               | 0.0502567  |
| LossBefore              | 0.0775887  |
| MaxReturn               | 1.16e+03   |
| MeanKL                  | 0.00994905 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 782        |
| NumTrajs                | 18         |
| Perplexity              | 27.5918    |
| PolicyExecTime          | 0.48       |
| ProcessExecTime         | 0.0575     |
| StdReturn               | 105        |
| Time                    | 1.41e+03   |
| dLoss                   | 0.027332   |
----------------------------------------
itr #174 | 
Mem: 682.445312
Obtaining samples...
Obtaining samples for iteration 174...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5146, #subsample_inputs: 5146
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.391      |
| AbsLearnSignalNew       | 0.391      |
| AbsLearningOld          | 0.391      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 11.4492    |
| AveragePolicyStd        | 0.736625   |
| AverageReturn           | 1.1e+03    |
| Entropy                 | 3.32576    |
| EnvExecTime             | 1.83       |
| ExplainedVariance       | -0.157     |
| Iteration               | 174        |
| ItrTime                 | 8          |
| LossAfter               | -0.0336811 |
| LossBefore              | -0.0111515 |
| MaxReturn               | 1.8e+03    |
| MeanKL                  | 0.00968832 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 850        |
| NumTrajs                | 15         |
| Perplexity              | 27.8201    |
| PolicyExecTime          | 0.471      |
| ProcessExecTime         | 0.0563     |
| StdReturn               | 261        |
| Time                    | 1.41e+03   |
| dLoss                   | 0.0225296  |
----------------------------------------
itr #175 | 
Mem: 682.445312
Obtaining samples...
Obtaining samples for iteration 175...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5123, #subsample_inputs: 5123
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.757      |
| AbsLearnSignalNew       | 0.757      |
| AbsLearningOld          | 0.757      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 10.8994    |
| AveragePolicyStd        | 0.735598   |
| AverageReturn           | 928        |
| Entropy                 | 3.32151    |
| EnvExecTime             | 1.79       |
| ExplainedVariance       | 0.934      |
| Iteration               | 175        |
| ItrTime                 | 7.97       |
| LossAfter               | 0.291546   |
| LossBefore              | 0.322207   |
| MaxReturn               | 1.15e+03   |
| MeanKL                  | 0.00969495 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 728        |
| NumTrajs                | 18         |
| Perplexity              | 27.7022    |
| PolicyExecTime          | 0.459      |
| ProcessExecTime         | 0.0546     |
| StdReturn               | 126        |
| Time                    | 1.42e+03   |
| dLoss                   | 0.0306602  |
----------------------------------------
itr #176 | 
Mem: 682.445312
Obtaining samples...
Obtaining samples for iteration 176...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5220, #subsample_inputs: 5220
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.524      |
| AbsLearnSignalNew       | 0.524      |
| AbsLearningOld          | 0.524      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 9.37421    |
| AveragePolicyStd        | 0.74157    |
| AverageReturn           | 990        |
| Entropy                 | 3.34478    |
| EnvExecTime             | 2.08       |
| ExplainedVariance       | 0.725      |
| Iteration               | 176        |
| ItrTime                 | 8.45       |
| LossAfter               | -0.0724687 |
| LossBefore              | -0.0528946 |
| MaxReturn               | 1.56e+03   |
| MeanKL                  | 0.00967748 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 677        |
| NumTrajs                | 17         |
| Perplexity              | 28.3542    |
| PolicyExecTime          | 0.524      |
| ProcessExecTime         | 0.0604     |
| StdReturn               | 193        |
| Time                    | 1.43e+03   |
| dLoss                   | 0.0195741  |
----------------------------------------
itr #177 | 
Mem: 682.445312
Obtaining samples...
Obtaining samples for iteration 177...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5348, #subsample_inputs: 5348
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.782      |
| AbsLearnSignalNew       | 0.782      |
| AbsLearningOld          | 0.782      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 10.2641    |
| AveragePolicyStd        | 0.751862   |
| AverageReturn           | 1.09e+03   |
| Entropy                 | 3.38919    |
| EnvExecTime             | 1.85       |
| ExplainedVariance       | 0.943      |
| Iteration               | 177        |
| ItrTime                 | 8.44       |
| LossAfter               | -0.160233  |
| LossBefore              | -0.133986  |
| MaxReturn               | 1.3e+03    |
| MeanKL                  | 0.00994528 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 807        |
| NumTrajs                | 16         |
| Perplexity              | 29.6419    |
| PolicyExecTime          | 0.474      |
| ProcessExecTime         | 0.058      |
| StdReturn               | 135        |
| Time                    | 1.44e+03   |
| dLoss                   | 0.0262473  |
----------------------------------------
itr #178 | 
Mem: 682.703125
Obtaining samples...
Obtaining samples for iteration 178...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5282, #subsample_inputs: 5282
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.533      |
| AbsLearnSignalNew       | 0.533      |
| AbsLearningOld          | 0.533      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 10.2923    |
| AveragePolicyStd        | 0.751912   |
| AverageReturn           | 1.13e+03   |
| Entropy                 | 3.38992    |
| EnvExecTime             | 1.85       |
| ExplainedVariance       | 0.712      |
| Iteration               | 178        |
| ItrTime                 | 8.17       |
| LossAfter               | -0.552359  |
| LossBefore              | -0.529948  |
| MaxReturn               | 1.66e+03   |
| MeanKL                  | 0.00670719 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 717        |
| NumTrajs                | 15         |
| Perplexity              | 29.6636    |
| PolicyExecTime          | 0.471      |
| ProcessExecTime         | 0.0571     |
| StdReturn               | 252        |
| Time                    | 1.45e+03   |
| dLoss                   | 0.022411   |
----------------------------------------
itr #179 | 
Mem: 682.703125
Obtaining samples...
Obtaining samples for iteration 179...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5040, #subsample_inputs: 5040
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.714      |
| AbsLearnSignalNew       | 0.714      |
| AbsLearningOld          | 0.714      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 9.54447    |
| AveragePolicyStd        | 0.752087   |
| AverageReturn           | 1.17e+03   |
| Entropy                 | 3.38914    |
| EnvExecTime             | 1.81       |
| ExplainedVariance       | 0.9        |
| Iteration               | 179        |
| ItrTime                 | 7.84       |
| LossAfter               | -0.747612  |
| LossBefore              | -0.721872  |
| MaxReturn               | 1.84e+03   |
| MeanKL                  | 0.00937083 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 814        |
| NumTrajs                | 14         |
| Perplexity              | 29.6405    |
| PolicyExecTime          | 0.457      |
| ProcessExecTime         | 0.0558     |
| StdReturn               | 267        |
| Time                    | 1.45e+03   |
| dLoss                   | 0.0257398  |
----------------------------------------
itr #180 | 
Mem: 682.703125
Obtaining samples...
Obtaining samples for iteration 180...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5191, #subsample_inputs: 5191
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.759      |
| AbsLearnSignalNew       | 0.759      |
| AbsLearningOld          | 0.759      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 9.59255    |
| AveragePolicyStd        | 0.756613   |
| AverageReturn           | 1.11e+03   |
| Entropy                 | 3.40753    |
| EnvExecTime             | 1.78       |
| ExplainedVariance       | 0.928      |
| Iteration               | 180        |
| ItrTime                 | 8.01       |
| LossAfter               | -0.917976  |
| LossBefore              | -0.894895  |
| MaxReturn               | 1.77e+03   |
| MeanKL                  | 0.00642413 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 844        |
| NumTrajs                | 15         |
| Perplexity              | 30.1906    |
| PolicyExecTime          | 0.462      |
| ProcessExecTime         | 0.0544     |
| StdReturn               | 241        |
| Time                    | 1.46e+03   |
| dLoss                   | 0.0230811  |
----------------------------------------
itr #181 | 
Mem: 682.703125
Obtaining samples...
Obtaining samples for iteration 181...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5207, #subsample_inputs: 5207
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.753      |
| AbsLearnSignalNew       | 0.753      |
| AbsLearningOld          | 0.753      |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 9.85088    |
| AveragePolicyStd        | 0.758638   |
| AverageReturn           | 1.17e+03   |
| Entropy                 | 3.41383    |
| EnvExecTime             | 1.94       |
| ExplainedVariance       | 0.894      |
| Iteration               | 181        |
| ItrTime                 | 8.2        |
| LossAfter               | -0.426693  |
| LossBefore              | -0.399176  |
| MaxReturn               | 1.64e+03   |
| MeanKL                  | 0.00999185 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 790        |
| NumTrajs                | 14         |
| Perplexity              | 30.3814    |
| PolicyExecTime          | 0.486      |
| ProcessExecTime         | 0.0615     |
| StdReturn               | 195        |
| Time                    | 1.47e+03   |
| dLoss                   | 0.0275166  |
----------------------------------------
itr #182 | 
Mem: 682.703125
Obtaining samples...
Obtaining samples for iteration 182...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5148, #subsample_inputs: 5148
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.505      |
| AbsLearnSignalNew       | 0.505      |
| AbsLearningOld          | 0.505      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 10.2064    |
| AveragePolicyStd        | 0.758368   |
| AverageReturn           | 1.36e+03   |
| Entropy                 | 3.41163    |
| EnvExecTime             | 1.95       |
| ExplainedVariance       | 0.509      |
| Iteration               | 182        |
| ItrTime                 | 8.16       |
| LossAfter               | 0.345791   |
| LossBefore              | 0.364375   |
| MaxReturn               | 2.65e+03   |
| MeanKL                  | 0.00645206 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.02e+03   |
| NumTrajs                | 12         |
| Perplexity              | 30.3146    |
| PolicyExecTime          | 0.495      |
| ProcessExecTime         | 0.0598     |
| StdReturn               | 452        |
| Time                    | 1.48e+03   |
| dLoss                   | 0.0185847  |
----------------------------------------
itr #183 | 
Mem: 682.957031
Obtaining samples...
Obtaining samples for iteration 183...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5487, #subsample_inputs: 5487
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
-----------------------------------------
| AbsLearnSignal          | 0.626       |
| AbsLearnSignalNew       | 0.626       |
| AbsLearningOld          | 0.626       |
| AverageDiscountedReturn | 236         |
| AveragePhiLoss          | 10.2576     |
| AveragePolicyStd        | 0.756876    |
| AverageReturn           | 1.1e+03     |
| Entropy                 | 3.40295     |
| EnvExecTime             | 2.08        |
| ExplainedVariance       | 0.792       |
| Iteration               | 183         |
| ItrTime                 | 8.58        |
| LossAfter               | -0.022832   |
| LossBefore              | -0.00457274 |
| MaxReturn               | 2.15e+03    |
| MeanKL                  | 0.00984597  |
| MeanKLBefore            | 0.0         |
| MinReturn               | 262         |
| NumTrajs                | 16          |
| Perplexity              | 30.0526     |
| PolicyExecTime          | 0.529       |
| ProcessExecTime         | 0.0631      |
| StdReturn               | 369         |
| Time                    | 1.49e+03    |
| dLoss                   | 0.0182592   |
-----------------------------------------
itr #184 | 
Mem: 684.500000
Obtaining samples...
Obtaining samples for iteration 184...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5002, #subsample_inputs: 5002
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.669      |
| AbsLearnSignalNew       | 0.669      |
| AbsLearningOld          | 0.669      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 11.1384    |
| AveragePolicyStd        | 0.757522   |
| AverageReturn           | 1.07e+03   |
| Entropy                 | 3.4031     |
| EnvExecTime             | 1.97       |
| ExplainedVariance       | 0.818      |
| Iteration               | 184        |
| ItrTime                 | 8.11       |
| LossAfter               | 0.273931   |
| LossBefore              | 0.295939   |
| MaxReturn               | 1.62e+03   |
| MeanKL                  | 0.00697449 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 710        |
| NumTrajs                | 15         |
| Perplexity              | 30.057     |
| PolicyExecTime          | 0.498      |
| ProcessExecTime         | 0.061      |
| StdReturn               | 206        |
| Time                    | 1.5e+03    |
| dLoss                   | 0.0220073  |
----------------------------------------
itr #185 | 
Mem: 684.500000
Obtaining samples...
Obtaining samples for iteration 185...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5089, #subsample_inputs: 5089
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.738      |
| AbsLearnSignalNew       | 0.738      |
| AbsLearningOld          | 0.738      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 9.85599    |
| AveragePolicyStd        | 0.749302   |
| AverageReturn           | 972        |
| Entropy                 | 3.37185    |
| EnvExecTime             | 1.94       |
| ExplainedVariance       | 0.911      |
| Iteration               | 185        |
| ItrTime                 | 8.03       |
| LossAfter               | 0.349802   |
| LossBefore              | 0.365849   |
| MaxReturn               | 1.15e+03   |
| MeanKL                  | 0.00646407 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 839        |
| NumTrajs                | 17         |
| Perplexity              | 29.1323    |
| PolicyExecTime          | 0.496      |
| ProcessExecTime         | 0.058      |
| StdReturn               | 81.8       |
| Time                    | 1.5e+03    |
| dLoss                   | 0.0160466  |
----------------------------------------
itr #186 | 
Mem: 685.269531
Obtaining samples...
Obtaining samples for iteration 186...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5278, #subsample_inputs: 5278
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.328      |
| AbsLearnSignalNew       | 0.328      |
| AbsLearningOld          | 0.328      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 8.78578    |
| AveragePolicyStd        | 0.745488   |
| AverageReturn           | 1.13e+03   |
| Entropy                 | 3.35856    |
| EnvExecTime             | 2.09       |
| ExplainedVariance       | -1.23      |
| Iteration               | 186        |
| ItrTime                 | 8.4        |
| LossAfter               | -0.135856  |
| LossBefore              | -0.11678   |
| MaxReturn               | 1.77e+03   |
| MeanKL                  | 0.00960208 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 877        |
| NumTrajs                | 15         |
| Perplexity              | 28.7478    |
| PolicyExecTime          | 0.526      |
| ProcessExecTime         | 0.0634     |
| StdReturn               | 228        |
| Time                    | 1.51e+03   |
| dLoss                   | 0.0190766  |
----------------------------------------
itr #187 | 
Mem: 685.269531
Obtaining samples...
Obtaining samples for iteration 187...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5013, #subsample_inputs: 5013
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.689     |
| AbsLearnSignalNew       | 0.689     |
| AbsLearningOld          | 0.689     |
| AverageDiscountedReturn | 241       |
| AveragePhiLoss          | 10.5374   |
| AveragePolicyStd        | 0.747963  |
| AverageReturn           | 1.07e+03  |
| Entropy                 | 3.3698    |
| EnvExecTime             | 1.84      |
| ExplainedVariance       | 0.86      |
| Iteration               | 187       |
| ItrTime                 | 7.93      |
| LossAfter               | -0.574402 |
| LossBefore              | -0.548708 |
| MaxReturn               | 1.38e+03  |
| MeanKL                  | 0.0065342 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 837       |
| NumTrajs                | 15        |
| Perplexity              | 29.0727   |
| PolicyExecTime          | 0.465     |
| ProcessExecTime         | 0.0574    |
| StdReturn               | 159       |
| Time                    | 1.52e+03  |
| dLoss                   | 0.0256939 |
---------------------------------------
itr #188 | 
Mem: 685.269531
Obtaining samples...
Obtaining samples for iteration 188...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5161, #subsample_inputs: 5161
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.747      |
| AbsLearnSignalNew       | 0.747      |
| AbsLearningOld          | 0.747      |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 10.3407    |
| AveragePolicyStd        | 0.745398   |
| AverageReturn           | 1.08e+03   |
| Entropy                 | 3.35967    |
| EnvExecTime             | 1.86       |
| ExplainedVariance       | 0.807      |
| Iteration               | 188        |
| ItrTime                 | 8.04       |
| LossAfter               | -0.197403  |
| LossBefore              | -0.169013  |
| MaxReturn               | 1.56e+03   |
| MeanKL                  | 0.00977961 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 747        |
| NumTrajs                | 15         |
| Perplexity              | 28.7798    |
| PolicyExecTime          | 0.48       |
| ProcessExecTime         | 0.0557     |
| StdReturn               | 210        |
| Time                    | 1.53e+03   |
| dLoss                   | 0.0283902  |
----------------------------------------
itr #189 | 
Mem: 685.269531
Obtaining samples...
Obtaining samples for iteration 189...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5176, #subsample_inputs: 5176
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.787      |
| AbsLearnSignalNew       | 0.787      |
| AbsLearningOld          | 0.787      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 9.76909    |
| AveragePolicyStd        | 0.756716   |
| AverageReturn           | 1.05e+03   |
| Entropy                 | 3.40605    |
| EnvExecTime             | 1.95       |
| ExplainedVariance       | 0.942      |
| Iteration               | 189        |
| ItrTime                 | 8.2        |
| LossAfter               | -0.211121  |
| LossBefore              | -0.184956  |
| MaxReturn               | 1.25e+03   |
| MeanKL                  | 0.00988394 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 924        |
| NumTrajs                | 16         |
| Perplexity              | 30.1459    |
| PolicyExecTime          | 0.495      |
| ProcessExecTime         | 0.0583     |
| StdReturn               | 91.6       |
| Time                    | 1.54e+03   |
| dLoss                   | 0.026165   |
----------------------------------------
itr #190 | 
Mem: 685.269531
Obtaining samples...
Obtaining samples for iteration 190...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5296, #subsample_inputs: 5296
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.713      |
| AbsLearnSignalNew       | 0.713      |
| AbsLearningOld          | 0.713      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 10.3436    |
| AveragePolicyStd        | 0.755498   |
| AverageReturn           | 1.07e+03   |
| Entropy                 | 3.40123    |
| EnvExecTime             | 1.9        |
| ExplainedVariance       | 0.899      |
| Iteration               | 190        |
| ItrTime                 | 8.22       |
| LossAfter               | -0.152003  |
| LossBefore              | -0.1277    |
| MaxReturn               | 1.44e+03   |
| MeanKL                  | 0.00945721 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 799        |
| NumTrajs                | 16         |
| Perplexity              | 30.001     |
| PolicyExecTime          | 0.488      |
| ProcessExecTime         | 0.0574     |
| StdReturn               | 159        |
| Time                    | 1.54e+03   |
| dLoss                   | 0.0243025  |
----------------------------------------
itr #191 | 
Mem: 685.269531
Obtaining samples...
Obtaining samples for iteration 191...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5517, #subsample_inputs: 5517
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.773     |
| AbsLearnSignalNew       | 0.773     |
| AbsLearningOld          | 0.773     |
| AverageDiscountedReturn | 239       |
| AveragePhiLoss          | 9.64224   |
| AveragePolicyStd        | 0.761516  |
| AverageReturn           | 1.24e+03  |
| Entropy                 | 3.42573   |
| EnvExecTime             | 2         |
| ExplainedVariance       | 0.909     |
| Iteration               | 191       |
| ItrTime                 | 8.51      |
| LossAfter               | 0.20484   |
| LossBefore              | 0.228372  |
| MaxReturn               | 1.69e+03  |
| MeanKL                  | 0.0096993 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 889       |
| NumTrajs                | 14        |
| Perplexity              | 30.7451   |
| PolicyExecTime          | 0.519     |
| ProcessExecTime         | 0.0607    |
| StdReturn               | 269       |
| Time                    | 1.55e+03  |
| dLoss                   | 0.0235329 |
---------------------------------------
itr #192 | 
Mem: 685.269531
Obtaining samples...
Obtaining samples for iteration 192...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5071, #subsample_inputs: 5071
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.679      |
| AbsLearnSignalNew       | 0.679      |
| AbsLearningOld          | 0.679      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 11.2314    |
| AveragePolicyStd        | 0.760436   |
| AverageReturn           | 1.2e+03    |
| Entropy                 | 3.42141    |
| EnvExecTime             | 1.85       |
| ExplainedVariance       | 0.809      |
| Iteration               | 192        |
| ItrTime                 | 7.98       |
| LossAfter               | 0.634447   |
| LossBefore              | 0.654452   |
| MaxReturn               | 1.66e+03   |
| MeanKL                  | 0.00646882 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.03e+03   |
| NumTrajs                | 13         |
| Perplexity              | 30.6125    |
| PolicyExecTime          | 0.47       |
| ProcessExecTime         | 0.0572     |
| StdReturn               | 198        |
| Time                    | 1.56e+03   |
| dLoss                   | 0.0200045  |
----------------------------------------
itr #193 | 
Mem: 685.269531
Obtaining samples...
Obtaining samples for iteration 193...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5291, #subsample_inputs: 5291
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.553      |
| AbsLearnSignalNew       | 0.553      |
| AbsLearningOld          | 0.553      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 7.57024    |
| AveragePolicyStd        | 0.758017   |
| AverageReturn           | 1.19e+03   |
| Entropy                 | 3.41155    |
| EnvExecTime             | 1.75       |
| ExplainedVariance       | 0.336      |
| Iteration               | 193        |
| ItrTime                 | 8.06       |
| LossAfter               | -0.385703  |
| LossBefore              | -0.363628  |
| MaxReturn               | 2.28e+03   |
| MeanKL                  | 0.00994915 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 838        |
| NumTrajs                | 14         |
| Perplexity              | 30.3121    |
| PolicyExecTime          | 0.452      |
| ProcessExecTime         | 0.0538     |
| StdReturn               | 362        |
| Time                    | 1.57e+03   |
| dLoss                   | 0.0220755  |
----------------------------------------
itr #194 | 
Mem: 685.269531
Obtaining samples...
Obtaining samples for iteration 194...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5319, #subsample_inputs: 5319
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.623      |
| AbsLearnSignalNew       | 0.623      |
| AbsLearningOld          | 0.623      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 10.6962    |
| AveragePolicyStd        | 0.752671   |
| AverageReturn           | 1.16e+03   |
| Entropy                 | 3.39115    |
| EnvExecTime             | 2.13       |
| ExplainedVariance       | 0.72       |
| Iteration               | 194        |
| ItrTime                 | 8.57       |
| LossAfter               | 0.448398   |
| LossBefore              | 0.474665   |
| MaxReturn               | 1.62e+03   |
| MeanKL                  | 0.00980247 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 809        |
| NumTrajs                | 14         |
| Perplexity              | 29.7       |
| PolicyExecTime          | 0.525      |
| ProcessExecTime         | 0.0661     |
| StdReturn               | 255        |
| Time                    | 1.58e+03   |
| dLoss                   | 0.0262673  |
----------------------------------------
itr #195 | 
Mem: 685.269531
Obtaining samples...
Obtaining samples for iteration 195...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5095, #subsample_inputs: 5095
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.745      |
| AbsLearnSignalNew       | 0.745      |
| AbsLearningOld          | 0.745      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 10.4565    |
| AveragePolicyStd        | 0.747504   |
| AverageReturn           | 1.07e+03   |
| Entropy                 | 3.37004    |
| EnvExecTime             | 1.82       |
| ExplainedVariance       | 0.873      |
| Iteration               | 195        |
| ItrTime                 | 7.91       |
| LossAfter               | 0.481009   |
| LossBefore              | 0.501868   |
| MaxReturn               | 1.59e+03   |
| MeanKL                  | 0.00659618 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 855        |
| NumTrajs                | 15         |
| Perplexity              | 29.0796    |
| PolicyExecTime          | 0.466      |
| ProcessExecTime         | 0.0545     |
| StdReturn               | 178        |
| Time                    | 1.59e+03   |
| dLoss                   | 0.0208592  |
----------------------------------------
itr #196 | 
Mem: 685.269531
Obtaining samples...
Obtaining samples for iteration 196...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5055, #subsample_inputs: 5055
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.703      |
| AbsLearnSignalNew       | 0.703      |
| AbsLearningOld          | 0.703      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 10.6777    |
| AveragePolicyStd        | 0.743972   |
| AverageReturn           | 1.2e+03    |
| Entropy                 | 3.35742    |
| EnvExecTime             | 1.77       |
| ExplainedVariance       | 0.839      |
| Iteration               | 196        |
| ItrTime                 | 7.87       |
| LossAfter               | -0.0227919 |
| LossBefore              | -0.0068037 |
| MaxReturn               | 1.74e+03   |
| MeanKL                  | 0.00641797 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 753        |
| NumTrajs                | 13         |
| Perplexity              | 28.7149    |
| PolicyExecTime          | 0.449      |
| ProcessExecTime         | 0.0556     |
| StdReturn               | 280        |
| Time                    | 1.59e+03   |
| dLoss                   | 0.0159882  |
----------------------------------------
itr #197 | 
Mem: 686.050781
Obtaining samples...
Obtaining samples for iteration 197...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5643, #subsample_inputs: 5643
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.754      |
| AbsLearnSignalNew       | 0.754      |
| AbsLearningOld          | 0.754      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 9.87659    |
| AveragePolicyStd        | 0.747984   |
| AverageReturn           | 1.27e+03   |
| Entropy                 | 3.37419    |
| EnvExecTime             | 2.22       |
| ExplainedVariance       | 0.842      |
| Iteration               | 197        |
| ItrTime                 | 8.84       |
| LossAfter               | 0.0065322  |
| LossBefore              | 0.0264366  |
| MaxReturn               | 2.72e+03   |
| MeanKL                  | 0.00968949 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.01e+03   |
| NumTrajs                | 14         |
| Perplexity              | 29.2006    |
| PolicyExecTime          | 0.557      |
| ProcessExecTime         | 0.0671     |
| StdReturn               | 449        |
| Time                    | 1.6e+03    |
| dLoss                   | 0.0199044  |
----------------------------------------
itr #198 | 
Mem: 688.105469
Obtaining samples...
Obtaining samples for iteration 198...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5469, #subsample_inputs: 5469
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.674      |
| AbsLearnSignalNew       | 0.674      |
| AbsLearningOld          | 0.674      |
| AverageDiscountedReturn | 234        |
| AveragePhiLoss          | 10.2546    |
| AveragePolicyStd        | 0.744299   |
| AverageReturn           | 1.34e+03   |
| Entropy                 | 3.36033    |
| EnvExecTime             | 2.04       |
| ExplainedVariance       | 0.636      |
| Iteration               | 198        |
| ItrTime                 | 8.57       |
| LossAfter               | 0.00618965 |
| LossBefore              | 0.0309047  |
| MaxReturn               | 2.25e+03   |
| MeanKL                  | 0.0099426  |
| MeanKLBefore            | 0.0        |
| MinReturn               | 792        |
| NumTrajs                | 12         |
| Perplexity              | 28.7986    |
| PolicyExecTime          | 0.518      |
| ProcessExecTime         | 0.0608     |
| StdReturn               | 380        |
| Time                    | 1.61e+03   |
| dLoss                   | 0.024715   |
----------------------------------------
itr #199 | 
Mem: 688.363281
Obtaining samples...
Obtaining samples for iteration 199...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5169, #subsample_inputs: 5169
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.624      |
| AbsLearnSignalNew       | 0.624      |
| AbsLearningOld          | 0.624      |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 9.04503    |
| AveragePolicyStd        | 0.750712   |
| AverageReturn           | 1.1e+03    |
| Entropy                 | 3.38784    |
| EnvExecTime             | 1.99       |
| ExplainedVariance       | 0.745      |
| Iteration               | 199        |
| ItrTime                 | 8.22       |
| LossAfter               | 0.363775   |
| LossBefore              | 0.38835    |
| MaxReturn               | 1.92e+03   |
| MeanKL                  | 0.00995249 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 522        |
| NumTrajs                | 15         |
| Perplexity              | 29.6021    |
| PolicyExecTime          | 0.499      |
| ProcessExecTime         | 0.0585     |
| StdReturn               | 307        |
| Time                    | 1.62e+03   |
| dLoss                   | 0.0245754  |
----------------------------------------
itr #200 | 
Mem: 688.363281
Obtaining samples...
Obtaining samples for iteration 200...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5270, #subsample_inputs: 5270
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.595      |
| AbsLearnSignalNew       | 0.595      |
| AbsLearningOld          | 0.595      |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 8.24191    |
| AveragePolicyStd        | 0.757334   |
| AverageReturn           | 1.28e+03   |
| Entropy                 | 3.41368    |
| EnvExecTime             | 1.81       |
| ExplainedVariance       | 0.851      |
| Iteration               | 200        |
| ItrTime                 | 8.04       |
| LossAfter               | -0.0902541 |
| LossBefore              | -0.0688883 |
| MaxReturn               | 2.06e+03   |
| MeanKL                  | 0.00658495 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 880        |
| NumTrajs                | 13         |
| Perplexity              | 30.3769    |
| PolicyExecTime          | 0.467      |
| ProcessExecTime         | 0.0552     |
| StdReturn               | 349        |
| Time                    | 1.63e+03   |
| dLoss                   | 0.0213658  |
----------------------------------------
itr #201 | 
Mem: 688.363281
Obtaining samples...
Obtaining samples for iteration 201...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5308, #subsample_inputs: 5308
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.581      |
| AbsLearnSignalNew       | 0.581      |
| AbsLearningOld          | 0.581      |
| AverageDiscountedReturn | 234        |
| AveragePhiLoss          | 13.5855    |
| AveragePolicyStd        | 0.756843   |
| AverageReturn           | 1.11e+03   |
| Entropy                 | 3.41294    |
| EnvExecTime             | 1.91       |
| ExplainedVariance       | 0.655      |
| Iteration               | 201        |
| ItrTime                 | 8.24       |
| LossAfter               | 0.485936   |
| LossBefore              | 0.5133     |
| MaxReturn               | 1.68e+03   |
| MeanKL                  | 0.00666165 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 423        |
| NumTrajs                | 15         |
| Perplexity              | 30.3544    |
| PolicyExecTime          | 0.485      |
| ProcessExecTime         | 0.0589     |
| StdReturn               | 320        |
| Time                    | 1.64e+03   |
| dLoss                   | 0.0273638  |
----------------------------------------
itr #202 | 
Mem: 688.363281
Obtaining samples...
Obtaining samples for iteration 202...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5323, #subsample_inputs: 5323
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.718      |
| AbsLearnSignalNew       | 0.718      |
| AbsLearningOld          | 0.718      |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 9.99719    |
| AveragePolicyStd        | 0.751055   |
| AverageReturn           | 1.28e+03   |
| Entropy                 | 3.38896    |
| EnvExecTime             | 1.97       |
| ExplainedVariance       | 0.748      |
| Iteration               | 202        |
| ItrTime                 | 8.35       |
| LossAfter               | -0.200693  |
| LossBefore              | -0.179341  |
| MaxReturn               | 2.31e+03   |
| MeanKL                  | 0.00644436 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 868        |
| NumTrajs                | 13         |
| Perplexity              | 29.6351    |
| PolicyExecTime          | 0.506      |
| ProcessExecTime         | 0.0606     |
| StdReturn               | 473        |
| Time                    | 1.64e+03   |
| dLoss                   | 0.0213512  |
----------------------------------------
itr #203 | 
Mem: 688.621094
Obtaining samples...
Obtaining samples for iteration 203...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5322, #subsample_inputs: 5322
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.756      |
| AbsLearnSignalNew       | 0.756      |
| AbsLearningOld          | 0.756      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 9.85363    |
| AveragePolicyStd        | 0.753082   |
| AverageReturn           | 1.21e+03   |
| Entropy                 | 3.39554    |
| EnvExecTime             | 2.02       |
| ExplainedVariance       | 0.91       |
| Iteration               | 203        |
| ItrTime                 | 8.44       |
| LossAfter               | 0.172939   |
| LossBefore              | 0.19771    |
| MaxReturn               | 2.2e+03    |
| MeanKL                  | 0.00997988 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 952        |
| NumTrajs                | 14         |
| Perplexity              | 29.8308    |
| PolicyExecTime          | 0.506      |
| ProcessExecTime         | 0.0627     |
| StdReturn               | 317        |
| Time                    | 1.65e+03   |
| dLoss                   | 0.0247709  |
----------------------------------------
itr #204 | 
Mem: 688.621094
Obtaining samples...
Obtaining samples for iteration 204...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5711, #subsample_inputs: 5711
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.745      |
| AbsLearnSignalNew       | 0.745      |
| AbsLearningOld          | 0.745      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 9.87795    |
| AveragePolicyStd        | 0.752921   |
| AverageReturn           | 1.25e+03   |
| Entropy                 | 3.39428    |
| EnvExecTime             | 2.5        |
| ExplainedVariance       | 0.849      |
| Iteration               | 204        |
| ItrTime                 | 9.25       |
| LossAfter               | 0.752995   |
| LossBefore              | 0.778819   |
| MaxReturn               | 2.6e+03    |
| MeanKL                  | 0.00996812 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 855        |
| NumTrajs                | 14         |
| Perplexity              | 29.7932    |
| PolicyExecTime          | 0.626      |
| ProcessExecTime         | 0.0729     |
| StdReturn               | 430        |
| Time                    | 1.66e+03   |
| dLoss                   | 0.0258248  |
----------------------------------------
itr #205 | 
Mem: 688.871094
Obtaining samples...
Obtaining samples for iteration 205...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5918, #subsample_inputs: 5918
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.699      |
| AbsLearnSignalNew       | 0.699      |
| AbsLearningOld          | 0.698      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 10.5055    |
| AveragePolicyStd        | 0.753341   |
| AverageReturn           | 1.19e+03   |
| Entropy                 | 3.39477    |
| EnvExecTime             | 2.24       |
| ExplainedVariance       | 0.76       |
| Iteration               | 205        |
| ItrTime                 | 9.12       |
| LossAfter               | 0.0371704  |
| LossBefore              | 0.058772   |
| MaxReturn               | 2.37e+03   |
| MeanKL                  | 0.00706408 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 772        |
| NumTrajs                | 15         |
| Perplexity              | 29.8077    |
| PolicyExecTime          | 0.566      |
| ProcessExecTime         | 0.067      |
| StdReturn               | 408        |
| Time                    | 1.67e+03   |
| dLoss                   | 0.0216016  |
----------------------------------------
itr #206 | 
Mem: 690.148438
Obtaining samples...
Obtaining samples for iteration 206...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5046, #subsample_inputs: 5046
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.707      |
| AbsLearnSignalNew       | 0.707      |
| AbsLearningOld          | 0.707      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 9.97632    |
| AveragePolicyStd        | 0.752654   |
| AverageReturn           | 1.09e+03   |
| Entropy                 | 3.39311    |
| EnvExecTime             | 1.74       |
| ExplainedVariance       | 0.914      |
| Iteration               | 206        |
| ItrTime                 | 7.82       |
| LossAfter               | -0.494061  |
| LossBefore              | -0.462006  |
| MaxReturn               | 1.6e+03    |
| MeanKL                  | 0.00954929 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 838        |
| NumTrajs                | 15         |
| Perplexity              | 29.7585    |
| PolicyExecTime          | 0.447      |
| ProcessExecTime         | 0.054      |
| StdReturn               | 187        |
| Time                    | 1.68e+03   |
| dLoss                   | 0.0320545  |
----------------------------------------
itr #207 | 
Mem: 690.148438
Obtaining samples...
Obtaining samples for iteration 207...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5321, #subsample_inputs: 5321
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.738      |
| AbsLearnSignalNew       | 0.738      |
| AbsLearningOld          | 0.738      |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 9.23923    |
| AveragePolicyStd        | 0.757876   |
| AverageReturn           | 1.2e+03    |
| Entropy                 | 3.41529    |
| EnvExecTime             | 1.97       |
| ExplainedVariance       | 0.901      |
| Iteration               | 207        |
| ItrTime                 | 8.44       |
| LossAfter               | -0.167164  |
| LossBefore              | -0.148929  |
| MaxReturn               | 1.72e+03   |
| MeanKL                  | 0.00644206 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 875        |
| NumTrajs                | 14         |
| Perplexity              | 30.4257    |
| PolicyExecTime          | 0.506      |
| ProcessExecTime         | 0.0593     |
| StdReturn               | 270        |
| Time                    | 1.69e+03   |
| dLoss                   | 0.0182347  |
----------------------------------------
itr #208 | 
Mem: 690.148438
Obtaining samples...
Obtaining samples for iteration 208...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5119, #subsample_inputs: 5119
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.746     |
| AbsLearnSignalNew       | 0.746     |
| AbsLearningOld          | 0.747     |
| AverageDiscountedReturn | 240       |
| AveragePhiLoss          | 9.96452   |
| AveragePolicyStd        | 0.761254  |
| AverageReturn           | 1.16e+03  |
| Entropy                 | 3.4269    |
| EnvExecTime             | 1.92      |
| ExplainedVariance       | 0.903     |
| Iteration               | 208       |
| ItrTime                 | 8.1       |
| LossAfter               | -0.201761 |
| LossBefore              | -0.183324 |
| MaxReturn               | 1.87e+03  |
| MeanKL                  | 0.0065305 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 817       |
| NumTrajs                | 14        |
| Perplexity              | 30.781    |
| PolicyExecTime          | 0.483     |
| ProcessExecTime         | 0.0586    |
| StdReturn               | 303       |
| Time                    | 1.7e+03   |
| dLoss                   | 0.0184365 |
---------------------------------------
itr #209 | 
Mem: 690.148438
Obtaining samples...
Obtaining samples for iteration 209...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5047, #subsample_inputs: 5047
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.687      |
| AbsLearnSignalNew       | 0.687      |
| AbsLearningOld          | 0.687      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 9.16365    |
| AveragePolicyStd        | 0.762068   |
| AverageReturn           | 1.3e+03    |
| Entropy                 | 3.42851    |
| EnvExecTime             | 1.86       |
| ExplainedVariance       | 0.75       |
| Iteration               | 209        |
| ItrTime                 | 7.97       |
| LossAfter               | -0.484543  |
| LossBefore              | -0.465478  |
| MaxReturn               | 2.39e+03   |
| MeanKL                  | 0.00654078 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 934        |
| NumTrajs                | 12         |
| Perplexity              | 30.8306    |
| PolicyExecTime          | 0.473      |
| ProcessExecTime         | 0.0569     |
| StdReturn               | 359        |
| Time                    | 1.7e+03    |
| dLoss                   | 0.0190649  |
----------------------------------------
itr #210 | 
Mem: 690.148438
Obtaining samples...
Obtaining samples for iteration 210...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5041, #subsample_inputs: 5041
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.685      |
| AbsLearnSignalNew       | 0.685      |
| AbsLearningOld          | 0.685      |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 10.8291    |
| AveragePolicyStd        | 0.758081   |
| AverageReturn           | 1.05e+03   |
| Entropy                 | 3.4126     |
| EnvExecTime             | 2.04       |
| ExplainedVariance       | 0.85       |
| Iteration               | 210        |
| ItrTime                 | 8.14       |
| LossAfter               | -0.474919  |
| LossBefore              | -0.4481    |
| MaxReturn               | 1.38e+03   |
| MeanKL                  | 0.00640937 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 858        |
| NumTrajs                | 15         |
| Perplexity              | 30.344     |
| PolicyExecTime          | 0.511      |
| ProcessExecTime         | 0.061      |
| StdReturn               | 135        |
| Time                    | 1.71e+03   |
| dLoss                   | 0.0268188  |
----------------------------------------
itr #211 | 
Mem: 690.148438
Obtaining samples...
Obtaining samples for iteration 211...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5308, #subsample_inputs: 5308
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.781      |
| AbsLearnSignalNew       | 0.781      |
| AbsLearningOld          | 0.781      |
| AverageDiscountedReturn | 236        |
| AveragePhiLoss          | 9.82165    |
| AveragePolicyStd        | 0.756719   |
| AverageReturn           | 1.36e+03   |
| Entropy                 | 3.40686    |
| EnvExecTime             | 2.19       |
| ExplainedVariance       | 0.678      |
| Iteration               | 211        |
| ItrTime                 | 8.62       |
| LossAfter               | 0.168019   |
| LossBefore              | 0.185323   |
| MaxReturn               | 2.2e+03    |
| MeanKL                  | 0.00646927 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.04e+03   |
| NumTrajs                | 12         |
| Perplexity              | 30.1703    |
| PolicyExecTime          | 0.553      |
| ProcessExecTime         | 0.0663     |
| StdReturn               | 357        |
| Time                    | 1.72e+03   |
| dLoss                   | 0.0173034  |
----------------------------------------
itr #212 | 
Mem: 690.148438
Obtaining samples...
Obtaining samples for iteration 212...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5171, #subsample_inputs: 5171
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.706     |
| AbsLearnSignalNew       | 0.706     |
| AbsLearningOld          | 0.706     |
| AverageDiscountedReturn | 237       |
| AveragePhiLoss          | 9.99464   |
| AveragePolicyStd        | 0.754738  |
| AverageReturn           | 1.25e+03  |
| Entropy                 | 3.39897   |
| EnvExecTime             | 1.99      |
| ExplainedVariance       | 0.903     |
| Iteration               | 212       |
| ItrTime                 | 8.25      |
| LossAfter               | 0.255897  |
| LossBefore              | 0.28229   |
| MaxReturn               | 1.6e+03   |
| MeanKL                  | 0.0097607 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.02e+03  |
| NumTrajs                | 13        |
| Perplexity              | 29.9334   |
| PolicyExecTime          | 0.511     |
| ProcessExecTime         | 0.0588    |
| StdReturn               | 207       |
| Time                    | 1.73e+03  |
| dLoss                   | 0.0263939 |
---------------------------------------
itr #213 | 
Mem: 690.148438
Obtaining samples...
Obtaining samples for iteration 213...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5363, #subsample_inputs: 5363
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.747      |
| AbsLearnSignalNew       | 0.747      |
| AbsLearningOld          | 0.747      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 10.1825    |
| AveragePolicyStd        | 0.753209   |
| AverageReturn           | 1.29e+03   |
| Entropy                 | 3.39219    |
| EnvExecTime             | 1.91       |
| ExplainedVariance       | 0.867      |
| Iteration               | 213        |
| ItrTime                 | 8.32       |
| LossAfter               | -0.32061   |
| LossBefore              | -0.293815  |
| MaxReturn               | 1.6e+03    |
| MeanKL                  | 0.00975986 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.02e+03   |
| NumTrajs                | 13         |
| Perplexity              | 29.731     |
| PolicyExecTime          | 0.491      |
| ProcessExecTime         | 0.0579     |
| StdReturn               | 209        |
| Time                    | 1.74e+03   |
| dLoss                   | 0.0267953  |
----------------------------------------
itr #214 | 
Mem: 690.148438
Obtaining samples...
Obtaining samples for iteration 214...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5156, #subsample_inputs: 5156
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.615      |
| AbsLearnSignalNew       | 0.615      |
| AbsLearningOld          | 0.615      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 9.20432    |
| AveragePolicyStd        | 0.761142   |
| AverageReturn           | 1.08e+03   |
| Entropy                 | 3.42343    |
| EnvExecTime             | 1.9        |
| ExplainedVariance       | 0.783      |
| Iteration               | 214        |
| ItrTime                 | 8.12       |
| LossAfter               | 0.328754   |
| LossBefore              | 0.357378   |
| MaxReturn               | 1.58e+03   |
| MeanKL                  | 0.00978468 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 679        |
| NumTrajs                | 15         |
| Perplexity              | 30.6744    |
| PolicyExecTime          | 0.48       |
| ProcessExecTime         | 0.0582     |
| StdReturn               | 201        |
| Time                    | 1.75e+03   |
| dLoss                   | 0.0286237  |
----------------------------------------
itr #215 | 
Mem: 690.148438
Obtaining samples...
Obtaining samples for iteration 215...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5104, #subsample_inputs: 5104
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.741      |
| AbsLearnSignalNew       | 0.741      |
| AbsLearningOld          | 0.741      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 9.63695    |
| AveragePolicyStd        | 0.767292   |
| AverageReturn           | 978        |
| Entropy                 | 3.44711    |
| EnvExecTime             | 2.01       |
| ExplainedVariance       | 0.928      |
| Iteration               | 215        |
| ItrTime                 | 8.14       |
| LossAfter               | -0.214663  |
| LossBefore              | -0.189046  |
| MaxReturn               | 1.18e+03   |
| MeanKL                  | 0.00972886 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 791        |
| NumTrajs                | 17         |
| Perplexity              | 31.4096    |
| PolicyExecTime          | 0.506      |
| ProcessExecTime         | 0.0605     |
| StdReturn               | 102        |
| Time                    | 1.75e+03   |
| dLoss                   | 0.0256174  |
----------------------------------------
itr #216 | 
Mem: 690.148438
Obtaining samples...
Obtaining samples for iteration 216...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5305, #subsample_inputs: 5305
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.256      |
| AbsLearnSignalNew       | 0.256      |
| AbsLearningOld          | 0.256      |
| AverageDiscountedReturn | 236        |
| AveragePhiLoss          | 6.39002    |
| AveragePolicyStd        | 0.767392   |
| AverageReturn           | 1.18e+03   |
| Entropy                 | 3.44973    |
| EnvExecTime             | 2.02       |
| ExplainedVariance       | -39        |
| Iteration               | 216        |
| ItrTime                 | 8.47       |
| LossAfter               | 0.258075   |
| LossBefore              | 0.283087   |
| MaxReturn               | 2.41e+03   |
| MeanKL                  | 0.00971238 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 776        |
| NumTrajs                | 14         |
| Perplexity              | 31.4919    |
| PolicyExecTime          | 0.507      |
| ProcessExecTime         | 0.0623     |
| StdReturn               | 392        |
| Time                    | 1.76e+03   |
| dLoss                   | 0.0250126  |
----------------------------------------
itr #217 | 
Mem: 691.871094
Obtaining samples...
Obtaining samples for iteration 217...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5038, #subsample_inputs: 5038
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.714      |
| AbsLearnSignalNew       | 0.714      |
| AbsLearningOld          | 0.714      |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 9.34381    |
| AveragePolicyStd        | 0.776656   |
| AverageReturn           | 1.21e+03   |
| Entropy                 | 3.4866     |
| EnvExecTime             | 1.78       |
| ExplainedVariance       | 0.855      |
| Iteration               | 217        |
| ItrTime                 | 7.88       |
| LossAfter               | 0.190703   |
| LossBefore              | 0.214319   |
| MaxReturn               | 2.17e+03   |
| MeanKL                  | 0.00640839 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 927        |
| NumTrajs                | 13         |
| Perplexity              | 32.6748    |
| PolicyExecTime          | 0.453      |
| ProcessExecTime         | 0.0549     |
| StdReturn               | 324        |
| Time                    | 1.77e+03   |
| dLoss                   | 0.0236162  |
----------------------------------------
itr #218 | 
Mem: 693.128906
Obtaining samples...
Obtaining samples for iteration 218...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5157, #subsample_inputs: 5157
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.699      |
| AbsLearnSignalNew       | 0.699      |
| AbsLearningOld          | 0.699      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 8.95143    |
| AveragePolicyStd        | 0.771287   |
| AverageReturn           | 1.1e+03    |
| Entropy                 | 3.4653     |
| EnvExecTime             | 2.01       |
| ExplainedVariance       | 0.899      |
| Iteration               | 218        |
| ItrTime                 | 8.22       |
| LossAfter               | -0.616296  |
| LossBefore              | -0.592581  |
| MaxReturn               | 1.89e+03   |
| MeanKL                  | 0.00987088 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 776        |
| NumTrajs                | 15         |
| Perplexity              | 31.9861    |
| PolicyExecTime          | 0.517      |
| ProcessExecTime         | 0.0591     |
| StdReturn               | 266        |
| Time                    | 1.78e+03   |
| dLoss                   | 0.0237157  |
----------------------------------------
itr #219 | 
Mem: 693.128906
Obtaining samples...
Obtaining samples for iteration 219...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5084, #subsample_inputs: 5084
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.755      |
| AbsLearnSignalNew       | 0.755      |
| AbsLearningOld          | 0.754      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 8.64773    |
| AveragePolicyStd        | 0.775804   |
| AverageReturn           | 1.08e+03   |
| Entropy                 | 3.48219    |
| EnvExecTime             | 1.79       |
| ExplainedVariance       | 0.907      |
| Iteration               | 219        |
| ItrTime                 | 7.96       |
| LossAfter               | -0.180578  |
| LossBefore              | -0.152168  |
| MaxReturn               | 1.8e+03    |
| MeanKL                  | 0.00994299 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 773        |
| NumTrajs                | 15         |
| Perplexity              | 32.5308    |
| PolicyExecTime          | 0.461      |
| ProcessExecTime         | 0.0553     |
| StdReturn               | 252        |
| Time                    | 1.79e+03   |
| dLoss                   | 0.0284096  |
----------------------------------------
itr #220 | 
Mem: 693.128906
Obtaining samples...
Obtaining samples for iteration 220...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5246, #subsample_inputs: 5246
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.714      |
| AbsLearnSignalNew       | 0.714      |
| AbsLearningOld          | 0.714      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 8.84986    |
| AveragePolicyStd        | 0.773751   |
| AverageReturn           | 1.16e+03   |
| Entropy                 | 3.47242    |
| EnvExecTime             | 1.89       |
| ExplainedVariance       | 0.804      |
| Iteration               | 220        |
| ItrTime                 | 8.23       |
| LossAfter               | 0.031358   |
| LossBefore              | 0.0526377  |
| MaxReturn               | 1.79e+03   |
| MeanKL                  | 0.00642486 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 955        |
| NumTrajs                | 14         |
| Perplexity              | 32.2147    |
| PolicyExecTime          | 0.486      |
| ProcessExecTime         | 0.0558     |
| StdReturn               | 239        |
| Time                    | 1.8e+03    |
| dLoss                   | 0.0212797  |
----------------------------------------
itr #221 | 
Mem: 693.128906
Obtaining samples...
Obtaining samples for iteration 221...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5135, #subsample_inputs: 5135
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.717      |
| AbsLearnSignalNew       | 0.717      |
| AbsLearningOld          | 0.717      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 9.18002    |
| AveragePolicyStd        | 0.77384    |
| AverageReturn           | 1.15e+03   |
| Entropy                 | 3.47419    |
| EnvExecTime             | 2.04       |
| ExplainedVariance       | 0.874      |
| Iteration               | 221        |
| ItrTime                 | 8.19       |
| LossAfter               | -0.659114  |
| LossBefore              | -0.631351  |
| MaxReturn               | 2.07e+03   |
| MeanKL                  | 0.00981737 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 715        |
| NumTrajs                | 14         |
| Perplexity              | 32.2717    |
| PolicyExecTime          | 0.51       |
| ProcessExecTime         | 0.0601     |
| StdReturn               | 337        |
| Time                    | 1.8e+03    |
| dLoss                   | 0.027763   |
----------------------------------------
itr #222 | 
Mem: 693.152344
Obtaining samples...
Obtaining samples for iteration 222...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5202, #subsample_inputs: 5202
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.607      |
| AbsLearnSignalNew       | 0.607      |
| AbsLearningOld          | 0.607      |
| AverageDiscountedReturn | 234        |
| AveragePhiLoss          | 10.5163    |
| AveragePolicyStd        | 0.776061   |
| AverageReturn           | 979        |
| Entropy                 | 3.48125    |
| EnvExecTime             | 2.12       |
| ExplainedVariance       | 0.806      |
| Iteration               | 222        |
| ItrTime                 | 8.4        |
| LossAfter               | 0.307314   |
| LossBefore              | 0.330787   |
| MaxReturn               | 1.26e+03   |
| MeanKL                  | 0.00648175 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 230        |
| NumTrajs                | 17         |
| Perplexity              | 32.5002    |
| PolicyExecTime          | 0.527      |
| ProcessExecTime         | 0.063      |
| StdReturn               | 216        |
| Time                    | 1.81e+03   |
| dLoss                   | 0.0234731  |
----------------------------------------
itr #223 | 
Mem: 693.152344
Obtaining samples...
Obtaining samples for iteration 223...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5445, #subsample_inputs: 5445
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.654     |
| AbsLearnSignalNew       | 0.654     |
| AbsLearningOld          | 0.654     |
| AverageDiscountedReturn | 241       |
| AveragePhiLoss          | 9.44514   |
| AveragePolicyStd        | 0.773984  |
| AverageReturn           | 1.03e+03  |
| Entropy                 | 3.47546   |
| EnvExecTime             | 2.08      |
| ExplainedVariance       | 0.847     |
| Iteration               | 223       |
| ItrTime                 | 8.63      |
| LossAfter               | 0.0364996 |
| LossBefore              | 0.0558679 |
| MaxReturn               | 1.9e+03   |
| MeanKL                  | 0.0066817 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 688       |
| NumTrajs                | 17        |
| Perplexity              | 32.3128   |
| PolicyExecTime          | 0.52      |
| ProcessExecTime         | 0.0621    |
| StdReturn               | 251       |
| Time                    | 1.82e+03  |
| dLoss                   | 0.0193683 |
---------------------------------------
itr #224 | 
Mem: 693.656250
Obtaining samples...
Obtaining samples for iteration 224...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5004, #subsample_inputs: 5004
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.734      |
| AbsLearnSignalNew       | 0.734      |
| AbsLearningOld          | 0.734      |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 9.54138    |
| AveragePolicyStd        | 0.774021   |
| AverageReturn           | 999        |
| Entropy                 | 3.47599    |
| EnvExecTime             | 1.86       |
| ExplainedVariance       | 0.885      |
| Iteration               | 224        |
| ItrTime                 | 7.87       |
| LossAfter               | -0.171951  |
| LossBefore              | -0.142394  |
| MaxReturn               | 1.57e+03   |
| MeanKL                  | 0.00999484 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 724        |
| NumTrajs                | 16         |
| Perplexity              | 32.33      |
| PolicyExecTime          | 0.471      |
| ProcessExecTime         | 0.0558     |
| StdReturn               | 196        |
| Time                    | 1.83e+03   |
| dLoss                   | 0.0295574  |
----------------------------------------
itr #225 | 
Mem: 693.656250
Obtaining samples...
Obtaining samples for iteration 225...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5224, #subsample_inputs: 5224
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
-----------------------------------------
| AbsLearnSignal          | 0.601       |
| AbsLearnSignalNew       | 0.601       |
| AbsLearningOld          | 0.601       |
| AverageDiscountedReturn | 233         |
| AveragePhiLoss          | 9.91368     |
| AveragePolicyStd        | 0.771621    |
| AverageReturn           | 881         |
| Entropy                 | 3.464       |
| EnvExecTime             | 1.78        |
| ExplainedVariance       | 0.713       |
| Iteration               | 225         |
| ItrTime                 | 8.06        |
| LossAfter               | -0.0203186  |
| LossBefore              | 0.000540736 |
| MaxReturn               | 1.14e+03    |
| MeanKL                  | 0.00659751  |
| MeanKLBefore            | 0.0         |
| MinReturn               | 174         |
| NumTrajs                | 19          |
| Perplexity              | 31.9446     |
| PolicyExecTime          | 0.449       |
| ProcessExecTime         | 0.0537      |
| StdReturn               | 205         |
| Time                    | 1.84e+03    |
| dLoss                   | 0.0208593   |
-----------------------------------------
itr #226 | 
Mem: 693.656250
Obtaining samples...
Obtaining samples for iteration 226...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5441, #subsample_inputs: 5441
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.3       |
| AbsLearnSignalNew       | 0.3       |
| AbsLearningOld          | 0.3       |
| AverageDiscountedReturn | 235       |
| AveragePhiLoss          | 10.3747   |
| AveragePolicyStd        | 0.768692  |
| AverageReturn           | 1.09e+03  |
| Entropy                 | 3.45191   |
| EnvExecTime             | 1.99      |
| ExplainedVariance       | -166      |
| Iteration               | 226       |
| ItrTime                 | 8.45      |
| LossAfter               | 0.05906   |
| LossBefore              | 0.0775353 |
| MaxReturn               | 2.5e+03   |
| MeanKL                  | 0.006498  |
| MeanKLBefore            | 0.0       |
| MinReturn               | 702       |
| NumTrajs                | 15        |
| Perplexity              | 31.5606   |
| PolicyExecTime          | 0.511     |
| ProcessExecTime         | 0.0587    |
| StdReturn               | 428       |
| Time                    | 1.84e+03  |
| dLoss                   | 0.0184753 |
---------------------------------------
itr #227 | 
Mem: 693.660156
Obtaining samples...
Obtaining samples for iteration 227...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5124, #subsample_inputs: 5124
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.751      |
| AbsLearnSignalNew       | 0.751      |
| AbsLearningOld          | 0.751      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 10.0843    |
| AveragePolicyStd        | 0.763457   |
| AverageReturn           | 1.03e+03   |
| Entropy                 | 3.43136    |
| EnvExecTime             | 1.88       |
| ExplainedVariance       | 0.858      |
| Iteration               | 227        |
| ItrTime                 | 8.16       |
| LossAfter               | -0.0680383 |
| LossBefore              | -0.043052  |
| MaxReturn               | 1.48e+03   |
| MeanKL                  | 0.00996871 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 763        |
| NumTrajs                | 16         |
| Perplexity              | 30.9185    |
| PolicyExecTime          | 0.48       |
| ProcessExecTime         | 0.0556     |
| StdReturn               | 199        |
| Time                    | 1.85e+03   |
| dLoss                   | 0.0249863  |
----------------------------------------
itr #228 | 
Mem: 693.660156
Obtaining samples...
Obtaining samples for iteration 228...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5144, #subsample_inputs: 5144
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.76       |
| AbsLearnSignalNew       | 0.76       |
| AbsLearningOld          | 0.76       |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 9.01807    |
| AveragePolicyStd        | 0.766616   |
| AverageReturn           | 929        |
| Entropy                 | 3.44487    |
| EnvExecTime             | 1.81       |
| ExplainedVariance       | 0.925      |
| Iteration               | 228        |
| ItrTime                 | 8          |
| LossAfter               | -0.0604423 |
| LossBefore              | -0.0396828 |
| MaxReturn               | 1.25e+03   |
| MeanKL                  | 0.00645331 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 724        |
| NumTrajs                | 18         |
| Perplexity              | 31.3392    |
| PolicyExecTime          | 0.454      |
| ProcessExecTime         | 0.0545     |
| StdReturn               | 136        |
| Time                    | 1.86e+03   |
| dLoss                   | 0.0207594  |
----------------------------------------
itr #229 | 
Mem: 693.660156
Obtaining samples...
Obtaining samples for iteration 229...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5010, #subsample_inputs: 5010
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.684      |
| AbsLearnSignalNew       | 0.684      |
| AbsLearningOld          | 0.684      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 9.6437     |
| AveragePolicyStd        | 0.764706   |
| AverageReturn           | 947        |
| Entropy                 | 3.43785    |
| EnvExecTime             | 1.74       |
| ExplainedVariance       | 0.881      |
| Iteration               | 229        |
| ItrTime                 | 7.84       |
| LossAfter               | 0.180736   |
| LossBefore              | 0.206375   |
| MaxReturn               | 1.18e+03   |
| MeanKL                  | 0.00999283 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 731        |
| NumTrajs                | 17         |
| Perplexity              | 31.1199    |
| PolicyExecTime          | 0.443      |
| ProcessExecTime         | 0.0517     |
| StdReturn               | 141        |
| Time                    | 1.87e+03   |
| dLoss                   | 0.025639   |
----------------------------------------
itr #230 | 
Mem: 693.660156
Obtaining samples...
Obtaining samples for iteration 230...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5182, #subsample_inputs: 5182
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.665      |
| AbsLearnSignalNew       | 0.665      |
| AbsLearningOld          | 0.665      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 9.77175    |
| AveragePolicyStd        | 0.761167   |
| AverageReturn           | 935        |
| Entropy                 | 3.42681    |
| EnvExecTime             | 1.77       |
| ExplainedVariance       | 0.861      |
| Iteration               | 230        |
| ItrTime                 | 7.93       |
| LossAfter               | -0.489194  |
| LossBefore              | -0.468352  |
| MaxReturn               | 1.28e+03   |
| MeanKL                  | 0.00645943 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 735        |
| NumTrajs                | 18         |
| Perplexity              | 30.7784    |
| PolicyExecTime          | 0.452      |
| ProcessExecTime         | 0.0528     |
| StdReturn               | 130        |
| Time                    | 1.88e+03   |
| dLoss                   | 0.0208416  |
----------------------------------------
itr #231 | 
Mem: 693.660156
Obtaining samples...
Obtaining samples for iteration 231...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5041, #subsample_inputs: 5041
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.474      |
| AbsLearnSignalNew       | 0.474      |
| AbsLearningOld          | 0.473      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 9.11915    |
| AveragePolicyStd        | 0.760047   |
| AverageReturn           | 1.04e+03   |
| Entropy                 | 3.42321    |
| EnvExecTime             | 2.01       |
| ExplainedVariance       | 0.195      |
| Iteration               | 231        |
| ItrTime                 | 8.15       |
| LossAfter               | -0.23637   |
| LossBefore              | -0.21086   |
| MaxReturn               | 1.54e+03   |
| MeanKL                  | 0.00992211 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 762        |
| NumTrajs                | 15         |
| Perplexity              | 30.6677    |
| PolicyExecTime          | 0.507      |
| ProcessExecTime         | 0.0579     |
| StdReturn               | 186        |
| Time                    | 1.89e+03   |
| dLoss                   | 0.0255097  |
----------------------------------------
itr #232 | 
Mem: 693.660156
Obtaining samples...
Obtaining samples for iteration 232...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5179, #subsample_inputs: 5179
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.779      |
| AbsLearnSignalNew       | 0.779      |
| AbsLearningOld          | 0.779      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 9.8543     |
| AveragePolicyStd        | 0.760773   |
| AverageReturn           | 942        |
| Entropy                 | 3.42663    |
| EnvExecTime             | 1.97       |
| ExplainedVariance       | 0.915      |
| Iteration               | 232        |
| ItrTime                 | 8.25       |
| LossAfter               | 0.282483   |
| LossBefore              | 0.301386   |
| MaxReturn               | 1.11e+03   |
| MeanKL                  | 0.00647698 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 793        |
| NumTrajs                | 18         |
| Perplexity              | 30.7728    |
| PolicyExecTime          | 0.491      |
| ProcessExecTime         | 0.0593     |
| StdReturn               | 106        |
| Time                    | 1.89e+03   |
| dLoss                   | 0.0189022  |
----------------------------------------
itr #233 | 
Mem: 693.660156
Obtaining samples...
Obtaining samples for iteration 233...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5030, #subsample_inputs: 5030
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.458      |
| AbsLearnSignalNew       | 0.458      |
| AbsLearningOld          | 0.458      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 12.2539    |
| AveragePolicyStd        | 0.753458   |
| AverageReturn           | 1.01e+03   |
| Entropy                 | 3.39787    |
| EnvExecTime             | 1.79       |
| ExplainedVariance       | 0.503      |
| Iteration               | 233        |
| ItrTime                 | 7.84       |
| LossAfter               | 0.0654948  |
| LossBefore              | 0.092945   |
| MaxReturn               | 1.58e+03   |
| MeanKL                  | 0.00997796 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 765        |
| NumTrajs                | 16         |
| Perplexity              | 29.9004    |
| PolicyExecTime          | 0.456      |
| ProcessExecTime         | 0.0523     |
| StdReturn               | 168        |
| Time                    | 1.9e+03    |
| dLoss                   | 0.0274502  |
----------------------------------------
itr #234 | 
Mem: 693.660156
Obtaining samples...
Obtaining samples for iteration 234...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5157, #subsample_inputs: 5157
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.726      |
| AbsLearnSignalNew       | 0.726      |
| AbsLearningOld          | 0.726      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 10.0833    |
| AveragePolicyStd        | 0.752659   |
| AverageReturn           | 1.04e+03   |
| Entropy                 | 3.39444    |
| EnvExecTime             | 1.87       |
| ExplainedVariance       | 0.886      |
| Iteration               | 234        |
| ItrTime                 | 8.03       |
| LossAfter               | -0.118235  |
| LossBefore              | -0.0942031 |
| MaxReturn               | 1.55e+03   |
| MeanKL                  | 0.00986965 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 869        |
| NumTrajs                | 16         |
| Perplexity              | 29.798     |
| PolicyExecTime          | 0.476      |
| ProcessExecTime         | 0.054      |
| StdReturn               | 178        |
| Time                    | 1.91e+03   |
| dLoss                   | 0.0240319  |
----------------------------------------
itr #235 | 
Mem: 694.933594
Obtaining samples...
Obtaining samples for iteration 235...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5080, #subsample_inputs: 5080
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.764      |
| AbsLearnSignalNew       | 0.764      |
| AbsLearningOld          | 0.764      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 9.89344    |
| AveragePolicyStd        | 0.753429   |
| AverageReturn           | 969        |
| Entropy                 | 3.3975     |
| EnvExecTime             | 2.07       |
| ExplainedVariance       | 0.923      |
| Iteration               | 235        |
| ItrTime                 | 8.27       |
| LossAfter               | 0.0981209  |
| LossBefore              | 0.124954   |
| MaxReturn               | 1.26e+03   |
| MeanKL                  | 0.00963857 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 780        |
| NumTrajs                | 17         |
| Perplexity              | 29.8892    |
| PolicyExecTime          | 0.509      |
| ProcessExecTime         | 0.0631     |
| StdReturn               | 111        |
| Time                    | 1.92e+03   |
| dLoss                   | 0.0268328  |
----------------------------------------
itr #236 | 
Mem: 694.933594
Obtaining samples...
Obtaining samples for iteration 236...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5008, #subsample_inputs: 5008
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.279      |
| AbsLearnSignalNew       | 0.279      |
| AbsLearningOld          | 0.279      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 14.7338    |
| AveragePolicyStd        | 0.754272   |
| AverageReturn           | 1.22e+03   |
| Entropy                 | 3.40084    |
| EnvExecTime             | 1.96       |
| ExplainedVariance       | -121       |
| Iteration               | 236        |
| ItrTime                 | 8.04       |
| LossAfter               | 0.078711   |
| LossBefore              | 0.0960093  |
| MaxReturn               | 2.5e+03    |
| MeanKL                  | 0.00647127 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 939        |
| NumTrajs                | 13         |
| Perplexity              | 29.9894    |
| PolicyExecTime          | 0.487      |
| ProcessExecTime         | 0.0581     |
| StdReturn               | 401        |
| Time                    | 1.93e+03   |
| dLoss                   | 0.0172983  |
----------------------------------------
itr #237 | 
Mem: 695.187500
Obtaining samples...
Obtaining samples for iteration 237...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5375, #subsample_inputs: 5375
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.734     |
| AbsLearnSignalNew       | 0.734     |
| AbsLearningOld          | 0.734     |
| AverageDiscountedReturn | 239       |
| AveragePhiLoss          | 10.1792   |
| AveragePolicyStd        | 0.74803   |
| AverageReturn           | 1.14e+03  |
| Entropy                 | 3.37779   |
| EnvExecTime             | 1.95      |
| ExplainedVariance       | 0.906     |
| Iteration               | 237       |
| ItrTime                 | 8.33      |
| LossAfter               | -0.760948 |
| LossBefore              | -0.739579 |
| MaxReturn               | 1.42e+03  |
| MeanKL                  | 0.0065226 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.02e+03  |
| NumTrajs                | 15        |
| Perplexity              | 29.3059   |
| PolicyExecTime          | 0.489     |
| ProcessExecTime         | 0.0608    |
| StdReturn               | 131       |
| Time                    | 1.93e+03  |
| dLoss                   | 0.0213684 |
---------------------------------------
itr #238 | 
Mem: 695.187500
Obtaining samples...
Obtaining samples for iteration 238...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5232, #subsample_inputs: 5232
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.769      |
| AbsLearnSignalNew       | 0.769      |
| AbsLearningOld          | 0.769      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 9.76314    |
| AveragePolicyStd        | 0.744688   |
| AverageReturn           | 1.05e+03   |
| Entropy                 | 3.36518    |
| EnvExecTime             | 1.8        |
| ExplainedVariance       | 0.925      |
| Iteration               | 238        |
| ItrTime                 | 8.02       |
| LossAfter               | -0.346872  |
| LossBefore              | -0.327278  |
| MaxReturn               | 1.45e+03   |
| MeanKL                  | 0.00641923 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 841        |
| NumTrajs                | 16         |
| Perplexity              | 28.9388    |
| PolicyExecTime          | 0.461      |
| ProcessExecTime         | 0.0531     |
| StdReturn               | 147        |
| Time                    | 1.94e+03   |
| dLoss                   | 0.0195934  |
----------------------------------------
itr #239 | 
Mem: 695.187500
Obtaining samples...
Obtaining samples for iteration 239...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5237, #subsample_inputs: 5237
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.664      |
| AbsLearnSignalNew       | 0.664      |
| AbsLearningOld          | 0.664      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 10.1032    |
| AveragePolicyStd        | 0.744664   |
| AverageReturn           | 1.03e+03   |
| Entropy                 | 3.36478    |
| EnvExecTime             | 1.89       |
| ExplainedVariance       | 0.84       |
| Iteration               | 239        |
| ItrTime                 | 8.15       |
| LossAfter               | -0.0617918 |
| LossBefore              | -0.041162  |
| MaxReturn               | 1.59e+03   |
| MeanKL                  | 0.00645174 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 799        |
| NumTrajs                | 16         |
| Perplexity              | 28.9273    |
| PolicyExecTime          | 0.477      |
| ProcessExecTime         | 0.0579     |
| StdReturn               | 193        |
| Time                    | 1.95e+03   |
| dLoss                   | 0.0206298  |
----------------------------------------
itr #240 | 
Mem: 695.187500
Obtaining samples...
Obtaining samples for iteration 240...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5265, #subsample_inputs: 5265
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.685      |
| AbsLearnSignalNew       | 0.685      |
| AbsLearningOld          | 0.685      |
| AverageDiscountedReturn | 230        |
| AveragePhiLoss          | 11.0403    |
| AveragePolicyStd        | 0.74097    |
| AverageReturn           | 1.05e+03   |
| Entropy                 | 3.34994    |
| EnvExecTime             | 2.06       |
| ExplainedVariance       | 0.718      |
| Iteration               | 240        |
| ItrTime                 | 8.36       |
| LossAfter               | 0.0161871  |
| LossBefore              | 0.0321696  |
| MaxReturn               | 1.87e+03   |
| MeanKL                  | 0.00658183 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 226        |
| NumTrajs                | 15         |
| Perplexity              | 28.501     |
| PolicyExecTime          | 0.512      |
| ProcessExecTime         | 0.0606     |
| StdReturn               | 321        |
| Time                    | 1.96e+03   |
| dLoss                   | 0.0159825  |
----------------------------------------
itr #241 | 
Mem: 695.187500
Obtaining samples...
Obtaining samples for iteration 241...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5135, #subsample_inputs: 5135
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.701      |
| AbsLearnSignalNew       | 0.701      |
| AbsLearningOld          | 0.701      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 9.79839    |
| AveragePolicyStd        | 0.742119   |
| AverageReturn           | 1.22e+03   |
| Entropy                 | 3.35442    |
| EnvExecTime             | 2.01       |
| ExplainedVariance       | 0.746      |
| Iteration               | 241        |
| ItrTime                 | 8.18       |
| LossAfter               | -0.346717  |
| LossBefore              | -0.321455  |
| MaxReturn               | 2.54e+03   |
| MeanKL                  | 0.00983065 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 992        |
| NumTrajs                | 13         |
| Perplexity              | 28.6289    |
| PolicyExecTime          | 0.509      |
| ProcessExecTime         | 0.0569     |
| StdReturn               | 414        |
| Time                    | 1.97e+03   |
| dLoss                   | 0.0252629  |
----------------------------------------
itr #242 | 
Mem: 695.433594
Obtaining samples...
Obtaining samples for iteration 242...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5318, #subsample_inputs: 5318
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.733      |
| AbsLearnSignalNew       | 0.733      |
| AbsLearningOld          | 0.733      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 9.44228    |
| AveragePolicyStd        | 0.746487   |
| AverageReturn           | 1.06e+03   |
| Entropy                 | 3.37377    |
| EnvExecTime             | 1.89       |
| ExplainedVariance       | 0.919      |
| Iteration               | 242        |
| ItrTime                 | 8.23       |
| LossAfter               | -0.286813  |
| LossBefore              | -0.265915  |
| MaxReturn               | 1.61e+03   |
| MeanKL                  | 0.00641626 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 829        |
| NumTrajs                | 16         |
| Perplexity              | 29.1885    |
| PolicyExecTime          | 0.484      |
| ProcessExecTime         | 0.0558     |
| StdReturn               | 171        |
| Time                    | 1.98e+03   |
| dLoss                   | 0.0208983  |
----------------------------------------
itr #243 | 
Mem: 695.433594
Obtaining samples...
Obtaining samples for iteration 243...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5120, #subsample_inputs: 5120
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.742      |
| AbsLearnSignalNew       | 0.742      |
| AbsLearningOld          | 0.743      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 9.58846    |
| AveragePolicyStd        | 0.743253   |
| AverageReturn           | 1.03e+03   |
| Entropy                 | 3.3613     |
| EnvExecTime             | 1.93       |
| ExplainedVariance       | 0.925      |
| Iteration               | 243        |
| ItrTime                 | 8.04       |
| LossAfter               | -0.254348  |
| LossBefore              | -0.22886   |
| MaxReturn               | 1.25e+03   |
| MeanKL                  | 0.00988149 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 901        |
| NumTrajs                | 16         |
| Perplexity              | 28.8267    |
| PolicyExecTime          | 0.488      |
| ProcessExecTime         | 0.0564     |
| StdReturn               | 101        |
| Time                    | 1.98e+03   |
| dLoss                   | 0.0254887  |
----------------------------------------
itr #244 | 
Mem: 695.433594
Obtaining samples...
Obtaining samples for iteration 244...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5271, #subsample_inputs: 5271
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.765      |
| AbsLearnSignalNew       | 0.765      |
| AbsLearningOld          | 0.765      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 10.5253    |
| AveragePolicyStd        | 0.739288   |
| AverageReturn           | 1.05e+03   |
| Entropy                 | 3.34486    |
| EnvExecTime             | 2.02       |
| ExplainedVariance       | 0.923      |
| Iteration               | 244        |
| ItrTime                 | 8.34       |
| LossAfter               | -0.317828  |
| LossBefore              | -0.29862   |
| MaxReturn               | 1.53e+03   |
| MeanKL                  | 0.00641119 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 819        |
| NumTrajs                | 16         |
| Perplexity              | 28.3567    |
| PolicyExecTime          | 0.51       |
| ProcessExecTime         | 0.059      |
| StdReturn               | 148        |
| Time                    | 1.99e+03   |
| dLoss                   | 0.019208   |
----------------------------------------
itr #245 | 
Mem: 695.433594
Obtaining samples...
Obtaining samples for iteration 245...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5015, #subsample_inputs: 5015
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.757      |
| AbsLearnSignalNew       | 0.757      |
| AbsLearningOld          | 0.758      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 10.6786    |
| AveragePolicyStd        | 0.732701   |
| AverageReturn           | 1.07e+03   |
| Entropy                 | 3.31726    |
| EnvExecTime             | 1.75       |
| ExplainedVariance       | 0.915      |
| Iteration               | 245        |
| ItrTime                 | 7.73       |
| LossAfter               | 0.325157   |
| LossBefore              | 0.351714   |
| MaxReturn               | 1.38e+03   |
| MeanKL                  | 0.00995815 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 840        |
| NumTrajs                | 15         |
| Perplexity              | 27.5846    |
| PolicyExecTime          | 0.447      |
| ProcessExecTime         | 0.0523     |
| StdReturn               | 144        |
| Time                    | 2e+03      |
| dLoss                   | 0.0265571  |
----------------------------------------
itr #246 | 
Mem: 695.433594
Obtaining samples...
Obtaining samples for iteration 246...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5130, #subsample_inputs: 5130
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.695      |
| AbsLearnSignalNew       | 0.695      |
| AbsLearningOld          | 0.695      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 11.7434    |
| AveragePolicyStd        | 0.730643   |
| AverageReturn           | 1.14e+03   |
| Entropy                 | 3.30764    |
| EnvExecTime             | 1.83       |
| ExplainedVariance       | 0.778      |
| Iteration               | 246        |
| ItrTime                 | 8.03       |
| LossAfter               | 0.0525127  |
| LossBefore              | 0.0734048  |
| MaxReturn               | 1.72e+03   |
| MeanKL                  | 0.00665792 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 960        |
| NumTrajs                | 14         |
| Perplexity              | 27.3205    |
| PolicyExecTime          | 0.471      |
| ProcessExecTime         | 0.0545     |
| StdReturn               | 222        |
| Time                    | 2.01e+03   |
| dLoss                   | 0.0208921  |
----------------------------------------
itr #247 | 
Mem: 695.433594
Obtaining samples...
Obtaining samples for iteration 247...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5179, #subsample_inputs: 5179
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.456      |
| AbsLearnSignalNew       | 0.456      |
| AbsLearningOld          | 0.456      |
| AverageDiscountedReturn | 236        |
| AveragePhiLoss          | 11.1702    |
| AveragePolicyStd        | 0.725697   |
| AverageReturn           | 1.19e+03   |
| Entropy                 | 3.28776    |
| EnvExecTime             | 1.84       |
| ExplainedVariance       | -1.93      |
| Iteration               | 247        |
| ItrTime                 | 8.04       |
| LossAfter               | 0.406284   |
| LossBefore              | 0.422925   |
| MaxReturn               | 2.54e+03   |
| MeanKL                  | 0.00660054 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 743        |
| NumTrajs                | 13         |
| Perplexity              | 26.7827    |
| PolicyExecTime          | 0.463      |
| ProcessExecTime         | 0.0557     |
| StdReturn               | 444        |
| Time                    | 2.02e+03   |
| dLoss                   | 0.0166414  |
----------------------------------------
itr #248 | 
Mem: 695.437500
Obtaining samples...
Obtaining samples for iteration 248...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5150, #subsample_inputs: 5150
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.75       |
| AbsLearnSignalNew       | 0.75       |
| AbsLearningOld          | 0.75       |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 10.4346    |
| AveragePolicyStd        | 0.726852   |
| AverageReturn           | 1.25e+03   |
| Entropy                 | 3.29091    |
| EnvExecTime             | 1.95       |
| ExplainedVariance       | 0.895      |
| Iteration               | 248        |
| ItrTime                 | 8.11       |
| LossAfter               | 0.0824697  |
| LossBefore              | 0.111712   |
| MaxReturn               | 2.23e+03   |
| MeanKL                  | 0.00993436 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 974        |
| NumTrajs                | 13         |
| Perplexity              | 26.8672    |
| PolicyExecTime          | 0.493      |
| ProcessExecTime         | 0.0553     |
| StdReturn               | 361        |
| Time                    | 2.02e+03   |
| dLoss                   | 0.0292426  |
----------------------------------------
itr #249 | 
Mem: 695.437500
Obtaining samples...
Obtaining samples for iteration 249...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5003, #subsample_inputs: 5003
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.733      |
| AbsLearnSignalNew       | 0.733      |
| AbsLearningOld          | 0.733      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 12.1047    |
| AveragePolicyStd        | 0.722528   |
| AverageReturn           | 1.13e+03   |
| Entropy                 | 3.27097    |
| EnvExecTime             | 1.76       |
| ExplainedVariance       | 0.911      |
| Iteration               | 249        |
| ItrTime                 | 7.76       |
| LossAfter               | 0.858706   |
| LossBefore              | 0.884435   |
| MaxReturn               | 1.87e+03   |
| MeanKL                  | 0.00977451 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 825        |
| NumTrajs                | 14         |
| Perplexity              | 26.337     |
| PolicyExecTime          | 0.45       |
| ProcessExecTime         | 0.0517     |
| StdReturn               | 282        |
| Time                    | 2.03e+03   |
| dLoss                   | 0.0257295  |
----------------------------------------
itr #250 | 
Mem: 696.128906
Obtaining samples...
Obtaining samples for iteration 250...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5305, #subsample_inputs: 5305
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.571      |
| AbsLearnSignalNew       | 0.571      |
| AbsLearningOld          | 0.57       |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 11.0457    |
| AveragePolicyStd        | 0.718865   |
| AverageReturn           | 1.33e+03   |
| Entropy                 | 3.25399    |
| EnvExecTime             | 1.96       |
| ExplainedVariance       | 0.364      |
| Iteration               | 250        |
| ItrTime                 | 8.26       |
| LossAfter               | 0.238418   |
| LossBefore              | 0.266517   |
| MaxReturn               | 2.38e+03   |
| MeanKL                  | 0.00998741 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 803        |
| NumTrajs                | 12         |
| Perplexity              | 25.8935    |
| PolicyExecTime          | 0.503      |
| ProcessExecTime         | 0.0573     |
| StdReturn               | 439        |
| Time                    | 2.04e+03   |
| dLoss                   | 0.0280997  |
----------------------------------------
itr #251 | 
Mem: 696.195312
Obtaining samples...
Obtaining samples for iteration 251...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5133, #subsample_inputs: 5133
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.731      |
| AbsLearnSignalNew       | 0.731      |
| AbsLearningOld          | 0.731      |
| AverageDiscountedReturn | 236        |
| AveragePhiLoss          | 10.7371    |
| AveragePolicyStd        | 0.721164   |
| AverageReturn           | 1.13e+03   |
| Entropy                 | 3.26434    |
| EnvExecTime             | 1.89       |
| ExplainedVariance       | 0.867      |
| Iteration               | 251        |
| ItrTime                 | 8.05       |
| LossAfter               | -0.321001  |
| LossBefore              | -0.300597  |
| MaxReturn               | 1.77e+03   |
| MeanKL                  | 0.00648693 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 768        |
| NumTrajs                | 14         |
| Perplexity              | 26.1629    |
| PolicyExecTime          | 0.477      |
| ProcessExecTime         | 0.0545     |
| StdReturn               | 282        |
| Time                    | 2.05e+03   |
| dLoss                   | 0.0204037  |
----------------------------------------
itr #252 | 
Mem: 696.195312
Obtaining samples...
Obtaining samples for iteration 252...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5056, #subsample_inputs: 5056
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.768      |
| AbsLearnSignalNew       | 0.768      |
| AbsLearningOld          | 0.768      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 11.4394    |
| AveragePolicyStd        | 0.723263   |
| AverageReturn           | 1.23e+03   |
| Entropy                 | 3.27235    |
| EnvExecTime             | 1.83       |
| ExplainedVariance       | 0.898      |
| Iteration               | 252        |
| ItrTime                 | 7.9        |
| LossAfter               | 0.114274   |
| LossBefore              | 0.135831   |
| MaxReturn               | 1.6e+03    |
| MeanKL                  | 0.00645057 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 813        |
| NumTrajs                | 13         |
| Perplexity              | 26.3734    |
| PolicyExecTime          | 0.463      |
| ProcessExecTime         | 0.0552     |
| StdReturn               | 219        |
| Time                    | 2.06e+03   |
| dLoss                   | 0.0215576  |
----------------------------------------
itr #253 | 
Mem: 696.195312
Obtaining samples...
Obtaining samples for iteration 253...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5334, #subsample_inputs: 5334
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.741     |
| AbsLearnSignalNew       | 0.741     |
| AbsLearningOld          | 0.741     |
| AverageDiscountedReturn | 239       |
| AveragePhiLoss          | 11.2983   |
| AveragePolicyStd        | 0.718366  |
| AverageReturn           | 1.06e+03  |
| Entropy                 | 3.25132   |
| EnvExecTime             | 1.77      |
| ExplainedVariance       | 0.852     |
| Iteration               | 253       |
| ItrTime                 | 8.13      |
| LossAfter               | 0.295127  |
| LossBefore              | 0.314164  |
| MaxReturn               | 1.81e+03  |
| MeanKL                  | 0.0064043 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 773       |
| NumTrajs                | 16        |
| Perplexity              | 25.8245   |
| PolicyExecTime          | 0.451     |
| ProcessExecTime         | 0.0537    |
| StdReturn               | 304       |
| Time                    | 2.06e+03  |
| dLoss                   | 0.0190365 |
---------------------------------------
itr #254 | 
Mem: 696.195312
Obtaining samples...
Obtaining samples for iteration 254...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5280, #subsample_inputs: 5280
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.754      |
| AbsLearnSignalNew       | 0.754      |
| AbsLearningOld          | 0.754      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 11.5185    |
| AveragePolicyStd        | 0.719241   |
| AverageReturn           | 1.06e+03   |
| Entropy                 | 3.25336    |
| EnvExecTime             | 1.93       |
| ExplainedVariance       | 0.916      |
| Iteration               | 254        |
| ItrTime                 | 8.24       |
| LossAfter               | 0.232312   |
| LossBefore              | 0.254144   |
| MaxReturn               | 1.62e+03   |
| MeanKL                  | 0.00644773 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 780        |
| NumTrajs                | 16         |
| Perplexity              | 25.8772    |
| PolicyExecTime          | 0.485      |
| ProcessExecTime         | 0.0562     |
| StdReturn               | 184        |
| Time                    | 2.07e+03   |
| dLoss                   | 0.0218324  |
----------------------------------------
itr #255 | 
Mem: 696.195312
Obtaining samples...
Obtaining samples for iteration 255...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5197, #subsample_inputs: 5197
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.738      |
| AbsLearnSignalNew       | 0.738      |
| AbsLearningOld          | 0.738      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 11.8616    |
| AveragePolicyStd        | 0.717698   |
| AverageReturn           | 1.04e+03   |
| Entropy                 | 3.24595    |
| EnvExecTime             | 1.85       |
| ExplainedVariance       | 0.925      |
| Iteration               | 255        |
| ItrTime                 | 8.05       |
| LossAfter               | 0.232849   |
| LossBefore              | 0.258176   |
| MaxReturn               | 1.51e+03   |
| MeanKL                  | 0.00992783 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 738        |
| NumTrajs                | 16         |
| Perplexity              | 25.6861    |
| PolicyExecTime          | 0.466      |
| ProcessExecTime         | 0.0547     |
| StdReturn               | 199        |
| Time                    | 2.08e+03   |
| dLoss                   | 0.0253266  |
----------------------------------------
itr #256 | 
Mem: 696.195312
Obtaining samples...
Obtaining samples for iteration 256...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5118, #subsample_inputs: 5118
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.421      |
| AbsLearnSignalNew       | 0.421      |
| AbsLearningOld          | 0.421      |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 10.0098    |
| AveragePolicyStd        | 0.714228   |
| AverageReturn           | 1.11e+03   |
| Entropy                 | 3.23192    |
| EnvExecTime             | 1.8        |
| ExplainedVariance       | -0.846     |
| Iteration               | 256        |
| ItrTime                 | 7.87       |
| LossAfter               | 0.536964   |
| LossBefore              | 0.562185   |
| MaxReturn               | 2.35e+03   |
| MeanKL                  | 0.00640446 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 744        |
| NumTrajs                | 14         |
| Perplexity              | 25.3283    |
| PolicyExecTime          | 0.459      |
| ProcessExecTime         | 0.0526     |
| StdReturn               | 382        |
| Time                    | 2.09e+03   |
| dLoss                   | 0.0252216  |
----------------------------------------
itr #257 | 
Mem: 696.199219
Obtaining samples...
Obtaining samples for iteration 257...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5052, #subsample_inputs: 5052
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.707      |
| AbsLearnSignalNew       | 0.707      |
| AbsLearningOld          | 0.707      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 11.6409    |
| AveragePolicyStd        | 0.716324   |
| AverageReturn           | 1.02e+03   |
| Entropy                 | 3.24103    |
| EnvExecTime             | 1.83       |
| ExplainedVariance       | 0.919      |
| Iteration               | 257        |
| ItrTime                 | 7.94       |
| LossAfter               | 0.137952   |
| LossBefore              | 0.163323   |
| MaxReturn               | 1.32e+03   |
| MeanKL                  | 0.00965412 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 799        |
| NumTrajs                | 16         |
| Perplexity              | 25.56      |
| PolicyExecTime          | 0.46       |
| ProcessExecTime         | 0.0552     |
| StdReturn               | 128        |
| Time                    | 2.1e+03    |
| dLoss                   | 0.0253705  |
----------------------------------------
itr #258 | 
Mem: 696.199219
Obtaining samples...
Obtaining samples for iteration 258...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5119, #subsample_inputs: 5119
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.752      |
| AbsLearnSignalNew       | 0.752      |
| AbsLearningOld          | 0.752      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 11.2528    |
| AveragePolicyStd        | 0.719481   |
| AverageReturn           | 1.1e+03    |
| Entropy                 | 3.25531    |
| EnvExecTime             | 2.08       |
| ExplainedVariance       | 0.911      |
| Iteration               | 258        |
| ItrTime                 | 8.27       |
| LossAfter               | -0.343376  |
| LossBefore              | -0.321812  |
| MaxReturn               | 1.65e+03   |
| MeanKL                  | 0.00977384 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 865        |
| NumTrajs                | 15         |
| Perplexity              | 25.9278    |
| PolicyExecTime          | 0.519      |
| ProcessExecTime         | 0.0596     |
| StdReturn               | 188        |
| Time                    | 2.11e+03   |
| dLoss                   | 0.0215634  |
----------------------------------------
itr #259 | 
Mem: 696.199219
Obtaining samples...
Obtaining samples for iteration 259...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5055, #subsample_inputs: 5055
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.74       |
| AbsLearnSignalNew       | 0.74       |
| AbsLearningOld          | 0.74       |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 12.4021    |
| AveragePolicyStd        | 0.715405   |
| AverageReturn           | 1.15e+03   |
| Entropy                 | 3.23776    |
| EnvExecTime             | 1.85       |
| ExplainedVariance       | 0.879      |
| Iteration               | 259        |
| ItrTime                 | 7.96       |
| LossAfter               | -0.139336  |
| LossBefore              | -0.11924   |
| MaxReturn               | 1.8e+03    |
| MeanKL                  | 0.00646358 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 789        |
| NumTrajs                | 14         |
| Perplexity              | 25.4766    |
| PolicyExecTime          | 0.468      |
| ProcessExecTime         | 0.0557     |
| StdReturn               | 295        |
| Time                    | 2.11e+03   |
| dLoss                   | 0.0200955  |
----------------------------------------
itr #260 | 
Mem: 696.199219
Obtaining samples...
Obtaining samples for iteration 260...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5088, #subsample_inputs: 5088
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.779      |
| AbsLearnSignalNew       | 0.779      |
| AbsLearningOld          | 0.779      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 11.6688    |
| AveragePolicyStd        | 0.714561   |
| AverageReturn           | 1.1e+03    |
| Entropy                 | 3.23256    |
| EnvExecTime             | 2.25       |
| ExplainedVariance       | 0.924      |
| Iteration               | 260        |
| ItrTime                 | 8.44       |
| LossAfter               | -0.634694  |
| LossBefore              | -0.612562  |
| MaxReturn               | 1.61e+03   |
| MeanKL                  | 0.00649229 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 805        |
| NumTrajs                | 15         |
| Perplexity              | 25.3445    |
| PolicyExecTime          | 0.56       |
| ProcessExecTime         | 0.0621     |
| StdReturn               | 199        |
| Time                    | 2.12e+03   |
| dLoss                   | 0.0221316  |
----------------------------------------
itr #261 | 
Mem: 696.199219
Obtaining samples...
Obtaining samples for iteration 261...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5123, #subsample_inputs: 5123
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.741      |
| AbsLearnSignalNew       | 0.741      |
| AbsLearningOld          | 0.741      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 12.3537    |
| AveragePolicyStd        | 0.712871   |
| AverageReturn           | 971        |
| Entropy                 | 3.22264    |
| EnvExecTime             | 1.87       |
| ExplainedVariance       | 0.932      |
| Iteration               | 261        |
| ItrTime                 | 8.02       |
| LossAfter               | -0.209724  |
| LossBefore              | -0.186064  |
| MaxReturn               | 1.53e+03   |
| MeanKL                  | 0.00661792 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 747        |
| NumTrajs                | 17         |
| Perplexity              | 25.0942    |
| PolicyExecTime          | 0.472      |
| ProcessExecTime         | 0.0558     |
| StdReturn               | 175        |
| Time                    | 2.13e+03   |
| dLoss                   | 0.0236599  |
----------------------------------------
itr #262 | 
Mem: 696.199219
Obtaining samples...
Obtaining samples for iteration 262...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5056, #subsample_inputs: 5056
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.743      |
| AbsLearnSignalNew       | 0.743      |
| AbsLearningOld          | 0.743      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 11.4906    |
| AveragePolicyStd        | 0.712923   |
| AverageReturn           | 972        |
| Entropy                 | 3.22178    |
| EnvExecTime             | 1.99       |
| ExplainedVariance       | 0.933      |
| Iteration               | 262        |
| ItrTime                 | 8.09       |
| LossAfter               | -0.56999   |
| LossBefore              | -0.547864  |
| MaxReturn               | 1.28e+03   |
| MeanKL                  | 0.00644941 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 775        |
| NumTrajs                | 17         |
| Perplexity              | 25.0726    |
| PolicyExecTime          | 0.494      |
| ProcessExecTime         | 0.0599     |
| StdReturn               | 111        |
| Time                    | 2.14e+03   |
| dLoss                   | 0.0221255  |
----------------------------------------
itr #263 | 
Mem: 696.199219
Obtaining samples...
Obtaining samples for iteration 263...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5058, #subsample_inputs: 5058
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.648      |
| AbsLearnSignalNew       | 0.648      |
| AbsLearningOld          | 0.648      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 13.0511    |
| AveragePolicyStd        | 0.719319   |
| AverageReturn           | 971        |
| Entropy                 | 3.24632    |
| EnvExecTime             | 1.96       |
| ExplainedVariance       | 0.897      |
| Iteration               | 263        |
| ItrTime                 | 8.09       |
| LossAfter               | 0.890637   |
| LossBefore              | 0.921803   |
| MaxReturn               | 1.46e+03   |
| MeanKL                  | 0.00644007 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 759        |
| NumTrajs                | 17         |
| Perplexity              | 25.6955    |
| PolicyExecTime          | 0.484      |
| ProcessExecTime         | 0.0581     |
| StdReturn               | 155        |
| Time                    | 2.15e+03   |
| dLoss                   | 0.0311657  |
----------------------------------------
itr #264 | 
Mem: 696.199219
Obtaining samples...
Obtaining samples for iteration 264...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5070, #subsample_inputs: 5070
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.58       |
| AbsLearnSignalNew       | 0.58       |
| AbsLearningOld          | 0.58       |
| AverageDiscountedReturn | 235        |
| AveragePhiLoss          | 12.9855    |
| AveragePolicyStd        | 0.718533   |
| AverageReturn           | 907        |
| Entropy                 | 3.24218    |
| EnvExecTime             | 1.87       |
| ExplainedVariance       | 0.765      |
| Iteration               | 264        |
| ItrTime                 | 7.97       |
| LossAfter               | 0.0662289  |
| LossBefore              | 0.0932417  |
| MaxReturn               | 1.26e+03   |
| MeanKL                  | 0.00974605 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 239        |
| NumTrajs                | 18         |
| Perplexity              | 25.5895    |
| PolicyExecTime          | 0.469      |
| ProcessExecTime         | 0.0543     |
| StdReturn               | 197        |
| Time                    | 2.15e+03   |
| dLoss                   | 0.0270128  |
----------------------------------------
itr #265 | 
Mem: 696.199219
Obtaining samples...
Obtaining samples for iteration 265...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5102, #subsample_inputs: 5102
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.706      |
| AbsLearnSignalNew       | 0.706      |
| AbsLearningOld          | 0.706      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 12.4683    |
| AveragePolicyStd        | 0.714477   |
| AverageReturn           | 976        |
| Entropy                 | 3.22298    |
| EnvExecTime             | 2.06       |
| ExplainedVariance       | 0.861      |
| Iteration               | 265        |
| ItrTime                 | 8.21       |
| LossAfter               | 0.109592   |
| LossBefore              | 0.132581   |
| MaxReturn               | 1.47e+03   |
| MeanKL                  | 0.00997828 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 757        |
| NumTrajs                | 17         |
| Perplexity              | 25.1027    |
| PolicyExecTime          | 0.511      |
| ProcessExecTime         | 0.0604     |
| StdReturn               | 181        |
| Time                    | 2.16e+03   |
| dLoss                   | 0.0229893  |
----------------------------------------
itr #266 | 
Mem: 696.199219
Obtaining samples...
Obtaining samples for iteration 266...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5191, #subsample_inputs: 5191
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.601      |
| AbsLearnSignalNew       | 0.601      |
| AbsLearningOld          | 0.6        |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 12.5221    |
| AveragePolicyStd        | 0.712219   |
| AverageReturn           | 976        |
| Entropy                 | 3.21188    |
| EnvExecTime             | 1.96       |
| ExplainedVariance       | 0.693      |
| Iteration               | 266        |
| ItrTime                 | 8.19       |
| LossAfter               | -0.344983  |
| LossBefore              | -0.328982  |
| MaxReturn               | 1.58e+03   |
| MeanKL                  | 0.00647617 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 668        |
| NumTrajs                | 17         |
| Perplexity              | 24.8258    |
| PolicyExecTime          | 0.504      |
| ProcessExecTime         | 0.0562     |
| StdReturn               | 207        |
| Time                    | 2.17e+03   |
| dLoss                   | 0.0160013  |
----------------------------------------
itr #267 | 
Mem: 696.199219
Obtaining samples...
Obtaining samples for iteration 267...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5262, #subsample_inputs: 5262
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.626      |
| AbsLearnSignalNew       | 0.626      |
| AbsLearningOld          | 0.626      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 16.3152    |
| AveragePolicyStd        | 0.713444   |
| AverageReturn           | 1.04e+03   |
| Entropy                 | 3.2144     |
| EnvExecTime             | 1.92       |
| ExplainedVariance       | 0.617      |
| Iteration               | 267        |
| ItrTime                 | 8.17       |
| LossAfter               | 0.0333323  |
| LossBefore              | 0.0561886  |
| MaxReturn               | 1.6e+03    |
| MeanKL                  | 0.00651073 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 540        |
| NumTrajs                | 16         |
| Perplexity              | 24.8884    |
| PolicyExecTime          | 0.484      |
| ProcessExecTime         | 0.0562     |
| StdReturn               | 266        |
| Time                    | 2.18e+03   |
| dLoss                   | 0.0228563  |
----------------------------------------
itr #268 | 
Mem: 696.199219
Obtaining samples...
Obtaining samples for iteration 268...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5454, #subsample_inputs: 5454
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.455     |
| AbsLearnSignalNew       | 0.455     |
| AbsLearningOld          | 0.455     |
| AverageDiscountedReturn | 236       |
| AveragePhiLoss          | 13.9211   |
| AveragePolicyStd        | 0.712129  |
| AverageReturn           | 1.2e+03   |
| Entropy                 | 3.20467   |
| EnvExecTime             | 1.82      |
| ExplainedVariance       | -1.22     |
| Iteration               | 268       |
| ItrTime                 | 8.23      |
| LossAfter               | 0.783054  |
| LossBefore              | 0.811174  |
| MaxReturn               | 2.51e+03  |
| MeanKL                  | 0.0065029 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 762       |
| NumTrajs                | 14        |
| Perplexity              | 24.6473   |
| PolicyExecTime          | 0.463     |
| ProcessExecTime         | 0.0554    |
| StdReturn               | 497       |
| Time                    | 2.19e+03  |
| dLoss                   | 0.0281197 |
---------------------------------------
itr #269 | 
Mem: 696.199219
Obtaining samples...
Obtaining samples for iteration 269...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5054, #subsample_inputs: 5054
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.763      |
| AbsLearnSignalNew       | 0.763      |
| AbsLearningOld          | 0.763      |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 12.2976    |
| AveragePolicyStd        | 0.712318   |
| AverageReturn           | 1.07e+03   |
| Entropy                 | 3.20632    |
| EnvExecTime             | 1.82       |
| ExplainedVariance       | 0.887      |
| Iteration               | 269        |
| ItrTime                 | 7.87       |
| LossAfter               | -0.446241  |
| LossBefore              | -0.420726  |
| MaxReturn               | 1.58e+03   |
| MeanKL                  | 0.00658356 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 744        |
| NumTrajs                | 15         |
| Perplexity              | 24.688     |
| PolicyExecTime          | 0.466      |
| ProcessExecTime         | 0.0541     |
| StdReturn               | 213        |
| Time                    | 2.19e+03   |
| dLoss                   | 0.0255147  |
----------------------------------------
itr #270 | 
Mem: 696.199219
Obtaining samples...
Obtaining samples for iteration 270...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5129, #subsample_inputs: 5129
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.662      |
| AbsLearnSignalNew       | 0.662      |
| AbsLearningOld          | 0.662      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 11.9583    |
| AveragePolicyStd        | 0.711438   |
| AverageReturn           | 1.02e+03   |
| Entropy                 | 3.20227    |
| EnvExecTime             | 1.83       |
| ExplainedVariance       | 0.767      |
| Iteration               | 270        |
| ItrTime                 | 7.96       |
| LossAfter               | -0.181001  |
| LossBefore              | -0.157298  |
| MaxReturn               | 1.34e+03   |
| MeanKL                  | 0.00951268 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 877        |
| NumTrajs                | 16         |
| Perplexity              | 24.5883    |
| PolicyExecTime          | 0.468      |
| ProcessExecTime         | 0.054      |
| StdReturn               | 106        |
| Time                    | 2.2e+03    |
| dLoss                   | 0.0237036  |
----------------------------------------
itr #271 | 
Mem: 696.199219
Obtaining samples...
Obtaining samples for iteration 271...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5149, #subsample_inputs: 5149
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.746      |
| AbsLearnSignalNew       | 0.746      |
| AbsLearningOld          | 0.746      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 13.0063    |
| AveragePolicyStd        | 0.711469   |
| AverageReturn           | 983        |
| Entropy                 | 3.20411    |
| EnvExecTime             | 1.79       |
| ExplainedVariance       | 0.926      |
| Iteration               | 271        |
| ItrTime                 | 7.88       |
| LossAfter               | -0.39534   |
| LossBefore              | -0.372561  |
| MaxReturn               | 1.15e+03   |
| MeanKL                  | 0.00645144 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 744        |
| NumTrajs                | 17         |
| Perplexity              | 24.6335    |
| PolicyExecTime          | 0.454      |
| ProcessExecTime         | 0.0534     |
| StdReturn               | 113        |
| Time                    | 2.21e+03   |
| dLoss                   | 0.0227789  |
----------------------------------------
itr #272 | 
Mem: 696.199219
Obtaining samples...
Obtaining samples for iteration 272...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5232, #subsample_inputs: 5232
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.691      |
| AbsLearnSignalNew       | 0.691      |
| AbsLearningOld          | 0.691      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 11.8697    |
| AveragePolicyStd        | 0.710751   |
| AverageReturn           | 1.04e+03   |
| Entropy                 | 3.2017     |
| EnvExecTime             | 1.77       |
| ExplainedVariance       | 0.833      |
| Iteration               | 272        |
| ItrTime                 | 7.96       |
| LossAfter               | -0.262883  |
| LossBefore              | -0.233699  |
| MaxReturn               | 1.33e+03   |
| MeanKL                  | 0.00999085 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 839        |
| NumTrajs                | 16         |
| Perplexity              | 24.5743    |
| PolicyExecTime          | 0.448      |
| ProcessExecTime         | 0.0532     |
| StdReturn               | 124        |
| Time                    | 2.22e+03   |
| dLoss                   | 0.0291844  |
----------------------------------------
itr #273 | 
Mem: 696.199219
Obtaining samples...
Obtaining samples for iteration 273...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5186, #subsample_inputs: 5186
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.667      |
| AbsLearnSignalNew       | 0.667      |
| AbsLearningOld          | 0.667      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 11.8718    |
| AveragePolicyStd        | 0.711787   |
| AverageReturn           | 971        |
| Entropy                 | 3.20558    |
| EnvExecTime             | 2.02       |
| ExplainedVariance       | 0.821      |
| Iteration               | 273        |
| ItrTime                 | 8.25       |
| LossAfter               | -0.334362  |
| LossBefore              | -0.308462  |
| MaxReturn               | 1.32e+03   |
| MeanKL                  | 0.00978291 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 580        |
| NumTrajs                | 17         |
| Perplexity              | 24.6699    |
| PolicyExecTime          | 0.504      |
| ProcessExecTime         | 0.0585     |
| StdReturn               | 164        |
| Time                    | 2.23e+03   |
| dLoss                   | 0.0259004  |
----------------------------------------
itr #274 | 
Mem: 696.199219
Obtaining samples...
Obtaining samples for iteration 274...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5872, #subsample_inputs: 5872
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.397     |
| AbsLearnSignalNew       | 0.397     |
| AbsLearningOld          | 0.397     |
| AverageDiscountedReturn | 239       |
| AveragePhiLoss          | 9.70124   |
| AveragePolicyStd        | 0.710473  |
| AverageReturn           | 1.1e+03   |
| Entropy                 | 3.19867   |
| EnvExecTime             | 2.13      |
| ExplainedVariance       | -3.09     |
| Iteration               | 274       |
| ItrTime                 | 8.96      |
| LossAfter               | 0.185796  |
| LossBefore              | 0.198257  |
| MaxReturn               | 2.28e+03  |
| MeanKL                  | 0.0066943 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 829       |
| NumTrajs                | 16        |
| Perplexity              | 24.4999   |
| PolicyExecTime          | 0.533     |
| ProcessExecTime         | 0.0645    |
| StdReturn               | 319       |
| Time                    | 2.24e+03  |
| dLoss                   | 0.0124606 |
---------------------------------------
itr #275 | 
Mem: 696.199219
Obtaining samples...
Obtaining samples for iteration 275...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5031, #subsample_inputs: 5031
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.735      |
| AbsLearnSignalNew       | 0.735      |
| AbsLearningOld          | 0.735      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 12.2776    |
| AveragePolicyStd        | 0.707615   |
| AverageReturn           | 1.01e+03   |
| Entropy                 | 3.18472    |
| EnvExecTime             | 1.69       |
| ExplainedVariance       | 0.881      |
| Iteration               | 275        |
| ItrTime                 | 7.78       |
| LossAfter               | 0.965413   |
| LossBefore              | 0.990439   |
| MaxReturn               | 1.5e+03    |
| MeanKL                  | 0.00646186 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 755        |
| NumTrajs                | 16         |
| Perplexity              | 24.1604    |
| PolicyExecTime          | 0.43       |
| ProcessExecTime         | 0.0518     |
| StdReturn               | 179        |
| Time                    | 2.24e+03   |
| dLoss                   | 0.0250263  |
----------------------------------------
itr #276 | 
Mem: 696.199219
Obtaining samples...
Obtaining samples for iteration 276...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5123, #subsample_inputs: 5123
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.629      |
| AbsLearnSignalNew       | 0.629      |
| AbsLearningOld          | 0.629      |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 12.6629    |
| AveragePolicyStd        | 0.706102   |
| AverageReturn           | 1.14e+03   |
| Entropy                 | 3.1775     |
| EnvExecTime             | 2.08       |
| ExplainedVariance       | 0.644      |
| Iteration               | 276        |
| ItrTime                 | 8.23       |
| LossAfter               | 0.961929   |
| LossBefore              | 0.983692   |
| MaxReturn               | 2.03e+03   |
| MeanKL                  | 0.00643413 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 851        |
| NumTrajs                | 14         |
| Perplexity              | 23.9868    |
| PolicyExecTime          | 0.514      |
| ProcessExecTime         | 0.0647     |
| StdReturn               | 319        |
| Time                    | 2.25e+03   |
| dLoss                   | 0.0217631  |
----------------------------------------
itr #277 | 
Mem: 696.199219
Obtaining samples...
Obtaining samples for iteration 277...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5125, #subsample_inputs: 5125
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.753      |
| AbsLearnSignalNew       | 0.753      |
| AbsLearningOld          | 0.753      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 13.5466    |
| AveragePolicyStd        | 0.706807   |
| AverageReturn           | 1.05e+03   |
| Entropy                 | 3.18169    |
| EnvExecTime             | 2.18       |
| ExplainedVariance       | 0.876      |
| Iteration               | 277        |
| ItrTime                 | 8.4        |
| LossAfter               | 0.198948   |
| LossBefore              | 0.218964   |
| MaxReturn               | 2.37e+03   |
| MeanKL                  | 0.00650166 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 761        |
| NumTrajs                | 15         |
| Perplexity              | 24.0875    |
| PolicyExecTime          | 0.541      |
| ProcessExecTime         | 0.0679     |
| StdReturn               | 393        |
| Time                    | 2.26e+03   |
| dLoss                   | 0.0200154  |
----------------------------------------
itr #278 | 
Mem: 697.199219
Obtaining samples...
Obtaining samples for iteration 278...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5041, #subsample_inputs: 5041
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.729      |
| AbsLearnSignalNew       | 0.729      |
| AbsLearningOld          | 0.729      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 13.6291    |
| AveragePolicyStd        | 0.705702   |
| AverageReturn           | 1.21e+03   |
| Entropy                 | 3.17755    |
| EnvExecTime             | 1.87       |
| ExplainedVariance       | 0.784      |
| Iteration               | 278        |
| ItrTime                 | 7.91       |
| LossAfter               | -0.0556186 |
| LossBefore              | -0.0350424 |
| MaxReturn               | 1.65e+03   |
| MeanKL                  | 0.00642907 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 779        |
| NumTrajs                | 13         |
| Perplexity              | 23.988     |
| PolicyExecTime          | 0.469      |
| ProcessExecTime         | 0.0545     |
| StdReturn               | 262        |
| Time                    | 2.27e+03   |
| dLoss                   | 0.0205761  |
----------------------------------------
itr #279 | 
Mem: 697.199219
Obtaining samples...
Obtaining samples for iteration 279...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5077, #subsample_inputs: 5077
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.635      |
| AbsLearnSignalNew       | 0.635      |
| AbsLearningOld          | 0.635      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 12.3919    |
| AveragePolicyStd        | 0.701554   |
| AverageReturn           | 1.12e+03   |
| Entropy                 | 3.16029    |
| EnvExecTime             | 1.98       |
| ExplainedVariance       | 0.714      |
| Iteration               | 279        |
| ItrTime                 | 8.12       |
| LossAfter               | -0.869511  |
| LossBefore              | -0.849947  |
| MaxReturn               | 1.79e+03   |
| MeanKL                  | 0.00653698 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 692        |
| NumTrajs                | 14         |
| Perplexity              | 23.5773    |
| PolicyExecTime          | 0.494      |
| ProcessExecTime         | 0.0594     |
| StdReturn               | 292        |
| Time                    | 2.28e+03   |
| dLoss                   | 0.0195633  |
----------------------------------------
itr #280 | 
Mem: 697.199219
Obtaining samples...
Obtaining samples for iteration 280...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5153, #subsample_inputs: 5153
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.739      |
| AbsLearnSignalNew       | 0.739      |
| AbsLearningOld          | 0.739      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 13.2108    |
| AveragePolicyStd        | 0.698591   |
| AverageReturn           | 1.11e+03   |
| Entropy                 | 3.1447     |
| EnvExecTime             | 2.17       |
| ExplainedVariance       | 0.897      |
| Iteration               | 280        |
| ItrTime                 | 8.41       |
| LossAfter               | 0.17031    |
| LossBefore              | 0.18972    |
| MaxReturn               | 1.53e+03   |
| MeanKL                  | 0.00650052 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 785        |
| NumTrajs                | 15         |
| Perplexity              | 23.2126    |
| PolicyExecTime          | 0.546      |
| ProcessExecTime         | 0.0623     |
| StdReturn               | 172        |
| Time                    | 2.29e+03   |
| dLoss                   | 0.0194103  |
----------------------------------------
itr #281 | 
Mem: 697.199219
Obtaining samples...
Obtaining samples for iteration 281...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5264, #subsample_inputs: 5264
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.644      |
| AbsLearnSignalNew       | 0.644      |
| AbsLearningOld          | 0.644      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 13.6355    |
| AveragePolicyStd        | 0.697889   |
| AverageReturn           | 1.04e+03   |
| Entropy                 | 3.14108    |
| EnvExecTime             | 2.05       |
| ExplainedVariance       | 0.726      |
| Iteration               | 281        |
| ItrTime                 | 8.35       |
| LossAfter               | -0.188448  |
| LossBefore              | -0.167794  |
| MaxReturn               | 1.52e+03   |
| MeanKL                  | 0.00997609 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 827        |
| NumTrajs                | 16         |
| Perplexity              | 23.1288    |
| PolicyExecTime          | 0.511      |
| ProcessExecTime         | 0.0604     |
| StdReturn               | 158        |
| Time                    | 2.29e+03   |
| dLoss                   | 0.0206534  |
----------------------------------------
itr #282 | 
Mem: 697.199219
Obtaining samples...
Obtaining samples for iteration 282...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5017, #subsample_inputs: 5017
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.757      |
| AbsLearnSignalNew       | 0.757      |
| AbsLearningOld          | 0.757      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 13.38      |
| AveragePolicyStd        | 0.694817   |
| AverageReturn           | 1.02e+03   |
| Entropy                 | 3.12395    |
| EnvExecTime             | 2.03       |
| ExplainedVariance       | 0.902      |
| Iteration               | 282        |
| ItrTime                 | 8.21       |
| LossAfter               | 0.544713   |
| LossBefore              | 0.565698   |
| MaxReturn               | 1.33e+03   |
| MeanKL                  | 0.00643825 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 787        |
| NumTrajs                | 16         |
| Perplexity              | 22.7361    |
| PolicyExecTime          | 0.511      |
| ProcessExecTime         | 0.0602     |
| StdReturn               | 136        |
| Time                    | 2.3e+03    |
| dLoss                   | 0.0209848  |
----------------------------------------
itr #283 | 
Mem: 697.199219
Obtaining samples...
Obtaining samples for iteration 283...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5132, #subsample_inputs: 5132
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.771      |
| AbsLearnSignalNew       | 0.771      |
| AbsLearningOld          | 0.771      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 13.7983    |
| AveragePolicyStd        | 0.694263   |
| AverageReturn           | 1.1e+03    |
| Entropy                 | 3.12577    |
| EnvExecTime             | 1.81       |
| ExplainedVariance       | 0.933      |
| Iteration               | 283        |
| ItrTime                 | 7.94       |
| LossAfter               | 0.508525   |
| LossBefore              | 0.531423   |
| MaxReturn               | 1.55e+03   |
| MeanKL                  | 0.00969219 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 900        |
| NumTrajs                | 15         |
| Perplexity              | 22.7774    |
| PolicyExecTime          | 0.454      |
| ProcessExecTime         | 0.0555     |
| StdReturn               | 158        |
| Time                    | 2.31e+03   |
| dLoss                   | 0.022898   |
----------------------------------------
itr #284 | 
Mem: 697.199219
Obtaining samples...
Obtaining samples for iteration 284...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5133, #subsample_inputs: 5133
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.295      |
| AbsLearnSignalNew       | 0.295      |
| AbsLearningOld          | 0.295      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 16.3642    |
| AveragePolicyStd        | 0.694833   |
| AverageReturn           | 1.28e+03   |
| Entropy                 | 3.12619    |
| EnvExecTime             | 2.19       |
| ExplainedVariance       | -38.1      |
| Iteration               | 284        |
| ItrTime                 | 8.41       |
| LossAfter               | 0.28942    |
| LossBefore              | 0.313866   |
| MaxReturn               | 2.31e+03   |
| MeanKL                  | 0.00995473 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 934        |
| NumTrajs                | 12         |
| Perplexity              | 22.7869    |
| PolicyExecTime          | 0.557      |
| ProcessExecTime         | 0.0627     |
| StdReturn               | 363        |
| Time                    | 2.32e+03   |
| dLoss                   | 0.024446   |
----------------------------------------
itr #285 | 
Mem: 697.203125
Obtaining samples...
Obtaining samples for iteration 285...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5504, #subsample_inputs: 5504
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.739     |
| AbsLearnSignalNew       | 0.739     |
| AbsLearningOld          | 0.739     |
| AverageDiscountedReturn | 237       |
| AveragePhiLoss          | 13.8721   |
| AveragePolicyStd        | 0.6932    |
| AverageReturn           | 1.33e+03  |
| Entropy                 | 3.11904   |
| EnvExecTime             | 2.2       |
| ExplainedVariance       | 0.871     |
| Iteration               | 285       |
| ItrTime                 | 8.7       |
| LossAfter               | 0.0853402 |
| LossBefore              | 0.102944  |
| MaxReturn               | 2.36e+03  |
| MeanKL                  | 0.0065433 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 815       |
| NumTrajs                | 12        |
| Perplexity              | 22.6246   |
| PolicyExecTime          | 0.555     |
| ProcessExecTime         | 0.0631    |
| StdReturn               | 503       |
| Time                    | 2.33e+03  |
| dLoss                   | 0.0176033 |
---------------------------------------
itr #286 | 
Mem: 697.449219
Obtaining samples...
Obtaining samples for iteration 286...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5247, #subsample_inputs: 5247
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.695      |
| AbsLearnSignalNew       | 0.695      |
| AbsLearningOld          | 0.695      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 14.4185    |
| AveragePolicyStd        | 0.693546   |
| AverageReturn           | 1.34e+03   |
| Entropy                 | 3.1103     |
| EnvExecTime             | 2.12       |
| ExplainedVariance       | 0.793      |
| Iteration               | 286        |
| ItrTime                 | 8.39       |
| LossAfter               | -0.158303  |
| LossBefore              | -0.137189  |
| MaxReturn               | 2.3e+03    |
| MeanKL                  | 0.00647364 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 962        |
| NumTrajs                | 12         |
| Perplexity              | 22.4279    |
| PolicyExecTime          | 0.535      |
| ProcessExecTime         | 0.0595     |
| StdReturn               | 347        |
| Time                    | 2.34e+03   |
| dLoss                   | 0.0211134  |
----------------------------------------
itr #287 | 
Mem: 697.449219
Obtaining samples...
Obtaining samples for iteration 287...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5195, #subsample_inputs: 5195
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.76       |
| AbsLearnSignalNew       | 0.76       |
| AbsLearningOld          | 0.76       |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 13.5125    |
| AveragePolicyStd        | 0.695908   |
| AverageReturn           | 1.2e+03    |
| Entropy                 | 3.11832    |
| EnvExecTime             | 2.3        |
| ExplainedVariance       | 0.838      |
| Iteration               | 287        |
| ItrTime                 | 8.62       |
| LossAfter               | -0.513914  |
| LossBefore              | -0.486943  |
| MaxReturn               | 2.32e+03   |
| MeanKL                  | 0.00995431 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 921        |
| NumTrajs                | 13         |
| Perplexity              | 22.6084    |
| PolicyExecTime          | 0.571      |
| ProcessExecTime         | 0.0674     |
| StdReturn               | 348        |
| Time                    | 2.34e+03   |
| dLoss                   | 0.0269717  |
----------------------------------------
itr #288 | 
Mem: 697.449219
Obtaining samples...
Obtaining samples for iteration 288...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5209, #subsample_inputs: 5209
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.682      |
| AbsLearnSignalNew       | 0.682      |
| AbsLearningOld          | 0.682      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 12.2721    |
| AveragePolicyStd        | 0.702913   |
| AverageReturn           | 1.23e+03   |
| Entropy                 | 3.14415    |
| EnvExecTime             | 1.85       |
| ExplainedVariance       | 0.751      |
| Iteration               | 288        |
| ItrTime                 | 8.04       |
| LossAfter               | -0.56125   |
| LossBefore              | -0.537893  |
| MaxReturn               | 2.23e+03   |
| MeanKL                  | 0.00980414 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 949        |
| NumTrajs                | 13         |
| Perplexity              | 23.2       |
| PolicyExecTime          | 0.466      |
| ProcessExecTime         | 0.056      |
| StdReturn               | 340        |
| Time                    | 2.35e+03   |
| dLoss                   | 0.023357   |
----------------------------------------
itr #289 | 
Mem: 697.972656
Obtaining samples...
Obtaining samples for iteration 289...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5152, #subsample_inputs: 5152
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.668      |
| AbsLearnSignalNew       | 0.668      |
| AbsLearningOld          | 0.668      |
| AverageDiscountedReturn | 236        |
| AveragePhiLoss          | 13.9249    |
| AveragePolicyStd        | 0.702777   |
| AverageReturn           | 1.26e+03   |
| Entropy                 | 3.14726    |
| EnvExecTime             | 2.02       |
| ExplainedVariance       | 0.633      |
| Iteration               | 289        |
| ItrTime                 | 8.24       |
| LossAfter               | 0.15607    |
| LossBefore              | 0.181432   |
| MaxReturn               | 2.35e+03   |
| MeanKL                  | 0.00984533 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 815        |
| NumTrajs                | 12         |
| Perplexity              | 23.2722    |
| PolicyExecTime          | 0.514      |
| ProcessExecTime         | 0.0575     |
| StdReturn               | 397        |
| Time                    | 2.36e+03   |
| dLoss                   | 0.0253622  |
----------------------------------------
itr #290 | 
Mem: 697.972656
Obtaining samples...
Obtaining samples for iteration 290...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5067, #subsample_inputs: 5067
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.753     |
| AbsLearnSignalNew       | 0.753     |
| AbsLearningOld          | 0.753     |
| AverageDiscountedReturn | 239       |
| AveragePhiLoss          | 15.2139   |
| AveragePolicyStd        | 0.705261  |
| AverageReturn           | 1.21e+03  |
| Entropy                 | 3.154     |
| EnvExecTime             | 2.12      |
| ExplainedVariance       | 0.823     |
| Iteration               | 290       |
| ItrTime                 | 8.28      |
| LossAfter               | 0.0703905 |
| LossBefore              | 0.0934504 |
| MaxReturn               | 2.14e+03  |
| MeanKL                  | 0.0064368 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 729       |
| NumTrajs                | 13        |
| Perplexity              | 23.4296   |
| PolicyExecTime          | 0.525     |
| ProcessExecTime         | 0.0636    |
| StdReturn               | 401       |
| Time                    | 2.37e+03  |
| dLoss                   | 0.0230598 |
---------------------------------------
itr #291 | 
Mem: 697.972656
Obtaining samples...
Obtaining samples for iteration 291...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5032, #subsample_inputs: 5032
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.655      |
| AbsLearnSignalNew       | 0.655      |
| AbsLearningOld          | 0.655      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 14.4915    |
| AveragePolicyStd        | 0.70214    |
| AverageReturn           | 1.19e+03   |
| Entropy                 | 3.14142    |
| EnvExecTime             | 1.85       |
| ExplainedVariance       | 0.724      |
| Iteration               | 291        |
| ItrTime                 | 7.9        |
| LossAfter               | 0.277624   |
| LossBefore              | 0.298815   |
| MaxReturn               | 2.45e+03   |
| MeanKL                  | 0.00641411 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 832        |
| NumTrajs                | 13         |
| Perplexity              | 23.1367    |
| PolicyExecTime          | 0.465      |
| ProcessExecTime         | 0.0557     |
| StdReturn               | 396        |
| Time                    | 2.38e+03   |
| dLoss                   | 0.0211903  |
----------------------------------------
itr #292 | 
Mem: 697.972656
Obtaining samples...
Obtaining samples for iteration 292...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5157, #subsample_inputs: 5157
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.749      |
| AbsLearnSignalNew       | 0.749      |
| AbsLearningOld          | 0.748      |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 14.2039    |
| AveragePolicyStd        | 0.699494   |
| AverageReturn           | 1.3e+03    |
| Entropy                 | 3.12973    |
| EnvExecTime             | 1.84       |
| ExplainedVariance       | 0.818      |
| Iteration               | 292        |
| ItrTime                 | 7.99       |
| LossAfter               | 0.205018   |
| LossBefore              | 0.23199    |
| MaxReturn               | 2.39e+03   |
| MeanKL                  | 0.00996169 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.01e+03   |
| NumTrajs                | 12         |
| Perplexity              | 22.8677    |
| PolicyExecTime          | 0.471      |
| ProcessExecTime         | 0.0543     |
| StdReturn               | 392        |
| Time                    | 2.39e+03   |
| dLoss                   | 0.0269719  |
----------------------------------------
itr #293 | 
Mem: 699.460938
Obtaining samples...
Obtaining samples for iteration 293...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5133, #subsample_inputs: 5133
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.758      |
| AbsLearnSignalNew       | 0.758      |
| AbsLearningOld          | 0.758      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 13.8318    |
| AveragePolicyStd        | 0.700994   |
| AverageReturn           | 1.4e+03    |
| Entropy                 | 3.13417    |
| EnvExecTime             | 1.77       |
| ExplainedVariance       | 0.826      |
| Iteration               | 293        |
| ItrTime                 | 7.83       |
| LossAfter               | 0.644366   |
| LossBefore              | 0.669991   |
| MaxReturn               | 2.47e+03   |
| MeanKL                  | 0.00986235 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 779        |
| NumTrajs                | 11         |
| Perplexity              | 22.9695    |
| PolicyExecTime          | 0.449      |
| ProcessExecTime         | 0.0529     |
| StdReturn               | 489        |
| Time                    | 2.39e+03   |
| dLoss                   | 0.0256256  |
----------------------------------------
itr #294 | 
Mem: 699.714844
Obtaining samples...
Obtaining samples for iteration 294...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5382, #subsample_inputs: 5382
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.647      |
| AbsLearnSignalNew       | 0.647      |
| AbsLearningOld          | 0.647      |
| AverageDiscountedReturn | 236        |
| AveragePhiLoss          | 13.2332    |
| AveragePolicyStd        | 0.705253   |
| AverageReturn           | 1.23e+03   |
| Entropy                 | 3.15206    |
| EnvExecTime             | 2.12       |
| ExplainedVariance       | 0.594      |
| Iteration               | 294        |
| ItrTime                 | 8.53       |
| LossAfter               | 0.303819   |
| LossBefore              | 0.32341    |
| MaxReturn               | 1.92e+03   |
| MeanKL                  | 0.00662958 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 700        |
| NumTrajs                | 13         |
| Perplexity              | 23.3842    |
| PolicyExecTime          | 0.538      |
| ProcessExecTime         | 0.0598     |
| StdReturn               | 298        |
| Time                    | 2.4e+03    |
| dLoss                   | 0.0195905  |
----------------------------------------
itr #295 | 
Mem: 699.714844
Obtaining samples...
Obtaining samples for iteration 295...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5154, #subsample_inputs: 5154
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.682      |
| AbsLearnSignalNew       | 0.682      |
| AbsLearningOld          | 0.682      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 14.1051    |
| AveragePolicyStd        | 0.705687   |
| AverageReturn           | 1.04e+03   |
| Entropy                 | 3.1559     |
| EnvExecTime             | 1.67       |
| ExplainedVariance       | 0.855      |
| Iteration               | 295        |
| ItrTime                 | 7.79       |
| LossAfter               | -0.515292  |
| LossBefore              | -0.489662  |
| MaxReturn               | 1.43e+03   |
| MeanKL                  | 0.00642879 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 752        |
| NumTrajs                | 16         |
| Perplexity              | 23.4743    |
| PolicyExecTime          | 0.426      |
| ProcessExecTime         | 0.0512     |
| StdReturn               | 162        |
| Time                    | 2.41e+03   |
| dLoss                   | 0.0256299  |
----------------------------------------
itr #296 | 
Mem: 699.714844
Obtaining samples...
Obtaining samples for iteration 296...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5160, #subsample_inputs: 5160
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.54       |
| AbsLearnSignalNew       | 0.54       |
| AbsLearningOld          | 0.54       |
| AverageDiscountedReturn | 230        |
| AveragePhiLoss          | 12.2137    |
| AveragePolicyStd        | 0.703802   |
| AverageReturn           | 1.01e+03   |
| Entropy                 | 3.14261    |
| EnvExecTime             | 1.87       |
| ExplainedVariance       | 0.594      |
| Iteration               | 296        |
| ItrTime                 | 8.07       |
| LossAfter               | -0.629053  |
| LossBefore              | -0.599058  |
| MaxReturn               | 1.55e+03   |
| MeanKL                  | 0.00981332 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 248        |
| NumTrajs                | 16         |
| Perplexity              | 23.1643    |
| PolicyExecTime          | 0.469      |
| ProcessExecTime         | 0.0551     |
| StdReturn               | 325        |
| Time                    | 2.42e+03   |
| dLoss                   | 0.0299954  |
----------------------------------------
itr #297 | 
Mem: 699.714844
Obtaining samples...
Obtaining samples for iteration 297...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5220, #subsample_inputs: 5220
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.684      |
| AbsLearnSignalNew       | 0.684      |
| AbsLearningOld          | 0.684      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 12.912     |
| AveragePolicyStd        | 0.704515   |
| AverageReturn           | 1.24e+03   |
| Entropy                 | 3.14971    |
| EnvExecTime             | 1.76       |
| ExplainedVariance       | 0.748      |
| Iteration               | 297        |
| ItrTime                 | 7.94       |
| LossAfter               | -0.0745093 |
| LossBefore              | -0.048257  |
| MaxReturn               | 1.88e+03   |
| MeanKL                  | 0.00998086 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.03e+03   |
| NumTrajs                | 13         |
| Perplexity              | 23.3292    |
| PolicyExecTime          | 0.451      |
| ProcessExecTime         | 0.0535     |
| StdReturn               | 281        |
| Time                    | 2.43e+03   |
| dLoss                   | 0.0262523  |
----------------------------------------
itr #298 | 
Mem: 699.714844
Obtaining samples...
Obtaining samples for iteration 298...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5595, #subsample_inputs: 5595
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.493     |
| AbsLearnSignalNew       | 0.493     |
| AbsLearningOld          | 0.493     |
| AverageDiscountedReturn | 235       |
| AveragePhiLoss          | 13.0424   |
| AveragePolicyStd        | 0.700908  |
| AverageReturn           | 1.26e+03  |
| Entropy                 | 3.13581   |
| EnvExecTime             | 2.21      |
| ExplainedVariance       | -0.62     |
| Iteration               | 298       |
| ItrTime                 | 8.8       |
| LossAfter               | -0.14398  |
| LossBefore              | -0.113293 |
| MaxReturn               | 2.82e+03  |
| MeanKL                  | 0.0098906 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 879       |
| NumTrajs                | 13        |
| Perplexity              | 23.0073   |
| PolicyExecTime          | 0.553     |
| ProcessExecTime         | 0.0659    |
| StdReturn               | 572       |
| Time                    | 2.43e+03  |
| dLoss                   | 0.0306872 |
---------------------------------------
itr #299 | 
Mem: 699.714844
Obtaining samples...
Obtaining samples for iteration 299...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5093, #subsample_inputs: 5093
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.722      |
| AbsLearnSignalNew       | 0.722      |
| AbsLearningOld          | 0.722      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 14.0757    |
| AveragePolicyStd        | 0.705002   |
| AverageReturn           | 1.03e+03   |
| Entropy                 | 3.15536    |
| EnvExecTime             | 1.85       |
| ExplainedVariance       | 0.874      |
| Iteration               | 299        |
| ItrTime                 | 7.92       |
| LossAfter               | 0.160341   |
| LossBefore              | 0.188221   |
| MaxReturn               | 1.33e+03   |
| MeanKL                  | 0.00996001 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 759        |
| NumTrajs                | 16         |
| Perplexity              | 23.4616    |
| PolicyExecTime          | 0.464      |
| ProcessExecTime         | 0.0546     |
| StdReturn               | 185        |
| Time                    | 2.44e+03   |
| dLoss                   | 0.027881   |
----------------------------------------
itr #300 | 
Mem: 699.960938
Obtaining samples...
Obtaining samples for iteration 300...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5295, #subsample_inputs: 5295
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.737      |
| AbsLearnSignalNew       | 0.737      |
| AbsLearningOld          | 0.737      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 13.4441    |
| AveragePolicyStd        | 0.702971   |
| AverageReturn           | 1.12e+03   |
| Entropy                 | 3.14649    |
| EnvExecTime             | 2.11       |
| ExplainedVariance       | 0.896      |
| Iteration               | 300        |
| ItrTime                 | 8.42       |
| LossAfter               | 0.697895   |
| LossBefore              | 0.719554   |
| MaxReturn               | 1.5e+03    |
| MeanKL                  | 0.00641063 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 791        |
| NumTrajs                | 15         |
| Perplexity              | 23.2544    |
| PolicyExecTime          | 0.533      |
| ProcessExecTime         | 0.0624     |
| StdReturn               | 193        |
| Time                    | 2.45e+03   |
| dLoss                   | 0.0216587  |
----------------------------------------
itr #301 | 
Mem: 699.960938
Obtaining samples...
Obtaining samples for iteration 301...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5232, #subsample_inputs: 5232
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.767      |
| AbsLearnSignalNew       | 0.767      |
| AbsLearningOld          | 0.767      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 14.0442    |
| AveragePolicyStd        | 0.707014   |
| AverageReturn           | 1.11e+03   |
| Entropy                 | 3.16413    |
| EnvExecTime             | 1.81       |
| ExplainedVariance       | 0.924      |
| Iteration               | 301        |
| ItrTime                 | 7.95       |
| LossAfter               | -0.291308  |
| LossBefore              | -0.268797  |
| MaxReturn               | 1.62e+03   |
| MeanKL                  | 0.00990205 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 750        |
| NumTrajs                | 15         |
| Perplexity              | 23.6682    |
| PolicyExecTime          | 0.462      |
| ProcessExecTime         | 0.054      |
| StdReturn               | 253        |
| Time                    | 2.46e+03   |
| dLoss                   | 0.0225106  |
----------------------------------------
itr #302 | 
Mem: 699.960938
Obtaining samples...
Obtaining samples for iteration 302...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5154, #subsample_inputs: 5154
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.606      |
| AbsLearnSignalNew       | 0.606      |
| AbsLearningOld          | 0.606      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 15.879     |
| AveragePolicyStd        | 0.705647   |
| AverageReturn           | 987        |
| Entropy                 | 3.1595     |
| EnvExecTime             | 1.76       |
| ExplainedVariance       | 0.773      |
| Iteration               | 302        |
| ItrTime                 | 7.88       |
| LossAfter               | -1.16944   |
| LossBefore              | -1.13659   |
| MaxReturn               | 1.35e+03   |
| MeanKL                  | 0.00989883 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 236        |
| NumTrajs                | 17         |
| Perplexity              | 23.5588    |
| PolicyExecTime          | 0.45       |
| ProcessExecTime         | 0.0525     |
| StdReturn               | 225        |
| Time                    | 2.47e+03   |
| dLoss                   | 0.0328536  |
----------------------------------------
itr #303 | 
Mem: 699.960938
Obtaining samples...
Obtaining samples for iteration 303...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5225, #subsample_inputs: 5225
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.626      |
| AbsLearnSignalNew       | 0.626      |
| AbsLearningOld          | 0.626      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 12.5253    |
| AveragePolicyStd        | 0.704017   |
| AverageReturn           | 1.11e+03   |
| Entropy                 | 3.15334    |
| EnvExecTime             | 1.74       |
| ExplainedVariance       | 0.734      |
| Iteration               | 303        |
| ItrTime                 | 7.91       |
| LossAfter               | -0.554047  |
| LossBefore              | -0.534912  |
| MaxReturn               | 1.75e+03   |
| MeanKL                  | 0.00648071 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 847        |
| NumTrajs                | 15         |
| Perplexity              | 23.4143    |
| PolicyExecTime          | 0.442      |
| ProcessExecTime         | 0.0522     |
| StdReturn               | 205        |
| Time                    | 2.47e+03   |
| dLoss                   | 0.0191344  |
----------------------------------------
itr #304 | 
Mem: 699.960938
Obtaining samples...
Obtaining samples for iteration 304...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5021, #subsample_inputs: 5021
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.753      |
| AbsLearnSignalNew       | 0.753      |
| AbsLearningOld          | 0.753      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 14.5854    |
| AveragePolicyStd        | 0.700863   |
| AverageReturn           | 1.16e+03   |
| Entropy                 | 3.14254    |
| EnvExecTime             | 1.66       |
| ExplainedVariance       | 0.919      |
| Iteration               | 304        |
| ItrTime                 | 7.6        |
| LossAfter               | -0.594752  |
| LossBefore              | -0.566928  |
| MaxReturn               | 1.59e+03   |
| MeanKL                  | 0.00966281 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 781        |
| NumTrajs                | 14         |
| Perplexity              | 23.1625    |
| PolicyExecTime          | 0.421      |
| ProcessExecTime         | 0.0501     |
| StdReturn               | 232        |
| Time                    | 2.48e+03   |
| dLoss                   | 0.027824   |
----------------------------------------
itr #305 | 
Mem: 699.960938
Obtaining samples...
Obtaining samples for iteration 305...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5016, #subsample_inputs: 5016
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.688      |
| AbsLearnSignalNew       | 0.688      |
| AbsLearningOld          | 0.688      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 12.2699    |
| AveragePolicyStd        | 0.701717   |
| AverageReturn           | 1.07e+03   |
| Entropy                 | 3.14641    |
| EnvExecTime             | 1.89       |
| ExplainedVariance       | 0.861      |
| Iteration               | 305        |
| ItrTime                 | 7.93       |
| LossAfter               | -0.185114  |
| LossBefore              | -0.157547  |
| MaxReturn               | 1.32e+03   |
| MeanKL                  | 0.00956478 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 837        |
| NumTrajs                | 15         |
| Perplexity              | 23.2525    |
| PolicyExecTime          | 0.467      |
| ProcessExecTime         | 0.0569     |
| StdReturn               | 141        |
| Time                    | 2.49e+03   |
| dLoss                   | 0.0275663  |
----------------------------------------
itr #306 | 
Mem: 699.960938
Obtaining samples...
Obtaining samples for iteration 306...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5106, #subsample_inputs: 5106
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.566      |
| AbsLearnSignalNew       | 0.566      |
| AbsLearningOld          | 0.566      |
| AverageDiscountedReturn | 230        |
| AveragePhiLoss          | 12.088     |
| AveragePolicyStd        | 0.706349   |
| AverageReturn           | 959        |
| Entropy                 | 3.16478    |
| EnvExecTime             | 2.13       |
| ExplainedVariance       | 0.676      |
| Iteration               | 306        |
| ItrTime                 | 8.33       |
| LossAfter               | -0.0787696 |
| LossBefore              | -0.0470312 |
| MaxReturn               | 1.55e+03   |
| MeanKL                  | 0.00990374 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 241        |
| NumTrajs                | 17         |
| Perplexity              | 23.6835    |
| PolicyExecTime          | 0.524      |
| ProcessExecTime         | 0.063      |
| StdReturn               | 331        |
| Time                    | 2.5e+03    |
| dLoss                   | 0.0317383  |
----------------------------------------
itr #307 | 
Mem: 699.960938
Obtaining samples...
Obtaining samples for iteration 307...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5015, #subsample_inputs: 5015
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.792      |
| AbsLearnSignalNew       | 0.792      |
| AbsLearningOld          | 0.792      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 12.8537    |
| AveragePolicyStd        | 0.70546    |
| AverageReturn           | 1.15e+03   |
| Entropy                 | 3.16566    |
| EnvExecTime             | 1.69       |
| ExplainedVariance       | 0.888      |
| Iteration               | 307        |
| ItrTime                 | 7.71       |
| LossAfter               | -0.202784  |
| LossBefore              | -0.177304  |
| MaxReturn               | 1.67e+03   |
| MeanKL                  | 0.00645414 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 850        |
| NumTrajs                | 14         |
| Perplexity              | 23.7043    |
| PolicyExecTime          | 0.433      |
| ProcessExecTime         | 0.0516     |
| StdReturn               | 203        |
| Time                    | 2.51e+03   |
| dLoss                   | 0.0254806  |
----------------------------------------
itr #308 | 
Mem: 699.960938
Obtaining samples...
Obtaining samples for iteration 308...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5133, #subsample_inputs: 5133
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.595      |
| AbsLearnSignalNew       | 0.595      |
| AbsLearningOld          | 0.595      |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 13.0774    |
| AveragePolicyStd        | 0.706651   |
| AverageReturn           | 1.12e+03   |
| Entropy                 | 3.17103    |
| EnvExecTime             | 2.13       |
| ExplainedVariance       | 0.559      |
| Iteration               | 308        |
| ItrTime                 | 8.3        |
| LossAfter               | 0.47638    |
| LossBefore              | 0.502779   |
| MaxReturn               | 1.98e+03   |
| MeanKL                  | 0.00972328 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 797        |
| NumTrajs                | 14         |
| Perplexity              | 23.8321    |
| PolicyExecTime          | 0.53       |
| ProcessExecTime         | 0.0621     |
| StdReturn               | 317        |
| Time                    | 2.51e+03   |
| dLoss                   | 0.0263995  |
----------------------------------------
itr #309 | 
Mem: 699.960938
Obtaining samples...
Obtaining samples for iteration 309...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5245, #subsample_inputs: 5245
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.7        |
| AbsLearnSignalNew       | 0.7        |
| AbsLearningOld          | 0.7        |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 13.0977    |
| AveragePolicyStd        | 0.708754   |
| AverageReturn           | 1.21e+03   |
| Entropy                 | 3.18148    |
| EnvExecTime             | 2.1        |
| ExplainedVariance       | 0.861      |
| Iteration               | 309        |
| ItrTime                 | 8.42       |
| LossAfter               | -0.0882133 |
| LossBefore              | -0.0605321 |
| MaxReturn               | 1.71e+03   |
| MeanKL                  | 0.00991668 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 862        |
| NumTrajs                | 14         |
| Perplexity              | 24.0825    |
| PolicyExecTime          | 0.53       |
| ProcessExecTime         | 0.0595     |
| StdReturn               | 192        |
| Time                    | 2.52e+03   |
| dLoss                   | 0.0276812  |
----------------------------------------
itr #310 | 
Mem: 699.960938
Obtaining samples...
Obtaining samples for iteration 310...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5403, #subsample_inputs: 5403
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.688      |
| AbsLearnSignalNew       | 0.688      |
| AbsLearningOld          | 0.688      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 13.6128    |
| AveragePolicyStd        | 0.709052   |
| AverageReturn           | 1.25e+03   |
| Entropy                 | 3.18393    |
| EnvExecTime             | 2          |
| ExplainedVariance       | 0.703      |
| Iteration               | 310        |
| ItrTime                 | 8.4        |
| LossAfter               | 0.107048   |
| LossBefore              | 0.12462    |
| MaxReturn               | 2.25e+03   |
| MeanKL                  | 0.00655183 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 893        |
| NumTrajs                | 13         |
| Perplexity              | 24.1413    |
| PolicyExecTime          | 0.499      |
| ProcessExecTime         | 0.0601     |
| StdReturn               | 371        |
| Time                    | 2.53e+03   |
| dLoss                   | 0.0175715  |
----------------------------------------
itr #311 | 
Mem: 699.960938
Obtaining samples...
Obtaining samples for iteration 311...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5341, #subsample_inputs: 5341
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.678      |
| AbsLearnSignalNew       | 0.678      |
| AbsLearningOld          | 0.678      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 14.6979    |
| AveragePolicyStd        | 0.709192   |
| AverageReturn           | 1.16e+03   |
| Entropy                 | 3.18269    |
| EnvExecTime             | 1.86       |
| ExplainedVariance       | 0.756      |
| Iteration               | 311        |
| ItrTime                 | 8.2        |
| LossAfter               | 0.142538   |
| LossBefore              | 0.161951   |
| MaxReturn               | 2.03e+03   |
| MeanKL                  | 0.00670612 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 829        |
| NumTrajs                | 14         |
| Perplexity              | 24.1116    |
| PolicyExecTime          | 0.477      |
| ProcessExecTime         | 0.055      |
| StdReturn               | 302        |
| Time                    | 2.54e+03   |
| dLoss                   | 0.0194139  |
----------------------------------------
itr #312 | 
Mem: 699.960938
Obtaining samples...
Obtaining samples for iteration 312...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5700, #subsample_inputs: 5700
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.649      |
| AbsLearnSignalNew       | 0.649      |
| AbsLearningOld          | 0.649      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 13.973     |
| AveragePolicyStd        | 0.703942   |
| AverageReturn           | 1.08e+03   |
| Entropy                 | 3.15979    |
| EnvExecTime             | 2.21       |
| ExplainedVariance       | 0.781      |
| Iteration               | 312        |
| ItrTime                 | 8.91       |
| LossAfter               | -0.122599  |
| LossBefore              | -0.102047  |
| MaxReturn               | 1.81e+03   |
| MeanKL                  | 0.00647849 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 828        |
| NumTrajs                | 16         |
| Perplexity              | 23.5656    |
| PolicyExecTime          | 0.551      |
| ProcessExecTime         | 0.0668     |
| StdReturn               | 279        |
| Time                    | 2.55e+03   |
| dLoss                   | 0.0205527  |
----------------------------------------
itr #313 | 
Mem: 699.960938
Obtaining samples...
Obtaining samples for iteration 313...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5055, #subsample_inputs: 5055
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.782      |
| AbsLearnSignalNew       | 0.782      |
| AbsLearningOld          | 0.782      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 13.9829    |
| AveragePolicyStd        | 0.704449   |
| AverageReturn           | 972        |
| Entropy                 | 3.16018    |
| EnvExecTime             | 1.94       |
| ExplainedVariance       | 0.917      |
| Iteration               | 313        |
| ItrTime                 | 8.06       |
| LossAfter               | 0.363596   |
| LossBefore              | 0.388732   |
| MaxReturn               | 1.36e+03   |
| MeanKL                  | 0.00994259 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 736        |
| NumTrajs                | 17         |
| Perplexity              | 23.5749    |
| PolicyExecTime          | 0.486      |
| ProcessExecTime         | 0.0573     |
| StdReturn               | 165        |
| Time                    | 2.56e+03   |
| dLoss                   | 0.0251359  |
----------------------------------------
itr #314 | 
Mem: 699.960938
Obtaining samples...
Obtaining samples for iteration 314...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5104, #subsample_inputs: 5104
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.55       |
| AbsLearnSignalNew       | 0.55       |
| AbsLearningOld          | 0.55       |
| AverageDiscountedReturn | 236        |
| AveragePhiLoss          | 14.0667    |
| AveragePolicyStd        | 0.703241   |
| AverageReturn           | 1.02e+03   |
| Entropy                 | 3.15565    |
| EnvExecTime             | 1.92       |
| ExplainedVariance       | 0.667      |
| Iteration               | 314        |
| ItrTime                 | 8.06       |
| LossAfter               | 0.450319   |
| LossBefore              | 0.475606   |
| MaxReturn               | 1.55e+03   |
| MeanKL                  | 0.00975987 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 254        |
| NumTrajs                | 16         |
| Perplexity              | 23.4683    |
| PolicyExecTime          | 0.486      |
| ProcessExecTime         | 0.0572     |
| StdReturn               | 283        |
| Time                    | 2.57e+03   |
| dLoss                   | 0.025286   |
----------------------------------------
itr #315 | 
Mem: 699.960938
Obtaining samples...
Obtaining samples for iteration 315...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5107, #subsample_inputs: 5107
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.674      |
| AbsLearnSignalNew       | 0.674      |
| AbsLearningOld          | 0.675      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 14.6782    |
| AveragePolicyStd        | 0.707642   |
| AverageReturn           | 1.01e+03   |
| Entropy                 | 3.17263    |
| EnvExecTime             | 1.87       |
| ExplainedVariance       | 0.793      |
| Iteration               | 315        |
| ItrTime                 | 8.04       |
| LossAfter               | 0.606115   |
| LossBefore              | 0.625996   |
| MaxReturn               | 1.24e+03   |
| MeanKL                  | 0.00659786 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 793        |
| NumTrajs                | 16         |
| Perplexity              | 23.8701    |
| PolicyExecTime          | 0.473      |
| ProcessExecTime         | 0.0541     |
| StdReturn               | 122        |
| Time                    | 2.57e+03   |
| dLoss                   | 0.0198804  |
----------------------------------------
itr #316 | 
Mem: 699.960938
Obtaining samples...
Obtaining samples for iteration 316...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5005, #subsample_inputs: 5005
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.735      |
| AbsLearnSignalNew       | 0.735      |
| AbsLearningOld          | 0.735      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 14.6302    |
| AveragePolicyStd        | 0.703765   |
| AverageReturn           | 1.07e+03   |
| Entropy                 | 3.15364    |
| EnvExecTime             | 1.71       |
| ExplainedVariance       | 0.842      |
| Iteration               | 316        |
| ItrTime                 | 7.67       |
| LossAfter               | 0.363931   |
| LossBefore              | 0.391681   |
| MaxReturn               | 1.6e+03    |
| MeanKL                  | 0.00978494 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 741        |
| NumTrajs                | 15         |
| Perplexity              | 23.4212    |
| PolicyExecTime          | 0.439      |
| ProcessExecTime         | 0.0512     |
| StdReturn               | 210        |
| Time                    | 2.58e+03   |
| dLoss                   | 0.0277495  |
----------------------------------------
itr #317 | 
Mem: 699.960938
Obtaining samples...
Obtaining samples for iteration 317...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5262, #subsample_inputs: 5262
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.649      |
| AbsLearnSignalNew       | 0.649      |
| AbsLearningOld          | 0.649      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 18.3619    |
| AveragePolicyStd        | 0.705682   |
| AverageReturn           | 1.2e+03    |
| Entropy                 | 3.16371    |
| EnvExecTime             | 1.79       |
| ExplainedVariance       | 0.792      |
| Iteration               | 317        |
| ItrTime                 | 7.98       |
| LossAfter               | 0.148759   |
| LossBefore              | 0.175525   |
| MaxReturn               | 2.11e+03   |
| MeanKL                  | 0.00978646 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 807        |
| NumTrajs                | 14         |
| Perplexity              | 23.6582    |
| PolicyExecTime          | 0.455      |
| ProcessExecTime         | 0.0531     |
| StdReturn               | 341        |
| Time                    | 2.59e+03   |
| dLoss                   | 0.0267657  |
----------------------------------------
itr #318 | 
Mem: 699.960938
Obtaining samples...
Obtaining samples for iteration 318...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5360, #subsample_inputs: 5360
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.767      |
| AbsLearnSignalNew       | 0.767      |
| AbsLearningOld          | 0.767      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 14.4007    |
| AveragePolicyStd        | 0.705563   |
| AverageReturn           | 1.3e+03    |
| Entropy                 | 3.16273    |
| EnvExecTime             | 2.02       |
| ExplainedVariance       | 0.88       |
| Iteration               | 318        |
| ItrTime                 | 8.45       |
| LossAfter               | -0.244224  |
| LossBefore              | -0.223529  |
| MaxReturn               | 1.93e+03   |
| MeanKL                  | 0.00652206 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 860        |
| NumTrajs                | 13         |
| Perplexity              | 23.6351    |
| PolicyExecTime          | 0.513      |
| ProcessExecTime         | 0.0605     |
| StdReturn               | 340        |
| Time                    | 2.6e+03    |
| dLoss                   | 0.020695   |
----------------------------------------
itr #319 | 
Mem: 699.960938
Obtaining samples...
Obtaining samples for iteration 319...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5318, #subsample_inputs: 5318
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.693      |
| AbsLearnSignalNew       | 0.693      |
| AbsLearningOld          | 0.693      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 14.1731    |
| AveragePolicyStd        | 0.702225   |
| AverageReturn           | 1.31e+03   |
| Entropy                 | 3.14644    |
| EnvExecTime             | 2.23       |
| ExplainedVariance       | 0.779      |
| Iteration               | 319        |
| ItrTime                 | 8.62       |
| LossAfter               | 0.355639   |
| LossBefore              | 0.38198    |
| MaxReturn               | 2.15e+03   |
| MeanKL                  | 0.00985814 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 900        |
| NumTrajs                | 12         |
| Perplexity              | 23.253     |
| PolicyExecTime          | 0.575      |
| ProcessExecTime         | 0.0632     |
| StdReturn               | 371        |
| Time                    | 2.61e+03   |
| dLoss                   | 0.0263412  |
----------------------------------------
itr #320 | 
Mem: 700.222656
Obtaining samples...
Obtaining samples for iteration 320...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5095, #subsample_inputs: 5095
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.608      |
| AbsLearnSignalNew       | 0.608      |
| AbsLearningOld          | 0.608      |
| AverageDiscountedReturn | 230        |
| AveragePhiLoss          | 15.2832    |
| AveragePolicyStd        | 0.702931   |
| AverageReturn           | 1.16e+03   |
| Entropy                 | 3.14819    |
| EnvExecTime             | 1.94       |
| ExplainedVariance       | 0.691      |
| Iteration               | 320        |
| ItrTime                 | 8.12       |
| LossAfter               | 0.0830459  |
| LossBefore              | 0.102526   |
| MaxReturn               | 2.44e+03   |
| MeanKL                  | 0.00650278 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 184        |
| NumTrajs                | 13         |
| Perplexity              | 23.2939    |
| PolicyExecTime          | 0.488      |
| ProcessExecTime         | 0.0567     |
| StdReturn               | 481        |
| Time                    | 2.61e+03   |
| dLoss                   | 0.0194801  |
----------------------------------------
itr #321 | 
Mem: 700.222656
Obtaining samples...
Obtaining samples for iteration 321...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5090, #subsample_inputs: 5090
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.748      |
| AbsLearnSignalNew       | 0.748      |
| AbsLearningOld          | 0.748      |
| AverageDiscountedReturn | 235        |
| AveragePhiLoss          | 15.0709    |
| AveragePolicyStd        | 0.705841   |
| AverageReturn           | 1.32e+03   |
| Entropy                 | 3.15625    |
| EnvExecTime             | 1.84       |
| ExplainedVariance       | 0.823      |
| Iteration               | 321        |
| ItrTime                 | 7.9        |
| LossAfter               | -0.530969  |
| LossBefore              | -0.509898  |
| MaxReturn               | 2.41e+03   |
| MeanKL                  | 0.00640473 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 995        |
| NumTrajs                | 11         |
| Perplexity              | 23.4824    |
| PolicyExecTime          | 0.461      |
| ProcessExecTime         | 0.055      |
| StdReturn               | 407        |
| Time                    | 2.62e+03   |
| dLoss                   | 0.0210716  |
----------------------------------------
itr #322 | 
Mem: 700.222656
Obtaining samples...
Obtaining samples for iteration 322...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5489, #subsample_inputs: 5489
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.742      |
| AbsLearnSignalNew       | 0.742      |
| AbsLearningOld          | 0.742      |
| AverageDiscountedReturn | 234        |
| AveragePhiLoss          | 13.7968    |
| AveragePolicyStd        | 0.70186    |
| AverageReturn           | 1.27e+03   |
| Entropy                 | 3.13804    |
| EnvExecTime             | 2.19       |
| ExplainedVariance       | 0.69       |
| Iteration               | 322        |
| ItrTime                 | 8.67       |
| LossAfter               | -0.0424178 |
| LossBefore              | -0.0188299 |
| MaxReturn               | 2.28e+03   |
| MeanKL                  | 0.00650779 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 751        |
| NumTrajs                | 13         |
| Perplexity              | 23.0586    |
| PolicyExecTime          | 0.544      |
| ProcessExecTime         | 0.0636     |
| StdReturn               | 372        |
| Time                    | 2.63e+03   |
| dLoss                   | 0.0235879  |
----------------------------------------
itr #323 | 
Mem: 700.222656
Obtaining samples...
Obtaining samples for iteration 323...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5318, #subsample_inputs: 5318
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.684      |
| AbsLearnSignalNew       | 0.684      |
| AbsLearningOld          | 0.684      |
| AverageDiscountedReturn | 232        |
| AveragePhiLoss          | 14.6603    |
| AveragePolicyStd        | 0.703241   |
| AverageReturn           | 1.26e+03   |
| Entropy                 | 3.13812    |
| EnvExecTime             | 2.09       |
| ExplainedVariance       | 0.686      |
| Iteration               | 323        |
| ItrTime                 | 8.44       |
| LossAfter               | 0.354149   |
| LossBefore              | 0.37919    |
| MaxReturn               | 2.29e+03   |
| MeanKL                  | 0.00977764 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 805        |
| NumTrajs                | 12         |
| Perplexity              | 23.0604    |
| PolicyExecTime          | 0.531      |
| ProcessExecTime         | 0.0606     |
| StdReturn               | 380        |
| Time                    | 2.64e+03   |
| dLoss                   | 0.0250409  |
----------------------------------------
itr #324 | 
Mem: 700.222656
Obtaining samples...
Obtaining samples for iteration 324...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5018, #subsample_inputs: 5018
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.764     |
| AbsLearnSignalNew       | 0.764     |
| AbsLearningOld          | 0.764     |
| AverageDiscountedReturn | 239       |
| AveragePhiLoss          | 14.3698   |
| AveragePolicyStd        | 0.70729   |
| AverageReturn           | 1.37e+03  |
| Entropy                 | 3.15573   |
| EnvExecTime             | 1.8       |
| ExplainedVariance       | 0.836     |
| Iteration               | 324       |
| ItrTime                 | 7.8       |
| LossAfter               | -0.306772 |
| LossBefore              | -0.28375  |
| MaxReturn               | 2.33e+03  |
| MeanKL                  | 0.0064812 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.04e+03  |
| NumTrajs                | 11        |
| Perplexity              | 23.4701   |
| PolicyExecTime          | 0.462     |
| ProcessExecTime         | 0.0525    |
| StdReturn               | 356       |
| Time                    | 2.65e+03  |
| dLoss                   | 0.0230218 |
---------------------------------------
itr #325 | 
Mem: 700.222656
Obtaining samples...
Obtaining samples for iteration 325...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5109, #subsample_inputs: 5109
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.724      |
| AbsLearnSignalNew       | 0.724      |
| AbsLearningOld          | 0.724      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 13.7509    |
| AveragePolicyStd        | 0.705195   |
| AverageReturn           | 1.24e+03   |
| Entropy                 | 3.14652    |
| EnvExecTime             | 2.11       |
| ExplainedVariance       | 0.869      |
| Iteration               | 325        |
| ItrTime                 | 8.33       |
| LossAfter               | 0.698559   |
| LossBefore              | 0.724524   |
| MaxReturn               | 1.93e+03   |
| MeanKL                  | 0.00988922 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.02e+03   |
| NumTrajs                | 13         |
| Perplexity              | 23.2549    |
| PolicyExecTime          | 0.539      |
| ProcessExecTime         | 0.0588     |
| StdReturn               | 233        |
| Time                    | 2.66e+03   |
| dLoss                   | 0.0259656  |
----------------------------------------
itr #326 | 
Mem: 700.222656
Obtaining samples...
Obtaining samples for iteration 326...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5375, #subsample_inputs: 5375
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.674     |
| AbsLearnSignalNew       | 0.674     |
| AbsLearningOld          | 0.674     |
| AverageDiscountedReturn | 234       |
| AveragePhiLoss          | 14.862    |
| AveragePolicyStd        | 0.706821  |
| AverageReturn           | 1.18e+03  |
| Entropy                 | 3.1508    |
| EnvExecTime             | 2.26      |
| ExplainedVariance       | 0.638     |
| Iteration               | 326       |
| ItrTime                 | 8.87      |
| LossAfter               | -0.541746 |
| LossBefore              | -0.516385 |
| MaxReturn               | 1.81e+03  |
| MeanKL                  | 0.0099686 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 849       |
| NumTrajs                | 13        |
| Perplexity              | 23.3547   |
| PolicyExecTime          | 0.564     |
| ProcessExecTime         | 0.0669    |
| StdReturn               | 287       |
| Time                    | 2.66e+03  |
| dLoss                   | 0.0253611 |
---------------------------------------
itr #327 | 
Mem: 700.222656
Obtaining samples...
Obtaining samples for iteration 327...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5609, #subsample_inputs: 5609
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.627      |
| AbsLearnSignalNew       | 0.627      |
| AbsLearningOld          | 0.627      |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 13.6427    |
| AveragePolicyStd        | 0.70698    |
| AverageReturn           | 1.42e+03   |
| Entropy                 | 3.14885    |
| EnvExecTime             | 2.11       |
| ExplainedVariance       | 0.309      |
| Iteration               | 327        |
| ItrTime                 | 8.69       |
| LossAfter               | -0.50099   |
| LossBefore              | -0.482767  |
| MaxReturn               | 2.6e+03    |
| MeanKL                  | 0.00649644 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.02e+03   |
| NumTrajs                | 12         |
| Perplexity              | 23.3093    |
| PolicyExecTime          | 0.531      |
| ProcessExecTime         | 0.0637     |
| StdReturn               | 457        |
| Time                    | 2.67e+03   |
| dLoss                   | 0.0182235  |
----------------------------------------
itr #328 | 
Mem: 700.222656
Obtaining samples...
Obtaining samples for iteration 328...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5067, #subsample_inputs: 5067
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.696      |
| AbsLearnSignalNew       | 0.696      |
| AbsLearningOld          | 0.696      |
| AverageDiscountedReturn | 236        |
| AveragePhiLoss          | 14.8249    |
| AveragePolicyStd        | 0.70697    |
| AverageReturn           | 1.2e+03    |
| Entropy                 | 3.14887    |
| EnvExecTime             | 2.24       |
| ExplainedVariance       | 0.795      |
| Iteration               | 328        |
| ItrTime                 | 8.44       |
| LossAfter               | 0.11764    |
| LossBefore              | 0.145936   |
| MaxReturn               | 1.73e+03   |
| MeanKL                  | 0.00981318 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 852        |
| NumTrajs                | 13         |
| Perplexity              | 23.3097    |
| PolicyExecTime          | 0.566      |
| ProcessExecTime         | 0.0629     |
| StdReturn               | 240        |
| Time                    | 2.68e+03   |
| dLoss                   | 0.0282963  |
----------------------------------------
itr #329 | 
Mem: 700.222656
Obtaining samples...
Obtaining samples for iteration 329...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5756, #subsample_inputs: 5756
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.574     |
| AbsLearnSignalNew       | 0.574     |
| AbsLearningOld          | 0.574     |
| AverageDiscountedReturn | 227       |
| AveragePhiLoss          | 13.0452   |
| AveragePolicyStd        | 0.707474  |
| AverageReturn           | 1.71e+03  |
| Entropy                 | 3.15168   |
| EnvExecTime             | 2.29      |
| ExplainedVariance       | -3.13     |
| Iteration               | 329       |
| ItrTime                 | 9.01      |
| LossAfter               | 0.253845  |
| LossBefore              | 0.279597  |
| MaxReturn               | 2.35e+03  |
| MeanKL                  | 0.0099405 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.08e+03  |
| NumTrajs                | 9         |
| Perplexity              | 23.3754   |
| PolicyExecTime          | 0.576     |
| ProcessExecTime         | 0.0663    |
| StdReturn               | 522       |
| Time                    | 2.69e+03  |
| dLoss                   | 0.0257525 |
---------------------------------------
itr #330 | 
Mem: 701.234375
Obtaining samples...
Obtaining samples for iteration 330...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5056, #subsample_inputs: 5056
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.643      |
| AbsLearnSignalNew       | 0.643      |
| AbsLearningOld          | 0.643      |
| AverageDiscountedReturn | 231        |
| AveragePhiLoss          | 14.6261    |
| AveragePolicyStd        | 0.707194   |
| AverageReturn           | 1.63e+03   |
| Entropy                 | 3.14608    |
| EnvExecTime             | 2.28       |
| ExplainedVariance       | 0.702      |
| Iteration               | 330        |
| ItrTime                 | 8.51       |
| LossAfter               | 0.643231   |
| LossBefore              | 0.673992   |
| MaxReturn               | 2.43e+03   |
| MeanKL                  | 0.00970417 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 902        |
| NumTrajs                | 9          |
| Perplexity              | 23.2447    |
| PolicyExecTime          | 0.568      |
| ProcessExecTime         | 0.0647     |
| StdReturn               | 492        |
| Time                    | 2.7e+03    |
| dLoss                   | 0.0307613  |
----------------------------------------
itr #331 | 
Mem: 701.234375
Obtaining samples...
Obtaining samples for iteration 331...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5179, #subsample_inputs: 5179
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.699      |
| AbsLearnSignalNew       | 0.699      |
| AbsLearningOld          | 0.699      |
| AverageDiscountedReturn | 235        |
| AveragePhiLoss          | 14.6861    |
| AveragePolicyStd        | 0.710957   |
| AverageReturn           | 1.53e+03   |
| Entropy                 | 3.16279    |
| EnvExecTime             | 2.24       |
| ExplainedVariance       | 0.628      |
| Iteration               | 331        |
| ItrTime                 | 8.53       |
| LossAfter               | 0.129996   |
| LossBefore              | 0.151917   |
| MaxReturn               | 2.59e+03   |
| MeanKL                  | 0.00646704 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.01e+03   |
| NumTrajs                | 10         |
| Perplexity              | 23.6365    |
| PolicyExecTime          | 0.576      |
| ProcessExecTime         | 0.0629     |
| StdReturn               | 467        |
| Time                    | 2.71e+03   |
| dLoss                   | 0.0219208  |
----------------------------------------
itr #332 | 
Mem: 701.234375
Obtaining samples...
Obtaining samples for iteration 332...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5214, #subsample_inputs: 5214
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.701      |
| AbsLearnSignalNew       | 0.701      |
| AbsLearningOld          | 0.701      |
| AverageDiscountedReturn | 232        |
| AveragePhiLoss          | 15.7433    |
| AveragePolicyStd        | 0.708355   |
| AverageReturn           | 1.59e+03   |
| Entropy                 | 3.14879    |
| EnvExecTime             | 2.19       |
| ExplainedVariance       | 0.713      |
| Iteration               | 332        |
| ItrTime                 | 8.43       |
| LossAfter               | -0.500004  |
| LossBefore              | -0.474389  |
| MaxReturn               | 2.3e+03    |
| MeanKL                  | 0.00987341 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.04e+03   |
| NumTrajs                | 9          |
| Perplexity              | 23.3079    |
| PolicyExecTime          | 0.556      |
| ProcessExecTime         | 0.0627     |
| StdReturn               | 369        |
| Time                    | 2.72e+03   |
| dLoss                   | 0.0256155  |
----------------------------------------
itr #333 | 
Mem: 701.234375
Obtaining samples...
Obtaining samples for iteration 333...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5188, #subsample_inputs: 5188
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.747      |
| AbsLearnSignalNew       | 0.747      |
| AbsLearningOld          | 0.748      |
| AverageDiscountedReturn | 232        |
| AveragePhiLoss          | 14.3182    |
| AveragePolicyStd        | 0.708479   |
| AverageReturn           | 1.61e+03   |
| Entropy                 | 3.14908    |
| EnvExecTime             | 2.37       |
| ExplainedVariance       | 0.807      |
| Iteration               | 333        |
| ItrTime                 | 8.71       |
| LossAfter               | 0.164903   |
| LossBefore              | 0.191275   |
| MaxReturn               | 2.56e+03   |
| MeanKL                  | 0.00991311 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1e+03      |
| NumTrajs                | 9          |
| Perplexity              | 23.3147    |
| PolicyExecTime          | 0.589      |
| ProcessExecTime         | 0.0674     |
| StdReturn               | 564        |
| Time                    | 2.73e+03   |
| dLoss                   | 0.0263718  |
----------------------------------------
itr #334 | 
Mem: 701.234375
Obtaining samples...
Obtaining samples for iteration 334...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5214, #subsample_inputs: 5214
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.619     |
| AbsLearnSignalNew       | 0.619     |
| AbsLearningOld          | 0.619     |
| AverageDiscountedReturn | 231       |
| AveragePhiLoss          | 17.2649   |
| AveragePolicyStd        | 0.708368  |
| AverageReturn           | 1.42e+03  |
| Entropy                 | 3.1474    |
| EnvExecTime             | 2.19      |
| ExplainedVariance       | 0.686     |
| Iteration               | 334       |
| ItrTime                 | 8.51      |
| LossAfter               | 0.341636  |
| LossBefore              | 0.36122   |
| MaxReturn               | 2.36e+03  |
| MeanKL                  | 0.0064149 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 693       |
| NumTrajs                | 10        |
| Perplexity              | 23.2754   |
| PolicyExecTime          | 0.556     |
| ProcessExecTime         | 0.0653    |
| StdReturn               | 541       |
| Time                    | 2.73e+03  |
| dLoss                   | 0.0195835 |
---------------------------------------
itr #335 | 
Mem: 701.234375
Obtaining samples...
Obtaining samples for iteration 335...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5831, #subsample_inputs: 5831
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.735      |
| AbsLearnSignalNew       | 0.735      |
| AbsLearningOld          | 0.735      |
| AverageDiscountedReturn | 234        |
| AveragePhiLoss          | 13.6694    |
| AveragePolicyStd        | 0.710126   |
| AverageReturn           | 1.49e+03   |
| Entropy                 | 3.15091    |
| EnvExecTime             | 2.23       |
| ExplainedVariance       | 0.779      |
| Iteration               | 335        |
| ItrTime                 | 9.05       |
| LossAfter               | -0.187629  |
| LossBefore              | -0.168365  |
| MaxReturn               | 2.36e+03   |
| MeanKL                  | 0.00650605 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.02e+03   |
| NumTrajs                | 11         |
| Perplexity              | 23.3573    |
| PolicyExecTime          | 0.559      |
| ProcessExecTime         | 0.0682     |
| StdReturn               | 452        |
| Time                    | 2.74e+03   |
| dLoss                   | 0.0192643  |
----------------------------------------
itr #336 | 
Mem: 701.234375
Obtaining samples...
Obtaining samples for iteration 336...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5345, #subsample_inputs: 5345
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.744      |
| AbsLearnSignalNew       | 0.744      |
| AbsLearningOld          | 0.744      |
| AverageDiscountedReturn | 229        |
| AveragePhiLoss          | 14.7506    |
| AveragePolicyStd        | 0.710248   |
| AverageReturn           | 1.69e+03   |
| Entropy                 | 3.15104    |
| EnvExecTime             | 2.38       |
| ExplainedVariance       | 0.798      |
| Iteration               | 336        |
| ItrTime                 | 8.9        |
| LossAfter               | -0.440597  |
| LossBefore              | -0.413761  |
| MaxReturn               | 2.3e+03    |
| MeanKL                  | 0.00967353 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.15e+03   |
| NumTrajs                | 9          |
| Perplexity              | 23.3603    |
| PolicyExecTime          | 0.598      |
| ProcessExecTime         | 0.0693     |
| StdReturn               | 348        |
| Time                    | 2.75e+03   |
| dLoss                   | 0.0268359  |
----------------------------------------
itr #337 | 
Mem: 701.320312
Obtaining samples...
Obtaining samples for iteration 337...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5153, #subsample_inputs: 5153
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.653      |
| AbsLearnSignalNew       | 0.653      |
| AbsLearningOld          | 0.653      |
| AverageDiscountedReturn | 233        |
| AveragePhiLoss          | 18.7148    |
| AveragePolicyStd        | 0.708103   |
| AverageReturn           | 1.48e+03   |
| Entropy                 | 3.14639    |
| EnvExecTime             | 2.08       |
| ExplainedVariance       | 0.756      |
| Iteration               | 337        |
| ItrTime                 | 8.44       |
| LossAfter               | -0.370639  |
| LossBefore              | -0.336855  |
| MaxReturn               | 2.28e+03   |
| MeanKL                  | 0.00992166 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 924        |
| NumTrajs                | 10         |
| Perplexity              | 23.2519    |
| PolicyExecTime          | 0.53       |
| ProcessExecTime         | 0.0637     |
| StdReturn               | 380        |
| Time                    | 2.76e+03   |
| dLoss                   | 0.0337843  |
----------------------------------------
itr #338 | 
Mem: 701.871094
Obtaining samples...
Obtaining samples for iteration 338...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5092, #subsample_inputs: 5092
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.702     |
| AbsLearnSignalNew       | 0.702     |
| AbsLearningOld          | 0.702     |
| AverageDiscountedReturn | 230       |
| AveragePhiLoss          | 14.4447   |
| AveragePolicyStd        | 0.709006  |
| AverageReturn           | 1.7e+03   |
| Entropy                 | 3.1472    |
| EnvExecTime             | 2.12      |
| ExplainedVariance       | 0.531     |
| Iteration               | 338       |
| ItrTime                 | 8.27      |
| LossAfter               | -0.382134 |
| LossBefore              | -0.359852 |
| MaxReturn               | 2.6e+03   |
| MeanKL                  | 0.0065467 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1e+03     |
| NumTrajs                | 8         |
| Perplexity              | 23.2708   |
| PolicyExecTime          | 0.535     |
| ProcessExecTime         | 0.0627    |
| StdReturn               | 605       |
| Time                    | 2.77e+03  |
| dLoss                   | 0.0222821 |
---------------------------------------
itr #339 | 
Mem: 702.121094
Obtaining samples...
Obtaining samples for iteration 339...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5619, #subsample_inputs: 5619
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.677     |
| AbsLearnSignalNew       | 0.677     |
| AbsLearningOld          | 0.677     |
| AverageDiscountedReturn | 233       |
| AveragePhiLoss          | 15.9447   |
| AveragePolicyStd        | 0.707342  |
| AverageReturn           | 1.6e+03   |
| Entropy                 | 3.13608   |
| EnvExecTime             | 2.08      |
| ExplainedVariance       | 0.542     |
| Iteration               | 339       |
| ItrTime                 | 8.57      |
| LossAfter               | 0.131266  |
| LossBefore              | 0.162674  |
| MaxReturn               | 2.74e+03  |
| MeanKL                  | 0.0099639 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.03e+03  |
| NumTrajs                | 10        |
| Perplexity              | 23.0135   |
| PolicyExecTime          | 0.529     |
| ProcessExecTime         | 0.0626    |
| StdReturn               | 573       |
| Time                    | 2.78e+03  |
| dLoss                   | 0.0314084 |
---------------------------------------
itr #340 | 
Mem: 705.371094
Obtaining samples...
Obtaining samples for iteration 340...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5155, #subsample_inputs: 5155
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.702      |
| AbsLearnSignalNew       | 0.702      |
| AbsLearningOld          | 0.702      |
| AverageDiscountedReturn | 234        |
| AveragePhiLoss          | 14.0622    |
| AveragePolicyStd        | 0.704826   |
| AverageReturn           | 1.29e+03   |
| Entropy                 | 3.1327     |
| EnvExecTime             | 2.16       |
| ExplainedVariance       | 0.782      |
| Iteration               | 340        |
| ItrTime                 | 8.45       |
| LossAfter               | 0.22191    |
| LossBefore              | 0.241912   |
| MaxReturn               | 1.68e+03   |
| MeanKL                  | 0.00646219 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 931        |
| NumTrajs                | 12         |
| Perplexity              | 22.9358    |
| PolicyExecTime          | 0.55       |
| ProcessExecTime         | 0.0627     |
| StdReturn               | 249        |
| Time                    | 2.79e+03   |
| dLoss                   | 0.0200026  |
----------------------------------------
itr #341 | 
Mem: 705.371094
Obtaining samples...
Obtaining samples for iteration 341...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5061, #subsample_inputs: 5061
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.419      |
| AbsLearnSignalNew       | 0.419      |
| AbsLearningOld          | 0.419      |
| AverageDiscountedReturn | 234        |
| AveragePhiLoss          | 15.3239    |
| AveragePolicyStd        | 0.705702   |
| AverageReturn           | 1.6e+03    |
| Entropy                 | 3.13794    |
| EnvExecTime             | 2.19       |
| ExplainedVariance       | -6.34      |
| Iteration               | 341        |
| ItrTime                 | 8.33       |
| LossAfter               | -0.842811  |
| LossBefore              | -0.815451  |
| MaxReturn               | 2.31e+03   |
| MeanKL                  | 0.00645172 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.04e+03   |
| NumTrajs                | 9          |
| Perplexity              | 23.0562    |
| PolicyExecTime          | 0.551      |
| ProcessExecTime         | 0.0603     |
| StdReturn               | 452        |
| Time                    | 2.79e+03   |
| dLoss                   | 0.02736    |
----------------------------------------
itr #342 | 
Mem: 705.371094
Obtaining samples...
Obtaining samples for iteration 342...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5341, #subsample_inputs: 5341
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.74       |
| AbsLearnSignalNew       | 0.74       |
| AbsLearningOld          | 0.74       |
| AverageDiscountedReturn | 230        |
| AveragePhiLoss          | 16.3573    |
| AveragePolicyStd        | 0.707175   |
| AverageReturn           | 1.82e+03   |
| Entropy                 | 3.14173    |
| EnvExecTime             | 2.38       |
| ExplainedVariance       | 0.759      |
| Iteration               | 342        |
| ItrTime                 | 8.91       |
| LossAfter               | 0.0648963  |
| LossBefore              | 0.0982642  |
| MaxReturn               | 2.4e+03    |
| MeanKL                  | 0.00991661 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.06e+03   |
| NumTrajs                | 8          |
| Perplexity              | 23.1438    |
| PolicyExecTime          | 0.607      |
| ProcessExecTime         | 0.0665     |
| StdReturn               | 508        |
| Time                    | 2.8e+03    |
| dLoss                   | 0.0333678  |
----------------------------------------
itr #343 | 
Mem: 705.449219
Obtaining samples...
Obtaining samples for iteration 343...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5242, #subsample_inputs: 5242
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.698      |
| AbsLearnSignalNew       | 0.698      |
| AbsLearningOld          | 0.698      |
| AverageDiscountedReturn | 230        |
| AveragePhiLoss          | 15.1283    |
| AveragePolicyStd        | 0.713699   |
| AverageReturn           | 1.94e+03   |
| Entropy                 | 3.16508    |
| EnvExecTime             | 2.05       |
| ExplainedVariance       | 0.835      |
| Iteration               | 343        |
| ItrTime                 | 8.34       |
| LossAfter               | 0.255309   |
| LossBefore              | 0.280478   |
| MaxReturn               | 2.46e+03   |
| MeanKL                  | 0.00648842 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 827        |
| NumTrajs                | 7          |
| Perplexity              | 23.6905    |
| PolicyExecTime          | 0.515      |
| ProcessExecTime         | 0.0605     |
| StdReturn               | 594        |
| Time                    | 2.81e+03   |
| dLoss                   | 0.0251685  |
----------------------------------------
itr #344 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 344...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5142, #subsample_inputs: 5142
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.634      |
| AbsLearnSignalNew       | 0.634      |
| AbsLearningOld          | 0.634      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 15.5485    |
| AveragePolicyStd        | 0.709992   |
| AverageReturn           | 1.21e+03   |
| Entropy                 | 3.15438    |
| EnvExecTime             | 1.84       |
| ExplainedVariance       | 0.716      |
| Iteration               | 344        |
| ItrTime                 | 8.04       |
| LossAfter               | 0.742037   |
| LossBefore              | 0.764743   |
| MaxReturn               | 1.62e+03   |
| MeanKL                  | 0.00641177 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 785        |
| NumTrajs                | 13         |
| Perplexity              | 23.4384    |
| PolicyExecTime          | 0.476      |
| ProcessExecTime         | 0.054      |
| StdReturn               | 204        |
| Time                    | 2.82e+03   |
| dLoss                   | 0.022706   |
----------------------------------------
itr #345 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 345...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5089, #subsample_inputs: 5089
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.382      |
| AbsLearnSignalNew       | 0.382      |
| AbsLearningOld          | 0.382      |
| AverageDiscountedReturn | 234        |
| AveragePhiLoss          | 15.4969    |
| AveragePolicyStd        | 0.707404   |
| AverageReturn           | 1.48e+03   |
| Entropy                 | 3.13981    |
| EnvExecTime             | 2.29       |
| ExplainedVariance       | -8.25      |
| Iteration               | 345        |
| ItrTime                 | 8.5        |
| LossAfter               | -0.0835981 |
| LossBefore              | -0.0550571 |
| MaxReturn               | 2.4e+03    |
| MeanKL                  | 0.0099972  |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.05e+03   |
| NumTrajs                | 10         |
| Perplexity              | 23.0995    |
| PolicyExecTime          | 0.571      |
| ProcessExecTime         | 0.0644     |
| StdReturn               | 453        |
| Time                    | 2.83e+03   |
| dLoss                   | 0.028541   |
----------------------------------------
itr #346 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 346...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5006, #subsample_inputs: 5006
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.695      |
| AbsLearnSignalNew       | 0.695      |
| AbsLearningOld          | 0.695      |
| AverageDiscountedReturn | 232        |
| AveragePhiLoss          | 14.7866    |
| AveragePolicyStd        | 0.712074   |
| AverageReturn           | 1.48e+03   |
| Entropy                 | 3.15611    |
| EnvExecTime             | 1.92       |
| ExplainedVariance       | 0.734      |
| Iteration               | 346        |
| ItrTime                 | 7.91       |
| LossAfter               | 1.08377    |
| LossBefore              | 1.1128     |
| MaxReturn               | 2.16e+03   |
| MeanKL                  | 0.00647505 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.03e+03   |
| NumTrajs                | 10         |
| Perplexity              | 23.4792    |
| PolicyExecTime          | 0.481      |
| ProcessExecTime         | 0.0554     |
| StdReturn               | 401        |
| Time                    | 2.84e+03   |
| dLoss                   | 0.0290239  |
----------------------------------------
itr #347 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 347...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5441, #subsample_inputs: 5441
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.749      |
| AbsLearnSignalNew       | 0.749      |
| AbsLearningOld          | 0.749      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 16.8896    |
| AveragePolicyStd        | 0.711392   |
| AverageReturn           | 1.49e+03   |
| Entropy                 | 3.15227    |
| EnvExecTime             | 1.92       |
| ExplainedVariance       | 0.799      |
| Iteration               | 347        |
| ItrTime                 | 8.38       |
| LossAfter               | 0.192862   |
| LossBefore              | 0.220431   |
| MaxReturn               | 2.42e+03   |
| MeanKL                  | 0.00957084 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 960        |
| NumTrajs                | 11         |
| Perplexity              | 23.3892    |
| PolicyExecTime          | 0.496      |
| ProcessExecTime         | 0.0567     |
| StdReturn               | 467        |
| Time                    | 2.84e+03   |
| dLoss                   | 0.0275689  |
----------------------------------------
itr #348 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 348...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5142, #subsample_inputs: 5142
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.701      |
| AbsLearnSignalNew       | 0.701      |
| AbsLearningOld          | 0.701      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 13.3351    |
| AveragePolicyStd        | 0.719968   |
| AverageReturn           | 1.17e+03   |
| Entropy                 | 3.18954    |
| EnvExecTime             | 2.1        |
| ExplainedVariance       | 0.874      |
| Iteration               | 348        |
| ItrTime                 | 8.32       |
| LossAfter               | -0.209373  |
| LossBefore              | -0.187773  |
| MaxReturn               | 1.77e+03   |
| MeanKL                  | 0.00643162 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 897        |
| NumTrajs                | 14         |
| Perplexity              | 24.2772    |
| PolicyExecTime          | 0.537      |
| ProcessExecTime         | 0.0592     |
| StdReturn               | 202        |
| Time                    | 2.85e+03   |
| dLoss                   | 0.0215996  |
----------------------------------------
itr #349 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 349...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5332, #subsample_inputs: 5332
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.761      |
| AbsLearnSignalNew       | 0.761      |
| AbsLearningOld          | 0.761      |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 14.0253    |
| AveragePolicyStd        | 0.718856   |
| AverageReturn           | 1.28e+03   |
| Entropy                 | 3.18858    |
| EnvExecTime             | 2.01       |
| ExplainedVariance       | 0.85       |
| Iteration               | 349        |
| ItrTime                 | 8.4        |
| LossAfter               | 0.141978   |
| LossBefore              | 0.164028   |
| MaxReturn               | 1.96e+03   |
| MeanKL                  | 0.00642229 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 935        |
| NumTrajs                | 13         |
| Perplexity              | 24.2539    |
| PolicyExecTime          | 0.513      |
| ProcessExecTime         | 0.0581     |
| StdReturn               | 289        |
| Time                    | 2.86e+03   |
| dLoss                   | 0.0220501  |
----------------------------------------
itr #350 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 350...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5433, #subsample_inputs: 5433
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.748      |
| AbsLearnSignalNew       | 0.748      |
| AbsLearningOld          | 0.748      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 13.7074    |
| AveragePolicyStd        | 0.724168   |
| AverageReturn           | 1.37e+03   |
| Entropy                 | 3.21161    |
| EnvExecTime             | 2.04       |
| ExplainedVariance       | 0.834      |
| Iteration               | 350        |
| ItrTime                 | 8.55       |
| LossAfter               | 0.0614544  |
| LossBefore              | 0.0852628  |
| MaxReturn               | 2.48e+03   |
| MeanKL                  | 0.00646199 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 804        |
| NumTrajs                | 12         |
| Perplexity              | 24.8191    |
| PolicyExecTime          | 0.523      |
| ProcessExecTime         | 0.0618     |
| StdReturn               | 410        |
| Time                    | 2.87e+03   |
| dLoss                   | 0.0238084  |
----------------------------------------
itr #351 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 351...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5100, #subsample_inputs: 5100
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.693      |
| AbsLearnSignalNew       | 0.693      |
| AbsLearningOld          | 0.693      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 13.7421    |
| AveragePolicyStd        | 0.724536   |
| AverageReturn           | 1.1e+03    |
| Entropy                 | 3.21257    |
| EnvExecTime             | 2.09       |
| ExplainedVariance       | 0.854      |
| Iteration               | 351        |
| ItrTime                 | 8.23       |
| LossAfter               | -0.0640552 |
| LossBefore              | -0.0384835 |
| MaxReturn               | 2.02e+03   |
| MeanKL                  | 0.00653289 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 745        |
| NumTrajs                | 15         |
| Perplexity              | 24.843     |
| PolicyExecTime          | 0.524      |
| ProcessExecTime         | 0.0594     |
| StdReturn               | 297        |
| Time                    | 2.88e+03   |
| dLoss                   | 0.0255717  |
----------------------------------------
itr #352 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 352...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5308, #subsample_inputs: 5308
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.644      |
| AbsLearnSignalNew       | 0.644      |
| AbsLearningOld          | 0.644      |
| AverageDiscountedReturn | 232        |
| AveragePhiLoss          | 15.3536    |
| AveragePolicyStd        | 0.726706   |
| AverageReturn           | 1.27e+03   |
| Entropy                 | 3.21915    |
| EnvExecTime             | 1.8        |
| ExplainedVariance       | 0.672      |
| Iteration               | 352        |
| ItrTime                 | 8.06       |
| LossAfter               | 0.514542   |
| LossBefore              | 0.537354   |
| MaxReturn               | 2.11e+03   |
| MeanKL                  | 0.00656002 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 250        |
| NumTrajs                | 13         |
| Perplexity              | 25.0068    |
| PolicyExecTime          | 0.465      |
| ProcessExecTime         | 0.0557     |
| StdReturn               | 487        |
| Time                    | 2.89e+03   |
| dLoss                   | 0.0228119  |
----------------------------------------
itr #353 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 353...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5158, #subsample_inputs: 5158
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.712      |
| AbsLearnSignalNew       | 0.712      |
| AbsLearningOld          | 0.712      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 14.0014    |
| AveragePolicyStd        | 0.721523   |
| AverageReturn           | 1.21e+03   |
| Entropy                 | 3.2031     |
| EnvExecTime             | 1.97       |
| ExplainedVariance       | 0.747      |
| Iteration               | 353        |
| ItrTime                 | 8.24       |
| LossAfter               | -0.240277  |
| LossBefore              | -0.212089  |
| MaxReturn               | 2.38e+03   |
| MeanKL                  | 0.00992856 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 821        |
| NumTrajs                | 13         |
| Perplexity              | 24.6087    |
| PolicyExecTime          | 0.503      |
| ProcessExecTime         | 0.057      |
| StdReturn               | 405        |
| Time                    | 2.89e+03   |
| dLoss                   | 0.0281878  |
----------------------------------------
itr #354 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 354...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5169, #subsample_inputs: 5169
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.733      |
| AbsLearnSignalNew       | 0.733      |
| AbsLearningOld          | 0.733      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 14.7673    |
| AveragePolicyStd        | 0.722446   |
| AverageReturn           | 1.14e+03   |
| Entropy                 | 3.20638    |
| EnvExecTime             | 2.05       |
| ExplainedVariance       | 0.815      |
| Iteration               | 354        |
| ItrTime                 | 8.25       |
| LossAfter               | -0.0655152 |
| LossBefore              | -0.0362219 |
| MaxReturn               | 1.76e+03   |
| MeanKL                  | 0.00967858 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 897        |
| NumTrajs                | 14         |
| Perplexity              | 24.6895    |
| PolicyExecTime          | 0.52       |
| ProcessExecTime         | 0.062      |
| StdReturn               | 223        |
| Time                    | 2.9e+03    |
| dLoss                   | 0.0292933  |
----------------------------------------
itr #355 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 355...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5090, #subsample_inputs: 5090
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.741      |
| AbsLearnSignalNew       | 0.741      |
| AbsLearningOld          | 0.741      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 14.7126    |
| AveragePolicyStd        | 0.727812   |
| AverageReturn           | 1.24e+03   |
| Entropy                 | 3.22494    |
| EnvExecTime             | 1.87       |
| ExplainedVariance       | 0.847      |
| Iteration               | 355        |
| ItrTime                 | 7.97       |
| LossAfter               | -0.313816  |
| LossBefore              | -0.287635  |
| MaxReturn               | 2.81e+03   |
| MeanKL                  | 0.00980863 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 784        |
| NumTrajs                | 13         |
| Perplexity              | 25.1521    |
| PolicyExecTime          | 0.471      |
| ProcessExecTime         | 0.0562     |
| StdReturn               | 487        |
| Time                    | 2.91e+03   |
| dLoss                   | 0.0261816  |
----------------------------------------
itr #356 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 356...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5279, #subsample_inputs: 5279
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.725      |
| AbsLearnSignalNew       | 0.725      |
| AbsLearningOld          | 0.725      |
| AverageDiscountedReturn | 236        |
| AveragePhiLoss          | 12.8154    |
| AveragePolicyStd        | 0.730922   |
| AverageReturn           | 1.34e+03   |
| Entropy                 | 3.2406     |
| EnvExecTime             | 1.81       |
| ExplainedVariance       | 0.812      |
| Iteration               | 356        |
| ItrTime                 | 8.07       |
| LossAfter               | -0.351407  |
| LossBefore              | -0.327294  |
| MaxReturn               | 2.32e+03   |
| MeanKL                  | 0.00669813 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 984        |
| NumTrajs                | 12         |
| Perplexity              | 25.5491    |
| PolicyExecTime          | 0.469      |
| ProcessExecTime         | 0.0545     |
| StdReturn               | 378        |
| Time                    | 2.92e+03   |
| dLoss                   | 0.0241134  |
----------------------------------------
itr #357 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 357...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5183, #subsample_inputs: 5183
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.665      |
| AbsLearnSignalNew       | 0.665      |
| AbsLearningOld          | 0.665      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 12.3312    |
| AveragePolicyStd        | 0.730561   |
| AverageReturn           | 1.04e+03   |
| Entropy                 | 3.24071    |
| EnvExecTime             | 2.01       |
| ExplainedVariance       | 0.792      |
| Iteration               | 357        |
| ItrTime                 | 8.25       |
| LossAfter               | -0.989357  |
| LossBefore              | -0.968477  |
| MaxReturn               | 1.39e+03   |
| MeanKL                  | 0.00641397 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 760        |
| NumTrajs                | 16         |
| Perplexity              | 25.5519    |
| PolicyExecTime          | 0.509      |
| ProcessExecTime         | 0.0579     |
| StdReturn               | 169        |
| Time                    | 2.93e+03   |
| dLoss                   | 0.0208803  |
----------------------------------------
itr #358 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 358...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5189, #subsample_inputs: 5189
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.299      |
| AbsLearnSignalNew       | 0.299      |
| AbsLearningOld          | 0.299      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 14.8608    |
| AveragePolicyStd        | 0.731484   |
| AverageReturn           | 1.07e+03   |
| Entropy                 | 3.24538    |
| EnvExecTime             | 2.22       |
| ExplainedVariance       | -24.6      |
| Iteration               | 358        |
| ItrTime                 | 8.49       |
| LossAfter               | -0.267466  |
| LossBefore              | -0.241731  |
| MaxReturn               | 2.36e+03   |
| MeanKL                  | 0.00974883 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 470        |
| NumTrajs                | 15         |
| Perplexity              | 25.6716    |
| PolicyExecTime          | 0.546      |
| ProcessExecTime         | 0.0658     |
| StdReturn               | 406        |
| Time                    | 2.94e+03   |
| dLoss                   | 0.025735   |
----------------------------------------
itr #359 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 359...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5329, #subsample_inputs: 5329
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.774      |
| AbsLearnSignalNew       | 0.774      |
| AbsLearningOld          | 0.774      |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 14.3693    |
| AveragePolicyStd        | 0.734253   |
| AverageReturn           | 1.2e+03    |
| Entropy                 | 3.25152    |
| EnvExecTime             | 1.82       |
| ExplainedVariance       | 0.873      |
| Iteration               | 359        |
| ItrTime                 | 8.19       |
| LossAfter               | 0.159986   |
| LossBefore              | 0.193061   |
| MaxReturn               | 1.78e+03   |
| MeanKL                  | 0.00996119 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 985        |
| NumTrajs                | 14         |
| Perplexity              | 25.8295    |
| PolicyExecTime          | 0.462      |
| ProcessExecTime         | 0.0577     |
| StdReturn               | 243        |
| Time                    | 2.94e+03   |
| dLoss                   | 0.0330746  |
----------------------------------------
itr #360 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 360...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5179, #subsample_inputs: 5179
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.615      |
| AbsLearnSignalNew       | 0.615      |
| AbsLearningOld          | 0.615      |
| AverageDiscountedReturn | 234        |
| AveragePhiLoss          | 13.6839    |
| AveragePolicyStd        | 0.735072   |
| AverageReturn           | 1.1e+03    |
| Entropy                 | 3.25472    |
| EnvExecTime             | 2.31       |
| ExplainedVariance       | 0.774      |
| Iteration               | 360        |
| ItrTime                 | 8.61       |
| LossAfter               | 0.564883   |
| LossBefore              | 0.586832   |
| MaxReturn               | 1.63e+03   |
| MeanKL                  | 0.00657713 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 262        |
| NumTrajs                | 15         |
| Perplexity              | 25.9122    |
| PolicyExecTime          | 0.582      |
| ProcessExecTime         | 0.0649     |
| StdReturn               | 332        |
| Time                    | 2.95e+03   |
| dLoss                   | 0.0219494  |
----------------------------------------
itr #361 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 361...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5376, #subsample_inputs: 5376
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.789      |
| AbsLearnSignalNew       | 0.789      |
| AbsLearningOld          | 0.789      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 14.1398    |
| AveragePolicyStd        | 0.731015   |
| AverageReturn           | 1.08e+03   |
| Entropy                 | 3.23886    |
| EnvExecTime             | 1.99       |
| ExplainedVariance       | 0.898      |
| Iteration               | 361        |
| ItrTime                 | 8.4        |
| LossAfter               | 0.225917   |
| LossBefore              | 0.243935   |
| MaxReturn               | 1.61e+03   |
| MeanKL                  | 0.00645257 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 798        |
| NumTrajs                | 16         |
| Perplexity              | 25.5046    |
| PolicyExecTime          | 0.509      |
| ProcessExecTime         | 0.0577     |
| StdReturn               | 199        |
| Time                    | 2.96e+03   |
| dLoss                   | 0.0180185  |
----------------------------------------
itr #362 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 362...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5332, #subsample_inputs: 5332
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.752      |
| AbsLearnSignalNew       | 0.752      |
| AbsLearningOld          | 0.752      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 14.6454    |
| AveragePolicyStd        | 0.729999   |
| AverageReturn           | 1.06e+03   |
| Entropy                 | 3.2369     |
| EnvExecTime             | 1.99       |
| ExplainedVariance       | 0.908      |
| Iteration               | 362        |
| ItrTime                 | 8.34       |
| LossAfter               | 0.598528   |
| LossBefore              | 0.626239   |
| MaxReturn               | 1.26e+03   |
| MeanKL                  | 0.00977309 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 797        |
| NumTrajs                | 16         |
| Perplexity              | 25.4547    |
| PolicyExecTime          | 0.504      |
| ProcessExecTime         | 0.0579     |
| StdReturn               | 116        |
| Time                    | 2.97e+03   |
| dLoss                   | 0.0277106  |
----------------------------------------
itr #363 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 363...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5070, #subsample_inputs: 5070
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.702     |
| AbsLearnSignalNew       | 0.702     |
| AbsLearningOld          | 0.702     |
| AverageDiscountedReturn | 242       |
| AveragePhiLoss          | 13.9344   |
| AveragePolicyStd        | 0.730618  |
| AverageReturn           | 1.09e+03  |
| Entropy                 | 3.23864   |
| EnvExecTime             | 1.79      |
| ExplainedVariance       | 0.919     |
| Iteration               | 363       |
| ItrTime                 | 7.86      |
| LossAfter               | 0.305516  |
| LossBefore              | 0.331695  |
| MaxReturn               | 1.44e+03  |
| MeanKL                  | 0.0098898 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 834       |
| NumTrajs                | 15        |
| Perplexity              | 25.499    |
| PolicyExecTime          | 0.453     |
| ProcessExecTime         | 0.0555    |
| StdReturn               | 147       |
| Time                    | 2.98e+03  |
| dLoss                   | 0.0261793 |
---------------------------------------
itr #364 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 364...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5249, #subsample_inputs: 5249
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.666      |
| AbsLearnSignalNew       | 0.666      |
| AbsLearningOld          | 0.666      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 12.4155    |
| AveragePolicyStd        | 0.737884   |
| AverageReturn           | 1.11e+03   |
| Entropy                 | 3.26089    |
| EnvExecTime             | 1.9        |
| ExplainedVariance       | 0.817      |
| Iteration               | 364        |
| ItrTime                 | 8.16       |
| LossAfter               | -0.133959  |
| LossBefore              | -0.113137  |
| MaxReturn               | 2.16e+03   |
| MeanKL                  | 0.00645701 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 769        |
| NumTrajs                | 15         |
| Perplexity              | 26.0727    |
| PolicyExecTime          | 0.485      |
| ProcessExecTime         | 0.056      |
| StdReturn               | 301        |
| Time                    | 2.99e+03   |
| dLoss                   | 0.0208225  |
----------------------------------------
itr #365 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 365...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5024, #subsample_inputs: 5024
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.75      |
| AbsLearnSignalNew       | 0.75      |
| AbsLearningOld          | 0.75      |
| AverageDiscountedReturn | 243       |
| AveragePhiLoss          | 14.1392   |
| AveragePolicyStd        | 0.736849  |
| AverageReturn           | 1.08e+03  |
| Entropy                 | 3.26107   |
| EnvExecTime             | 1.84      |
| ExplainedVariance       | 0.912     |
| Iteration               | 365       |
| ItrTime                 | 7.86      |
| LossAfter               | -0.67281  |
| LossBefore              | -0.650271 |
| MaxReturn               | 1.54e+03  |
| MeanKL                  | 0.0064242 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 821       |
| NumTrajs                | 15        |
| Perplexity              | 26.0775   |
| PolicyExecTime          | 0.468     |
| ProcessExecTime         | 0.0546    |
| StdReturn               | 209       |
| Time                    | 2.99e+03  |
| dLoss                   | 0.0225393 |
---------------------------------------
itr #366 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 366...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5028, #subsample_inputs: 5028
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.728      |
| AbsLearnSignalNew       | 0.728      |
| AbsLearningOld          | 0.728      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 12.0912    |
| AveragePolicyStd        | 0.739402   |
| AverageReturn           | 1.01e+03   |
| Entropy                 | 3.27042    |
| EnvExecTime             | 1.97       |
| ExplainedVariance       | 0.879      |
| Iteration               | 366        |
| ItrTime                 | 8.04       |
| LossAfter               | 0.92963    |
| LossBefore              | 0.950959   |
| MaxReturn               | 1.82e+03   |
| MeanKL                  | 0.00647793 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 793        |
| NumTrajs                | 16         |
| Perplexity              | 26.3225    |
| PolicyExecTime          | 0.507      |
| ProcessExecTime         | 0.0562     |
| StdReturn               | 234        |
| Time                    | 3e+03      |
| dLoss                   | 0.0213295  |
----------------------------------------
itr #367 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 367...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5193, #subsample_inputs: 5193
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.619      |
| AbsLearnSignalNew       | 0.619      |
| AbsLearningOld          | 0.619      |
| AverageDiscountedReturn | 232        |
| AveragePhiLoss          | 14.5793    |
| AveragePolicyStd        | 0.737085   |
| AverageReturn           | 977        |
| Entropy                 | 3.26523    |
| EnvExecTime             | 2.17       |
| ExplainedVariance       | 0.782      |
| Iteration               | 367        |
| ItrTime                 | 8.43       |
| LossAfter               | 0.179543   |
| LossBefore              | 0.202422   |
| MaxReturn               | 1.66e+03   |
| MeanKL                  | 0.00671659 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 146        |
| NumTrajs                | 17         |
| Perplexity              | 26.1861    |
| PolicyExecTime          | 0.525      |
| ProcessExecTime         | 0.0655     |
| StdReturn               | 307        |
| Time                    | 3.01e+03   |
| dLoss                   | 0.0228792  |
----------------------------------------
itr #368 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 368...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5133, #subsample_inputs: 5133
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.742      |
| AbsLearnSignalNew       | 0.742      |
| AbsLearningOld          | 0.741      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 13.7674    |
| AveragePolicyStd        | 0.730374   |
| AverageReturn           | 1.1e+03    |
| Entropy                 | 3.23933    |
| EnvExecTime             | 1.96       |
| ExplainedVariance       | 0.92       |
| Iteration               | 368        |
| ItrTime                 | 8.1        |
| LossAfter               | -0.23829   |
| LossBefore              | -0.21583   |
| MaxReturn               | 1.87e+03   |
| MeanKL                  | 0.00649602 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 773        |
| NumTrajs                | 15         |
| Perplexity              | 25.5166    |
| PolicyExecTime          | 0.494      |
| ProcessExecTime         | 0.0573     |
| StdReturn               | 308        |
| Time                    | 3.02e+03   |
| dLoss                   | 0.0224599  |
----------------------------------------
itr #369 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 369...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5142, #subsample_inputs: 5142
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.757      |
| AbsLearnSignalNew       | 0.757      |
| AbsLearningOld          | 0.757      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 13.1503    |
| AveragePolicyStd        | 0.734884   |
| AverageReturn           | 1.16e+03   |
| Entropy                 | 3.25371    |
| EnvExecTime             | 1.92       |
| ExplainedVariance       | 0.895      |
| Iteration               | 369        |
| ItrTime                 | 8.03       |
| LossAfter               | -0.222739  |
| LossBefore              | -0.201348  |
| MaxReturn               | 2.34e+03   |
| MeanKL                  | 0.00654011 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 805        |
| NumTrajs                | 14         |
| Perplexity              | 25.8862    |
| PolicyExecTime          | 0.497      |
| ProcessExecTime         | 0.0552     |
| StdReturn               | 375        |
| Time                    | 3.03e+03   |
| dLoss                   | 0.0213911  |
----------------------------------------
itr #370 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 370...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5068, #subsample_inputs: 5068
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.752      |
| AbsLearnSignalNew       | 0.752      |
| AbsLearningOld          | 0.752      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 13.509     |
| AveragePolicyStd        | 0.733481   |
| AverageReturn           | 1.29e+03   |
| Entropy                 | 3.24695    |
| EnvExecTime             | 1.95       |
| ExplainedVariance       | 0.854      |
| Iteration               | 370        |
| ItrTime                 | 8.13       |
| LossAfter               | 0.155512   |
| LossBefore              | 0.176998   |
| MaxReturn               | 1.9e+03    |
| MeanKL                  | 0.00651607 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 794        |
| NumTrajs                | 12         |
| Perplexity              | 25.7118    |
| PolicyExecTime          | 0.496      |
| ProcessExecTime         | 0.0583     |
| StdReturn               | 295        |
| Time                    | 3.03e+03   |
| dLoss                   | 0.0214862  |
----------------------------------------
itr #371 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 371...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5131, #subsample_inputs: 5131
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.61       |
| AbsLearnSignalNew       | 0.61       |
| AbsLearningOld          | 0.609      |
| AverageDiscountedReturn | 233        |
| AveragePhiLoss          | 16.0675    |
| AveragePolicyStd        | 0.730766   |
| AverageReturn           | 1.05e+03   |
| Entropy                 | 3.23444    |
| EnvExecTime             | 2.25       |
| ExplainedVariance       | 0.664      |
| Iteration               | 371        |
| ItrTime                 | 8.49       |
| LossAfter               | -0.888478  |
| LossBefore              | -0.866218  |
| MaxReturn               | 1.53e+03   |
| MeanKL                  | 0.00648496 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 485        |
| NumTrajs                | 15         |
| Perplexity              | 25.3921    |
| PolicyExecTime          | 0.559      |
| ProcessExecTime         | 0.0669     |
| StdReturn               | 269        |
| Time                    | 3.04e+03   |
| dLoss                   | 0.0222604  |
----------------------------------------
itr #372 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 372...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5628, #subsample_inputs: 5628
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.718      |
| AbsLearnSignalNew       | 0.718      |
| AbsLearningOld          | 0.718      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 13.7446    |
| AveragePolicyStd        | 0.730846   |
| AverageReturn           | 1.18e+03   |
| Entropy                 | 3.23338    |
| EnvExecTime             | 2.4        |
| ExplainedVariance       | 0.727      |
| Iteration               | 372        |
| ItrTime                 | 9.15       |
| LossAfter               | 0.154367   |
| LossBefore              | 0.178764   |
| MaxReturn               | 1.96e+03   |
| MeanKL                  | 0.00997437 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 995        |
| NumTrajs                | 15         |
| Perplexity              | 25.3653    |
| PolicyExecTime          | 0.59       |
| ProcessExecTime         | 0.0733     |
| StdReturn               | 275        |
| Time                    | 3.05e+03   |
| dLoss                   | 0.024397   |
----------------------------------------
itr #373 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 373...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5049, #subsample_inputs: 5049
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.754      |
| AbsLearnSignalNew       | 0.754      |
| AbsLearningOld          | 0.754      |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 13.5377    |
| AveragePolicyStd        | 0.726565   |
| AverageReturn           | 1.13e+03   |
| Entropy                 | 3.21798    |
| EnvExecTime             | 1.92       |
| ExplainedVariance       | 0.9        |
| Iteration               | 373        |
| ItrTime                 | 7.98       |
| LossAfter               | -1.01811   |
| LossBefore              | -0.988598  |
| MaxReturn               | 1.62e+03   |
| MeanKL                  | 0.00997278 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 839        |
| NumTrajs                | 14         |
| Perplexity              | 24.9776    |
| PolicyExecTime          | 0.487      |
| ProcessExecTime         | 0.058      |
| StdReturn               | 197        |
| Time                    | 3.06e+03   |
| dLoss                   | 0.0295159  |
----------------------------------------
itr #374 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 374...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5144, #subsample_inputs: 5144
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.649      |
| AbsLearnSignalNew       | 0.649      |
| AbsLearningOld          | 0.65       |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 15.5329    |
| AveragePolicyStd        | 0.726208   |
| AverageReturn           | 1.03e+03   |
| Entropy                 | 3.22213    |
| EnvExecTime             | 1.94       |
| ExplainedVariance       | 0.865      |
| Iteration               | 374        |
| ItrTime                 | 8.13       |
| LossAfter               | 0.580616   |
| LossBefore              | 0.604144   |
| MaxReturn               | 1.34e+03   |
| MeanKL                  | 0.00962522 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 720        |
| NumTrajs                | 16         |
| Perplexity              | 25.0816    |
| PolicyExecTime          | 0.503      |
| ProcessExecTime         | 0.0559     |
| StdReturn               | 156        |
| Time                    | 3.07e+03   |
| dLoss                   | 0.0235285  |
----------------------------------------
itr #375 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 375...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5014, #subsample_inputs: 5014
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.74       |
| AbsLearnSignalNew       | 0.74       |
| AbsLearningOld          | 0.74       |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 14.2978    |
| AveragePolicyStd        | 0.727855   |
| AverageReturn           | 1.01e+03   |
| Entropy                 | 3.22864    |
| EnvExecTime             | 1.9        |
| ExplainedVariance       | 0.896      |
| Iteration               | 375        |
| ItrTime                 | 7.93       |
| LossAfter               | 0.216184   |
| LossBefore              | 0.238406   |
| MaxReturn               | 1.77e+03   |
| MeanKL                  | 0.00666636 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 688        |
| NumTrajs                | 16         |
| Perplexity              | 25.2453    |
| PolicyExecTime          | 0.481      |
| ProcessExecTime         | 0.056      |
| StdReturn               | 252        |
| Time                    | 3.08e+03   |
| dLoss                   | 0.0222219  |
----------------------------------------
itr #376 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 376...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5031, #subsample_inputs: 5031
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.764      |
| AbsLearnSignalNew       | 0.764      |
| AbsLearningOld          | 0.764      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 14.4359    |
| AveragePolicyStd        | 0.720524   |
| AverageReturn           | 1.14e+03   |
| Entropy                 | 3.19807    |
| EnvExecTime             | 1.94       |
| ExplainedVariance       | 0.876      |
| Iteration               | 376        |
| ItrTime                 | 8          |
| LossAfter               | 0.258082   |
| LossBefore              | 0.284615   |
| MaxReturn               | 1.7e+03    |
| MeanKL                  | 0.00956472 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 833        |
| NumTrajs                | 14         |
| Perplexity              | 24.4852    |
| PolicyExecTime          | 0.475      |
| ProcessExecTime         | 0.0581     |
| StdReturn               | 247        |
| Time                    | 3.08e+03   |
| dLoss                   | 0.0265327  |
----------------------------------------
itr #377 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 377...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5088, #subsample_inputs: 5088
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.764      |
| AbsLearnSignalNew       | 0.764      |
| AbsLearningOld          | 0.764      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 14.2826    |
| AveragePolicyStd        | 0.723522   |
| AverageReturn           | 1.16e+03   |
| Entropy                 | 3.20492    |
| EnvExecTime             | 1.92       |
| ExplainedVariance       | 0.889      |
| Iteration               | 377        |
| ItrTime                 | 7.99       |
| LossAfter               | 0.101366   |
| LossBefore              | 0.121548   |
| MaxReturn               | 2.24e+03   |
| MeanKL                  | 0.00653876 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 832        |
| NumTrajs                | 14         |
| Perplexity              | 24.6536    |
| PolicyExecTime          | 0.488      |
| ProcessExecTime         | 0.0571     |
| StdReturn               | 403        |
| Time                    | 3.09e+03   |
| dLoss                   | 0.0201827  |
----------------------------------------
itr #378 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 378...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5242, #subsample_inputs: 5242
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.717      |
| AbsLearnSignalNew       | 0.717      |
| AbsLearningOld          | 0.717      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 13.4235    |
| AveragePolicyStd        | 0.726825   |
| AverageReturn           | 1e+03      |
| Entropy                 | 3.21737    |
| EnvExecTime             | 2          |
| ExplainedVariance       | 0.911      |
| Iteration               | 378        |
| ItrTime                 | 8.28       |
| LossAfter               | 0.324171   |
| LossBefore              | 0.346507   |
| MaxReturn               | 1.34e+03   |
| MeanKL                  | 0.00641978 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 811        |
| NumTrajs                | 17         |
| Perplexity              | 24.9623    |
| PolicyExecTime          | 0.51       |
| ProcessExecTime         | 0.059      |
| StdReturn               | 160        |
| Time                    | 3.1e+03    |
| dLoss                   | 0.0223368  |
----------------------------------------
itr #379 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 379...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5318, #subsample_inputs: 5318
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.584      |
| AbsLearnSignalNew       | 0.584      |
| AbsLearningOld          | 0.584      |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 13.489     |
| AveragePolicyStd        | 0.72495    |
| AverageReturn           | 1e+03      |
| Entropy                 | 3.20909    |
| EnvExecTime             | 2.23       |
| ExplainedVariance       | 0.77       |
| Iteration               | 379        |
| ItrTime                 | 8.61       |
| LossAfter               | -0.112525  |
| LossBefore              | -0.0867109 |
| MaxReturn               | 1.23e+03   |
| MeanKL                  | 0.0096361  |
| MeanKLBefore            | 0.0        |
| MinReturn               | 516        |
| NumTrajs                | 17         |
| Perplexity              | 24.7566    |
| PolicyExecTime          | 0.559      |
| ProcessExecTime         | 0.0646     |
| StdReturn               | 197        |
| Time                    | 3.11e+03   |
| dLoss                   | 0.0258145  |
----------------------------------------
itr #380 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 380...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5280, #subsample_inputs: 5280
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.57       |
| AbsLearnSignalNew       | 0.57       |
| AbsLearningOld          | 0.57       |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 14.5872    |
| AveragePolicyStd        | 0.731579   |
| AverageReturn           | 1.19e+03   |
| Entropy                 | 3.23263    |
| EnvExecTime             | 1.94       |
| ExplainedVariance       | 0.468      |
| Iteration               | 380        |
| ItrTime                 | 8.19       |
| LossAfter               | -0.0796238 |
| LossBefore              | -0.0404001 |
| MaxReturn               | 1.74e+03   |
| MeanKL                  | 0.00994418 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 902        |
| NumTrajs                | 14         |
| Perplexity              | 25.3462    |
| PolicyExecTime          | 0.497      |
| ProcessExecTime         | 0.0584     |
| StdReturn               | 247        |
| Time                    | 3.12e+03   |
| dLoss                   | 0.0392236  |
----------------------------------------
itr #381 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 381...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5179, #subsample_inputs: 5179
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.725      |
| AbsLearnSignalNew       | 0.725      |
| AbsLearningOld          | 0.725      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 13.6822    |
| AveragePolicyStd        | 0.729652   |
| AverageReturn           | 1.25e+03   |
| Entropy                 | 3.22642    |
| EnvExecTime             | 1.9        |
| ExplainedVariance       | 0.857      |
| Iteration               | 381        |
| ItrTime                 | 8.11       |
| LossAfter               | 0.323491   |
| LossBefore              | 0.352438   |
| MaxReturn               | 2.25e+03   |
| MeanKL                  | 0.00971188 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 747        |
| NumTrajs                | 13         |
| Perplexity              | 25.1894    |
| PolicyExecTime          | 0.483      |
| ProcessExecTime         | 0.0559     |
| StdReturn               | 395        |
| Time                    | 3.13e+03   |
| dLoss                   | 0.0289478  |
----------------------------------------
itr #382 | 
Mem: 705.960938
Obtaining samples...
Obtaining samples for iteration 382...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5998, #subsample_inputs: 5998
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.622      |
| AbsLearnSignalNew       | 0.622      |
| AbsLearningOld          | 0.622      |
| AverageDiscountedReturn | 232        |
| AveragePhiLoss          | 13.9846    |
| AveragePolicyStd        | 0.729187   |
| AverageReturn           | 1.45e+03   |
| Entropy                 | 3.22391    |
| EnvExecTime             | 2.24       |
| ExplainedVariance       | 0.605      |
| Iteration               | 382        |
| ItrTime                 | 9.19       |
| LossAfter               | -0.17331   |
| LossBefore              | -0.148367  |
| MaxReturn               | 2.54e+03   |
| MeanKL                  | 0.00962408 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 856        |
| NumTrajs                | 12         |
| Perplexity              | 25.1261    |
| PolicyExecTime          | 0.564      |
| ProcessExecTime         | 0.0675     |
| StdReturn               | 536        |
| Time                    | 3.14e+03   |
| dLoss                   | 0.0249428  |
----------------------------------------
itr #383 | 
Mem: 707.164062
Obtaining samples...
Obtaining samples for iteration 383...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5396, #subsample_inputs: 5396
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.734      |
| AbsLearnSignalNew       | 0.734      |
| AbsLearningOld          | 0.734      |
| AverageDiscountedReturn | 233        |
| AveragePhiLoss          | 15.8883    |
| AveragePolicyStd        | 0.732967   |
| AverageReturn           | 1.5e+03    |
| Entropy                 | 3.23818    |
| EnvExecTime             | 1.95       |
| ExplainedVariance       | 0.773      |
| Iteration               | 383        |
| ItrTime                 | 8.33       |
| LossAfter               | -0.857384  |
| LossBefore              | -0.830424  |
| MaxReturn               | 2.22e+03   |
| MeanKL                  | 0.00982448 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 979        |
| NumTrajs                | 11         |
| Perplexity              | 25.4872    |
| PolicyExecTime          | 0.495      |
| ProcessExecTime         | 0.0573     |
| StdReturn               | 415        |
| Time                    | 3.14e+03   |
| dLoss                   | 0.02696    |
----------------------------------------
itr #384 | 
Mem: 707.164062
Obtaining samples...
Obtaining samples for iteration 384...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5274, #subsample_inputs: 5274
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.703      |
| AbsLearnSignalNew       | 0.703      |
| AbsLearningOld          | 0.703      |
| AverageDiscountedReturn | 227        |
| AveragePhiLoss          | 14.0148    |
| AveragePolicyStd        | 0.732393   |
| AverageReturn           | 1.41e+03   |
| Entropy                 | 3.23752    |
| EnvExecTime             | 2.05       |
| ExplainedVariance       | 0.517      |
| Iteration               | 384        |
| ItrTime                 | 8.29       |
| LossAfter               | -0.171393  |
| LossBefore              | -0.14817   |
| MaxReturn               | 2.53e+03   |
| MeanKL                  | 0.00971511 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 902        |
| NumTrajs                | 10         |
| Perplexity              | 25.4705    |
| PolicyExecTime          | 0.522      |
| ProcessExecTime         | 0.0583     |
| StdReturn               | 574        |
| Time                    | 3.15e+03   |
| dLoss                   | 0.0232231  |
----------------------------------------
itr #385 | 
Mem: 707.164062
Obtaining samples...
Obtaining samples for iteration 385...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5224, #subsample_inputs: 5224
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.68       |
| AbsLearnSignalNew       | 0.68       |
| AbsLearningOld          | 0.679      |
| AverageDiscountedReturn | 234        |
| AveragePhiLoss          | 14.494     |
| AveragePolicyStd        | 0.734987   |
| AverageReturn           | 1.7e+03    |
| Entropy                 | 3.2496     |
| EnvExecTime             | 1.88       |
| ExplainedVariance       | 0.697      |
| Iteration               | 385        |
| ItrTime                 | 8.1        |
| LossAfter               | -0.946059  |
| LossBefore              | -0.92308   |
| MaxReturn               | 2.48e+03   |
| MeanKL                  | 0.00647143 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 998        |
| NumTrajs                | 9          |
| Perplexity              | 25.7799    |
| PolicyExecTime          | 0.474      |
| ProcessExecTime         | 0.0562     |
| StdReturn               | 546        |
| Time                    | 3.16e+03   |
| dLoss                   | 0.0229796  |
----------------------------------------
itr #386 | 
Mem: 707.164062
Obtaining samples...
Obtaining samples for iteration 386...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5303, #subsample_inputs: 5303
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.654      |
| AbsLearnSignalNew       | 0.654      |
| AbsLearningOld          | 0.654      |
| AverageDiscountedReturn | 231        |
| AveragePhiLoss          | 15.7884    |
| AveragePolicyStd        | 0.730043   |
| AverageReturn           | 1.44e+03   |
| Entropy                 | 3.23187    |
| EnvExecTime             | 2.16       |
| ExplainedVariance       | 0.75       |
| Iteration               | 386        |
| ItrTime                 | 8.54       |
| LossAfter               | 0.628812   |
| LossBefore              | 0.65879    |
| MaxReturn               | 2.35e+03   |
| MeanKL                  | 0.00959565 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 751        |
| NumTrajs                | 10         |
| Perplexity              | 25.3271    |
| PolicyExecTime          | 0.545      |
| ProcessExecTime         | 0.0633     |
| StdReturn               | 509        |
| Time                    | 3.17e+03   |
| dLoss                   | 0.0299784  |
----------------------------------------
itr #387 | 
Mem: 707.164062
Obtaining samples...
Obtaining samples for iteration 387...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5318, #subsample_inputs: 5318
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.773      |
| AbsLearnSignalNew       | 0.773      |
| AbsLearningOld          | 0.773      |
| AverageDiscountedReturn | 235        |
| AveragePhiLoss          | 14.0041    |
| AveragePolicyStd        | 0.731882   |
| AverageReturn           | 1.69e+03   |
| Entropy                 | 3.23694    |
| EnvExecTime             | 2.2        |
| ExplainedVariance       | 0.819      |
| Iteration               | 387        |
| ItrTime                 | 8.58       |
| LossAfter               | 0.495743   |
| LossBefore              | 0.520278   |
| MaxReturn               | 2.48e+03   |
| MeanKL                  | 0.00983417 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1e+03      |
| NumTrajs                | 9          |
| Perplexity              | 25.4557    |
| PolicyExecTime          | 0.568      |
| ProcessExecTime         | 0.0629     |
| StdReturn               | 510        |
| Time                    | 3.18e+03   |
| dLoss                   | 0.0245355  |
----------------------------------------
itr #388 | 
Mem: 707.167969
Obtaining samples...
Obtaining samples for iteration 388...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5027, #subsample_inputs: 5027
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.692     |
| AbsLearnSignalNew       | 0.692     |
| AbsLearningOld          | 0.692     |
| AverageDiscountedReturn | 233       |
| AveragePhiLoss          | 14.1315   |
| AveragePolicyStd        | 0.729382  |
| AverageReturn           | 1.27e+03  |
| Entropy                 | 3.22877   |
| EnvExecTime             | 2         |
| ExplainedVariance       | 0.776     |
| Iteration               | 388       |
| ItrTime                 | 8.09      |
| LossAfter               | 0.180913  |
| LossBefore              | 0.205151  |
| MaxReturn               | 1.73e+03  |
| MeanKL                  | 0.006577  |
| MeanKLBefore            | 0.0       |
| MinReturn               | 879       |
| NumTrajs                | 12        |
| Perplexity              | 25.2485   |
| PolicyExecTime          | 0.514     |
| ProcessExecTime         | 0.0569    |
| StdReturn               | 259       |
| Time                    | 3.19e+03  |
| dLoss                   | 0.0242385 |
---------------------------------------
itr #389 | 
Mem: 707.167969
Obtaining samples...
Obtaining samples for iteration 389...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5396, #subsample_inputs: 5396
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.617      |
| AbsLearnSignalNew       | 0.617      |
| AbsLearningOld          | 0.617      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 10.7163    |
| AveragePolicyStd        | 0.728467   |
| AverageReturn           | 1.2e+03    |
| Entropy                 | 3.22715    |
| EnvExecTime             | 1.93       |
| ExplainedVariance       | 0.689      |
| Iteration               | 389        |
| ItrTime                 | 8.32       |
| LossAfter               | 0.259079   |
| LossBefore              | 0.284509   |
| MaxReturn               | 1.64e+03   |
| MeanKL                  | 0.00977898 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 866        |
| NumTrajs                | 14         |
| Perplexity              | 25.2077    |
| PolicyExecTime          | 0.5        |
| ProcessExecTime         | 0.0568     |
| StdReturn               | 240        |
| Time                    | 3.19e+03   |
| dLoss                   | 0.0254303  |
----------------------------------------
itr #390 | 
Mem: 707.167969
Obtaining samples...
Obtaining samples for iteration 390...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5433, #subsample_inputs: 5433
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.733      |
| AbsLearnSignalNew       | 0.733      |
| AbsLearningOld          | 0.733      |
| AverageDiscountedReturn | 236        |
| AveragePhiLoss          | 13.7082    |
| AveragePolicyStd        | 0.736074   |
| AverageReturn           | 1.2e+03    |
| Entropy                 | 3.25979    |
| EnvExecTime             | 2.24       |
| ExplainedVariance       | 0.763      |
| Iteration               | 390        |
| ItrTime                 | 8.75       |
| LossAfter               | 0.240862   |
| LossBefore              | 0.267569   |
| MaxReturn               | 1.93e+03   |
| MeanKL                  | 0.00641321 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 589        |
| NumTrajs                | 14         |
| Perplexity              | 26.0441    |
| PolicyExecTime          | 0.567      |
| ProcessExecTime         | 0.0638     |
| StdReturn               | 334        |
| Time                    | 3.2e+03    |
| dLoss                   | 0.0267079  |
----------------------------------------
itr #391 | 
Mem: 707.167969
Obtaining samples...
Obtaining samples for iteration 391...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5614, #subsample_inputs: 5614
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.752      |
| AbsLearnSignalNew       | 0.752      |
| AbsLearningOld          | 0.752      |
| AverageDiscountedReturn | 234        |
| AveragePhiLoss          | 13.3562    |
| AveragePolicyStd        | 0.733094   |
| AverageReturn           | 1.38e+03   |
| Entropy                 | 3.24786    |
| EnvExecTime             | 2.15       |
| ExplainedVariance       | 0.76       |
| Iteration               | 391        |
| ItrTime                 | 8.72       |
| LossAfter               | -0.494852  |
| LossBefore              | -0.469964  |
| MaxReturn               | 2.61e+03   |
| MeanKL                  | 0.00648463 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.02e+03   |
| NumTrajs                | 12         |
| Perplexity              | 25.7353    |
| PolicyExecTime          | 0.553      |
| ProcessExecTime         | 0.0623     |
| StdReturn               | 457        |
| Time                    | 3.21e+03   |
| dLoss                   | 0.0248882  |
----------------------------------------
itr #392 | 
Mem: 707.167969
Obtaining samples...
Obtaining samples for iteration 392...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5329, #subsample_inputs: 5329
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.745      |
| AbsLearnSignalNew       | 0.745      |
| AbsLearningOld          | 0.745      |
| AverageDiscountedReturn | 234        |
| AveragePhiLoss          | 14.2936    |
| AveragePolicyStd        | 0.731284   |
| AverageReturn           | 1.42e+03   |
| Entropy                 | 3.23795    |
| EnvExecTime             | 2.01       |
| ExplainedVariance       | 0.804      |
| Iteration               | 392        |
| ItrTime                 | 8.36       |
| LossAfter               | -0.171172  |
| LossBefore              | -0.15219   |
| MaxReturn               | 2.46e+03   |
| MeanKL                  | 0.00657015 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 826        |
| NumTrajs                | 11         |
| Perplexity              | 25.4814    |
| PolicyExecTime          | 0.513      |
| ProcessExecTime         | 0.0596     |
| StdReturn               | 416        |
| Time                    | 3.22e+03   |
| dLoss                   | 0.0189821  |
----------------------------------------
itr #393 | 
Mem: 707.167969
Obtaining samples...
Obtaining samples for iteration 393...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5001, #subsample_inputs: 5001
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.754      |
| AbsLearnSignalNew       | 0.754      |
| AbsLearningOld          | 0.754      |
| AverageDiscountedReturn | 234        |
| AveragePhiLoss          | 13.5415    |
| AveragePolicyStd        | 0.725041   |
| AverageReturn           | 1.66e+03   |
| Entropy                 | 3.21272    |
| EnvExecTime             | 1.83       |
| ExplainedVariance       | 0.747      |
| Iteration               | 393        |
| ItrTime                 | 7.84       |
| LossAfter               | -0.743885  |
| LossBefore              | -0.715705  |
| MaxReturn               | 2.55e+03   |
| MeanKL                  | 0.00988389 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.01e+03   |
| NumTrajs                | 9          |
| Perplexity              | 24.8465    |
| PolicyExecTime          | 0.473      |
| ProcessExecTime         | 0.0535     |
| StdReturn               | 540        |
| Time                    | 3.23e+03   |
| dLoss                   | 0.0281795  |
----------------------------------------
itr #394 | 
Mem: 707.167969
Obtaining samples...
Obtaining samples for iteration 394...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5256, #subsample_inputs: 5256
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.739      |
| AbsLearnSignalNew       | 0.739      |
| AbsLearningOld          | 0.739      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 15.1018    |
| AveragePolicyStd        | 0.725146   |
| AverageReturn           | 1.25e+03   |
| Entropy                 | 3.2117     |
| EnvExecTime             | 2.06       |
| ExplainedVariance       | 0.856      |
| Iteration               | 394        |
| ItrTime                 | 8.34       |
| LossAfter               | -0.914846  |
| LossBefore              | -0.893632  |
| MaxReturn               | 1.71e+03   |
| MeanKL                  | 0.00650533 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 998        |
| NumTrajs                | 13         |
| Perplexity              | 24.8213    |
| PolicyExecTime          | 0.515      |
| ProcessExecTime         | 0.0616     |
| StdReturn               | 211        |
| Time                    | 3.24e+03   |
| dLoss                   | 0.0212148  |
----------------------------------------
itr #395 | 
Mem: 707.167969
Obtaining samples...
Obtaining samples for iteration 395...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5716, #subsample_inputs: 5716
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.512     |
| AbsLearnSignalNew       | 0.512     |
| AbsLearningOld          | 0.513     |
| AverageDiscountedReturn | 237       |
| AveragePhiLoss          | 12.5315   |
| AveragePolicyStd        | 0.721995  |
| AverageReturn           | 1.42e+03  |
| Entropy                 | 3.20055   |
| EnvExecTime             | 2.32      |
| ExplainedVariance       | -1.54     |
| Iteration               | 395       |
| ItrTime                 | 9.06      |
| LossAfter               | -0.690479 |
| LossBefore              | -0.670568 |
| MaxReturn               | 2.72e+03  |
| MeanKL                  | 0.0065307 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 805       |
| NumTrajs                | 12        |
| Perplexity              | 24.5459   |
| PolicyExecTime          | 0.588     |
| ProcessExecTime         | 0.0682    |
| StdReturn               | 615       |
| Time                    | 3.25e+03  |
| dLoss                   | 0.0199115 |
---------------------------------------
itr #396 | 
Mem: 707.167969
Obtaining samples...
Obtaining samples for iteration 396...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5000, #subsample_inputs: 5000
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.707      |
| AbsLearnSignalNew       | 0.707      |
| AbsLearningOld          | 0.707      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 13.9825    |
| AveragePolicyStd        | 0.716778   |
| AverageReturn           | 1.31e+03   |
| Entropy                 | 3.18055    |
| EnvExecTime             | 1.82       |
| ExplainedVariance       | 0.856      |
| Iteration               | 396        |
| ItrTime                 | 7.86       |
| LossAfter               | -1.15521   |
| LossBefore              | -1.12693   |
| MaxReturn               | 2.43e+03   |
| MeanKL                  | 0.00998166 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 829        |
| NumTrajs                | 12         |
| Perplexity              | 24.0599    |
| PolicyExecTime          | 0.469      |
| ProcessExecTime         | 0.0535     |
| StdReturn               | 393        |
| Time                    | 3.25e+03   |
| dLoss                   | 0.0282748  |
----------------------------------------
itr #397 | 
Mem: 707.167969
Obtaining samples...
Obtaining samples for iteration 397...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5160, #subsample_inputs: 5160
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.768      |
| AbsLearnSignalNew       | 0.768      |
| AbsLearningOld          | 0.768      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 15.2532    |
| AveragePolicyStd        | 0.714901   |
| AverageReturn           | 1.27e+03   |
| Entropy                 | 3.17604    |
| EnvExecTime             | 1.75       |
| ExplainedVariance       | 0.92       |
| Iteration               | 397        |
| ItrTime                 | 7.95       |
| LossAfter               | 0.594249   |
| LossBefore              | 0.614666   |
| MaxReturn               | 2.18e+03   |
| MeanKL                  | 0.00656109 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 985        |
| NumTrajs                | 13         |
| Perplexity              | 23.9518    |
| PolicyExecTime          | 0.454      |
| ProcessExecTime         | 0.055      |
| StdReturn               | 315        |
| Time                    | 3.26e+03   |
| dLoss                   | 0.0204168  |
----------------------------------------
itr #398 | 
Mem: 707.167969
Obtaining samples...
Obtaining samples for iteration 398...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5064, #subsample_inputs: 5064
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.728      |
| AbsLearnSignalNew       | 0.728      |
| AbsLearningOld          | 0.728      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 14.719     |
| AveragePolicyStd        | 0.710838   |
| AverageReturn           | 1.16e+03   |
| Entropy                 | 3.16008    |
| EnvExecTime             | 1.81       |
| ExplainedVariance       | 0.878      |
| Iteration               | 398        |
| ItrTime                 | 7.87       |
| LossAfter               | -0.351362  |
| LossBefore              | -0.326266  |
| MaxReturn               | 1.73e+03   |
| MeanKL                  | 0.00655703 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 829        |
| NumTrajs                | 14         |
| Perplexity              | 23.5725    |
| PolicyExecTime          | 0.468      |
| ProcessExecTime         | 0.0539     |
| StdReturn               | 267        |
| Time                    | 3.27e+03   |
| dLoss                   | 0.0250957  |
----------------------------------------
itr #399 | 
Mem: 707.167969
Obtaining samples...
Obtaining samples for iteration 399...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5306, #subsample_inputs: 5306
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.776      |
| AbsLearnSignalNew       | 0.776      |
| AbsLearningOld          | 0.776      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 14.9541    |
| AveragePolicyStd        | 0.706067   |
| AverageReturn           | 1.21e+03   |
| Entropy                 | 3.14206    |
| EnvExecTime             | 2          |
| ExplainedVariance       | 0.923      |
| Iteration               | 399        |
| ItrTime                 | 8.46       |
| LossAfter               | 0.106435   |
| LossBefore              | 0.130371   |
| MaxReturn               | 1.73e+03   |
| MeanKL                  | 0.00643362 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.01e+03   |
| NumTrajs                | 14         |
| Perplexity              | 23.1516    |
| PolicyExecTime          | 0.506      |
| ProcessExecTime         | 0.0601     |
| StdReturn               | 210        |
| Time                    | 3.28e+03   |
| dLoss                   | 0.023936   |
----------------------------------------
itr #400 | 
Mem: 707.167969
Obtaining samples...
Obtaining samples for iteration 400...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5001, #subsample_inputs: 5001
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.757      |
| AbsLearnSignalNew       | 0.757      |
| AbsLearningOld          | 0.757      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 14.8607    |
| AveragePolicyStd        | 0.708546   |
| AverageReturn           | 1.24e+03   |
| Entropy                 | 3.15029    |
| EnvExecTime             | 1.82       |
| ExplainedVariance       | 0.913      |
| Iteration               | 400        |
| ItrTime                 | 7.84       |
| LossAfter               | 1.24906    |
| LossBefore              | 1.27114    |
| MaxReturn               | 1.62e+03   |
| MeanKL                  | 0.00649222 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 837        |
| NumTrajs                | 13         |
| Perplexity              | 23.3427    |
| PolicyExecTime          | 0.458      |
| ProcessExecTime         | 0.0542     |
| StdReturn               | 229        |
| Time                    | 3.29e+03   |
| dLoss                   | 0.0220779  |
----------------------------------------
itr #401 | 
Mem: 707.167969
Obtaining samples...
Obtaining samples for iteration 401...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5143, #subsample_inputs: 5143
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.778     |
| AbsLearnSignalNew       | 0.778     |
| AbsLearningOld          | 0.778     |
| AverageDiscountedReturn | 242       |
| AveragePhiLoss          | 14.5151   |
| AveragePolicyStd        | 0.706512  |
| AverageReturn           | 1.18e+03  |
| Entropy                 | 3.13813   |
| EnvExecTime             | 1.85      |
| ExplainedVariance       | 0.927     |
| Iteration               | 401       |
| ItrTime                 | 8.01      |
| LossAfter               | 0.455583  |
| LossBefore              | 0.481464  |
| MaxReturn               | 2.13e+03  |
| MeanKL                  | 0.0099307 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 958       |
| NumTrajs                | 14        |
| Perplexity              | 23.0607   |
| PolicyExecTime          | 0.474     |
| ProcessExecTime         | 0.0559    |
| StdReturn               | 292       |
| Time                    | 3.29e+03  |
| dLoss                   | 0.025881  |
---------------------------------------
itr #402 | 
Mem: 707.167969
Obtaining samples...
Obtaining samples for iteration 402...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5091, #subsample_inputs: 5091
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.767      |
| AbsLearnSignalNew       | 0.767      |
| AbsLearningOld          | 0.767      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 14.2533    |
| AveragePolicyStd        | 0.707934   |
| AverageReturn           | 1.24e+03   |
| Entropy                 | 3.13958    |
| EnvExecTime             | 1.95       |
| ExplainedVariance       | 0.912      |
| Iteration               | 402        |
| ItrTime                 | 8.04       |
| LossAfter               | -1.78695   |
| LossBefore              | -1.75397   |
| MaxReturn               | 1.7e+03    |
| MeanKL                  | 0.00957312 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 897        |
| NumTrajs                | 13         |
| Perplexity              | 23.0942    |
| PolicyExecTime          | 0.492      |
| ProcessExecTime         | 0.0574     |
| StdReturn               | 256        |
| Time                    | 3.3e+03    |
| dLoss                   | 0.0329882  |
----------------------------------------
itr #403 | 
Mem: 707.167969
Obtaining samples...
Obtaining samples for iteration 403...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5163, #subsample_inputs: 5163
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.757      |
| AbsLearnSignalNew       | 0.757      |
| AbsLearningOld          | 0.757      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 15.4438    |
| AveragePolicyStd        | 0.708844   |
| AverageReturn           | 1.18e+03   |
| Entropy                 | 3.14615    |
| EnvExecTime             | 1.91       |
| ExplainedVariance       | 0.888      |
| Iteration               | 403        |
| ItrTime                 | 8.06       |
| LossAfter               | -0.211367  |
| LossBefore              | -0.182745  |
| MaxReturn               | 1.83e+03   |
| MeanKL                  | 0.00993217 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 729        |
| NumTrajs                | 14         |
| Perplexity              | 23.2464    |
| PolicyExecTime          | 0.481      |
| ProcessExecTime         | 0.0577     |
| StdReturn               | 318        |
| Time                    | 3.31e+03   |
| dLoss                   | 0.0286215  |
----------------------------------------
itr #404 | 
Mem: 707.167969
Obtaining samples...
Obtaining samples for iteration 404...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5492, #subsample_inputs: 5492
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.471     |
| AbsLearnSignalNew       | 0.471     |
| AbsLearningOld          | 0.471     |
| AverageDiscountedReturn | 239       |
| AveragePhiLoss          | 13.1959   |
| AveragePolicyStd        | 0.707018  |
| AverageReturn           | 1.4e+03   |
| Entropy                 | 3.14047   |
| EnvExecTime             | 2.13      |
| ExplainedVariance       | -0.0553   |
| Iteration               | 404       |
| ItrTime                 | 8.61      |
| LossAfter               | 0.145197  |
| LossBefore              | 0.161673  |
| MaxReturn               | 2.61e+03  |
| MeanKL                  | 0.0065849 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 880       |
| NumTrajs                | 12        |
| Perplexity              | 23.1147   |
| PolicyExecTime          | 0.544     |
| ProcessExecTime         | 0.0641    |
| StdReturn               | 495       |
| Time                    | 3.32e+03  |
| dLoss                   | 0.0164762 |
---------------------------------------
itr #405 | 
Mem: 707.167969
Obtaining samples...
Obtaining samples for iteration 405...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5440, #subsample_inputs: 5440
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.774      |
| AbsLearnSignalNew       | 0.774      |
| AbsLearningOld          | 0.774      |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 14.783     |
| AveragePolicyStd        | 0.707276   |
| AverageReturn           | 1.21e+03   |
| Entropy                 | 3.13923    |
| EnvExecTime             | 2.17       |
| ExplainedVariance       | 0.904      |
| Iteration               | 405        |
| ItrTime                 | 8.67       |
| LossAfter               | 0.446203   |
| LossBefore              | 0.473134   |
| MaxReturn               | 1.7e+03    |
| MeanKL                  | 0.00981876 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.04e+03   |
| NumTrajs                | 14         |
| Perplexity              | 23.0861    |
| PolicyExecTime          | 0.546      |
| ProcessExecTime         | 0.0646     |
| StdReturn               | 176        |
| Time                    | 3.33e+03   |
| dLoss                   | 0.0269315  |
----------------------------------------
itr #406 | 
Mem: 707.167969
Obtaining samples...
Obtaining samples for iteration 406...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5171, #subsample_inputs: 5171
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.754      |
| AbsLearnSignalNew       | 0.754      |
| AbsLearningOld          | 0.754      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 14.0061    |
| AveragePolicyStd        | 0.706627   |
| AverageReturn           | 1.34e+03   |
| Entropy                 | 3.13949    |
| EnvExecTime             | 1.97       |
| ExplainedVariance       | 0.88       |
| Iteration               | 406        |
| ItrTime                 | 8.21       |
| LossAfter               | -0.415577  |
| LossBefore              | -0.393609  |
| MaxReturn               | 2.06e+03   |
| MeanKL                  | 0.00643259 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 886        |
| NumTrajs                | 12         |
| Perplexity              | 23.092     |
| PolicyExecTime          | 0.506      |
| ProcessExecTime         | 0.0592     |
| StdReturn               | 360        |
| Time                    | 3.34e+03   |
| dLoss                   | 0.0219682  |
----------------------------------------
itr #407 | 
Mem: 707.167969
Obtaining samples...
Obtaining samples for iteration 407...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5198, #subsample_inputs: 5198
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.755      |
| AbsLearnSignalNew       | 0.755      |
| AbsLearningOld          | 0.755      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 16.1526    |
| AveragePolicyStd        | 0.702256   |
| AverageReturn           | 1.35e+03   |
| Entropy                 | 3.11769    |
| EnvExecTime             | 1.92       |
| ExplainedVariance       | 0.889      |
| Iteration               | 407        |
| ItrTime                 | 8.17       |
| LossAfter               | -0.46539   |
| LossBefore              | -0.441535  |
| MaxReturn               | 1.97e+03   |
| MeanKL                  | 0.00640905 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 930        |
| NumTrajs                | 12         |
| Perplexity              | 22.5942    |
| PolicyExecTime          | 0.499      |
| ProcessExecTime         | 0.0568     |
| StdReturn               | 376        |
| Time                    | 3.34e+03   |
| dLoss                   | 0.0238557  |
----------------------------------------
itr #408 | 
Mem: 707.167969
Obtaining samples...
Obtaining samples for iteration 408...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5320, #subsample_inputs: 5320
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.654      |
| AbsLearnSignalNew       | 0.654      |
| AbsLearningOld          | 0.654      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 17.3137    |
| AveragePolicyStd        | 0.701998   |
| AverageReturn           | 1.41e+03   |
| Entropy                 | 3.11691    |
| EnvExecTime             | 2.17       |
| ExplainedVariance       | 0.771      |
| Iteration               | 408        |
| ItrTime                 | 8.58       |
| LossAfter               | -0.804365  |
| LossBefore              | -0.773339  |
| MaxReturn               | 2.43e+03   |
| MeanKL                  | 0.00991305 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.04e+03   |
| NumTrajs                | 12         |
| Perplexity              | 22.5766    |
| PolicyExecTime          | 0.547      |
| ProcessExecTime         | 0.0643     |
| StdReturn               | 379        |
| Time                    | 3.35e+03   |
| dLoss                   | 0.0310256  |
----------------------------------------
itr #409 | 
Mem: 707.167969
Obtaining samples...
Obtaining samples for iteration 409...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5054, #subsample_inputs: 5054
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.768      |
| AbsLearnSignalNew       | 0.768      |
| AbsLearningOld          | 0.767      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 15.5387    |
| AveragePolicyStd        | 0.703105   |
| AverageReturn           | 1.08e+03   |
| Entropy                 | 3.12169    |
| EnvExecTime             | 1.7        |
| ExplainedVariance       | 0.924      |
| Iteration               | 409        |
| ItrTime                 | 7.71       |
| LossAfter               | 0.0692058  |
| LossBefore              | 0.0947235  |
| MaxReturn               | 1.31e+03   |
| MeanKL                  | 0.00653217 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 816        |
| NumTrajs                | 15         |
| Perplexity              | 22.6847    |
| PolicyExecTime          | 0.438      |
| ProcessExecTime         | 0.0521     |
| StdReturn               | 160        |
| Time                    | 3.36e+03   |
| dLoss                   | 0.0255177  |
----------------------------------------
itr #410 | 
Mem: 707.167969
Obtaining samples...
Obtaining samples for iteration 410...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5222, #subsample_inputs: 5222
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.637      |
| AbsLearnSignalNew       | 0.637      |
| AbsLearningOld          | 0.637      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 15.1476    |
| AveragePolicyStd        | 0.702272   |
| AverageReturn           | 1.17e+03   |
| Entropy                 | 3.11837    |
| EnvExecTime             | 2.07       |
| ExplainedVariance       | 0.746      |
| Iteration               | 410        |
| ItrTime                 | 8.36       |
| LossAfter               | -0.137707  |
| LossBefore              | -0.107261  |
| MaxReturn               | 1.83e+03   |
| MeanKL                  | 0.00980867 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 898        |
| NumTrajs                | 14         |
| Perplexity              | 22.6095    |
| PolicyExecTime          | 0.522      |
| ProcessExecTime         | 0.0611     |
| StdReturn               | 244        |
| Time                    | 3.37e+03   |
| dLoss                   | 0.0304461  |
----------------------------------------
itr #411 | 
Mem: 707.167969
Obtaining samples...
Obtaining samples for iteration 411...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5142, #subsample_inputs: 5142
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.726      |
| AbsLearnSignalNew       | 0.726      |
| AbsLearningOld          | 0.726      |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 15.5708    |
| AveragePolicyStd        | 0.702472   |
| AverageReturn           | 1.46e+03   |
| Entropy                 | 3.12202    |
| EnvExecTime             | 1.82       |
| ExplainedVariance       | 0.8        |
| Iteration               | 411        |
| ItrTime                 | 7.96       |
| LossAfter               | -0.586424  |
| LossBefore              | -0.5622    |
| MaxReturn               | 2.58e+03   |
| MeanKL                  | 0.00939695 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 963        |
| NumTrajs                | 11         |
| Perplexity              | 22.6923    |
| PolicyExecTime          | 0.464      |
| ProcessExecTime         | 0.0549     |
| StdReturn               | 514        |
| Time                    | 3.38e+03   |
| dLoss                   | 0.0242237  |
----------------------------------------
itr #412 | 
Mem: 707.167969
Obtaining samples...
Obtaining samples for iteration 412...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5311, #subsample_inputs: 5311
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.757      |
| AbsLearnSignalNew       | 0.757      |
| AbsLearningOld          | 0.757      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 15.172     |
| AveragePolicyStd        | 0.701779   |
| AverageReturn           | 1.3e+03    |
| Entropy                 | 3.1193     |
| EnvExecTime             | 1.99       |
| ExplainedVariance       | 0.909      |
| Iteration               | 412        |
| ItrTime                 | 8.31       |
| LossAfter               | -0.540871  |
| LossBefore              | -0.515715  |
| MaxReturn               | 1.74e+03   |
| MeanKL                  | 0.00649294 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 992        |
| NumTrajs                | 13         |
| Perplexity              | 22.6305    |
| PolicyExecTime          | 0.497      |
| ProcessExecTime         | 0.0592     |
| StdReturn               | 228        |
| Time                    | 3.39e+03   |
| dLoss                   | 0.0251554  |
----------------------------------------
itr #413 | 
Mem: 707.167969
Obtaining samples...
Obtaining samples for iteration 413...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5117, #subsample_inputs: 5117
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.757      |
| AbsLearnSignalNew       | 0.757      |
| AbsLearningOld          | 0.757      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 15.3493    |
| AveragePolicyStd        | 0.702308   |
| AverageReturn           | 1.18e+03   |
| Entropy                 | 3.11975    |
| EnvExecTime             | 1.83       |
| ExplainedVariance       | 0.925      |
| Iteration               | 413        |
| ItrTime                 | 7.93       |
| LossAfter               | -0.538497  |
| LossBefore              | -0.510444  |
| MaxReturn               | 1.62e+03   |
| MeanKL                  | 0.00985519 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 921        |
| NumTrajs                | 14         |
| Perplexity              | 22.6407    |
| PolicyExecTime          | 0.461      |
| ProcessExecTime         | 0.055      |
| StdReturn               | 221        |
| Time                    | 3.39e+03   |
| dLoss                   | 0.0280524  |
----------------------------------------
itr #414 | 
Mem: 707.167969
Obtaining samples...
Obtaining samples for iteration 414...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5234, #subsample_inputs: 5234
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.394      |
| AbsLearnSignalNew       | 0.394      |
| AbsLearningOld          | 0.394      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 13.9513    |
| AveragePolicyStd        | 0.701547   |
| AverageReturn           | 1.42e+03   |
| Entropy                 | 3.12104    |
| EnvExecTime             | 1.98       |
| ExplainedVariance       | -0.945     |
| Iteration               | 414        |
| ItrTime                 | 8.26       |
| LossAfter               | -0.29021   |
| LossBefore              | -0.264323  |
| MaxReturn               | 2.5e+03    |
| MeanKL                  | 0.00971505 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 964        |
| NumTrajs                | 11         |
| Perplexity              | 22.67      |
| PolicyExecTime          | 0.513      |
| ProcessExecTime         | 0.0574     |
| StdReturn               | 468        |
| Time                    | 3.4e+03    |
| dLoss                   | 0.0258867  |
----------------------------------------
itr #415 | 
Mem: 707.167969
Obtaining samples...
Obtaining samples for iteration 415...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5092, #subsample_inputs: 5092
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.726      |
| AbsLearnSignalNew       | 0.726      |
| AbsLearningOld          | 0.726      |
| AverageDiscountedReturn | 234        |
| AveragePhiLoss          | 14.3664    |
| AveragePolicyStd        | 0.700178   |
| AverageReturn           | 1.29e+03   |
| Entropy                 | 3.11595    |
| EnvExecTime             | 2.03       |
| ExplainedVariance       | 0.866      |
| Iteration               | 415        |
| ItrTime                 | 8.18       |
| LossAfter               | 0.156043   |
| LossBefore              | 0.176905   |
| MaxReturn               | 1.78e+03   |
| MeanKL                  | 0.00655724 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 906        |
| NumTrajs                | 12         |
| Perplexity              | 22.5549    |
| PolicyExecTime          | 0.516      |
| ProcessExecTime         | 0.0585     |
| StdReturn               | 258        |
| Time                    | 3.41e+03   |
| dLoss                   | 0.0208623  |
----------------------------------------
itr #416 | 
Mem: 707.167969
Obtaining samples...
Obtaining samples for iteration 416...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5306, #subsample_inputs: 5306
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.706      |
| AbsLearnSignalNew       | 0.706      |
| AbsLearningOld          | 0.706      |
| AverageDiscountedReturn | 234        |
| AveragePhiLoss          | 14.9871    |
| AveragePolicyStd        | 0.699345   |
| AverageReturn           | 1.77e+03   |
| Entropy                 | 3.11333    |
| EnvExecTime             | 1.92       |
| ExplainedVariance       | 0.666      |
| Iteration               | 416        |
| ItrTime                 | 8.22       |
| LossAfter               | -0.452171  |
| LossBefore              | -0.422038  |
| MaxReturn               | 2.69e+03   |
| MeanKL                  | 0.00972428 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 956        |
| NumTrajs                | 9          |
| Perplexity              | 22.4958    |
| PolicyExecTime          | 0.498      |
| ProcessExecTime         | 0.0566     |
| StdReturn               | 576        |
| Time                    | 3.42e+03   |
| dLoss                   | 0.0301331  |
----------------------------------------
itr #417 | 
Mem: 707.175781
Obtaining samples...
Obtaining samples for iteration 417...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5368, #subsample_inputs: 5368
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.713     |
| AbsLearnSignalNew       | 0.713     |
| AbsLearningOld          | 0.714     |
| AverageDiscountedReturn | 232       |
| AveragePhiLoss          | 14.0468   |
| AveragePolicyStd        | 0.701588  |
| AverageReturn           | 1.62e+03  |
| Entropy                 | 3.12142   |
| EnvExecTime             | 2.13      |
| ExplainedVariance       | 0.85      |
| Iteration               | 417       |
| ItrTime                 | 8.58      |
| LossAfter               | 0.126717  |
| LossBefore              | 0.148485  |
| MaxReturn               | 1.99e+03  |
| MeanKL                  | 0.0065352 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.03e+03  |
| NumTrajs                | 10        |
| Perplexity              | 22.6786   |
| PolicyExecTime          | 0.539     |
| ProcessExecTime         | 0.0614    |
| StdReturn               | 323       |
| Time                    | 3.43e+03  |
| dLoss                   | 0.021768  |
---------------------------------------
itr #418 | 
Mem: 707.945312
Obtaining samples...
Obtaining samples for iteration 418...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5628, #subsample_inputs: 5628
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.771      |
| AbsLearnSignalNew       | 0.771      |
| AbsLearningOld          | 0.771      |
| AverageDiscountedReturn | 233        |
| AveragePhiLoss          | 15.0124    |
| AveragePolicyStd        | 0.702765   |
| AverageReturn           | 1.66e+03   |
| Entropy                 | 3.12383    |
| EnvExecTime             | 2.35       |
| ExplainedVariance       | 0.748      |
| Iteration               | 418        |
| ItrTime                 | 9.06       |
| LossAfter               | 1.47916    |
| LossBefore              | 1.50059    |
| MaxReturn               | 2.69e+03   |
| MeanKL                  | 0.00649255 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.09e+03   |
| NumTrajs                | 10         |
| Perplexity              | 22.7333    |
| PolicyExecTime          | 0.605      |
| ProcessExecTime         | 0.0673     |
| StdReturn               | 446        |
| Time                    | 3.44e+03   |
| dLoss                   | 0.0214337  |
----------------------------------------
itr #419 | 
Mem: 708.191406
Obtaining samples...
Obtaining samples for iteration 419...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5211, #subsample_inputs: 5211
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.726      |
| AbsLearnSignalNew       | 0.726      |
| AbsLearningOld          | 0.726      |
| AverageDiscountedReturn | 236        |
| AveragePhiLoss          | 14.1386    |
| AveragePolicyStd        | 0.705026   |
| AverageReturn           | 1.46e+03   |
| Entropy                 | 3.13195    |
| EnvExecTime             | 1.86       |
| ExplainedVariance       | 0.862      |
| Iteration               | 419        |
| ItrTime                 | 8.07       |
| LossAfter               | 0.472694   |
| LossBefore              | 0.493928   |
| MaxReturn               | 1.92e+03   |
| MeanKL                  | 0.00640617 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.02e+03   |
| NumTrajs                | 11         |
| Perplexity              | 22.9186    |
| PolicyExecTime          | 0.478      |
| ProcessExecTime         | 0.0563     |
| StdReturn               | 276        |
| Time                    | 3.44e+03   |
| dLoss                   | 0.0212346  |
----------------------------------------
itr #420 | 
Mem: 708.191406
Obtaining samples...
Obtaining samples for iteration 420...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5032, #subsample_inputs: 5032
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.76      |
| AbsLearnSignalNew       | 0.76      |
| AbsLearningOld          | 0.76      |
| AverageDiscountedReturn | 233       |
| AveragePhiLoss          | 14.8277   |
| AveragePolicyStd        | 0.702127  |
| AverageReturn           | 1.36e+03  |
| Entropy                 | 3.12388   |
| EnvExecTime             | 1.85      |
| ExplainedVariance       | 0.763     |
| Iteration               | 420       |
| ItrTime                 | 7.91      |
| LossAfter               | 0.366172  |
| LossBefore              | 0.388269  |
| MaxReturn               | 2.64e+03  |
| MeanKL                  | 0.0064827 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.02e+03  |
| NumTrajs                | 11        |
| Perplexity              | 22.7345   |
| PolicyExecTime          | 0.472     |
| ProcessExecTime         | 0.0554    |
| StdReturn               | 489       |
| Time                    | 3.45e+03  |
| dLoss                   | 0.0220973 |
---------------------------------------
itr #421 | 
Mem: 708.191406
Obtaining samples...
Obtaining samples for iteration 421...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5145, #subsample_inputs: 5145
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.755      |
| AbsLearnSignalNew       | 0.755      |
| AbsLearningOld          | 0.755      |
| AverageDiscountedReturn | 235        |
| AveragePhiLoss          | 15.3679    |
| AveragePolicyStd        | 0.701074   |
| AverageReturn           | 1.44e+03   |
| Entropy                 | 3.11671    |
| EnvExecTime             | 1.78       |
| ExplainedVariance       | 0.858      |
| Iteration               | 421        |
| ItrTime                 | 7.91       |
| LossAfter               | 0.100598   |
| LossBefore              | 0.129901   |
| MaxReturn               | 1.8e+03    |
| MeanKL                  | 0.00987899 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.06e+03   |
| NumTrajs                | 11         |
| Perplexity              | 22.5719    |
| PolicyExecTime          | 0.465      |
| ProcessExecTime         | 0.0535     |
| StdReturn               | 262        |
| Time                    | 3.46e+03   |
| dLoss                   | 0.0293039  |
----------------------------------------
itr #422 | 
Mem: 708.191406
Obtaining samples...
Obtaining samples for iteration 422...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5442, #subsample_inputs: 5442
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.753      |
| AbsLearnSignalNew       | 0.753      |
| AbsLearningOld          | 0.754      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 15.8584    |
| AveragePolicyStd        | 0.701935   |
| AverageReturn           | 1.42e+03   |
| Entropy                 | 3.11886    |
| EnvExecTime             | 2.08       |
| ExplainedVariance       | 0.883      |
| Iteration               | 422        |
| ItrTime                 | 8.56       |
| LossAfter               | 0.409544   |
| LossBefore              | 0.436397   |
| MaxReturn               | 2.4e+03    |
| MeanKL                  | 0.00991347 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 864        |
| NumTrajs                | 12         |
| Perplexity              | 22.6206    |
| PolicyExecTime          | 0.54       |
| ProcessExecTime         | 0.0602     |
| StdReturn               | 439        |
| Time                    | 3.47e+03   |
| dLoss                   | 0.0268533  |
----------------------------------------
itr #423 | 
Mem: 708.191406
Obtaining samples...
Obtaining samples for iteration 423...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5252, #subsample_inputs: 5252
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.662      |
| AbsLearnSignalNew       | 0.662      |
| AbsLearningOld          | 0.662      |
| AverageDiscountedReturn | 235        |
| AveragePhiLoss          | 14.4436    |
| AveragePolicyStd        | 0.700512   |
| AverageReturn           | 1.42e+03   |
| Entropy                 | 3.11351    |
| EnvExecTime             | 1.91       |
| ExplainedVariance       | 0.719      |
| Iteration               | 423        |
| ItrTime                 | 8.15       |
| LossAfter               | 0.312167   |
| LossBefore              | 0.337477   |
| MaxReturn               | 2.53e+03   |
| MeanKL                  | 0.00999666 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 894        |
| NumTrajs                | 11         |
| Perplexity              | 22.4998    |
| PolicyExecTime          | 0.493      |
| ProcessExecTime         | 0.0562     |
| StdReturn               | 492        |
| Time                    | 3.48e+03   |
| dLoss                   | 0.0253102  |
----------------------------------------
itr #424 | 
Mem: 708.191406
Obtaining samples...
Obtaining samples for iteration 424...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5187, #subsample_inputs: 5187
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.747      |
| AbsLearnSignalNew       | 0.747      |
| AbsLearningOld          | 0.747      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 14.9758    |
| AveragePolicyStd        | 0.696943   |
| AverageReturn           | 1.22e+03   |
| Entropy                 | 3.10231    |
| EnvExecTime             | 2.17       |
| ExplainedVariance       | 0.899      |
| Iteration               | 424        |
| ItrTime                 | 8.46       |
| LossAfter               | 0.221619   |
| LossBefore              | 0.244575   |
| MaxReturn               | 1.72e+03   |
| MeanKL                  | 0.00649081 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.04e+03   |
| NumTrajs                | 13         |
| Perplexity              | 22.2493    |
| PolicyExecTime          | 0.554      |
| ProcessExecTime         | 0.0615     |
| StdReturn               | 248        |
| Time                    | 3.49e+03   |
| dLoss                   | 0.0229558  |
----------------------------------------
itr #425 | 
Mem: 708.191406
Obtaining samples...
Obtaining samples for iteration 425...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5274, #subsample_inputs: 5274
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.767      |
| AbsLearnSignalNew       | 0.767      |
| AbsLearningOld          | 0.767      |
| AverageDiscountedReturn | 234        |
| AveragePhiLoss          | 15.3255    |
| AveragePolicyStd        | 0.695203   |
| AverageReturn           | 1.45e+03   |
| Entropy                 | 3.09553    |
| EnvExecTime             | 1.85       |
| ExplainedVariance       | 0.825      |
| Iteration               | 425        |
| ItrTime                 | 8.11       |
| LossAfter               | 0.251662   |
| LossBefore              | 0.276142   |
| MaxReturn               | 2.39e+03   |
| MeanKL                  | 0.00990553 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.04e+03   |
| NumTrajs                | 11         |
| Perplexity              | 22.099     |
| PolicyExecTime          | 0.476      |
| ProcessExecTime         | 0.0547     |
| StdReturn               | 369        |
| Time                    | 3.49e+03   |
| dLoss                   | 0.0244802  |
----------------------------------------
itr #426 | 
Mem: 708.191406
Obtaining samples...
Obtaining samples for iteration 426...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5376, #subsample_inputs: 5376
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.75       |
| AbsLearnSignalNew       | 0.75       |
| AbsLearningOld          | 0.75       |
| AverageDiscountedReturn | 233        |
| AveragePhiLoss          | 15.0138    |
| AveragePolicyStd        | 0.693035   |
| AverageReturn           | 1.64e+03   |
| Entropy                 | 3.08543    |
| EnvExecTime             | 2.3        |
| ExplainedVariance       | 0.888      |
| Iteration               | 426        |
| ItrTime                 | 8.81       |
| LossAfter               | 0.378518   |
| LossBefore              | 0.397448   |
| MaxReturn               | 2.07e+03   |
| MeanKL                  | 0.00641342 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.11e+03   |
| NumTrajs                | 10         |
| Perplexity              | 21.8769    |
| PolicyExecTime          | 0.58       |
| ProcessExecTime         | 0.0674     |
| StdReturn               | 304        |
| Time                    | 3.5e+03    |
| dLoss                   | 0.0189301  |
----------------------------------------
itr #427 | 
Mem: 708.191406
Obtaining samples...
Obtaining samples for iteration 427...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5341, #subsample_inputs: 5341
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.73       |
| AbsLearnSignalNew       | 0.73       |
| AbsLearningOld          | 0.73       |
| AverageDiscountedReturn | 234        |
| AveragePhiLoss          | 15.4768    |
| AveragePolicyStd        | 0.689356   |
| AverageReturn           | 1.45e+03   |
| Entropy                 | 3.07209    |
| EnvExecTime             | 2.11       |
| ExplainedVariance       | 0.743      |
| Iteration               | 427        |
| ItrTime                 | 8.53       |
| LossAfter               | -0.442685  |
| LossBefore              | -0.412659  |
| MaxReturn               | 2.57e+03   |
| MeanKL                  | 0.00990075 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 942        |
| NumTrajs                | 11         |
| Perplexity              | 21.587     |
| PolicyExecTime          | 0.543      |
| ProcessExecTime         | 0.0614     |
| StdReturn               | 454        |
| Time                    | 3.51e+03   |
| dLoss                   | 0.0300254  |
----------------------------------------
itr #428 | 
Mem: 708.191406
Obtaining samples...
Obtaining samples for iteration 428...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5705, #subsample_inputs: 5705
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.601      |
| AbsLearnSignalNew       | 0.601      |
| AbsLearningOld          | 0.601      |
| AverageDiscountedReturn | 223        |
| AveragePhiLoss          | 13.0719    |
| AveragePolicyStd        | 0.691836   |
| AverageReturn           | 1.74e+03   |
| Entropy                 | 3.08104    |
| EnvExecTime             | 2.13       |
| ExplainedVariance       | 0.438      |
| Iteration               | 428        |
| ItrTime                 | 8.8        |
| LossAfter               | -0.279521  |
| LossBefore              | -0.262185  |
| MaxReturn               | 2.54e+03   |
| MeanKL                  | 0.00640877 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 844        |
| NumTrajs                | 9          |
| Perplexity              | 21.781     |
| PolicyExecTime          | 0.538      |
| ProcessExecTime         | 0.0639     |
| StdReturn               | 586        |
| Time                    | 3.52e+03   |
| dLoss                   | 0.017336   |
----------------------------------------
itr #429 | 
Mem: 709.679688
Obtaining samples...
Obtaining samples for iteration 429...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5132, #subsample_inputs: 5132
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.749      |
| AbsLearnSignalNew       | 0.749      |
| AbsLearningOld          | 0.749      |
| AverageDiscountedReturn | 232        |
| AveragePhiLoss          | 14.3862    |
| AveragePolicyStd        | 0.690745   |
| AverageReturn           | 1.53e+03   |
| Entropy                 | 3.08057    |
| EnvExecTime             | 1.96       |
| ExplainedVariance       | 0.823      |
| Iteration               | 429        |
| ItrTime                 | 8.12       |
| LossAfter               | -0.393583  |
| LossBefore              | -0.36718   |
| MaxReturn               | 2.17e+03   |
| MeanKL                  | 0.00648768 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.08e+03   |
| NumTrajs                | 10         |
| Perplexity              | 21.7709    |
| PolicyExecTime          | 0.499      |
| ProcessExecTime         | 0.0573     |
| StdReturn               | 316        |
| Time                    | 3.53e+03   |
| dLoss                   | 0.0264026  |
----------------------------------------
itr #430 | 
Mem: 709.679688
Obtaining samples...
Obtaining samples for iteration 430...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5218, #subsample_inputs: 5218
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.751     |
| AbsLearnSignalNew       | 0.751     |
| AbsLearningOld          | 0.751     |
| AverageDiscountedReturn | 228       |
| AveragePhiLoss          | 15.2572   |
| AveragePolicyStd        | 0.689931  |
| AverageReturn           | 1.91e+03  |
| Entropy                 | 3.07773   |
| EnvExecTime             | 2.13      |
| ExplainedVariance       | 0.745     |
| Iteration               | 430       |
| ItrTime                 | 8.44      |
| LossAfter               | 0.46114   |
| LossBefore              | 0.485852  |
| MaxReturn               | 2.66e+03  |
| MeanKL                  | 0.0064134 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 953       |
| NumTrajs                | 8         |
| Perplexity              | 21.7091   |
| PolicyExecTime          | 0.541     |
| ProcessExecTime         | 0.0617    |
| StdReturn               | 492       |
| Time                    | 3.54e+03  |
| dLoss                   | 0.024712  |
---------------------------------------
itr #431 | 
Mem: 709.738281
Obtaining samples...
Obtaining samples for iteration 431...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5116, #subsample_inputs: 5116
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.735      |
| AbsLearnSignalNew       | 0.735      |
| AbsLearningOld          | 0.735      |
| AverageDiscountedReturn | 231        |
| AveragePhiLoss          | 15.0146    |
| AveragePolicyStd        | 0.688094   |
| AverageReturn           | 1.68e+03   |
| Entropy                 | 3.0663     |
| EnvExecTime             | 2.21       |
| ExplainedVariance       | 0.835      |
| Iteration               | 431        |
| ItrTime                 | 8.42       |
| LossAfter               | 0.470891   |
| LossBefore              | 0.497226   |
| MaxReturn               | 2.08e+03   |
| MeanKL                  | 0.00984881 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.09e+03   |
| NumTrajs                | 9          |
| Perplexity              | 21.4624    |
| PolicyExecTime          | 0.563      |
| ProcessExecTime         | 0.0627     |
| StdReturn               | 307        |
| Time                    | 3.54e+03   |
| dLoss                   | 0.0263351  |
----------------------------------------
itr #432 | 
Mem: 709.738281
Obtaining samples...
Obtaining samples for iteration 432...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5360, #subsample_inputs: 5360
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.745      |
| AbsLearnSignalNew       | 0.745      |
| AbsLearningOld          | 0.745      |
| AverageDiscountedReturn | 230        |
| AveragePhiLoss          | 15.8152    |
| AveragePolicyStd        | 0.691866   |
| AverageReturn           | 1.61e+03   |
| Entropy                 | 3.07692    |
| EnvExecTime             | 2.1        |
| ExplainedVariance       | 0.865      |
| Iteration               | 432        |
| ItrTime                 | 8.57       |
| LossAfter               | -0.46178   |
| LossBefore              | -0.438116  |
| MaxReturn               | 2.06e+03   |
| MeanKL                  | 0.00996951 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.22e+03   |
| NumTrajs                | 10         |
| Perplexity              | 21.6916    |
| PolicyExecTime          | 0.532      |
| ProcessExecTime         | 0.0613     |
| StdReturn               | 300        |
| Time                    | 3.55e+03   |
| dLoss                   | 0.0236638  |
----------------------------------------
itr #433 | 
Mem: 709.738281
Obtaining samples...
Obtaining samples for iteration 433...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5034, #subsample_inputs: 5034
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.652      |
| AbsLearnSignalNew       | 0.652      |
| AbsLearningOld          | 0.652      |
| AverageDiscountedReturn | 230        |
| AveragePhiLoss          | 16.5323    |
| AveragePolicyStd        | 0.690109   |
| AverageReturn           | 1.47e+03   |
| Entropy                 | 3.06941    |
| EnvExecTime             | 1.94       |
| ExplainedVariance       | 0.711      |
| Iteration               | 433        |
| ItrTime                 | 8.03       |
| LossAfter               | 0.148308   |
| LossBefore              | 0.173825   |
| MaxReturn               | 2.59e+03   |
| MeanKL                  | 0.00964424 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 737        |
| NumTrajs                | 10         |
| Perplexity              | 21.5292    |
| PolicyExecTime          | 0.504      |
| ProcessExecTime         | 0.0564     |
| StdReturn               | 470        |
| Time                    | 3.56e+03   |
| dLoss                   | 0.0255177  |
----------------------------------------
itr #434 | 
Mem: 709.738281
Obtaining samples...
Obtaining samples for iteration 434...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5358, #subsample_inputs: 5358
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.724     |
| AbsLearnSignalNew       | 0.724     |
| AbsLearningOld          | 0.724     |
| AverageDiscountedReturn | 230       |
| AveragePhiLoss          | 18.2179   |
| AveragePolicyStd        | 0.690322  |
| AverageReturn           | 1.63e+03  |
| Entropy                 | 3.07274   |
| EnvExecTime             | 2.13      |
| ExplainedVariance       | 0.831     |
| Iteration               | 434       |
| ItrTime                 | 8.64      |
| LossAfter               | 0.0948374 |
| LossBefore              | 0.120421  |
| MaxReturn               | 2.15e+03  |
| MeanKL                  | 0.0064077 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 987       |
| NumTrajs                | 10        |
| Perplexity              | 21.6009   |
| PolicyExecTime          | 0.558     |
| ProcessExecTime         | 0.0606    |
| StdReturn               | 339       |
| Time                    | 3.57e+03  |
| dLoss                   | 0.0255841 |
---------------------------------------
itr #435 | 
Mem: 709.738281
Obtaining samples...
Obtaining samples for iteration 435...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5401, #subsample_inputs: 5401
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.673      |
| AbsLearnSignalNew       | 0.673      |
| AbsLearningOld          | 0.673      |
| AverageDiscountedReturn | 229        |
| AveragePhiLoss          | 13.3821    |
| AveragePolicyStd        | 0.689044   |
| AverageReturn           | 1.59e+03   |
| Entropy                 | 3.06921    |
| EnvExecTime             | 2.19       |
| ExplainedVariance       | 0.755      |
| Iteration               | 435        |
| ItrTime                 | 8.73       |
| LossAfter               | -0.133261  |
| LossBefore              | -0.110489  |
| MaxReturn               | 2.23e+03   |
| MeanKL                  | 0.00982904 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 889        |
| NumTrajs                | 10         |
| Perplexity              | 21.5249    |
| PolicyExecTime          | 0.564      |
| ProcessExecTime         | 0.0638     |
| StdReturn               | 475        |
| Time                    | 3.58e+03   |
| dLoss                   | 0.0227719  |
----------------------------------------
itr #436 | 
Mem: 709.738281
Obtaining samples...
Obtaining samples for iteration 436...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5257, #subsample_inputs: 5257
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.685     |
| AbsLearnSignalNew       | 0.685     |
| AbsLearningOld          | 0.685     |
| AverageDiscountedReturn | 231       |
| AveragePhiLoss          | 15.1737   |
| AveragePolicyStd        | 0.692685  |
| AverageReturn           | 1.58e+03  |
| Entropy                 | 3.08503   |
| EnvExecTime             | 1.81      |
| ExplainedVariance       | 0.73      |
| Iteration               | 436       |
| ItrTime                 | 8.01      |
| LossAfter               | 0.353909  |
| LossBefore              | 0.381239  |
| MaxReturn               | 2.68e+03  |
| MeanKL                  | 0.0099948 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 834       |
| NumTrajs                | 10        |
| Perplexity              | 21.868    |
| PolicyExecTime          | 0.468     |
| ProcessExecTime         | 0.0542    |
| StdReturn               | 531       |
| Time                    | 3.59e+03  |
| dLoss                   | 0.0273302 |
---------------------------------------
itr #437 | 
Mem: 709.738281
Obtaining samples...
Obtaining samples for iteration 437...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5513, #subsample_inputs: 5513
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.736      |
| AbsLearnSignalNew       | 0.736      |
| AbsLearningOld          | 0.736      |
| AverageDiscountedReturn | 235        |
| AveragePhiLoss          | 16.5729    |
| AveragePolicyStd        | 0.693164   |
| AverageReturn           | 1.68e+03   |
| Entropy                 | 3.08649    |
| EnvExecTime             | 1.97       |
| ExplainedVariance       | 0.846      |
| Iteration               | 437        |
| ItrTime                 | 8.39       |
| LossAfter               | -0.153532  |
| LossBefore              | -0.129289  |
| MaxReturn               | 3.03e+03   |
| MeanKL                  | 0.00648252 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 988        |
| NumTrajs                | 10         |
| Perplexity              | 21.9       |
| PolicyExecTime          | 0.507      |
| ProcessExecTime         | 0.0589     |
| StdReturn               | 681        |
| Time                    | 3.6e+03    |
| dLoss                   | 0.0242428  |
----------------------------------------
itr #438 | 
Mem: 709.738281
Obtaining samples...
Obtaining samples for iteration 438...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5105, #subsample_inputs: 5105
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.7        |
| AbsLearnSignalNew       | 0.7        |
| AbsLearningOld          | 0.7        |
| AverageDiscountedReturn | 229        |
| AveragePhiLoss          | 14.8423    |
| AveragePolicyStd        | 0.688524   |
| AverageReturn           | 1.39e+03   |
| Entropy                 | 3.06624    |
| EnvExecTime             | 2.02       |
| ExplainedVariance       | 0.735      |
| Iteration               | 438        |
| ItrTime                 | 8.21       |
| LossAfter               | -0.642236  |
| LossBefore              | -0.624295  |
| MaxReturn               | 2.61e+03   |
| MeanKL                  | 0.00644685 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 699        |
| NumTrajs                | 11         |
| Perplexity              | 21.4611    |
| PolicyExecTime          | 0.516      |
| ProcessExecTime         | 0.0573     |
| StdReturn               | 524        |
| Time                    | 3.6e+03    |
| dLoss                   | 0.0179406  |
----------------------------------------
itr #439 | 
Mem: 709.738281
Obtaining samples...
Obtaining samples for iteration 439...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5190, #subsample_inputs: 5190
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.761      |
| AbsLearnSignalNew       | 0.761      |
| AbsLearningOld          | 0.761      |
| AverageDiscountedReturn | 235        |
| AveragePhiLoss          | 16.263     |
| AveragePolicyStd        | 0.685117   |
| AverageReturn           | 1.77e+03   |
| Entropy                 | 3.05275    |
| EnvExecTime             | 2.11       |
| ExplainedVariance       | 0.861      |
| Iteration               | 439        |
| ItrTime                 | 8.37       |
| LossAfter               | 0.103397   |
| LossBefore              | 0.13344    |
| MaxReturn               | 2.53e+03   |
| MeanKL                  | 0.00976878 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.22e+03   |
| NumTrajs                | 9          |
| Perplexity              | 21.1735    |
| PolicyExecTime          | 0.533      |
| ProcessExecTime         | 0.062      |
| StdReturn               | 388        |
| Time                    | 3.61e+03   |
| dLoss                   | 0.0300429  |
----------------------------------------
itr #440 | 
Mem: 709.738281
Obtaining samples...
Obtaining samples for iteration 440...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5027, #subsample_inputs: 5027
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.772      |
| AbsLearnSignalNew       | 0.772      |
| AbsLearningOld          | 0.772      |
| AverageDiscountedReturn | 233        |
| AveragePhiLoss          | 15.3168    |
| AveragePolicyStd        | 0.685613   |
| AverageReturn           | 1.7e+03    |
| Entropy                 | 3.05779    |
| EnvExecTime             | 2.05       |
| ExplainedVariance       | 0.851      |
| Iteration               | 440        |
| ItrTime                 | 8.17       |
| LossAfter               | 0.295029   |
| LossBefore              | 0.31808    |
| MaxReturn               | 2.48e+03   |
| MeanKL                  | 0.00995732 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 957        |
| NumTrajs                | 9          |
| Perplexity              | 21.2804    |
| PolicyExecTime          | 0.532      |
| ProcessExecTime         | 0.0583     |
| StdReturn               | 471        |
| Time                    | 3.62e+03   |
| dLoss                   | 0.0230508  |
----------------------------------------
itr #441 | 
Mem: 709.738281
Obtaining samples...
Obtaining samples for iteration 441...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5662, #subsample_inputs: 5662
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.755      |
| AbsLearnSignalNew       | 0.755      |
| AbsLearningOld          | 0.755      |
| AverageDiscountedReturn | 224        |
| AveragePhiLoss          | 16.7908    |
| AveragePolicyStd        | 0.685082   |
| AverageReturn           | 1.48e+03   |
| Entropy                 | 3.05683    |
| EnvExecTime             | 2.12       |
| ExplainedVariance       | 0.747      |
| Iteration               | 441        |
| ItrTime                 | 8.74       |
| LossAfter               | -0.667947  |
| LossBefore              | -0.64069   |
| MaxReturn               | 2.76e+03   |
| MeanKL                  | 0.00985159 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 700        |
| NumTrajs                | 11         |
| Perplexity              | 21.26      |
| PolicyExecTime          | 0.549      |
| ProcessExecTime         | 0.0624     |
| StdReturn               | 670        |
| Time                    | 3.63e+03   |
| dLoss                   | 0.0272574  |
----------------------------------------
itr #442 | 
Mem: 709.738281
Obtaining samples...
Obtaining samples for iteration 442...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5313, #subsample_inputs: 5313
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.68       |
| AbsLearnSignalNew       | 0.68       |
| AbsLearningOld          | 0.68       |
| AverageDiscountedReturn | 226        |
| AveragePhiLoss          | 15.8947    |
| AveragePolicyStd        | 0.684955   |
| AverageReturn           | 1.28e+03   |
| Entropy                 | 3.06025    |
| EnvExecTime             | 2.34       |
| ExplainedVariance       | 0.72       |
| Iteration               | 442        |
| ItrTime                 | 8.77       |
| LossAfter               | 0.0925634  |
| LossBefore              | 0.119881   |
| MaxReturn               | 2.6e+03    |
| MeanKL                  | 0.00997147 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 798        |
| NumTrajs                | 12         |
| Perplexity              | 21.3329    |
| PolicyExecTime          | 0.599      |
| ProcessExecTime         | 0.0666     |
| StdReturn               | 560        |
| Time                    | 3.64e+03   |
| dLoss                   | 0.0273179  |
----------------------------------------
itr #443 | 
Mem: 709.738281
Obtaining samples...
Obtaining samples for iteration 443...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5355, #subsample_inputs: 5355
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.742      |
| AbsLearnSignalNew       | 0.742      |
| AbsLearningOld          | 0.742      |
| AverageDiscountedReturn | 228        |
| AveragePhiLoss          | 14.8318    |
| AveragePolicyStd        | 0.686005   |
| AverageReturn           | 1.91e+03   |
| Entropy                 | 3.06517    |
| EnvExecTime             | 1.96       |
| ExplainedVariance       | 0.848      |
| Iteration               | 443        |
| ItrTime                 | 8.42       |
| LossAfter               | -1.13241   |
| LossBefore              | -1.10521   |
| MaxReturn               | 2.66e+03   |
| MeanKL                  | 0.00991635 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 846        |
| NumTrajs                | 8          |
| Perplexity              | 21.4382    |
| PolicyExecTime          | 0.498      |
| ProcessExecTime         | 0.0579     |
| StdReturn               | 591        |
| Time                    | 3.65e+03   |
| dLoss                   | 0.0271999  |
----------------------------------------
itr #444 | 
Mem: 710.238281
Obtaining samples...
Obtaining samples for iteration 444...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5177, #subsample_inputs: 5177
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.697      |
| AbsLearnSignalNew       | 0.697      |
| AbsLearningOld          | 0.697      |
| AverageDiscountedReturn | 227        |
| AveragePhiLoss          | 20.4036    |
| AveragePolicyStd        | 0.687162   |
| AverageReturn           | 1.84e+03   |
| Entropy                 | 3.06508    |
| EnvExecTime             | 1.97       |
| ExplainedVariance       | 0.76       |
| Iteration               | 444        |
| ItrTime                 | 8.17       |
| LossAfter               | -0.678944  |
| LossBefore              | -0.636388  |
| MaxReturn               | 2.65e+03   |
| MeanKL                  | 0.00998189 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 736        |
| NumTrajs                | 8          |
| Perplexity              | 21.4362    |
| PolicyExecTime          | 0.503      |
| ProcessExecTime         | 0.0597     |
| StdReturn               | 636        |
| Time                    | 3.65e+03   |
| dLoss                   | 0.0425559  |
----------------------------------------
itr #445 | 
Mem: 710.238281
Obtaining samples...
Obtaining samples for iteration 445...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5038, #subsample_inputs: 5038
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.707      |
| AbsLearnSignalNew       | 0.707      |
| AbsLearningOld          | 0.706      |
| AverageDiscountedReturn | 224        |
| AveragePhiLoss          | 16.0781    |
| AveragePolicyStd        | 0.687163   |
| AverageReturn           | 1.74e+03   |
| Entropy                 | 3.06639    |
| EnvExecTime             | 2.11       |
| ExplainedVariance       | 0.817      |
| Iteration               | 445        |
| ItrTime                 | 8.18       |
| LossAfter               | -0.02704   |
| LossBefore              | 0.00158154 |
| MaxReturn               | 2.62e+03   |
| MeanKL                  | 0.00994277 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 648        |
| NumTrajs                | 8          |
| Perplexity              | 21.4643    |
| PolicyExecTime          | 0.539      |
| ProcessExecTime         | 0.0588     |
| StdReturn               | 706        |
| Time                    | 3.66e+03   |
| dLoss                   | 0.0286215  |
----------------------------------------
itr #446 | 
Mem: 710.238281
Obtaining samples...
Obtaining samples for iteration 446...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5256, #subsample_inputs: 5256
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.689      |
| AbsLearnSignalNew       | 0.689      |
| AbsLearningOld          | 0.689      |
| AverageDiscountedReturn | 228        |
| AveragePhiLoss          | 15.9151    |
| AveragePolicyStd        | 0.686362   |
| AverageReturn           | 1.91e+03   |
| Entropy                 | 3.06127    |
| EnvExecTime             | 1.98       |
| ExplainedVariance       | 0.714      |
| Iteration               | 446        |
| ItrTime                 | 8.21       |
| LossAfter               | 0.500071   |
| LossBefore              | 0.524592   |
| MaxReturn               | 2.81e+03   |
| MeanKL                  | 0.00983711 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.18e+03   |
| NumTrajs                | 8          |
| Perplexity              | 21.3546    |
| PolicyExecTime          | 0.511      |
| ProcessExecTime         | 0.0587     |
| StdReturn               | 579        |
| Time                    | 3.67e+03   |
| dLoss                   | 0.0245211  |
----------------------------------------
itr #447 | 
Mem: 710.238281
Obtaining samples...
Obtaining samples for iteration 447...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5268, #subsample_inputs: 5268
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.74       |
| AbsLearnSignalNew       | 0.74       |
| AbsLearningOld          | 0.74       |
| AverageDiscountedReturn | 231        |
| AveragePhiLoss          | 16.2232    |
| AveragePolicyStd        | 0.688348   |
| AverageReturn           | 1.78e+03   |
| Entropy                 | 3.06982    |
| EnvExecTime             | 2.16       |
| ExplainedVariance       | 0.832      |
| Iteration               | 447        |
| ItrTime                 | 8.48       |
| LossAfter               | -0.82156   |
| LossBefore              | -0.797531  |
| MaxReturn               | 2.58e+03   |
| MeanKL                  | 0.00642072 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.44e+03   |
| NumTrajs                | 9          |
| Perplexity              | 21.5381    |
| PolicyExecTime          | 0.55       |
| ProcessExecTime         | 0.0635     |
| StdReturn               | 339        |
| Time                    | 3.68e+03   |
| dLoss                   | 0.0240285  |
----------------------------------------
itr #448 | 
Mem: 710.238281
Obtaining samples...
Obtaining samples for iteration 448...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5854, #subsample_inputs: 5854
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.571      |
| AbsLearnSignalNew       | 0.571      |
| AbsLearningOld          | 0.571      |
| AverageDiscountedReturn | 232        |
| AveragePhiLoss          | 16.6958    |
| AveragePolicyStd        | 0.688457   |
| AverageReturn           | 2.1e+03    |
| Entropy                 | 3.06911    |
| EnvExecTime             | 2.24       |
| ExplainedVariance       | 0.548      |
| Iteration               | 448        |
| ItrTime                 | 9.01       |
| LossAfter               | -0.517783  |
| LossBefore              | -0.501244  |
| MaxReturn               | 2.74e+03   |
| MeanKL                  | 0.00649644 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.53e+03   |
| NumTrajs                | 8          |
| Perplexity              | 21.5226    |
| PolicyExecTime          | 0.58       |
| ProcessExecTime         | 0.065      |
| StdReturn               | 456        |
| Time                    | 3.69e+03   |
| dLoss                   | 0.0165388  |
----------------------------------------
itr #449 | 
Mem: 710.246094
Obtaining samples...
Obtaining samples for iteration 449...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5360, #subsample_inputs: 5360
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.677      |
| AbsLearnSignalNew       | 0.677      |
| AbsLearningOld          | 0.677      |
| AverageDiscountedReturn | 231        |
| AveragePhiLoss          | 15.5206    |
| AveragePolicyStd        | 0.68752    |
| AverageReturn           | 1.94e+03   |
| Entropy                 | 3.06359    |
| EnvExecTime             | 2.26       |
| ExplainedVariance       | 0.823      |
| Iteration               | 449        |
| ItrTime                 | 8.75       |
| LossAfter               | -0.433831  |
| LossBefore              | -0.406606  |
| MaxReturn               | 2.92e+03   |
| MeanKL                  | 0.00987081 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 952        |
| NumTrajs                | 8          |
| Perplexity              | 21.4043    |
| PolicyExecTime          | 0.556      |
| ProcessExecTime         | 0.0689     |
| StdReturn               | 616        |
| Time                    | 3.7e+03    |
| dLoss                   | 0.0272249  |
----------------------------------------
itr #450 | 
Mem: 710.246094
Obtaining samples...
Obtaining samples for iteration 450...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5379, #subsample_inputs: 5379
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.756      |
| AbsLearnSignalNew       | 0.756      |
| AbsLearningOld          | 0.756      |
| AverageDiscountedReturn | 228        |
| AveragePhiLoss          | 17.3787    |
| AveragePolicyStd        | 0.688204   |
| AverageReturn           | 1.7e+03    |
| Entropy                 | 3.06743    |
| EnvExecTime             | 1.89       |
| ExplainedVariance       | 0.836      |
| Iteration               | 450        |
| ItrTime                 | 8.35       |
| LossAfter               | -0.876057  |
| LossBefore              | -0.853263  |
| MaxReturn               | 2.62e+03   |
| MeanKL                  | 0.00659739 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 791        |
| NumTrajs                | 9          |
| Perplexity              | 21.4867    |
| PolicyExecTime          | 0.487      |
| ProcessExecTime         | 0.0566     |
| StdReturn               | 662        |
| Time                    | 3.71e+03   |
| dLoss                   | 0.0227939  |
----------------------------------------
itr #451 | 
Mem: 710.246094
Obtaining samples...
Obtaining samples for iteration 451...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5157, #subsample_inputs: 5157
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.643      |
| AbsLearnSignalNew       | 0.643      |
| AbsLearningOld          | 0.643      |
| AverageDiscountedReturn | 226        |
| AveragePhiLoss          | 17.0127    |
| AveragePolicyStd        | 0.688052   |
| AverageReturn           | 1.85e+03   |
| Entropy                 | 3.0665     |
| EnvExecTime             | 2.23       |
| ExplainedVariance       | 0.654      |
| Iteration               | 451        |
| ItrTime                 | 8.49       |
| LossAfter               | -0.293502  |
| LossBefore              | -0.266154  |
| MaxReturn               | 2.99e+03   |
| MeanKL                  | 0.00991412 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 968        |
| NumTrajs                | 8          |
| Perplexity              | 21.4667    |
| PolicyExecTime          | 0.554      |
| ProcessExecTime         | 0.0644     |
| StdReturn               | 755        |
| Time                    | 3.71e+03   |
| dLoss                   | 0.0273475  |
----------------------------------------
itr #452 | 
Mem: 710.246094
Obtaining samples...
Obtaining samples for iteration 452...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5767, #subsample_inputs: 5767
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.709      |
| AbsLearnSignalNew       | 0.709      |
| AbsLearningOld          | 0.709      |
| AverageDiscountedReturn | 227        |
| AveragePhiLoss          | 15.9688    |
| AveragePolicyStd        | 0.68811    |
| AverageReturn           | 1.61e+03   |
| Entropy                 | 3.06648    |
| EnvExecTime             | 2.39       |
| ExplainedVariance       | 0.712      |
| Iteration               | 452        |
| ItrTime                 | 9.21       |
| LossAfter               | -0.117558  |
| LossBefore              | -0.0947348 |
| MaxReturn               | 2.46e+03   |
| MeanKL                  | 0.00647695 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.1e+03    |
| NumTrajs                | 10         |
| Perplexity              | 21.4661    |
| PolicyExecTime          | 0.605      |
| ProcessExecTime         | 0.0677     |
| StdReturn               | 460        |
| Time                    | 3.72e+03   |
| dLoss                   | 0.0228231  |
----------------------------------------
itr #453 | 
Mem: 710.246094
Obtaining samples...
Obtaining samples for iteration 453...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5184, #subsample_inputs: 5184
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.713      |
| AbsLearnSignalNew       | 0.713      |
| AbsLearningOld          | 0.713      |
| AverageDiscountedReturn | 225        |
| AveragePhiLoss          | 16.1616    |
| AveragePolicyStd        | 0.686578   |
| AverageReturn           | 1.81e+03   |
| Entropy                 | 3.06096    |
| EnvExecTime             | 2.04       |
| ExplainedVariance       | 0.728      |
| Iteration               | 453        |
| ItrTime                 | 8.33       |
| LossAfter               | 0.408702   |
| LossBefore              | 0.43858    |
| MaxReturn               | 2.61e+03   |
| MeanKL                  | 0.00989799 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.19e+03   |
| NumTrajs                | 8          |
| Perplexity              | 21.348     |
| PolicyExecTime          | 0.511      |
| ProcessExecTime         | 0.0591     |
| StdReturn               | 521        |
| Time                    | 3.73e+03   |
| dLoss                   | 0.0298782  |
----------------------------------------
itr #454 | 
Mem: 710.246094
Obtaining samples...
Obtaining samples for iteration 454...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5009, #subsample_inputs: 5009
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.631      |
| AbsLearnSignalNew       | 0.631      |
| AbsLearningOld          | 0.631      |
| AverageDiscountedReturn | 229        |
| AveragePhiLoss          | 22.5205    |
| AveragePolicyStd        | 0.687505   |
| AverageReturn           | 2.03e+03   |
| Entropy                 | 3.0619     |
| EnvExecTime             | 1.88       |
| ExplainedVariance       | 0.784      |
| Iteration               | 454        |
| ItrTime                 | 7.92       |
| LossAfter               | -0.577368  |
| LossBefore              | -0.548007  |
| MaxReturn               | 2.96e+03   |
| MeanKL                  | 0.00654014 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.12e+03   |
| NumTrajs                | 7          |
| Perplexity              | 21.3681    |
| PolicyExecTime          | 0.488      |
| ProcessExecTime         | 0.0552     |
| StdReturn               | 745        |
| Time                    | 3.74e+03   |
| dLoss                   | 0.0293602  |
----------------------------------------
itr #455 | 
Mem: 710.925781
Obtaining samples...
Obtaining samples for iteration 455...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5357, #subsample_inputs: 5357
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.715      |
| AbsLearnSignalNew       | 0.715      |
| AbsLearningOld          | 0.716      |
| AverageDiscountedReturn | 230        |
| AveragePhiLoss          | 16.8939    |
| AveragePolicyStd        | 0.684433   |
| AverageReturn           | 1.59e+03   |
| Entropy                 | 3.04773    |
| EnvExecTime             | 2.27       |
| ExplainedVariance       | 0.803      |
| Iteration               | 455        |
| ItrTime                 | 8.79       |
| LossAfter               | 0.411255   |
| LossBefore              | 0.438786   |
| MaxReturn               | 2.59e+03   |
| MeanKL                  | 0.00996216 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 873        |
| NumTrajs                | 10         |
| Perplexity              | 21.0676    |
| PolicyExecTime          | 0.584      |
| ProcessExecTime         | 0.0631     |
| StdReturn               | 569        |
| Time                    | 3.75e+03   |
| dLoss                   | 0.0275303  |
----------------------------------------
itr #456 | 
Mem: 711.007812
Obtaining samples...
Obtaining samples for iteration 456...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5498, #subsample_inputs: 5498
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.758      |
| AbsLearnSignalNew       | 0.758      |
| AbsLearningOld          | 0.758      |
| AverageDiscountedReturn | 228        |
| AveragePhiLoss          | 16.0271    |
| AveragePolicyStd        | 0.682397   |
| AverageReturn           | 1.71e+03   |
| Entropy                 | 3.0403     |
| EnvExecTime             | 2.16       |
| ExplainedVariance       | 0.873      |
| Iteration               | 456        |
| ItrTime                 | 8.64       |
| LossAfter               | -0.165363  |
| LossBefore              | -0.141623  |
| MaxReturn               | 2.61e+03   |
| MeanKL                  | 0.00984488 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 860        |
| NumTrajs                | 9          |
| Perplexity              | 20.9115    |
| PolicyExecTime          | 0.546      |
| ProcessExecTime         | 0.0629     |
| StdReturn               | 618        |
| Time                    | 3.76e+03   |
| dLoss                   | 0.0237401  |
----------------------------------------
itr #457 | 
Mem: 711.007812
Obtaining samples...
Obtaining samples for iteration 457...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5473, #subsample_inputs: 5473
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.575      |
| AbsLearnSignalNew       | 0.575      |
| AbsLearningOld          | 0.574      |
| AverageDiscountedReturn | 230        |
| AveragePhiLoss          | 14.4908    |
| AveragePolicyStd        | 0.686113   |
| AverageReturn           | 2.25e+03   |
| Entropy                 | 3.05435    |
| EnvExecTime             | 2.75       |
| ExplainedVariance       | 0.633      |
| Iteration               | 457        |
| ItrTime                 | 9.36       |
| LossAfter               | 0.132999   |
| LossBefore              | 0.150533   |
| MaxReturn               | 2.93e+03   |
| MeanKL                  | 0.00655683 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.17e+03   |
| NumTrajs                | 7          |
| Perplexity              | 21.2074    |
| PolicyExecTime          | 0.684      |
| ProcessExecTime         | 0.0746     |
| StdReturn               | 677        |
| Time                    | 3.77e+03   |
| dLoss                   | 0.0175342  |
----------------------------------------
itr #458 | 
Mem: 711.261719
Obtaining samples...
Obtaining samples for iteration 458...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5382, #subsample_inputs: 5382
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.679      |
| AbsLearnSignalNew       | 0.679      |
| AbsLearningOld          | 0.679      |
| AverageDiscountedReturn | 228        |
| AveragePhiLoss          | 16.8413    |
| AveragePolicyStd        | 0.68261    |
| AverageReturn           | 1.99e+03   |
| Entropy                 | 3.03678    |
| EnvExecTime             | 2.43       |
| ExplainedVariance       | 0.798      |
| Iteration               | 458        |
| ItrTime                 | 8.97       |
| LossAfter               | -0.832734  |
| LossBefore              | -0.8076    |
| MaxReturn               | 2.81e+03   |
| MeanKL                  | 0.00986035 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 707        |
| NumTrajs                | 8          |
| Perplexity              | 20.8381    |
| PolicyExecTime          | 0.613      |
| ProcessExecTime         | 0.0703     |
| StdReturn               | 696        |
| Time                    | 3.78e+03   |
| dLoss                   | 0.0251339  |
----------------------------------------
itr #459 | 
Mem: 711.261719
Obtaining samples...
Obtaining samples for iteration 459...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5816, #subsample_inputs: 5816
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.6        |
| AbsLearnSignalNew       | 0.6        |
| AbsLearningOld          | 0.6        |
| AverageDiscountedReturn | 226        |
| AveragePhiLoss          | 15.0262    |
| AveragePolicyStd        | 0.68352    |
| AverageReturn           | 1.8e+03    |
| Entropy                 | 3.03905    |
| EnvExecTime             | 2.73       |
| ExplainedVariance       | 0.667      |
| Iteration               | 459        |
| ItrTime                 | 9.59       |
| LossAfter               | 0.23046    |
| LossBefore              | 0.246146   |
| MaxReturn               | 2.79e+03   |
| MeanKL                  | 0.00658186 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 709        |
| NumTrajs                | 9          |
| Perplexity              | 20.8854    |
| PolicyExecTime          | 0.692      |
| ProcessExecTime         | 0.0775     |
| StdReturn               | 740        |
| Time                    | 3.79e+03   |
| dLoss                   | 0.0156862  |
----------------------------------------
itr #460 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 460...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5342, #subsample_inputs: 5342
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.702      |
| AbsLearnSignalNew       | 0.702      |
| AbsLearningOld          | 0.702      |
| AverageDiscountedReturn | 230        |
| AveragePhiLoss          | 16.1733    |
| AveragePolicyStd        | 0.681933   |
| AverageReturn           | 1.61e+03   |
| Entropy                 | 3.03314    |
| EnvExecTime             | 2.25       |
| ExplainedVariance       | 0.827      |
| Iteration               | 460        |
| ItrTime                 | 8.74       |
| LossAfter               | 0.168852   |
| LossBefore              | 0.186756   |
| MaxReturn               | 2.71e+03   |
| MeanKL                  | 0.00648187 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 804        |
| NumTrajs                | 10         |
| Perplexity              | 20.7624    |
| PolicyExecTime          | 0.559      |
| ProcessExecTime         | 0.0655     |
| StdReturn               | 504        |
| Time                    | 3.79e+03   |
| dLoss                   | 0.0179042  |
----------------------------------------
itr #461 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 461...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5339, #subsample_inputs: 5339
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.531      |
| AbsLearnSignalNew       | 0.531      |
| AbsLearningOld          | 0.531      |
| AverageDiscountedReturn | 230        |
| AveragePhiLoss          | 19.1323    |
| AveragePolicyStd        | 0.679868   |
| AverageReturn           | 2.24e+03   |
| Entropy                 | 3.02388    |
| EnvExecTime             | 2.13       |
| ExplainedVariance       | 0.55       |
| Iteration               | 461        |
| ItrTime                 | 8.59       |
| LossAfter               | -0.098581  |
| LossBefore              | -0.0824011 |
| MaxReturn               | 2.88e+03   |
| MeanKL                  | 0.00657491 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.22e+03   |
| NumTrajs                | 7          |
| Perplexity              | 20.571     |
| PolicyExecTime          | 0.548      |
| ProcessExecTime         | 0.0609     |
| StdReturn               | 624        |
| Time                    | 3.8e+03    |
| dLoss                   | 0.01618    |
----------------------------------------
itr #462 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 462...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5509, #subsample_inputs: 5509
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.646      |
| AbsLearnSignalNew       | 0.646      |
| AbsLearningOld          | 0.646      |
| AverageDiscountedReturn | 235        |
| AveragePhiLoss          | 16.5583    |
| AveragePolicyStd        | 0.679581   |
| AverageReturn           | 1.71e+03   |
| Entropy                 | 3.01834    |
| EnvExecTime             | 2.22       |
| ExplainedVariance       | 0.797      |
| Iteration               | 462        |
| ItrTime                 | 8.77       |
| LossAfter               | 0.39267    |
| LossBefore              | 0.417115   |
| MaxReturn               | 2.45e+03   |
| MeanKL                  | 0.00642612 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 862        |
| NumTrajs                | 10         |
| Perplexity              | 20.4573    |
| PolicyExecTime          | 0.562      |
| ProcessExecTime         | 0.0642     |
| StdReturn               | 514        |
| Time                    | 3.81e+03   |
| dLoss                   | 0.0244447  |
----------------------------------------
itr #463 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 463...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5649, #subsample_inputs: 5649
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.74       |
| AbsLearnSignalNew       | 0.74       |
| AbsLearningOld          | 0.739      |
| AverageDiscountedReturn | 234        |
| AveragePhiLoss          | 17.0694    |
| AveragePolicyStd        | 0.679724   |
| AverageReturn           | 1.75e+03   |
| Entropy                 | 3.01865    |
| EnvExecTime             | 2.32       |
| ExplainedVariance       | 0.892      |
| Iteration               | 463        |
| ItrTime                 | 8.98       |
| LossAfter               | 0.550432   |
| LossBefore              | 0.575084   |
| MaxReturn               | 2.31e+03   |
| MeanKL                  | 0.00643584 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 971        |
| NumTrajs                | 10         |
| Perplexity              | 20.4636    |
| PolicyExecTime          | 0.583      |
| ProcessExecTime         | 0.0696     |
| StdReturn               | 428        |
| Time                    | 3.82e+03   |
| dLoss                   | 0.024652   |
----------------------------------------
itr #464 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 464...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5585, #subsample_inputs: 5585
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.745      |
| AbsLearnSignalNew       | 0.745      |
| AbsLearningOld          | 0.745      |
| AverageDiscountedReturn | 231        |
| AveragePhiLoss          | 18.2788    |
| AveragePolicyStd        | 0.67826    |
| AverageReturn           | 1.7e+03    |
| Entropy                 | 3.01366    |
| EnvExecTime             | 1.98       |
| ExplainedVariance       | 0.851      |
| Iteration               | 464        |
| ItrTime                 | 8.62       |
| LossAfter               | 0.0476982  |
| LossBefore              | 0.0676591  |
| MaxReturn               | 2.58e+03   |
| MeanKL                  | 0.00647814 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 678        |
| NumTrajs                | 10         |
| Perplexity              | 20.3618    |
| PolicyExecTime          | 0.513      |
| ProcessExecTime         | 0.0601     |
| StdReturn               | 652        |
| Time                    | 3.83e+03   |
| dLoss                   | 0.0199609  |
----------------------------------------
itr #465 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 465...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5137, #subsample_inputs: 5137
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.751      |
| AbsLearnSignalNew       | 0.751      |
| AbsLearningOld          | 0.751      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 16.9636    |
| AveragePolicyStd        | 0.67731    |
| AverageReturn           | 1.47e+03   |
| Entropy                 | 3.00795    |
| EnvExecTime             | 1.95       |
| ExplainedVariance       | 0.896      |
| Iteration               | 465        |
| ItrTime                 | 8.07       |
| LossAfter               | -0.226347  |
| LossBefore              | -0.204311  |
| MaxReturn               | 2.16e+03   |
| MeanKL                  | 0.00642209 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 962        |
| NumTrajs                | 11         |
| Perplexity              | 20.2459    |
| PolicyExecTime          | 0.493      |
| ProcessExecTime         | 0.0571     |
| StdReturn               | 359        |
| Time                    | 3.84e+03   |
| dLoss                   | 0.0220366  |
----------------------------------------
itr #466 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 466...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5260, #subsample_inputs: 5260
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.777      |
| AbsLearnSignalNew       | 0.777      |
| AbsLearningOld          | 0.777      |
| AverageDiscountedReturn | 233        |
| AveragePhiLoss          | 16.814     |
| AveragePolicyStd        | 0.678913   |
| AverageReturn           | 1.78e+03   |
| Entropy                 | 3.01328    |
| EnvExecTime             | 1.92       |
| ExplainedVariance       | 0.895      |
| Iteration               | 466        |
| ItrTime                 | 8.13       |
| LossAfter               | 0.669432   |
| LossBefore              | 0.695752   |
| MaxReturn               | 2.94e+03   |
| MeanKL                  | 0.00656271 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.2e+03    |
| NumTrajs                | 9          |
| Perplexity              | 20.3541    |
| PolicyExecTime          | 0.499      |
| ProcessExecTime         | 0.056      |
| StdReturn               | 549        |
| Time                    | 3.85e+03   |
| dLoss                   | 0.0263198  |
----------------------------------------
itr #467 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 467...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5192, #subsample_inputs: 5192
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.739      |
| AbsLearnSignalNew       | 0.739      |
| AbsLearningOld          | 0.738      |
| AverageDiscountedReturn | 236        |
| AveragePhiLoss          | 17.4183    |
| AveragePolicyStd        | 0.678752   |
| AverageReturn           | 1.79e+03   |
| Entropy                 | 3.01391    |
| EnvExecTime             | 2.1        |
| ExplainedVariance       | 0.883      |
| Iteration               | 467        |
| ItrTime                 | 8.38       |
| LossAfter               | -0.0834145 |
| LossBefore              | -0.0572417 |
| MaxReturn               | 2.66e+03   |
| MeanKL                  | 0.00964417 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.2e+03    |
| NumTrajs                | 9          |
| Perplexity              | 20.3669    |
| PolicyExecTime          | 0.528      |
| ProcessExecTime         | 0.0632     |
| StdReturn               | 481        |
| Time                    | 3.85e+03   |
| dLoss                   | 0.0261728  |
----------------------------------------
itr #468 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 468...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5011, #subsample_inputs: 5011
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.728      |
| AbsLearnSignalNew       | 0.728      |
| AbsLearningOld          | 0.728      |
| AverageDiscountedReturn | 232        |
| AveragePhiLoss          | 17.8005    |
| AveragePolicyStd        | 0.681314   |
| AverageReturn           | 1.39e+03   |
| Entropy                 | 3.02489    |
| EnvExecTime             | 2.59       |
| ExplainedVariance       | 0.886      |
| Iteration               | 468        |
| ItrTime                 | 8.82       |
| LossAfter               | 0.0643462  |
| LossBefore              | 0.0927821  |
| MaxReturn               | 2.04e+03   |
| MeanKL                  | 0.00995889 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 815        |
| NumTrajs                | 11         |
| Perplexity              | 20.5917    |
| PolicyExecTime          | 0.645      |
| ProcessExecTime         | 0.071      |
| StdReturn               | 395        |
| Time                    | 3.86e+03   |
| dLoss                   | 0.0284359  |
----------------------------------------
itr #469 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 469...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5276, #subsample_inputs: 5276
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.783      |
| AbsLearnSignalNew       | 0.783      |
| AbsLearningOld          | 0.783      |
| AverageDiscountedReturn | 235        |
| AveragePhiLoss          | 16.1896    |
| AveragePolicyStd        | 0.680875   |
| AverageReturn           | 2.05e+03   |
| Entropy                 | 3.02222    |
| EnvExecTime             | 2.09       |
| ExplainedVariance       | 0.896      |
| Iteration               | 469        |
| ItrTime                 | 8.4        |
| LossAfter               | 1.17846    |
| LossBefore              | 1.20345    |
| MaxReturn               | 2.9e+03    |
| MeanKL                  | 0.00994091 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.24e+03   |
| NumTrajs                | 8          |
| Perplexity              | 20.5368    |
| PolicyExecTime          | 0.529      |
| ProcessExecTime         | 0.0613     |
| StdReturn               | 564        |
| Time                    | 3.87e+03   |
| dLoss                   | 0.0249878  |
----------------------------------------
itr #470 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 470...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5362, #subsample_inputs: 5362
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.775      |
| AbsLearnSignalNew       | 0.775      |
| AbsLearningOld          | 0.775      |
| AverageDiscountedReturn | 233        |
| AveragePhiLoss          | 17.8647    |
| AveragePolicyStd        | 0.682805   |
| AverageReturn           | 1.82e+03   |
| Entropy                 | 3.03214    |
| EnvExecTime             | 2.17       |
| ExplainedVariance       | 0.905      |
| Iteration               | 470        |
| ItrTime                 | 8.71       |
| LossAfter               | -0.551777  |
| LossBefore              | -0.529703  |
| MaxReturn               | 2.81e+03   |
| MeanKL                  | 0.00659325 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.05e+03   |
| NumTrajs                | 9          |
| Perplexity              | 20.7416    |
| PolicyExecTime          | 0.552      |
| ProcessExecTime         | 0.0642     |
| StdReturn               | 603        |
| Time                    | 3.88e+03   |
| dLoss                   | 0.0220737  |
----------------------------------------
itr #471 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 471...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5435, #subsample_inputs: 5435
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.708     |
| AbsLearnSignalNew       | 0.708     |
| AbsLearningOld          | 0.708     |
| AverageDiscountedReturn | 230       |
| AveragePhiLoss          | 16.6033   |
| AveragePolicyStd        | 0.681848  |
| AverageReturn           | 2.07e+03  |
| Entropy                 | 3.02695   |
| EnvExecTime             | 2.02      |
| ExplainedVariance       | 0.887     |
| Iteration               | 471       |
| ItrTime                 | 8.53      |
| LossAfter               | 0.344528  |
| LossBefore              | 0.3656    |
| MaxReturn               | 2.8e+03   |
| MeanKL                  | 0.0098731 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1e+03     |
| NumTrajs                | 8         |
| Perplexity              | 20.6342   |
| PolicyExecTime          | 0.52      |
| ProcessExecTime         | 0.0604    |
| StdReturn               | 569       |
| Time                    | 3.89e+03  |
| dLoss                   | 0.0210721 |
---------------------------------------
itr #472 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 472...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5042, #subsample_inputs: 5042
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.783      |
| AbsLearnSignalNew       | 0.783      |
| AbsLearningOld          | 0.783      |
| AverageDiscountedReturn | 235        |
| AveragePhiLoss          | 16.6522    |
| AveragePolicyStd        | 0.681834   |
| AverageReturn           | 1.58e+03   |
| Entropy                 | 3.02763    |
| EnvExecTime             | 1.89       |
| ExplainedVariance       | 0.92       |
| Iteration               | 472        |
| ItrTime                 | 7.96       |
| LossAfter               | 0.930554   |
| LossBefore              | 0.950657   |
| MaxReturn               | 2.18e+03   |
| MeanKL                  | 0.00641654 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 948        |
| NumTrajs                | 10         |
| Perplexity              | 20.6482    |
| PolicyExecTime          | 0.48       |
| ProcessExecTime         | 0.0547     |
| StdReturn               | 324        |
| Time                    | 3.9e+03    |
| dLoss                   | 0.0201027  |
----------------------------------------
itr #473 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 473...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5151, #subsample_inputs: 5151
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.761      |
| AbsLearnSignalNew       | 0.761      |
| AbsLearningOld          | 0.761      |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 16.6654    |
| AveragePolicyStd        | 0.681286   |
| AverageReturn           | 1.48e+03   |
| Entropy                 | 3.02663    |
| EnvExecTime             | 1.96       |
| ExplainedVariance       | 0.914      |
| Iteration               | 473        |
| ItrTime                 | 8.09       |
| LossAfter               | -0.132299  |
| LossBefore              | -0.105952  |
| MaxReturn               | 2.08e+03   |
| MeanKL                  | 0.00989791 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.11e+03   |
| NumTrajs                | 11         |
| Perplexity              | 20.6275    |
| PolicyExecTime          | 0.497      |
| ProcessExecTime         | 0.057      |
| StdReturn               | 265        |
| Time                    | 3.91e+03   |
| dLoss                   | 0.0263469  |
----------------------------------------
itr #474 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 474...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5140, #subsample_inputs: 5140
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.754      |
| AbsLearnSignalNew       | 0.754      |
| AbsLearningOld          | 0.754      |
| AverageDiscountedReturn | 233        |
| AveragePhiLoss          | 16.2024    |
| AveragePolicyStd        | 0.680603   |
| AverageReturn           | 1.76e+03   |
| Entropy                 | 3.0241     |
| EnvExecTime             | 2.25       |
| ExplainedVariance       | 0.865      |
| Iteration               | 474        |
| ItrTime                 | 8.46       |
| LossAfter               | -0.518584  |
| LossBefore              | -0.493168  |
| MaxReturn               | 2.82e+03   |
| MeanKL                  | 0.00985635 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 908        |
| NumTrajs                | 9          |
| Perplexity              | 20.5754    |
| PolicyExecTime          | 0.561      |
| ProcessExecTime         | 0.0646     |
| StdReturn               | 598        |
| Time                    | 3.91e+03   |
| dLoss                   | 0.0254162  |
----------------------------------------
itr #475 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 475...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5050, #subsample_inputs: 5050
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.754      |
| AbsLearnSignalNew       | 0.754      |
| AbsLearningOld          | 0.754      |
| AverageDiscountedReturn | 235        |
| AveragePhiLoss          | 16.6861    |
| AveragePolicyStd        | 0.681721   |
| AverageReturn           | 1.74e+03   |
| Entropy                 | 3.02709    |
| EnvExecTime             | 2.14       |
| ExplainedVariance       | 0.894      |
| Iteration               | 475        |
| ItrTime                 | 8.3        |
| LossAfter               | 0.186068   |
| LossBefore              | 0.204712   |
| MaxReturn               | 2.68e+03   |
| MeanKL                  | 0.00643611 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.24e+03   |
| NumTrajs                | 9          |
| Perplexity              | 20.637     |
| PolicyExecTime          | 0.549      |
| ProcessExecTime         | 0.0609     |
| StdReturn               | 480        |
| Time                    | 3.92e+03   |
| dLoss                   | 0.0186438  |
----------------------------------------
itr #476 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 476...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5460, #subsample_inputs: 5460
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.735      |
| AbsLearnSignalNew       | 0.735      |
| AbsLearningOld          | 0.735      |
| AverageDiscountedReturn | 234        |
| AveragePhiLoss          | 18.1628    |
| AveragePolicyStd        | 0.681175   |
| AverageReturn           | 1.87e+03   |
| Entropy                 | 3.0239     |
| EnvExecTime             | 2.06       |
| ExplainedVariance       | 0.911      |
| Iteration               | 476        |
| ItrTime                 | 8.57       |
| LossAfter               | 0.291706   |
| LossBefore              | 0.312214   |
| MaxReturn               | 2.89e+03   |
| MeanKL                  | 0.00642362 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 977        |
| NumTrajs                | 9          |
| Perplexity              | 20.5713    |
| PolicyExecTime          | 0.529      |
| ProcessExecTime         | 0.0604     |
| StdReturn               | 644        |
| Time                    | 3.93e+03   |
| dLoss                   | 0.020508   |
----------------------------------------
itr #477 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 477...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5466, #subsample_inputs: 5466
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.75       |
| AbsLearnSignalNew       | 0.75       |
| AbsLearningOld          | 0.751      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 17.183     |
| AveragePolicyStd        | 0.680868   |
| AverageReturn           | 1.7e+03    |
| Entropy                 | 3.02377    |
| EnvExecTime             | 2.08       |
| ExplainedVariance       | 0.914      |
| Iteration               | 477        |
| ItrTime                 | 8.56       |
| LossAfter               | -0.293742  |
| LossBefore              | -0.27416   |
| MaxReturn               | 2.11e+03   |
| MeanKL                  | 0.00645194 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.11e+03   |
| NumTrajs                | 10         |
| Perplexity              | 20.5688    |
| PolicyExecTime          | 0.526      |
| ProcessExecTime         | 0.0618     |
| StdReturn               | 347        |
| Time                    | 3.94e+03   |
| dLoss                   | 0.0195827  |
----------------------------------------
itr #478 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 478...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5293, #subsample_inputs: 5293
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.777      |
| AbsLearnSignalNew       | 0.777      |
| AbsLearningOld          | 0.777      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 16.7462    |
| AveragePolicyStd        | 0.683077   |
| AverageReturn           | 1.39e+03   |
| Entropy                 | 3.03309    |
| EnvExecTime             | 2.06       |
| ExplainedVariance       | 0.917      |
| Iteration               | 478        |
| ItrTime                 | 8.44       |
| LossAfter               | 0.240354   |
| LossBefore              | 0.265248   |
| MaxReturn               | 2.06e+03   |
| MeanKL                  | 0.00989666 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 954        |
| NumTrajs                | 12         |
| Perplexity              | 20.7613    |
| PolicyExecTime          | 0.525      |
| ProcessExecTime         | 0.0589     |
| StdReturn               | 320        |
| Time                    | 3.95e+03   |
| dLoss                   | 0.0248942  |
----------------------------------------
itr #479 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 479...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5269, #subsample_inputs: 5269
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.757      |
| AbsLearnSignalNew       | 0.757      |
| AbsLearningOld          | 0.757      |
| AverageDiscountedReturn | 235        |
| AveragePhiLoss          | 17.0517    |
| AveragePolicyStd        | 0.683983   |
| AverageReturn           | 1.49e+03   |
| Entropy                 | 3.03926    |
| EnvExecTime             | 1.96       |
| ExplainedVariance       | 0.906      |
| Iteration               | 479        |
| ItrTime                 | 8.26       |
| LossAfter               | 0.421864   |
| LossBefore              | 0.447358   |
| MaxReturn               | 1.96e+03   |
| MeanKL                  | 0.00983875 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 890        |
| NumTrajs                | 11         |
| Perplexity              | 20.8897    |
| PolicyExecTime          | 0.498      |
| ProcessExecTime         | 0.0588     |
| StdReturn               | 352        |
| Time                    | 3.96e+03   |
| dLoss                   | 0.0254938  |
----------------------------------------
itr #480 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 480...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5423, #subsample_inputs: 5423
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.742     |
| AbsLearnSignalNew       | 0.742     |
| AbsLearningOld          | 0.742     |
| AverageDiscountedReturn | 231       |
| AveragePhiLoss          | 16.0513   |
| AveragePolicyStd        | 0.682767  |
| AverageReturn           | 1.49e+03  |
| Entropy                 | 3.0341    |
| EnvExecTime             | 2.31      |
| ExplainedVariance       | 0.858     |
| Iteration               | 480       |
| ItrTime                 | 8.89      |
| LossAfter               | -0.259259 |
| LossBefore              | -0.241717 |
| MaxReturn               | 2.49e+03  |
| MeanKL                  | 0.0065063 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 832       |
| NumTrajs                | 11        |
| Perplexity              | 20.7822   |
| PolicyExecTime          | 0.574     |
| ProcessExecTime         | 0.0667    |
| StdReturn               | 517       |
| Time                    | 3.97e+03  |
| dLoss                   | 0.0175421 |
---------------------------------------
itr #481 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 481...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5405, #subsample_inputs: 5405
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.737     |
| AbsLearnSignalNew       | 0.737     |
| AbsLearningOld          | 0.737     |
| AverageDiscountedReturn | 235       |
| AveragePhiLoss          | 15.3465   |
| AveragePolicyStd        | 0.684999  |
| AverageReturn           | 1.67e+03  |
| Entropy                 | 3.04189   |
| EnvExecTime             | 2.11      |
| ExplainedVariance       | 0.885     |
| Iteration               | 481       |
| ItrTime                 | 8.65      |
| LossAfter               | -0.227281 |
| LossBefore              | -0.203627 |
| MaxReturn               | 2.96e+03  |
| MeanKL                  | 0.006506  |
| MeanKLBefore            | 0.0       |
| MinReturn               | 942       |
| NumTrajs                | 10        |
| Perplexity              | 20.9448   |
| PolicyExecTime          | 0.528     |
| ProcessExecTime         | 0.0618    |
| StdReturn               | 540       |
| Time                    | 3.97e+03  |
| dLoss                   | 0.0236543 |
---------------------------------------
itr #482 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 482...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5156, #subsample_inputs: 5156
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.728      |
| AbsLearnSignalNew       | 0.728      |
| AbsLearningOld          | 0.728      |
| AverageDiscountedReturn | 235        |
| AveragePhiLoss          | 15.2143    |
| AveragePolicyStd        | 0.684772   |
| AverageReturn           | 1.99e+03   |
| Entropy                 | 3.04049    |
| EnvExecTime             | 2.26       |
| ExplainedVariance       | 0.881      |
| Iteration               | 482        |
| ItrTime                 | 8.52       |
| LossAfter               | -0.399441  |
| LossBefore              | -0.375162  |
| MaxReturn               | 2.95e+03   |
| MeanKL                  | 0.00995158 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.54e+03   |
| NumTrajs                | 8          |
| Perplexity              | 20.9155    |
| PolicyExecTime          | 0.556      |
| ProcessExecTime         | 0.0654     |
| StdReturn               | 423        |
| Time                    | 3.98e+03   |
| dLoss                   | 0.0242796  |
----------------------------------------
itr #483 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 483...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5236, #subsample_inputs: 5236
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.732      |
| AbsLearnSignalNew       | 0.732      |
| AbsLearningOld          | 0.732      |
| AverageDiscountedReturn | 232        |
| AveragePhiLoss          | 15.5559    |
| AveragePolicyStd        | 0.686851   |
| AverageReturn           | 1.6e+03    |
| Entropy                 | 3.04904    |
| EnvExecTime             | 2.11       |
| ExplainedVariance       | 0.892      |
| Iteration               | 483        |
| ItrTime                 | 8.39       |
| LossAfter               | 0.201069   |
| LossBefore              | 0.226607   |
| MaxReturn               | 2.36e+03   |
| MeanKL                  | 0.00997429 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.02e+03   |
| NumTrajs                | 10         |
| Perplexity              | 21.0952    |
| PolicyExecTime          | 0.55       |
| ProcessExecTime         | 0.0603     |
| StdReturn               | 417        |
| Time                    | 3.99e+03   |
| dLoss                   | 0.0255382  |
----------------------------------------
itr #484 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 484...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5700, #subsample_inputs: 5700
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.747      |
| AbsLearnSignalNew       | 0.747      |
| AbsLearningOld          | 0.747      |
| AverageDiscountedReturn | 230        |
| AveragePhiLoss          | 16.0945    |
| AveragePolicyStd        | 0.688633   |
| AverageReturn           | 1.58e+03   |
| Entropy                 | 3.05417    |
| EnvExecTime             | 2.29       |
| ExplainedVariance       | 0.866      |
| Iteration               | 484        |
| ItrTime                 | 8.98       |
| LossAfter               | -1.24992   |
| LossBefore              | -1.22746   |
| MaxReturn               | 2.2e+03    |
| MeanKL                  | 0.00641174 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 776        |
| NumTrajs                | 11         |
| Perplexity              | 21.2036    |
| PolicyExecTime          | 0.573      |
| ProcessExecTime         | 0.0683     |
| StdReturn               | 484        |
| Time                    | 4e+03      |
| dLoss                   | 0.0224549  |
----------------------------------------
itr #485 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 485...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5307, #subsample_inputs: 5307
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.689      |
| AbsLearnSignalNew       | 0.689      |
| AbsLearningOld          | 0.689      |
| AverageDiscountedReturn | 230        |
| AveragePhiLoss          | 14.0637    |
| AveragePolicyStd        | 0.690316   |
| AverageReturn           | 1.98e+03   |
| Entropy                 | 3.06041    |
| EnvExecTime             | 1.99       |
| ExplainedVariance       | 0.798      |
| Iteration               | 485        |
| ItrTime                 | 8.31       |
| LossAfter               | -0.19967   |
| LossBefore              | -0.178088  |
| MaxReturn               | 2.66e+03   |
| MeanKL                  | 0.00995545 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 955        |
| NumTrajs                | 8          |
| Perplexity              | 21.3362    |
| PolicyExecTime          | 0.513      |
| ProcessExecTime         | 0.0592     |
| StdReturn               | 612        |
| Time                    | 4.01e+03   |
| dLoss                   | 0.0215818  |
----------------------------------------
itr #486 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 486...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5587, #subsample_inputs: 5587
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.73       |
| AbsLearnSignalNew       | 0.73       |
| AbsLearningOld          | 0.73       |
| AverageDiscountedReturn | 231        |
| AveragePhiLoss          | 15.9144    |
| AveragePolicyStd        | 0.691289   |
| AverageReturn           | 1.68e+03   |
| Entropy                 | 3.06503    |
| EnvExecTime             | 2.04       |
| ExplainedVariance       | 0.868      |
| Iteration               | 486        |
| ItrTime                 | 8.56       |
| LossAfter               | 0.514314   |
| LossBefore              | 0.537274   |
| MaxReturn               | 2.8e+03    |
| MeanKL                  | 0.00646794 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 944        |
| NumTrajs                | 10         |
| Perplexity              | 21.4351    |
| PolicyExecTime          | 0.524      |
| ProcessExecTime         | 0.0618     |
| StdReturn               | 588        |
| Time                    | 4.02e+03   |
| dLoss                   | 0.0229604  |
----------------------------------------
itr #487 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 487...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5676, #subsample_inputs: 5676
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.737      |
| AbsLearnSignalNew       | 0.737      |
| AbsLearningOld          | 0.737      |
| AverageDiscountedReturn | 233        |
| AveragePhiLoss          | 16.4567    |
| AveragePolicyStd        | 0.689702   |
| AverageReturn           | 1.73e+03   |
| Entropy                 | 3.05944    |
| EnvExecTime             | 2.2        |
| ExplainedVariance       | 0.897      |
| Iteration               | 487        |
| ItrTime                 | 8.79       |
| LossAfter               | -0.933499  |
| LossBefore              | -0.913994  |
| MaxReturn               | 2.34e+03   |
| MeanKL                  | 0.00649172 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 991        |
| NumTrajs                | 10         |
| Perplexity              | 21.3157    |
| PolicyExecTime          | 0.556      |
| ProcessExecTime         | 0.0648     |
| StdReturn               | 490        |
| Time                    | 4.03e+03   |
| dLoss                   | 0.0195051  |
----------------------------------------
itr #488 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 488...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5224, #subsample_inputs: 5224
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.747      |
| AbsLearnSignalNew       | 0.747      |
| AbsLearningOld          | 0.747      |
| AverageDiscountedReturn | 233        |
| AveragePhiLoss          | 16.793     |
| AveragePolicyStd        | 0.688095   |
| AverageReturn           | 1.46e+03   |
| Entropy                 | 3.05202    |
| EnvExecTime             | 2.11       |
| ExplainedVariance       | 0.903      |
| Iteration               | 488        |
| ItrTime                 | 8.34       |
| LossAfter               | -0.252051  |
| LossBefore              | -0.224643  |
| MaxReturn               | 2.1e+03    |
| MeanKL                  | 0.00999738 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 889        |
| NumTrajs                | 11         |
| Perplexity              | 21.1581    |
| PolicyExecTime          | 0.534      |
| ProcessExecTime         | 0.0617     |
| StdReturn               | 362        |
| Time                    | 4.03e+03   |
| dLoss                   | 0.027408   |
----------------------------------------
itr #489 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 489...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5538, #subsample_inputs: 5538
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.737      |
| AbsLearnSignalNew       | 0.737      |
| AbsLearningOld          | 0.737      |
| AverageDiscountedReturn | 234        |
| AveragePhiLoss          | 16.8683    |
| AveragePolicyStd        | 0.688249   |
| AverageReturn           | 1.71e+03   |
| Entropy                 | 3.05331    |
| EnvExecTime             | 2.05       |
| ExplainedVariance       | 0.886      |
| Iteration               | 489        |
| ItrTime                 | 8.55       |
| LossAfter               | 0.785014   |
| LossBefore              | 0.803744   |
| MaxReturn               | 2.21e+03   |
| MeanKL                  | 0.00644613 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.21e+03   |
| NumTrajs                | 10         |
| Perplexity              | 21.1855    |
| PolicyExecTime          | 0.52       |
| ProcessExecTime         | 0.0606     |
| StdReturn               | 307        |
| Time                    | 4.04e+03   |
| dLoss                   | 0.0187298  |
----------------------------------------
itr #490 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 490...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5145, #subsample_inputs: 5145
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.773      |
| AbsLearnSignalNew       | 0.773      |
| AbsLearningOld          | 0.774      |
| AverageDiscountedReturn | 235        |
| AveragePhiLoss          | 16.4091    |
| AveragePolicyStd        | 0.687566   |
| AverageReturn           | 1.6e+03    |
| Entropy                 | 3.04785    |
| EnvExecTime             | 2.1        |
| ExplainedVariance       | 0.887      |
| Iteration               | 490        |
| ItrTime                 | 8.35       |
| LossAfter               | -0.23764   |
| LossBefore              | -0.210658  |
| MaxReturn               | 2.56e+03   |
| MeanKL                  | 0.00991683 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.03e+03   |
| NumTrajs                | 10         |
| Perplexity              | 21.07      |
| PolicyExecTime          | 0.536      |
| ProcessExecTime         | 0.0628     |
| StdReturn               | 389        |
| Time                    | 4.05e+03   |
| dLoss                   | 0.0269821  |
----------------------------------------
itr #491 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 491...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5481, #subsample_inputs: 5481
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.766      |
| AbsLearnSignalNew       | 0.766      |
| AbsLearningOld          | 0.766      |
| AverageDiscountedReturn | 234        |
| AveragePhiLoss          | 17.3956    |
| AveragePolicyStd        | 0.688723   |
| AverageReturn           | 1.54e+03   |
| Entropy                 | 3.05355    |
| EnvExecTime             | 2.14       |
| ExplainedVariance       | 0.904      |
| Iteration               | 491        |
| ItrTime                 | 8.63       |
| LossAfter               | -0.102572  |
| LossBefore              | -0.0787337 |
| MaxReturn               | 2.59e+03   |
| MeanKL                  | 0.00647201 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 910        |
| NumTrajs                | 11         |
| Perplexity              | 21.1904    |
| PolicyExecTime          | 0.551      |
| ProcessExecTime         | 0.0622     |
| StdReturn               | 474        |
| Time                    | 4.06e+03   |
| dLoss                   | 0.0238385  |
----------------------------------------
itr #492 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 492...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5089, #subsample_inputs: 5089
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.757      |
| AbsLearnSignalNew       | 0.757      |
| AbsLearningOld          | 0.757      |
| AverageDiscountedReturn | 232        |
| AveragePhiLoss          | 19.1767    |
| AveragePolicyStd        | 0.688144   |
| AverageReturn           | 1.96e+03   |
| Entropy                 | 3.05065    |
| EnvExecTime             | 1.96       |
| ExplainedVariance       | 0.893      |
| Iteration               | 492        |
| ItrTime                 | 8.09       |
| LossAfter               | -0.187405  |
| LossBefore              | -0.165604  |
| MaxReturn               | 2.47e+03   |
| MeanKL                  | 0.00643263 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.6e+03    |
| NumTrajs                | 8          |
| Perplexity              | 21.1291    |
| PolicyExecTime          | 0.501      |
| ProcessExecTime         | 0.0601     |
| StdReturn               | 290        |
| Time                    | 4.07e+03   |
| dLoss                   | 0.0218017  |
----------------------------------------
itr #493 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 493...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5405, #subsample_inputs: 5405
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.754      |
| AbsLearnSignalNew       | 0.754      |
| AbsLearningOld          | 0.754      |
| AverageDiscountedReturn | 232        |
| AveragePhiLoss          | 17.0648    |
| AveragePolicyStd        | 0.68907    |
| AverageReturn           | 1.83e+03   |
| Entropy                 | 3.05343    |
| EnvExecTime             | 2.16       |
| ExplainedVariance       | 0.867      |
| Iteration               | 493        |
| ItrTime                 | 8.65       |
| LossAfter               | -0.0946638 |
| LossBefore              | -0.0719979 |
| MaxReturn               | 2.79e+03   |
| MeanKL                  | 0.0064106  |
| MeanKLBefore            | 0.0        |
| MinReturn               | 981        |
| NumTrajs                | 9          |
| Perplexity              | 21.188     |
| PolicyExecTime          | 0.551      |
| ProcessExecTime         | 0.0621     |
| StdReturn               | 506        |
| Time                    | 4.08e+03   |
| dLoss                   | 0.0226658  |
----------------------------------------
itr #494 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 494...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5303, #subsample_inputs: 5303
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.711      |
| AbsLearnSignalNew       | 0.711      |
| AbsLearningOld          | 0.711      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 17.2458    |
| AveragePolicyStd        | 0.68873    |
| AverageReturn           | 1.65e+03   |
| Entropy                 | 3.05058    |
| EnvExecTime             | 2.21       |
| ExplainedVariance       | 0.879      |
| Iteration               | 494        |
| ItrTime                 | 8.55       |
| LossAfter               | 0.753754   |
| LossBefore              | 0.775659   |
| MaxReturn               | 2.25e+03   |
| MeanKL                  | 0.00651075 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.19e+03   |
| NumTrajs                | 10         |
| Perplexity              | 21.1276    |
| PolicyExecTime          | 0.564      |
| ProcessExecTime         | 0.0646     |
| StdReturn               | 319        |
| Time                    | 4.09e+03   |
| dLoss                   | 0.0219049  |
----------------------------------------
itr #495 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 495...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5276, #subsample_inputs: 5276
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.773      |
| AbsLearnSignalNew       | 0.773      |
| AbsLearningOld          | 0.773      |
| AverageDiscountedReturn | 235        |
| AveragePhiLoss          | 18.2767    |
| AveragePolicyStd        | 0.687145   |
| AverageReturn           | 1.37e+03   |
| Entropy                 | 3.04317    |
| EnvExecTime             | 1.94       |
| ExplainedVariance       | 0.902      |
| Iteration               | 495        |
| ItrTime                 | 8.17       |
| LossAfter               | 0.0734309  |
| LossBefore              | 0.0980695  |
| MaxReturn               | 1.84e+03   |
| MeanKL                  | 0.00988626 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 898        |
| NumTrajs                | 12         |
| Perplexity              | 20.9717    |
| PolicyExecTime          | 0.492      |
| ProcessExecTime         | 0.0581     |
| StdReturn               | 289        |
| Time                    | 4.09e+03   |
| dLoss                   | 0.0246386  |
----------------------------------------
itr #496 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 496...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5181, #subsample_inputs: 5181
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.781      |
| AbsLearnSignalNew       | 0.781      |
| AbsLearningOld          | 0.781      |
| AverageDiscountedReturn | 235        |
| AveragePhiLoss          | 17.3382    |
| AveragePolicyStd        | 0.683558   |
| AverageReturn           | 1.78e+03   |
| Entropy                 | 3.02902    |
| EnvExecTime             | 2.07       |
| ExplainedVariance       | 0.863      |
| Iteration               | 496        |
| ItrTime                 | 8.38       |
| LossAfter               | -0.317748  |
| LossBefore              | -0.296857  |
| MaxReturn               | 2.14e+03   |
| MeanKL                  | 0.00640156 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.29e+03   |
| NumTrajs                | 9          |
| Perplexity              | 20.677     |
| PolicyExecTime          | 0.534      |
| ProcessExecTime         | 0.0603     |
| StdReturn               | 276        |
| Time                    | 4.1e+03    |
| dLoss                   | 0.0208911  |
----------------------------------------
itr #497 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 497...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5309, #subsample_inputs: 5309
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.699      |
| AbsLearnSignalNew       | 0.699      |
| AbsLearningOld          | 0.699      |
| AverageDiscountedReturn | 235        |
| AveragePhiLoss          | 16.6351    |
| AveragePolicyStd        | 0.681895   |
| AverageReturn           | 1.83e+03   |
| Entropy                 | 3.0202     |
| EnvExecTime             | 2.11       |
| ExplainedVariance       | 0.895      |
| Iteration               | 497        |
| ItrTime                 | 8.47       |
| LossAfter               | -1.07164   |
| LossBefore              | -1.04851   |
| MaxReturn               | 2.22e+03   |
| MeanKL                  | 0.00649214 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.29e+03   |
| NumTrajs                | 9          |
| Perplexity              | 20.4953    |
| PolicyExecTime          | 0.542      |
| ProcessExecTime         | 0.0628     |
| StdReturn               | 268        |
| Time                    | 4.11e+03   |
| dLoss                   | 0.0231273  |
----------------------------------------
itr #498 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 498...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5440, #subsample_inputs: 5440
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.754      |
| AbsLearnSignalNew       | 0.754      |
| AbsLearningOld          | 0.754      |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 17.1333    |
| AveragePolicyStd        | 0.679899   |
| AverageReturn           | 1.56e+03   |
| Entropy                 | 3.01237    |
| EnvExecTime             | 1.95       |
| ExplainedVariance       | 0.896      |
| Iteration               | 498        |
| ItrTime                 | 8.39       |
| LossAfter               | 0.697103   |
| LossBefore              | 0.729668   |
| MaxReturn               | 2.41e+03   |
| MeanKL                  | 0.00996639 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.04e+03   |
| NumTrajs                | 11         |
| Perplexity              | 20.3355    |
| PolicyExecTime          | 0.496      |
| ProcessExecTime         | 0.0577     |
| StdReturn               | 358        |
| Time                    | 4.12e+03   |
| dLoss                   | 0.0325643  |
----------------------------------------
itr #499 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 499...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5575, #subsample_inputs: 5575
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.77       |
| AbsLearnSignalNew       | 0.77       |
| AbsLearningOld          | 0.77       |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 17.1701    |
| AveragePolicyStd        | 0.681069   |
| AverageReturn           | 1.48e+03   |
| Entropy                 | 3.01705    |
| EnvExecTime             | 1.98       |
| ExplainedVariance       | 0.913      |
| Iteration               | 499        |
| ItrTime                 | 8.49       |
| LossAfter               | -0.407051  |
| LossBefore              | -0.389947  |
| MaxReturn               | 2.22e+03   |
| MeanKL                  | 0.00651735 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.03e+03   |
| NumTrajs                | 12         |
| Perplexity              | 20.431     |
| PolicyExecTime          | 0.506      |
| ProcessExecTime         | 0.0603     |
| StdReturn               | 327        |
| Time                    | 4.13e+03   |
| dLoss                   | 0.0171041  |
----------------------------------------
itr #500 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 500...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5949, #subsample_inputs: 5949
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.781      |
| AbsLearnSignalNew       | 0.781      |
| AbsLearningOld          | 0.782      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 17.9616    |
| AveragePolicyStd        | 0.67752    |
| AverageReturn           | 1.68e+03   |
| Entropy                 | 3.00383    |
| EnvExecTime             | 2.41       |
| ExplainedVariance       | 0.897      |
| Iteration               | 500        |
| ItrTime                 | 9.34       |
| LossAfter               | -0.97957   |
| LossBefore              | -0.954299  |
| MaxReturn               | 2.97e+03   |
| MeanKL                  | 0.00996151 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.1e+03    |
| NumTrajs                | 11         |
| Perplexity              | 20.1625    |
| PolicyExecTime          | 0.604      |
| ProcessExecTime         | 0.0708     |
| StdReturn               | 504        |
| Time                    | 4.14e+03   |
| dLoss                   | 0.0252704  |
----------------------------------------
itr #501 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 501...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5386, #subsample_inputs: 5386
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.732      |
| AbsLearnSignalNew       | 0.732      |
| AbsLearningOld          | 0.732      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 17.2961    |
| AveragePolicyStd        | 0.677866   |
| AverageReturn           | 1.4e+03    |
| Entropy                 | 3.00346    |
| EnvExecTime             | 1.94       |
| ExplainedVariance       | 0.902      |
| Iteration               | 501        |
| ItrTime                 | 8.32       |
| LossAfter               | 0.783295   |
| LossBefore              | 0.809446   |
| MaxReturn               | 2.07e+03   |
| MeanKL                  | 0.00981075 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 940        |
| NumTrajs                | 12         |
| Perplexity              | 20.1552    |
| PolicyExecTime          | 0.494      |
| ProcessExecTime         | 0.0583     |
| StdReturn               | 305        |
| Time                    | 4.14e+03   |
| dLoss                   | 0.0261506  |
----------------------------------------
itr #502 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 502...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5378, #subsample_inputs: 5378
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.671      |
| AbsLearnSignalNew       | 0.671      |
| AbsLearningOld          | 0.672      |
| AverageDiscountedReturn | 235        |
| AveragePhiLoss          | 19.2125    |
| AveragePolicyStd        | 0.678013   |
| AverageReturn           | 1.51e+03   |
| Entropy                 | 3.00422    |
| EnvExecTime             | 1.92       |
| ExplainedVariance       | 0.801      |
| Iteration               | 502        |
| ItrTime                 | 8.37       |
| LossAfter               | -0.0472714 |
| LossBefore              | -0.0264688 |
| MaxReturn               | 2.54e+03   |
| MeanKL                  | 0.00643613 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.08e+03   |
| NumTrajs                | 11         |
| Perplexity              | 20.1705    |
| PolicyExecTime          | 0.495      |
| ProcessExecTime         | 0.0571     |
| StdReturn               | 403        |
| Time                    | 4.15e+03   |
| dLoss                   | 0.0208027  |
----------------------------------------
itr #503 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 503...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5057, #subsample_inputs: 5057
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.766      |
| AbsLearnSignalNew       | 0.766      |
| AbsLearningOld          | 0.766      |
| AverageDiscountedReturn | 233        |
| AveragePhiLoss          | 17.6623    |
| AveragePolicyStd        | 0.676644   |
| AverageReturn           | 1.54e+03   |
| Entropy                 | 2.99909    |
| EnvExecTime             | 2.04       |
| ExplainedVariance       | 0.868      |
| Iteration               | 503        |
| ItrTime                 | 8.22       |
| LossAfter               | -0.116012  |
| LossBefore              | -0.090487  |
| MaxReturn               | 2.33e+03   |
| MeanKL                  | 0.00994907 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 866        |
| NumTrajs                | 10         |
| Perplexity              | 20.0673    |
| PolicyExecTime          | 0.517      |
| ProcessExecTime         | 0.0605     |
| StdReturn               | 469        |
| Time                    | 4.16e+03   |
| dLoss                   | 0.0255249  |
----------------------------------------
itr #504 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 504...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5374, #subsample_inputs: 5374
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.766     |
| AbsLearnSignalNew       | 0.766     |
| AbsLearningOld          | 0.766     |
| AverageDiscountedReturn | 240       |
| AveragePhiLoss          | 17.1907   |
| AveragePolicyStd        | 0.676141  |
| AverageReturn           | 1.54e+03  |
| Entropy                 | 2.99644   |
| EnvExecTime             | 2.1       |
| ExplainedVariance       | 0.917     |
| Iteration               | 504       |
| ItrTime                 | 8.57      |
| LossAfter               | 0.6737    |
| LossBefore              | 0.696981  |
| MaxReturn               | 2.42e+03  |
| MeanKL                  | 0.0064169 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.12e+03  |
| NumTrajs                | 11        |
| Perplexity              | 20.0141   |
| PolicyExecTime          | 0.542     |
| ProcessExecTime         | 0.0602    |
| StdReturn               | 349       |
| Time                    | 4.17e+03  |
| dLoss                   | 0.0232811 |
---------------------------------------
itr #505 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 505...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5632, #subsample_inputs: 5632
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.776      |
| AbsLearnSignalNew       | 0.776      |
| AbsLearningOld          | 0.776      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 17.0137    |
| AveragePolicyStd        | 0.676644   |
| AverageReturn           | 1.74e+03   |
| Entropy                 | 2.99927    |
| EnvExecTime             | 2.33       |
| ExplainedVariance       | 0.871      |
| Iteration               | 505        |
| ItrTime                 | 8.92       |
| LossAfter               | 0.406258   |
| LossBefore              | 0.425283   |
| MaxReturn               | 2.11e+03   |
| MeanKL                  | 0.00644334 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.2e+03    |
| NumTrajs                | 10         |
| Perplexity              | 20.071     |
| PolicyExecTime          | 0.587      |
| ProcessExecTime         | 0.0682     |
| StdReturn               | 342        |
| Time                    | 4.18e+03   |
| dLoss                   | 0.0190249  |
----------------------------------------
itr #506 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 506...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5507, #subsample_inputs: 5507
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.759      |
| AbsLearnSignalNew       | 0.759      |
| AbsLearningOld          | 0.759      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 17.9643    |
| AveragePolicyStd        | 0.676296   |
| AverageReturn           | 1.57e+03   |
| Entropy                 | 2.99556    |
| EnvExecTime             | 1.81       |
| ExplainedVariance       | 0.897      |
| Iteration               | 506        |
| ItrTime                 | 8.24       |
| LossAfter               | -0.209799  |
| LossBefore              | -0.192623  |
| MaxReturn               | 2.13e+03   |
| MeanKL                  | 0.00645263 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.14e+03   |
| NumTrajs                | 11         |
| Perplexity              | 19.9966    |
| PolicyExecTime          | 0.474      |
| ProcessExecTime         | 0.0568     |
| StdReturn               | 351        |
| Time                    | 4.19e+03   |
| dLoss                   | 0.017176   |
----------------------------------------
itr #507 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 507...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5248, #subsample_inputs: 5248
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.755      |
| AbsLearnSignalNew       | 0.755      |
| AbsLearningOld          | 0.754      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 16.8408    |
| AveragePolicyStd        | 0.672954   |
| AverageReturn           | 1.37e+03   |
| Entropy                 | 2.98084    |
| EnvExecTime             | 1.87       |
| ExplainedVariance       | 0.899      |
| Iteration               | 507        |
| ItrTime                 | 8.18       |
| LossAfter               | 0.262367   |
| LossBefore              | 0.281439   |
| MaxReturn               | 2.04e+03   |
| MeanKL                  | 0.00656652 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 901        |
| NumTrajs                | 12         |
| Perplexity              | 19.7043    |
| PolicyExecTime          | 0.483      |
| ProcessExecTime         | 0.0559     |
| StdReturn               | 308        |
| Time                    | 4.2e+03    |
| dLoss                   | 0.0190721  |
----------------------------------------
itr #508 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 508...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5029, #subsample_inputs: 5029
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.795      |
| AbsLearnSignalNew       | 0.795      |
| AbsLearningOld          | 0.795      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 17.6559    |
| AveragePolicyStd        | 0.668939   |
| AverageReturn           | 1.33e+03   |
| Entropy                 | 2.96423    |
| EnvExecTime             | 1.8        |
| ExplainedVariance       | 0.915      |
| Iteration               | 508        |
| ItrTime                 | 7.8        |
| LossAfter               | 0.431996   |
| LossBefore              | 0.455051   |
| MaxReturn               | 1.85e+03   |
| MeanKL                  | 0.00996635 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 961        |
| NumTrajs                | 12         |
| Perplexity              | 19.3797    |
| PolicyExecTime          | 0.45       |
| ProcessExecTime         | 0.0553     |
| StdReturn               | 270        |
| Time                    | 4.2e+03    |
| dLoss                   | 0.0230557  |
----------------------------------------
itr #509 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 509...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5108, #subsample_inputs: 5108
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.783      |
| AbsLearnSignalNew       | 0.783      |
| AbsLearningOld          | 0.783      |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 17.9152    |
| AveragePolicyStd        | 0.670656   |
| AverageReturn           | 1.58e+03   |
| Entropy                 | 2.97164    |
| EnvExecTime             | 1.78       |
| ExplainedVariance       | 0.874      |
| Iteration               | 509        |
| ItrTime                 | 7.87       |
| LossAfter               | 0.578147   |
| LossBefore              | 0.604648   |
| MaxReturn               | 2.05e+03   |
| MeanKL                  | 0.00970205 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.06e+03   |
| NumTrajs                | 10         |
| Perplexity              | 19.5238    |
| PolicyExecTime          | 0.456      |
| ProcessExecTime         | 0.0532     |
| StdReturn               | 311        |
| Time                    | 4.21e+03   |
| dLoss                   | 0.0265008  |
----------------------------------------
itr #510 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 510...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5057, #subsample_inputs: 5057
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.752      |
| AbsLearnSignalNew       | 0.752      |
| AbsLearningOld          | 0.753      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 18.3469    |
| AveragePolicyStd        | 0.674152   |
| AverageReturn           | 1.58e+03   |
| Entropy                 | 2.98808    |
| EnvExecTime             | 1.77       |
| ExplainedVariance       | 0.904      |
| Iteration               | 510        |
| ItrTime                 | 7.83       |
| LossAfter               | -0.360476  |
| LossBefore              | -0.339314  |
| MaxReturn               | 2.33e+03   |
| MeanKL                  | 0.00645914 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.13e+03   |
| NumTrajs                | 10         |
| Perplexity              | 19.8476    |
| PolicyExecTime          | 0.458      |
| ProcessExecTime         | 0.0524     |
| StdReturn               | 422        |
| Time                    | 4.22e+03   |
| dLoss                   | 0.021162   |
----------------------------------------
itr #511 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 511...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5300, #subsample_inputs: 5300
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.777      |
| AbsLearnSignalNew       | 0.777      |
| AbsLearningOld          | 0.778      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 17.9308    |
| AveragePolicyStd        | 0.67214    |
| AverageReturn           | 1.5e+03    |
| Entropy                 | 2.97821    |
| EnvExecTime             | 1.88       |
| ExplainedVariance       | 0.883      |
| Iteration               | 511        |
| ItrTime                 | 8.17       |
| LossAfter               | -0.172078  |
| LossBefore              | -0.146943  |
| MaxReturn               | 2.12e+03   |
| MeanKL                  | 0.00998773 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.03e+03   |
| NumTrajs                | 11         |
| Perplexity              | 19.6526    |
| PolicyExecTime          | 0.477      |
| ProcessExecTime         | 0.0559     |
| StdReturn               | 344        |
| Time                    | 4.23e+03   |
| dLoss                   | 0.0251355  |
----------------------------------------
itr #512 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 512...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5115, #subsample_inputs: 5115
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.748      |
| AbsLearnSignalNew       | 0.748      |
| AbsLearningOld          | 0.748      |
| AverageDiscountedReturn | 234        |
| AveragePhiLoss          | 17.8961    |
| AveragePolicyStd        | 0.668305   |
| AverageReturn           | 1.44e+03   |
| Entropy                 | 2.96168    |
| EnvExecTime             | 2.07       |
| ExplainedVariance       | 0.875      |
| Iteration               | 512        |
| ItrTime                 | 8.23       |
| LossAfter               | -0.498703  |
| LossBefore              | -0.474344  |
| MaxReturn               | 2.01e+03   |
| MeanKL                  | 0.00646181 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 895        |
| NumTrajs                | 11         |
| Perplexity              | 19.3304    |
| PolicyExecTime          | 0.519      |
| ProcessExecTime         | 0.0609     |
| StdReturn               | 342        |
| Time                    | 4.24e+03   |
| dLoss                   | 0.0243593  |
----------------------------------------
itr #513 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 513...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5206, #subsample_inputs: 5206
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.783      |
| AbsLearnSignalNew       | 0.783      |
| AbsLearningOld          | 0.783      |
| AverageDiscountedReturn | 235        |
| AveragePhiLoss          | 20.1983    |
| AveragePolicyStd        | 0.669418   |
| AverageReturn           | 1.34e+03   |
| Entropy                 | 2.96505    |
| EnvExecTime             | 2.07       |
| ExplainedVariance       | 0.902      |
| Iteration               | 513        |
| ItrTime                 | 8.33       |
| LossAfter               | 0.207579   |
| LossBefore              | 0.238546   |
| MaxReturn               | 1.83e+03   |
| MeanKL                  | 0.00993082 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 773        |
| NumTrajs                | 12         |
| Perplexity              | 19.3957    |
| PolicyExecTime          | 0.524      |
| ProcessExecTime         | 0.06       |
| StdReturn               | 294        |
| Time                    | 4.24e+03   |
| dLoss                   | 0.0309673  |
----------------------------------------
itr #514 | 
Mem: 714.031250
Obtaining samples...
Obtaining samples for iteration 514...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5150, #subsample_inputs: 5150
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.71      |
| AbsLearnSignalNew       | 0.71      |
| AbsLearningOld          | 0.71      |
| AverageDiscountedReturn | 235       |
| AveragePhiLoss          | 19.5127   |
| AveragePolicyStd        | 0.668167  |
| AverageReturn           | 1.72e+03  |
| Entropy                 | 2.95962   |
| EnvExecTime             | 2.13      |
| ExplainedVariance       | 0.722     |
| Iteration               | 514       |
| ItrTime                 | 8.43      |
| LossAfter               | 0.305108  |
| LossBefore              | 0.334157  |
| MaxReturn               | 2.79e+03  |
| MeanKL                  | 0.0099363 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 873       |
| NumTrajs                | 9         |
| Perplexity              | 19.2906   |
| PolicyExecTime          | 0.54      |
| ProcessExecTime         | 0.0629    |
| StdReturn               | 697       |
| Time                    | 4.25e+03  |
| dLoss                   | 0.0290492 |
---------------------------------------
itr #515 | 
Mem: 714.273438
Obtaining samples...
Obtaining samples for iteration 515...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5517, #subsample_inputs: 5517
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.742     |
| AbsLearnSignalNew       | 0.742     |
| AbsLearningOld          | 0.742     |
| AverageDiscountedReturn | 233       |
| AveragePhiLoss          | 19.501    |
| AveragePolicyStd        | 0.665294  |
| AverageReturn           | 1.68e+03  |
| Entropy                 | 2.9469    |
| EnvExecTime             | 2.31      |
| ExplainedVariance       | 0.821     |
| Iteration               | 515       |
| ItrTime                 | 8.88      |
| LossAfter               | 0.428866  |
| LossBefore              | 0.456862  |
| MaxReturn               | 2.16e+03  |
| MeanKL                  | 0.0099922 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 930       |
| NumTrajs                | 10        |
| Perplexity              | 19.0468   |
| PolicyExecTime          | 0.593     |
| ProcessExecTime         | 0.0656    |
| StdReturn               | 378       |
| Time                    | 4.26e+03  |
| dLoss                   | 0.0279956 |
---------------------------------------
itr #516 | 
Mem: 714.273438
Obtaining samples...
Obtaining samples for iteration 516...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5689, #subsample_inputs: 5689
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.707      |
| AbsLearnSignalNew       | 0.707      |
| AbsLearningOld          | 0.708      |
| AverageDiscountedReturn | 236        |
| AveragePhiLoss          | 18.3884    |
| AveragePolicyStd        | 0.666324   |
| AverageReturn           | 1.59e+03   |
| Entropy                 | 2.95176    |
| EnvExecTime             | 2.11       |
| ExplainedVariance       | 0.786      |
| Iteration               | 516        |
| ItrTime                 | 8.76       |
| LossAfter               | -0.140276  |
| LossBefore              | -0.110906  |
| MaxReturn               | 2.78e+03   |
| MeanKL                  | 0.00995249 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 882        |
| NumTrajs                | 11         |
| Perplexity              | 19.1396    |
| PolicyExecTime          | 0.534      |
| ProcessExecTime         | 0.0629     |
| StdReturn               | 569        |
| Time                    | 4.27e+03   |
| dLoss                   | 0.0293702  |
----------------------------------------
itr #517 | 
Mem: 714.273438
Obtaining samples...
Obtaining samples for iteration 517...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5456, #subsample_inputs: 5456
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.725      |
| AbsLearnSignalNew       | 0.725      |
| AbsLearningOld          | 0.725      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 17.6978    |
| AveragePolicyStd        | 0.666794   |
| AverageReturn           | 1.42e+03   |
| Entropy                 | 2.95359    |
| EnvExecTime             | 1.91       |
| ExplainedVariance       | 0.849      |
| Iteration               | 517        |
| ItrTime                 | 8.32       |
| LossAfter               | 0.354145   |
| LossBefore              | 0.371552   |
| MaxReturn               | 2.08e+03   |
| MeanKL                  | 0.00658926 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 815        |
| NumTrajs                | 12         |
| Perplexity              | 19.1746    |
| PolicyExecTime          | 0.491      |
| ProcessExecTime         | 0.0567     |
| StdReturn               | 393        |
| Time                    | 4.28e+03   |
| dLoss                   | 0.0174061  |
----------------------------------------
itr #518 | 
Mem: 714.273438
Obtaining samples...
Obtaining samples for iteration 518...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5298, #subsample_inputs: 5298
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.772      |
| AbsLearnSignalNew       | 0.772      |
| AbsLearningOld          | 0.772      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 19.456     |
| AveragePolicyStd        | 0.666651   |
| AverageReturn           | 1.41e+03   |
| Entropy                 | 2.95187    |
| EnvExecTime             | 2.23       |
| ExplainedVariance       | 0.899      |
| Iteration               | 518        |
| ItrTime                 | 8.64       |
| LossAfter               | 0.516182   |
| LossBefore              | 0.53946    |
| MaxReturn               | 2.1e+03    |
| MeanKL                  | 0.00645802 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.12e+03   |
| NumTrajs                | 12         |
| Perplexity              | 19.1417    |
| PolicyExecTime          | 0.567      |
| ProcessExecTime         | 0.0635     |
| StdReturn               | 313        |
| Time                    | 4.29e+03   |
| dLoss                   | 0.0232782  |
----------------------------------------
itr #519 | 
Mem: 714.273438
Obtaining samples...
Obtaining samples for iteration 519...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5497, #subsample_inputs: 5497
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.749     |
| AbsLearnSignalNew       | 0.749     |
| AbsLearningOld          | 0.749     |
| AverageDiscountedReturn | 237       |
| AveragePhiLoss          | 21.5681   |
| AveragePolicyStd        | 0.66599   |
| AverageReturn           | 1.55e+03  |
| Entropy                 | 2.94706   |
| EnvExecTime             | 2.01      |
| ExplainedVariance       | 0.863     |
| Iteration               | 519       |
| ItrTime                 | 8.45      |
| LossAfter               | -0.346718 |
| LossBefore              | -0.327587 |
| MaxReturn               | 2.89e+03  |
| MeanKL                  | 0.0064742 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 881       |
| NumTrajs                | 11        |
| Perplexity              | 19.0498   |
| PolicyExecTime          | 0.516     |
| ProcessExecTime         | 0.0602    |
| StdReturn               | 519       |
| Time                    | 4.3e+03   |
| dLoss                   | 0.0191303 |
---------------------------------------
itr #520 | 
Mem: 714.273438
Obtaining samples...
Obtaining samples for iteration 520...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5107, #subsample_inputs: 5107
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.761      |
| AbsLearnSignalNew       | 0.761      |
| AbsLearningOld          | 0.761      |
| AverageDiscountedReturn | 234        |
| AveragePhiLoss          | 17.9942    |
| AveragePolicyStd        | 0.666467   |
| AverageReturn           | 1.75e+03   |
| Entropy                 | 2.94921    |
| EnvExecTime             | 2.04       |
| ExplainedVariance       | 0.888      |
| Iteration               | 520        |
| ItrTime                 | 8.21       |
| LossAfter               | -0.210851  |
| LossBefore              | -0.181661  |
| MaxReturn               | 2.14e+03   |
| MeanKL                  | 0.00994689 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.06e+03   |
| NumTrajs                | 9          |
| Perplexity              | 19.0908    |
| PolicyExecTime          | 0.521      |
| ProcessExecTime         | 0.0587     |
| StdReturn               | 358        |
| Time                    | 4.3e+03    |
| dLoss                   | 0.0291902  |
----------------------------------------
itr #521 | 
Mem: 714.273438
Obtaining samples...
Obtaining samples for iteration 521...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5004, #subsample_inputs: 5004
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.754      |
| AbsLearnSignalNew       | 0.754      |
| AbsLearningOld          | 0.754      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 18.5894    |
| AveragePolicyStd        | 0.665595   |
| AverageReturn           | 1.44e+03   |
| Entropy                 | 2.94588    |
| EnvExecTime             | 1.91       |
| ExplainedVariance       | 0.898      |
| Iteration               | 521        |
| ItrTime                 | 7.96       |
| LossAfter               | -0.293669  |
| LossBefore              | -0.266711  |
| MaxReturn               | 2.01e+03   |
| MeanKL                  | 0.00978537 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.09e+03   |
| NumTrajs                | 11         |
| Perplexity              | 19.0274    |
| PolicyExecTime          | 0.494      |
| ProcessExecTime         | 0.0557     |
| StdReturn               | 323        |
| Time                    | 4.31e+03   |
| dLoss                   | 0.0269571  |
----------------------------------------
itr #522 | 
Mem: 714.273438
Obtaining samples...
Obtaining samples for iteration 522...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5070, #subsample_inputs: 5070
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.783      |
| AbsLearnSignalNew       | 0.783      |
| AbsLearningOld          | 0.783      |
| AverageDiscountedReturn | 235        |
| AveragePhiLoss          | 19.5165    |
| AveragePolicyStd        | 0.663168   |
| AverageReturn           | 1.42e+03   |
| Entropy                 | 2.93499    |
| EnvExecTime             | 1.94       |
| ExplainedVariance       | 0.878      |
| Iteration               | 522        |
| ItrTime                 | 8.13       |
| LossAfter               | -0.645055  |
| LossBefore              | -0.622013  |
| MaxReturn               | 1.95e+03   |
| MeanKL                  | 0.00651324 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 859        |
| NumTrajs                | 11         |
| Perplexity              | 18.8213    |
| PolicyExecTime          | 0.502      |
| ProcessExecTime         | 0.0554     |
| StdReturn               | 366        |
| Time                    | 4.32e+03   |
| dLoss                   | 0.0230415  |
----------------------------------------
itr #523 | 
Mem: 714.273438
Obtaining samples...
Obtaining samples for iteration 523...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5080, #subsample_inputs: 5080
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.784      |
| AbsLearnSignalNew       | 0.784      |
| AbsLearningOld          | 0.784      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 19.1647    |
| AveragePolicyStd        | 0.665708   |
| AverageReturn           | 1.46e+03   |
| Entropy                 | 2.94484    |
| EnvExecTime             | 1.83       |
| ExplainedVariance       | 0.909      |
| Iteration               | 523        |
| ItrTime                 | 7.9        |
| LossAfter               | -0.24201   |
| LossBefore              | -0.21809   |
| MaxReturn               | 1.92e+03   |
| MeanKL                  | 0.00995668 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.1e+03    |
| NumTrajs                | 11         |
| Perplexity              | 19.0075    |
| PolicyExecTime          | 0.473      |
| ProcessExecTime         | 0.0532     |
| StdReturn               | 260        |
| Time                    | 4.33e+03   |
| dLoss                   | 0.023919   |
----------------------------------------
itr #524 | 
Mem: 714.273438
Obtaining samples...
Obtaining samples for iteration 524...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5605, #subsample_inputs: 5605
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.714      |
| AbsLearnSignalNew       | 0.714      |
| AbsLearningOld          | 0.714      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 18.3055    |
| AveragePolicyStd        | 0.66527    |
| AverageReturn           | 1.73e+03   |
| Entropy                 | 2.94198    |
| EnvExecTime             | 2.21       |
| ExplainedVariance       | 0.753      |
| Iteration               | 524        |
| ItrTime                 | 8.77       |
| LossAfter               | 0.932472   |
| LossBefore              | 0.961109   |
| MaxReturn               | 2.67e+03   |
| MeanKL                  | 0.00980243 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.03e+03   |
| NumTrajs                | 10         |
| Perplexity              | 18.9534    |
| PolicyExecTime          | 0.563      |
| ProcessExecTime         | 0.0632     |
| StdReturn               | 569        |
| Time                    | 4.34e+03   |
| dLoss                   | 0.0286371  |
----------------------------------------
itr #525 | 
Mem: 714.273438
Obtaining samples...
Obtaining samples for iteration 525...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5439, #subsample_inputs: 5439
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.759      |
| AbsLearnSignalNew       | 0.759      |
| AbsLearningOld          | 0.759      |
| AverageDiscountedReturn | 236        |
| AveragePhiLoss          | 18.3519    |
| AveragePolicyStd        | 0.665015   |
| AverageReturn           | 1.68e+03   |
| Entropy                 | 2.94356    |
| EnvExecTime             | 2.07       |
| ExplainedVariance       | 0.833      |
| Iteration               | 525        |
| ItrTime                 | 8.59       |
| LossAfter               | 0.573267   |
| LossBefore              | 0.59784    |
| MaxReturn               | 2.53e+03   |
| MeanKL                  | 0.00645994 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.02e+03   |
| NumTrajs                | 10         |
| Perplexity              | 18.9834    |
| PolicyExecTime          | 0.527      |
| ProcessExecTime         | 0.0618     |
| StdReturn               | 449        |
| Time                    | 4.35e+03   |
| dLoss                   | 0.0245736  |
----------------------------------------
itr #526 | 
Mem: 714.273438
Obtaining samples...
Obtaining samples for iteration 526...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5236, #subsample_inputs: 5236
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.762      |
| AbsLearnSignalNew       | 0.762      |
| AbsLearningOld          | 0.762      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 20.1124    |
| AveragePolicyStd        | 0.664149   |
| AverageReturn           | 1.49e+03   |
| Entropy                 | 2.93985    |
| EnvExecTime             | 2.2        |
| ExplainedVariance       | 0.878      |
| Iteration               | 526        |
| ItrTime                 | 8.52       |
| LossAfter               | 0.446756   |
| LossBefore              | 0.473178   |
| MaxReturn               | 1.91e+03   |
| MeanKL                  | 0.00995241 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.02e+03   |
| NumTrajs                | 11         |
| Perplexity              | 18.913     |
| PolicyExecTime          | 0.558      |
| ProcessExecTime         | 0.0643     |
| StdReturn               | 284        |
| Time                    | 4.35e+03   |
| dLoss                   | 0.0264213  |
----------------------------------------
itr #527 | 
Mem: 714.273438
Obtaining samples...
Obtaining samples for iteration 527...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5106, #subsample_inputs: 5106
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.784      |
| AbsLearnSignalNew       | 0.784      |
| AbsLearningOld          | 0.784      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 17.411     |
| AveragePolicyStd        | 0.662932   |
| AverageReturn           | 1.75e+03   |
| Entropy                 | 2.9371     |
| EnvExecTime             | 2.01       |
| ExplainedVariance       | 0.889      |
| Iteration               | 527        |
| ItrTime                 | 8.19       |
| LossAfter               | 0.0928176  |
| LossBefore              | 0.122955   |
| MaxReturn               | 2.33e+03   |
| MeanKL                  | 0.00986699 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.03e+03   |
| NumTrajs                | 9          |
| Perplexity              | 18.8612    |
| PolicyExecTime          | 0.519      |
| ProcessExecTime         | 0.0579     |
| StdReturn               | 377        |
| Time                    | 4.36e+03   |
| dLoss                   | 0.0301376  |
----------------------------------------
itr #528 | 
Mem: 714.273438
Obtaining samples...
Obtaining samples for iteration 528...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5595, #subsample_inputs: 5595
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.735      |
| AbsLearnSignalNew       | 0.735      |
| AbsLearningOld          | 0.735      |
| AverageDiscountedReturn | 233        |
| AveragePhiLoss          | 18.1338    |
| AveragePolicyStd        | 0.662882   |
| AverageReturn           | 1.66e+03   |
| Entropy                 | 2.93927    |
| EnvExecTime             | 2.24       |
| ExplainedVariance       | 0.787      |
| Iteration               | 528        |
| ItrTime                 | 8.88       |
| LossAfter               | 0.261788   |
| LossBefore              | 0.281973   |
| MaxReturn               | 2.88e+03   |
| MeanKL                  | 0.00651726 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 835        |
| NumTrajs                | 10         |
| Perplexity              | 18.9021    |
| PolicyExecTime          | 0.57       |
| ProcessExecTime         | 0.0647     |
| StdReturn               | 625        |
| Time                    | 4.37e+03   |
| dLoss                   | 0.020185   |
----------------------------------------
itr #529 | 
Mem: 714.273438
Obtaining samples...
Obtaining samples for iteration 529...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5072, #subsample_inputs: 5072
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.732      |
| AbsLearnSignalNew       | 0.732      |
| AbsLearningOld          | 0.732      |
| AverageDiscountedReturn | 234        |
| AveragePhiLoss          | 17.7836    |
| AveragePolicyStd        | 0.662501   |
| AverageReturn           | 1.56e+03   |
| Entropy                 | 2.93937    |
| EnvExecTime             | 1.9        |
| ExplainedVariance       | 0.873      |
| Iteration               | 529        |
| ItrTime                 | 7.98       |
| LossAfter               | 1.12524    |
| LossBefore              | 1.15066    |
| MaxReturn               | 2.17e+03   |
| MeanKL                  | 0.00989616 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 870        |
| NumTrajs                | 10         |
| Perplexity              | 18.9039    |
| PolicyExecTime          | 0.487      |
| ProcessExecTime         | 0.0557     |
| StdReturn               | 408        |
| Time                    | 4.38e+03   |
| dLoss                   | 0.0254276  |
----------------------------------------
itr #530 | 
Mem: 714.273438
Obtaining samples...
Obtaining samples for iteration 530...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5279, #subsample_inputs: 5279
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.625      |
| AbsLearnSignalNew       | 0.625      |
| AbsLearningOld          | 0.625      |
| AverageDiscountedReturn | 231        |
| AveragePhiLoss          | 17.7408    |
| AveragePolicyStd        | 0.6623     |
| AverageReturn           | 1.7e+03    |
| Entropy                 | 2.93895    |
| EnvExecTime             | 2.08       |
| ExplainedVariance       | 0.634      |
| Iteration               | 530        |
| ItrTime                 | 8.46       |
| LossAfter               | 0.609447   |
| LossBefore              | 0.628845   |
| MaxReturn               | 2.68e+03   |
| MeanKL                  | 0.00650183 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 850        |
| NumTrajs                | 9          |
| Perplexity              | 18.896     |
| PolicyExecTime          | 0.528      |
| ProcessExecTime         | 0.06       |
| StdReturn               | 676        |
| Time                    | 4.39e+03   |
| dLoss                   | 0.0193977  |
----------------------------------------
itr #531 | 
Mem: 714.273438
Obtaining samples...
Obtaining samples for iteration 531...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5378, #subsample_inputs: 5378
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.692      |
| AbsLearnSignalNew       | 0.692      |
| AbsLearningOld          | 0.691      |
| AverageDiscountedReturn | 233        |
| AveragePhiLoss          | 17.3479    |
| AveragePolicyStd        | 0.663585   |
| AverageReturn           | 2e+03      |
| Entropy                 | 2.94332    |
| EnvExecTime             | 2.2        |
| ExplainedVariance       | 0.781      |
| Iteration               | 531        |
| ItrTime                 | 8.7        |
| LossAfter               | -0.413155  |
| LossBefore              | -0.38518   |
| MaxReturn               | 2.81e+03   |
| MeanKL                  | 0.00651965 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.1e+03    |
| NumTrajs                | 8          |
| Perplexity              | 18.9788    |
| PolicyExecTime          | 0.56       |
| ProcessExecTime         | 0.0639     |
| StdReturn               | 636        |
| Time                    | 4.4e+03    |
| dLoss                   | 0.0279754  |
----------------------------------------
itr #532 | 
Mem: 714.273438
Obtaining samples...
Obtaining samples for iteration 532...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5007, #subsample_inputs: 5007
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.726      |
| AbsLearnSignalNew       | 0.726      |
| AbsLearningOld          | 0.726      |
| AverageDiscountedReturn | 234        |
| AveragePhiLoss          | 18.441     |
| AveragePolicyStd        | 0.663969   |
| AverageReturn           | 1.66e+03   |
| Entropy                 | 2.94614    |
| EnvExecTime             | 2.09       |
| ExplainedVariance       | 0.839      |
| Iteration               | 532        |
| ItrTime                 | 8.13       |
| LossAfter               | -0.947543  |
| LossBefore              | -0.917624  |
| MaxReturn               | 2.74e+03   |
| MeanKL                  | 0.00978057 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.16e+03   |
| NumTrajs                | 9          |
| Perplexity              | 19.0324    |
| PolicyExecTime          | 0.543      |
| ProcessExecTime         | 0.0591     |
| StdReturn               | 477        |
| Time                    | 4.41e+03   |
| dLoss                   | 0.0299192  |
----------------------------------------
itr #533 | 
Mem: 714.300781
Obtaining samples...
Obtaining samples for iteration 533...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5721, #subsample_inputs: 5721
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.742      |
| AbsLearnSignalNew       | 0.742      |
| AbsLearningOld          | 0.742      |
| AverageDiscountedReturn | 233        |
| AveragePhiLoss          | 21.2934    |
| AveragePolicyStd        | 0.66571    |
| AverageReturn           | 1.94e+03   |
| Entropy                 | 2.95251    |
| EnvExecTime             | 2.47       |
| ExplainedVariance       | 0.819      |
| Iteration               | 533        |
| ItrTime                 | 9.23       |
| LossAfter               | 0.210189   |
| LossBefore              | 0.229907   |
| MaxReturn               | 2.79e+03   |
| MeanKL                  | 0.00650126 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.28e+03   |
| NumTrajs                | 9          |
| Perplexity              | 19.1539    |
| PolicyExecTime          | 0.611      |
| ProcessExecTime         | 0.0736     |
| StdReturn               | 458        |
| Time                    | 4.41e+03   |
| dLoss                   | 0.0197187  |
----------------------------------------
itr #534 | 
Mem: 714.300781
Obtaining samples...
Obtaining samples for iteration 534...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5349, #subsample_inputs: 5349
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.666      |
| AbsLearnSignalNew       | 0.666      |
| AbsLearningOld          | 0.666      |
| AverageDiscountedReturn | 231        |
| AveragePhiLoss          | 17.4461    |
| AveragePolicyStd        | 0.664294   |
| AverageReturn           | 1.75e+03   |
| Entropy                 | 2.94453    |
| EnvExecTime             | 2.15       |
| ExplainedVariance       | 0.728      |
| Iteration               | 534        |
| ItrTime                 | 8.66       |
| LossAfter               | 0.0983928  |
| LossBefore              | 0.11574    |
| MaxReturn               | 2.56e+03   |
| MeanKL                  | 0.00641632 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.01e+03   |
| NumTrajs                | 9          |
| Perplexity              | 19.0017    |
| PolicyExecTime          | 0.56       |
| ProcessExecTime         | 0.0612     |
| StdReturn               | 478        |
| Time                    | 4.42e+03   |
| dLoss                   | 0.0173475  |
----------------------------------------
itr #535 | 
Mem: 714.300781
Obtaining samples...
Obtaining samples for iteration 535...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5150, #subsample_inputs: 5150
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.756      |
| AbsLearnSignalNew       | 0.756      |
| AbsLearningOld          | 0.756      |
| AverageDiscountedReturn | 231        |
| AveragePhiLoss          | 19.649     |
| AveragePolicyStd        | 0.663121   |
| AverageReturn           | 1.71e+03   |
| Entropy                 | 2.93952    |
| EnvExecTime             | 1.99       |
| ExplainedVariance       | 0.836      |
| Iteration               | 535        |
| ItrTime                 | 8.2        |
| LossAfter               | -0.332086  |
| LossBefore              | -0.308585  |
| MaxReturn               | 2.83e+03   |
| MeanKL                  | 0.00652103 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 897        |
| NumTrajs                | 9          |
| Perplexity              | 18.9067    |
| PolicyExecTime          | 0.503      |
| ProcessExecTime         | 0.0594     |
| StdReturn               | 585        |
| Time                    | 4.43e+03   |
| dLoss                   | 0.0235002  |
----------------------------------------
itr #536 | 
Mem: 714.300781
Obtaining samples...
Obtaining samples for iteration 536...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5591, #subsample_inputs: 5591
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.727     |
| AbsLearnSignalNew       | 0.727     |
| AbsLearningOld          | 0.727     |
| AverageDiscountedReturn | 232       |
| AveragePhiLoss          | 18.6302   |
| AveragePolicyStd        | 0.663219  |
| AverageReturn           | 1.55e+03  |
| Entropy                 | 2.94008   |
| EnvExecTime             | 2.17      |
| ExplainedVariance       | 0.853     |
| Iteration               | 536       |
| ItrTime                 | 8.73      |
| LossAfter               | 0.4413    |
| LossBefore              | 0.469022  |
| MaxReturn               | 2.39e+03  |
| MeanKL                  | 0.0097483 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.01e+03  |
| NumTrajs                | 11        |
| Perplexity              | 18.9174   |
| PolicyExecTime          | 0.553     |
| ProcessExecTime         | 0.0629    |
| StdReturn               | 431       |
| Time                    | 4.44e+03  |
| dLoss                   | 0.0277227 |
---------------------------------------
itr #537 | 
Mem: 714.300781
Obtaining samples...
Obtaining samples for iteration 537...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5697, #subsample_inputs: 5697
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.55       |
| AbsLearnSignalNew       | 0.55       |
| AbsLearningOld          | 0.55       |
| AverageDiscountedReturn | 230        |
| AveragePhiLoss          | 20.6108    |
| AveragePolicyStd        | 0.663148   |
| AverageReturn           | 1.63e+03   |
| Entropy                 | 2.94112    |
| EnvExecTime             | 2.17       |
| ExplainedVariance       | 0.39       |
| Iteration               | 537        |
| ItrTime                 | 8.8        |
| LossAfter               | -1.11849   |
| LossBefore              | -1.09878   |
| MaxReturn               | 2.61e+03   |
| MeanKL                  | 0.00986891 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 714        |
| NumTrajs                | 10         |
| Perplexity              | 18.937     |
| PolicyExecTime          | 0.558      |
| ProcessExecTime         | 0.0634     |
| StdReturn               | 655        |
| Time                    | 4.45e+03   |
| dLoss                   | 0.0197039  |
----------------------------------------
itr #538 | 
Mem: 714.300781
Obtaining samples...
Obtaining samples for iteration 538...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5350, #subsample_inputs: 5350
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.75       |
| AbsLearnSignalNew       | 0.75       |
| AbsLearningOld          | 0.75       |
| AverageDiscountedReturn | 229        |
| AveragePhiLoss          | 19.8378    |
| AveragePolicyStd        | 0.660989   |
| AverageReturn           | 1.56e+03   |
| Entropy                 | 2.93465    |
| EnvExecTime             | 2.36       |
| ExplainedVariance       | 0.678      |
| Iteration               | 538        |
| ItrTime                 | 8.82       |
| LossAfter               | -0.743543  |
| LossBefore              | -0.717976  |
| MaxReturn               | 2.2e+03    |
| MeanKL                  | 0.00996333 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.16e+03   |
| NumTrajs                | 10         |
| Perplexity              | 18.815     |
| PolicyExecTime          | 0.61       |
| ProcessExecTime         | 0.0655     |
| StdReturn               | 338        |
| Time                    | 4.46e+03   |
| dLoss                   | 0.0255672  |
----------------------------------------
itr #539 | 
Mem: 714.300781
Obtaining samples...
Obtaining samples for iteration 539...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5498, #subsample_inputs: 5498
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.64       |
| AbsLearnSignalNew       | 0.64       |
| AbsLearningOld          | 0.64       |
| AverageDiscountedReturn | 234        |
| AveragePhiLoss          | 18.9201    |
| AveragePolicyStd        | 0.662968   |
| AverageReturn           | 1.84e+03   |
| Entropy                 | 2.94165    |
| EnvExecTime             | 2.39       |
| ExplainedVariance       | 0.714      |
| Iteration               | 539        |
| ItrTime                 | 8.91       |
| LossAfter               | 0.064568   |
| LossBefore              | 0.0873042  |
| MaxReturn               | 2.55e+03   |
| MeanKL                  | 0.00642426 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 974        |
| NumTrajs                | 9          |
| Perplexity              | 18.9472    |
| PolicyExecTime          | 0.608      |
| ProcessExecTime         | 0.0682     |
| StdReturn               | 493        |
| Time                    | 4.47e+03   |
| dLoss                   | 0.0227362  |
----------------------------------------
itr #540 | 
Mem: 714.300781
Obtaining samples...
Obtaining samples for iteration 540...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5046, #subsample_inputs: 5046
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.731      |
| AbsLearnSignalNew       | 0.731      |
| AbsLearningOld          | 0.731      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 16.4385    |
| AveragePolicyStd        | 0.661449   |
| AverageReturn           | 1.71e+03   |
| Entropy                 | 2.93877    |
| EnvExecTime             | 2.03       |
| ExplainedVariance       | 0.845      |
| Iteration               | 540        |
| ItrTime                 | 8.12       |
| LossAfter               | -0.226947  |
| LossBefore              | -0.197956  |
| MaxReturn               | 2.88e+03   |
| MeanKL                  | 0.00979845 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.02e+03   |
| NumTrajs                | 9          |
| Perplexity              | 18.8925    |
| PolicyExecTime          | 0.528      |
| ProcessExecTime         | 0.0574     |
| StdReturn               | 602        |
| Time                    | 4.48e+03   |
| dLoss                   | 0.0289905  |
----------------------------------------
itr #541 | 
Mem: 714.300781
Obtaining samples...
Obtaining samples for iteration 541...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5311, #subsample_inputs: 5311
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.728     |
| AbsLearnSignalNew       | 0.728     |
| AbsLearningOld          | 0.728     |
| AverageDiscountedReturn | 239       |
| AveragePhiLoss          | 17.921    |
| AveragePolicyStd        | 0.661647  |
| AverageReturn           | 1.39e+03  |
| Entropy                 | 2.94321   |
| EnvExecTime             | 2.09      |
| ExplainedVariance       | 0.817     |
| Iteration               | 541       |
| ItrTime                 | 8.41      |
| LossAfter               | 0.816745  |
| LossBefore              | 0.83766   |
| MaxReturn               | 2.99e+03  |
| MeanKL                  | 0.0064379 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 940       |
| NumTrajs                | 12        |
| Perplexity              | 18.9767   |
| PolicyExecTime          | 0.534     |
| ProcessExecTime         | 0.0622    |
| StdReturn               | 528       |
| Time                    | 4.48e+03  |
| dLoss                   | 0.0209148 |
---------------------------------------
itr #542 | 
Mem: 714.300781
Obtaining samples...
Obtaining samples for iteration 542...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5312, #subsample_inputs: 5312
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.741      |
| AbsLearnSignalNew       | 0.741      |
| AbsLearningOld          | 0.741      |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 19.7779    |
| AveragePolicyStd        | 0.660614   |
| AverageReturn           | 1.51e+03   |
| Entropy                 | 2.93755    |
| EnvExecTime             | 2.03       |
| ExplainedVariance       | 0.863      |
| Iteration               | 542        |
| ItrTime                 | 8.36       |
| LossAfter               | -0.794839  |
| LossBefore              | -0.769515  |
| MaxReturn               | 2.28e+03   |
| MeanKL                  | 0.00642827 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 742        |
| NumTrajs                | 11         |
| Perplexity              | 18.8695    |
| PolicyExecTime          | 0.52       |
| ProcessExecTime         | 0.0625     |
| StdReturn               | 440        |
| Time                    | 4.49e+03   |
| dLoss                   | 0.0253237  |
----------------------------------------
itr #543 | 
Mem: 714.300781
Obtaining samples...
Obtaining samples for iteration 543...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5174, #subsample_inputs: 5174
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.695      |
| AbsLearnSignalNew       | 0.695      |
| AbsLearningOld          | 0.695      |
| AverageDiscountedReturn | 234        |
| AveragePhiLoss          | 16.2982    |
| AveragePolicyStd        | 0.659861   |
| AverageReturn           | 1.76e+03   |
| Entropy                 | 2.9341     |
| EnvExecTime             | 1.99       |
| ExplainedVariance       | 0.72       |
| Iteration               | 543        |
| ItrTime                 | 8.26       |
| LossAfter               | -0.506666  |
| LossBefore              | -0.483308  |
| MaxReturn               | 2.88e+03   |
| MeanKL                  | 0.00647052 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1e+03      |
| NumTrajs                | 9          |
| Perplexity              | 18.8047    |
| PolicyExecTime          | 0.509      |
| ProcessExecTime         | 0.0608     |
| StdReturn               | 537        |
| Time                    | 4.5e+03    |
| dLoss                   | 0.0233573  |
----------------------------------------
itr #544 | 
Mem: 714.300781
Obtaining samples...
Obtaining samples for iteration 544...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5841, #subsample_inputs: 5841
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.774      |
| AbsLearnSignalNew       | 0.774      |
| AbsLearningOld          | 0.774      |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 18.6215    |
| AveragePolicyStd        | 0.660514   |
| AverageReturn           | 1.54e+03   |
| Entropy                 | 2.93784    |
| EnvExecTime             | 2.21       |
| ExplainedVariance       | 0.88       |
| Iteration               | 544        |
| ItrTime                 | 9.04       |
| LossAfter               | -1.09503   |
| LossBefore              | -1.06978   |
| MaxReturn               | 2.93e+03   |
| MeanKL                  | 0.00992852 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 866        |
| NumTrajs                | 12         |
| Perplexity              | 18.8751    |
| PolicyExecTime          | 0.554      |
| ProcessExecTime         | 0.0669     |
| StdReturn               | 508        |
| Time                    | 4.51e+03   |
| dLoss                   | 0.0252503  |
----------------------------------------
itr #545 | 
Mem: 716.339844
Obtaining samples...
Obtaining samples for iteration 545...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5330, #subsample_inputs: 5330
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.782      |
| AbsLearnSignalNew       | 0.782      |
| AbsLearningOld          | 0.782      |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 17.6056    |
| AveragePolicyStd        | 0.663918   |
| AverageReturn           | 1.4e+03    |
| Entropy                 | 2.95141    |
| EnvExecTime             | 1.96       |
| ExplainedVariance       | 0.888      |
| Iteration               | 545        |
| ItrTime                 | 8.32       |
| LossAfter               | 1.3105     |
| LossBefore              | 1.33122    |
| MaxReturn               | 2.05e+03   |
| MeanKL                  | 0.00644695 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 759        |
| NumTrajs                | 12         |
| Perplexity              | 19.1329    |
| PolicyExecTime          | 0.506      |
| ProcessExecTime         | 0.0584     |
| StdReturn               | 383        |
| Time                    | 4.52e+03   |
| dLoss                   | 0.0207205  |
----------------------------------------
itr #546 | 
Mem: 716.339844
Obtaining samples...
Obtaining samples for iteration 546...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5372, #subsample_inputs: 5372
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.746      |
| AbsLearnSignalNew       | 0.746      |
| AbsLearningOld          | 0.746      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 18.2254    |
| AveragePolicyStd        | 0.664254   |
| AverageReturn           | 1.53e+03   |
| Entropy                 | 2.95266    |
| EnvExecTime             | 2.07       |
| ExplainedVariance       | 0.873      |
| Iteration               | 546        |
| ItrTime                 | 8.53       |
| LossAfter               | 0.244317   |
| LossBefore              | 0.263057   |
| MaxReturn               | 2.51e+03   |
| MeanKL                  | 0.00649553 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.03e+03   |
| NumTrajs                | 11         |
| Perplexity              | 19.1568    |
| PolicyExecTime          | 0.536      |
| ProcessExecTime         | 0.0615     |
| StdReturn               | 405        |
| Time                    | 4.53e+03   |
| dLoss                   | 0.0187402  |
----------------------------------------
itr #547 | 
Mem: 716.339844
Obtaining samples...
Obtaining samples for iteration 547...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5129, #subsample_inputs: 5129
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.797      |
| AbsLearnSignalNew       | 0.797      |
| AbsLearningOld          | 0.797      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 16.7043    |
| AveragePolicyStd        | 0.661975   |
| AverageReturn           | 1.45e+03   |
| Entropy                 | 2.94416    |
| EnvExecTime             | 2.01       |
| ExplainedVariance       | 0.899      |
| Iteration               | 547        |
| ItrTime                 | 8.17       |
| LossAfter               | -0.322992  |
| LossBefore              | -0.294761  |
| MaxReturn               | 1.99e+03   |
| MeanKL                  | 0.00986084 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.07e+03   |
| NumTrajs                | 11         |
| Perplexity              | 18.9947    |
| PolicyExecTime          | 0.505      |
| ProcessExecTime         | 0.0595     |
| StdReturn               | 292        |
| Time                    | 4.53e+03   |
| dLoss                   | 0.0282308  |
----------------------------------------
itr #548 | 
Mem: 716.339844
Obtaining samples...
Obtaining samples for iteration 548...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5292, #subsample_inputs: 5292
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.78       |
| AbsLearnSignalNew       | 0.78       |
| AbsLearningOld          | 0.78       |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 19.2067    |
| AveragePolicyStd        | 0.658671   |
| AverageReturn           | 1.51e+03   |
| Entropy                 | 2.93141    |
| EnvExecTime             | 2.05       |
| ExplainedVariance       | 0.894      |
| Iteration               | 548        |
| ItrTime                 | 8.38       |
| LossAfter               | 0.0752845  |
| LossBefore              | 0.100274   |
| MaxReturn               | 2.45e+03   |
| MeanKL                  | 0.00992316 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.12e+03   |
| NumTrajs                | 11         |
| Perplexity              | 18.7541    |
| PolicyExecTime          | 0.514      |
| ProcessExecTime         | 0.0648     |
| StdReturn               | 440        |
| Time                    | 4.54e+03   |
| dLoss                   | 0.0249892  |
----------------------------------------
itr #549 | 
Mem: 716.339844
Obtaining samples...
Obtaining samples for iteration 549...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5165, #subsample_inputs: 5165
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.765      |
| AbsLearnSignalNew       | 0.765      |
| AbsLearningOld          | 0.765      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 19.2247    |
| AveragePolicyStd        | 0.657352   |
| AverageReturn           | 1.36e+03   |
| Entropy                 | 2.92823    |
| EnvExecTime             | 1.86       |
| ExplainedVariance       | 0.887      |
| Iteration               | 549        |
| ItrTime                 | 8.03       |
| LossAfter               | -0.11299   |
| LossBefore              | -0.0874542 |
| MaxReturn               | 2.79e+03   |
| MeanKL                  | 0.00994685 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 901        |
| NumTrajs                | 12         |
| Perplexity              | 18.6945    |
| PolicyExecTime          | 0.473      |
| ProcessExecTime         | 0.0558     |
| StdReturn               | 483        |
| Time                    | 4.55e+03   |
| dLoss                   | 0.0255357  |
----------------------------------------
itr #550 | 
Mem: 716.339844
Obtaining samples...
Obtaining samples for iteration 550...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5181, #subsample_inputs: 5181
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.766      |
| AbsLearnSignalNew       | 0.766      |
| AbsLearningOld          | 0.766      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 16.7641    |
| AveragePolicyStd        | 0.659121   |
| AverageReturn           | 1.38e+03   |
| Entropy                 | 2.93647    |
| EnvExecTime             | 2.15       |
| ExplainedVariance       | 0.904      |
| Iteration               | 550        |
| ItrTime                 | 8.47       |
| LossAfter               | 0.634577   |
| LossBefore              | 0.658687   |
| MaxReturn               | 2.24e+03   |
| MeanKL                  | 0.00983225 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 888        |
| NumTrajs                | 12         |
| Perplexity              | 18.8492    |
| PolicyExecTime          | 0.55       |
| ProcessExecTime         | 0.0625     |
| StdReturn               | 352        |
| Time                    | 4.56e+03   |
| dLoss                   | 0.0241107  |
----------------------------------------
itr #551 | 
Mem: 716.339844
Obtaining samples...
Obtaining samples for iteration 551...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5387, #subsample_inputs: 5387
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.798      |
| AbsLearnSignalNew       | 0.798      |
| AbsLearningOld          | 0.798      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 18.5432    |
| AveragePolicyStd        | 0.659646   |
| AverageReturn           | 1.3e+03    |
| Entropy                 | 2.94098    |
| EnvExecTime             | 2.16       |
| ExplainedVariance       | 0.893      |
| Iteration               | 551        |
| ItrTime                 | 8.67       |
| LossAfter               | -0.257755  |
| LossBefore              | -0.237416  |
| MaxReturn               | 1.82e+03   |
| MeanKL                  | 0.00641807 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 788        |
| NumTrajs                | 13         |
| Perplexity              | 18.9344    |
| PolicyExecTime          | 0.549      |
| ProcessExecTime         | 0.0617     |
| StdReturn               | 329        |
| Time                    | 4.57e+03   |
| dLoss                   | 0.020339   |
----------------------------------------
itr #552 | 
Mem: 716.339844
Obtaining samples...
Obtaining samples for iteration 552...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5046, #subsample_inputs: 5046
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.744      |
| AbsLearnSignalNew       | 0.744      |
| AbsLearningOld          | 0.744      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 18.4606    |
| AveragePolicyStd        | 0.65793    |
| AverageReturn           | 1.25e+03   |
| Entropy                 | 2.93151    |
| EnvExecTime             | 1.84       |
| ExplainedVariance       | 0.909      |
| Iteration               | 552        |
| ItrTime                 | 8.01       |
| LossAfter               | 0.440988   |
| LossBefore              | 0.464162   |
| MaxReturn               | 1.63e+03   |
| MeanKL                  | 0.00989057 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 837        |
| NumTrajs                | 13         |
| Perplexity              | 18.756     |
| PolicyExecTime          | 0.473      |
| ProcessExecTime         | 0.0545     |
| StdReturn               | 227        |
| Time                    | 4.58e+03   |
| dLoss                   | 0.0231745  |
----------------------------------------
itr #553 | 
Mem: 716.339844
Obtaining samples...
Obtaining samples for iteration 553...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5643, #subsample_inputs: 5643
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.698      |
| AbsLearnSignalNew       | 0.698      |
| AbsLearningOld          | 0.698      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 19.8692    |
| AveragePolicyStd        | 0.65939    |
| AverageReturn           | 1.59e+03   |
| Entropy                 | 2.94       |
| EnvExecTime             | 2.37       |
| ExplainedVariance       | 0.501      |
| Iteration               | 553        |
| ItrTime                 | 9.07       |
| LossAfter               | 1.02717    |
| LossBefore              | 1.05571    |
| MaxReturn               | 2.14e+03   |
| MeanKL                  | 0.00995685 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 927        |
| NumTrajs                | 11         |
| Perplexity              | 18.9158    |
| PolicyExecTime          | 0.59       |
| ProcessExecTime         | 0.0702     |
| StdReturn               | 434        |
| Time                    | 4.59e+03   |
| dLoss                   | 0.0285444  |
----------------------------------------
itr #554 | 
Mem: 716.347656
Obtaining samples...
Obtaining samples for iteration 554...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5115, #subsample_inputs: 5115
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.743      |
| AbsLearnSignalNew       | 0.743      |
| AbsLearningOld          | 0.743      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 17.3703    |
| AveragePolicyStd        | 0.663311   |
| AverageReturn           | 1.26e+03   |
| Entropy                 | 2.96056    |
| EnvExecTime             | 1.73       |
| ExplainedVariance       | 0.877      |
| Iteration               | 554        |
| ItrTime                 | 7.79       |
| LossAfter               | -0.118642  |
| LossBefore              | -0.0969264 |
| MaxReturn               | 1.71e+03   |
| MeanKL                  | 0.00642644 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 965        |
| NumTrajs                | 13         |
| Perplexity              | 19.3088    |
| PolicyExecTime          | 0.448      |
| ProcessExecTime         | 0.0527     |
| StdReturn               | 211        |
| Time                    | 4.59e+03   |
| dLoss                   | 0.0217154  |
----------------------------------------
itr #555 | 
Mem: 716.347656
Obtaining samples...
Obtaining samples for iteration 555...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5368, #subsample_inputs: 5368
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
-----------------------------------------
| AbsLearnSignal          | 0.754       |
| AbsLearnSignalNew       | 0.754       |
| AbsLearningOld          | 0.754       |
| AverageDiscountedReturn | 241         |
| AveragePhiLoss          | 18.1245     |
| AveragePolicyStd        | 0.663432    |
| AverageReturn           | 1.42e+03    |
| Entropy                 | 2.96186     |
| EnvExecTime             | 2.19        |
| ExplainedVariance       | 0.877       |
| Iteration               | 555         |
| ItrTime                 | 8.67        |
| LossAfter               | -0.00833436 |
| LossBefore              | 0.0102919   |
| MaxReturn               | 2.23e+03    |
| MeanKL                  | 0.00657246  |
| MeanKLBefore            | 0.0         |
| MinReturn               | 844         |
| NumTrajs                | 12          |
| Perplexity              | 19.334      |
| PolicyExecTime          | 0.548       |
| ProcessExecTime         | 0.0648      |
| StdReturn               | 367         |
| Time                    | 4.6e+03     |
| dLoss                   | 0.0186263   |
-----------------------------------------
itr #556 | 
Mem: 716.347656
Obtaining samples...
Obtaining samples for iteration 556...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5245, #subsample_inputs: 5245
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.77       |
| AbsLearnSignalNew       | 0.77       |
| AbsLearningOld          | 0.77       |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 18.37      |
| AveragePolicyStd        | 0.66179    |
| AverageReturn           | 1.14e+03   |
| Entropy                 | 2.95339    |
| EnvExecTime             | 1.8        |
| ExplainedVariance       | 0.921      |
| Iteration               | 556        |
| ItrTime                 | 8.02       |
| LossAfter               | 0.239884   |
| LossBefore              | 0.261798   |
| MaxReturn               | 1.5e+03    |
| MeanKL                  | 0.00993644 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 855        |
| NumTrajs                | 15         |
| Perplexity              | 19.1708    |
| PolicyExecTime          | 0.464      |
| ProcessExecTime         | 0.053      |
| StdReturn               | 167        |
| Time                    | 4.61e+03   |
| dLoss                   | 0.0219147  |
----------------------------------------
itr #557 | 
Mem: 717.378906
Obtaining samples...
Obtaining samples for iteration 557...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5245, #subsample_inputs: 5245
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.756      |
| AbsLearnSignalNew       | 0.756      |
| AbsLearningOld          | 0.756      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 18.9851    |
| AveragePolicyStd        | 0.659018   |
| AverageReturn           | 1.22e+03   |
| Entropy                 | 2.94063    |
| EnvExecTime             | 1.94       |
| ExplainedVariance       | 0.932      |
| Iteration               | 557        |
| ItrTime                 | 8.18       |
| LossAfter               | -0.242551  |
| LossBefore              | -0.21562   |
| MaxReturn               | 1.53e+03   |
| MeanKL                  | 0.00984672 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 989        |
| NumTrajs                | 14         |
| Perplexity              | 18.9278    |
| PolicyExecTime          | 0.487      |
| ProcessExecTime         | 0.0591     |
| StdReturn               | 152        |
| Time                    | 4.62e+03   |
| dLoss                   | 0.0269311  |
----------------------------------------
itr #558 | 
Mem: 717.378906
Obtaining samples...
Obtaining samples for iteration 558...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5047, #subsample_inputs: 5047
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.741      |
| AbsLearnSignalNew       | 0.741      |
| AbsLearningOld          | 0.741      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 18.1897    |
| AveragePolicyStd        | 0.661068   |
| AverageReturn           | 1.1e+03    |
| Entropy                 | 2.947      |
| EnvExecTime             | 1.72       |
| ExplainedVariance       | 0.924      |
| Iteration               | 558        |
| ItrTime                 | 7.74       |
| LossAfter               | -0.0340702 |
| LossBefore              | -0.015507  |
| MaxReturn               | 1.4e+03    |
| MeanKL                  | 0.00643394 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 838        |
| NumTrajs                | 15         |
| Perplexity              | 19.0487    |
| PolicyExecTime          | 0.441      |
| ProcessExecTime         | 0.0516     |
| StdReturn               | 124        |
| Time                    | 4.63e+03   |
| dLoss                   | 0.0185633  |
----------------------------------------
itr #559 | 
Mem: 717.378906
Obtaining samples...
Obtaining samples for iteration 559...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5172, #subsample_inputs: 5172
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.478     |
| AbsLearnSignalNew       | 0.478     |
| AbsLearningOld          | 0.478     |
| AverageDiscountedReturn | 243       |
| AveragePhiLoss          | 20.3712   |
| AveragePolicyStd        | 0.661231  |
| AverageReturn           | 1.27e+03  |
| Entropy                 | 2.94965   |
| EnvExecTime             | 1.77      |
| ExplainedVariance       | 0.348     |
| Iteration               | 559       |
| ItrTime                 | 7.97      |
| LossAfter               | -0.257134 |
| LossBefore              | -0.238929 |
| MaxReturn               | 2.03e+03  |
| MeanKL                  | 0.0065061 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 796       |
| NumTrajs                | 13        |
| Perplexity              | 19.0992   |
| PolicyExecTime          | 0.452     |
| ProcessExecTime         | 0.0547    |
| StdReturn               | 352       |
| Time                    | 4.63e+03  |
| dLoss                   | 0.018205  |
---------------------------------------
itr #560 | 
Mem: 717.378906
Obtaining samples...
Obtaining samples for iteration 560...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5036, #subsample_inputs: 5036
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.76       |
| AbsLearnSignalNew       | 0.76       |
| AbsLearningOld          | 0.76       |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 20.3919    |
| AveragePolicyStd        | 0.658513   |
| AverageReturn           | 1.34e+03   |
| Entropy                 | 2.93443    |
| EnvExecTime             | 2.02       |
| ExplainedVariance       | 0.895      |
| Iteration               | 560        |
| ItrTime                 | 8.22       |
| LossAfter               | 0.566303   |
| LossBefore              | 0.587535   |
| MaxReturn               | 1.84e+03   |
| MeanKL                  | 0.00640966 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 980        |
| NumTrajs                | 12         |
| Perplexity              | 18.8107    |
| PolicyExecTime          | 0.522      |
| ProcessExecTime         | 0.0575     |
| StdReturn               | 291        |
| Time                    | 4.64e+03   |
| dLoss                   | 0.0212322  |
----------------------------------------
itr #561 | 
Mem: 717.378906
Obtaining samples...
Obtaining samples for iteration 561...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5210, #subsample_inputs: 5210
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.773      |
| AbsLearnSignalNew       | 0.773      |
| AbsLearningOld          | 0.773      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 19.0225    |
| AveragePolicyStd        | 0.658042   |
| AverageReturn           | 1.06e+03   |
| Entropy                 | 2.93381    |
| EnvExecTime             | 2          |
| ExplainedVariance       | 0.913      |
| Iteration               | 561        |
| ItrTime                 | 8.31       |
| LossAfter               | -0.0172816 |
| LossBefore              | 0.00826666 |
| MaxReturn               | 1.55e+03   |
| MeanKL                  | 0.00994185 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 830        |
| NumTrajs                | 16         |
| Perplexity              | 18.7991    |
| PolicyExecTime          | 0.508      |
| ProcessExecTime         | 0.0582     |
| StdReturn               | 183        |
| Time                    | 4.65e+03   |
| dLoss                   | 0.0255483  |
----------------------------------------
itr #562 | 
Mem: 717.378906
Obtaining samples...
Obtaining samples for iteration 562...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5200, #subsample_inputs: 5200
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.758      |
| AbsLearnSignalNew       | 0.758      |
| AbsLearningOld          | 0.758      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 18.0869    |
| AveragePolicyStd        | 0.652818   |
| AverageReturn           | 1.06e+03   |
| Entropy                 | 2.9134     |
| EnvExecTime             | 1.72       |
| ExplainedVariance       | 0.932      |
| Iteration               | 562        |
| ItrTime                 | 7.91       |
| LossAfter               | 0.500104   |
| LossBefore              | 0.531317   |
| MaxReturn               | 1.47e+03   |
| MeanKL                  | 0.00978871 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 758        |
| NumTrajs                | 16         |
| Perplexity              | 18.4194    |
| PolicyExecTime          | 0.448      |
| ProcessExecTime         | 0.0524     |
| StdReturn               | 189        |
| Time                    | 4.66e+03   |
| dLoss                   | 0.0312129  |
----------------------------------------
itr #563 | 
Mem: 717.378906
Obtaining samples...
Obtaining samples for iteration 563...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5178, #subsample_inputs: 5178
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.785     |
| AbsLearnSignalNew       | 0.785     |
| AbsLearningOld          | 0.785     |
| AverageDiscountedReturn | 245       |
| AveragePhiLoss          | 18.8316   |
| AveragePolicyStd        | 0.653686  |
| AverageReturn           | 1e+03     |
| Entropy                 | 2.91832   |
| EnvExecTime             | 1.8       |
| ExplainedVariance       | 0.934     |
| Iteration               | 563       |
| ItrTime                 | 7.97      |
| LossAfter               | 1.03554   |
| LossBefore              | 1.06087   |
| MaxReturn               | 1.27e+03  |
| MeanKL                  | 0.0098479 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 758       |
| NumTrajs                | 17        |
| Perplexity              | 18.5102   |
| PolicyExecTime          | 0.457     |
| ProcessExecTime         | 0.0544    |
| StdReturn               | 156       |
| Time                    | 4.67e+03  |
| dLoss                   | 0.0253257 |
---------------------------------------
itr #564 | 
Mem: 717.378906
Obtaining samples...
Obtaining samples for iteration 564...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5081, #subsample_inputs: 5081
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.743      |
| AbsLearnSignalNew       | 0.743      |
| AbsLearningOld          | 0.743      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 20.3981    |
| AveragePolicyStd        | 0.652245   |
| AverageReturn           | 1.05e+03   |
| Entropy                 | 2.91178    |
| EnvExecTime             | 1.89       |
| ExplainedVariance       | 0.91       |
| Iteration               | 564        |
| ItrTime                 | 7.98       |
| LossAfter               | 1.25559    |
| LossBefore              | 1.28278    |
| MaxReturn               | 1.56e+03   |
| MeanKL                  | 0.00989709 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 788        |
| NumTrajs                | 16         |
| Perplexity              | 18.3895    |
| PolicyExecTime          | 0.486      |
| ProcessExecTime         | 0.0546     |
| StdReturn               | 243        |
| Time                    | 4.67e+03   |
| dLoss                   | 0.0271883  |
----------------------------------------
itr #565 | 
Mem: 717.378906
Obtaining samples...
Obtaining samples for iteration 565...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5130, #subsample_inputs: 5130
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.791      |
| AbsLearnSignalNew       | 0.791      |
| AbsLearningOld          | 0.791      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 18.4548    |
| AveragePolicyStd        | 0.650256   |
| AverageReturn           | 989        |
| Entropy                 | 2.90192    |
| EnvExecTime             | 1.94       |
| ExplainedVariance       | 0.934      |
| Iteration               | 565        |
| ItrTime                 | 8.11       |
| LossAfter               | 0.725583   |
| LossBefore              | 0.748443   |
| MaxReturn               | 1.3e+03    |
| MeanKL                  | 0.00646048 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 747        |
| NumTrajs                | 17         |
| Perplexity              | 18.2091    |
| PolicyExecTime          | 0.492      |
| ProcessExecTime         | 0.0582     |
| StdReturn               | 187        |
| Time                    | 4.68e+03   |
| dLoss                   | 0.0228606  |
----------------------------------------
itr #566 | 
Mem: 717.378906
Obtaining samples...
Obtaining samples for iteration 566...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5148, #subsample_inputs: 5148
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.769      |
| AbsLearnSignalNew       | 0.769      |
| AbsLearningOld          | 0.769      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 18.6264    |
| AveragePolicyStd        | 0.649303   |
| AverageReturn           | 946        |
| Entropy                 | 2.89845    |
| EnvExecTime             | 1.94       |
| ExplainedVariance       | 0.937      |
| Iteration               | 566        |
| ItrTime                 | 8.11       |
| LossAfter               | 0.41078    |
| LossBefore              | 0.436944   |
| MaxReturn               | 1.2e+03    |
| MeanKL                  | 0.00978149 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 748        |
| NumTrajs                | 18         |
| Perplexity              | 18.1461    |
| PolicyExecTime          | 0.488      |
| ProcessExecTime         | 0.0578     |
| StdReturn               | 143        |
| Time                    | 4.69e+03   |
| dLoss                   | 0.0261635  |
----------------------------------------
itr #567 | 
Mem: 717.378906
Obtaining samples...
Obtaining samples for iteration 567...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5250, #subsample_inputs: 5250
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.761      |
| AbsLearnSignalNew       | 0.761      |
| AbsLearningOld          | 0.761      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 17.3361    |
| AveragePolicyStd        | 0.652047   |
| AverageReturn           | 1.08e+03   |
| Entropy                 | 2.90977    |
| EnvExecTime             | 1.95       |
| ExplainedVariance       | 0.931      |
| Iteration               | 567        |
| ItrTime                 | 8.19       |
| LossAfter               | 0.244707   |
| LossBefore              | 0.269666   |
| MaxReturn               | 1.34e+03   |
| MeanKL                  | 0.00980216 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 824        |
| NumTrajs                | 16         |
| Perplexity              | 18.3525    |
| PolicyExecTime          | 0.5        |
| ProcessExecTime         | 0.0598     |
| StdReturn               | 109        |
| Time                    | 4.7e+03    |
| dLoss                   | 0.0249597  |
----------------------------------------
itr #568 | 
Mem: 717.378906
Obtaining samples...
Obtaining samples for iteration 568...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5516, #subsample_inputs: 5516
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.611      |
| AbsLearnSignalNew       | 0.611      |
| AbsLearningOld          | 0.611      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 17.8545    |
| AveragePolicyStd        | 0.653251   |
| AverageReturn           | 1.19e+03   |
| Entropy                 | 2.91485    |
| EnvExecTime             | 1.93       |
| ExplainedVariance       | 0.788      |
| Iteration               | 568        |
| ItrTime                 | 8.44       |
| LossAfter               | 0.446422   |
| LossBefore              | 0.467771   |
| MaxReturn               | 1.78e+03   |
| MeanKL                  | 0.00642142 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 917        |
| NumTrajs                | 15         |
| Perplexity              | 18.4461    |
| PolicyExecTime          | 0.489      |
| ProcessExecTime         | 0.0593     |
| StdReturn               | 240        |
| Time                    | 4.71e+03   |
| dLoss                   | 0.021349   |
----------------------------------------
itr #569 | 
Mem: 717.378906
Obtaining samples...
Obtaining samples for iteration 569...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5229, #subsample_inputs: 5229
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.771      |
| AbsLearnSignalNew       | 0.771      |
| AbsLearningOld          | 0.771      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 18.9607    |
| AveragePolicyStd        | 0.653138   |
| AverageReturn           | 1e+03      |
| Entropy                 | 2.91349    |
| EnvExecTime             | 1.87       |
| ExplainedVariance       | 0.939      |
| Iteration               | 569        |
| ItrTime                 | 8.15       |
| LossAfter               | -0.418297  |
| LossBefore              | -0.389362  |
| MaxReturn               | 1.28e+03   |
| MeanKL                  | 0.00999635 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 783        |
| NumTrajs                | 17         |
| Perplexity              | 18.421     |
| PolicyExecTime          | 0.476      |
| ProcessExecTime         | 0.0569     |
| StdReturn               | 121        |
| Time                    | 4.72e+03   |
| dLoss                   | 0.0289353  |
----------------------------------------
itr #570 | 
Mem: 717.378906
Obtaining samples...
Obtaining samples for iteration 570...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5151, #subsample_inputs: 5151
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.746      |
| AbsLearnSignalNew       | 0.746      |
| AbsLearningOld          | 0.747      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 19.0662    |
| AveragePolicyStd        | 0.651057   |
| AverageReturn           | 1.05e+03   |
| Entropy                 | 2.90298    |
| EnvExecTime             | 1.9        |
| ExplainedVariance       | 0.93       |
| Iteration               | 570        |
| ItrTime                 | 8.02       |
| LossAfter               | 0.0902519  |
| LossBefore              | 0.117391   |
| MaxReturn               | 1.63e+03   |
| MeanKL                  | 0.00965004 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 741        |
| NumTrajs                | 16         |
| Perplexity              | 18.2283    |
| PolicyExecTime          | 0.484      |
| ProcessExecTime         | 0.0555     |
| StdReturn               | 211        |
| Time                    | 4.72e+03   |
| dLoss                   | 0.0271387  |
----------------------------------------
itr #571 | 
Mem: 717.378906
Obtaining samples...
Obtaining samples for iteration 571...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5121, #subsample_inputs: 5121
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.777      |
| AbsLearnSignalNew       | 0.777      |
| AbsLearningOld          | 0.777      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 18.0193    |
| AveragePolicyStd        | 0.653702   |
| AverageReturn           | 1.11e+03   |
| Entropy                 | 2.91705    |
| EnvExecTime             | 1.64       |
| ExplainedVariance       | 0.936      |
| Iteration               | 571        |
| ItrTime                 | 7.77       |
| LossAfter               | 0.945805   |
| LossBefore              | 0.973967   |
| MaxReturn               | 1.44e+03   |
| MeanKL                  | 0.00993675 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 743        |
| NumTrajs                | 15         |
| Perplexity              | 18.4867    |
| PolicyExecTime          | 0.426      |
| ProcessExecTime         | 0.0507     |
| StdReturn               | 154        |
| Time                    | 4.73e+03   |
| dLoss                   | 0.0281628  |
----------------------------------------
itr #572 | 
Mem: 717.378906
Obtaining samples...
Obtaining samples for iteration 572...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5197, #subsample_inputs: 5197
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.773      |
| AbsLearnSignalNew       | 0.773      |
| AbsLearningOld          | 0.773      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 18.3589    |
| AveragePolicyStd        | 0.654038   |
| AverageReturn           | 1.12e+03   |
| Entropy                 | 2.91694    |
| EnvExecTime             | 1.71       |
| ExplainedVariance       | 0.937      |
| Iteration               | 572        |
| ItrTime                 | 7.88       |
| LossAfter               | -0.0665983 |
| LossBefore              | -0.044777  |
| MaxReturn               | 1.61e+03   |
| MeanKL                  | 0.00652285 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 840        |
| NumTrajs                | 15         |
| Perplexity              | 18.4847    |
| PolicyExecTime          | 0.441      |
| ProcessExecTime         | 0.0527     |
| StdReturn               | 179        |
| Time                    | 4.74e+03   |
| dLoss                   | 0.0218213  |
----------------------------------------
itr #573 | 
Mem: 717.378906
Obtaining samples...
Obtaining samples for iteration 573...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5159, #subsample_inputs: 5159
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.786      |
| AbsLearnSignalNew       | 0.786      |
| AbsLearningOld          | 0.786      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 19.3627    |
| AveragePolicyStd        | 0.653476   |
| AverageReturn           | 1.11e+03   |
| Entropy                 | 2.91543    |
| EnvExecTime             | 1.88       |
| ExplainedVariance       | 0.935      |
| Iteration               | 573        |
| ItrTime                 | 8.05       |
| LossAfter               | 0.738295   |
| LossBefore              | 0.766661   |
| MaxReturn               | 1.45e+03   |
| MeanKL                  | 0.00964167 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 844        |
| NumTrajs                | 15         |
| Perplexity              | 18.4567    |
| PolicyExecTime          | 0.478      |
| ProcessExecTime         | 0.0563     |
| StdReturn               | 172        |
| Time                    | 4.75e+03   |
| dLoss                   | 0.028366   |
----------------------------------------
itr #574 | 
Mem: 717.378906
Obtaining samples...
Obtaining samples for iteration 574...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5128, #subsample_inputs: 5128
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.762      |
| AbsLearnSignalNew       | 0.762      |
| AbsLearningOld          | 0.762      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 18.5789    |
| AveragePolicyStd        | 0.654712   |
| AverageReturn           | 1.18e+03   |
| Entropy                 | 2.92492    |
| EnvExecTime             | 1.86       |
| ExplainedVariance       | 0.924      |
| Iteration               | 574        |
| ItrTime                 | 7.99       |
| LossAfter               | 0.36451    |
| LossBefore              | 0.38767    |
| MaxReturn               | 1.61e+03   |
| MeanKL                  | 0.00648698 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 945        |
| NumTrajs                | 14         |
| Perplexity              | 18.6327    |
| PolicyExecTime          | 0.476      |
| ProcessExecTime         | 0.0557     |
| StdReturn               | 197        |
| Time                    | 4.76e+03   |
| dLoss                   | 0.0231599  |
----------------------------------------
itr #575 | 
Mem: 717.378906
Obtaining samples...
Obtaining samples for iteration 575...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5004, #subsample_inputs: 5004
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.775     |
| AbsLearnSignalNew       | 0.775     |
| AbsLearningOld          | 0.775     |
| AverageDiscountedReturn | 244       |
| AveragePhiLoss          | 18.8031   |
| AveragePolicyStd        | 0.653483  |
| AverageReturn           | 1.16e+03  |
| Entropy                 | 2.91928   |
| EnvExecTime             | 1.75      |
| ExplainedVariance       | 0.922     |
| Iteration               | 575       |
| ItrTime                 | 7.73      |
| LossAfter               | 0.700139  |
| LossBefore              | 0.725069  |
| MaxReturn               | 1.6e+03   |
| MeanKL                  | 0.0098244 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 845       |
| NumTrajs                | 14        |
| Perplexity              | 18.5279   |
| PolicyExecTime          | 0.448     |
| ProcessExecTime         | 0.0527    |
| StdReturn               | 250       |
| Time                    | 4.76e+03  |
| dLoss                   | 0.0249304 |
---------------------------------------
itr #576 | 
Mem: 717.378906
Obtaining samples...
Obtaining samples for iteration 576...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5053, #subsample_inputs: 5053
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.736      |
| AbsLearnSignalNew       | 0.736      |
| AbsLearningOld          | 0.736      |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 18.5039    |
| AveragePolicyStd        | 0.654383   |
| AverageReturn           | 1.43e+03   |
| Entropy                 | 2.92345    |
| EnvExecTime             | 2.01       |
| ExplainedVariance       | 0.746      |
| Iteration               | 576        |
| ItrTime                 | 8.14       |
| LossAfter               | 0.384356   |
| LossBefore              | 0.406452   |
| MaxReturn               | 2.31e+03   |
| MeanKL                  | 0.00651447 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 837        |
| NumTrajs                | 11         |
| Perplexity              | 18.6053    |
| PolicyExecTime          | 0.511      |
| ProcessExecTime         | 0.0607     |
| StdReturn               | 450        |
| Time                    | 4.77e+03   |
| dLoss                   | 0.0220956  |
----------------------------------------
itr #577 | 
Mem: 717.378906
Obtaining samples...
Obtaining samples for iteration 577...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5521, #subsample_inputs: 5521
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.767      |
| AbsLearnSignalNew       | 0.767      |
| AbsLearningOld          | 0.767      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 23.1204    |
| AveragePolicyStd        | 0.654068   |
| AverageReturn           | 1.57e+03   |
| Entropy                 | 2.92294    |
| EnvExecTime             | 1.94       |
| ExplainedVariance       | 0.89       |
| Iteration               | 577        |
| ItrTime                 | 8.34       |
| LossAfter               | -0.140754  |
| LossBefore              | -0.119169  |
| MaxReturn               | 2.14e+03   |
| MeanKL                  | 0.00645874 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.09e+03   |
| NumTrajs                | 11         |
| Perplexity              | 18.5959    |
| PolicyExecTime          | 0.499      |
| ProcessExecTime         | 0.0588     |
| StdReturn               | 327        |
| Time                    | 4.78e+03   |
| dLoss                   | 0.0215853  |
----------------------------------------
itr #578 | 
Mem: 717.378906
Obtaining samples...
Obtaining samples for iteration 578...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5286, #subsample_inputs: 5286
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.747      |
| AbsLearnSignalNew       | 0.747      |
| AbsLearningOld          | 0.747      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 19.1121    |
| AveragePolicyStd        | 0.652897   |
| AverageReturn           | 1.29e+03   |
| Entropy                 | 2.91869    |
| EnvExecTime             | 1.81       |
| ExplainedVariance       | 0.898      |
| Iteration               | 578        |
| ItrTime                 | 8.09       |
| LossAfter               | -0.260281  |
| LossBefore              | -0.229639  |
| MaxReturn               | 1.96e+03   |
| MeanKL                  | 0.00999463 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 919        |
| NumTrajs                | 13         |
| Perplexity              | 18.517     |
| PolicyExecTime          | 0.466      |
| ProcessExecTime         | 0.0558     |
| StdReturn               | 280        |
| Time                    | 4.79e+03   |
| dLoss                   | 0.0306422  |
----------------------------------------
itr #579 | 
Mem: 717.378906
Obtaining samples...
Obtaining samples for iteration 579...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5397, #subsample_inputs: 5397
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.78       |
| AbsLearnSignalNew       | 0.78       |
| AbsLearningOld          | 0.78       |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 17.3915    |
| AveragePolicyStd        | 0.65405    |
| AverageReturn           | 1.24e+03   |
| Entropy                 | 2.92459    |
| EnvExecTime             | 2.25       |
| ExplainedVariance       | 0.922      |
| Iteration               | 579        |
| ItrTime                 | 8.81       |
| LossAfter               | -0.0606397 |
| LossBefore              | -0.0385128 |
| MaxReturn               | 1.57e+03   |
| MeanKL                  | 0.00998479 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1e+03      |
| NumTrajs                | 14         |
| Perplexity              | 18.6267    |
| PolicyExecTime          | 0.566      |
| ProcessExecTime         | 0.0652     |
| StdReturn               | 171        |
| Time                    | 4.8e+03    |
| dLoss                   | 0.0221268  |
----------------------------------------
itr #580 | 
Mem: 717.378906
Obtaining samples...
Obtaining samples for iteration 580...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5155, #subsample_inputs: 5155
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.762      |
| AbsLearnSignalNew       | 0.762      |
| AbsLearningOld          | 0.762      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 18.4366    |
| AveragePolicyStd        | 0.654952   |
| AverageReturn           | 1.05e+03   |
| Entropy                 | 2.92825    |
| EnvExecTime             | 1.91       |
| ExplainedVariance       | 0.923      |
| Iteration               | 580        |
| ItrTime                 | 8.15       |
| LossAfter               | -0.199333  |
| LossBefore              | -0.173245  |
| MaxReturn               | 1.26e+03   |
| MeanKL                  | 0.00640477 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 905        |
| NumTrajs                | 16         |
| Perplexity              | 18.6948    |
| PolicyExecTime          | 0.493      |
| ProcessExecTime         | 0.0584     |
| StdReturn               | 79.6       |
| Time                    | 4.81e+03   |
| dLoss                   | 0.0260885  |
----------------------------------------
itr #581 | 
Mem: 717.378906
Obtaining samples...
Obtaining samples for iteration 581...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5338, #subsample_inputs: 5338
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.342      |
| AbsLearnSignalNew       | 0.342      |
| AbsLearningOld          | 0.342      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 17.5761    |
| AveragePolicyStd        | 0.653365   |
| AverageReturn           | 1.4e+03    |
| Entropy                 | 2.92392    |
| EnvExecTime             | 1.87       |
| ExplainedVariance       | -7.22      |
| Iteration               | 581        |
| ItrTime                 | 8.26       |
| LossAfter               | 0.503246   |
| LossBefore              | 0.525533   |
| MaxReturn               | 2.34e+03   |
| MeanKL                  | 0.00649441 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.06e+03   |
| NumTrajs                | 12         |
| Perplexity              | 18.6141    |
| PolicyExecTime          | 0.486      |
| ProcessExecTime         | 0.0561     |
| StdReturn               | 440        |
| Time                    | 4.81e+03   |
| dLoss                   | 0.0222865  |
----------------------------------------
itr #582 | 
Mem: 717.378906
Obtaining samples...
Obtaining samples for iteration 582...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5095, #subsample_inputs: 5095
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.761      |
| AbsLearnSignalNew       | 0.761      |
| AbsLearningOld          | 0.761      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 17.5953    |
| AveragePolicyStd        | 0.65403    |
| AverageReturn           | 1.25e+03   |
| Entropy                 | 2.92755    |
| EnvExecTime             | 1.83       |
| ExplainedVariance       | 0.905      |
| Iteration               | 582        |
| ItrTime                 | 7.93       |
| LossAfter               | -0.129322  |
| LossBefore              | -0.10538   |
| MaxReturn               | 1.8e+03    |
| MeanKL                  | 0.00646642 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 986        |
| NumTrajs                | 13         |
| Perplexity              | 18.6817    |
| PolicyExecTime          | 0.469      |
| ProcessExecTime         | 0.0546     |
| StdReturn               | 219        |
| Time                    | 4.82e+03   |
| dLoss                   | 0.0239418  |
----------------------------------------
itr #583 | 
Mem: 717.378906
Obtaining samples...
Obtaining samples for iteration 583...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5261, #subsample_inputs: 5261
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.758      |
| AbsLearnSignalNew       | 0.758      |
| AbsLearningOld          | 0.758      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 16.3988    |
| AveragePolicyStd        | 0.650779   |
| AverageReturn           | 1.5e+03    |
| Entropy                 | 2.91531    |
| EnvExecTime             | 1.88       |
| ExplainedVariance       | 0.835      |
| Iteration               | 583        |
| ItrTime                 | 8.15       |
| LossAfter               | -0.340707  |
| LossBefore              | -0.321231  |
| MaxReturn               | 2.44e+03   |
| MeanKL                  | 0.00648169 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 896        |
| NumTrajs                | 11         |
| Perplexity              | 18.4545    |
| PolicyExecTime          | 0.487      |
| ProcessExecTime         | 0.0568     |
| StdReturn               | 424        |
| Time                    | 4.83e+03   |
| dLoss                   | 0.0194766  |
----------------------------------------
itr #584 | 
Mem: 717.378906
Obtaining samples...
Obtaining samples for iteration 584...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5309, #subsample_inputs: 5309
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.767      |
| AbsLearnSignalNew       | 0.767      |
| AbsLearningOld          | 0.767      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 18.4385    |
| AveragePolicyStd        | 0.648666   |
| AverageReturn           | 1.21e+03   |
| Entropy                 | 2.90589    |
| EnvExecTime             | 1.87       |
| ExplainedVariance       | 0.905      |
| Iteration               | 584        |
| ItrTime                 | 8.21       |
| LossAfter               | -0.399949  |
| LossBefore              | -0.38059   |
| MaxReturn               | 1.57e+03   |
| MeanKL                  | 0.00649249 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 866        |
| NumTrajs                | 14         |
| Perplexity              | 18.2816    |
| PolicyExecTime          | 0.483      |
| ProcessExecTime         | 0.0555     |
| StdReturn               | 252        |
| Time                    | 4.84e+03   |
| dLoss                   | 0.019359   |
----------------------------------------
itr #585 | 
Mem: 717.378906
Obtaining samples...
Obtaining samples for iteration 585...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5259, #subsample_inputs: 5259
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.796      |
| AbsLearnSignalNew       | 0.796      |
| AbsLearningOld          | 0.796      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 18.9024    |
| AveragePolicyStd        | 0.646967   |
| AverageReturn           | 1.14e+03   |
| Entropy                 | 2.89722    |
| EnvExecTime             | 1.87       |
| ExplainedVariance       | 0.914      |
| Iteration               | 585        |
| ItrTime                 | 8.08       |
| LossAfter               | 0.244111   |
| LossBefore              | 0.262591   |
| MaxReturn               | 1.39e+03   |
| MeanKL                  | 0.00654633 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 881        |
| NumTrajs                | 15         |
| Perplexity              | 18.1237    |
| PolicyExecTime          | 0.471      |
| ProcessExecTime         | 0.0557     |
| StdReturn               | 182        |
| Time                    | 4.85e+03   |
| dLoss                   | 0.0184807  |
----------------------------------------
itr #586 | 
Mem: 717.378906
Obtaining samples...
Obtaining samples for iteration 586...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5181, #subsample_inputs: 5181
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.74       |
| AbsLearnSignalNew       | 0.74       |
| AbsLearningOld          | 0.74       |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 18.3907    |
| AveragePolicyStd        | 0.645051   |
| AverageReturn           | 1.19e+03   |
| Entropy                 | 2.88641    |
| EnvExecTime             | 1.88       |
| ExplainedVariance       | 0.88       |
| Iteration               | 586        |
| ItrTime                 | 8.04       |
| LossAfter               | -0.233903  |
| LossBefore              | -0.212977  |
| MaxReturn               | 1.59e+03   |
| MeanKL                  | 0.00641804 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 850        |
| NumTrajs                | 14         |
| Perplexity              | 17.9288    |
| PolicyExecTime          | 0.474      |
| ProcessExecTime         | 0.0576     |
| StdReturn               | 213        |
| Time                    | 4.85e+03   |
| dLoss                   | 0.0209254  |
----------------------------------------
itr #587 | 
Mem: 717.378906
Obtaining samples...
Obtaining samples for iteration 587...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5113, #subsample_inputs: 5113
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.78       |
| AbsLearnSignalNew       | 0.78       |
| AbsLearningOld          | 0.78       |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 18.3933    |
| AveragePolicyStd        | 0.645388   |
| AverageReturn           | 1.31e+03   |
| Entropy                 | 2.88813    |
| EnvExecTime             | 1.77       |
| ExplainedVariance       | 0.845      |
| Iteration               | 587        |
| ItrTime                 | 7.84       |
| LossAfter               | 0.760469   |
| LossBefore              | 0.784577   |
| MaxReturn               | 1.75e+03   |
| MeanKL                  | 0.00999128 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.03e+03   |
| NumTrajs                | 12         |
| Perplexity              | 17.9597    |
| PolicyExecTime          | 0.458      |
| ProcessExecTime         | 0.0524     |
| StdReturn               | 246        |
| Time                    | 4.86e+03   |
| dLoss                   | 0.0241086  |
----------------------------------------
itr #588 | 
Mem: 717.378906
Obtaining samples...
Obtaining samples for iteration 588...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5129, #subsample_inputs: 5129
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.788      |
| AbsLearnSignalNew       | 0.788      |
| AbsLearningOld          | 0.788      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 17.4239    |
| AveragePolicyStd        | 0.6447     |
| AverageReturn           | 1.09e+03   |
| Entropy                 | 2.88867    |
| EnvExecTime             | 1.99       |
| ExplainedVariance       | 0.9        |
| Iteration               | 588        |
| ItrTime                 | 8.17       |
| LossAfter               | 0.00312525 |
| LossBefore              | 0.0244417  |
| MaxReturn               | 1.79e+03   |
| MeanKL                  | 0.00646654 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 781        |
| NumTrajs                | 15         |
| Perplexity              | 17.9694    |
| PolicyExecTime          | 0.51       |
| ProcessExecTime         | 0.0576     |
| StdReturn               | 211        |
| Time                    | 4.87e+03   |
| dLoss                   | 0.0213165  |
----------------------------------------
itr #589 | 
Mem: 717.378906
Obtaining samples...
Obtaining samples for iteration 589...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5345, #subsample_inputs: 5345
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.754      |
| AbsLearnSignalNew       | 0.754      |
| AbsLearningOld          | 0.754      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 18.3936    |
| AveragePolicyStd        | 0.644538   |
| AverageReturn           | 1.31e+03   |
| Entropy                 | 2.88845    |
| EnvExecTime             | 1.97       |
| ExplainedVariance       | 0.902      |
| Iteration               | 589        |
| ItrTime                 | 8.35       |
| LossAfter               | -0.222189  |
| LossBefore              | -0.198767  |
| MaxReturn               | 2.32e+03   |
| MeanKL                  | 0.00981226 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.04e+03   |
| NumTrajs                | 13         |
| Perplexity              | 17.9654    |
| PolicyExecTime          | 0.498      |
| ProcessExecTime         | 0.0589     |
| StdReturn               | 347        |
| Time                    | 4.88e+03   |
| dLoss                   | 0.0234224  |
----------------------------------------
itr #590 | 
Mem: 717.378906
Obtaining samples...
Obtaining samples for iteration 590...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5180, #subsample_inputs: 5180
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.79       |
| AbsLearnSignalNew       | 0.79       |
| AbsLearningOld          | 0.79       |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 19.6829    |
| AveragePolicyStd        | 0.646164   |
| AverageReturn           | 1.2e+03    |
| Entropy                 | 2.89789    |
| EnvExecTime             | 1.72       |
| ExplainedVariance       | 0.925      |
| Iteration               | 590        |
| ItrTime                 | 7.88       |
| LossAfter               | 0.220549   |
| LossBefore              | 0.245322   |
| MaxReturn               | 1.81e+03   |
| MeanKL                  | 0.00996693 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 852        |
| NumTrajs                | 14         |
| Perplexity              | 18.1359    |
| PolicyExecTime          | 0.443      |
| ProcessExecTime         | 0.0527     |
| StdReturn               | 243        |
| Time                    | 4.89e+03   |
| dLoss                   | 0.0247727  |
----------------------------------------
itr #591 | 
Mem: 717.378906
Obtaining samples...
Obtaining samples for iteration 591...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5254, #subsample_inputs: 5254
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.793      |
| AbsLearnSignalNew       | 0.793      |
| AbsLearningOld          | 0.793      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 18.1069    |
| AveragePolicyStd        | 0.647655   |
| AverageReturn           | 1.29e+03   |
| Entropy                 | 2.90749    |
| EnvExecTime             | 1.94       |
| ExplainedVariance       | 0.904      |
| Iteration               | 591        |
| ItrTime                 | 8.22       |
| LossAfter               | -0.923096  |
| LossBefore              | -0.896847  |
| MaxReturn               | 1.75e+03   |
| MeanKL                  | 0.00982601 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.03e+03   |
| NumTrajs                | 13         |
| Perplexity              | 18.3108    |
| PolicyExecTime          | 0.492      |
| ProcessExecTime         | 0.0579     |
| StdReturn               | 247        |
| Time                    | 4.9e+03    |
| dLoss                   | 0.0262488  |
----------------------------------------
itr #592 | 
Mem: 717.378906
Obtaining samples...
Obtaining samples for iteration 592...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5104, #subsample_inputs: 5104
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.753      |
| AbsLearnSignalNew       | 0.753      |
| AbsLearningOld          | 0.753      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 19.0076    |
| AveragePolicyStd        | 0.647053   |
| AverageReturn           | 1.35e+03   |
| Entropy                 | 2.90347    |
| EnvExecTime             | 2.14       |
| ExplainedVariance       | 0.913      |
| Iteration               | 592        |
| ItrTime                 | 8.41       |
| LossAfter               | 1.41242    |
| LossBefore              | 1.43941    |
| MaxReturn               | 2.05e+03   |
| MeanKL                  | 0.00986626 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 944        |
| NumTrajs                | 12         |
| Perplexity              | 18.2374    |
| PolicyExecTime          | 0.531      |
| ProcessExecTime         | 0.0652     |
| StdReturn               | 334        |
| Time                    | 4.9e+03    |
| dLoss                   | 0.026985   |
----------------------------------------
itr #593 | 
Mem: 717.378906
Obtaining samples...
Obtaining samples for iteration 593...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5047, #subsample_inputs: 5047
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.761      |
| AbsLearnSignalNew       | 0.761      |
| AbsLearningOld          | 0.761      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 17.7572    |
| AveragePolicyStd        | 0.647674   |
| AverageReturn           | 1.41e+03   |
| Entropy                 | 2.90437    |
| EnvExecTime             | 2.1        |
| ExplainedVariance       | 0.882      |
| Iteration               | 593        |
| ItrTime                 | 8.19       |
| LossAfter               | 0.693547   |
| LossBefore              | 0.713958   |
| MaxReturn               | 2.64e+03   |
| MeanKL                  | 0.00648491 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1e+03      |
| NumTrajs                | 11         |
| Perplexity              | 18.2537    |
| PolicyExecTime          | 0.535      |
| ProcessExecTime         | 0.0594     |
| StdReturn               | 465        |
| Time                    | 4.91e+03   |
| dLoss                   | 0.0204108  |
----------------------------------------
itr #594 | 
Mem: 717.382812
Obtaining samples...
Obtaining samples for iteration 594...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5156, #subsample_inputs: 5156
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.792      |
| AbsLearnSignalNew       | 0.792      |
| AbsLearningOld          | 0.792      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 17.8198    |
| AveragePolicyStd        | 0.645      |
| AverageReturn           | 1.43e+03   |
| Entropy                 | 2.88928    |
| EnvExecTime             | 2.04       |
| ExplainedVariance       | 0.821      |
| Iteration               | 594        |
| ItrTime                 | 8.23       |
| LossAfter               | -0.797967  |
| LossBefore              | -0.769661  |
| MaxReturn               | 2.64e+03   |
| MeanKL                  | 0.00995423 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 866        |
| NumTrajs                | 11         |
| Perplexity              | 17.9803    |
| PolicyExecTime          | 0.513      |
| ProcessExecTime         | 0.0601     |
| StdReturn               | 496        |
| Time                    | 4.92e+03   |
| dLoss                   | 0.0283064  |
----------------------------------------
itr #595 | 
Mem: 717.382812
Obtaining samples...
Obtaining samples for iteration 595...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5343, #subsample_inputs: 5343
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.763      |
| AbsLearnSignalNew       | 0.763      |
| AbsLearningOld          | 0.763      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 19.1842    |
| AveragePolicyStd        | 0.642228   |
| AverageReturn           | 1.14e+03   |
| Entropy                 | 2.87654    |
| EnvExecTime             | 1.98       |
| ExplainedVariance       | 0.892      |
| Iteration               | 595        |
| ItrTime                 | 8.39       |
| LossAfter               | -1.63642   |
| LossBefore              | -1.61518   |
| MaxReturn               | 1.58e+03   |
| MeanKL                  | 0.00994948 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 852        |
| NumTrajs                | 15         |
| Perplexity              | 17.7528    |
| PolicyExecTime          | 0.508      |
| ProcessExecTime         | 0.0577     |
| StdReturn               | 181        |
| Time                    | 4.93e+03   |
| dLoss                   | 0.0212407  |
----------------------------------------
itr #596 | 
Mem: 717.382812
Obtaining samples...
Obtaining samples for iteration 596...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5256, #subsample_inputs: 5256
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.755     |
| AbsLearnSignalNew       | 0.755     |
| AbsLearningOld          | 0.755     |
| AverageDiscountedReturn | 244       |
| AveragePhiLoss          | 18.1279   |
| AveragePolicyStd        | 0.642504  |
| AverageReturn           | 1.14e+03  |
| Entropy                 | 2.8755    |
| EnvExecTime             | 1.83      |
| ExplainedVariance       | 0.925     |
| Iteration               | 596       |
| ItrTime                 | 8.07      |
| LossAfter               | -0.149547 |
| LossBefore              | -0.127687 |
| MaxReturn               | 1.62e+03  |
| MeanKL                  | 0.0065269 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 852       |
| NumTrajs                | 15        |
| Perplexity              | 17.7344   |
| PolicyExecTime          | 0.469     |
| ProcessExecTime         | 0.0552    |
| StdReturn               | 188       |
| Time                    | 4.94e+03  |
| dLoss                   | 0.0218602 |
---------------------------------------
itr #597 | 
Mem: 717.382812
Obtaining samples...
Obtaining samples for iteration 597...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5039, #subsample_inputs: 5039
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.775      |
| AbsLearnSignalNew       | 0.775      |
| AbsLearningOld          | 0.775      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 19.1393    |
| AveragePolicyStd        | 0.641006   |
| AverageReturn           | 1.44e+03   |
| Entropy                 | 2.8676     |
| EnvExecTime             | 1.74       |
| ExplainedVariance       | 0.809      |
| Iteration               | 597        |
| ItrTime                 | 7.79       |
| LossAfter               | 0.1373     |
| LossBefore              | 0.158366   |
| MaxReturn               | 2.82e+03   |
| MeanKL                  | 0.00646248 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 978        |
| NumTrajs                | 11         |
| Perplexity              | 17.5948    |
| PolicyExecTime          | 0.452      |
| ProcessExecTime         | 0.0526     |
| StdReturn               | 495        |
| Time                    | 4.94e+03   |
| dLoss                   | 0.0210667  |
----------------------------------------
itr #598 | 
Mem: 717.382812
Obtaining samples...
Obtaining samples for iteration 598...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5111, #subsample_inputs: 5111
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.783      |
| AbsLearnSignalNew       | 0.783      |
| AbsLearningOld          | 0.783      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 18.9321    |
| AveragePolicyStd        | 0.641214   |
| AverageReturn           | 1.17e+03   |
| Entropy                 | 2.86813    |
| EnvExecTime             | 1.8        |
| ExplainedVariance       | 0.9        |
| Iteration               | 598        |
| ItrTime                 | 7.9        |
| LossAfter               | -1.04247   |
| LossBefore              | -1.01771   |
| MaxReturn               | 1.58e+03   |
| MeanKL                  | 0.00986816 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 815        |
| NumTrajs                | 14         |
| Perplexity              | 17.6041    |
| PolicyExecTime          | 0.464      |
| ProcessExecTime         | 0.0537     |
| StdReturn               | 179        |
| Time                    | 4.95e+03   |
| dLoss                   | 0.0247673  |
----------------------------------------
itr #599 | 
Mem: 717.382812
Obtaining samples...
Obtaining samples for iteration 599...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5195, #subsample_inputs: 5195
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.736      |
| AbsLearnSignalNew       | 0.736      |
| AbsLearningOld          | 0.736      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 19.6175    |
| AveragePolicyStd        | 0.640826   |
| AverageReturn           | 1.06e+03   |
| Entropy                 | 2.86949    |
| EnvExecTime             | 2          |
| ExplainedVariance       | 0.931      |
| Iteration               | 599        |
| ItrTime                 | 8.3        |
| LossAfter               | 0.313481   |
| LossBefore              | 0.334976   |
| MaxReturn               | 1.41e+03   |
| MeanKL                  | 0.00653065 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 741        |
| NumTrajs                | 16         |
| Perplexity              | 17.628     |
| PolicyExecTime          | 0.516      |
| ProcessExecTime         | 0.0586     |
| StdReturn               | 167        |
| Time                    | 4.96e+03   |
| dLoss                   | 0.0214952  |
----------------------------------------
itr #600 | 
Mem: 717.382812
Obtaining samples...
Obtaining samples for iteration 600...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5098, #subsample_inputs: 5098
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.703      |
| AbsLearnSignalNew       | 0.703      |
| AbsLearningOld          | 0.703      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 19.9161    |
| AveragePolicyStd        | 0.638873   |
| AverageReturn           | 1.25e+03   |
| Entropy                 | 2.85843    |
| EnvExecTime             | 1.84       |
| ExplainedVariance       | 0.845      |
| Iteration               | 600        |
| ItrTime                 | 7.92       |
| LossAfter               | -0.0414313 |
| LossBefore              | -0.0164306 |
| MaxReturn               | 1.9e+03    |
| MeanKL                  | 0.00658869 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.03e+03   |
| NumTrajs                | 13         |
| Perplexity              | 17.4341    |
| PolicyExecTime          | 0.46       |
| ProcessExecTime         | 0.0565     |
| StdReturn               | 270        |
| Time                    | 4.97e+03   |
| dLoss                   | 0.0250006  |
----------------------------------------
itr #601 | 
Mem: 717.382812
Obtaining samples...
Obtaining samples for iteration 601...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5333, #subsample_inputs: 5333
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.767      |
| AbsLearnSignalNew       | 0.767      |
| AbsLearningOld          | 0.766      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 19.1262    |
| AveragePolicyStd        | 0.637827   |
| AverageReturn           | 1.22e+03   |
| Entropy                 | 2.85364    |
| EnvExecTime             | 1.85       |
| ExplainedVariance       | 0.932      |
| Iteration               | 601        |
| ItrTime                 | 8.18       |
| LossAfter               | -0.24922   |
| LossBefore              | -0.224224  |
| MaxReturn               | 1.59e+03   |
| MeanKL                  | 0.00649084 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 916        |
| NumTrajs                | 14         |
| Perplexity              | 17.3508    |
| PolicyExecTime          | 0.478      |
| ProcessExecTime         | 0.0555     |
| StdReturn               | 197        |
| Time                    | 4.98e+03   |
| dLoss                   | 0.0249956  |
----------------------------------------
itr #602 | 
Mem: 717.382812
Obtaining samples...
Obtaining samples for iteration 602...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5119, #subsample_inputs: 5119
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.775      |
| AbsLearnSignalNew       | 0.775      |
| AbsLearningOld          | 0.775      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 19.7721    |
| AveragePolicyStd        | 0.634844   |
| AverageReturn           | 1.25e+03   |
| Entropy                 | 2.84101    |
| EnvExecTime             | 1.95       |
| ExplainedVariance       | 0.912      |
| Iteration               | 602        |
| ItrTime                 | 8.09       |
| LossAfter               | -0.0226446 |
| LossBefore              | 0.00263683 |
| MaxReturn               | 2.18e+03   |
| MeanKL                  | 0.00984713 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 939        |
| NumTrajs                | 13         |
| Perplexity              | 17.133     |
| PolicyExecTime          | 0.49       |
| ProcessExecTime         | 0.0574     |
| StdReturn               | 338        |
| Time                    | 4.99e+03   |
| dLoss                   | 0.0252814  |
----------------------------------------
itr #603 | 
Mem: 717.382812
Obtaining samples...
Obtaining samples for iteration 603...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5206, #subsample_inputs: 5206
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.788      |
| AbsLearnSignalNew       | 0.788      |
| AbsLearningOld          | 0.788      |
| AverageDiscountedReturn | 240        |
| AveragePhiLoss          | 18.8117    |
| AveragePolicyStd        | 0.635327   |
| AverageReturn           | 1.16e+03   |
| Entropy                 | 2.84584    |
| EnvExecTime             | 1.8        |
| ExplainedVariance       | 0.863      |
| Iteration               | 603        |
| ItrTime                 | 8.03       |
| LossAfter               | -0.850476  |
| LossBefore              | -0.830287  |
| MaxReturn               | 1.6e+03    |
| MeanKL                  | 0.00641717 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 768        |
| NumTrajs                | 14         |
| Perplexity              | 17.216     |
| PolicyExecTime          | 0.467      |
| ProcessExecTime         | 0.0533     |
| StdReturn               | 229        |
| Time                    | 4.99e+03   |
| dLoss                   | 0.020189   |
----------------------------------------
itr #604 | 
Mem: 717.382812
Obtaining samples...
Obtaining samples for iteration 604...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5246, #subsample_inputs: 5246
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.536      |
| AbsLearnSignalNew       | 0.536      |
| AbsLearningOld          | 0.536      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 15.2786    |
| AveragePolicyStd        | 0.634714   |
| AverageReturn           | 1.27e+03   |
| Entropy                 | 2.84458    |
| EnvExecTime             | 1.81       |
| ExplainedVariance       | 0.298      |
| Iteration               | 604        |
| ItrTime                 | 8.04       |
| LossAfter               | -1.03875   |
| LossBefore              | -1.01978   |
| MaxReturn               | 2.48e+03   |
| MeanKL                  | 0.00649775 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 867        |
| NumTrajs                | 13         |
| Perplexity              | 17.1944    |
| PolicyExecTime          | 0.47       |
| ProcessExecTime         | 0.0543     |
| StdReturn               | 411        |
| Time                    | 5e+03      |
| dLoss                   | 0.018971   |
----------------------------------------
itr #605 | 
Mem: 717.382812
Obtaining samples...
Obtaining samples for iteration 605...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5029, #subsample_inputs: 5029
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.781     |
| AbsLearnSignalNew       | 0.781     |
| AbsLearningOld          | 0.781     |
| AverageDiscountedReturn | 244       |
| AveragePhiLoss          | 19.8314   |
| AveragePolicyStd        | 0.634191  |
| AverageReturn           | 1.17e+03  |
| Entropy                 | 2.84161   |
| EnvExecTime             | 1.93      |
| ExplainedVariance       | 0.927     |
| Iteration               | 605       |
| ItrTime                 | 8.07      |
| LossAfter               | 0.320844  |
| LossBefore              | 0.347836  |
| MaxReturn               | 1.59e+03  |
| MeanKL                  | 0.009884  |
| MeanKLBefore            | 0.0       |
| MinReturn               | 880       |
| NumTrajs                | 14        |
| Perplexity              | 17.1434   |
| PolicyExecTime          | 0.49      |
| ProcessExecTime         | 0.0576    |
| StdReturn               | 216       |
| Time                    | 5.01e+03  |
| dLoss                   | 0.0269927 |
---------------------------------------
itr #606 | 
Mem: 717.382812
Obtaining samples...
Obtaining samples for iteration 606...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5230, #subsample_inputs: 5230
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.768      |
| AbsLearnSignalNew       | 0.768      |
| AbsLearningOld          | 0.767      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 17.7713    |
| AveragePolicyStd        | 0.633571   |
| AverageReturn           | 1.12e+03   |
| Entropy                 | 2.83833    |
| EnvExecTime             | 2.07       |
| ExplainedVariance       | 0.921      |
| Iteration               | 606        |
| ItrTime                 | 8.38       |
| LossAfter               | -0.460661  |
| LossBefore              | -0.434066  |
| MaxReturn               | 1.76e+03   |
| MeanKL                  | 0.00992593 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 770        |
| NumTrajs                | 15         |
| Perplexity              | 17.0871    |
| PolicyExecTime          | 0.525      |
| ProcessExecTime         | 0.0622     |
| StdReturn               | 264        |
| Time                    | 5.02e+03   |
| dLoss                   | 0.0265944  |
----------------------------------------
itr #607 | 
Mem: 717.382812
Obtaining samples...
Obtaining samples for iteration 607...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5176, #subsample_inputs: 5176
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.776      |
| AbsLearnSignalNew       | 0.776      |
| AbsLearningOld          | 0.776      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 18.647     |
| AveragePolicyStd        | 0.635674   |
| AverageReturn           | 1.05e+03   |
| Entropy                 | 2.8475     |
| EnvExecTime             | 2.01       |
| ExplainedVariance       | 0.887      |
| Iteration               | 607        |
| ItrTime                 | 8.3        |
| LossAfter               | -0.402299  |
| LossBefore              | -0.381363  |
| MaxReturn               | 1.3e+03    |
| MeanKL                  | 0.00646934 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 797        |
| NumTrajs                | 16         |
| Perplexity              | 17.2446    |
| PolicyExecTime          | 0.504      |
| ProcessExecTime         | 0.0592     |
| StdReturn               | 163        |
| Time                    | 5.03e+03   |
| dLoss                   | 0.0209357  |
----------------------------------------
itr #608 | 
Mem: 717.382812
Obtaining samples...
Obtaining samples for iteration 608...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5198, #subsample_inputs: 5198
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.765     |
| AbsLearnSignalNew       | 0.765     |
| AbsLearningOld          | 0.765     |
| AverageDiscountedReturn | 245       |
| AveragePhiLoss          | 20.0641   |
| AveragePolicyStd        | 0.635196  |
| AverageReturn           | 998       |
| Entropy                 | 2.84699   |
| EnvExecTime             | 1.84      |
| ExplainedVariance       | 0.933     |
| Iteration               | 608       |
| ItrTime                 | 8.05      |
| LossAfter               | 0.210668  |
| LossBefore              | 0.242438  |
| MaxReturn               | 1.24e+03  |
| MeanKL                  | 0.0097512 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 649       |
| NumTrajs                | 17        |
| Perplexity              | 17.2359   |
| PolicyExecTime          | 0.472     |
| ProcessExecTime         | 0.0548    |
| StdReturn               | 138       |
| Time                    | 5.03e+03  |
| dLoss                   | 0.0317697 |
---------------------------------------
itr #609 | 
Mem: 717.382812
Obtaining samples...
Obtaining samples for iteration 609...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5071, #subsample_inputs: 5071
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.794      |
| AbsLearnSignalNew       | 0.794      |
| AbsLearningOld          | 0.794      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 21.1194    |
| AveragePolicyStd        | 0.632802   |
| AverageReturn           | 983        |
| Entropy                 | 2.83609    |
| EnvExecTime             | 1.87       |
| ExplainedVariance       | 0.946      |
| Iteration               | 609        |
| ItrTime                 | 7.96       |
| LossAfter               | -0.233963  |
| LossBefore              | -0.20419   |
| MaxReturn               | 1.24e+03   |
| MeanKL                  | 0.00993311 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 814        |
| NumTrajs                | 17         |
| Perplexity              | 17.0489    |
| PolicyExecTime          | 0.473      |
| ProcessExecTime         | 0.0552     |
| StdReturn               | 123        |
| Time                    | 5.04e+03   |
| dLoss                   | 0.0297725  |
----------------------------------------
itr #610 | 
Mem: 717.382812
Obtaining samples...
Obtaining samples for iteration 610...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5063, #subsample_inputs: 5063
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.761      |
| AbsLearnSignalNew       | 0.761      |
| AbsLearningOld          | 0.761      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 19.4456    |
| AveragePolicyStd        | 0.632128   |
| AverageReturn           | 1.04e+03   |
| Entropy                 | 2.83124    |
| EnvExecTime             | 1.74       |
| ExplainedVariance       | 0.931      |
| Iteration               | 610        |
| ItrTime                 | 7.77       |
| LossAfter               | -0.831445  |
| LossBefore              | -0.805191  |
| MaxReturn               | 1.33e+03   |
| MeanKL                  | 0.00947437 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 807        |
| NumTrajs                | 16         |
| Perplexity              | 16.9664    |
| PolicyExecTime          | 0.448      |
| ProcessExecTime         | 0.0512     |
| StdReturn               | 134        |
| Time                    | 5.05e+03   |
| dLoss                   | 0.0262546  |
----------------------------------------
itr #611 | 
Mem: 717.382812
Obtaining samples...
Obtaining samples for iteration 611...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5228, #subsample_inputs: 5228
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.44       |
| AbsLearnSignalNew       | 0.44       |
| AbsLearningOld          | 0.44       |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 16.3964    |
| AveragePolicyStd        | 0.630505   |
| AverageReturn           | 1.12e+03   |
| Entropy                 | 2.82496    |
| EnvExecTime             | 2          |
| ExplainedVariance       | 0.217      |
| Iteration               | 611        |
| ItrTime                 | 8.26       |
| LossAfter               | -0.0795823 |
| LossBefore              | -0.0556446 |
| MaxReturn               | 2.03e+03   |
| MeanKL                  | 0.00650445 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 825        |
| NumTrajs                | 15         |
| Perplexity              | 16.8602    |
| PolicyExecTime          | 0.506      |
| ProcessExecTime         | 0.0592     |
| StdReturn               | 332        |
| Time                    | 5.06e+03   |
| dLoss                   | 0.0239377  |
----------------------------------------
itr #612 | 
Mem: 717.382812
Obtaining samples...
Obtaining samples for iteration 612...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5158, #subsample_inputs: 5158
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.788      |
| AbsLearnSignalNew       | 0.788      |
| AbsLearningOld          | 0.788      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 19.6187    |
| AveragePolicyStd        | 0.630196   |
| AverageReturn           | 992        |
| Entropy                 | 2.82388    |
| EnvExecTime             | 1.9        |
| ExplainedVariance       | 0.943      |
| Iteration               | 612        |
| ItrTime                 | 8.06       |
| LossAfter               | -0.249268  |
| LossBefore              | -0.227345  |
| MaxReturn               | 1.19e+03   |
| MeanKL                  | 0.00967733 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 840        |
| NumTrajs                | 17         |
| Perplexity              | 16.8421    |
| PolicyExecTime          | 0.482      |
| ProcessExecTime         | 0.0573     |
| StdReturn               | 107        |
| Time                    | 5.07e+03   |
| dLoss                   | 0.0219227  |
----------------------------------------
itr #613 | 
Mem: 717.382812
Obtaining samples...
Obtaining samples for iteration 613...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5121, #subsample_inputs: 5121
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.707      |
| AbsLearnSignalNew       | 0.707      |
| AbsLearningOld          | 0.707      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 18.8888    |
| AveragePolicyStd        | 0.629679   |
| AverageReturn           | 937        |
| Entropy                 | 2.82263    |
| EnvExecTime             | 1.76       |
| ExplainedVariance       | 0.895      |
| Iteration               | 613        |
| ItrTime                 | 7.87       |
| LossAfter               | -0.596165  |
| LossBefore              | -0.572995  |
| MaxReturn               | 1.49e+03   |
| MeanKL                  | 0.00641592 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 696        |
| NumTrajs                | 18         |
| Perplexity              | 16.821     |
| PolicyExecTime          | 0.445      |
| ProcessExecTime         | 0.0531     |
| StdReturn               | 167        |
| Time                    | 5.07e+03   |
| dLoss                   | 0.0231701  |
----------------------------------------
itr #614 | 
Mem: 717.382812
Obtaining samples...
Obtaining samples for iteration 614...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5197, #subsample_inputs: 5197
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.689      |
| AbsLearnSignalNew       | 0.689      |
| AbsLearningOld          | 0.689      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 18.717     |
| AveragePolicyStd        | 0.628663   |
| AverageReturn           | 1.05e+03   |
| Entropy                 | 2.81751    |
| EnvExecTime             | 1.73       |
| ExplainedVariance       | 0.858      |
| Iteration               | 614        |
| ItrTime                 | 7.89       |
| LossAfter               | -0.512021  |
| LossBefore              | -0.483908  |
| MaxReturn               | 1.6e+03    |
| MeanKL                  | 0.00968761 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 660        |
| NumTrajs                | 16         |
| Perplexity              | 16.7351    |
| PolicyExecTime          | 0.442      |
| ProcessExecTime         | 0.0526     |
| StdReturn               | 271        |
| Time                    | 5.08e+03   |
| dLoss                   | 0.0281136  |
----------------------------------------
itr #615 | 
Mem: 717.382812
Obtaining samples...
Obtaining samples for iteration 615...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5307, #subsample_inputs: 5307
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.776      |
| AbsLearnSignalNew       | 0.776      |
| AbsLearningOld          | 0.776      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 19.5742    |
| AveragePolicyStd        | 0.630699   |
| AverageReturn           | 1.08e+03   |
| Entropy                 | 2.82548    |
| EnvExecTime             | 1.78       |
| ExplainedVariance       | 0.927      |
| Iteration               | 615        |
| ItrTime                 | 8.05       |
| LossAfter               | -0.308362  |
| LossBefore              | -0.278204  |
| MaxReturn               | 1.55e+03   |
| MeanKL                  | 0.00997372 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 800        |
| NumTrajs                | 16         |
| Perplexity              | 16.8691    |
| PolicyExecTime          | 0.456      |
| ProcessExecTime         | 0.0544     |
| StdReturn               | 228        |
| Time                    | 5.09e+03   |
| dLoss                   | 0.0301583  |
----------------------------------------
itr #616 | 
Mem: 717.382812
Obtaining samples...
Obtaining samples for iteration 616...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5008, #subsample_inputs: 5008
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.78      |
| AbsLearnSignalNew       | 0.78      |
| AbsLearningOld          | 0.78      |
| AverageDiscountedReturn | 245       |
| AveragePhiLoss          | 18.7112   |
| AveragePolicyStd        | 0.633854  |
| AverageReturn           | 1.03e+03  |
| Entropy                 | 2.83804   |
| EnvExecTime             | 1.79      |
| ExplainedVariance       | 0.933     |
| Iteration               | 616       |
| ItrTime                 | 7.82      |
| LossAfter               | -0.128706 |
| LossBefore              | -0.109687 |
| MaxReturn               | 1.42e+03  |
| MeanKL                  | 0.0064457 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 634       |
| NumTrajs                | 16        |
| Perplexity              | 17.0822   |
| PolicyExecTime          | 0.454     |
| ProcessExecTime         | 0.0529    |
| StdReturn               | 172       |
| Time                    | 5.1e+03   |
| dLoss                   | 0.019019  |
---------------------------------------
itr #617 | 
Mem: 717.382812
Obtaining samples...
Obtaining samples for iteration 617...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5265, #subsample_inputs: 5265
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.779     |
| AbsLearnSignalNew       | 0.779     |
| AbsLearningOld          | 0.779     |
| AverageDiscountedReturn | 245       |
| AveragePhiLoss          | 19.908    |
| AveragePolicyStd        | 0.634037  |
| AverageReturn           | 958       |
| Entropy                 | 2.84007   |
| EnvExecTime             | 1.89      |
| ExplainedVariance       | 0.943     |
| Iteration               | 617       |
| ItrTime                 | 8.15      |
| LossAfter               | 0.463093  |
| LossBefore              | 0.489086  |
| MaxReturn               | 1.28e+03  |
| MeanKL                  | 0.0099574 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 708       |
| NumTrajs                | 18        |
| Perplexity              | 17.117    |
| PolicyExecTime          | 0.482     |
| ProcessExecTime         | 0.0558    |
| StdReturn               | 130       |
| Time                    | 5.11e+03  |
| dLoss                   | 0.0259931 |
---------------------------------------
itr #618 | 
Mem: 717.902344
Obtaining samples...
Obtaining samples for iteration 618...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5208, #subsample_inputs: 5208
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.729      |
| AbsLearnSignalNew       | 0.729      |
| AbsLearningOld          | 0.729      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 19.831     |
| AveragePolicyStd        | 0.632439   |
| AverageReturn           | 1e+03      |
| Entropy                 | 2.83137    |
| EnvExecTime             | 1.99       |
| ExplainedVariance       | 0.904      |
| Iteration               | 618        |
| ItrTime                 | 8.23       |
| LossAfter               | 0.0187801  |
| LossBefore              | 0.0414836  |
| MaxReturn               | 1.3e+03    |
| MeanKL                  | 0.00646174 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 695        |
| NumTrajs                | 17         |
| Perplexity              | 16.9687    |
| PolicyExecTime          | 0.5        |
| ProcessExecTime         | 0.0579     |
| StdReturn               | 151        |
| Time                    | 5.12e+03   |
| dLoss                   | 0.0227035  |
----------------------------------------
itr #619 | 
Mem: 717.902344
Obtaining samples...
Obtaining samples for iteration 619...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5222, #subsample_inputs: 5222
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.767      |
| AbsLearnSignalNew       | 0.767      |
| AbsLearningOld          | 0.766      |
| AverageDiscountedReturn | 247        |
| AveragePhiLoss          | 18.8218    |
| AveragePolicyStd        | 0.63298    |
| AverageReturn           | 1.01e+03   |
| Entropy                 | 2.83336    |
| EnvExecTime             | 1.82       |
| ExplainedVariance       | 0.952      |
| Iteration               | 619        |
| ItrTime                 | 8.09       |
| LossAfter               | -1.18725   |
| LossBefore              | -1.16157   |
| MaxReturn               | 1.29e+03   |
| MeanKL                  | 0.00979666 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 790        |
| NumTrajs                | 17         |
| Perplexity              | 17.0025    |
| PolicyExecTime          | 0.466      |
| ProcessExecTime         | 0.0547     |
| StdReturn               | 126        |
| Time                    | 5.12e+03   |
| dLoss                   | 0.0256796  |
----------------------------------------
itr #620 | 
Mem: 717.902344
Obtaining samples...
Obtaining samples for iteration 620...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5164, #subsample_inputs: 5164
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.578      |
| AbsLearnSignalNew       | 0.578      |
| AbsLearningOld          | 0.579      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 19.2603    |
| AveragePolicyStd        | 0.631372   |
| AverageReturn           | 1.06e+03   |
| Entropy                 | 2.82436    |
| EnvExecTime             | 2          |
| ExplainedVariance       | 0.868      |
| Iteration               | 620        |
| ItrTime                 | 8.23       |
| LossAfter               | 0.820711   |
| LossBefore              | 0.844189   |
| MaxReturn               | 1.36e+03   |
| MeanKL                  | 0.00647633 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 866        |
| NumTrajs                | 16         |
| Perplexity              | 16.8501    |
| PolicyExecTime          | 0.503      |
| ProcessExecTime         | 0.0589     |
| StdReturn               | 126        |
| Time                    | 5.13e+03   |
| dLoss                   | 0.0234783  |
----------------------------------------
itr #621 | 
Mem: 717.902344
Obtaining samples...
Obtaining samples for iteration 621...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5140, #subsample_inputs: 5140
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.623      |
| AbsLearnSignalNew       | 0.623      |
| AbsLearningOld          | 0.623      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 18.7508    |
| AveragePolicyStd        | 0.628688   |
| AverageReturn           | 1.18e+03   |
| Entropy                 | 2.81315    |
| EnvExecTime             | 1.92       |
| ExplainedVariance       | 0.672      |
| Iteration               | 621        |
| ItrTime                 | 8.1        |
| LossAfter               | -0.0814728 |
| LossBefore              | -0.0518606 |
| MaxReturn               | 1.61e+03   |
| MeanKL                  | 0.00964007 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 837        |
| NumTrajs                | 14         |
| Perplexity              | 16.6624    |
| PolicyExecTime          | 0.485      |
| ProcessExecTime         | 0.0574     |
| StdReturn               | 253        |
| Time                    | 5.14e+03   |
| dLoss                   | 0.0296122  |
----------------------------------------
itr #622 | 
Mem: 717.902344
Obtaining samples...
Obtaining samples for iteration 622...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5072, #subsample_inputs: 5072
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.774      |
| AbsLearnSignalNew       | 0.774      |
| AbsLearningOld          | 0.774      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 19.9841    |
| AveragePolicyStd        | 0.628936   |
| AverageReturn           | 1.17e+03   |
| Entropy                 | 2.81248    |
| EnvExecTime             | 2.06       |
| ExplainedVariance       | 0.931      |
| Iteration               | 622        |
| ItrTime                 | 8.25       |
| LossAfter               | 0.373103   |
| LossBefore              | 0.396523   |
| MaxReturn               | 1.65e+03   |
| MeanKL                  | 0.00646064 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.02e+03   |
| NumTrajs                | 14         |
| Perplexity              | 16.6512    |
| PolicyExecTime          | 0.524      |
| ProcessExecTime         | 0.059      |
| StdReturn               | 192        |
| Time                    | 5.15e+03   |
| dLoss                   | 0.0234208  |
----------------------------------------
itr #623 | 
Mem: 717.902344
Obtaining samples...
Obtaining samples for iteration 623...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5359, #subsample_inputs: 5359
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.759      |
| AbsLearnSignalNew       | 0.759      |
| AbsLearningOld          | 0.759      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 18.7883    |
| AveragePolicyStd        | 0.629245   |
| AverageReturn           | 1.08e+03   |
| Entropy                 | 2.81408    |
| EnvExecTime             | 1.82       |
| ExplainedVariance       | 0.941      |
| Iteration               | 623        |
| ItrTime                 | 8.19       |
| LossAfter               | -0.0243763 |
| LossBefore              | 0.00170557 |
| MaxReturn               | 1.29e+03   |
| MeanKL                  | 0.00996277 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 775        |
| NumTrajs                | 16         |
| Perplexity              | 16.6778    |
| PolicyExecTime          | 0.469      |
| ProcessExecTime         | 0.0548     |
| StdReturn               | 136        |
| Time                    | 5.16e+03   |
| dLoss                   | 0.0260818  |
----------------------------------------
itr #624 | 
Mem: 717.902344
Obtaining samples...
Obtaining samples for iteration 624...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5139, #subsample_inputs: 5139
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.605      |
| AbsLearnSignalNew       | 0.605      |
| AbsLearningOld          | 0.605      |
| AverageDiscountedReturn | 236        |
| AveragePhiLoss          | 20.3033    |
| AveragePolicyStd        | 0.627612   |
| AverageReturn           | 976        |
| Entropy                 | 2.80486    |
| EnvExecTime             | 1.82       |
| ExplainedVariance       | 0.809      |
| Iteration               | 624        |
| ItrTime                 | 7.9        |
| LossAfter               | 0.132922   |
| LossBefore              | 0.1617     |
| MaxReturn               | 1.31e+03   |
| MeanKL                  | 0.00998783 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 198        |
| NumTrajs                | 17         |
| Perplexity              | 16.5248    |
| PolicyExecTime          | 0.465      |
| ProcessExecTime         | 0.0538     |
| StdReturn               | 233        |
| Time                    | 5.16e+03   |
| dLoss                   | 0.0287784  |
----------------------------------------
itr #625 | 
Mem: 717.902344
Obtaining samples...
Obtaining samples for iteration 625...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5384, #subsample_inputs: 5384
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.706      |
| AbsLearnSignalNew       | 0.706      |
| AbsLearningOld          | 0.706      |
| AverageDiscountedReturn | 244        |
| AveragePhiLoss          | 20.3815    |
| AveragePolicyStd        | 0.627234   |
| AverageReturn           | 1.09e+03   |
| Entropy                 | 2.80349    |
| EnvExecTime             | 1.91       |
| ExplainedVariance       | 0.902      |
| Iteration               | 625        |
| ItrTime                 | 8.28       |
| LossAfter               | -0.396166  |
| LossBefore              | -0.3746    |
| MaxReturn               | 1.56e+03   |
| MeanKL                  | 0.00995205 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 849        |
| NumTrajs                | 16         |
| Perplexity              | 16.5022    |
| PolicyExecTime          | 0.491      |
| ProcessExecTime         | 0.0557     |
| StdReturn               | 177        |
| Time                    | 5.17e+03   |
| dLoss                   | 0.0215659  |
----------------------------------------
itr #626 | 
Mem: 717.902344
Obtaining samples...
Obtaining samples for iteration 626...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5216, #subsample_inputs: 5216
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.772      |
| AbsLearnSignalNew       | 0.772      |
| AbsLearningOld          | 0.772      |
| AverageDiscountedReturn | 245        |
| AveragePhiLoss          | 19.5972    |
| AveragePolicyStd        | 0.625224   |
| AverageReturn           | 1.07e+03   |
| Entropy                 | 2.79171    |
| EnvExecTime             | 1.98       |
| ExplainedVariance       | 0.94       |
| Iteration               | 626        |
| ItrTime                 | 8.24       |
| LossAfter               | -0.565562  |
| LossBefore              | -0.537689  |
| MaxReturn               | 1.34e+03   |
| MeanKL                  | 0.00993518 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 825        |
| NumTrajs                | 16         |
| Perplexity              | 16.3089    |
| PolicyExecTime          | 0.496      |
| ProcessExecTime         | 0.0588     |
| StdReturn               | 134        |
| Time                    | 5.18e+03   |
| dLoss                   | 0.0278729  |
----------------------------------------
itr #627 | 
Mem: 717.902344
Obtaining samples...
Obtaining samples for iteration 627...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5110, #subsample_inputs: 5110
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.61      |
| AbsLearnSignalNew       | 0.61      |
| AbsLearningOld          | 0.61      |
| AverageDiscountedReturn | 243       |
| AveragePhiLoss          | 18.4462   |
| AveragePolicyStd        | 0.623776  |
| AverageReturn           | 1.09e+03  |
| Entropy                 | 2.78463   |
| EnvExecTime             | 1.84      |
| ExplainedVariance       | 0.817     |
| Iteration               | 627       |
| ItrTime                 | 7.92      |
| LossAfter               | 0.491821  |
| LossBefore              | 0.509747  |
| MaxReturn               | 1.67e+03  |
| MeanKL                  | 0.0065407 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 815       |
| NumTrajs                | 15        |
| Perplexity              | 16.1938   |
| PolicyExecTime          | 0.463     |
| ProcessExecTime         | 0.0568    |
| StdReturn               | 207       |
| Time                    | 5.19e+03  |
| dLoss                   | 0.0179265 |
---------------------------------------
itr #628 | 
Mem: 717.902344
Obtaining samples...
Obtaining samples for iteration 628...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5215, #subsample_inputs: 5215
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.735     |
| AbsLearnSignalNew       | 0.735     |
| AbsLearningOld          | 0.734     |
| AverageDiscountedReturn | 242       |
| AveragePhiLoss          | 20.4959   |
| AveragePolicyStd        | 0.625351  |
| AverageReturn           | 1.11e+03  |
| Entropy                 | 2.79014   |
| EnvExecTime             | 1.96      |
| ExplainedVariance       | 0.889     |
| Iteration               | 628       |
| ItrTime                 | 8.25      |
| LossAfter               | 0.40427   |
| LossBefore              | 0.424717  |
| MaxReturn               | 1.59e+03  |
| MeanKL                  | 0.0064372 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 736       |
| NumTrajs                | 15        |
| Perplexity              | 16.2832   |
| PolicyExecTime          | 0.491     |
| ProcessExecTime         | 0.0616    |
| StdReturn               | 222       |
| Time                    | 5.2e+03   |
| dLoss                   | 0.0204466 |
---------------------------------------
itr #629 | 
Mem: 717.902344
Obtaining samples...
Obtaining samples for iteration 629...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5168, #subsample_inputs: 5168
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.748      |
| AbsLearnSignalNew       | 0.748      |
| AbsLearningOld          | 0.748      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 21.2924    |
| AveragePolicyStd        | 0.62413    |
| AverageReturn           | 1.28e+03   |
| Entropy                 | 2.78654    |
| EnvExecTime             | 1.78       |
| ExplainedVariance       | 0.906      |
| Iteration               | 629        |
| ItrTime                 | 7.93       |
| LossAfter               | -0.058989  |
| LossBefore              | -0.0412201 |
| MaxReturn               | 1.62e+03   |
| MeanKL                  | 0.00657046 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 992        |
| NumTrajs                | 13         |
| Perplexity              | 16.2248    |
| PolicyExecTime          | 0.455      |
| ProcessExecTime         | 0.0533     |
| StdReturn               | 196        |
| Time                    | 5.21e+03   |
| dLoss                   | 0.0177688  |
----------------------------------------
itr #630 | 
Mem: 717.902344
Obtaining samples...
Obtaining samples for iteration 630...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5287, #subsample_inputs: 5287
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.77       |
| AbsLearnSignalNew       | 0.77       |
| AbsLearningOld          | 0.77       |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 19.6839    |
| AveragePolicyStd        | 0.622226   |
| AverageReturn           | 1.14e+03   |
| Entropy                 | 2.77921    |
| EnvExecTime             | 1.78       |
| ExplainedVariance       | 0.935      |
| Iteration               | 630        |
| ItrTime                 | 8.12       |
| LossAfter               | -0.227493  |
| LossBefore              | -0.199216  |
| MaxReturn               | 1.42e+03   |
| MeanKL                  | 0.00998149 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 822        |
| NumTrajs                | 15         |
| Perplexity              | 16.1063    |
| PolicyExecTime          | 0.464      |
| ProcessExecTime         | 0.0536     |
| StdReturn               | 158        |
| Time                    | 5.21e+03   |
| dLoss                   | 0.0282772  |
----------------------------------------
itr #631 | 
Mem: 717.902344
Obtaining samples...
Obtaining samples for iteration 631...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5014, #subsample_inputs: 5014
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.766     |
| AbsLearnSignalNew       | 0.766     |
| AbsLearningOld          | 0.767     |
| AverageDiscountedReturn | 243       |
| AveragePhiLoss          | 19.6459   |
| AveragePolicyStd        | 0.622767  |
| AverageReturn           | 1.15e+03  |
| Entropy                 | 2.78498   |
| EnvExecTime             | 1.91      |
| ExplainedVariance       | 0.93      |
| Iteration               | 631       |
| ItrTime                 | 7.98      |
| LossAfter               | 0.106486  |
| LossBefore              | 0.130636  |
| MaxReturn               | 1.59e+03  |
| MeanKL                  | 0.0064318 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.02e+03  |
| NumTrajs                | 14        |
| Perplexity              | 16.1995   |
| PolicyExecTime          | 0.474     |
| ProcessExecTime         | 0.0579    |
| StdReturn               | 157       |
| Time                    | 5.22e+03  |
| dLoss                   | 0.02415   |
---------------------------------------
itr #632 | 
Mem: 717.902344
Obtaining samples...
Obtaining samples for iteration 632...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5482, #subsample_inputs: 5482
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.777      |
| AbsLearnSignalNew       | 0.777      |
| AbsLearningOld          | 0.777      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 20.0639    |
| AveragePolicyStd        | 0.621517   |
| AverageReturn           | 1.18e+03   |
| Entropy                 | 2.78061    |
| EnvExecTime             | 1.95       |
| ExplainedVariance       | 0.93       |
| Iteration               | 632        |
| ItrTime                 | 8.37       |
| LossAfter               | -0.0398162 |
| LossBefore              | -0.0133486 |
| MaxReturn               | 1.68e+03   |
| MeanKL                  | 0.00991234 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 744        |
| NumTrajs                | 15         |
| Perplexity              | 16.1288    |
| PolicyExecTime          | 0.5        |
| ProcessExecTime         | 0.0576     |
| StdReturn               | 238        |
| Time                    | 5.23e+03   |
| dLoss                   | 0.0264677  |
----------------------------------------
itr #633 | 
Mem: 717.902344
Obtaining samples...
Obtaining samples for iteration 633...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5069, #subsample_inputs: 5069
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.734      |
| AbsLearnSignalNew       | 0.734      |
| AbsLearningOld          | 0.734      |
| AverageDiscountedReturn | 246        |
| AveragePhiLoss          | 20.4111    |
| AveragePolicyStd        | 0.621464   |
| AverageReturn           | 1.18e+03   |
| Entropy                 | 2.78133    |
| EnvExecTime             | 1.72       |
| ExplainedVariance       | 0.924      |
| Iteration               | 633        |
| ItrTime                 | 7.77       |
| LossAfter               | -0.0352742 |
| LossBefore              | -0.0119965 |
| MaxReturn               | 1.89e+03   |
| MeanKL                  | 0.0065872  |
| MeanKLBefore            | 0.0        |
| MinReturn               | 955        |
| NumTrajs                | 14         |
| Perplexity              | 16.1404    |
| PolicyExecTime          | 0.434      |
| ProcessExecTime         | 0.0524     |
| StdReturn               | 211        |
| Time                    | 5.24e+03   |
| dLoss                   | 0.0232776  |
----------------------------------------
itr #634 | 
Mem: 717.902344
Obtaining samples...
Obtaining samples for iteration 634...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5616, #subsample_inputs: 5616
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.743      |
| AbsLearnSignalNew       | 0.743      |
| AbsLearningOld          | 0.743      |
| AverageDiscountedReturn | 243        |
| AveragePhiLoss          | 19.8976    |
| AveragePolicyStd        | 0.624021   |
| AverageReturn           | 1.37e+03   |
| Entropy                 | 2.78913    |
| EnvExecTime             | 2.28       |
| ExplainedVariance       | 0.874      |
| Iteration               | 634        |
| ItrTime                 | 8.9        |
| LossAfter               | -0.938691  |
| LossBefore              | -0.915346  |
| MaxReturn               | 2.5e+03    |
| MeanKL                  | 0.00642429 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.07e+03   |
| NumTrajs                | 13         |
| Perplexity              | 16.2668    |
| PolicyExecTime          | 0.563      |
| ProcessExecTime         | 0.0701     |
| StdReturn               | 396        |
| Time                    | 5.25e+03   |
| dLoss                   | 0.0233452  |
----------------------------------------
itr #635 | 
Mem: 717.902344
Obtaining samples...
Obtaining samples for iteration 635...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5149, #subsample_inputs: 5149
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.746      |
| AbsLearnSignalNew       | 0.746      |
| AbsLearningOld          | 0.746      |
| AverageDiscountedReturn | 242        |
| AveragePhiLoss          | 20.3893    |
| AveragePolicyStd        | 0.623566   |
| AverageReturn           | 1.38e+03   |
| Entropy                 | 2.78669    |
| EnvExecTime             | 1.99       |
| ExplainedVariance       | 0.891      |
| Iteration               | 635        |
| ItrTime                 | 8.2        |
| LossAfter               | -0.173075  |
| LossBefore              | -0.150279  |
| MaxReturn               | 1.9e+03    |
| MeanKL                  | 0.00640906 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.11e+03   |
| NumTrajs                | 12         |
| Perplexity              | 16.2272    |
| PolicyExecTime          | 0.513      |
| ProcessExecTime         | 0.0579     |
| StdReturn               | 233        |
| Time                    | 5.25e+03   |
| dLoss                   | 0.0227961  |
----------------------------------------
itr #636 | 
Mem: 718.152344
Obtaining samples...
Obtaining samples for iteration 636...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5224, #subsample_inputs: 5224
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.777      |
| AbsLearnSignalNew       | 0.777      |
| AbsLearningOld          | 0.777      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 20.0787    |
| AveragePolicyStd        | 0.621654   |
| AverageReturn           | 1.27e+03   |
| Entropy                 | 2.77939    |
| EnvExecTime             | 2.09       |
| ExplainedVariance       | 0.927      |
| Iteration               | 636        |
| ItrTime                 | 8.38       |
| LossAfter               | 0.285053   |
| LossBefore              | 0.306355   |
| MaxReturn               | 1.64e+03   |
| MeanKL                  | 0.00640155 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.02e+03   |
| NumTrajs                | 13         |
| Perplexity              | 16.1092    |
| PolicyExecTime          | 0.527      |
| ProcessExecTime         | 0.0612     |
| StdReturn               | 219        |
| Time                    | 5.26e+03   |
| dLoss                   | 0.0213026  |
----------------------------------------
itr #637 | 
Mem: 718.152344
Obtaining samples...
Obtaining samples for iteration 637...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5172, #subsample_inputs: 5172
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.781      |
| AbsLearnSignalNew       | 0.781      |
| AbsLearningOld          | 0.781      |
| AverageDiscountedReturn | 237        |
| AveragePhiLoss          | 21.316     |
| AveragePolicyStd        | 0.621023   |
| AverageReturn           | 1.35e+03   |
| Entropy                 | 2.77623    |
| EnvExecTime             | 1.95       |
| ExplainedVariance       | 0.88       |
| Iteration               | 637        |
| ItrTime                 | 8.17       |
| LossAfter               | 0.510898   |
| LossBefore              | 0.537598   |
| MaxReturn               | 1.81e+03   |
| MeanKL                  | 0.00966115 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 810        |
| NumTrajs                | 12         |
| Perplexity              | 16.0584    |
| PolicyExecTime          | 0.507      |
| ProcessExecTime         | 0.0573     |
| StdReturn               | 337        |
| Time                    | 5.27e+03   |
| dLoss                   | 0.0267001  |
----------------------------------------
itr #638 | 
Mem: 718.152344
Obtaining samples...
Obtaining samples for iteration 638...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5260, #subsample_inputs: 5260
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.636     |
| AbsLearnSignalNew       | 0.636     |
| AbsLearningOld          | 0.637     |
| AverageDiscountedReturn | 238       |
| AveragePhiLoss          | 18.96     |
| AveragePolicyStd        | 0.622698  |
| AverageReturn           | 1.37e+03  |
| Entropy                 | 2.78303   |
| EnvExecTime             | 2.05      |
| ExplainedVariance       | 0.752     |
| Iteration               | 638       |
| ItrTime                 | 8.32      |
| LossAfter               | -0.804017 |
| LossBefore              | -0.775768 |
| MaxReturn               | 1.99e+03  |
| MeanKL                  | 0.0098754 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 702       |
| NumTrajs                | 12        |
| Perplexity              | 16.168    |
| PolicyExecTime          | 0.525     |
| ProcessExecTime         | 0.0597    |
| StdReturn               | 321       |
| Time                    | 5.28e+03  |
| dLoss                   | 0.0282486 |
---------------------------------------
itr #639 | 
Mem: 718.152344
Obtaining samples...
Obtaining samples for iteration 639...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5384, #subsample_inputs: 5384
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.723      |
| AbsLearnSignalNew       | 0.723      |
| AbsLearningOld          | 0.723      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 21.8484    |
| AveragePolicyStd        | 0.620843   |
| AverageReturn           | 1.49e+03   |
| Entropy                 | 2.77466    |
| EnvExecTime             | 1.97       |
| ExplainedVariance       | 0.62       |
| Iteration               | 639        |
| ItrTime                 | 8.42       |
| LossAfter               | -1.02305   |
| LossBefore              | -0.994249  |
| MaxReturn               | 2.85e+03   |
| MeanKL                  | 0.00994484 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 940        |
| NumTrajs                | 11         |
| Perplexity              | 16.0331    |
| PolicyExecTime          | 0.512      |
| ProcessExecTime         | 0.0578     |
| StdReturn               | 517        |
| Time                    | 5.29e+03   |
| dLoss                   | 0.0288048  |
----------------------------------------
itr #640 | 
Mem: 718.152344
Obtaining samples...
Obtaining samples for iteration 640...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5056, #subsample_inputs: 5056
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.775      |
| AbsLearnSignalNew       | 0.775      |
| AbsLearningOld          | 0.775      |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 20.6784    |
| AveragePolicyStd        | 0.622342   |
| AverageReturn           | 1.59e+03   |
| Entropy                 | 2.77894    |
| EnvExecTime             | 2.03       |
| ExplainedVariance       | 0.89       |
| Iteration               | 640        |
| ItrTime                 | 8.13       |
| LossAfter               | -0.337691  |
| LossBefore              | -0.30413   |
| MaxReturn               | 2.28e+03   |
| MeanKL                  | 0.00989361 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.13e+03   |
| NumTrajs                | 10         |
| Perplexity              | 16.102     |
| PolicyExecTime          | 0.524      |
| ProcessExecTime         | 0.0569     |
| StdReturn               | 379        |
| Time                    | 5.3e+03    |
| dLoss                   | 0.0335615  |
----------------------------------------
itr #641 | 
Mem: 718.152344
Obtaining samples...
Obtaining samples for iteration 641...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5334, #subsample_inputs: 5334
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.627      |
| AbsLearnSignalNew       | 0.627      |
| AbsLearningOld          | 0.627      |
| AverageDiscountedReturn | 230        |
| AveragePhiLoss          | 21.6647    |
| AveragePolicyStd        | 0.6228     |
| AverageReturn           | 1.45e+03   |
| Entropy                 | 2.78161    |
| EnvExecTime             | 2.34       |
| ExplainedVariance       | 0.652      |
| Iteration               | 641        |
| ItrTime                 | 8.87       |
| LossAfter               | 0.943859   |
| LossBefore              | 0.967031   |
| MaxReturn               | 2.24e+03   |
| MeanKL                  | 0.00655627 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 552        |
| NumTrajs                | 11         |
| Perplexity              | 16.1451    |
| PolicyExecTime          | 0.597      |
| ProcessExecTime         | 0.0671     |
| StdReturn               | 496        |
| Time                    | 5.31e+03   |
| dLoss                   | 0.023172   |
----------------------------------------
itr #642 | 
Mem: 718.402344
Obtaining samples...
Obtaining samples for iteration 642...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5273, #subsample_inputs: 5273
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.767      |
| AbsLearnSignalNew       | 0.767      |
| AbsLearningOld          | 0.767      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 24.6424    |
| AveragePolicyStd        | 0.620732   |
| AverageReturn           | 1.28e+03   |
| Entropy                 | 2.76983    |
| EnvExecTime             | 2.01       |
| ExplainedVariance       | 0.796      |
| Iteration               | 642        |
| ItrTime                 | 8.36       |
| LossAfter               | -0.224629  |
| LossBefore              | -0.198155  |
| MaxReturn               | 1.71e+03   |
| MeanKL                  | 0.00987463 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 538        |
| NumTrajs                | 13         |
| Perplexity              | 15.9559    |
| PolicyExecTime          | 0.517      |
| ProcessExecTime         | 0.0587     |
| StdReturn               | 270        |
| Time                    | 5.31e+03   |
| dLoss                   | 0.0264738  |
----------------------------------------
itr #643 | 
Mem: 718.402344
Obtaining samples...
Obtaining samples for iteration 643...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5143, #subsample_inputs: 5143
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.681     |
| AbsLearnSignalNew       | 0.681     |
| AbsLearningOld          | 0.681     |
| AverageDiscountedReturn | 231       |
| AveragePhiLoss          | 23.8676   |
| AveragePolicyStd        | 0.619356  |
| AverageReturn           | 1.7e+03   |
| Entropy                 | 2.76346   |
| EnvExecTime             | 2.13      |
| ExplainedVariance       | 0.45      |
| Iteration               | 643       |
| ItrTime                 | 8.37      |
| LossAfter               | -0.16281  |
| LossBefore              | -0.13702  |
| MaxReturn               | 2.42e+03  |
| MeanKL                  | 0.0064218 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 893       |
| NumTrajs                | 9         |
| Perplexity              | 15.8545   |
| PolicyExecTime          | 0.556     |
| ProcessExecTime         | 0.0607    |
| StdReturn               | 483       |
| Time                    | 5.32e+03  |
| dLoss                   | 0.0257899 |
---------------------------------------
itr #644 | 
Mem: 718.402344
Obtaining samples...
Obtaining samples for iteration 644...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5233, #subsample_inputs: 5233
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.747     |
| AbsLearnSignalNew       | 0.747     |
| AbsLearningOld          | 0.747     |
| AverageDiscountedReturn | 233       |
| AveragePhiLoss          | 24.9394   |
| AveragePolicyStd        | 0.618708  |
| AverageReturn           | 1.73e+03  |
| Entropy                 | 2.76112   |
| EnvExecTime             | 1.96      |
| ExplainedVariance       | 0.738     |
| Iteration               | 644       |
| ItrTime                 | 8.22      |
| LossAfter               | -0.161684 |
| LossBefore              | -0.135074 |
| MaxReturn               | 2.96e+03  |
| MeanKL                  | 0.0099061 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 1.21e+03  |
| NumTrajs                | 9         |
| Perplexity              | 15.8176   |
| PolicyExecTime          | 0.507     |
| ProcessExecTime         | 0.0579    |
| StdReturn               | 646       |
| Time                    | 5.33e+03  |
| dLoss                   | 0.02661   |
---------------------------------------
itr #645 | 
Mem: 718.402344
Obtaining samples...
Obtaining samples for iteration 645...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5255, #subsample_inputs: 5255
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.766      |
| AbsLearnSignalNew       | 0.766      |
| AbsLearningOld          | 0.766      |
| AverageDiscountedReturn | 229        |
| AveragePhiLoss          | 21.9227    |
| AveragePolicyStd        | 0.617553   |
| AverageReturn           | 1.59e+03   |
| Entropy                 | 2.7563     |
| EnvExecTime             | 2.13       |
| ExplainedVariance       | 0.805      |
| Iteration               | 645        |
| ItrTime                 | 8.52       |
| LossAfter               | -0.965681  |
| LossBefore              | -0.942612  |
| MaxReturn               | 2.58e+03   |
| MeanKL                  | 0.00648062 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 836        |
| NumTrajs                | 10         |
| Perplexity              | 15.7415    |
| PolicyExecTime          | 0.547      |
| ProcessExecTime         | 0.0624     |
| StdReturn               | 519        |
| Time                    | 5.34e+03   |
| dLoss                   | 0.0230689  |
----------------------------------------
itr #646 | 
Mem: 718.402344
Obtaining samples...
Obtaining samples for iteration 646...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5519, #subsample_inputs: 5519
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.637      |
| AbsLearnSignalNew       | 0.637      |
| AbsLearningOld          | 0.637      |
| AverageDiscountedReturn | 239        |
| AveragePhiLoss          | 19.6947    |
| AveragePolicyStd        | 0.617339   |
| AverageReturn           | 1.55e+03   |
| Entropy                 | 2.75622    |
| EnvExecTime             | 2          |
| ExplainedVariance       | 0.672      |
| Iteration               | 646        |
| ItrTime                 | 8.53       |
| LossAfter               | -0.0365924 |
| LossBefore              | -0.0114426 |
| MaxReturn               | 1.99e+03   |
| MeanKL                  | 0.00999601 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.2e+03    |
| NumTrajs                | 11         |
| Perplexity              | 15.7402    |
| PolicyExecTime          | 0.516      |
| ProcessExecTime         | 0.0587     |
| StdReturn               | 247        |
| Time                    | 5.35e+03   |
| dLoss                   | 0.0251497  |
----------------------------------------
itr #647 | 
Mem: 719.593750
Obtaining samples...
Obtaining samples for iteration 647...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5111, #subsample_inputs: 5111
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.57       |
| AbsLearnSignalNew       | 0.57       |
| AbsLearningOld          | 0.57       |
| AverageDiscountedReturn | 235        |
| AveragePhiLoss          | 23.2914    |
| AveragePolicyStd        | 0.616442   |
| AverageReturn           | 1.75e+03   |
| Entropy                 | 2.75292    |
| EnvExecTime             | 1.93       |
| ExplainedVariance       | -0.265     |
| Iteration               | 647        |
| ItrTime                 | 8.03       |
| LossAfter               | -1.26961   |
| LossBefore              | -1.23882   |
| MaxReturn               | 2.65e+03   |
| MeanKL                  | 0.00990548 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.07e+03   |
| NumTrajs                | 9          |
| Perplexity              | 15.6884    |
| PolicyExecTime          | 0.495      |
| ProcessExecTime         | 0.0574     |
| StdReturn               | 581        |
| Time                    | 5.36e+03   |
| dLoss                   | 0.0307895  |
----------------------------------------
itr #648 | 
Mem: 719.691406
Obtaining samples...
Obtaining samples for iteration 648...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5001, #subsample_inputs: 5001
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.766      |
| AbsLearnSignalNew       | 0.766      |
| AbsLearningOld          | 0.766      |
| AverageDiscountedReturn | 233        |
| AveragePhiLoss          | 20.4024    |
| AveragePolicyStd        | 0.616683   |
| AverageReturn           | 1.28e+03   |
| Entropy                 | 2.75647    |
| EnvExecTime             | 1.91       |
| ExplainedVariance       | 0.856      |
| Iteration               | 648        |
| ItrTime                 | 7.9        |
| LossAfter               | 1.06563    |
| LossBefore              | 1.09163    |
| MaxReturn               | 1.71e+03   |
| MeanKL                  | 0.00999521 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 728        |
| NumTrajs                | 12         |
| Perplexity              | 15.7442    |
| PolicyExecTime          | 0.486      |
| ProcessExecTime         | 0.0549     |
| StdReturn               | 317        |
| Time                    | 5.36e+03   |
| dLoss                   | 0.0259987  |
----------------------------------------
itr #649 | 
Mem: 719.691406
Obtaining samples...
Obtaining samples for iteration 649...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5429, #subsample_inputs: 5429
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.662      |
| AbsLearnSignalNew       | 0.662      |
| AbsLearningOld          | 0.662      |
| AverageDiscountedReturn | 230        |
| AveragePhiLoss          | 20.0708    |
| AveragePolicyStd        | 0.619248   |
| AverageReturn           | 1.51e+03   |
| Entropy                 | 2.77026    |
| EnvExecTime             | 2.13       |
| ExplainedVariance       | 0.71       |
| Iteration               | 649        |
| ItrTime                 | 8.66       |
| LossAfter               | -0.846754  |
| LossBefore              | -0.823308  |
| MaxReturn               | 2.67e+03   |
| MeanKL                  | 0.00980818 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 532        |
| NumTrajs                | 11         |
| Perplexity              | 15.9628    |
| PolicyExecTime          | 0.544      |
| ProcessExecTime         | 0.0623     |
| StdReturn               | 546        |
| Time                    | 5.37e+03   |
| dLoss                   | 0.023446   |
----------------------------------------
itr #650 | 
Mem: 719.691406
Obtaining samples...
Obtaining samples for iteration 650...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5227, #subsample_inputs: 5227
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.762      |
| AbsLearnSignalNew       | 0.762      |
| AbsLearningOld          | 0.762      |
| AverageDiscountedReturn | 231        |
| AveragePhiLoss          | 20.1552    |
| AveragePolicyStd        | 0.619775   |
| AverageReturn           | 1.6e+03    |
| Entropy                 | 2.77258    |
| EnvExecTime             | 1.88       |
| ExplainedVariance       | 0.864      |
| Iteration               | 650        |
| ItrTime                 | 8.09       |
| LossAfter               | 0.156915   |
| LossBefore              | 0.178231   |
| MaxReturn               | 2.33e+03   |
| MeanKL                  | 0.00642437 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 948        |
| NumTrajs                | 10         |
| Perplexity              | 15.9998    |
| PolicyExecTime          | 0.485      |
| ProcessExecTime         | 0.0556     |
| StdReturn               | 447        |
| Time                    | 5.38e+03   |
| dLoss                   | 0.0213165  |
----------------------------------------
itr #651 | 
Mem: 719.691406
Obtaining samples...
Obtaining samples for iteration 651...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5291, #subsample_inputs: 5291
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.623      |
| AbsLearnSignalNew       | 0.623      |
| AbsLearningOld          | 0.623      |
| AverageDiscountedReturn | 233        |
| AveragePhiLoss          | 25.7581    |
| AveragePolicyStd        | 0.620255   |
| AverageReturn           | 1.36e+03   |
| Entropy                 | 2.77495    |
| EnvExecTime             | 2.13       |
| ExplainedVariance       | 0.725      |
| Iteration               | 651        |
| ItrTime                 | 8.49       |
| LossAfter               | 0.0524348  |
| LossBefore              | 0.076743   |
| MaxReturn               | 2.3e+03    |
| MeanKL                  | 0.00655367 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 574        |
| NumTrajs                | 12         |
| Perplexity              | 16.0379    |
| PolicyExecTime          | 0.549      |
| ProcessExecTime         | 0.0612     |
| StdReturn               | 427        |
| Time                    | 5.39e+03   |
| dLoss                   | 0.0243082  |
----------------------------------------
itr #652 | 
Mem: 719.691406
Obtaining samples...
Obtaining samples for iteration 652...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5161, #subsample_inputs: 5161
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.772      |
| AbsLearnSignalNew       | 0.772      |
| AbsLearningOld          | 0.772      |
| AverageDiscountedReturn | 234        |
| AveragePhiLoss          | 20.4005    |
| AveragePolicyStd        | 0.619617   |
| AverageReturn           | 1.45e+03   |
| Entropy                 | 2.77165    |
| EnvExecTime             | 1.96       |
| ExplainedVariance       | 0.838      |
| Iteration               | 652        |
| ItrTime                 | 8.16       |
| LossAfter               | -0.638707  |
| LossBefore              | -0.619809  |
| MaxReturn               | 2e+03      |
| MeanKL                  | 0.00640588 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 771        |
| NumTrajs                | 11         |
| Perplexity              | 15.985     |
| PolicyExecTime          | 0.502      |
| ProcessExecTime         | 0.0569     |
| StdReturn               | 340        |
| Time                    | 5.4e+03    |
| dLoss                   | 0.0188975  |
----------------------------------------
itr #653 | 
Mem: 719.691406
Obtaining samples...
Obtaining samples for iteration 653...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5514, #subsample_inputs: 5514
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.674      |
| AbsLearnSignalNew       | 0.674      |
| AbsLearningOld          | 0.674      |
| AverageDiscountedReturn | 234        |
| AveragePhiLoss          | 22.6896    |
| AveragePolicyStd        | 0.617314   |
| AverageReturn           | 1.68e+03   |
| Entropy                 | 2.7596     |
| EnvExecTime             | 1.88       |
| ExplainedVariance       | 0.781      |
| Iteration               | 653        |
| ItrTime                 | 8.31       |
| LossAfter               | 0.200111   |
| LossBefore              | 0.223105   |
| MaxReturn               | 2.91e+03   |
| MeanKL                  | 0.00652631 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.03e+03   |
| NumTrajs                | 10         |
| Perplexity              | 15.7936    |
| PolicyExecTime          | 0.487      |
| ProcessExecTime         | 0.056      |
| StdReturn               | 597        |
| Time                    | 5.41e+03   |
| dLoss                   | 0.0229943  |
----------------------------------------
itr #654 | 
Mem: 719.691406
Obtaining samples...
Obtaining samples for iteration 654...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5554, #subsample_inputs: 5554
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.743      |
| AbsLearnSignalNew       | 0.743      |
| AbsLearningOld          | 0.743      |
| AverageDiscountedReturn | 235        |
| AveragePhiLoss          | 20.9047    |
| AveragePolicyStd        | 0.616567   |
| AverageReturn           | 1.33e+03   |
| Entropy                 | 2.7559     |
| EnvExecTime             | 2.5        |
| ExplainedVariance       | 0.884      |
| Iteration               | 654        |
| ItrTime                 | 9.21       |
| LossAfter               | 0.231025   |
| LossBefore              | 0.251035   |
| MaxReturn               | 2.09e+03   |
| MeanKL                  | 0.00641907 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 976        |
| NumTrajs                | 13         |
| Perplexity              | 15.7351    |
| PolicyExecTime          | 0.619      |
| ProcessExecTime         | 0.0717     |
| StdReturn               | 343        |
| Time                    | 5.41e+03   |
| dLoss                   | 0.0200107  |
----------------------------------------
itr #655 | 
Mem: 719.691406
Obtaining samples...
Obtaining samples for iteration 655...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5284, #subsample_inputs: 5284
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.772      |
| AbsLearnSignalNew       | 0.772      |
| AbsLearningOld          | 0.772      |
| AverageDiscountedReturn | 241        |
| AveragePhiLoss          | 20.3751    |
| AveragePolicyStd        | 0.616576   |
| AverageReturn           | 1.2e+03    |
| Entropy                 | 2.75705    |
| EnvExecTime             | 2.01       |
| ExplainedVariance       | 0.912      |
| Iteration               | 655        |
| ItrTime                 | 8.26       |
| LossAfter               | 0.559347   |
| LossBefore              | 0.578664   |
| MaxReturn               | 1.61e+03   |
| MeanKL                  | 0.00647254 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 978        |
| NumTrajs                | 14         |
| Perplexity              | 15.7532    |
| PolicyExecTime          | 0.513      |
| ProcessExecTime         | 0.0601     |
| StdReturn               | 213        |
| Time                    | 5.42e+03   |
| dLoss                   | 0.0193172  |
----------------------------------------
itr #656 | 
Mem: 719.691406
Obtaining samples...
Obtaining samples for iteration 656...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5529, #subsample_inputs: 5529
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.747      |
| AbsLearnSignalNew       | 0.747      |
| AbsLearningOld          | 0.747      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 21.9853    |
| AveragePolicyStd        | 0.615869   |
| AverageReturn           | 1.44e+03   |
| Entropy                 | 2.75516    |
| EnvExecTime             | 2.08       |
| ExplainedVariance       | 0.899      |
| Iteration               | 656        |
| ItrTime                 | 8.59       |
| LossAfter               | -0.194002  |
| LossBefore              | -0.17593   |
| MaxReturn               | 2.16e+03   |
| MeanKL                  | 0.00642867 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.06e+03   |
| NumTrajs                | 12         |
| Perplexity              | 15.7235    |
| PolicyExecTime          | 0.536      |
| ProcessExecTime         | 0.0599     |
| StdReturn               | 349        |
| Time                    | 5.43e+03   |
| dLoss                   | 0.0180719  |
----------------------------------------
itr #657 | 
Mem: 719.691406
Obtaining samples...
Obtaining samples for iteration 657...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5017, #subsample_inputs: 5017
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.61       |
| AbsLearnSignalNew       | 0.61       |
| AbsLearningOld          | 0.61       |
| AverageDiscountedReturn | 219        |
| AveragePhiLoss          | 22.2934    |
| AveragePolicyStd        | 0.6146     |
| AverageReturn           | 1.26e+03   |
| Entropy                 | 2.74944    |
| EnvExecTime             | 1.77       |
| ExplainedVariance       | 0.648      |
| Iteration               | 657        |
| ItrTime                 | 7.8        |
| LossAfter               | -0.125943  |
| LossBefore              | -0.0982093 |
| MaxReturn               | 2.2e+03    |
| MeanKL                  | 0.00647098 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 242        |
| NumTrajs                | 12         |
| Perplexity              | 15.6339    |
| PolicyExecTime          | 0.451      |
| ProcessExecTime         | 0.055      |
| StdReturn               | 563        |
| Time                    | 5.44e+03   |
| dLoss                   | 0.0277341  |
----------------------------------------
itr #658 | 
Mem: 719.691406
Obtaining samples...
Obtaining samples for iteration 658...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5120, #subsample_inputs: 5120
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.672     |
| AbsLearnSignalNew       | 0.672     |
| AbsLearningOld          | 0.672     |
| AverageDiscountedReturn | 231       |
| AveragePhiLoss          | 17.9157   |
| AveragePolicyStd        | 0.614323  |
| AverageReturn           | 1.41e+03  |
| Entropy                 | 2.74875   |
| EnvExecTime             | 2.25      |
| ExplainedVariance       | 0.714     |
| Iteration               | 658       |
| ItrTime                 | 8.46      |
| LossAfter               | 0.407506  |
| LossBefore              | 0.431262  |
| MaxReturn               | 2.22e+03  |
| MeanKL                  | 0.0064461 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 521       |
| NumTrajs                | 11        |
| Perplexity              | 15.6231   |
| PolicyExecTime          | 0.562     |
| ProcessExecTime         | 0.0633    |
| StdReturn               | 501       |
| Time                    | 5.45e+03  |
| dLoss                   | 0.0237561 |
---------------------------------------
itr #659 | 
Mem: 719.691406
Obtaining samples...
Obtaining samples for iteration 659...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5192, #subsample_inputs: 5192
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.722      |
| AbsLearnSignalNew       | 0.722      |
| AbsLearningOld          | 0.722      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 20.2978    |
| AveragePolicyStd        | 0.613243   |
| AverageReturn           | 1.26e+03   |
| Entropy                 | 2.74493    |
| EnvExecTime             | 1.86       |
| ExplainedVariance       | 0.815      |
| Iteration               | 659        |
| ItrTime                 | 8.08       |
| LossAfter               | 0.115853   |
| LossBefore              | 0.142111   |
| MaxReturn               | 2.03e+03   |
| MeanKL                  | 0.00984569 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 568        |
| NumTrajs                | 13         |
| Perplexity              | 15.5635    |
| PolicyExecTime          | 0.472      |
| ProcessExecTime         | 0.0555     |
| StdReturn               | 325        |
| Time                    | 5.46e+03   |
| dLoss                   | 0.0262586  |
----------------------------------------
itr #660 | 
Mem: 719.691406
Obtaining samples...
Obtaining samples for iteration 660...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5463, #subsample_inputs: 5463
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.787      |
| AbsLearnSignalNew       | 0.787      |
| AbsLearningOld          | 0.787      |
| AverageDiscountedReturn | 235        |
| AveragePhiLoss          | 21.8756    |
| AveragePolicyStd        | 0.613954   |
| AverageReturn           | 1.53e+03   |
| Entropy                 | 2.74816    |
| EnvExecTime             | 2.14       |
| ExplainedVariance       | 0.877      |
| Iteration               | 660        |
| ItrTime                 | 8.55       |
| LossAfter               | -0.07263   |
| LossBefore              | -0.0497098 |
| MaxReturn               | 2.12e+03   |
| MeanKL                  | 0.00999515 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.02e+03   |
| NumTrajs                | 11         |
| Perplexity              | 15.6138    |
| PolicyExecTime          | 0.556      |
| ProcessExecTime         | 0.0624     |
| StdReturn               | 395        |
| Time                    | 5.46e+03   |
| dLoss                   | 0.0229202  |
----------------------------------------
itr #661 | 
Mem: 719.691406
Obtaining samples...
Obtaining samples for iteration 661...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5615, #subsample_inputs: 5615
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.733      |
| AbsLearnSignalNew       | 0.733      |
| AbsLearningOld          | 0.733      |
| AverageDiscountedReturn | 235        |
| AveragePhiLoss          | 22.2891    |
| AveragePolicyStd        | 0.610889   |
| AverageReturn           | 1.44e+03   |
| Entropy                 | 2.73102    |
| EnvExecTime             | 2.16       |
| ExplainedVariance       | 0.859      |
| Iteration               | 661        |
| ItrTime                 | 8.74       |
| LossAfter               | -0.321111  |
| LossBefore              | -0.295222  |
| MaxReturn               | 2.38e+03   |
| MeanKL                  | 0.00999929 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 901        |
| NumTrajs                | 12         |
| Perplexity              | 15.3485    |
| PolicyExecTime          | 0.554      |
| ProcessExecTime         | 0.0633     |
| StdReturn               | 382        |
| Time                    | 5.47e+03   |
| dLoss                   | 0.0258891  |
----------------------------------------
itr #662 | 
Mem: 720.066406
Obtaining samples...
Obtaining samples for iteration 662...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5295, #subsample_inputs: 5295
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.753     |
| AbsLearnSignalNew       | 0.753     |
| AbsLearningOld          | 0.754     |
| AverageDiscountedReturn | 241       |
| AveragePhiLoss          | 20.2581   |
| AveragePolicyStd        | 0.611418  |
| AverageReturn           | 1.3e+03   |
| Entropy                 | 2.7331    |
| EnvExecTime             | 1.98      |
| ExplainedVariance       | 0.904     |
| Iteration               | 662       |
| ItrTime                 | 8.31      |
| LossAfter               | -0.514521 |
| LossBefore              | -0.486422 |
| MaxReturn               | 1.74e+03  |
| MeanKL                  | 0.0099714 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 973       |
| NumTrajs                | 13        |
| Perplexity              | 15.3805   |
| PolicyExecTime          | 0.515     |
| ProcessExecTime         | 0.0576    |
| StdReturn               | 233       |
| Time                    | 5.48e+03  |
| dLoss                   | 0.0280986 |
---------------------------------------
itr #663 | 
Mem: 720.066406
Obtaining samples...
Obtaining samples for iteration 663...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5005, #subsample_inputs: 5005
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.748      |
| AbsLearnSignalNew       | 0.748      |
| AbsLearningOld          | 0.748      |
| AverageDiscountedReturn | 238        |
| AveragePhiLoss          | 22.1729    |
| AveragePolicyStd        | 0.613191   |
| AverageReturn           | 1.42e+03   |
| Entropy                 | 2.7401     |
| EnvExecTime             | 1.93       |
| ExplainedVariance       | 0.862      |
| Iteration               | 663        |
| ItrTime                 | 7.97       |
| LossAfter               | 0.316782   |
| LossBefore              | 0.345145   |
| MaxReturn               | 2.22e+03   |
| MeanKL                  | 0.00988292 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.01e+03   |
| NumTrajs                | 11         |
| Perplexity              | 15.4885    |
| PolicyExecTime          | 0.495      |
| ProcessExecTime         | 0.055      |
| StdReturn               | 349        |
| Time                    | 5.49e+03   |
| dLoss                   | 0.0283629  |
----------------------------------------
itr #664 | 
Mem: 720.066406
Obtaining samples...
Obtaining samples for iteration 664...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5259, #subsample_inputs: 5259
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.788     |
| AbsLearnSignalNew       | 0.788     |
| AbsLearningOld          | 0.787     |
| AverageDiscountedReturn | 242       |
| AveragePhiLoss          | 20.4233   |
| AveragePolicyStd        | 0.615747  |
| AverageReturn           | 1.2e+03   |
| Entropy                 | 2.75119   |
| EnvExecTime             | 1.94      |
| ExplainedVariance       | 0.901     |
| Iteration               | 664       |
| ItrTime                 | 8.2       |
| LossAfter               | 0.158924  |
| LossBefore              | 0.185872  |
| MaxReturn               | 1.97e+03  |
| MeanKL                  | 0.009969  |
| MeanKLBefore            | 0.0       |
| MinReturn               | 955       |
| NumTrajs                | 14        |
| Perplexity              | 15.6612   |
| PolicyExecTime          | 0.491     |
| ProcessExecTime         | 0.059     |
| StdReturn               | 244       |
| Time                    | 5.5e+03   |
| dLoss                   | 0.0269479 |
---------------------------------------
itr #665 | 
Mem: 720.066406
Obtaining samples...
Obtaining samples for iteration 665...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5029, #subsample_inputs: 5029
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.629      |
| AbsLearnSignalNew       | 0.629      |
| AbsLearningOld          | 0.629      |
| AverageDiscountedReturn | 228        |
| AveragePhiLoss          | 20.9087    |
| AveragePolicyStd        | 0.616265   |
| AverageReturn           | 1.12e+03   |
| Entropy                 | 2.75249    |
| EnvExecTime             | 1.81       |
| ExplainedVariance       | 0.702      |
| Iteration               | 665        |
| ItrTime                 | 7.83       |
| LossAfter               | -0.697351  |
| LossBefore              | -0.673005  |
| MaxReturn               | 1.74e+03   |
| MeanKL                  | 0.00982481 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 189        |
| NumTrajs                | 14         |
| Perplexity              | 15.6817    |
| PolicyExecTime          | 0.465      |
| ProcessExecTime         | 0.0535     |
| StdReturn               | 406        |
| Time                    | 5.51e+03   |
| dLoss                   | 0.0243456  |
----------------------------------------
itr #666 | 
Mem: 720.066406
Obtaining samples...
Obtaining samples for iteration 666...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 7606, #inputs: 5352, #subsample_inputs: 5352
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.684     |
| AbsLearnSignalNew       | 0.684     |
| AbsLearningOld          | 0.684     |
| AverageDiscountedReturn | 239       |
| AveragePhiLoss          | 18.9198   |
| AveragePolicyStd        | 0.619859  |
| AverageReturn           | 1.21e+03  |
| Entropy                 | 2.76857   |
| EnvExecTime             | 1.72      |
| ExplainedVariance       | 0.752     |
| Iteration               | 666       |
| ItrTime                 | 8.04      |
| LossAfter               | 0.288312  |
| LossBefore              | 0.30806   |
| MaxReturn               | 2.24e+03  |
| MeanKL                  | 0.0064894 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 747       |
| NumTrajs                | 14        |
| Perplexity              | 15.9358   |
| PolicyExecTime          | 0.444     |
| ProcessExecTime         | 0.053     |
| StdReturn               | 329       |
| Time                    | 5.51e+03  |
| dLoss                   | 0.0197475 |
---------------------------------------
itr #667 | 
Mem: 720.066406
Obtaining samples...
Obtaining samples for iteration 667...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
