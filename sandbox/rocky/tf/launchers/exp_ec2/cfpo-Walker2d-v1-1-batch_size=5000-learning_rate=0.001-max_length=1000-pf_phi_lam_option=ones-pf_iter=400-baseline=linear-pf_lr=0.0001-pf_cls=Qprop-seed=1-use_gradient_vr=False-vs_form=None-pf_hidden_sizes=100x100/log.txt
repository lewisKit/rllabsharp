output_formats ['stdout', 'log', 'json', 'tensorboard']
Logging to exp_ec2/cfpo-Walker2d-v1-1-batch_size=5000-learning_rate=0.001-max_length=1000-pf_phi_lam_option=ones-pf_iter=400-baseline=linear-pf_lr=0.0001-pf_cls=Qprop-seed=1-use_gradient_vr=False-vs_form=None-pf_hidden_sizes=100x100
Setting seed to 1
Setting seed to 2
Setting seed to 4
Setting seed to 3
observation space: Box(17,)
action space: Box(6,)
use_gradient_vr is False
pf_learning_rate is 0.0001
observation space: Box(17,)
action space: Box(6,)
observation space: Box(17,)
action space: Box(6,)
observation space: Box(17,)
action space: Box(6,)
observation space: Box(17,)
action space: Box(6,)
observation space: Box(17,)
action space: Box(6,)
qf is None
using reward as variance reduction
parameter of phi Phinet/obs_h0/W:0, shape=(17, 100)
parameter of phi Phinet/obs_h0/b:0, shape=(100,)
parameter of phi Phinet/act_h0/W:0, shape=(6, 100)
parameter of phi Phinet/act_h0/b:0, shape=(100,)
parameter of phi Phinet/h1/W:0, shape=(100, 100)
parameter of phi Phinet/h1/b:0, shape=(100,)
parameter of phi Phinet/output/W:0, shape=(100, 1)
parameter of phi Phinet/output/b:0, shape=(1,)
No checkpoint exp_ec2/cfpo-Walker2d-v1-1-batch_size=5000-learning_rate=0.001-max_length=1000-pf_phi_lam_option=ones-pf_iter=400-baseline=linear-pf_lr=0.0001-pf_cls=Qprop-seed=1-use_gradient_vr=False-vs_form=None-pf_hidden_sizes=100x100/params.chk
itr #0 | 
Mem: 264.695312
Obtaining samples...
Obtaining samples for iteration 0...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5021, #subsample_inputs: 5021
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.788      |
| AbsLearnSignalNew       | 0.788      |
| AbsLearningOld          | 0.787      |
| AverageDiscountedReturn | -2.99      |
| AveragePhiLoss          | 0.964102   |
| AveragePolicyStd        | 1.0        |
| AverageReturn           | -4.13      |
| Entropy                 | 8.51363    |
| EnvExecTime             | 2.21       |
| ExplainedVariance       | 3.38e-10   |
| Iteration               | 0          |
| ItrTime                 | 8.67       |
| LossAfter               | -0.151472  |
| LossBefore              | -0.0918141 |
| MaxReturn               | 19.2       |
| MeanKL                  | 0.00644247 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -19.2      |
| NumTrajs                | 209        |
| Perplexity              | 4982.22    |
| PolicyExecTime          | 0.473      |
| ProcessExecTime         | 0.071      |
| StdReturn               | 6.28       |
| Time                    | 8.67       |
| dLoss                   | 0.0596577  |
----------------------------------------
itr #1 | 
Mem: 607.718750
Obtaining samples...
Obtaining samples for iteration 1...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5016, #subsample_inputs: 5016
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.68       |
| AbsLearnSignalNew       | 0.68       |
| AbsLearningOld          | 0.682      |
| AverageDiscountedReturn | -1.59      |
| AveragePhiLoss          | 0.943005   |
| AveragePolicyStd        | 1.00036    |
| AverageReturn           | -2.62      |
| Entropy                 | 8.51579    |
| EnvExecTime             | 2.16       |
| ExplainedVariance       | 0.172      |
| Iteration               | 1          |
| ItrTime                 | 8.98       |
| LossAfter               | 0.12322    |
| LossBefore              | 0.18358    |
| MaxReturn               | 64.9       |
| MeanKL                  | 0.00654025 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -17.6      |
| NumTrajs                | 200        |
| Perplexity              | 4992.96    |
| PolicyExecTime          | 0.441      |
| ProcessExecTime         | 0.0695     |
| StdReturn               | 7.8        |
| Time                    | 17.7       |
| dLoss                   | 0.0603595  |
----------------------------------------
itr #2 | 
Mem: 615.878906
Obtaining samples...
Obtaining samples for iteration 2...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5003, #subsample_inputs: 5003
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.78       |
| AbsLearnSignalNew       | 0.78       |
| AbsLearningOld          | 0.78       |
| AverageDiscountedReturn | -0.352     |
| AveragePhiLoss          | 0.93233    |
| AveragePolicyStd        | 0.999205   |
| AverageReturn           | -1.46      |
| Entropy                 | 8.50882    |
| EnvExecTime             | 2.49       |
| ExplainedVariance       | 0.265      |
| Iteration               | 2          |
| ItrTime                 | 10.7       |
| LossAfter               | 0.322747   |
| LossBefore              | 0.383337   |
| MaxReturn               | 21.2       |
| MeanKL                  | 0.00643355 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -15.8      |
| NumTrajs                | 190        |
| Perplexity              | 4958.3     |
| PolicyExecTime          | 0.558      |
| ProcessExecTime         | 0.0909     |
| StdReturn               | 6.46       |
| Time                    | 28.5       |
| dLoss                   | 0.0605898  |
----------------------------------------
itr #3 | 
Mem: 643.941406
Obtaining samples...
Obtaining samples for iteration 3...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5022, #subsample_inputs: 5022
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.747      |
| AbsLearnSignalNew       | 0.747      |
| AbsLearningOld          | 0.75       |
| AverageDiscountedReturn | 0.645      |
| AveragePhiLoss          | 0.920685   |
| AveragePolicyStd        | 0.999597   |
| AverageReturn           | -0.39      |
| Entropy                 | 8.51116    |
| EnvExecTime             | 2.2        |
| ExplainedVariance       | 0.302      |
| Iteration               | 3          |
| ItrTime                 | 9.97       |
| LossAfter               | -0.400247  |
| LossBefore              | -0.337643  |
| MaxReturn               | 24.3       |
| MeanKL                  | 0.00649748 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -15.2      |
| NumTrajs                | 180        |
| Perplexity              | 4969.9     |
| PolicyExecTime          | 0.469      |
| ProcessExecTime         | 0.0746     |
| StdReturn               | 6.99       |
| Time                    | 38.5       |
| dLoss                   | 0.0626039  |
----------------------------------------
itr #4 | 
Mem: 651.906250
Obtaining samples...
Obtaining samples for iteration 4...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5026, #subsample_inputs: 5026
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.708      |
| AbsLearnSignalNew       | 0.708      |
| AbsLearningOld          | 0.71       |
| AverageDiscountedReturn | 2.5        |
| AveragePhiLoss          | 0.94396    |
| AveragePolicyStd        | 0.998271   |
| AverageReturn           | 1.66       |
| Entropy                 | 8.50317    |
| EnvExecTime             | 2.51       |
| ExplainedVariance       | 0.238      |
| Iteration               | 4          |
| ItrTime                 | 10.4       |
| LossAfter               | -0.177934  |
| LossBefore              | -0.108943  |
| MaxReturn               | 52.8       |
| MeanKL                  | 0.00984593 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -12.5      |
| NumTrajs                | 167        |
| Perplexity              | 4930.39    |
| PolicyExecTime          | 0.574      |
| ProcessExecTime         | 0.089      |
| StdReturn               | 7.97       |
| Time                    | 48.9       |
| dLoss                   | 0.0689907  |
----------------------------------------
itr #5 | 
Mem: 659.871094
Obtaining samples...
Obtaining samples for iteration 5...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5011, #subsample_inputs: 5011
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.785      |
| AbsLearnSignalNew       | 0.785      |
| AbsLearningOld          | 0.786      |
| AverageDiscountedReturn | 4.63       |
| AveragePhiLoss          | 0.937778   |
| AveragePolicyStd        | 0.999054   |
| AverageReturn           | 4.34       |
| Entropy                 | 8.50784    |
| EnvExecTime             | 2.39       |
| ExplainedVariance       | 0.261      |
| Iteration               | 5          |
| ItrTime                 | 10.6       |
| LossAfter               | 0.60618    |
| LossBefore              | 0.663119   |
| MaxReturn               | 32.6       |
| MeanKL                  | 0.00643758 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -15        |
| NumTrajs                | 163        |
| Perplexity              | 4953.43    |
| PolicyExecTime          | 0.526      |
| ProcessExecTime         | 0.0791     |
| StdReturn               | 8.03       |
| Time                    | 59.6       |
| dLoss                   | 0.056939   |
----------------------------------------
itr #6 | 
Mem: 662.964844
Obtaining samples...
Obtaining samples for iteration 6...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5004, #subsample_inputs: 5004
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.764      |
| AbsLearnSignalNew       | 0.764      |
| AbsLearningOld          | 0.765      |
| AverageDiscountedReturn | 5.21       |
| AveragePhiLoss          | 0.935373   |
| AveragePolicyStd        | 0.996167   |
| AverageReturn           | 4.77       |
| Entropy                 | 8.49031    |
| EnvExecTime             | 2.5        |
| ExplainedVariance       | 0.331      |
| Iteration               | 6          |
| ItrTime                 | 9.71       |
| LossAfter               | 0.0701596  |
| LossBefore              | 0.138749   |
| MaxReturn               | 38.7       |
| MeanKL                  | 0.00988392 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -11.7      |
| NumTrajs                | 157        |
| Perplexity              | 4867.39    |
| PolicyExecTime          | 0.556      |
| ProcessExecTime         | 0.089      |
| StdReturn               | 8.23       |
| Time                    | 69.5       |
| dLoss                   | 0.0685893  |
----------------------------------------
itr #7 | 
Mem: 666.574219
Obtaining samples...
Obtaining samples for iteration 7...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5028, #subsample_inputs: 5028
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.795      |
| AbsLearnSignalNew       | 0.795      |
| AbsLearningOld          | 0.794      |
| AverageDiscountedReturn | 7.57       |
| AveragePhiLoss          | 0.939716   |
| AveragePolicyStd        | 0.992527   |
| AverageReturn           | 7.57       |
| Entropy                 | 8.46826    |
| EnvExecTime             | 2.52       |
| ExplainedVariance       | 0.276      |
| Iteration               | 7          |
| ItrTime                 | 10.8       |
| LossAfter               | 0.961668   |
| LossBefore              | 1.01822    |
| MaxReturn               | 47.3       |
| MeanKL                  | 0.00642828 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -14.6      |
| NumTrajs                | 135        |
| Perplexity              | 4761.22    |
| PolicyExecTime          | 0.57       |
| ProcessExecTime         | 0.0884     |
| StdReturn               | 9.95       |
| Time                    | 80.2       |
| dLoss                   | 0.0565518  |
----------------------------------------
itr #8 | 
Mem: 667.347656
Obtaining samples...
Obtaining samples for iteration 8...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5021, #subsample_inputs: 5021
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.749      |
| AbsLearnSignalNew       | 0.749      |
| AbsLearningOld          | 0.749      |
| AverageDiscountedReturn | 7.85       |
| AveragePhiLoss          | 0.938469   |
| AveragePolicyStd        | 0.991573   |
| AverageReturn           | 7.83       |
| Entropy                 | 8.46251    |
| EnvExecTime             | 2.27       |
| ExplainedVariance       | 0.319      |
| Iteration               | 8          |
| ItrTime                 | 10         |
| LossAfter               | 0.598185   |
| LossBefore              | 0.654787   |
| MaxReturn               | 59.6       |
| MeanKL                  | 0.00644014 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -18.8      |
| NumTrajs                | 135        |
| Perplexity              | 4733.92    |
| PolicyExecTime          | 0.493      |
| ProcessExecTime         | 0.0767     |
| StdReturn               | 11.8       |
| Time                    | 90.4       |
| dLoss                   | 0.0566026  |
----------------------------------------
itr #9 | 
Mem: 669.410156
Obtaining samples...
Obtaining samples for iteration 9...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5023, #subsample_inputs: 5023
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.737      |
| AbsLearnSignalNew       | 0.737      |
| AbsLearningOld          | 0.737      |
| AverageDiscountedReturn | 9.92       |
| AveragePhiLoss          | 0.939443   |
| AveragePolicyStd        | 0.990138   |
| AverageReturn           | 10.7       |
| Entropy                 | 8.45374    |
| EnvExecTime             | 2.5        |
| ExplainedVariance       | 0.198      |
| Iteration               | 9          |
| ItrTime                 | 10.4       |
| LossAfter               | -0.0137662 |
| LossBefore              | 0.052662   |
| MaxReturn               | 99.9       |
| MeanKL                  | 0.00998583 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -16.6      |
| NumTrajs                | 132        |
| Perplexity              | 4692.61    |
| PolicyExecTime          | 0.565      |
| ProcessExecTime         | 0.0876     |
| StdReturn               | 13         |
| Time                    | 101        |
| dLoss                   | 0.0664281  |
----------------------------------------
itr #10 | 
Mem: 673.269531
Obtaining samples...
Obtaining samples for iteration 10...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5140, #subsample_inputs: 5140
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.682      |
| AbsLearnSignalNew       | 0.682      |
| AbsLearningOld          | 0.682      |
| AverageDiscountedReturn | 15         |
| AveragePhiLoss          | 0.954305   |
| AveragePolicyStd        | 0.990328   |
| AverageReturn           | 19.8       |
| Entropy                 | 8.4549     |
| EnvExecTime             | 2.16       |
| ExplainedVariance       | 0.17       |
| Iteration               | 10         |
| ItrTime                 | 10.3       |
| LossAfter               | -0.522694  |
| LossBefore              | -0.453798  |
| MaxReturn               | 326        |
| MeanKL                  | 0.00986332 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -13.4      |
| NumTrajs                | 109        |
| Perplexity              | 4698.02    |
| PolicyExecTime          | 0.482      |
| ProcessExecTime         | 0.0715     |
| StdReturn               | 39.2       |
| Time                    | 111        |
| dLoss                   | 0.0688957  |
----------------------------------------
itr #11 | 
Mem: 676.617188
Obtaining samples...
Obtaining samples for iteration 11...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5004, #subsample_inputs: 5004
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.712      |
| AbsLearnSignalNew       | 0.712      |
| AbsLearningOld          | 0.713      |
| AverageDiscountedReturn | 16         |
| AveragePhiLoss          | 0.9456     |
| AveragePolicyStd        | 0.989509   |
| AverageReturn           | 19.7       |
| Entropy                 | 8.44998    |
| EnvExecTime             | 2.52       |
| ExplainedVariance       | 0.0917     |
| Iteration               | 11         |
| ItrTime                 | 9.56       |
| LossAfter               | 0.616423   |
| LossBefore              | 0.682029   |
| MaxReturn               | 179        |
| MeanKL                  | 0.00985121 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -8.95      |
| NumTrajs                | 108        |
| Perplexity              | 4674.99    |
| PolicyExecTime          | 0.575      |
| ProcessExecTime         | 0.0865     |
| StdReturn               | 27.4       |
| Time                    | 121        |
| dLoss                   | 0.0656058  |
----------------------------------------
itr #12 | 
Mem: 676.871094
Obtaining samples...
Obtaining samples for iteration 12...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5067, #subsample_inputs: 5067
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.462      |
| AbsLearnSignalNew       | 0.462      |
| AbsLearningOld          | 0.462      |
| AverageDiscountedReturn | 19.9       |
| AveragePhiLoss          | 0.961399   |
| AveragePolicyStd        | 0.984433   |
| AverageReturn           | 27.8       |
| Entropy                 | 8.41896    |
| EnvExecTime             | 2.51       |
| ExplainedVariance       | -1.47      |
| Iteration               | 12         |
| ItrTime                 | 10.7       |
| LossAfter               | -0.176371  |
| LossBefore              | -0.112341  |
| MaxReturn               | 263        |
| MeanKL                  | 0.00641998 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -7.01      |
| NumTrajs                | 88         |
| Perplexity              | 4532.19    |
| PolicyExecTime          | 0.587      |
| ProcessExecTime         | 0.0855     |
| StdReturn               | 42.6       |
| Time                    | 132        |
| dLoss                   | 0.06403    |
----------------------------------------
itr #13 | 
Mem: 682.269531
Obtaining samples...
Obtaining samples for iteration 13...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5069, #subsample_inputs: 5069
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.717      |
| AbsLearnSignalNew       | 0.717      |
| AbsLearningOld          | 0.717      |
| AverageDiscountedReturn | 16.8       |
| AveragePhiLoss          | 0.961272   |
| AveragePolicyStd        | 0.98362    |
| AverageReturn           | 21.2       |
| Entropy                 | 8.41419    |
| EnvExecTime             | 2.37       |
| ExplainedVariance       | 0.258      |
| Iteration               | 13         |
| ItrTime                 | 9.79       |
| LossAfter               | 0.354851   |
| LossBefore              | 0.416384   |
| MaxReturn               | 229        |
| MeanKL                  | 0.00981727 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -7.09      |
| NumTrajs                | 95         |
| Perplexity              | 4510.61    |
| PolicyExecTime          | 0.53       |
| ProcessExecTime         | 0.0803     |
| StdReturn               | 31.7       |
| Time                    | 142        |
| dLoss                   | 0.0615323  |
----------------------------------------
itr #14 | 
Mem: 685.613281
Obtaining samples...
Obtaining samples for iteration 14...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5040, #subsample_inputs: 5040
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.723      |
| AbsLearnSignalNew       | 0.723      |
| AbsLearningOld          | 0.723      |
| AverageDiscountedReturn | 20.1       |
| AveragePhiLoss          | 0.937906   |
| AveragePolicyStd        | 0.983251   |
| AverageReturn           | 25.8       |
| Entropy                 | 8.41188    |
| EnvExecTime             | 2.53       |
| ExplainedVariance       | 0.173      |
| Iteration               | 14         |
| ItrTime                 | 10.6       |
| LossAfter               | -0.288585  |
| LossBefore              | -0.219663  |
| MaxReturn               | 188        |
| MeanKL                  | 0.00991779 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -5.29      |
| NumTrajs                | 84         |
| Perplexity              | 4500.21    |
| PolicyExecTime          | 0.585      |
| ProcessExecTime         | 0.0857     |
| StdReturn               | 30.8       |
| Time                    | 152        |
| dLoss                   | 0.0689214  |
----------------------------------------
itr #15 | 
Mem: 686.125000
Obtaining samples...
Obtaining samples for iteration 15...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5100, #subsample_inputs: 5100
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.749     |
| AbsLearnSignalNew       | 0.749     |
| AbsLearningOld          | 0.749     |
| AverageDiscountedReturn | 28.3      |
| AveragePhiLoss          | 0.956864  |
| AveragePolicyStd        | 0.984936  |
| AverageReturn           | 43.3      |
| Entropy                 | 8.42203   |
| EnvExecTime             | 2.26      |
| ExplainedVariance       | 0.304     |
| Iteration               | 15        |
| ItrTime                 | 10.7      |
| LossAfter               | 0.289649  |
| LossBefore              | 0.353445  |
| MaxReturn               | 300       |
| MeanKL                  | 0.0098949 |
| MeanKLBefore            | 0.0       |
| MinReturn               | -0.0377   |
| NumTrajs                | 73        |
| Perplexity              | 4546.12   |
| PolicyExecTime          | 0.501     |
| ProcessExecTime         | 0.0723    |
| StdReturn               | 63.6      |
| Time                    | 163       |
| dLoss                   | 0.063796  |
---------------------------------------
itr #16 | 
Mem: 689.730469
Obtaining samples...
Obtaining samples for iteration 16...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5001, #subsample_inputs: 5001
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.77       |
| AbsLearnSignalNew       | 0.77       |
| AbsLearningOld          | 0.77       |
| AverageDiscountedReturn | 38.4       |
| AveragePhiLoss          | 0.954235   |
| AveragePolicyStd        | 0.984515   |
| AverageReturn           | 62.5       |
| Entropy                 | 8.41955    |
| EnvExecTime             | 2.44       |
| ExplainedVariance       | 0.293      |
| Iteration               | 16         |
| ItrTime                 | 9.56       |
| LossAfter               | -0.425012  |
| LossBefore              | -0.37375   |
| MaxReturn               | 285        |
| MeanKL                  | 0.00647718 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 2.32       |
| NumTrajs                | 60         |
| Perplexity              | 4534.87    |
| PolicyExecTime          | 0.567      |
| ProcessExecTime         | 0.0835     |
| StdReturn               | 70.5       |
| Time                    | 173        |
| dLoss                   | 0.0512613  |
----------------------------------------
itr #17 | 
Mem: 691.019531
Obtaining samples...
Obtaining samples for iteration 17...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5251, #subsample_inputs: 5251
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.773      |
| AbsLearnSignalNew       | 0.773      |
| AbsLearningOld          | 0.773      |
| AverageDiscountedReturn | 30.2       |
| AveragePhiLoss          | 0.950367   |
| AveragePolicyStd        | 0.983185   |
| AverageReturn           | 45.9       |
| Entropy                 | 8.41132    |
| EnvExecTime             | 2.54       |
| ExplainedVariance       | 0.355      |
| Iteration               | 17         |
| ItrTime                 | 11.1       |
| LossAfter               | 0.587467   |
| LossBefore              | 0.638919   |
| MaxReturn               | 251        |
| MeanKL                  | 0.00642799 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -6.84      |
| NumTrajs                | 70         |
| Perplexity              | 4497.68    |
| PolicyExecTime          | 0.583      |
| ProcessExecTime         | 0.0843     |
| StdReturn               | 61.2       |
| Time                    | 184        |
| dLoss                   | 0.0514518  |
----------------------------------------
itr #18 | 
Mem: 708.363281
Obtaining samples...
Obtaining samples for iteration 18...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5173, #subsample_inputs: 5173
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.792      |
| AbsLearnSignalNew       | 0.792      |
| AbsLearningOld          | 0.792      |
| AverageDiscountedReturn | 33.4       |
| AveragePhiLoss          | 0.956866   |
| AveragePolicyStd        | 0.984121   |
| AverageReturn           | 52.6       |
| Entropy                 | 8.41705    |
| EnvExecTime             | 2.46       |
| ExplainedVariance       | 0.301      |
| Iteration               | 18         |
| ItrTime                 | 10.2       |
| LossAfter               | 0.553467   |
| LossBefore              | 0.614867   |
| MaxReturn               | 309        |
| MeanKL                  | 0.00999527 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -0.237     |
| NumTrajs                | 58         |
| Perplexity              | 4523.52    |
| PolicyExecTime          | 0.551      |
| ProcessExecTime         | 0.0806     |
| StdReturn               | 60.9       |
| Time                    | 194        |
| dLoss                   | 0.0613999  |
----------------------------------------
itr #19 | 
Mem: 710.164062
Obtaining samples...
Obtaining samples for iteration 19...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5059, #subsample_inputs: 5059
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.787      |
| AbsLearnSignalNew       | 0.787      |
| AbsLearningOld          | 0.787      |
| AverageDiscountedReturn | 29.7       |
| AveragePhiLoss          | 0.954463   |
| AveragePolicyStd        | 0.979679   |
| AverageReturn           | 43.5       |
| Entropy                 | 8.38991    |
| EnvExecTime             | 2.44       |
| ExplainedVariance       | 0.268      |
| Iteration               | 19         |
| ItrTime                 | 10.5       |
| LossAfter               | -0.786068  |
| LossBefore              | -0.721942  |
| MaxReturn               | 165        |
| MeanKL                  | 0.00997836 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -7.94      |
| NumTrajs                | 57         |
| Perplexity              | 4402.44    |
| PolicyExecTime          | 0.562      |
| ProcessExecTime         | 0.0826     |
| StdReturn               | 44.8       |
| Time                    | 205        |
| dLoss                   | 0.0641252  |
----------------------------------------
itr #20 | 
Mem: 712.484375
Obtaining samples...
Obtaining samples for iteration 20...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5022, #subsample_inputs: 5022
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.75       |
| AbsLearnSignalNew       | 0.75       |
| AbsLearningOld          | 0.75       |
| AverageDiscountedReturn | 37.3       |
| AveragePhiLoss          | 0.953834   |
| AveragePolicyStd        | 0.97929    |
| AverageReturn           | 60.2       |
| Entropy                 | 8.38735    |
| EnvExecTime             | 2.23       |
| ExplainedVariance       | 0.305      |
| Iteration               | 20         |
| ItrTime                 | 10.2       |
| LossAfter               | -0.444208  |
| LossBefore              | -0.381552  |
| MaxReturn               | 318        |
| MeanKL                  | 0.00992272 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -0.00174   |
| NumTrajs                | 50         |
| Perplexity              | 4391.17    |
| PolicyExecTime          | 0.501      |
| ProcessExecTime         | 0.067      |
| StdReturn               | 62.5       |
| Time                    | 215        |
| dLoss                   | 0.0626557  |
----------------------------------------
itr #21 | 
Mem: 713.515625
Obtaining samples...
Obtaining samples for iteration 21...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5105, #subsample_inputs: 5105
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.781      |
| AbsLearnSignalNew       | 0.781      |
| AbsLearningOld          | 0.781      |
| AverageDiscountedReturn | 55.9       |
| AveragePhiLoss          | 0.96315    |
| AveragePolicyStd        | 0.975199   |
| AverageReturn           | 112        |
| Entropy                 | 8.36216    |
| EnvExecTime             | 2.65       |
| ExplainedVariance       | 0.251      |
| Iteration               | 21         |
| ItrTime                 | 9.93       |
| LossAfter               | -0.457374  |
| LossBefore              | -0.396251  |
| MaxReturn               | 327        |
| MeanKL                  | 0.00992729 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 1.1        |
| NumTrajs                | 42         |
| Perplexity              | 4281.92    |
| PolicyExecTime          | 0.615      |
| ProcessExecTime         | 0.0838     |
| StdReturn               | 97.6       |
| Time                    | 225        |
| dLoss                   | 0.0611225  |
----------------------------------------
itr #22 | 
Mem: 713.515625
Obtaining samples...
Obtaining samples for iteration 22...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5335, #subsample_inputs: 5335
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.808      |
| AbsLearnSignalNew       | 0.808      |
| AbsLearningOld          | 0.808      |
| AverageDiscountedReturn | 53.7       |
| AveragePhiLoss          | 0.966577   |
| AveragePolicyStd        | 0.97443    |
| AverageReturn           | 114        |
| Entropy                 | 8.35755    |
| EnvExecTime             | 2.71       |
| ExplainedVariance       | 0.291      |
| Iteration               | 22         |
| ItrTime                 | 11.4       |
| LossAfter               | -0.223256  |
| LossBefore              | -0.177518  |
| MaxReturn               | 463        |
| MeanKL                  | 0.00646852 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 6.72       |
| NumTrajs                | 45         |
| Perplexity              | 4262.25    |
| PolicyExecTime          | 0.62       |
| ProcessExecTime         | 0.0869     |
| StdReturn               | 119        |
| Time                    | 236        |
| dLoss                   | 0.0457385  |
----------------------------------------
itr #23 | 
Mem: 717.125000
Obtaining samples...
Obtaining samples for iteration 23...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5030, #subsample_inputs: 5030
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.78       |
| AbsLearnSignalNew       | 0.78       |
| AbsLearningOld          | 0.78       |
| AverageDiscountedReturn | 48.5       |
| AveragePhiLoss          | 0.956211   |
| AveragePolicyStd        | 0.971333   |
| AverageReturn           | 99.5       |
| Entropy                 | 8.33837    |
| EnvExecTime             | 2.41       |
| ExplainedVariance       | 0.381      |
| Iteration               | 23         |
| ItrTime                 | 9.88       |
| LossAfter               | 0.0877988  |
| LossBefore              | 0.137807   |
| MaxReturn               | 474        |
| MeanKL                  | 0.00640582 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -0.706     |
| NumTrajs                | 42         |
| Perplexity              | 4181.28    |
| PolicyExecTime          | 0.55       |
| ProcessExecTime         | 0.0776     |
| StdReturn               | 117        |
| Time                    | 246        |
| dLoss                   | 0.0500086  |
----------------------------------------
itr #24 | 
Mem: 717.125000
Obtaining samples...
Obtaining samples for iteration 24...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5008, #subsample_inputs: 5008
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.807      |
| AbsLearnSignalNew       | 0.807      |
| AbsLearningOld          | 0.807      |
| AverageDiscountedReturn | 65.6       |
| AveragePhiLoss          | 0.959183   |
| AveragePolicyStd        | 0.972183   |
| AverageReturn           | 135        |
| Entropy                 | 8.34372    |
| EnvExecTime             | 2.55       |
| ExplainedVariance       | 0.359      |
| Iteration               | 24         |
| ItrTime                 | 10.6       |
| LossAfter               | -0.561846  |
| LossBefore              | -0.512903  |
| MaxReturn               | 341        |
| MeanKL                  | 0.00647355 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 16         |
| NumTrajs                | 34         |
| Perplexity              | 4203.7     |
| PolicyExecTime          | 0.587      |
| ProcessExecTime         | 0.0804     |
| StdReturn               | 109        |
| Time                    | 257        |
| dLoss                   | 0.0489433  |
----------------------------------------
itr #25 | 
Mem: 717.125000
Obtaining samples...
Obtaining samples for iteration 25...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5065, #subsample_inputs: 5065
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.811     |
| AbsLearnSignalNew       | 0.811     |
| AbsLearningOld          | 0.811     |
| AverageDiscountedReturn | 63.3      |
| AveragePhiLoss          | 0.953895  |
| AveragePolicyStd        | 0.972234  |
| AverageReturn           | 131       |
| Entropy                 | 8.34384   |
| EnvExecTime             | 2.12      |
| ExplainedVariance       | 0.403     |
| Iteration               | 25        |
| ItrTime                 | 10.4      |
| LossAfter               | -0.852784 |
| LossBefore              | -0.804528 |
| MaxReturn               | 360       |
| MeanKL                  | 0.006424  |
| MeanKLBefore            | 0.0       |
| MinReturn               | 3.04      |
| NumTrajs                | 38        |
| Perplexity              | 4204.19   |
| PolicyExecTime          | 0.493     |
| ProcessExecTime         | 0.0679    |
| StdReturn               | 111       |
| Time                    | 268       |
| dLoss                   | 0.0482559 |
---------------------------------------
itr #26 | 
Mem: 717.125000
Obtaining samples...
Obtaining samples for iteration 26...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5026, #subsample_inputs: 5026
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.446      |
| AbsLearnSignalNew       | 0.446      |
| AbsLearningOld          | 0.446      |
| AverageDiscountedReturn | 63.8       |
| AveragePhiLoss          | 0.963583   |
| AveragePolicyStd        | 0.972063   |
| AverageReturn           | 136        |
| Entropy                 | 8.34265    |
| EnvExecTime             | 2.61       |
| ExplainedVariance       | -2.91      |
| Iteration               | 26         |
| ItrTime                 | 9.84       |
| LossAfter               | 0.637689   |
| LossBefore              | 0.718193   |
| MaxReturn               | 493        |
| MeanKL                  | 0.00936891 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 8.7        |
| NumTrajs                | 31         |
| Perplexity              | 4199.19    |
| PolicyExecTime          | 0.602      |
| ProcessExecTime         | 0.0818     |
| StdReturn               | 119        |
| Time                    | 278        |
| dLoss                   | 0.0805032  |
----------------------------------------
itr #27 | 
Mem: 717.125000
Obtaining samples...
Obtaining samples for iteration 27...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5075, #subsample_inputs: 5075
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.793      |
| AbsLearnSignalNew       | 0.793      |
| AbsLearningOld          | 0.793      |
| AverageDiscountedReturn | 47.5       |
| AveragePhiLoss          | 0.957717   |
| AveragePolicyStd        | 0.968662   |
| AverageReturn           | 91         |
| Entropy                 | 8.32175    |
| EnvExecTime             | 2.64       |
| ExplainedVariance       | 0.336      |
| Iteration               | 27         |
| ItrTime                 | 11         |
| LossAfter               | 1.3717     |
| LossBefore              | 1.41982    |
| MaxReturn               | 364        |
| MeanKL                  | 0.00644285 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -13.3      |
| NumTrajs                | 40         |
| Perplexity              | 4112.37    |
| PolicyExecTime          | 0.619      |
| ProcessExecTime         | 0.0844     |
| StdReturn               | 98.9       |
| Time                    | 289        |
| dLoss                   | 0.0481172  |
----------------------------------------
itr #28 | 
Mem: 718.656250
Obtaining samples...
Obtaining samples for iteration 28...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5045, #subsample_inputs: 5045
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.765      |
| AbsLearnSignalNew       | 0.765      |
| AbsLearningOld          | 0.765      |
| AverageDiscountedReturn | 53.9       |
| AveragePhiLoss          | 0.967557   |
| AveragePolicyStd        | 0.967422   |
| AverageReturn           | 113        |
| Entropy                 | 8.31442    |
| EnvExecTime             | 2.33       |
| ExplainedVariance       | 0.275      |
| Iteration               | 28         |
| ItrTime                 | 9.81       |
| LossAfter               | 0.716187   |
| LossBefore              | 0.765248   |
| MaxReturn               | 407        |
| MeanKL                  | 0.00649525 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -11.4      |
| NumTrajs                | 36         |
| Perplexity              | 4082.32    |
| PolicyExecTime          | 0.537      |
| ProcessExecTime         | 0.0773     |
| StdReturn               | 115        |
| Time                    | 298        |
| dLoss                   | 0.0490605  |
----------------------------------------
itr #29 | 
Mem: 719.171875
Obtaining samples...
Obtaining samples for iteration 29...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5003, #subsample_inputs: 5003
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.816      |
| AbsLearnSignalNew       | 0.816      |
| AbsLearningOld          | 0.816      |
| AverageDiscountedReturn | 57.3       |
| AveragePhiLoss          | 0.954336   |
| AveragePolicyStd        | 0.965029   |
| AverageReturn           | 123        |
| Entropy                 | 8.29965    |
| EnvExecTime             | 2.66       |
| ExplainedVariance       | 0.367      |
| Iteration               | 29         |
| ItrTime                 | 10.8       |
| LossAfter               | -0.218891  |
| LossBefore              | -0.156714  |
| MaxReturn               | 374        |
| MeanKL                  | 0.00988524 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 3.64       |
| NumTrajs                | 36         |
| Perplexity              | 4022.47    |
| PolicyExecTime          | 0.621      |
| ProcessExecTime         | 0.0838     |
| StdReturn               | 116        |
| Time                    | 309        |
| dLoss                   | 0.0621769  |
----------------------------------------
itr #30 | 
Mem: 721.746094
Obtaining samples...
Obtaining samples for iteration 30...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5047, #subsample_inputs: 5047
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.737      |
| AbsLearnSignalNew       | 0.737      |
| AbsLearningOld          | 0.737      |
| AverageDiscountedReturn | 65.1       |
| AveragePhiLoss          | 0.967622   |
| AveragePolicyStd        | 0.962727   |
| AverageReturn           | 154        |
| Entropy                 | 8.28526    |
| EnvExecTime             | 2.3        |
| ExplainedVariance       | 0.379      |
| Iteration               | 30         |
| ItrTime                 | 10.4       |
| LossAfter               | 0.229089   |
| LossBefore              | 0.278275   |
| MaxReturn               | 422        |
| MeanKL                  | 0.00645924 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 8.06       |
| NumTrajs                | 30         |
| Perplexity              | 3964.98    |
| PolicyExecTime          | 0.487      |
| ProcessExecTime         | 0.0654     |
| StdReturn               | 135        |
| Time                    | 320        |
| dLoss                   | 0.0491862  |
----------------------------------------
itr #31 | 
Mem: 722.003906
Obtaining samples...
Obtaining samples for iteration 31...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5104, #subsample_inputs: 5104
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.796     |
| AbsLearnSignalNew       | 0.796     |
| AbsLearningOld          | 0.796     |
| AverageDiscountedReturn | 79.3      |
| AveragePhiLoss          | 0.968282  |
| AveragePolicyStd        | 0.957519  |
| AverageReturn           | 189       |
| Entropy                 | 8.25273   |
| EnvExecTime             | 2.58      |
| ExplainedVariance       | 0.338     |
| Iteration               | 31        |
| ItrTime                 | 10.1      |
| LossAfter               | 0.694723  |
| LossBefore              | 0.753532  |
| MaxReturn               | 579       |
| MeanKL                  | 0.0099409 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 13.7      |
| NumTrajs                | 28        |
| Perplexity              | 3838.11   |
| PolicyExecTime          | 0.597     |
| ProcessExecTime         | 0.0847    |
| StdReturn               | 128       |
| Time                    | 330       |
| dLoss                   | 0.0588092 |
---------------------------------------
itr #32 | 
Mem: 722.003906
Obtaining samples...
Obtaining samples for iteration 32...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5076, #subsample_inputs: 5076
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.761      |
| AbsLearnSignalNew       | 0.761      |
| AbsLearningOld          | 0.761      |
| AverageDiscountedReturn | 72         |
| AveragePhiLoss          | 0.953588   |
| AveragePolicyStd        | 0.959862   |
| AverageReturn           | 180        |
| Entropy                 | 8.26736    |
| EnvExecTime             | 2.66       |
| ExplainedVariance       | 0.279      |
| Iteration               | 32         |
| ItrTime                 | 11.1       |
| LossAfter               | 0.162117   |
| LossBefore              | 0.211628   |
| MaxReturn               | 472        |
| MeanKL                  | 0.00651188 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 30.6       |
| NumTrajs                | 29         |
| Perplexity              | 3894.64    |
| PolicyExecTime          | 0.625      |
| ProcessExecTime         | 0.082      |
| StdReturn               | 131        |
| Time                    | 341        |
| dLoss                   | 0.0495112  |
----------------------------------------
itr #33 | 
Mem: 722.261719
Obtaining samples...
Obtaining samples for iteration 33...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5118, #subsample_inputs: 5118
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.734      |
| AbsLearnSignalNew       | 0.734      |
| AbsLearningOld          | 0.734      |
| AverageDiscountedReturn | 77.9       |
| AveragePhiLoss          | 0.964019   |
| AveragePolicyStd        | 0.957642   |
| AverageReturn           | 210        |
| Entropy                 | 8.25334    |
| EnvExecTime             | 2.72       |
| ExplainedVariance       | 0.371      |
| Iteration               | 33         |
| ItrTime                 | 10.2       |
| LossAfter               | -0.234774  |
| LossBefore              | -0.186579  |
| MaxReturn               | 566        |
| MeanKL                  | 0.00641662 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 15         |
| NumTrajs                | 24         |
| Perplexity              | 3840.44    |
| PolicyExecTime          | 0.617      |
| ProcessExecTime         | 0.0814     |
| StdReturn               | 156        |
| Time                    | 352        |
| dLoss                   | 0.0481957  |
----------------------------------------
itr #34 | 
Mem: 722.574219
Obtaining samples...
Obtaining samples for iteration 34...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5311, #subsample_inputs: 5311
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.767      |
| AbsLearnSignalNew       | 0.767      |
| AbsLearningOld          | 0.767      |
| AverageDiscountedReturn | 79.2       |
| AveragePhiLoss          | 0.966418   |
| AveragePolicyStd        | 0.95872    |
| AverageReturn           | 214        |
| Entropy                 | 8.25978    |
| EnvExecTime             | 2.78       |
| ExplainedVariance       | 0.28       |
| Iteration               | 34         |
| ItrTime                 | 11.3       |
| LossAfter               | 0.57741    |
| LossBefore              | 0.634264   |
| MaxReturn               | 556        |
| MeanKL                  | 0.00992625 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 32.2       |
| NumTrajs                | 24         |
| Perplexity              | 3865.22    |
| PolicyExecTime          | 0.631      |
| ProcessExecTime         | 0.086      |
| StdReturn               | 130        |
| Time                    | 363        |
| dLoss                   | 0.0568541  |
----------------------------------------
itr #35 | 
Mem: 724.890625
Obtaining samples...
Obtaining samples for iteration 35...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5008, #subsample_inputs: 5008
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.805      |
| AbsLearnSignalNew       | 0.805      |
| AbsLearningOld          | 0.805      |
| AverageDiscountedReturn | 66.3       |
| AveragePhiLoss          | 0.959083   |
| AveragePolicyStd        | 0.95951    |
| AverageReturn           | 141        |
| Entropy                 | 8.26462    |
| EnvExecTime             | 2.37       |
| ExplainedVariance       | 0.392      |
| Iteration               | 35         |
| ItrTime                 | 10.7       |
| LossAfter               | 0.518218   |
| LossBefore              | 0.564818   |
| MaxReturn               | 330        |
| MeanKL                  | 0.00646138 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -7.57      |
| NumTrajs                | 36         |
| Perplexity              | 3884.01    |
| PolicyExecTime          | 0.532      |
| ProcessExecTime         | 0.0681     |
| StdReturn               | 111        |
| Time                    | 374        |
| dLoss                   | 0.0466     |
----------------------------------------
itr #36 | 
Mem: 724.890625
Obtaining samples...
Obtaining samples for iteration 36...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5131, #subsample_inputs: 5131
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.69       |
| AbsLearnSignalNew       | 0.69       |
| AbsLearningOld          | 0.69       |
| AverageDiscountedReturn | 74.8       |
| AveragePhiLoss          | 0.947728   |
| AveragePolicyStd        | 0.958134   |
| AverageReturn           | 175        |
| Entropy                 | 8.25613    |
| EnvExecTime             | 2.79       |
| ExplainedVariance       | -0.0412    |
| Iteration               | 36         |
| ItrTime                 | 10.1       |
| LossAfter               | 0.149429   |
| LossBefore              | 0.197733   |
| MaxReturn               | 413        |
| MeanKL                  | 0.00648476 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 13.1       |
| NumTrajs                | 31         |
| Perplexity              | 3851.15    |
| PolicyExecTime          | 0.635      |
| ProcessExecTime         | 0.086      |
| StdReturn               | 122        |
| Time                    | 384        |
| dLoss                   | 0.0483046  |
----------------------------------------
itr #37 | 
Mem: 724.890625
Obtaining samples...
Obtaining samples for iteration 37...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5001, #subsample_inputs: 5001
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.77       |
| AbsLearnSignalNew       | 0.77       |
| AbsLearningOld          | 0.77       |
| AverageDiscountedReturn | 83.3       |
| AveragePhiLoss          | 0.960708   |
| AveragePolicyStd        | 0.954578   |
| AverageReturn           | 216        |
| Entropy                 | 8.23358    |
| EnvExecTime             | 2.61       |
| ExplainedVariance       | 0.365      |
| Iteration               | 37         |
| ItrTime                 | 10.8       |
| LossAfter               | 0.58642    |
| LossBefore              | 0.635655   |
| MaxReturn               | 433        |
| MeanKL                  | 0.00641949 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 51.3       |
| NumTrajs                | 25         |
| Perplexity              | 3765.31    |
| PolicyExecTime          | 0.594      |
| ProcessExecTime         | 0.0809     |
| StdReturn               | 135        |
| Time                    | 395        |
| dLoss                   | 0.0492346  |
----------------------------------------
itr #38 | 
Mem: 724.890625
Obtaining samples...
Obtaining samples for iteration 38...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5090, #subsample_inputs: 5090
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.752      |
| AbsLearnSignalNew       | 0.752      |
| AbsLearningOld          | 0.752      |
| AverageDiscountedReturn | 86.5       |
| AveragePhiLoss          | 0.963039   |
| AveragePolicyStd        | 0.953163   |
| AverageReturn           | 223        |
| Entropy                 | 8.22472    |
| EnvExecTime             | 2.43       |
| ExplainedVariance       | 0.327      |
| Iteration               | 38         |
| ItrTime                 | 10.1       |
| LossAfter               | 0.463193   |
| LossBefore              | 0.522379   |
| MaxReturn               | 557        |
| MeanKL                  | 0.00991221 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 22.3       |
| NumTrajs                | 26         |
| Perplexity              | 3732.09    |
| PolicyExecTime          | 0.539      |
| ProcessExecTime         | 0.0752     |
| StdReturn               | 133        |
| Time                    | 405        |
| dLoss                   | 0.0591857  |
----------------------------------------
itr #39 | 
Mem: 725.148438
Obtaining samples...
Obtaining samples for iteration 39...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5031, #subsample_inputs: 5031
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.768      |
| AbsLearnSignalNew       | 0.768      |
| AbsLearningOld          | 0.768      |
| AverageDiscountedReturn | 87.9       |
| AveragePhiLoss          | 0.956223   |
| AveragePolicyStd        | 0.952629   |
| AverageReturn           | 205        |
| Entropy                 | 8.22091    |
| EnvExecTime             | 2.79       |
| ExplainedVariance       | 0.414      |
| Iteration               | 39         |
| ItrTime                 | 10.8       |
| LossAfter               | 0.277538   |
| LossBefore              | 0.336143   |
| MaxReturn               | 388        |
| MeanKL                  | 0.00981556 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 22.2       |
| NumTrajs                | 30         |
| Perplexity              | 3717.88    |
| PolicyExecTime          | 0.638      |
| ProcessExecTime         | 0.0854     |
| StdReturn               | 105        |
| Time                    | 416        |
| dLoss                   | 0.0586049  |
----------------------------------------
itr #40 | 
Mem: 726.179688
Obtaining samples...
Obtaining samples for iteration 40...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5140, #subsample_inputs: 5140
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.72       |
| AbsLearnSignalNew       | 0.72       |
| AbsLearningOld          | 0.72       |
| AverageDiscountedReturn | 88.7       |
| AveragePhiLoss          | 0.965541   |
| AveragePolicyStd        | 0.951985   |
| AverageReturn           | 219        |
| Entropy                 | 8.21691    |
| EnvExecTime             | 2.38       |
| ExplainedVariance       | 0.431      |
| Iteration               | 40         |
| ItrTime                 | 10.7       |
| LossAfter               | -0.660341  |
| LossBefore              | -0.600295  |
| MaxReturn               | 442        |
| MeanKL                  | 0.00995987 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 42.7       |
| NumTrajs                | 26         |
| Perplexity              | 3703.03    |
| PolicyExecTime          | 0.52       |
| ProcessExecTime         | 0.0706     |
| StdReturn               | 104        |
| Time                    | 427        |
| dLoss                   | 0.0600454  |
----------------------------------------
itr #41 | 
Mem: 726.179688
Obtaining samples...
Obtaining samples for iteration 41...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5198, #subsample_inputs: 5198
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.765      |
| AbsLearnSignalNew       | 0.765      |
| AbsLearningOld          | 0.765      |
| AverageDiscountedReturn | 76.8       |
| AveragePhiLoss          | 0.962697   |
| AveragePolicyStd        | 0.948449   |
| AverageReturn           | 190        |
| Entropy                 | 8.19432    |
| EnvExecTime             | 2.65       |
| ExplainedVariance       | 0.328      |
| Iteration               | 41         |
| ItrTime                 | 9.88       |
| LossAfter               | 0.780383   |
| LossBefore              | 0.837752   |
| MaxReturn               | 579        |
| MeanKL                  | 0.00999292 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 5.27       |
| NumTrajs                | 28         |
| Perplexity              | 3620.33    |
| PolicyExecTime          | 0.595      |
| ProcessExecTime         | 0.0847     |
| StdReturn               | 142        |
| Time                    | 437        |
| dLoss                   | 0.0573683  |
----------------------------------------
itr #42 | 
Mem: 726.437500
Obtaining samples...
Obtaining samples for iteration 42...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5107, #subsample_inputs: 5107
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.756      |
| AbsLearnSignalNew       | 0.756      |
| AbsLearningOld          | 0.756      |
| AverageDiscountedReturn | 89.2       |
| AveragePhiLoss          | 0.97126    |
| AveragePolicyStd        | 0.946994   |
| AverageReturn           | 249        |
| Entropy                 | 8.18475    |
| EnvExecTime             | 2.68       |
| ExplainedVariance       | 0.335      |
| Iteration               | 42         |
| ItrTime                 | 11         |
| LossAfter               | 0.360095   |
| LossBefore              | 0.415728   |
| MaxReturn               | 493        |
| MeanKL                  | 0.00979087 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 45.6       |
| NumTrajs                | 22         |
| Perplexity              | 3585.84    |
| PolicyExecTime          | 0.611      |
| ProcessExecTime         | 0.0828     |
| StdReturn               | 122        |
| Time                    | 448        |
| dLoss                   | 0.0556328  |
----------------------------------------
itr #43 | 
Mem: 726.437500
Obtaining samples...
Obtaining samples for iteration 43...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5012, #subsample_inputs: 5012
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.742      |
| AbsLearnSignalNew       | 0.742      |
| AbsLearningOld          | 0.742      |
| AverageDiscountedReturn | 95.7       |
| AveragePhiLoss          | 0.958276   |
| AveragePolicyStd        | 0.947789   |
| AverageReturn           | 251        |
| Entropy                 | 8.18971    |
| EnvExecTime             | 2.6        |
| ExplainedVariance       | 0.503      |
| Iteration               | 43         |
| ItrTime                 | 9.83       |
| LossAfter               | 0.770865   |
| LossBefore              | 0.820098   |
| MaxReturn               | 435        |
| MeanKL                  | 0.00649229 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 34.9       |
| NumTrajs                | 24         |
| Perplexity              | 3603.69    |
| PolicyExecTime          | 0.58       |
| ProcessExecTime         | 0.08       |
| StdReturn               | 109        |
| Time                    | 458        |
| dLoss                   | 0.0492323  |
----------------------------------------
itr #44 | 
Mem: 726.437500
Obtaining samples...
Obtaining samples for iteration 44...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5451, #subsample_inputs: 5451
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.713      |
| AbsLearnSignalNew       | 0.713      |
| AbsLearningOld          | 0.713      |
| AverageDiscountedReturn | 100        |
| AveragePhiLoss          | 0.966195   |
| AveragePolicyStd        | 0.94459    |
| AverageReturn           | 299        |
| Entropy                 | 8.16987    |
| EnvExecTime             | 2.96       |
| ExplainedVariance       | 0.224      |
| Iteration               | 44         |
| ItrTime                 | 11.7       |
| LossAfter               | -0.315576  |
| LossBefore              | -0.270129  |
| MaxReturn               | 632        |
| MeanKL                  | 0.00644445 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 32.4       |
| NumTrajs                | 23         |
| Perplexity              | 3532.88    |
| PolicyExecTime          | 0.674      |
| ProcessExecTime         | 0.0898     |
| StdReturn               | 134        |
| Time                    | 470        |
| dLoss                   | 0.0454468  |
----------------------------------------
itr #45 | 
Mem: 728.238281
Obtaining samples...
Obtaining samples for iteration 45...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5112, #subsample_inputs: 5112
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.745      |
| AbsLearnSignalNew       | 0.745      |
| AbsLearningOld          | 0.745      |
| AverageDiscountedReturn | 94         |
| AveragePhiLoss          | 0.964857   |
| AveragePolicyStd        | 0.945138   |
| AverageReturn           | 248        |
| Entropy                 | 8.17333    |
| EnvExecTime             | 2.42       |
| ExplainedVariance       | 0.438      |
| Iteration               | 45         |
| ItrTime                 | 10.8       |
| LossAfter               | -0.0684833 |
| LossBefore              | -0.0108732 |
| MaxReturn               | 535        |
| MeanKL                  | 0.00994098 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 37.4       |
| NumTrajs                | 25         |
| Perplexity              | 3545.13    |
| PolicyExecTime          | 0.525      |
| ProcessExecTime         | 0.0716     |
| StdReturn               | 114        |
| Time                    | 481        |
| dLoss                   | 0.0576101  |
----------------------------------------
itr #46 | 
Mem: 728.496094
Obtaining samples...
Obtaining samples for iteration 46...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5099, #subsample_inputs: 5099
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.751      |
| AbsLearnSignalNew       | 0.751      |
| AbsLearningOld          | 0.751      |
| AverageDiscountedReturn | 91.3       |
| AveragePhiLoss          | 0.955959   |
| AveragePolicyStd        | 0.945035   |
| AverageReturn           | 259        |
| Entropy                 | 8.17281    |
| EnvExecTime             | 2.72       |
| ExplainedVariance       | 0.383      |
| Iteration               | 46         |
| ItrTime                 | 10         |
| LossAfter               | 1.25396    |
| LossBefore              | 1.31315    |
| MaxReturn               | 699        |
| MeanKL                  | 0.00983023 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 37.1       |
| NumTrajs                | 23         |
| Perplexity              | 3543.3     |
| PolicyExecTime          | 0.608      |
| ProcessExecTime         | 0.0831     |
| StdReturn               | 158        |
| Time                    | 491        |
| dLoss                   | 0.0591881  |
----------------------------------------
itr #47 | 
Mem: 730.339844
Obtaining samples...
Obtaining samples for iteration 47...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5009, #subsample_inputs: 5009
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.735      |
| AbsLearnSignalNew       | 0.735      |
| AbsLearningOld          | 0.735      |
| AverageDiscountedReturn | 103        |
| AveragePhiLoss          | 0.963327   |
| AveragePolicyStd        | 0.944578   |
| AverageReturn           | 257        |
| Entropy                 | 8.1691     |
| EnvExecTime             | 2.84       |
| ExplainedVariance       | 0.464      |
| Iteration               | 47         |
| ItrTime                 | 11.1       |
| LossAfter               | 0.815341   |
| LossBefore              | 0.874082   |
| MaxReturn               | 401        |
| MeanKL                  | 0.00996583 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 71.7       |
| NumTrajs                | 25         |
| Perplexity              | 3530.15    |
| PolicyExecTime          | 0.669      |
| ProcessExecTime         | 0.0861     |
| StdReturn               | 80.2       |
| Time                    | 502        |
| dLoss                   | 0.0587416  |
----------------------------------------
itr #48 | 
Mem: 730.339844
Obtaining samples...
Obtaining samples for iteration 48...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5027, #subsample_inputs: 5027
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.776      |
| AbsLearnSignalNew       | 0.776      |
| AbsLearningOld          | 0.776      |
| AverageDiscountedReturn | 90.7       |
| AveragePhiLoss          | 0.966714   |
| AveragePolicyStd        | 0.943336   |
| AverageReturn           | 243        |
| Entropy                 | 8.16142    |
| EnvExecTime             | 2.43       |
| ExplainedVariance       | 0.358      |
| Iteration               | 48         |
| ItrTime                 | 10.1       |
| LossAfter               | -0.0335976 |
| LossBefore              | 0.0219603  |
| MaxReturn               | 477        |
| MeanKL                  | 0.00988158 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -1.27      |
| NumTrajs                | 25         |
| Perplexity              | 3503.14    |
| PolicyExecTime          | 0.537      |
| ProcessExecTime         | 0.0729     |
| StdReturn               | 132        |
| Time                    | 512        |
| dLoss                   | 0.055558   |
----------------------------------------
itr #49 | 
Mem: 730.339844
Obtaining samples...
Obtaining samples for iteration 49...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5072, #subsample_inputs: 5072
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.688      |
| AbsLearnSignalNew       | 0.688      |
| AbsLearningOld          | 0.688      |
| AverageDiscountedReturn | 89.6       |
| AveragePhiLoss          | 0.967003   |
| AveragePolicyStd        | 0.943643   |
| AverageReturn           | 247        |
| Entropy                 | 8.16283    |
| EnvExecTime             | 2.63       |
| ExplainedVariance       | 0.336      |
| Iteration               | 49         |
| ItrTime                 | 10.6       |
| LossAfter               | 1.46605    |
| LossBefore              | 1.52396    |
| MaxReturn               | 641        |
| MeanKL                  | 0.00998807 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 59.3       |
| NumTrajs                | 21         |
| Perplexity              | 3508.09    |
| PolicyExecTime          | 0.581      |
| ProcessExecTime         | 0.0809     |
| StdReturn               | 153        |
| Time                    | 523        |
| dLoss                   | 0.0579096  |
----------------------------------------
itr #50 | 
Mem: 730.339844
Obtaining samples...
Obtaining samples for iteration 50...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5026, #subsample_inputs: 5026
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.753      |
| AbsLearnSignalNew       | 0.753      |
| AbsLearningOld          | 0.753      |
| AverageDiscountedReturn | 107        |
| AveragePhiLoss          | 0.958104   |
| AveragePolicyStd        | 0.941151   |
| AverageReturn           | 295        |
| Entropy                 | 8.14653    |
| EnvExecTime             | 2.37       |
| ExplainedVariance       | 0.427      |
| Iteration               | 50         |
| ItrTime                 | 10.5       |
| LossAfter               | 0.344151   |
| LossBefore              | 0.39093    |
| MaxReturn               | 598        |
| MeanKL                  | 0.00648052 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 80.7       |
| NumTrajs                | 25         |
| Perplexity              | 3451.38    |
| PolicyExecTime          | 0.51       |
| ProcessExecTime         | 0.0689     |
| StdReturn               | 105        |
| Time                    | 534        |
| dLoss                   | 0.046779   |
----------------------------------------
itr #51 | 
Mem: 730.339844
Obtaining samples...
Obtaining samples for iteration 51...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5171, #subsample_inputs: 5171
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.727     |
| AbsLearnSignalNew       | 0.727     |
| AbsLearningOld          | 0.727     |
| AverageDiscountedReturn | 108       |
| AveragePhiLoss          | 0.958061  |
| AveragePolicyStd        | 0.940865  |
| AverageReturn           | 297       |
| Entropy                 | 8.14412   |
| EnvExecTime             | 2.74      |
| ExplainedVariance       | 0.507     |
| Iteration               | 51        |
| ItrTime                 | 9.94      |
| LossAfter               | -0.594162 |
| LossBefore              | -0.546712 |
| MaxReturn               | 467       |
| MeanKL                  | 0.0064078 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 62.3      |
| NumTrajs                | 25        |
| Perplexity              | 3443.07   |
| PolicyExecTime          | 0.619     |
| ProcessExecTime         | 0.0866    |
| StdReturn               | 84.4      |
| Time                    | 544       |
| dLoss                   | 0.0474502 |
---------------------------------------
itr #52 | 
Mem: 730.339844
Obtaining samples...
Obtaining samples for iteration 52...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5000, #subsample_inputs: 5000
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.711      |
| AbsLearnSignalNew       | 0.711      |
| AbsLearningOld          | 0.711      |
| AverageDiscountedReturn | 96         |
| AveragePhiLoss          | 0.958002   |
| AveragePolicyStd        | 0.939456   |
| AverageReturn           | 253        |
| Entropy                 | 8.1348     |
| EnvExecTime             | 2.85       |
| ExplainedVariance       | 0.462      |
| Iteration               | 52         |
| ItrTime                 | 11.3       |
| LossAfter               | -0.165479  |
| LossBefore              | -0.106235  |
| MaxReturn               | 498        |
| MeanKL                  | 0.00990545 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 12.2       |
| NumTrajs                | 25         |
| Perplexity              | 3411.13    |
| PolicyExecTime          | 0.653      |
| ProcessExecTime         | 0.0862     |
| StdReturn               | 126        |
| Time                    | 555        |
| dLoss                   | 0.0592447  |
----------------------------------------
itr #53 | 
Mem: 730.339844
Obtaining samples...
Obtaining samples for iteration 53...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5169, #subsample_inputs: 5169
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.747      |
| AbsLearnSignalNew       | 0.747      |
| AbsLearningOld          | 0.747      |
| AverageDiscountedReturn | 107        |
| AveragePhiLoss          | 0.9708     |
| AveragePolicyStd        | 0.939674   |
| AverageReturn           | 300        |
| Entropy                 | 8.13529    |
| EnvExecTime             | 2.74       |
| ExplainedVariance       | 0.511      |
| Iteration               | 53         |
| ItrTime                 | 10.4       |
| LossAfter               | 0.19593    |
| LossBefore              | 0.24161    |
| MaxReturn               | 493        |
| MeanKL                  | 0.00644634 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 60.3       |
| NumTrajs                | 24         |
| Perplexity              | 3412.8     |
| PolicyExecTime          | 0.59       |
| ProcessExecTime         | 0.0803     |
| StdReturn               | 107        |
| Time                    | 565        |
| dLoss                   | 0.0456798  |
----------------------------------------
itr #54 | 
Mem: 730.597656
Obtaining samples...
Obtaining samples for iteration 54...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5131, #subsample_inputs: 5131
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.711      |
| AbsLearnSignalNew       | 0.711      |
| AbsLearningOld          | 0.711      |
| AverageDiscountedReturn | 99.6       |
| AveragePhiLoss          | 0.972081   |
| AveragePolicyStd        | 0.940163   |
| AverageReturn           | 263        |
| Entropy                 | 8.13856    |
| EnvExecTime             | 2.85       |
| ExplainedVariance       | 0.523      |
| Iteration               | 54         |
| ItrTime                 | 10.9       |
| LossAfter               | 0.637399   |
| LossBefore              | 0.681441   |
| MaxReturn               | 496        |
| MeanKL                  | 0.00648076 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 45.2       |
| NumTrajs                | 26         |
| Perplexity              | 3423.99    |
| PolicyExecTime          | 0.638      |
| ProcessExecTime         | 0.0871     |
| StdReturn               | 106        |
| Time                    | 576        |
| dLoss                   | 0.0440415  |
----------------------------------------
itr #55 | 
Mem: 730.597656
Obtaining samples...
Obtaining samples for iteration 55...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5229, #subsample_inputs: 5229
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.733      |
| AbsLearnSignalNew       | 0.733      |
| AbsLearningOld          | 0.733      |
| AverageDiscountedReturn | 101        |
| AveragePhiLoss          | 0.961983   |
| AveragePolicyStd        | 0.939807   |
| AverageReturn           | 290        |
| Entropy                 | 8.13664    |
| EnvExecTime             | 2.79       |
| ExplainedVariance       | 0.519      |
| Iteration               | 55         |
| ItrTime                 | 11.3       |
| LossAfter               | 0.249653   |
| LossBefore              | 0.307332   |
| MaxReturn               | 477        |
| MeanKL                  | 0.00994577 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 11.4       |
| NumTrajs                | 25         |
| Perplexity              | 3417.4     |
| PolicyExecTime          | 0.601      |
| ProcessExecTime         | 0.08       |
| StdReturn               | 118        |
| Time                    | 588        |
| dLoss                   | 0.0576796  |
----------------------------------------
itr #56 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 56...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5267, #subsample_inputs: 5267
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.699      |
| AbsLearnSignalNew       | 0.699      |
| AbsLearningOld          | 0.699      |
| AverageDiscountedReturn | 103        |
| AveragePhiLoss          | 0.963122   |
| AveragePolicyStd        | 0.936948   |
| AverageReturn           | 289        |
| Entropy                 | 8.11913    |
| EnvExecTime             | 2.93       |
| ExplainedVariance       | 0.537      |
| Iteration               | 56         |
| ItrTime                 | 10.2       |
| LossAfter               | 0.647552   |
| LossBefore              | 0.7034     |
| MaxReturn               | 526        |
| MeanKL                  | 0.00998048 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 44.3       |
| NumTrajs                | 26         |
| Perplexity              | 3358.1     |
| PolicyExecTime          | 0.65       |
| ProcessExecTime         | 0.088      |
| StdReturn               | 113        |
| Time                    | 598        |
| dLoss                   | 0.0558483  |
----------------------------------------
itr #57 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 57...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5106, #subsample_inputs: 5106
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
-----------------------------------------
| AbsLearnSignal          | 0.722       |
| AbsLearnSignalNew       | 0.722       |
| AbsLearningOld          | 0.721       |
| AverageDiscountedReturn | 105         |
| AveragePhiLoss          | 0.960771    |
| AveragePolicyStd        | 0.935041    |
| AverageReturn           | 284         |
| Entropy                 | 8.10732     |
| EnvExecTime             | 2.77        |
| ExplainedVariance       | 0.546       |
| Iteration               | 57          |
| ItrTime                 | 11.1        |
| LossAfter               | -0.0552526  |
| LossBefore              | 7.60721e-05 |
| MaxReturn               | 579         |
| MeanKL                  | 0.0098798   |
| MeanKLBefore            | 0.0         |
| MinReturn               | 51.3        |
| NumTrajs                | 25          |
| Perplexity              | 3318.67     |
| PolicyExecTime          | 0.605       |
| ProcessExecTime         | 0.0843      |
| StdReturn               | 114         |
| Time                    | 609         |
| dLoss                   | 0.0553286   |
-----------------------------------------
itr #58 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 58...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5359, #subsample_inputs: 5359
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.672     |
| AbsLearnSignalNew       | 0.672     |
| AbsLearningOld          | 0.672     |
| AverageDiscountedReturn | 106       |
| AveragePhiLoss          | 0.968105  |
| AveragePolicyStd        | 0.938016  |
| AverageReturn           | 288       |
| Entropy                 | 8.12651   |
| EnvExecTime             | 2.7       |
| ExplainedVariance       | 0.488     |
| Iteration               | 58        |
| ItrTime                 | 11        |
| LossAfter               | -0.409864 |
| LossBefore              | -0.364319 |
| MaxReturn               | 645       |
| MeanKL                  | 0.0064226 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 50        |
| NumTrajs                | 27        |
| Perplexity              | 3382.97   |
| PolicyExecTime          | 0.574     |
| ProcessExecTime         | 0.078     |
| StdReturn               | 118       |
| Time                    | 621       |
| dLoss                   | 0.0455459 |
---------------------------------------
itr #59 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 59...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5046, #subsample_inputs: 5046
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.687      |
| AbsLearnSignalNew       | 0.687      |
| AbsLearningOld          | 0.687      |
| AverageDiscountedReturn | 100        |
| AveragePhiLoss          | 0.967964   |
| AveragePolicyStd        | 0.935044   |
| AverageReturn           | 287        |
| Entropy                 | 8.10749    |
| EnvExecTime             | 2.72       |
| ExplainedVariance       | 0.437      |
| Iteration               | 59         |
| ItrTime                 | 10.5       |
| LossAfter               | -0.168687  |
| LossBefore              | -0.125826  |
| MaxReturn               | 516        |
| MeanKL                  | 0.00643391 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 13.4       |
| NumTrajs                | 22         |
| Perplexity              | 3319.24    |
| PolicyExecTime          | 0.594      |
| ProcessExecTime         | 0.0812     |
| StdReturn               | 127        |
| Time                    | 631        |
| dLoss                   | 0.042861   |
----------------------------------------
itr #60 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 60...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5189, #subsample_inputs: 5189
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.734     |
| AbsLearnSignalNew       | 0.734     |
| AbsLearningOld          | 0.734     |
| AverageDiscountedReturn | 104       |
| AveragePhiLoss          | 0.962847  |
| AveragePolicyStd        | 0.934363  |
| AverageReturn           | 293       |
| Entropy                 | 8.10338   |
| EnvExecTime             | 2.7       |
| ExplainedVariance       | 0.532     |
| Iteration               | 60        |
| ItrTime                 | 11.1      |
| LossAfter               | -0.462292 |
| LossBefore              | -0.407796 |
| MaxReturn               | 461       |
| MeanKL                  | 0.0097841 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 15.2      |
| NumTrajs                | 25        |
| Perplexity              | 3305.62   |
| PolicyExecTime          | 0.572     |
| ProcessExecTime         | 0.0769    |
| StdReturn               | 118       |
| Time                    | 642       |
| dLoss                   | 0.0544957 |
---------------------------------------
itr #61 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 61...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5000, #subsample_inputs: 5000
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.724      |
| AbsLearnSignalNew       | 0.724      |
| AbsLearningOld          | 0.724      |
| AverageDiscountedReturn | 103        |
| AveragePhiLoss          | 0.966925   |
| AveragePolicyStd        | 0.9355     |
| AverageReturn           | 292        |
| Entropy                 | 8.11098    |
| EnvExecTime             | 2.74       |
| ExplainedVariance       | 0.528      |
| Iteration               | 61         |
| ItrTime                 | 9.66       |
| LossAfter               | 0.134955   |
| LossBefore              | 0.182099   |
| MaxReturn               | 603        |
| MeanKL                  | 0.00645052 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 72.3       |
| NumTrajs                | 23         |
| Perplexity              | 3330.84    |
| PolicyExecTime          | 0.6        |
| ProcessExecTime         | 0.0839     |
| StdReturn               | 126        |
| Time                    | 652        |
| dLoss                   | 0.0471446  |
----------------------------------------
itr #62 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 62...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5014, #subsample_inputs: 5014
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.705      |
| AbsLearnSignalNew       | 0.705      |
| AbsLearningOld          | 0.705      |
| AverageDiscountedReturn | 109        |
| AveragePhiLoss          | 0.969098   |
| AveragePolicyStd        | 0.932806   |
| AverageReturn           | 317        |
| Entropy                 | 8.09294    |
| EnvExecTime             | 2.6        |
| ExplainedVariance       | 0.473      |
| Iteration               | 62         |
| ItrTime                 | 10.9       |
| LossAfter               | -0.343426  |
| LossBefore              | -0.296766  |
| MaxReturn               | 660        |
| MeanKL                  | 0.00643647 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 107        |
| NumTrajs                | 22         |
| Perplexity              | 3271.3     |
| PolicyExecTime          | 0.576      |
| ProcessExecTime         | 0.0809     |
| StdReturn               | 112        |
| Time                    | 663        |
| dLoss                   | 0.0466593  |
----------------------------------------
itr #63 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 63...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5110, #subsample_inputs: 5110
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.715      |
| AbsLearnSignalNew       | 0.715      |
| AbsLearningOld          | 0.715      |
| AverageDiscountedReturn | 107        |
| AveragePhiLoss          | 0.968925   |
| AveragePolicyStd        | 0.932127   |
| AverageReturn           | 300        |
| Entropy                 | 8.08801    |
| EnvExecTime             | 2.57       |
| ExplainedVariance       | 0.588      |
| Iteration               | 63         |
| ItrTime                 | 10.3       |
| LossAfter               | 0.0388225  |
| LossBefore              | 0.0840674  |
| MaxReturn               | 490        |
| MeanKL                  | 0.00648555 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 45.8       |
| NumTrajs                | 25         |
| Perplexity              | 3255.22    |
| PolicyExecTime          | 0.537      |
| ProcessExecTime         | 0.0743     |
| StdReturn               | 96.1       |
| Time                    | 673        |
| dLoss                   | 0.045245   |
----------------------------------------
itr #64 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 64...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5196, #subsample_inputs: 5196
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.67       |
| AbsLearnSignalNew       | 0.67       |
| AbsLearningOld          | 0.67       |
| AverageDiscountedReturn | 108        |
| AveragePhiLoss          | 0.963603   |
| AveragePolicyStd        | 0.929968   |
| AverageReturn           | 300        |
| Entropy                 | 8.07455    |
| EnvExecTime             | 2.81       |
| ExplainedVariance       | 0.509      |
| Iteration               | 64         |
| ItrTime                 | 10.9       |
| LossAfter               | 0.424715   |
| LossBefore              | 0.46781    |
| MaxReturn               | 599        |
| MeanKL                  | 0.00644399 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 24.4       |
| NumTrajs                | 25         |
| Perplexity              | 3211.67    |
| PolicyExecTime          | 0.612      |
| ProcessExecTime         | 0.086      |
| StdReturn               | 126        |
| Time                    | 684        |
| dLoss                   | 0.0430942  |
----------------------------------------
itr #65 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 65...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5000, #subsample_inputs: 5000
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.701      |
| AbsLearnSignalNew       | 0.701      |
| AbsLearningOld          | 0.701      |
| AverageDiscountedReturn | 105        |
| AveragePhiLoss          | 0.972146   |
| AveragePolicyStd        | 0.928963   |
| AverageReturn           | 331        |
| Entropy                 | 8.06826    |
| EnvExecTime             | 2.83       |
| ExplainedVariance       | 0.499      |
| Iteration               | 65         |
| ItrTime                 | 11         |
| LossAfter               | 0.355541   |
| LossBefore              | 0.401056   |
| MaxReturn               | 520        |
| MeanKL                  | 0.00642459 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 90.3       |
| NumTrajs                | 20         |
| Perplexity              | 3191.54    |
| PolicyExecTime          | 0.626      |
| ProcessExecTime         | 0.0798     |
| StdReturn               | 113        |
| Time                    | 696        |
| dLoss                   | 0.0455152  |
----------------------------------------
itr #66 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 66...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5135, #subsample_inputs: 5135
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.698      |
| AbsLearnSignalNew       | 0.698      |
| AbsLearningOld          | 0.698      |
| AverageDiscountedReturn | 113        |
| AveragePhiLoss          | 0.967036   |
| AveragePolicyStd        | 0.930089   |
| AverageReturn           | 309        |
| Entropy                 | 8.07556    |
| EnvExecTime             | 2.76       |
| ExplainedVariance       | 0.607      |
| Iteration               | 66         |
| ItrTime                 | 9.83       |
| LossAfter               | 0.520325   |
| LossBefore              | 0.564067   |
| MaxReturn               | 498        |
| MeanKL                  | 0.00647272 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 78.1       |
| NumTrajs                | 26         |
| Perplexity              | 3214.94    |
| PolicyExecTime          | 0.604      |
| ProcessExecTime         | 0.0825     |
| StdReturn               | 86.1       |
| Time                    | 706        |
| dLoss                   | 0.043742   |
----------------------------------------
itr #67 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 67...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5018, #subsample_inputs: 5018
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.707      |
| AbsLearnSignalNew       | 0.707      |
| AbsLearningOld          | 0.707      |
| AverageDiscountedReturn | 108        |
| AveragePhiLoss          | 0.966693   |
| AveragePolicyStd        | 0.930564   |
| AverageReturn           | 308        |
| Entropy                 | 8.07834    |
| EnvExecTime             | 2.97       |
| ExplainedVariance       | 0.52       |
| Iteration               | 67         |
| ItrTime                 | 11.2       |
| LossAfter               | 0.245173   |
| LossBefore              | 0.290864   |
| MaxReturn               | 497        |
| MeanKL                  | 0.00642048 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 70.9       |
| NumTrajs                | 23         |
| Perplexity              | 3223.88    |
| PolicyExecTime          | 0.647      |
| ProcessExecTime         | 0.0866     |
| StdReturn               | 112        |
| Time                    | 717        |
| dLoss                   | 0.0456907  |
----------------------------------------
itr #68 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 68...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5023, #subsample_inputs: 5023
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.708     |
| AbsLearnSignalNew       | 0.708     |
| AbsLearningOld          | 0.709     |
| AverageDiscountedReturn | 104       |
| AveragePhiLoss          | 0.974607  |
| AveragePolicyStd        | 0.933081  |
| AverageReturn           | 282       |
| Entropy                 | 8.09448   |
| EnvExecTime             | 2.79      |
| ExplainedVariance       | 0.499     |
| Iteration               | 68        |
| ItrTime                 | 10.8      |
| LossAfter               | -0.301595 |
| LossBefore              | -0.248262 |
| MaxReturn               | 487       |
| MeanKL                  | 0.0098466 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 49.9      |
| NumTrajs                | 24        |
| Perplexity              | 3276.33   |
| PolicyExecTime          | 0.587     |
| ProcessExecTime         | 0.0763    |
| StdReturn               | 115       |
| Time                    | 728       |
| dLoss                   | 0.0533332 |
---------------------------------------
itr #69 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 69...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5183, #subsample_inputs: 5183
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.728      |
| AbsLearnSignalNew       | 0.728      |
| AbsLearningOld          | 0.728      |
| AverageDiscountedReturn | 109        |
| AveragePhiLoss          | 0.966263   |
| AveragePolicyStd        | 0.93467    |
| AverageReturn           | 278        |
| Entropy                 | 8.10509    |
| EnvExecTime             | 2.75       |
| ExplainedVariance       | 0.546      |
| Iteration               | 69         |
| ItrTime                 | 10.5       |
| LossAfter               | 0.137378   |
| LossBefore              | 0.19537    |
| MaxReturn               | 502        |
| MeanKL                  | 0.00999423 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 45.2       |
| NumTrajs                | 28         |
| Perplexity              | 3311.26    |
| PolicyExecTime          | 0.589      |
| ProcessExecTime         | 0.0839     |
| StdReturn               | 101        |
| Time                    | 738        |
| dLoss                   | 0.0579926  |
----------------------------------------
itr #70 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 70...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5072, #subsample_inputs: 5072
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.706      |
| AbsLearnSignalNew       | 0.706      |
| AbsLearningOld          | 0.706      |
| AverageDiscountedReturn | 111        |
| AveragePhiLoss          | 0.974272   |
| AveragePolicyStd        | 0.933691   |
| AverageReturn           | 304        |
| Entropy                 | 8.09893    |
| EnvExecTime             | 2.62       |
| ExplainedVariance       | 0.507      |
| Iteration               | 70         |
| ItrTime                 | 10.9       |
| LossAfter               | -0.0963381 |
| LossBefore              | -0.0544524 |
| MaxReturn               | 444        |
| MeanKL                  | 0.00644317 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 50.1       |
| NumTrajs                | 25         |
| Perplexity              | 3290.95    |
| PolicyExecTime          | 0.567      |
| ProcessExecTime         | 0.0771     |
| StdReturn               | 95.6       |
| Time                    | 749        |
| dLoss                   | 0.0418857  |
----------------------------------------
itr #71 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 71...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5116, #subsample_inputs: 5116
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.728      |
| AbsLearnSignalNew       | 0.728      |
| AbsLearningOld          | 0.728      |
| AverageDiscountedReturn | 112        |
| AveragePhiLoss          | 0.96828    |
| AveragePolicyStd        | 0.932534   |
| AverageReturn           | 310        |
| Entropy                 | 8.0915     |
| EnvExecTime             | 2.99       |
| ExplainedVariance       | 0.515      |
| Iteration               | 71         |
| ItrTime                 | 10.3       |
| LossAfter               | 0.122127   |
| LossBefore              | 0.166043   |
| MaxReturn               | 463        |
| MeanKL                  | 0.00641261 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 43.1       |
| NumTrajs                | 25         |
| Perplexity              | 3266.58    |
| PolicyExecTime          | 0.664      |
| ProcessExecTime         | 0.0899     |
| StdReturn               | 96.8       |
| Time                    | 760        |
| dLoss                   | 0.0439162  |
----------------------------------------
itr #72 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 72...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5010, #subsample_inputs: 5010
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.701      |
| AbsLearnSignalNew       | 0.701      |
| AbsLearningOld          | 0.701      |
| AverageDiscountedReturn | 108        |
| AveragePhiLoss          | 0.96739    |
| AveragePolicyStd        | 0.932279   |
| AverageReturn           | 338        |
| Entropy                 | 8.09005    |
| EnvExecTime             | 2.73       |
| ExplainedVariance       | 0.375      |
| Iteration               | 72         |
| ItrTime                 | 11         |
| LossAfter               | 0.354854   |
| LossBefore              | 0.408695   |
| MaxReturn               | 796        |
| MeanKL                  | 0.00997989 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 48.3       |
| NumTrajs                | 20         |
| Perplexity              | 3261.85    |
| PolicyExecTime          | 0.625      |
| ProcessExecTime         | 0.0815     |
| StdReturn               | 159        |
| Time                    | 771        |
| dLoss                   | 0.0538408  |
----------------------------------------
itr #73 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 73...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5092, #subsample_inputs: 5092
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.721      |
| AbsLearnSignalNew       | 0.721      |
| AbsLearningOld          | 0.721      |
| AverageDiscountedReturn | 109        |
| AveragePhiLoss          | 0.964757   |
| AveragePolicyStd        | 0.928693   |
| AverageReturn           | 325        |
| Entropy                 | 8.0677     |
| EnvExecTime             | 2.39       |
| ExplainedVariance       | 0.51       |
| Iteration               | 73         |
| ItrTime                 | 10.2       |
| LossAfter               | 0.91822    |
| LossBefore              | 0.972889   |
| MaxReturn               | 551        |
| MeanKL                  | 0.00992086 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 82.3       |
| NumTrajs                | 23         |
| Perplexity              | 3189.76    |
| PolicyExecTime          | 0.496      |
| ProcessExecTime         | 0.0664     |
| StdReturn               | 102        |
| Time                    | 781        |
| dLoss                   | 0.0546686  |
----------------------------------------
itr #74 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 74...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5033, #subsample_inputs: 5033
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.726      |
| AbsLearnSignalNew       | 0.726      |
| AbsLearningOld          | 0.726      |
| AverageDiscountedReturn | 114        |
| AveragePhiLoss          | 0.965178   |
| AveragePolicyStd        | 0.930467   |
| AverageReturn           | 318        |
| Entropy                 | 8.07866    |
| EnvExecTime             | 2.73       |
| ExplainedVariance       | 0.62       |
| Iteration               | 74         |
| ItrTime                 | 10.5       |
| LossAfter               | 0.850927   |
| LossBefore              | 0.894639   |
| MaxReturn               | 466        |
| MeanKL                  | 0.00647353 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 34.8       |
| NumTrajs                | 25         |
| Perplexity              | 3224.92    |
| PolicyExecTime          | 0.593      |
| ProcessExecTime         | 0.0817     |
| StdReturn               | 88.6       |
| Time                    | 792        |
| dLoss                   | 0.0437121  |
----------------------------------------
itr #75 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 75...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5036, #subsample_inputs: 5036
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.717      |
| AbsLearnSignalNew       | 0.717      |
| AbsLearningOld          | 0.717      |
| AverageDiscountedReturn | 111        |
| AveragePhiLoss          | 0.958871   |
| AveragePolicyStd        | 0.931733   |
| AverageReturn           | 313        |
| Entropy                 | 8.08615    |
| EnvExecTime             | 2.69       |
| ExplainedVariance       | 0.499      |
| Iteration               | 75         |
| ItrTime                 | 10.9       |
| LossAfter               | -0.567375  |
| LossBefore              | -0.523803  |
| MaxReturn               | 594        |
| MeanKL                  | 0.00642128 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 90.1       |
| NumTrajs                | 24         |
| Perplexity              | 3249.16    |
| PolicyExecTime          | 0.573      |
| ProcessExecTime         | 0.0776     |
| StdReturn               | 112        |
| Time                    | 803        |
| dLoss                   | 0.0435718  |
----------------------------------------
itr #76 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 76...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5050, #subsample_inputs: 5050
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.713      |
| AbsLearnSignalNew       | 0.713      |
| AbsLearningOld          | 0.713      |
| AverageDiscountedReturn | 112        |
| AveragePhiLoss          | 0.971697   |
| AveragePolicyStd        | 0.929342   |
| AverageReturn           | 347        |
| Entropy                 | 8.07115    |
| EnvExecTime             | 2.81       |
| ExplainedVariance       | 0.483      |
| Iteration               | 76         |
| ItrTime                 | 9.98       |
| LossAfter               | 0.221953   |
| LossBefore              | 0.279903   |
| MaxReturn               | 558        |
| MeanKL                  | 0.00989912 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 54.8       |
| NumTrajs                | 23         |
| Perplexity              | 3200.77    |
| PolicyExecTime          | 0.624      |
| ProcessExecTime         | 0.0827     |
| StdReturn               | 119        |
| Time                    | 813        |
| dLoss                   | 0.0579499  |
----------------------------------------
itr #77 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 77...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5014, #subsample_inputs: 5014
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.71       |
| AbsLearnSignalNew       | 0.71       |
| AbsLearningOld          | 0.71       |
| AverageDiscountedReturn | 107        |
| AveragePhiLoss          | 0.960235   |
| AveragePolicyStd        | 0.929323   |
| AverageReturn           | 303        |
| Entropy                 | 8.07058    |
| EnvExecTime             | 2.64       |
| ExplainedVariance       | 0.519      |
| Iteration               | 77         |
| ItrTime                 | 10.9       |
| LossAfter               | 0.28442    |
| LossBefore              | 0.342109   |
| MaxReturn               | 512        |
| MeanKL                  | 0.00979299 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 20         |
| NumTrajs                | 25         |
| Perplexity              | 3198.96    |
| PolicyExecTime          | 0.6        |
| ProcessExecTime         | 0.081      |
| StdReturn               | 119        |
| Time                    | 824        |
| dLoss                   | 0.0576898  |
----------------------------------------
itr #78 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 78...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5094, #subsample_inputs: 5094
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.739     |
| AbsLearnSignalNew       | 0.739     |
| AbsLearningOld          | 0.739     |
| AverageDiscountedReturn | 114       |
| AveragePhiLoss          | 0.971543  |
| AveragePolicyStd        | 0.930223  |
| AverageReturn           | 347       |
| Entropy                 | 8.07616   |
| EnvExecTime             | 2.53      |
| ExplainedVariance       | 0.528     |
| Iteration               | 78        |
| ItrTime                 | 10.6      |
| LossAfter               | 0.690757  |
| LossBefore              | 0.734507  |
| MaxReturn               | 693       |
| MeanKL                  | 0.0064486 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 75.1      |
| NumTrajs                | 23        |
| Perplexity              | 3216.87   |
| PolicyExecTime          | 0.544     |
| ProcessExecTime         | 0.0724    |
| StdReturn               | 125       |
| Time                    | 835       |
| dLoss                   | 0.0437502 |
---------------------------------------
itr #79 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 79...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5323, #subsample_inputs: 5323
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.761      |
| AbsLearnSignalNew       | 0.761      |
| AbsLearningOld          | 0.761      |
| AverageDiscountedReturn | 114        |
| AveragePhiLoss          | 0.968577   |
| AveragePolicyStd        | 0.930875   |
| AverageReturn           | 352        |
| Entropy                 | 8.07997    |
| EnvExecTime             | 2.93       |
| ExplainedVariance       | 0.648      |
| Iteration               | 79         |
| ItrTime                 | 11         |
| LossAfter               | -0.611795  |
| LossBefore              | -0.565882  |
| MaxReturn               | 528        |
| MeanKL                  | 0.00645266 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 234        |
| NumTrajs                | 24         |
| Perplexity              | 3229.15    |
| PolicyExecTime          | 0.646      |
| ProcessExecTime         | 0.0877     |
| StdReturn               | 87         |
| Time                    | 846        |
| dLoss                   | 0.0459126  |
----------------------------------------
itr #80 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 80...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5133, #subsample_inputs: 5133
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.635      |
| AbsLearnSignalNew       | 0.635      |
| AbsLearningOld          | 0.635      |
| AverageDiscountedReturn | 110        |
| AveragePhiLoss          | 0.969815   |
| AveragePolicyStd        | 0.93122    |
| AverageReturn           | 320        |
| Entropy                 | 8.08209    |
| EnvExecTime             | 2.68       |
| ExplainedVariance       | 0.402      |
| Iteration               | 80         |
| ItrTime                 | 11.2       |
| LossAfter               | -0.0406586 |
| LossBefore              | 0.0122154  |
| MaxReturn               | 643        |
| MeanKL                  | 0.00992045 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 47.9       |
| NumTrajs                | 24         |
| Perplexity              | 3236.0     |
| PolicyExecTime          | 0.576      |
| ProcessExecTime         | 0.0776     |
| StdReturn               | 110        |
| Time                    | 857        |
| dLoss                   | 0.052874   |
----------------------------------------
itr #81 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 81...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5068, #subsample_inputs: 5068
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.723     |
| AbsLearnSignalNew       | 0.723     |
| AbsLearningOld          | 0.723     |
| AverageDiscountedReturn | 111       |
| AveragePhiLoss          | 0.967081  |
| AveragePolicyStd        | 0.929312  |
| AverageReturn           | 345       |
| Entropy                 | 8.06979   |
| EnvExecTime             | 2.74      |
| ExplainedVariance       | 0.607     |
| Iteration               | 81        |
| ItrTime                 | 9.95      |
| LossAfter               | 0.280577  |
| LossBefore              | 0.334801  |
| MaxReturn               | 684       |
| MeanKL                  | 0.0099906 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 51.6      |
| NumTrajs                | 22        |
| Perplexity              | 3196.45   |
| PolicyExecTime          | 0.614     |
| ProcessExecTime         | 0.0854    |
| StdReturn               | 143       |
| Time                    | 867       |
| dLoss                   | 0.0542246 |
---------------------------------------
itr #82 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 82...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5004, #subsample_inputs: 5004
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.722      |
| AbsLearnSignalNew       | 0.722      |
| AbsLearningOld          | 0.722      |
| AverageDiscountedReturn | 112        |
| AveragePhiLoss          | 0.963603   |
| AveragePolicyStd        | 0.931173   |
| AverageReturn           | 338        |
| Entropy                 | 8.08068    |
| EnvExecTime             | 2.82       |
| ExplainedVariance       | 0.595      |
| Iteration               | 82         |
| ItrTime                 | 11.1       |
| LossAfter               | -0.177505  |
| LossBefore              | -0.117757  |
| MaxReturn               | 496        |
| MeanKL                  | 0.00983812 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 52.4       |
| NumTrajs                | 23         |
| Perplexity              | 3231.42    |
| PolicyExecTime          | 0.626      |
| ProcessExecTime         | 0.0837     |
| StdReturn               | 94.1       |
| Time                    | 878        |
| dLoss                   | 0.0597477  |
----------------------------------------
itr #83 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 83...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5045, #subsample_inputs: 5045
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.626      |
| AbsLearnSignalNew       | 0.626      |
| AbsLearningOld          | 0.626      |
| AverageDiscountedReturn | 110        |
| AveragePhiLoss          | 0.961237   |
| AveragePolicyStd        | 0.932787   |
| AverageReturn           | 325        |
| Entropy                 | 8.09113    |
| EnvExecTime             | 2.58       |
| ExplainedVariance       | 0.185      |
| Iteration               | 83         |
| ItrTime                 | 10.6       |
| LossAfter               | 0.243735   |
| LossBefore              | 0.294105   |
| MaxReturn               | 600        |
| MeanKL                  | 0.00997326 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 56.4       |
| NumTrajs                | 23         |
| Perplexity              | 3265.38    |
| PolicyExecTime          | 0.529      |
| ProcessExecTime         | 0.0708     |
| StdReturn               | 119        |
| Time                    | 889        |
| dLoss                   | 0.0503707  |
----------------------------------------
itr #84 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 84...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5133, #subsample_inputs: 5133
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.732      |
| AbsLearnSignalNew       | 0.732      |
| AbsLearningOld          | 0.732      |
| AverageDiscountedReturn | 118        |
| AveragePhiLoss          | 0.962926   |
| AveragePolicyStd        | 0.929684   |
| AverageReturn           | 348        |
| Entropy                 | 8.07111    |
| EnvExecTime             | 2.62       |
| ExplainedVariance       | 0.612      |
| Iteration               | 84         |
| ItrTime                 | 10.3       |
| LossAfter               | 1.02179    |
| LossBefore              | 1.06802    |
| MaxReturn               | 615        |
| MeanKL                  | 0.00645994 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 56.2       |
| NumTrajs                | 24         |
| Perplexity              | 3200.64    |
| PolicyExecTime          | 0.576      |
| ProcessExecTime         | 0.0824     |
| StdReturn               | 101        |
| Time                    | 899        |
| dLoss                   | 0.0462276  |
----------------------------------------
itr #85 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 85...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5005, #subsample_inputs: 5005
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.71      |
| AbsLearnSignalNew       | 0.71      |
| AbsLearningOld          | 0.71      |
| AverageDiscountedReturn | 104       |
| AveragePhiLoss          | 0.968723  |
| AveragePolicyStd        | 0.926478  |
| AverageReturn           | 343       |
| Entropy                 | 8.05085   |
| EnvExecTime             | 2.59      |
| ExplainedVariance       | 0.575     |
| Iteration               | 85        |
| ItrTime                 | 10.8      |
| LossAfter               | 0.371304  |
| LossBefore              | 0.426241  |
| MaxReturn               | 565       |
| MeanKL                  | 0.0098777 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 28.2      |
| NumTrajs                | 22        |
| Perplexity              | 3136.45   |
| PolicyExecTime          | 0.547     |
| ProcessExecTime         | 0.0757    |
| StdReturn               | 143       |
| Time                    | 910       |
| dLoss                   | 0.054937  |
---------------------------------------
itr #86 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 86...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5079, #subsample_inputs: 5079
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.71       |
| AbsLearnSignalNew       | 0.71       |
| AbsLearningOld          | 0.71       |
| AverageDiscountedReturn | 110        |
| AveragePhiLoss          | 0.976046   |
| AveragePolicyStd        | 0.92581    |
| AverageReturn           | 332        |
| Entropy                 | 8.04671    |
| EnvExecTime             | 2.89       |
| ExplainedVariance       | 0.544      |
| Iteration               | 86         |
| ItrTime                 | 9.85       |
| LossAfter               | -0.611178  |
| LossBefore              | -0.5706    |
| MaxReturn               | 502        |
| MeanKL                  | 0.00649177 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 55.1       |
| NumTrajs                | 23         |
| Perplexity              | 3123.51    |
| PolicyExecTime          | 0.617      |
| ProcessExecTime         | 0.0839     |
| StdReturn               | 120        |
| Time                    | 920        |
| dLoss                   | 0.0405783  |
----------------------------------------
itr #87 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 87...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5083, #subsample_inputs: 5083
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.726      |
| AbsLearnSignalNew       | 0.726      |
| AbsLearningOld          | 0.726      |
| AverageDiscountedReturn | 118        |
| AveragePhiLoss          | 0.963824   |
| AveragePolicyStd        | 0.924234   |
| AverageReturn           | 345        |
| Entropy                 | 8.03632    |
| EnvExecTime             | 2.9        |
| ExplainedVariance       | 0.568      |
| Iteration               | 87         |
| ItrTime                 | 11.4       |
| LossAfter               | 0.0385607  |
| LossBefore              | 0.086451   |
| MaxReturn               | 463        |
| MeanKL                  | 0.00640555 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 126        |
| NumTrajs                | 23         |
| Perplexity              | 3091.21    |
| PolicyExecTime          | 0.638      |
| ProcessExecTime         | 0.086      |
| StdReturn               | 73.7       |
| Time                    | 932        |
| dLoss                   | 0.0478903  |
----------------------------------------
itr #88 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 88...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5126, #subsample_inputs: 5126
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.721      |
| AbsLearnSignalNew       | 0.721      |
| AbsLearningOld          | 0.721      |
| AverageDiscountedReturn | 107        |
| AveragePhiLoss          | 0.970285   |
| AveragePolicyStd        | 0.926235   |
| AverageReturn           | 309        |
| Entropy                 | 8.04952    |
| EnvExecTime             | 2.59       |
| ExplainedVariance       | 0.523      |
| Iteration               | 88         |
| ItrTime                 | 10.6       |
| LossAfter               | 0.562278   |
| LossBefore              | 0.604183   |
| MaxReturn               | 456        |
| MeanKL                  | 0.00644453 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 45.1       |
| NumTrajs                | 24         |
| Perplexity              | 3132.28    |
| PolicyExecTime          | 0.543      |
| ProcessExecTime         | 0.0717     |
| StdReturn               | 117        |
| Time                    | 942        |
| dLoss                   | 0.0419056  |
----------------------------------------
itr #89 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 89...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5098, #subsample_inputs: 5098
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.683      |
| AbsLearnSignalNew       | 0.683      |
| AbsLearningOld          | 0.683      |
| AverageDiscountedReturn | 114        |
| AveragePhiLoss          | 0.958131   |
| AveragePolicyStd        | 0.92202    |
| AverageReturn           | 309        |
| Entropy                 | 8.0223     |
| EnvExecTime             | 2.68       |
| ExplainedVariance       | 0.537      |
| Iteration               | 89         |
| ItrTime                 | 10.5       |
| LossAfter               | 0.161525   |
| LossBefore              | 0.227743   |
| MaxReturn               | 472        |
| MeanKL                  | 0.00988811 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 88.3       |
| NumTrajs                | 26         |
| Perplexity              | 3048.18    |
| PolicyExecTime          | 0.586      |
| ProcessExecTime         | 0.0816     |
| StdReturn               | 87.2       |
| Time                    | 953        |
| dLoss                   | 0.0662182  |
----------------------------------------
itr #90 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 90...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5122, #subsample_inputs: 5122
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.712      |
| AbsLearnSignalNew       | 0.712      |
| AbsLearningOld          | 0.712      |
| AverageDiscountedReturn | 114        |
| AveragePhiLoss          | 0.964001   |
| AveragePolicyStd        | 0.925732   |
| AverageReturn           | 347        |
| Entropy                 | 8.04551    |
| EnvExecTime             | 2.74       |
| ExplainedVariance       | 0.589      |
| Iteration               | 90         |
| ItrTime                 | 11.1       |
| LossAfter               | -0.247419  |
| LossBefore              | -0.204031  |
| MaxReturn               | 594        |
| MeanKL                  | 0.00644839 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 75.4       |
| NumTrajs                | 23         |
| Perplexity              | 3119.77    |
| PolicyExecTime          | 0.567      |
| ProcessExecTime         | 0.0763     |
| StdReturn               | 103        |
| Time                    | 964        |
| dLoss                   | 0.0433882  |
----------------------------------------
itr #91 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 91...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5179, #subsample_inputs: 5179
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.715     |
| AbsLearnSignalNew       | 0.715     |
| AbsLearningOld          | 0.715     |
| AverageDiscountedReturn | 117       |
| AveragePhiLoss          | 0.970614  |
| AveragePolicyStd        | 0.924681  |
| AverageReturn           | 364       |
| Entropy                 | 8.03848   |
| EnvExecTime             | 2.98      |
| ExplainedVariance       | 0.622     |
| Iteration               | 91        |
| ItrTime                 | 10.3      |
| LossAfter               | 0.24318   |
| LossBefore              | 0.29866   |
| MaxReturn               | 572       |
| MeanKL                  | 0.0098992 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 111       |
| NumTrajs                | 23        |
| Perplexity              | 3097.91   |
| PolicyExecTime          | 0.675     |
| ProcessExecTime         | 0.0892    |
| StdReturn               | 105       |
| Time                    | 975       |
| dLoss                   | 0.0554804 |
---------------------------------------
itr #92 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 92...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5136, #subsample_inputs: 5136
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.692      |
| AbsLearnSignalNew       | 0.692      |
| AbsLearningOld          | 0.692      |
| AverageDiscountedReturn | 111        |
| AveragePhiLoss          | 0.965772   |
| AveragePolicyStd        | 0.925073   |
| AverageReturn           | 319        |
| Entropy                 | 8.04195    |
| EnvExecTime             | 2.83       |
| ExplainedVariance       | 0.54       |
| Iteration               | 92         |
| ItrTime                 | 11.3       |
| LossAfter               | 0.242575   |
| LossBefore              | 0.284835   |
| MaxReturn               | 475        |
| MeanKL                  | 0.00641615 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 43         |
| NumTrajs                | 24         |
| Perplexity              | 3108.68    |
| PolicyExecTime          | 0.607      |
| ProcessExecTime         | 0.0839     |
| StdReturn               | 113        |
| Time                    | 986        |
| dLoss                   | 0.0422597  |
----------------------------------------
itr #93 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 93...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5054, #subsample_inputs: 5054
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.694      |
| AbsLearnSignalNew       | 0.694      |
| AbsLearningOld          | 0.694      |
| AverageDiscountedReturn | 116        |
| AveragePhiLoss          | 0.965487   |
| AveragePolicyStd        | 0.923571   |
| AverageReturn           | 312        |
| Entropy                 | 8.03192    |
| EnvExecTime             | 2.64       |
| ExplainedVariance       | 0.54       |
| Iteration               | 93         |
| ItrTime                 | 10.6       |
| LossAfter               | 0.0748656  |
| LossBefore              | 0.119932   |
| MaxReturn               | 510        |
| MeanKL                  | 0.00650398 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 80.5       |
| NumTrajs                | 26         |
| Perplexity              | 3077.64    |
| PolicyExecTime          | 0.544      |
| ProcessExecTime         | 0.0714     |
| StdReturn               | 99.5       |
| Time                    | 997        |
| dLoss                   | 0.0450667  |
----------------------------------------
itr #94 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 94...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5186, #subsample_inputs: 5186
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.734      |
| AbsLearnSignalNew       | 0.734      |
| AbsLearningOld          | 0.734      |
| AverageDiscountedReturn | 113        |
| AveragePhiLoss          | 0.965315   |
| AveragePolicyStd        | 0.922384   |
| AverageReturn           | 334        |
| Entropy                 | 8.02281    |
| EnvExecTime             | 2.78       |
| ExplainedVariance       | 0.604      |
| Iteration               | 94         |
| ItrTime                 | 10.8       |
| LossAfter               | 0.169983   |
| LossBefore              | 0.226855   |
| MaxReturn               | 487        |
| MeanKL                  | 0.00985921 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 102        |
| NumTrajs                | 24         |
| Perplexity              | 3049.72    |
| PolicyExecTime          | 0.625      |
| ProcessExecTime         | 0.0877     |
| StdReturn               | 89.2       |
| Time                    | 1.01e+03   |
| dLoss                   | 0.0568722  |
----------------------------------------
itr #95 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 95...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5025, #subsample_inputs: 5025
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.681      |
| AbsLearnSignalNew       | 0.681      |
| AbsLearningOld          | 0.681      |
| AverageDiscountedReturn | 109        |
| AveragePhiLoss          | 0.964651   |
| AveragePolicyStd        | 0.922755   |
| AverageReturn           | 295        |
| Entropy                 | 8.02517    |
| EnvExecTime             | 2.76       |
| ExplainedVariance       | 0.623      |
| Iteration               | 95         |
| ItrTime                 | 11.1       |
| LossAfter               | 0.194142   |
| LossBefore              | 0.247729   |
| MaxReturn               | 447        |
| MeanKL                  | 0.00991959 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 21.5       |
| NumTrajs                | 27         |
| Perplexity              | 3056.95    |
| PolicyExecTime          | 0.578      |
| ProcessExecTime         | 0.0786     |
| StdReturn               | 123        |
| Time                    | 1.02e+03   |
| dLoss                   | 0.0535865  |
----------------------------------------
itr #96 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 96...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5250, #subsample_inputs: 5250
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.427      |
| AbsLearnSignalNew       | 0.427      |
| AbsLearningOld          | 0.427      |
| AverageDiscountedReturn | 115        |
| AveragePhiLoss          | 0.947913   |
| AveragePolicyStd        | 0.92423    |
| AverageReturn           | 386        |
| Entropy                 | 8.03469    |
| EnvExecTime             | 2.91       |
| ExplainedVariance       | -1.78      |
| Iteration               | 96         |
| ItrTime                 | 10.1       |
| LossAfter               | 0.801568   |
| LossBefore              | 0.907666   |
| MaxReturn               | 703        |
| MeanKL                  | 0.00983854 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 204        |
| NumTrajs                | 21         |
| Perplexity              | 3086.18    |
| PolicyExecTime          | 0.62       |
| ProcessExecTime         | 0.085      |
| StdReturn               | 106        |
| Time                    | 1.03e+03   |
| dLoss                   | 0.106098   |
----------------------------------------
itr #97 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 97...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5048, #subsample_inputs: 5048
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.647      |
| AbsLearnSignalNew       | 0.647      |
| AbsLearningOld          | 0.647      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 0.959929   |
| AveragePolicyStd        | 0.923674   |
| AverageReturn           | 344        |
| Entropy                 | 8.03024    |
| EnvExecTime             | 2.7        |
| ExplainedVariance       | 0.576      |
| Iteration               | 97         |
| ItrTime                 | 11.2       |
| LossAfter               | 0.608338   |
| LossBefore              | 0.666475   |
| MaxReturn               | 486        |
| MeanKL                  | 0.00997778 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 66.6       |
| NumTrajs                | 25         |
| Perplexity              | 3072.49    |
| PolicyExecTime          | 0.579      |
| ProcessExecTime         | 0.0816     |
| StdReturn               | 97.8       |
| Time                    | 1.04e+03   |
| dLoss                   | 0.0581374  |
----------------------------------------
itr #98 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 98...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5110, #subsample_inputs: 5110
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.714      |
| AbsLearnSignalNew       | 0.714      |
| AbsLearningOld          | 0.714      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 0.972851   |
| AveragePolicyStd        | 0.922631   |
| AverageReturn           | 362        |
| Entropy                 | 8.02412    |
| EnvExecTime             | 2.41       |
| ExplainedVariance       | 0.672      |
| Iteration               | 98         |
| ItrTime                 | 10.3       |
| LossAfter               | 0.492338   |
| LossBefore              | 0.546101   |
| MaxReturn               | 533        |
| MeanKL                  | 0.00991495 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 74         |
| NumTrajs                | 24         |
| Perplexity              | 3053.73    |
| PolicyExecTime          | 0.48       |
| ProcessExecTime         | 0.0674     |
| StdReturn               | 90         |
| Time                    | 1.05e+03   |
| dLoss                   | 0.0537632  |
----------------------------------------
itr #99 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 99...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5013, #subsample_inputs: 5013
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.656      |
| AbsLearnSignalNew       | 0.656      |
| AbsLearningOld          | 0.656      |
| AverageDiscountedReturn | 117        |
| AveragePhiLoss          | 0.961094   |
| AveragePolicyStd        | 0.925071   |
| AverageReturn           | 345        |
| Entropy                 | 8.03974    |
| EnvExecTime             | 2.75       |
| ExplainedVariance       | 0.613      |
| Iteration               | 99         |
| ItrTime                 | 10.4       |
| LossAfter               | 0.269548   |
| LossBefore              | 0.323939   |
| MaxReturn               | 502        |
| MeanKL                  | 0.00994353 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 68.9       |
| NumTrajs                | 24         |
| Perplexity              | 3101.81    |
| PolicyExecTime          | 0.585      |
| ProcessExecTime         | 0.0835     |
| StdReturn               | 107        |
| Time                    | 1.06e+03   |
| dLoss                   | 0.0543914  |
----------------------------------------
itr #100 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 100...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5013, #subsample_inputs: 5013
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.687      |
| AbsLearnSignalNew       | 0.687      |
| AbsLearningOld          | 0.687      |
| AverageDiscountedReturn | 109        |
| AveragePhiLoss          | 0.961271   |
| AveragePolicyStd        | 0.92281    |
| AverageReturn           | 300        |
| Entropy                 | 8.02508    |
| EnvExecTime             | 2.56       |
| ExplainedVariance       | 0.488      |
| Iteration               | 100        |
| ItrTime                 | 10.9       |
| LossAfter               | -0.61059   |
| LossBefore              | -0.56376   |
| MaxReturn               | 478        |
| MeanKL                  | 0.00645971 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 54.1       |
| NumTrajs                | 25         |
| Perplexity              | 3056.66    |
| PolicyExecTime          | 0.539      |
| ProcessExecTime         | 0.0713     |
| StdReturn               | 125        |
| Time                    | 1.07e+03   |
| dLoss                   | 0.0468305  |
----------------------------------------
itr #101 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 101...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5157, #subsample_inputs: 5157
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.576      |
| AbsLearnSignalNew       | 0.576      |
| AbsLearningOld          | 0.576      |
| AverageDiscountedReturn | 115        |
| AveragePhiLoss          | 0.963531   |
| AveragePolicyStd        | 0.922259   |
| AverageReturn           | 357        |
| Entropy                 | 8.02153    |
| EnvExecTime             | 2.95       |
| ExplainedVariance       | 0.127      |
| Iteration               | 101        |
| ItrTime                 | 10.1       |
| LossAfter               | 0.392633   |
| LossBefore              | 0.460659   |
| MaxReturn               | 574        |
| MeanKL                  | 0.00997453 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 105        |
| NumTrajs                | 22         |
| Perplexity              | 3045.83    |
| PolicyExecTime          | 0.631      |
| ProcessExecTime         | 0.0861     |
| StdReturn               | 117        |
| Time                    | 1.08e+03   |
| dLoss                   | 0.0680258  |
----------------------------------------
itr #102 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 102...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5039, #subsample_inputs: 5039
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.701      |
| AbsLearnSignalNew       | 0.701      |
| AbsLearningOld          | 0.701      |
| AverageDiscountedReturn | 118        |
| AveragePhiLoss          | 0.955874   |
| AveragePolicyStd        | 0.926011   |
| AverageReturn           | 358        |
| Entropy                 | 8.04576    |
| EnvExecTime             | 2.84       |
| ExplainedVariance       | 0.625      |
| Iteration               | 102        |
| ItrTime                 | 11.1       |
| LossAfter               | 1.11982    |
| LossBefore              | 1.18017    |
| MaxReturn               | 486        |
| MeanKL                  | 0.00996766 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 96.3       |
| NumTrajs                | 23         |
| Perplexity              | 3120.54    |
| PolicyExecTime          | 0.616      |
| ProcessExecTime         | 0.0839     |
| StdReturn               | 88.1       |
| Time                    | 1.09e+03   |
| dLoss                   | 0.0603517  |
----------------------------------------
itr #103 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 103...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5207, #subsample_inputs: 5207
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.662      |
| AbsLearnSignalNew       | 0.662      |
| AbsLearningOld          | 0.662      |
| AverageDiscountedReturn | 116        |
| AveragePhiLoss          | 0.9702     |
| AveragePolicyStd        | 0.927197   |
| AverageReturn           | 368        |
| Entropy                 | 8.05338    |
| EnvExecTime             | 2.58       |
| ExplainedVariance       | 0.581      |
| Iteration               | 103        |
| ItrTime                 | 10.7       |
| LossAfter               | -0.100494  |
| LossBefore              | -0.0488219 |
| MaxReturn               | 560        |
| MeanKL                  | 0.00999318 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 121        |
| NumTrajs                | 22         |
| Perplexity              | 3144.42    |
| PolicyExecTime          | 0.52       |
| ProcessExecTime         | 0.0705     |
| StdReturn               | 109        |
| Time                    | 1.1e+03    |
| dLoss                   | 0.0516725  |
----------------------------------------
itr #104 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 104...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5148, #subsample_inputs: 5148
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.699      |
| AbsLearnSignalNew       | 0.699      |
| AbsLearningOld          | 0.699      |
| AverageDiscountedReturn | 117        |
| AveragePhiLoss          | 0.974041   |
| AveragePolicyStd        | 0.925662   |
| AverageReturn           | 347        |
| Entropy                 | 8.04378    |
| EnvExecTime             | 3.01       |
| ExplainedVariance       | 0.584      |
| Iteration               | 104        |
| ItrTime                 | 10.6       |
| LossAfter               | 1.04505    |
| LossBefore              | 1.08835    |
| MaxReturn               | 562        |
| MeanKL                  | 0.00640772 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 68         |
| NumTrajs                | 23         |
| Perplexity              | 3114.35    |
| PolicyExecTime          | 0.637      |
| ProcessExecTime         | 0.0868     |
| StdReturn               | 106        |
| Time                    | 1.12e+03   |
| dLoss                   | 0.0432955  |
----------------------------------------
itr #105 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 105...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5058, #subsample_inputs: 5058
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.731      |
| AbsLearnSignalNew       | 0.731      |
| AbsLearningOld          | 0.731      |
| AverageDiscountedReturn | 117        |
| AveragePhiLoss          | 0.973518   |
| AveragePolicyStd        | 0.927288   |
| AverageReturn           | 337        |
| Entropy                 | 8.05382    |
| EnvExecTime             | 2.82       |
| ExplainedVariance       | 0.602      |
| Iteration               | 105        |
| ItrTime                 | 11.1       |
| LossAfter               | 1.44122    |
| LossBefore              | 1.49477    |
| MaxReturn               | 495        |
| MeanKL                  | 0.00997385 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 120        |
| NumTrajs                | 24         |
| Perplexity              | 3145.8     |
| PolicyExecTime          | 0.595      |
| ProcessExecTime         | 0.0804     |
| StdReturn               | 78.9       |
| Time                    | 1.13e+03   |
| dLoss                   | 0.0535548  |
----------------------------------------
itr #106 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 106...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5035, #subsample_inputs: 5035
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.504     |
| AbsLearnSignalNew       | 0.504     |
| AbsLearningOld          | 0.504     |
| AverageDiscountedReturn | 117       |
| AveragePhiLoss          | 0.969988  |
| AveragePolicyStd        | 0.927167  |
| AverageReturn           | 399       |
| Entropy                 | 8.05325   |
| EnvExecTime             | 2.89      |
| ExplainedVariance       | -0.436    |
| Iteration               | 106       |
| ItrTime                 | 10.3      |
| LossAfter               | 0.801648  |
| LossBefore              | 0.849687  |
| MaxReturn               | 668       |
| MeanKL                  | 0.0099273 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 154       |
| NumTrajs                | 20        |
| Perplexity              | 3144.0    |
| PolicyExecTime          | 0.618     |
| ProcessExecTime         | 0.0799    |
| StdReturn               | 110       |
| Time                    | 1.14e+03  |
| dLoss                   | 0.0480387 |
---------------------------------------
itr #107 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 107...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5135, #subsample_inputs: 5135
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.679      |
| AbsLearnSignalNew       | 0.679      |
| AbsLearningOld          | 0.679      |
| AverageDiscountedReturn | 116        |
| AveragePhiLoss          | 0.962101   |
| AveragePolicyStd        | 0.926482   |
| AverageReturn           | 344        |
| Entropy                 | 8.04802    |
| EnvExecTime             | 3.01       |
| ExplainedVariance       | 0.624      |
| Iteration               | 107        |
| ItrTime                 | 11.5       |
| LossAfter               | -0.0259045 |
| LossBefore              | 0.0281966  |
| MaxReturn               | 489        |
| MeanKL                  | 0.00997503 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 72         |
| NumTrajs                | 24         |
| Perplexity              | 3127.6     |
| PolicyExecTime          | 0.667      |
| ProcessExecTime         | 0.09       |
| StdReturn               | 104        |
| Time                    | 1.15e+03   |
| dLoss                   | 0.0541011  |
----------------------------------------
itr #108 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 108...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5049, #subsample_inputs: 5049
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.722      |
| AbsLearnSignalNew       | 0.722      |
| AbsLearningOld          | 0.722      |
| AverageDiscountedReturn | 114        |
| AveragePhiLoss          | 0.965028   |
| AveragePolicyStd        | 0.925147   |
| AverageReturn           | 326        |
| Entropy                 | 8.03794    |
| EnvExecTime             | 2.31       |
| ExplainedVariance       | 0.582      |
| Iteration               | 108        |
| ItrTime                 | 10.5       |
| LossAfter               | 0.435262   |
| LossBefore              | 0.487194   |
| MaxReturn               | 503        |
| MeanKL                  | 0.00989812 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 49.8       |
| NumTrajs                | 24         |
| Perplexity              | 3096.22    |
| PolicyExecTime          | 0.458      |
| ProcessExecTime         | 0.0632     |
| StdReturn               | 108        |
| Time                    | 1.16e+03   |
| dLoss                   | 0.0519317  |
----------------------------------------
itr #109 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 109...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5141, #subsample_inputs: 5141
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.486      |
| AbsLearnSignalNew       | 0.486      |
| AbsLearningOld          | 0.486      |
| AverageDiscountedReturn | 108        |
| AveragePhiLoss          | 0.950327   |
| AveragePolicyStd        | 0.924451   |
| AverageReturn           | 332        |
| Entropy                 | 8.03395    |
| EnvExecTime             | 2.84       |
| ExplainedVariance       | -0.75      |
| Iteration               | 109        |
| ItrTime                 | 10         |
| LossAfter               | -0.396258  |
| LossBefore              | -0.348334  |
| MaxReturn               | 778        |
| MeanKL                  | 0.00997402 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 61.6       |
| NumTrajs                | 22         |
| Perplexity              | 3083.9     |
| PolicyExecTime          | 0.597      |
| ProcessExecTime         | 0.0823     |
| StdReturn               | 162        |
| Time                    | 1.17e+03   |
| dLoss                   | 0.0479238  |
----------------------------------------
itr #110 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 110...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5134, #subsample_inputs: 5134
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.729      |
| AbsLearnSignalNew       | 0.729      |
| AbsLearningOld          | 0.729      |
| AverageDiscountedReturn | 111        |
| AveragePhiLoss          | 0.968137   |
| AveragePolicyStd        | 0.921928   |
| AverageReturn           | 328        |
| Entropy                 | 8.01679    |
| EnvExecTime             | 2.74       |
| ExplainedVariance       | 0.555      |
| Iteration               | 110        |
| ItrTime                 | 11.3       |
| LossAfter               | 0.920121   |
| LossBefore              | 0.978667   |
| MaxReturn               | 490        |
| MeanKL                  | 0.00977131 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 49.1       |
| NumTrajs                | 24         |
| Perplexity              | 3031.44    |
| PolicyExecTime          | 0.61       |
| ProcessExecTime         | 0.0831     |
| StdReturn               | 123        |
| Time                    | 1.18e+03   |
| dLoss                   | 0.0585465  |
----------------------------------------
itr #111 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 111...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5091, #subsample_inputs: 5091
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.689      |
| AbsLearnSignalNew       | 0.689      |
| AbsLearningOld          | 0.689      |
| AverageDiscountedReturn | 113        |
| AveragePhiLoss          | 0.969383   |
| AveragePolicyStd        | 0.923522   |
| AverageReturn           | 336        |
| Entropy                 | 8.02773    |
| EnvExecTime             | 2.74       |
| ExplainedVariance       | 0.582      |
| Iteration               | 111        |
| ItrTime                 | 10.1       |
| LossAfter               | 0.201543   |
| LossBefore              | 0.245266   |
| MaxReturn               | 581        |
| MeanKL                  | 0.00641988 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 50.8       |
| NumTrajs                | 23         |
| Perplexity              | 3064.79    |
| PolicyExecTime          | 0.578      |
| ProcessExecTime         | 0.0788     |
| StdReturn               | 125        |
| Time                    | 1.19e+03   |
| dLoss                   | 0.0437233  |
----------------------------------------
itr #112 | 
Mem: 732.402344
Obtaining samples...
Obtaining samples for iteration 112...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5207, #subsample_inputs: 5207
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.728     |
| AbsLearnSignalNew       | 0.728     |
| AbsLearningOld          | 0.728     |
| AverageDiscountedReturn | 120       |
| AveragePhiLoss          | 0.969329  |
| AveragePolicyStd        | 0.924786  |
| AverageReturn           | 366       |
| Entropy                 | 8.03597   |
| EnvExecTime             | 3.08      |
| ExplainedVariance       | 0.516     |
| Iteration               | 112       |
| ItrTime                 | 11.4      |
| LossAfter               | 0.871979  |
| LossBefore              | 0.912942  |
| MaxReturn               | 522       |
| MeanKL                  | 0.0064294 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 137       |
| NumTrajs                | 23        |
| Perplexity              | 3090.13   |
| PolicyExecTime          | 0.665     |
| ProcessExecTime         | 0.089     |
| StdReturn               | 99.2      |
| Time                    | 1.2e+03   |
| dLoss                   | 0.0409632 |
---------------------------------------
itr #113 | 
Mem: 733.355469
Obtaining samples...
Obtaining samples for iteration 113...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5085, #subsample_inputs: 5085
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.702      |
| AbsLearnSignalNew       | 0.702      |
| AbsLearningOld          | 0.702      |
| AverageDiscountedReturn | 114        |
| AveragePhiLoss          | 0.963193   |
| AveragePolicyStd        | 0.922652   |
| AverageReturn           | 353        |
| Entropy                 | 8.02142    |
| EnvExecTime             | 2.58       |
| ExplainedVariance       | 0.538      |
| Iteration               | 113        |
| ItrTime                 | 11.1       |
| LossAfter               | 0.743181   |
| LossBefore              | 0.79461    |
| MaxReturn               | 509        |
| MeanKL                  | 0.00990494 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 46.7       |
| NumTrajs                | 22         |
| Perplexity              | 3045.51    |
| PolicyExecTime          | 0.516      |
| ProcessExecTime         | 0.0678     |
| StdReturn               | 120        |
| Time                    | 1.21e+03   |
| dLoss                   | 0.0514287  |
----------------------------------------
itr #114 | 
Mem: 733.355469
Obtaining samples...
Obtaining samples for iteration 114...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5141, #subsample_inputs: 5141
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.697      |
| AbsLearnSignalNew       | 0.697      |
| AbsLearningOld          | 0.697      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 0.961926   |
| AveragePolicyStd        | 0.91986    |
| AverageReturn           | 376        |
| Entropy                 | 8.00301    |
| EnvExecTime             | 2.78       |
| ExplainedVariance       | 0.607      |
| Iteration               | 114        |
| ItrTime                 | 9.89       |
| LossAfter               | 0.397272   |
| LossBefore              | 0.454128   |
| MaxReturn               | 486        |
| MeanKL                  | 0.00999501 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 258        |
| NumTrajs                | 24         |
| Perplexity              | 2989.94    |
| PolicyExecTime          | 0.603      |
| ProcessExecTime         | 0.0805     |
| StdReturn               | 56.5       |
| Time                    | 1.22e+03   |
| dLoss                   | 0.0568555  |
----------------------------------------
itr #115 | 
Mem: 733.355469
Obtaining samples...
Obtaining samples for iteration 115...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5112, #subsample_inputs: 5112
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.422      |
| AbsLearnSignalNew       | 0.422      |
| AbsLearningOld          | 0.422      |
| AverageDiscountedReturn | 118        |
| AveragePhiLoss          | 0.972983   |
| AveragePolicyStd        | 0.919268   |
| AverageReturn           | 350        |
| Entropy                 | 7.99882    |
| EnvExecTime             | 2.89       |
| ExplainedVariance       | -0.845     |
| Iteration               | 115        |
| ItrTime                 | 11.2       |
| LossAfter               | 0.821327   |
| LossBefore              | 0.857712   |
| MaxReturn               | 569        |
| MeanKL                  | 0.00646293 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 33.4       |
| NumTrajs                | 23         |
| Perplexity              | 2977.46    |
| PolicyExecTime          | 0.606      |
| ProcessExecTime         | 0.0851     |
| StdReturn               | 101        |
| Time                    | 1.23e+03   |
| dLoss                   | 0.0363846  |
----------------------------------------
itr #116 | 
Mem: 733.355469
Obtaining samples...
Obtaining samples for iteration 116...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5116, #subsample_inputs: 5116
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.712      |
| AbsLearnSignalNew       | 0.712      |
| AbsLearningOld          | 0.712      |
| AverageDiscountedReturn | 123        |
| AveragePhiLoss          | 0.956917   |
| AveragePolicyStd        | 0.915955   |
| AverageReturn           | 368        |
| Entropy                 | 7.97805    |
| EnvExecTime             | 2.69       |
| ExplainedVariance       | 0.638      |
| Iteration               | 116        |
| ItrTime                 | 10.3       |
| LossAfter               | 0.670144   |
| LossBefore              | 0.730848   |
| MaxReturn               | 511        |
| MeanKL                  | 0.00981145 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 239        |
| NumTrajs                | 23         |
| Perplexity              | 2916.24    |
| PolicyExecTime          | 0.561      |
| ProcessExecTime         | 0.078      |
| StdReturn               | 72.8       |
| Time                    | 1.25e+03   |
| dLoss                   | 0.0607031  |
----------------------------------------
itr #117 | 
Mem: 733.355469
Obtaining samples...
Obtaining samples for iteration 117...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5216, #subsample_inputs: 5216
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.682      |
| AbsLearnSignalNew       | 0.682      |
| AbsLearningOld          | 0.682      |
| AverageDiscountedReturn | 114        |
| AveragePhiLoss          | 0.969049   |
| AveragePolicyStd        | 0.916054   |
| AverageReturn           | 333        |
| Entropy                 | 7.98056    |
| EnvExecTime             | 2.91       |
| ExplainedVariance       | 0.579      |
| Iteration               | 117        |
| ItrTime                 | 11.1       |
| LossAfter               | 0.575523   |
| LossBefore              | 0.628841   |
| MaxReturn               | 501        |
| MeanKL                  | 0.00995028 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 30.4       |
| NumTrajs                | 24         |
| Perplexity              | 2923.56    |
| PolicyExecTime          | 0.603      |
| ProcessExecTime         | 0.0822     |
| StdReturn               | 119        |
| Time                    | 1.26e+03   |
| dLoss                   | 0.0533176  |
----------------------------------------
itr #118 | 
Mem: 733.355469
Obtaining samples...
Obtaining samples for iteration 118...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5139, #subsample_inputs: 5139
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.708      |
| AbsLearnSignalNew       | 0.708      |
| AbsLearningOld          | 0.708      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 0.963365   |
| AveragePolicyStd        | 0.91644    |
| AverageReturn           | 357        |
| Entropy                 | 7.98226    |
| EnvExecTime             | 2.64       |
| ExplainedVariance       | 0.575      |
| Iteration               | 118        |
| ItrTime                 | 11         |
| LossAfter               | 0.0480071  |
| LossBefore              | 0.100213   |
| MaxReturn               | 497        |
| MeanKL                  | 0.00976273 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 70.9       |
| NumTrajs                | 24         |
| Perplexity              | 2928.55    |
| PolicyExecTime          | 0.536      |
| ProcessExecTime         | 0.0727     |
| StdReturn               | 105        |
| Time                    | 1.27e+03   |
| dLoss                   | 0.0522057  |
----------------------------------------
itr #119 | 
Mem: 733.355469
Obtaining samples...
Obtaining samples for iteration 119...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5240, #subsample_inputs: 5240
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.701      |
| AbsLearnSignalNew       | 0.701      |
| AbsLearningOld          | 0.701      |
| AverageDiscountedReturn | 119        |
| AveragePhiLoss          | 0.960592   |
| AveragePolicyStd        | 0.914478   |
| AverageReturn           | 394        |
| Entropy                 | 7.97063    |
| EnvExecTime             | 2.97       |
| ExplainedVariance       | 0.631      |
| Iteration               | 119        |
| ItrTime                 | 10.2       |
| LossAfter               | 0.387313   |
| LossBefore              | 0.44294    |
| MaxReturn               | 645        |
| MeanKL                  | 0.00996801 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 240        |
| NumTrajs                | 22         |
| Perplexity              | 2894.67    |
| PolicyExecTime          | 0.634      |
| ProcessExecTime         | 0.085      |
| StdReturn               | 88.2       |
| Time                    | 1.28e+03   |
| dLoss                   | 0.0556271  |
----------------------------------------
itr #120 | 
Mem: 733.355469
Obtaining samples...
Obtaining samples for iteration 120...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5088, #subsample_inputs: 5088
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.669      |
| AbsLearnSignalNew       | 0.669      |
| AbsLearningOld          | 0.668      |
| AverageDiscountedReturn | 116        |
| AveragePhiLoss          | 0.962727   |
| AveragePolicyStd        | 0.913872   |
| AverageReturn           | 338        |
| Entropy                 | 7.96645    |
| EnvExecTime             | 3.06       |
| ExplainedVariance       | 0.501      |
| Iteration               | 120        |
| ItrTime                 | 11.5       |
| LossAfter               | 0.509271   |
| LossBefore              | 0.562314   |
| MaxReturn               | 438        |
| MeanKL                  | 0.00994289 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 63         |
| NumTrajs                | 24         |
| Perplexity              | 2882.61    |
| PolicyExecTime          | 0.668      |
| ProcessExecTime         | 0.087      |
| StdReturn               | 108        |
| Time                    | 1.29e+03   |
| dLoss                   | 0.0530428  |
----------------------------------------
itr #121 | 
Mem: 733.355469
Obtaining samples...
Obtaining samples for iteration 121...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5007, #subsample_inputs: 5007
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.694      |
| AbsLearnSignalNew       | 0.694      |
| AbsLearningOld          | 0.694      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 0.968989   |
| AveragePolicyStd        | 0.915708   |
| AverageReturn           | 360        |
| Entropy                 | 7.97768    |
| EnvExecTime             | 2.54       |
| ExplainedVariance       | 0.562      |
| Iteration               | 121        |
| ItrTime                 | 10.1       |
| LossAfter               | 0.383345   |
| LossBefore              | 0.426613   |
| MaxReturn               | 555        |
| MeanKL                  | 0.00643085 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 69.7       |
| NumTrajs                | 23         |
| Perplexity              | 2915.16    |
| PolicyExecTime          | 0.509      |
| ProcessExecTime         | 0.0717     |
| StdReturn               | 105        |
| Time                    | 1.3e+03    |
| dLoss                   | 0.0432673  |
----------------------------------------
itr #122 | 
Mem: 733.355469
Obtaining samples...
Obtaining samples for iteration 122...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5147, #subsample_inputs: 5147
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.657      |
| AbsLearnSignalNew       | 0.657      |
| AbsLearningOld          | 0.657      |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 0.960202   |
| AveragePolicyStd        | 0.91462    |
| AverageReturn           | 358        |
| Entropy                 | 7.97032    |
| EnvExecTime             | 2.9        |
| ExplainedVariance       | 0.625      |
| Iteration               | 122        |
| ItrTime                 | 11.1       |
| LossAfter               | -0.458108  |
| LossBefore              | -0.410747  |
| MaxReturn               | 517        |
| MeanKL                  | 0.00642602 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 108        |
| NumTrajs                | 24         |
| Perplexity              | 2893.79    |
| PolicyExecTime          | 0.619      |
| ProcessExecTime         | 0.0865     |
| StdReturn               | 97.4       |
| Time                    | 1.31e+03   |
| dLoss                   | 0.0473608  |
----------------------------------------
itr #123 | 
Mem: 733.355469
Obtaining samples...
Obtaining samples for iteration 123...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5158, #subsample_inputs: 5158
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.637      |
| AbsLearnSignalNew       | 0.637      |
| AbsLearningOld          | 0.637      |
| AverageDiscountedReturn | 117        |
| AveragePhiLoss          | 0.967731   |
| AveragePolicyStd        | 0.914411   |
| AverageReturn           | 377        |
| Entropy                 | 7.96832    |
| EnvExecTime             | 2.87       |
| ExplainedVariance       | 0.538      |
| Iteration               | 123        |
| ItrTime                 | 11.4       |
| LossAfter               | 0.172372   |
| LossBefore              | 0.218267   |
| MaxReturn               | 714        |
| MeanKL                  | 0.00641883 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 50.2       |
| NumTrajs                | 22         |
| Perplexity              | 2888.01    |
| PolicyExecTime          | 0.587      |
| ProcessExecTime         | 0.0812     |
| StdReturn               | 141        |
| Time                    | 1.32e+03   |
| dLoss                   | 0.0458949  |
----------------------------------------
itr #124 | 
Mem: 733.355469
Obtaining samples...
Obtaining samples for iteration 124...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5098, #subsample_inputs: 5098
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.685      |
| AbsLearnSignalNew       | 0.685      |
| AbsLearningOld          | 0.685      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 0.96546    |
| AveragePolicyStd        | 0.915119   |
| AverageReturn           | 372        |
| Entropy                 | 7.97215    |
| EnvExecTime             | 2.89       |
| ExplainedVariance       | 0.64       |
| Iteration               | 124        |
| ItrTime                 | 9.88       |
| LossAfter               | -0.091685  |
| LossBefore              | -0.0376426 |
| MaxReturn               | 510        |
| MeanKL                  | 0.00989921 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 63.7       |
| NumTrajs                | 23         |
| Perplexity              | 2899.09    |
| PolicyExecTime          | 0.614      |
| ProcessExecTime         | 0.0851     |
| StdReturn               | 110        |
| Time                    | 1.33e+03   |
| dLoss                   | 0.0540424  |
----------------------------------------
itr #125 | 
Mem: 733.355469
Obtaining samples...
Obtaining samples for iteration 125...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5164, #subsample_inputs: 5164
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.684      |
| AbsLearnSignalNew       | 0.684      |
| AbsLearningOld          | 0.684      |
| AverageDiscountedReturn | 116        |
| AveragePhiLoss          | 0.978993   |
| AveragePolicyStd        | 0.91365    |
| AverageReturn           | 339        |
| Entropy                 | 7.96232    |
| EnvExecTime             | 3.09       |
| ExplainedVariance       | 0.564      |
| Iteration               | 125        |
| ItrTime                 | 11.5       |
| LossAfter               | 0.899552   |
| LossBefore              | 0.937614   |
| MaxReturn               | 437        |
| MeanKL                  | 0.00641527 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 46.6       |
| NumTrajs                | 24         |
| Perplexity              | 2870.73    |
| PolicyExecTime          | 0.649      |
| ProcessExecTime         | 0.0879     |
| StdReturn               | 111        |
| Time                    | 1.34e+03   |
| dLoss                   | 0.0380621  |
----------------------------------------
itr #126 | 
Mem: 733.355469
Obtaining samples...
Obtaining samples for iteration 126...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5098, #subsample_inputs: 5098
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.692      |
| AbsLearnSignalNew       | 0.692      |
| AbsLearningOld          | 0.692      |
| AverageDiscountedReturn | 118        |
| AveragePhiLoss          | 0.971873   |
| AveragePolicyStd        | 0.912429   |
| AverageReturn           | 344        |
| Entropy                 | 7.95406    |
| EnvExecTime             | 2.84       |
| ExplainedVariance       | 0.488      |
| Iteration               | 126        |
| ItrTime                 | 11         |
| LossAfter               | 1.04198    |
| LossBefore              | 1.08757    |
| MaxReturn               | 537        |
| MeanKL                  | 0.00653201 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 29.3       |
| NumTrajs                | 24         |
| Perplexity              | 2847.12    |
| PolicyExecTime          | 0.568      |
| ProcessExecTime         | 0.0793     |
| StdReturn               | 115        |
| Time                    | 1.36e+03   |
| dLoss                   | 0.0455854  |
----------------------------------------
itr #127 | 
Mem: 733.355469
Obtaining samples...
Obtaining samples for iteration 127...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5116, #subsample_inputs: 5116
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.704      |
| AbsLearnSignalNew       | 0.704      |
| AbsLearningOld          | 0.704      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 0.964639   |
| AveragePolicyStd        | 0.908797   |
| AverageReturn           | 386        |
| Entropy                 | 7.93111    |
| EnvExecTime             | 2.9        |
| ExplainedVariance       | 0.614      |
| Iteration               | 127        |
| ItrTime                 | 10.7       |
| LossAfter               | 0.842694   |
| LossBefore              | 0.88536    |
| MaxReturn               | 653        |
| MeanKL                  | 0.00647671 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 195        |
| NumTrajs                | 21         |
| Perplexity              | 2782.52    |
| PolicyExecTime          | 0.616      |
| ProcessExecTime         | 0.0839     |
| StdReturn               | 108        |
| Time                    | 1.37e+03   |
| dLoss                   | 0.0426655  |
----------------------------------------
itr #128 | 
Mem: 733.355469
Obtaining samples...
Obtaining samples for iteration 128...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5107, #subsample_inputs: 5107
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.684      |
| AbsLearnSignalNew       | 0.684      |
| AbsLearningOld          | 0.684      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 0.967868   |
| AveragePolicyStd        | 0.909305   |
| AverageReturn           | 352        |
| Entropy                 | 7.9357     |
| EnvExecTime             | 2.84       |
| ExplainedVariance       | 0.64       |
| Iteration               | 128        |
| ItrTime                 | 11.2       |
| LossAfter               | 1.21356    |
| LossBefore              | 1.25457    |
| MaxReturn               | 479        |
| MeanKL                  | 0.00648156 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 69.3       |
| NumTrajs                | 24         |
| Perplexity              | 2795.32    |
| PolicyExecTime          | 0.596      |
| ProcessExecTime         | 0.0772     |
| StdReturn               | 89.3       |
| Time                    | 1.38e+03   |
| dLoss                   | 0.041013   |
----------------------------------------
itr #129 | 
Mem: 733.355469
Obtaining samples...
Obtaining samples for iteration 129...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5254, #subsample_inputs: 5254
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.671      |
| AbsLearnSignalNew       | 0.671      |
| AbsLearningOld          | 0.671      |
| AverageDiscountedReturn | 115        |
| AveragePhiLoss          | 0.972446   |
| AveragePolicyStd        | 0.911857   |
| AverageReturn           | 340        |
| Entropy                 | 7.9512     |
| EnvExecTime             | 2.75       |
| ExplainedVariance       | 0.547      |
| Iteration               | 129        |
| ItrTime                 | 10.3       |
| LossAfter               | -0.0119281 |
| LossBefore              | 0.0432592  |
| MaxReturn               | 503        |
| MeanKL                  | 0.00992764 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 53.3       |
| NumTrajs                | 25         |
| Perplexity              | 2838.98    |
| PolicyExecTime          | 0.581      |
| ProcessExecTime         | 0.0809     |
| StdReturn               | 106        |
| Time                    | 1.39e+03   |
| dLoss                   | 0.0551872  |
----------------------------------------
itr #130 | 
Mem: 733.355469
Obtaining samples...
Obtaining samples for iteration 130...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5004, #subsample_inputs: 5004
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.715      |
| AbsLearnSignalNew       | 0.715      |
| AbsLearningOld          | 0.715      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 0.973345   |
| AveragePolicyStd        | 0.911802   |
| AverageReturn           | 376        |
| Entropy                 | 7.9494     |
| EnvExecTime             | 2.79       |
| ExplainedVariance       | 0.642      |
| Iteration               | 130        |
| ItrTime                 | 11         |
| LossAfter               | 0.0380488  |
| LossBefore              | 0.0922093  |
| MaxReturn               | 497        |
| MeanKL                  | 0.00989171 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 131        |
| NumTrajs                | 23         |
| Perplexity              | 2833.88    |
| PolicyExecTime          | 0.604      |
| ProcessExecTime         | 0.0814     |
| StdReturn               | 68.8       |
| Time                    | 1.4e+03    |
| dLoss                   | 0.0541605  |
----------------------------------------
itr #131 | 
Mem: 733.355469
Obtaining samples...
Obtaining samples for iteration 131...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5238, #subsample_inputs: 5238
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.633      |
| AbsLearnSignalNew       | 0.633      |
| AbsLearningOld          | 0.633      |
| AverageDiscountedReturn | 118        |
| AveragePhiLoss          | 0.959431   |
| AveragePolicyStd        | 0.911144   |
| AverageReturn           | 357        |
| Entropy                 | 7.94391    |
| EnvExecTime             | 2.55       |
| ExplainedVariance       | 0.437      |
| Iteration               | 131        |
| ItrTime                 | 10.9       |
| LossAfter               | 0.040829   |
| LossBefore              | 0.0821742  |
| MaxReturn               | 650        |
| MeanKL                  | 0.00645534 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 47.7       |
| NumTrajs                | 23         |
| Perplexity              | 2818.36    |
| PolicyExecTime          | 0.491      |
| ProcessExecTime         | 0.0682     |
| StdReturn               | 129        |
| Time                    | 1.41e+03   |
| dLoss                   | 0.0413452  |
----------------------------------------
itr #132 | 
Mem: 733.355469
Obtaining samples...
Obtaining samples for iteration 132...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5034, #subsample_inputs: 5034
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.758      |
| AbsLearnSignalNew       | 0.758      |
| AbsLearningOld          | 0.758      |
| AverageDiscountedReturn | 113        |
| AveragePhiLoss          | 0.972495   |
| AveragePolicyStd        | 0.90871    |
| AverageReturn           | 390        |
| Entropy                 | 7.92837    |
| EnvExecTime             | 2.85       |
| ExplainedVariance       | 0.498      |
| Iteration               | 132        |
| ItrTime                 | 10.1       |
| LossAfter               | 0.278566   |
| LossBefore              | 0.331145   |
| MaxReturn               | 537        |
| MeanKL                  | 0.00972001 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 75.8       |
| NumTrajs                | 20         |
| Perplexity              | 2774.91    |
| PolicyExecTime          | 0.594      |
| ProcessExecTime         | 0.0822     |
| StdReturn               | 109        |
| Time                    | 1.42e+03   |
| dLoss                   | 0.0525784  |
----------------------------------------
itr #133 | 
Mem: 733.355469
Obtaining samples...
Obtaining samples for iteration 133...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5186, #subsample_inputs: 5186
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.667      |
| AbsLearnSignalNew       | 0.667      |
| AbsLearningOld          | 0.667      |
| AverageDiscountedReturn | 123        |
| AveragePhiLoss          | 0.973301   |
| AveragePolicyStd        | 0.911919   |
| AverageReturn           | 383        |
| Entropy                 | 7.94805    |
| EnvExecTime             | 2.89       |
| ExplainedVariance       | 0.668      |
| Iteration               | 133        |
| ItrTime                 | 11.4       |
| LossAfter               | -0.935613  |
| LossBefore              | -0.890644  |
| MaxReturn               | 493        |
| MeanKL                  | 0.00643996 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 103        |
| NumTrajs                | 23         |
| Perplexity              | 2830.04    |
| PolicyExecTime          | 0.631      |
| ProcessExecTime         | 0.0828     |
| StdReturn               | 76.3       |
| Time                    | 1.43e+03   |
| dLoss                   | 0.0449686  |
----------------------------------------
itr #134 | 
Mem: 733.355469
Obtaining samples...
Obtaining samples for iteration 134...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5067, #subsample_inputs: 5067
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.709      |
| AbsLearnSignalNew       | 0.709      |
| AbsLearningOld          | 0.709      |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 0.957654   |
| AveragePolicyStd        | 0.911057   |
| AverageReturn           | 380        |
| Entropy                 | 7.94389    |
| EnvExecTime             | 2.74       |
| ExplainedVariance       | 0.82       |
| Iteration               | 134        |
| ItrTime                 | 9.89       |
| LossAfter               | 0.184731   |
| LossBefore              | 0.22937    |
| MaxReturn               | 475        |
| MeanKL                  | 0.00641014 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 263        |
| NumTrajs                | 24         |
| Perplexity              | 2818.31    |
| PolicyExecTime          | 0.583      |
| ProcessExecTime         | 0.083      |
| StdReturn               | 49.1       |
| Time                    | 1.44e+03   |
| dLoss                   | 0.0446388  |
----------------------------------------
itr #135 | 
Mem: 733.355469
Obtaining samples...
Obtaining samples for iteration 135...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5004, #subsample_inputs: 5004
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.611      |
| AbsLearnSignalNew       | 0.611      |
| AbsLearningOld          | 0.611      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 0.966589   |
| AveragePolicyStd        | 0.908733   |
| AverageReturn           | 382        |
| Entropy                 | 7.92779    |
| EnvExecTime             | 2.77       |
| ExplainedVariance       | 0.579      |
| Iteration               | 135        |
| ItrTime                 | 11         |
| LossAfter               | 0.137219   |
| LossBefore              | 0.179296   |
| MaxReturn               | 526        |
| MeanKL                  | 0.00645501 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 79         |
| NumTrajs                | 23         |
| Perplexity              | 2773.29    |
| PolicyExecTime          | 0.59       |
| ProcessExecTime         | 0.0817     |
| StdReturn               | 87.2       |
| Time                    | 1.45e+03   |
| dLoss                   | 0.0420775  |
----------------------------------------
itr #136 | 
Mem: 733.355469
Obtaining samples...
Obtaining samples for iteration 136...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5255, #subsample_inputs: 5255
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.682      |
| AbsLearnSignalNew       | 0.682      |
| AbsLearningOld          | 0.682      |
| AverageDiscountedReturn | 119        |
| AveragePhiLoss          | 0.966192   |
| AveragePolicyStd        | 0.908511   |
| AverageReturn           | 353        |
| Entropy                 | 7.92602    |
| EnvExecTime             | 2.68       |
| ExplainedVariance       | 0.583      |
| Iteration               | 136        |
| ItrTime                 | 11.2       |
| LossAfter               | 0.078242   |
| LossBefore              | 0.133744   |
| MaxReturn               | 478        |
| MeanKL                  | 0.00996087 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 26.3       |
| NumTrajs                | 25         |
| Perplexity              | 2768.4     |
| PolicyExecTime          | 0.54       |
| ProcessExecTime         | 0.0718     |
| StdReturn               | 101        |
| Time                    | 1.46e+03   |
| dLoss                   | 0.0555022  |
----------------------------------------
itr #137 | 
Mem: 733.355469
Obtaining samples...
Obtaining samples for iteration 137...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5129, #subsample_inputs: 5129
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.651     |
| AbsLearnSignalNew       | 0.651     |
| AbsLearningOld          | 0.651     |
| AverageDiscountedReturn | 106       |
| AveragePhiLoss          | 0.979737  |
| AveragePolicyStd        | 0.907193  |
| AverageReturn           | 321       |
| Entropy                 | 7.9161    |
| EnvExecTime             | 2.92      |
| ExplainedVariance       | 0.373     |
| Iteration               | 137       |
| ItrTime                 | 10.3      |
| LossAfter               | -0.437556 |
| LossBefore              | -0.38507  |
| MaxReturn               | 556       |
| MeanKL                  | 0.0099703 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 69.6      |
| NumTrajs                | 23        |
| Perplexity              | 2741.06   |
| PolicyExecTime          | 0.605     |
| ProcessExecTime         | 0.0835    |
| StdReturn               | 140       |
| Time                    | 1.47e+03  |
| dLoss                   | 0.0524859 |
---------------------------------------
itr #138 | 
Mem: 733.355469
Obtaining samples...
Obtaining samples for iteration 138...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5225, #subsample_inputs: 5225
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.719      |
| AbsLearnSignalNew       | 0.719      |
| AbsLearningOld          | 0.719      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 0.96806    |
| AveragePolicyStd        | 0.90754    |
| AverageReturn           | 376        |
| Entropy                 | 7.91871    |
| EnvExecTime             | 2.91       |
| ExplainedVariance       | 0.612      |
| Iteration               | 138        |
| ItrTime                 | 11.5       |
| LossAfter               | 0.446459   |
| LossBefore              | 0.487788   |
| MaxReturn               | 603        |
| MeanKL                  | 0.00644047 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 46.6       |
| NumTrajs                | 23         |
| Perplexity              | 2748.22    |
| PolicyExecTime          | 0.609      |
| ProcessExecTime         | 0.0829     |
| StdReturn               | 120        |
| Time                    | 1.49e+03   |
| dLoss                   | 0.0413286  |
----------------------------------------
itr #139 | 
Mem: 733.355469
Obtaining samples...
Obtaining samples for iteration 139...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5085, #subsample_inputs: 5085
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.688     |
| AbsLearnSignalNew       | 0.688     |
| AbsLearningOld          | 0.688     |
| AverageDiscountedReturn | 114       |
| AveragePhiLoss          | 0.972909  |
| AveragePolicyStd        | 0.907238  |
| AverageReturn           | 315       |
| Entropy                 | 7.9154    |
| EnvExecTime             | 2.9       |
| ExplainedVariance       | 0.558     |
| Iteration               | 139       |
| ItrTime                 | 10.4      |
| LossAfter               | -0.203238 |
| LossBefore              | -0.152182 |
| MaxReturn               | 536       |
| MeanKL                  | 0.0099227 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 25.6      |
| NumTrajs                | 25        |
| Perplexity              | 2739.14   |
| PolicyExecTime          | 0.614     |
| ProcessExecTime         | 0.0833    |
| StdReturn               | 123       |
| Time                    | 1.5e+03   |
| dLoss                   | 0.0510558 |
---------------------------------------
itr #140 | 
Mem: 733.613281
Obtaining samples...
Obtaining samples for iteration 140...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5000, #subsample_inputs: 5000
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.722      |
| AbsLearnSignalNew       | 0.722      |
| AbsLearningOld          | 0.722      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 0.965801   |
| AveragePolicyStd        | 0.906357   |
| AverageReturn           | 371        |
| Entropy                 | 7.91081    |
| EnvExecTime             | 2.78       |
| ExplainedVariance       | 0.697      |
| Iteration               | 140        |
| ItrTime                 | 10.9       |
| LossAfter               | 0.197855   |
| LossBefore              | 0.253331   |
| MaxReturn               | 533        |
| MeanKL                  | 0.00993411 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 179        |
| NumTrajs                | 24         |
| Perplexity              | 2726.6     |
| PolicyExecTime          | 0.589      |
| ProcessExecTime         | 0.0819     |
| StdReturn               | 73.6       |
| Time                    | 1.51e+03   |
| dLoss                   | 0.0554763  |
----------------------------------------
itr #141 | 
Mem: 733.613281
Obtaining samples...
Obtaining samples for iteration 141...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5052, #subsample_inputs: 5052
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.627      |
| AbsLearnSignalNew       | 0.627      |
| AbsLearningOld          | 0.626      |
| AverageDiscountedReturn | 112        |
| AveragePhiLoss          | 0.980667   |
| AveragePolicyStd        | 0.903044   |
| AverageReturn           | 323        |
| Entropy                 | 7.88912    |
| EnvExecTime             | 2.68       |
| ExplainedVariance       | 0.152      |
| Iteration               | 141        |
| ItrTime                 | 10.8       |
| LossAfter               | 0.427813   |
| LossBefore              | 0.470003   |
| MaxReturn               | 546        |
| MeanKL                  | 0.00980297 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 57.6       |
| NumTrajs                | 24         |
| Perplexity              | 2668.1     |
| PolicyExecTime          | 0.524      |
| ProcessExecTime         | 0.0671     |
| StdReturn               | 142        |
| Time                    | 1.52e+03   |
| dLoss                   | 0.0421898  |
----------------------------------------
itr #142 | 
Mem: 733.613281
Obtaining samples...
Obtaining samples for iteration 142...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5126, #subsample_inputs: 5126
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.745      |
| AbsLearnSignalNew       | 0.745      |
| AbsLearningOld          | 0.745      |
| AverageDiscountedReturn | 116        |
| AveragePhiLoss          | 0.967958   |
| AveragePolicyStd        | 0.903673   |
| AverageReturn           | 339        |
| Entropy                 | 7.89198    |
| EnvExecTime             | 3.17       |
| ExplainedVariance       | 0.599      |
| Iteration               | 142        |
| ItrTime                 | 10.5       |
| LossAfter               | 0.0724501  |
| LossBefore              | 0.123481   |
| MaxReturn               | 497        |
| MeanKL                  | 0.00990217 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 83.3       |
| NumTrajs                | 23         |
| Perplexity              | 2675.74    |
| PolicyExecTime          | 0.637      |
| ProcessExecTime         | 0.0856     |
| StdReturn               | 119        |
| Time                    | 1.53e+03   |
| dLoss                   | 0.0510313  |
----------------------------------------
itr #143 | 
Mem: 733.613281
Obtaining samples...
Obtaining samples for iteration 143...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5039, #subsample_inputs: 5039
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.678      |
| AbsLearnSignalNew       | 0.678      |
| AbsLearningOld          | 0.679      |
| AverageDiscountedReturn | 123        |
| AveragePhiLoss          | 0.977463   |
| AveragePolicyStd        | 0.90746    |
| AverageReturn           | 366        |
| Entropy                 | 7.91579    |
| EnvExecTime             | 2.79       |
| ExplainedVariance       | 0.289      |
| Iteration               | 143        |
| ItrTime                 | 11         |
| LossAfter               | -0.102375  |
| LossBefore              | -0.0600292 |
| MaxReturn               | 669        |
| MeanKL                  | 0.00650238 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 40.7       |
| NumTrajs                | 24         |
| Perplexity              | 2740.21    |
| PolicyExecTime          | 0.6        |
| ProcessExecTime         | 0.0805     |
| StdReturn               | 108        |
| Time                    | 1.54e+03   |
| dLoss                   | 0.0423461  |
----------------------------------------
itr #144 | 
Mem: 733.613281
Obtaining samples...
Obtaining samples for iteration 144...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5113, #subsample_inputs: 5113
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.69       |
| AbsLearnSignalNew       | 0.69       |
| AbsLearningOld          | 0.69       |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 0.966343   |
| AveragePolicyStd        | 0.903949   |
| AverageReturn           | 350        |
| Entropy                 | 7.8927     |
| EnvExecTime             | 2.6        |
| ExplainedVariance       | 0.563      |
| Iteration               | 144        |
| ItrTime                 | 10.4       |
| LossAfter               | 0.410072   |
| LossBefore              | 0.451611   |
| MaxReturn               | 512        |
| MeanKL                  | 0.00645197 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 78.5       |
| NumTrajs                | 24         |
| Perplexity              | 2677.67    |
| PolicyExecTime          | 0.525      |
| ProcessExecTime         | 0.0717     |
| StdReturn               | 88.4       |
| Time                    | 1.55e+03   |
| dLoss                   | 0.0415385  |
----------------------------------------
itr #145 | 
Mem: 733.867188
Obtaining samples...
Obtaining samples for iteration 145...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5076, #subsample_inputs: 5076
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.681      |
| AbsLearnSignalNew       | 0.681      |
| AbsLearningOld          | 0.681      |
| AverageDiscountedReturn | 119        |
| AveragePhiLoss          | 0.972699   |
| AveragePolicyStd        | 0.901271   |
| AverageReturn           | 361        |
| Entropy                 | 7.87566    |
| EnvExecTime             | 2.96       |
| ExplainedVariance       | 0.612      |
| Iteration               | 145        |
| ItrTime                 | 10.8       |
| LossAfter               | 0.645921   |
| LossBefore              | 0.684294   |
| MaxReturn               | 524        |
| MeanKL                  | 0.00644048 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 80.6       |
| NumTrajs                | 22         |
| Perplexity              | 2632.44    |
| PolicyExecTime          | 0.604      |
| ProcessExecTime         | 0.082      |
| StdReturn               | 102        |
| Time                    | 1.56e+03   |
| dLoss                   | 0.0383728  |
----------------------------------------
itr #146 | 
Mem: 733.867188
Obtaining samples...
Obtaining samples for iteration 146...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5048, #subsample_inputs: 5048
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.688      |
| AbsLearnSignalNew       | 0.688      |
| AbsLearningOld          | 0.688      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 0.961041   |
| AveragePolicyStd        | 0.89742    |
| AverageReturn           | 374        |
| Entropy                 | 7.85061    |
| EnvExecTime             | 2.67       |
| ExplainedVariance       | 0.584      |
| Iteration               | 146        |
| ItrTime                 | 11         |
| LossAfter               | -0.148201  |
| LossBefore              | -0.0921331 |
| MaxReturn               | 531        |
| MeanKL                  | 0.00991123 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 10.8       |
| NumTrajs                | 24         |
| Perplexity              | 2567.29    |
| PolicyExecTime          | 0.567      |
| ProcessExecTime         | 0.0715     |
| StdReturn               | 103        |
| Time                    | 1.57e+03   |
| dLoss                   | 0.0560682  |
----------------------------------------
itr #147 | 
Mem: 733.867188
Obtaining samples...
Obtaining samples for iteration 147...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5207, #subsample_inputs: 5207
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.724      |
| AbsLearnSignalNew       | 0.724      |
| AbsLearningOld          | 0.724      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 0.963274   |
| AveragePolicyStd        | 0.897661   |
| AverageReturn           | 378        |
| Entropy                 | 7.85309    |
| EnvExecTime             | 2.98       |
| ExplainedVariance       | 0.626      |
| Iteration               | 147        |
| ItrTime                 | 10.2       |
| LossAfter               | 0.272806   |
| LossBefore              | 0.314723   |
| MaxReturn               | 517        |
| MeanKL                  | 0.00650391 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 102        |
| NumTrajs                | 24         |
| Perplexity              | 2573.67    |
| PolicyExecTime          | 0.653      |
| ProcessExecTime         | 0.0879     |
| StdReturn               | 85.3       |
| Time                    | 1.58e+03   |
| dLoss                   | 0.041917   |
----------------------------------------
itr #148 | 
Mem: 733.867188
Obtaining samples...
Obtaining samples for iteration 148...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5279, #subsample_inputs: 5279
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
-----------------------------------------
| AbsLearnSignal          | 0.676       |
| AbsLearnSignalNew       | 0.676       |
| AbsLearningOld          | 0.676       |
| AverageDiscountedReturn | 116         |
| AveragePhiLoss          | 0.973211    |
| AveragePolicyStd        | 0.894143    |
| AverageReturn           | 342         |
| Entropy                 | 7.83168     |
| EnvExecTime             | 2.99        |
| ExplainedVariance       | 0.567       |
| Iteration               | 148         |
| ItrTime                 | 11.6        |
| LossAfter               | -0.00308415 |
| LossBefore              | 0.0357761   |
| MaxReturn               | 493         |
| MeanKL                  | 0.00647155  |
| MeanKLBefore            | 0.0         |
| MinReturn               | 32.2        |
| NumTrajs                | 25          |
| Perplexity              | 2519.16     |
| PolicyExecTime          | 0.631       |
| ProcessExecTime         | 0.084       |
| StdReturn               | 123         |
| Time                    | 1.59e+03    |
| dLoss                   | 0.0388603   |
-----------------------------------------
itr #149 | 
Mem: 735.414062
Obtaining samples...
Obtaining samples for iteration 149...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5140, #subsample_inputs: 5140
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.713      |
| AbsLearnSignalNew       | 0.713      |
| AbsLearningOld          | 0.713      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 0.97156    |
| AveragePolicyStd        | 0.892535   |
| AverageReturn           | 357        |
| Entropy                 | 7.82103    |
| EnvExecTime             | 2.53       |
| ExplainedVariance       | 0.649      |
| Iteration               | 149        |
| ItrTime                 | 10.3       |
| LossAfter               | -0.0773434 |
| LossBefore              | -0.0322203 |
| MaxReturn               | 536        |
| MeanKL                  | 0.00643035 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 109        |
| NumTrajs                | 25         |
| Perplexity              | 2492.48    |
| PolicyExecTime          | 0.528      |
| ProcessExecTime         | 0.0691     |
| StdReturn               | 83         |
| Time                    | 1.6e+03    |
| dLoss                   | 0.0451231  |
----------------------------------------
itr #150 | 
Mem: 735.414062
Obtaining samples...
Obtaining samples for iteration 150...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5152, #subsample_inputs: 5152
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.697      |
| AbsLearnSignalNew       | 0.697      |
| AbsLearningOld          | 0.697      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 0.969426   |
| AveragePolicyStd        | 0.889233   |
| AverageReturn           | 363        |
| Entropy                 | 7.79692    |
| EnvExecTime             | 2.88       |
| ExplainedVariance       | 0.597      |
| Iteration               | 150        |
| ItrTime                 | 10.9       |
| LossAfter               | -0.0915793 |
| LossBefore              | -0.0379719 |
| MaxReturn               | 491        |
| MeanKL                  | 0.00993964 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 69         |
| NumTrajs                | 23         |
| Perplexity              | 2433.1     |
| PolicyExecTime          | 0.607      |
| ProcessExecTime         | 0.0836     |
| StdReturn               | 107        |
| Time                    | 1.62e+03   |
| dLoss                   | 0.0536074  |
----------------------------------------
itr #151 | 
Mem: 735.414062
Obtaining samples...
Obtaining samples for iteration 151...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5147, #subsample_inputs: 5147
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.714      |
| AbsLearnSignalNew       | 0.714      |
| AbsLearningOld          | 0.714      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 0.970319   |
| AveragePolicyStd        | 0.886757   |
| AverageReturn           | 340        |
| Entropy                 | 7.78009    |
| EnvExecTime             | 2.61       |
| ExplainedVariance       | 0.615      |
| Iteration               | 151        |
| ItrTime                 | 10.9       |
| LossAfter               | 0.0110191  |
| LossBefore              | 0.0648067  |
| MaxReturn               | 469        |
| MeanKL                  | 0.00996519 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 33.4       |
| NumTrajs                | 26         |
| Perplexity              | 2392.49    |
| PolicyExecTime          | 0.515      |
| ProcessExecTime         | 0.0699     |
| StdReturn               | 102        |
| Time                    | 1.63e+03   |
| dLoss                   | 0.0537876  |
----------------------------------------
itr #152 | 
Mem: 735.414062
Obtaining samples...
Obtaining samples for iteration 152...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5065, #subsample_inputs: 5065
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.695      |
| AbsLearnSignalNew       | 0.695      |
| AbsLearningOld          | 0.695      |
| AverageDiscountedReturn | 115        |
| AveragePhiLoss          | 0.965894   |
| AveragePolicyStd        | 0.887326   |
| AverageReturn           | 314        |
| Entropy                 | 7.78346    |
| EnvExecTime             | 3          |
| ExplainedVariance       | 0.562      |
| Iteration               | 152        |
| ItrTime                 | 10.2       |
| LossAfter               | 0.131159   |
| LossBefore              | 0.182414   |
| MaxReturn               | 478        |
| MeanKL                  | 0.00993659 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 46.3       |
| NumTrajs                | 26         |
| Perplexity              | 2400.56    |
| PolicyExecTime          | 0.645      |
| ProcessExecTime         | 0.0866     |
| StdReturn               | 134        |
| Time                    | 1.64e+03   |
| dLoss                   | 0.051255   |
----------------------------------------
itr #153 | 
Mem: 735.414062
Obtaining samples...
Obtaining samples for iteration 153...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5192, #subsample_inputs: 5192
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.696      |
| AbsLearnSignalNew       | 0.696      |
| AbsLearningOld          | 0.696      |
| AverageDiscountedReturn | 119        |
| AveragePhiLoss          | 0.973627   |
| AveragePolicyStd        | 0.888484   |
| AverageReturn           | 347        |
| Entropy                 | 7.78996    |
| EnvExecTime             | 2.89       |
| ExplainedVariance       | 0.534      |
| Iteration               | 153        |
| ItrTime                 | 11.4       |
| LossAfter               | -0.367715  |
| LossBefore              | -0.312872  |
| MaxReturn               | 552        |
| MeanKL                  | 0.00990473 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 51.9       |
| NumTrajs                | 25         |
| Perplexity              | 2416.23    |
| PolicyExecTime          | 0.631      |
| ProcessExecTime         | 0.084      |
| StdReturn               | 103        |
| Time                    | 1.65e+03   |
| dLoss                   | 0.0548438  |
----------------------------------------
itr #154 | 
Mem: 735.414062
Obtaining samples...
Obtaining samples for iteration 154...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5103, #subsample_inputs: 5103
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.492      |
| AbsLearnSignalNew       | 0.492      |
| AbsLearningOld          | 0.492      |
| AverageDiscountedReturn | 123        |
| AveragePhiLoss          | 0.952006   |
| AveragePolicyStd        | 0.890103   |
| AverageReturn           | 346        |
| Entropy                 | 7.80077    |
| EnvExecTime             | 2.75       |
| ExplainedVariance       | 0.407      |
| Iteration               | 154        |
| ItrTime                 | 10.4       |
| LossAfter               | -0.0224601 |
| LossBefore              | 0.112834   |
| MaxReturn               | 483        |
| MeanKL                  | 0.00980779 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 110        |
| NumTrajs                | 25         |
| Perplexity              | 2442.49    |
| PolicyExecTime          | 0.564      |
| ProcessExecTime         | 0.0757     |
| StdReturn               | 86.1       |
| Time                    | 1.66e+03   |
| dLoss                   | 0.135294   |
----------------------------------------
itr #155 | 
Mem: 735.414062
Obtaining samples...
Obtaining samples for iteration 155...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5188, #subsample_inputs: 5188
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.592      |
| AbsLearnSignalNew       | 0.592      |
| AbsLearningOld          | 0.592      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 0.965451   |
| AveragePolicyStd        | 0.892275   |
| AverageReturn           | 351        |
| Entropy                 | 7.81549    |
| EnvExecTime             | 2.88       |
| ExplainedVariance       | 0.443      |
| Iteration               | 155        |
| ItrTime                 | 11         |
| LossAfter               | 0.266958   |
| LossBefore              | 0.3154     |
| MaxReturn               | 617        |
| MeanKL                  | 0.00999439 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 62.2       |
| NumTrajs                | 25         |
| Perplexity              | 2478.7     |
| PolicyExecTime          | 0.623      |
| ProcessExecTime         | 0.0858     |
| StdReturn               | 96.5       |
| Time                    | 1.67e+03   |
| dLoss                   | 0.0484422  |
----------------------------------------
itr #156 | 
Mem: 735.414062
Obtaining samples...
Obtaining samples for iteration 156...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5075, #subsample_inputs: 5075
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
-----------------------------------------
| AbsLearnSignal          | 0.712       |
| AbsLearnSignalNew       | 0.712       |
| AbsLearningOld          | 0.712       |
| AverageDiscountedReturn | 124         |
| AveragePhiLoss          | 0.962293    |
| AveragePolicyStd        | 0.893193    |
| AverageReturn           | 343         |
| Entropy                 | 7.82177     |
| EnvExecTime             | 2.67        |
| ExplainedVariance       | 0.641       |
| Iteration               | 156         |
| ItrTime                 | 10.8        |
| LossAfter               | -0.00261592 |
| LossBefore              | 0.0439353   |
| MaxReturn               | 445         |
| MeanKL                  | 0.00644016  |
| MeanKLBefore            | 0.0         |
| MinReturn               | 92.6        |
| NumTrajs                | 25          |
| Perplexity              | 2494.32     |
| PolicyExecTime          | 0.542       |
| ProcessExecTime         | 0.0724      |
| StdReturn               | 73.9        |
| Time                    | 1.68e+03    |
| dLoss                   | 0.0465512   |
-----------------------------------------
itr #157 | 
Mem: 735.414062
Obtaining samples...
Obtaining samples for iteration 157...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5121, #subsample_inputs: 5121
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.681      |
| AbsLearnSignalNew       | 0.681      |
| AbsLearningOld          | 0.682      |
| AverageDiscountedReturn | 129        |
| AveragePhiLoss          | 0.971566   |
| AveragePolicyStd        | 0.89212    |
| AverageReturn           | 377        |
| Entropy                 | 7.8149     |
| EnvExecTime             | 2.85       |
| ExplainedVariance       | 0.687      |
| Iteration               | 157        |
| ItrTime                 | 10         |
| LossAfter               | 0.0477367  |
| LossBefore              | 0.0900872  |
| MaxReturn               | 490        |
| MeanKL                  | 0.00646022 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 36.8       |
| NumTrajs                | 25         |
| Perplexity              | 2477.23    |
| PolicyExecTime          | 0.618      |
| ProcessExecTime         | 0.0849     |
| StdReturn               | 83.3       |
| Time                    | 1.69e+03   |
| dLoss                   | 0.0423506  |
----------------------------------------
itr #158 | 
Mem: 735.414062
Obtaining samples...
Obtaining samples for iteration 158...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5067, #subsample_inputs: 5067
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.624      |
| AbsLearnSignalNew       | 0.624      |
| AbsLearningOld          | 0.624      |
| AverageDiscountedReturn | 123        |
| AveragePhiLoss          | 0.971121   |
| AveragePolicyStd        | 0.893445   |
| AverageReturn           | 358        |
| Entropy                 | 7.8238     |
| EnvExecTime             | 2.91       |
| ExplainedVariance       | 0.57       |
| Iteration               | 158        |
| ItrTime                 | 11.5       |
| LossAfter               | 0.406895   |
| LossBefore              | 0.458398   |
| MaxReturn               | 521        |
| MeanKL                  | 0.00998418 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 101        |
| NumTrajs                | 23         |
| Perplexity              | 2499.38    |
| PolicyExecTime          | 0.621      |
| ProcessExecTime         | 0.086      |
| StdReturn               | 97.2       |
| Time                    | 1.7e+03    |
| dLoss                   | 0.0515035  |
----------------------------------------
itr #159 | 
Mem: 735.414062
Obtaining samples...
Obtaining samples for iteration 159...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5039, #subsample_inputs: 5039
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.723      |
| AbsLearnSignalNew       | 0.723      |
| AbsLearningOld          | 0.723      |
| AverageDiscountedReturn | 108        |
| AveragePhiLoss          | 0.976768   |
| AveragePolicyStd        | 0.893233   |
| AverageReturn           | 327        |
| Entropy                 | 7.8241     |
| EnvExecTime             | 2.6        |
| ExplainedVariance       | 0.475      |
| Iteration               | 159        |
| ItrTime                 | 10.3       |
| LossAfter               | 0.255368   |
| LossBefore              | 0.298575   |
| MaxReturn               | 515        |
| MeanKL                  | 0.00645105 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 56.2       |
| NumTrajs                | 22         |
| Perplexity              | 2500.14    |
| PolicyExecTime          | 0.504      |
| ProcessExecTime         | 0.0677     |
| StdReturn               | 142        |
| Time                    | 1.71e+03   |
| dLoss                   | 0.0432071  |
----------------------------------------
itr #160 | 
Mem: 735.414062
Obtaining samples...
Obtaining samples for iteration 160...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5057, #subsample_inputs: 5057
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.703      |
| AbsLearnSignalNew       | 0.703      |
| AbsLearningOld          | 0.703      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 0.96539    |
| AveragePolicyStd        | 0.89026    |
| AverageReturn           | 379        |
| Entropy                 | 7.80358    |
| EnvExecTime             | 2.92       |
| ExplainedVariance       | 0.59       |
| Iteration               | 160        |
| ItrTime                 | 10.7       |
| LossAfter               | 0.438014   |
| LossBefore              | 0.493928   |
| MaxReturn               | 615        |
| MeanKL                  | 0.00993134 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 90.6       |
| NumTrajs                | 23         |
| Perplexity              | 2449.37    |
| PolicyExecTime          | 0.61       |
| ProcessExecTime         | 0.0825     |
| StdReturn               | 90.7       |
| Time                    | 1.72e+03   |
| dLoss                   | 0.0559138  |
----------------------------------------
itr #161 | 
Mem: 735.414062
Obtaining samples...
Obtaining samples for iteration 161...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5084, #subsample_inputs: 5084
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.747      |
| AbsLearnSignalNew       | 0.747      |
| AbsLearningOld          | 0.747      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 0.971848   |
| AveragePolicyStd        | 0.891589   |
| AverageReturn           | 394        |
| Entropy                 | 7.81236    |
| EnvExecTime             | 2.57       |
| ExplainedVariance       | 0.776      |
| Iteration               | 161        |
| ItrTime                 | 10.9       |
| LossAfter               | 0.55572    |
| LossBefore              | 0.614338   |
| MaxReturn               | 549        |
| MeanKL                  | 0.00996466 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 303        |
| NumTrajs                | 23         |
| Perplexity              | 2470.96    |
| PolicyExecTime          | 0.527      |
| ProcessExecTime         | 0.0718     |
| StdReturn               | 55.5       |
| Time                    | 1.74e+03   |
| dLoss                   | 0.0586178  |
----------------------------------------
itr #162 | 
Mem: 735.414062
Obtaining samples...
Obtaining samples for iteration 162...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5042, #subsample_inputs: 5042
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.656      |
| AbsLearnSignalNew       | 0.656      |
| AbsLearningOld          | 0.656      |
| AverageDiscountedReturn | 124        |
| AveragePhiLoss          | 0.965047   |
| AveragePolicyStd        | 0.896657   |
| AverageReturn           | 352        |
| Entropy                 | 7.84611    |
| EnvExecTime             | 2.88       |
| ExplainedVariance       | 0.598      |
| Iteration               | 162        |
| ItrTime                 | 9.86       |
| LossAfter               | -0.21338   |
| LossBefore              | -0.157607  |
| MaxReturn               | 529        |
| MeanKL                  | 0.00997069 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 88.9       |
| NumTrajs                | 25         |
| Perplexity              | 2555.76    |
| PolicyExecTime          | 0.608      |
| ProcessExecTime         | 0.0853     |
| StdReturn               | 90.1       |
| Time                    | 1.75e+03   |
| dLoss                   | 0.0557737  |
----------------------------------------
itr #163 | 
Mem: 735.414062
Obtaining samples...
Obtaining samples for iteration 163...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5178, #subsample_inputs: 5178
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.671      |
| AbsLearnSignalNew       | 0.671      |
| AbsLearningOld          | 0.671      |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 0.982945   |
| AveragePolicyStd        | 0.89635    |
| AverageReturn           | 366        |
| Entropy                 | 7.84517    |
| EnvExecTime             | 2.83       |
| ExplainedVariance       | 0.636      |
| Iteration               | 163        |
| ItrTime                 | 11.3       |
| LossAfter               | 0.244109   |
| LossBefore              | 0.296993   |
| MaxReturn               | 517        |
| MeanKL                  | 0.00998568 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 68.5       |
| NumTrajs                | 24         |
| Perplexity              | 2553.38    |
| PolicyExecTime          | 0.59       |
| ProcessExecTime         | 0.0832     |
| StdReturn               | 102        |
| Time                    | 1.76e+03   |
| dLoss                   | 0.0528838  |
----------------------------------------
itr #164 | 
Mem: 735.414062
Obtaining samples...
Obtaining samples for iteration 164...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5209, #subsample_inputs: 5209
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.678      |
| AbsLearnSignalNew       | 0.678      |
| AbsLearningOld          | 0.678      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 0.968564   |
| AveragePolicyStd        | 0.895321   |
| AverageReturn           | 396        |
| Entropy                 | 7.83762    |
| EnvExecTime             | 2.91       |
| ExplainedVariance       | 0.554      |
| Iteration               | 164        |
| ItrTime                 | 11.1       |
| LossAfter               | 0.959972   |
| LossBefore              | 1.00517    |
| MaxReturn               | 637        |
| MeanKL                  | 0.00642142 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 76.1       |
| NumTrajs                | 22         |
| Perplexity              | 2534.17    |
| PolicyExecTime          | 0.569      |
| ProcessExecTime         | 0.0766     |
| StdReturn               | 118        |
| Time                    | 1.77e+03   |
| dLoss                   | 0.0452014  |
----------------------------------------
itr #165 | 
Mem: 735.414062
Obtaining samples...
Obtaining samples for iteration 165...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5074, #subsample_inputs: 5074
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.67       |
| AbsLearnSignalNew       | 0.67       |
| AbsLearningOld          | 0.67       |
| AverageDiscountedReturn | 117        |
| AveragePhiLoss          | 0.972102   |
| AveragePolicyStd        | 0.893703   |
| AverageReturn           | 353        |
| Entropy                 | 7.82626    |
| EnvExecTime             | 2.96       |
| ExplainedVariance       | 0.564      |
| Iteration               | 165        |
| ItrTime                 | 10.6       |
| LossAfter               | 0.119154   |
| LossBefore              | 0.170061   |
| MaxReturn               | 602        |
| MeanKL                  | 0.00974967 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 63.4       |
| NumTrajs                | 22         |
| Perplexity              | 2505.55    |
| PolicyExecTime          | 0.605      |
| ProcessExecTime         | 0.0855     |
| StdReturn               | 114        |
| Time                    | 1.78e+03   |
| dLoss                   | 0.050907   |
----------------------------------------
itr #166 | 
Mem: 735.414062
Obtaining samples...
Obtaining samples for iteration 166...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5036, #subsample_inputs: 5036
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.698      |
| AbsLearnSignalNew       | 0.698      |
| AbsLearningOld          | 0.698      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 0.973524   |
| AveragePolicyStd        | 0.894789   |
| AverageReturn           | 364        |
| Entropy                 | 7.833      |
| EnvExecTime             | 2.71       |
| ExplainedVariance       | 0.651      |
| Iteration               | 166        |
| ItrTime                 | 11         |
| LossAfter               | 0.0865665  |
| LossBefore              | 0.144905   |
| MaxReturn               | 477        |
| MeanKL                  | 0.00989474 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 35.9       |
| NumTrajs                | 23         |
| Perplexity              | 2522.48    |
| PolicyExecTime          | 0.565      |
| ProcessExecTime         | 0.0758     |
| StdReturn               | 92.7       |
| Time                    | 1.79e+03   |
| dLoss                   | 0.058339   |
----------------------------------------
itr #167 | 
Mem: 735.414062
Obtaining samples...
Obtaining samples for iteration 167...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5202, #subsample_inputs: 5202
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.736      |
| AbsLearnSignalNew       | 0.736      |
| AbsLearningOld          | 0.736      |
| AverageDiscountedReturn | 129        |
| AveragePhiLoss          | 0.972091   |
| AveragePolicyStd        | 0.894381   |
| AverageReturn           | 409        |
| Entropy                 | 7.82852    |
| EnvExecTime             | 2.99       |
| ExplainedVariance       | 0.724      |
| Iteration               | 167        |
| ItrTime                 | 10.2       |
| LossAfter               | 0.545224   |
| LossBefore              | 0.599172   |
| MaxReturn               | 526        |
| MeanKL                  | 0.00999073 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 332        |
| NumTrajs                | 23         |
| Perplexity              | 2511.22    |
| PolicyExecTime          | 0.634      |
| ProcessExecTime         | 0.0851     |
| StdReturn               | 50.6       |
| Time                    | 1.8e+03    |
| dLoss                   | 0.0539478  |
----------------------------------------
itr #168 | 
Mem: 735.414062
Obtaining samples...
Obtaining samples for iteration 168...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5017, #subsample_inputs: 5017
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.628      |
| AbsLearnSignalNew       | 0.628      |
| AbsLearningOld          | 0.628      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 0.973972   |
| AveragePolicyStd        | 0.889957   |
| AverageReturn           | 372        |
| Entropy                 | 7.79906    |
| EnvExecTime             | 2.88       |
| ExplainedVariance       | 0.64       |
| Iteration               | 168        |
| ItrTime                 | 11.1       |
| LossAfter               | 0.784292   |
| LossBefore              | 0.825175   |
| MaxReturn               | 521        |
| MeanKL                  | 0.00640578 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 83         |
| NumTrajs                | 24         |
| Perplexity              | 2438.31    |
| PolicyExecTime          | 0.596      |
| ProcessExecTime         | 0.0849     |
| StdReturn               | 79.8       |
| Time                    | 1.81e+03   |
| dLoss                   | 0.0408823  |
----------------------------------------
itr #169 | 
Mem: 735.414062
Obtaining samples...
Obtaining samples for iteration 169...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5046, #subsample_inputs: 5046
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.676      |
| AbsLearnSignalNew       | 0.676      |
| AbsLearningOld          | 0.676      |
| AverageDiscountedReturn | 124        |
| AveragePhiLoss          | 0.984233   |
| AveragePolicyStd        | 0.88635    |
| AverageReturn           | 342        |
| Entropy                 | 7.77438    |
| EnvExecTime             | 2.56       |
| ExplainedVariance       | 0.642      |
| Iteration               | 169        |
| ItrTime                 | 10.6       |
| LossAfter               | 0.450726   |
| LossBefore              | 0.489668   |
| MaxReturn               | 478        |
| MeanKL                  | 0.00643416 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 94.1       |
| NumTrajs                | 25         |
| Perplexity              | 2378.86    |
| PolicyExecTime          | 0.493      |
| ProcessExecTime         | 0.0663     |
| StdReturn               | 86.6       |
| Time                    | 1.82e+03   |
| dLoss                   | 0.0389423  |
----------------------------------------
itr #170 | 
Mem: 735.414062
Obtaining samples...
Obtaining samples for iteration 170...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5059, #subsample_inputs: 5059
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.715      |
| AbsLearnSignalNew       | 0.715      |
| AbsLearningOld          | 0.715      |
| AverageDiscountedReturn | 127        |
| AveragePhiLoss          | 0.966536   |
| AveragePolicyStd        | 0.881193   |
| AverageReturn           | 393        |
| Entropy                 | 7.74135    |
| EnvExecTime             | 2.73       |
| ExplainedVariance       | 0.599      |
| Iteration               | 170        |
| ItrTime                 | 10.2       |
| LossAfter               | 0.0212287  |
| LossBefore              | 0.0809989  |
| MaxReturn               | 528        |
| MeanKL                  | 0.00980885 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 103        |
| NumTrajs                | 23         |
| Perplexity              | 2301.57    |
| PolicyExecTime          | 0.577      |
| ProcessExecTime         | 0.0794     |
| StdReturn               | 97.6       |
| Time                    | 1.83e+03   |
| dLoss                   | 0.0597702  |
----------------------------------------
itr #171 | 
Mem: 735.414062
Obtaining samples...
Obtaining samples for iteration 171...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5125, #subsample_inputs: 5125
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.657      |
| AbsLearnSignalNew       | 0.657      |
| AbsLearningOld          | 0.657      |
| AverageDiscountedReturn | 119        |
| AveragePhiLoss          | 0.965723   |
| AveragePolicyStd        | 0.883345   |
| AverageReturn           | 344        |
| Entropy                 | 7.75616    |
| EnvExecTime             | 2.97       |
| ExplainedVariance       | 0.479      |
| Iteration               | 171        |
| ItrTime                 | 11.7       |
| LossAfter               | 0.285554   |
| LossBefore              | 0.333114   |
| MaxReturn               | 590        |
| MeanKL                  | 0.00646027 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 40.4       |
| NumTrajs                | 24         |
| Perplexity              | 2335.91    |
| PolicyExecTime          | 0.602      |
| ProcessExecTime         | 0.0816     |
| StdReturn               | 135        |
| Time                    | 1.84e+03   |
| dLoss                   | 0.0475598  |
----------------------------------------
itr #172 | 
Mem: 735.414062
Obtaining samples...
Obtaining samples for iteration 172...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5086, #subsample_inputs: 5086
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.724      |
| AbsLearnSignalNew       | 0.724      |
| AbsLearningOld          | 0.724      |
| AverageDiscountedReturn | 127        |
| AveragePhiLoss          | 0.964676   |
| AveragePolicyStd        | 0.881214   |
| AverageReturn           | 381        |
| Entropy                 | 7.74151    |
| EnvExecTime             | 2.9        |
| ExplainedVariance       | 0.649      |
| Iteration               | 172        |
| ItrTime                 | 10.4       |
| LossAfter               | -0.306428  |
| LossBefore              | -0.262374  |
| MaxReturn               | 533        |
| MeanKL                  | 0.00641323 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 54.8       |
| NumTrajs                | 24         |
| Perplexity              | 2301.95    |
| PolicyExecTime          | 0.603      |
| ProcessExecTime         | 0.0827     |
| StdReturn               | 92.5       |
| Time                    | 1.85e+03   |
| dLoss                   | 0.0440542  |
----------------------------------------
itr #173 | 
Mem: 735.414062
Obtaining samples...
Obtaining samples for iteration 173...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5301, #subsample_inputs: 5301
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.63       |
| AbsLearnSignalNew       | 0.63       |
| AbsLearningOld          | 0.63       |
| AverageDiscountedReturn | 127        |
| AveragePhiLoss          | 0.973689   |
| AveragePolicyStd        | 0.881877   |
| AverageReturn           | 374        |
| Entropy                 | 7.74553    |
| EnvExecTime             | 3          |
| ExplainedVariance       | 0.641      |
| Iteration               | 173        |
| ItrTime                 | 11.7       |
| LossAfter               | -0.11664   |
| LossBefore              | -0.0608687 |
| MaxReturn               | 571        |
| MeanKL                  | 0.00989338 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 90.3       |
| NumTrajs                | 25         |
| Perplexity              | 2311.21    |
| PolicyExecTime          | 0.614      |
| ProcessExecTime         | 0.0871     |
| StdReturn               | 101        |
| Time                    | 1.87e+03   |
| dLoss                   | 0.0557709  |
----------------------------------------
itr #174 | 
Mem: 735.515625
Obtaining samples...
Obtaining samples for iteration 174...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5077, #subsample_inputs: 5077
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.675      |
| AbsLearnSignalNew       | 0.675      |
| AbsLearningOld          | 0.675      |
| AverageDiscountedReturn | 115        |
| AveragePhiLoss          | 0.972339   |
| AveragePolicyStd        | 0.882857   |
| AverageReturn           | 324        |
| Entropy                 | 7.75158    |
| EnvExecTime             | 2.45       |
| ExplainedVariance       | 0.554      |
| Iteration               | 174        |
| ItrTime                 | 10.8       |
| LossAfter               | 0.0173817  |
| LossBefore              | 0.0710905  |
| MaxReturn               | 477        |
| MeanKL                  | 0.00984752 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 42.3       |
| NumTrajs                | 25         |
| Perplexity              | 2325.23    |
| PolicyExecTime          | 0.473      |
| ProcessExecTime         | 0.0667     |
| StdReturn               | 125        |
| Time                    | 1.88e+03   |
| dLoss                   | 0.0537087  |
----------------------------------------
itr #175 | 
Mem: 735.515625
Obtaining samples...
Obtaining samples for iteration 175...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5000, #subsample_inputs: 5000
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.73       |
| AbsLearnSignalNew       | 0.73       |
| AbsLearningOld          | 0.73       |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 0.968628   |
| AveragePolicyStd        | 0.882926   |
| AverageReturn           | 375        |
| Entropy                 | 7.75247    |
| EnvExecTime             | 2.8        |
| ExplainedVariance       | 0.619      |
| Iteration               | 175        |
| ItrTime                 | 9.92       |
| LossAfter               | -0.327136  |
| LossBefore              | -0.268585  |
| MaxReturn               | 492        |
| MeanKL                  | 0.00984014 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 120        |
| NumTrajs                | 24         |
| Perplexity              | 2327.31    |
| PolicyExecTime          | 0.597      |
| ProcessExecTime         | 0.0803     |
| StdReturn               | 73.9       |
| Time                    | 1.89e+03   |
| dLoss                   | 0.058551   |
----------------------------------------
itr #176 | 
Mem: 735.515625
Obtaining samples...
Obtaining samples for iteration 176...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5178, #subsample_inputs: 5178
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.657      |
| AbsLearnSignalNew       | 0.657      |
| AbsLearningOld          | 0.657      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 0.97579    |
| AveragePolicyStd        | 0.885373   |
| AverageReturn           | 360        |
| Entropy                 | 7.76938    |
| EnvExecTime             | 2.78       |
| ExplainedVariance       | 0.574      |
| Iteration               | 176        |
| ItrTime                 | 11.2       |
| LossAfter               | -0.429367  |
| LossBefore              | -0.390661  |
| MaxReturn               | 548        |
| MeanKL                  | 0.00646616 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 107        |
| NumTrajs                | 24         |
| Perplexity              | 2366.99    |
| PolicyExecTime          | 0.596      |
| ProcessExecTime         | 0.0814     |
| StdReturn               | 94.7       |
| Time                    | 1.9e+03    |
| dLoss                   | 0.0387057  |
----------------------------------------
itr #177 | 
Mem: 735.515625
Obtaining samples...
Obtaining samples for iteration 177...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5080, #subsample_inputs: 5080
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.686      |
| AbsLearnSignalNew       | 0.686      |
| AbsLearningOld          | 0.686      |
| AverageDiscountedReturn | 117        |
| AveragePhiLoss          | 0.97281    |
| AveragePolicyStd        | 0.88418    |
| AverageReturn           | 351        |
| Entropy                 | 7.76214    |
| EnvExecTime             | 2.85       |
| ExplainedVariance       | 0.591      |
| Iteration               | 177        |
| ItrTime                 | 10.4       |
| LossAfter               | 0.0401879  |
| LossBefore              | 0.0807354  |
| MaxReturn               | 530        |
| MeanKL                  | 0.00641309 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 66         |
| NumTrajs                | 23         |
| Perplexity              | 2349.92    |
| PolicyExecTime          | 0.582      |
| ProcessExecTime         | 0.0773     |
| StdReturn               | 134        |
| Time                    | 1.91e+03   |
| dLoss                   | 0.0405476  |
----------------------------------------
itr #178 | 
Mem: 735.515625
Obtaining samples...
Obtaining samples for iteration 178...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5166, #subsample_inputs: 5166
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.715     |
| AbsLearnSignalNew       | 0.715     |
| AbsLearningOld          | 0.715     |
| AverageDiscountedReturn | 122       |
| AveragePhiLoss          | 0.961286  |
| AveragePolicyStd        | 0.887398  |
| AverageReturn           | 400       |
| Entropy                 | 7.78338   |
| EnvExecTime             | 2.97      |
| ExplainedVariance       | 0.542     |
| Iteration               | 178       |
| ItrTime                 | 11.2      |
| LossAfter               | -0.955178 |
| LossBefore              | -0.9097   |
| MaxReturn               | 580       |
| MeanKL                  | 0.0064185 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 77.5      |
| NumTrajs                | 22        |
| Perplexity              | 2400.38   |
| PolicyExecTime          | 0.647     |
| ProcessExecTime         | 0.0833    |
| StdReturn               | 97.1      |
| Time                    | 1.92e+03  |
| dLoss                   | 0.0454782 |
---------------------------------------
itr #179 | 
Mem: 735.515625
Obtaining samples...
Obtaining samples for iteration 179...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5001, #subsample_inputs: 5001
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.672      |
| AbsLearnSignalNew       | 0.672      |
| AbsLearningOld          | 0.672      |
| AverageDiscountedReturn | 113        |
| AveragePhiLoss          | 0.97248    |
| AveragePolicyStd        | 0.88572    |
| AverageReturn           | 336        |
| Entropy                 | 7.77228    |
| EnvExecTime             | 2.65       |
| ExplainedVariance       | 0.481      |
| Iteration               | 179        |
| ItrTime                 | 10.8       |
| LossAfter               | 0.108892   |
| LossBefore              | 0.161139   |
| MaxReturn               | 496        |
| MeanKL                  | 0.00996182 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 58.4       |
| NumTrajs                | 23         |
| Perplexity              | 2373.87    |
| PolicyExecTime          | 0.513      |
| ProcessExecTime         | 0.0661     |
| StdReturn               | 146        |
| Time                    | 1.93e+03   |
| dLoss                   | 0.0522473  |
----------------------------------------
itr #180 | 
Mem: 735.515625
Obtaining samples...
Obtaining samples for iteration 180...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5200, #subsample_inputs: 5200
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.717      |
| AbsLearnSignalNew       | 0.717      |
| AbsLearningOld          | 0.717      |
| AverageDiscountedReturn | 124        |
| AveragePhiLoss          | 0.970588   |
| AveragePolicyStd        | 0.885422   |
| AverageReturn           | 374        |
| Entropy                 | 7.77047    |
| EnvExecTime             | 2.91       |
| ExplainedVariance       | 0.561      |
| Iteration               | 180        |
| ItrTime                 | 10.1       |
| LossAfter               | -0.0134828 |
| LossBefore              | 0.0280634  |
| MaxReturn               | 503        |
| MeanKL                  | 0.00641963 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 87.4       |
| NumTrajs                | 24         |
| Perplexity              | 2369.58    |
| PolicyExecTime          | 0.613      |
| ProcessExecTime         | 0.0826     |
| StdReturn               | 101        |
| Time                    | 1.94e+03   |
| dLoss                   | 0.0415462  |
----------------------------------------
itr #181 | 
Mem: 735.515625
Obtaining samples...
Obtaining samples for iteration 181...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5006, #subsample_inputs: 5006
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.733      |
| AbsLearnSignalNew       | 0.733      |
| AbsLearningOld          | 0.732      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 0.962344   |
| AveragePolicyStd        | 0.883482   |
| AverageReturn           | 361        |
| Entropy                 | 7.75748    |
| EnvExecTime             | 2.95       |
| ExplainedVariance       | 0.668      |
| Iteration               | 181        |
| ItrTime                 | 11.1       |
| LossAfter               | -0.248546  |
| LossBefore              | -0.192898  |
| MaxReturn               | 535        |
| MeanKL                  | 0.00991644 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 208        |
| NumTrajs                | 24         |
| Perplexity              | 2338.99    |
| PolicyExecTime          | 0.625      |
| ProcessExecTime         | 0.0831     |
| StdReturn               | 70.5       |
| Time                    | 1.95e+03   |
| dLoss                   | 0.0556476  |
----------------------------------------
itr #182 | 
Mem: 735.515625
Obtaining samples...
Obtaining samples for iteration 182...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5069, #subsample_inputs: 5069
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.616      |
| AbsLearnSignalNew       | 0.616      |
| AbsLearningOld          | 0.616      |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 0.982672   |
| AveragePolicyStd        | 0.882766   |
| AverageReturn           | 363        |
| Entropy                 | 7.7519     |
| EnvExecTime             | 2.66       |
| ExplainedVariance       | 0.617      |
| Iteration               | 182        |
| ItrTime                 | 10.1       |
| LossAfter               | -0.242393  |
| LossBefore              | -0.194201  |
| MaxReturn               | 492        |
| MeanKL                  | 0.00979485 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 50.6       |
| NumTrajs                | 24         |
| Perplexity              | 2325.98    |
| PolicyExecTime          | 0.53       |
| ProcessExecTime         | 0.0737     |
| StdReturn               | 102        |
| Time                    | 1.96e+03   |
| dLoss                   | 0.0481915  |
----------------------------------------
itr #183 | 
Mem: 735.515625
Obtaining samples...
Obtaining samples for iteration 183...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5056, #subsample_inputs: 5056
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.703      |
| AbsLearnSignalNew       | 0.703      |
| AbsLearningOld          | 0.703      |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 0.957435   |
| AveragePolicyStd        | 0.883461   |
| AverageReturn           | 390        |
| Entropy                 | 7.75646    |
| EnvExecTime             | 3.16       |
| ExplainedVariance       | 0.672      |
| Iteration               | 183        |
| ItrTime                 | 11.1       |
| LossAfter               | -0.545162  |
| LossBefore              | -0.498651  |
| MaxReturn               | 532        |
| MeanKL                  | 0.00647722 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 256        |
| NumTrajs                | 23         |
| Perplexity              | 2336.63    |
| PolicyExecTime          | 0.647      |
| ProcessExecTime         | 0.0868     |
| StdReturn               | 70.1       |
| Time                    | 1.97e+03   |
| dLoss                   | 0.046511   |
----------------------------------------
itr #184 | 
Mem: 735.515625
Obtaining samples...
Obtaining samples for iteration 184...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5127, #subsample_inputs: 5127
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.705      |
| AbsLearnSignalNew       | 0.705      |
| AbsLearningOld          | 0.705      |
| AverageDiscountedReturn | 118        |
| AveragePhiLoss          | 0.970416   |
| AveragePolicyStd        | 0.880818   |
| AverageReturn           | 379        |
| Entropy                 | 7.73853    |
| EnvExecTime             | 3.05       |
| ExplainedVariance       | 0.465      |
| Iteration               | 184        |
| ItrTime                 | 11.4       |
| LossAfter               | -0.563625  |
| LossBefore              | -0.520362  |
| MaxReturn               | 613        |
| MeanKL                  | 0.00642178 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 53.7       |
| NumTrajs                | 22         |
| Perplexity              | 2295.09    |
| PolicyExecTime          | 0.597      |
| ProcessExecTime         | 0.0784     |
| StdReturn               | 134        |
| Time                    | 1.99e+03   |
| dLoss                   | 0.0432627  |
----------------------------------------
itr #185 | 
Mem: 739.390625
Obtaining samples...
Obtaining samples for iteration 185...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5147, #subsample_inputs: 5147
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.691      |
| AbsLearnSignalNew       | 0.691      |
| AbsLearningOld          | 0.691      |
| AverageDiscountedReturn | 110        |
| AveragePhiLoss          | 0.975325   |
| AveragePolicyStd        | 0.877968   |
| AverageReturn           | 344        |
| Entropy                 | 7.72056    |
| EnvExecTime             | 3.03       |
| ExplainedVariance       | 0.528      |
| Iteration               | 185        |
| ItrTime                 | 9.92       |
| LossAfter               | 0.567246   |
| LossBefore              | 0.620471   |
| MaxReturn               | 715        |
| MeanKL                  | 0.00999182 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 26.7       |
| NumTrajs                | 22         |
| Perplexity              | 2254.21    |
| PolicyExecTime          | 0.602      |
| ProcessExecTime         | 0.0838     |
| StdReturn               | 173        |
| Time                    | 2e+03      |
| dLoss                   | 0.053225   |
----------------------------------------
itr #186 | 
Mem: 739.390625
Obtaining samples...
Obtaining samples for iteration 186...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5177, #subsample_inputs: 5177
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.758      |
| AbsLearnSignalNew       | 0.758      |
| AbsLearningOld          | 0.758      |
| AverageDiscountedReturn | 110        |
| AveragePhiLoss          | 0.969476   |
| AveragePolicyStd        | 0.874241   |
| AverageReturn           | 313        |
| Entropy                 | 7.69501    |
| EnvExecTime             | 3.15       |
| ExplainedVariance       | 0.583      |
| Iteration               | 186        |
| ItrTime                 | 11.7       |
| LossAfter               | -0.0158478 |
| LossBefore              | 0.0272952  |
| MaxReturn               | 548        |
| MeanKL                  | 0.00643897 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 22.2       |
| NumTrajs                | 26         |
| Perplexity              | 2197.35    |
| PolicyExecTime          | 0.64       |
| ProcessExecTime         | 0.0866     |
| StdReturn               | 157        |
| Time                    | 2.01e+03   |
| dLoss                   | 0.0431429  |
----------------------------------------
itr #187 | 
Mem: 739.390625
Obtaining samples...
Obtaining samples for iteration 187...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5113, #subsample_inputs: 5113
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.709      |
| AbsLearnSignalNew       | 0.709      |
| AbsLearningOld          | 0.709      |
| AverageDiscountedReturn | 118        |
| AveragePhiLoss          | 0.961526   |
| AveragePolicyStd        | 0.875972   |
| AverageReturn           | 379        |
| Entropy                 | 7.70673    |
| EnvExecTime             | 3.02       |
| ExplainedVariance       | 0.612      |
| Iteration               | 187        |
| ItrTime                 | 11.1       |
| LossAfter               | 0.0043363  |
| LossBefore              | 0.0555743  |
| MaxReturn               | 581        |
| MeanKL                  | 0.00996562 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 57         |
| NumTrajs                | 22         |
| Perplexity              | 2223.27    |
| PolicyExecTime          | 0.588      |
| ProcessExecTime         | 0.0789     |
| StdReturn               | 142        |
| Time                    | 2.02e+03   |
| dLoss                   | 0.051238   |
----------------------------------------
itr #188 | 
Mem: 739.390625
Obtaining samples...
Obtaining samples for iteration 188...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5078, #subsample_inputs: 5078
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.696      |
| AbsLearnSignalNew       | 0.696      |
| AbsLearningOld          | 0.696      |
| AverageDiscountedReturn | 115        |
| AveragePhiLoss          | 0.977727   |
| AveragePolicyStd        | 0.879359   |
| AverageReturn           | 356        |
| Entropy                 | 7.72683    |
| EnvExecTime             | 2.98       |
| ExplainedVariance       | 0.453      |
| Iteration               | 188        |
| ItrTime                 | 10.6       |
| LossAfter               | -0.125747  |
| LossBefore              | -0.0705567 |
| MaxReturn               | 654        |
| MeanKL                  | 0.00981255 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 56.5       |
| NumTrajs                | 23         |
| Perplexity              | 2268.4     |
| PolicyExecTime          | 0.623      |
| ProcessExecTime         | 0.084      |
| StdReturn               | 156        |
| Time                    | 2.03e+03   |
| dLoss                   | 0.0551905  |
----------------------------------------
itr #189 | 
Mem: 739.390625
Obtaining samples...
Obtaining samples for iteration 189...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5098, #subsample_inputs: 5098
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.713     |
| AbsLearnSignalNew       | 0.713     |
| AbsLearningOld          | 0.713     |
| AverageDiscountedReturn | 124       |
| AveragePhiLoss          | 0.976793  |
| AveragePolicyStd        | 0.881658  |
| AverageReturn           | 355       |
| Entropy                 | 7.74172   |
| EnvExecTime             | 2.58      |
| ExplainedVariance       | 0.566     |
| Iteration               | 189       |
| ItrTime                 | 10.7      |
| LossAfter               | 0.0417425 |
| LossBefore              | 0.0954433 |
| MaxReturn               | 495       |
| MeanKL                  | 0.009998  |
| MeanKLBefore            | 0.0       |
| MinReturn               | 70.1      |
| NumTrajs                | 25        |
| Perplexity              | 2302.44   |
| PolicyExecTime          | 0.519     |
| ProcessExecTime         | 0.0705    |
| StdReturn               | 97.9      |
| Time                    | 2.04e+03  |
| dLoss                   | 0.0537007 |
---------------------------------------
itr #190 | 
Mem: 739.390625
Obtaining samples...
Obtaining samples for iteration 190...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5102, #subsample_inputs: 5102
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.702     |
| AbsLearnSignalNew       | 0.702     |
| AbsLearningOld          | 0.703     |
| AverageDiscountedReturn | 130       |
| AveragePhiLoss          | 0.974517  |
| AveragePolicyStd        | 0.882863  |
| AverageReturn           | 365       |
| Entropy                 | 7.74772   |
| EnvExecTime             | 2.87      |
| ExplainedVariance       | 0.656     |
| Iteration               | 190       |
| ItrTime                 | 9.91      |
| LossAfter               | -0.301179 |
| LossBefore              | -0.258443 |
| MaxReturn               | 490       |
| MeanKL                  | 0.0064298 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 85        |
| NumTrajs                | 25        |
| Perplexity              | 2316.28   |
| PolicyExecTime          | 0.625     |
| ProcessExecTime         | 0.0834    |
| StdReturn               | 84.7      |
| Time                    | 2.05e+03  |
| dLoss                   | 0.0427358 |
---------------------------------------
itr #191 | 
Mem: 739.390625
Obtaining samples...
Obtaining samples for iteration 191...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5018, #subsample_inputs: 5018
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.412      |
| AbsLearnSignalNew       | 0.412      |
| AbsLearningOld          | 0.412      |
| AverageDiscountedReturn | 119        |
| AveragePhiLoss          | 0.954763   |
| AveragePolicyStd        | 0.882247   |
| AverageReturn           | 363        |
| Entropy                 | 7.74455    |
| EnvExecTime             | 3          |
| ExplainedVariance       | -0.868     |
| Iteration               | 191        |
| ItrTime                 | 11.2       |
| LossAfter               | -0.488357  |
| LossBefore              | -0.439987  |
| MaxReturn               | 638        |
| MeanKL                  | 0.00965634 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 55         |
| NumTrajs                | 22         |
| Perplexity              | 2308.95    |
| PolicyExecTime          | 0.607      |
| ProcessExecTime         | 0.0822     |
| StdReturn               | 124        |
| Time                    | 2.06e+03   |
| dLoss                   | 0.0483705  |
----------------------------------------
itr #192 | 
Mem: 739.390625
Obtaining samples...
Obtaining samples for iteration 192...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5026, #subsample_inputs: 5026
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.714      |
| AbsLearnSignalNew       | 0.714      |
| AbsLearningOld          | 0.714      |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 0.972065   |
| AveragePolicyStd        | 0.878837   |
| AverageReturn           | 398        |
| Entropy                 | 7.72243    |
| EnvExecTime             | 2.54       |
| ExplainedVariance       | 0.604      |
| Iteration               | 192        |
| ItrTime                 | 10.2       |
| LossAfter               | -0.0763315 |
| LossBefore              | -0.029997  |
| MaxReturn               | 542        |
| MeanKL                  | 0.00642184 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 65.7       |
| NumTrajs                | 23         |
| Perplexity              | 2258.43    |
| PolicyExecTime          | 0.517      |
| ProcessExecTime         | 0.0688     |
| StdReturn               | 99.6       |
| Time                    | 2.07e+03   |
| dLoss                   | 0.0463344  |
----------------------------------------
itr #193 | 
Mem: 739.390625
Obtaining samples...
Obtaining samples for iteration 193...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5122, #subsample_inputs: 5122
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.694      |
| AbsLearnSignalNew       | 0.694      |
| AbsLearningOld          | 0.694      |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 0.971743   |
| AveragePolicyStd        | 0.876314   |
| AverageReturn           | 369        |
| Entropy                 | 7.70545    |
| EnvExecTime             | 2.92       |
| ExplainedVariance       | 0.66       |
| Iteration               | 193        |
| ItrTime                 | 10.8       |
| LossAfter               | -0.165857  |
| LossBefore              | -0.107306  |
| MaxReturn               | 568        |
| MeanKL                  | 0.00992788 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 45.8       |
| NumTrajs                | 24         |
| Perplexity              | 2220.41    |
| PolicyExecTime          | 0.595      |
| ProcessExecTime         | 0.0823     |
| StdReturn               | 119        |
| Time                    | 2.08e+03   |
| dLoss                   | 0.0585517  |
----------------------------------------
itr #194 | 
Mem: 739.390625
Obtaining samples...
Obtaining samples for iteration 194...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5178, #subsample_inputs: 5178
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.647      |
| AbsLearnSignalNew       | 0.647      |
| AbsLearningOld          | 0.647      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 0.979514   |
| AveragePolicyStd        | 0.876853   |
| AverageReturn           | 391        |
| Entropy                 | 7.70988    |
| EnvExecTime             | 2.97       |
| ExplainedVariance       | 0.567      |
| Iteration               | 194        |
| ItrTime                 | 11.3       |
| LossAfter               | -0.212089  |
| LossBefore              | -0.171963  |
| MaxReturn               | 510        |
| MeanKL                  | 0.00645528 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 87.8       |
| NumTrajs                | 23         |
| Perplexity              | 2230.27    |
| PolicyExecTime          | 0.619      |
| ProcessExecTime         | 0.0755     |
| StdReturn               | 99.7       |
| Time                    | 2.09e+03   |
| dLoss                   | 0.0401261  |
----------------------------------------
itr #195 | 
Mem: 739.390625
Obtaining samples...
Obtaining samples for iteration 195...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5232, #subsample_inputs: 5232
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.696      |
| AbsLearnSignalNew       | 0.696      |
| AbsLearningOld          | 0.696      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 0.966248   |
| AveragePolicyStd        | 0.877522   |
| AverageReturn           | 380        |
| Entropy                 | 7.71449    |
| EnvExecTime             | 3.05       |
| ExplainedVariance       | 0.625      |
| Iteration               | 195        |
| ItrTime                 | 10.3       |
| LossAfter               | -0.103467  |
| LossBefore              | -0.0615005 |
| MaxReturn               | 555        |
| MeanKL                  | 0.00648327 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 68.8       |
| NumTrajs                | 24         |
| Perplexity              | 2240.58    |
| PolicyExecTime          | 0.624      |
| ProcessExecTime         | 0.0835     |
| StdReturn               | 104        |
| Time                    | 2.1e+03    |
| dLoss                   | 0.0419667  |
----------------------------------------
itr #196 | 
Mem: 739.390625
Obtaining samples...
Obtaining samples for iteration 196...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5080, #subsample_inputs: 5080
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.701      |
| AbsLearnSignalNew       | 0.701      |
| AbsLearningOld          | 0.701      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 0.978195   |
| AveragePolicyStd        | 0.871725   |
| AverageReturn           | 398        |
| Entropy                 | 7.67532    |
| EnvExecTime             | 2.95       |
| ExplainedVariance       | 0.583      |
| Iteration               | 196        |
| ItrTime                 | 11.2       |
| LossAfter               | -0.0700829 |
| LossBefore              | -0.0183405 |
| MaxReturn               | 583        |
| MeanKL                  | 0.0099663  |
| MeanKLBefore            | 0.0        |
| MinReturn               | 83.3       |
| NumTrajs                | 22         |
| Perplexity              | 2154.52    |
| PolicyExecTime          | 0.598      |
| ProcessExecTime         | 0.0809     |
| StdReturn               | 117        |
| Time                    | 2.12e+03   |
| dLoss                   | 0.0517424  |
----------------------------------------
itr #197 | 
Mem: 739.390625
Obtaining samples...
Obtaining samples for iteration 197...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5107, #subsample_inputs: 5107
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.733     |
| AbsLearnSignalNew       | 0.733     |
| AbsLearningOld          | 0.733     |
| AverageDiscountedReturn | 130       |
| AveragePhiLoss          | 0.96239   |
| AveragePolicyStd        | 0.873111  |
| AverageReturn           | 410       |
| Entropy                 | 7.68669   |
| EnvExecTime             | 2.65      |
| ExplainedVariance       | 0.694     |
| Iteration               | 197       |
| ItrTime                 | 10.6      |
| LossAfter               | -0.511527 |
| LossBefore              | -0.464576 |
| MaxReturn               | 561       |
| MeanKL                  | 0.0064241 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 295       |
| NumTrajs                | 23        |
| Perplexity              | 2179.14   |
| PolicyExecTime          | 0.527     |
| ProcessExecTime         | 0.0695    |
| StdReturn               | 75.3      |
| Time                    | 2.13e+03  |
| dLoss                   | 0.0469508 |
---------------------------------------
itr #198 | 
Mem: 739.390625
Obtaining samples...
Obtaining samples for iteration 198...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5118, #subsample_inputs: 5118
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.675      |
| AbsLearnSignalNew       | 0.675      |
| AbsLearningOld          | 0.675      |
| AverageDiscountedReturn | 117        |
| AveragePhiLoss          | 0.971818   |
| AveragePolicyStd        | 0.87223    |
| AverageReturn           | 338        |
| Entropy                 | 7.68003    |
| EnvExecTime             | 2.91       |
| ExplainedVariance       | 0.453      |
| Iteration               | 198        |
| ItrTime                 | 10.7       |
| LossAfter               | 0.0374435  |
| LossBefore              | 0.0782707  |
| MaxReturn               | 535        |
| MeanKL                  | 0.00643104 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 30.4       |
| NumTrajs                | 25         |
| Perplexity              | 2164.69    |
| PolicyExecTime          | 0.592      |
| ProcessExecTime         | 0.0809     |
| StdReturn               | 143        |
| Time                    | 2.14e+03   |
| dLoss                   | 0.0408273  |
----------------------------------------
itr #199 | 
Mem: 739.390625
Obtaining samples...
Obtaining samples for iteration 199...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5085, #subsample_inputs: 5085
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.584      |
| AbsLearnSignalNew       | 0.584      |
| AbsLearningOld          | 0.584      |
| AverageDiscountedReturn | 116        |
| AveragePhiLoss          | 0.969851   |
| AveragePolicyStd        | 0.871413   |
| AverageReturn           | 366        |
| Entropy                 | 7.67478    |
| EnvExecTime             | 2.66       |
| ExplainedVariance       | 0.24       |
| Iteration               | 199        |
| ItrTime                 | 10.8       |
| LossAfter               | -0.345405  |
| LossBefore              | -0.293866  |
| MaxReturn               | 598        |
| MeanKL                  | 0.00643747 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 67         |
| NumTrajs                | 22         |
| Perplexity              | 2153.35    |
| PolicyExecTime          | 0.537      |
| ProcessExecTime         | 0.0682     |
| StdReturn               | 146        |
| Time                    | 2.15e+03   |
| dLoss                   | 0.0515391  |
----------------------------------------
itr #200 | 
Mem: 739.390625
Obtaining samples...
Obtaining samples for iteration 200...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5145, #subsample_inputs: 5145
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.727      |
| AbsLearnSignalNew       | 0.727      |
| AbsLearningOld          | 0.727      |
| AverageDiscountedReturn | 119        |
| AveragePhiLoss          | 0.968438   |
| AveragePolicyStd        | 0.872446   |
| AverageReturn           | 365        |
| Entropy                 | 7.68113    |
| EnvExecTime             | 2.96       |
| ExplainedVariance       | 0.544      |
| Iteration               | 200        |
| ItrTime                 | 9.99       |
| LossAfter               | -0.162694  |
| LossBefore              | -0.119986  |
| MaxReturn               | 584        |
| MeanKL                  | 0.00643509 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 41         |
| NumTrajs                | 24         |
| Perplexity              | 2167.08    |
| PolicyExecTime          | 0.603      |
| ProcessExecTime         | 0.0817     |
| StdReturn               | 143        |
| Time                    | 2.16e+03   |
| dLoss                   | 0.042708   |
----------------------------------------
itr #201 | 
Mem: 739.390625
Obtaining samples...
Obtaining samples for iteration 201...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5095, #subsample_inputs: 5095
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.718      |
| AbsLearnSignalNew       | 0.718      |
| AbsLearningOld          | 0.718      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 0.974427   |
| AveragePolicyStd        | 0.868724   |
| AverageReturn           | 377        |
| Entropy                 | 7.65584    |
| EnvExecTime             | 2.86       |
| ExplainedVariance       | 0.591      |
| Iteration               | 201        |
| ItrTime                 | 11.2       |
| LossAfter               | 0.0831142  |
| LossBefore              | 0.130021   |
| MaxReturn               | 642        |
| MeanKL                  | 0.00997258 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 44.9       |
| NumTrajs                | 24         |
| Perplexity              | 2112.94    |
| PolicyExecTime          | 0.591      |
| ProcessExecTime         | 0.0797     |
| StdReturn               | 130        |
| Time                    | 2.17e+03   |
| dLoss                   | 0.0469066  |
----------------------------------------
itr #202 | 
Mem: 739.390625
Obtaining samples...
Obtaining samples for iteration 202...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5060, #subsample_inputs: 5060
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.711      |
| AbsLearnSignalNew       | 0.711      |
| AbsLearningOld          | 0.711      |
| AverageDiscountedReturn | 129        |
| AveragePhiLoss          | 0.974983   |
| AveragePolicyStd        | 0.86917    |
| AverageReturn           | 398        |
| Entropy                 | 7.6586     |
| EnvExecTime             | 2.65       |
| ExplainedVariance       | 0.549      |
| Iteration               | 202        |
| ItrTime                 | 10.2       |
| LossAfter               | -0.376674  |
| LossBefore              | -0.33518   |
| MaxReturn               | 643        |
| MeanKL                  | 0.00642203 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 156        |
| NumTrajs                | 23         |
| Perplexity              | 2118.79    |
| PolicyExecTime          | 0.512      |
| ProcessExecTime         | 0.0693     |
| StdReturn               | 92.7       |
| Time                    | 2.18e+03   |
| dLoss                   | 0.041494   |
----------------------------------------
itr #203 | 
Mem: 739.390625
Obtaining samples...
Obtaining samples for iteration 203...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5115, #subsample_inputs: 5115
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
-----------------------------------------
| AbsLearnSignal          | 0.681       |
| AbsLearnSignalNew       | 0.681       |
| AbsLearningOld          | 0.681       |
| AverageDiscountedReturn | 124         |
| AveragePhiLoss          | 0.965142    |
| AveragePolicyStd        | 0.86602     |
| AverageReturn           | 399         |
| Entropy                 | 7.63756     |
| EnvExecTime             | 2.96        |
| ExplainedVariance       | 0.564       |
| Iteration               | 203         |
| ItrTime                 | 11          |
| LossAfter               | -0.0623856  |
| LossBefore              | -0.00376372 |
| MaxReturn               | 532         |
| MeanKL                  | 0.00987132  |
| MeanKLBefore            | 0.0         |
| MinReturn               | 90          |
| NumTrajs                | 22          |
| Perplexity              | 2074.67     |
| PolicyExecTime          | 0.606       |
| ProcessExecTime         | 0.0805      |
| StdReturn               | 106         |
| Time                    | 2.19e+03    |
| dLoss                   | 0.0586219   |
-----------------------------------------
itr #204 | 
Mem: 739.390625
Obtaining samples...
Obtaining samples for iteration 204...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5106, #subsample_inputs: 5106
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.686      |
| AbsLearnSignalNew       | 0.686      |
| AbsLearningOld          | 0.686      |
| AverageDiscountedReturn | 130        |
| AveragePhiLoss          | 0.967758   |
| AveragePolicyStd        | 0.866214   |
| AverageReturn           | 405        |
| Entropy                 | 7.64003    |
| EnvExecTime             | 2.84       |
| ExplainedVariance       | 0.58       |
| Iteration               | 204        |
| ItrTime                 | 11.1       |
| LossAfter               | 0.0329095  |
| LossBefore              | 0.09529    |
| MaxReturn               | 576        |
| MeanKL                  | 0.00999981 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 156        |
| NumTrajs                | 23         |
| Perplexity              | 2079.81    |
| PolicyExecTime          | 0.603      |
| ProcessExecTime         | 0.074      |
| StdReturn               | 90.1       |
| Time                    | 2.2e+03    |
| dLoss                   | 0.0623806  |
----------------------------------------
itr #205 | 
Mem: 739.390625
Obtaining samples...
Obtaining samples for iteration 205...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5095, #subsample_inputs: 5095
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.513      |
| AbsLearnSignalNew       | 0.513      |
| AbsLearningOld          | 0.513      |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 0.97794    |
| AveragePolicyStd        | 0.865721   |
| AverageReturn           | 438        |
| Entropy                 | 7.63791    |
| EnvExecTime             | 2.94       |
| ExplainedVariance       | -0.051     |
| Iteration               | 205        |
| ItrTime                 | 9.95       |
| LossAfter               | 0.0117667  |
| LossBefore              | 0.0576975  |
| MaxReturn               | 749        |
| MeanKL                  | 0.00974673 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 59.1       |
| NumTrajs                | 20         |
| Perplexity              | 2075.4     |
| PolicyExecTime          | 0.603      |
| ProcessExecTime         | 0.0795     |
| StdReturn               | 156        |
| Time                    | 2.21e+03   |
| dLoss                   | 0.0459308  |
----------------------------------------
itr #206 | 
Mem: 739.390625
Obtaining samples...
Obtaining samples for iteration 206...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5150, #subsample_inputs: 5150
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.682      |
| AbsLearnSignalNew       | 0.682      |
| AbsLearningOld          | 0.682      |
| AverageDiscountedReturn | 117        |
| AveragePhiLoss          | 0.962998   |
| AveragePolicyStd        | 0.868557   |
| AverageReturn           | 434        |
| Entropy                 | 7.65715    |
| EnvExecTime             | 3.12       |
| ExplainedVariance       | 0.527      |
| Iteration               | 206        |
| ItrTime                 | 11.7       |
| LossAfter               | -0.242223  |
| LossBefore              | -0.186306  |
| MaxReturn               | 772        |
| MeanKL                  | 0.00985872 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 41.2       |
| NumTrajs                | 20         |
| Perplexity              | 2115.72    |
| PolicyExecTime          | 0.631      |
| ProcessExecTime         | 0.084      |
| StdReturn               | 172        |
| Time                    | 2.22e+03   |
| dLoss                   | 0.0559167  |
----------------------------------------
itr #207 | 
Mem: 739.390625
Obtaining samples...
Obtaining samples for iteration 207...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5014, #subsample_inputs: 5014
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.698      |
| AbsLearnSignalNew       | 0.698      |
| AbsLearningOld          | 0.698      |
| AverageDiscountedReturn | 114        |
| AveragePhiLoss          | 0.97509    |
| AveragePolicyStd        | 0.87213    |
| AverageReturn           | 384        |
| Entropy                 | 7.68154    |
| EnvExecTime             | 2.49       |
| ExplainedVariance       | 0.512      |
| Iteration               | 207        |
| ItrTime                 | 10.3       |
| LossAfter               | -0.293345  |
| LossBefore              | -0.250034  |
| MaxReturn               | 603        |
| MeanKL                  | 0.00642603 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 48.9       |
| NumTrajs                | 21         |
| Perplexity              | 2167.95    |
| PolicyExecTime          | 0.466      |
| ProcessExecTime         | 0.0621     |
| StdReturn               | 166        |
| Time                    | 2.23e+03   |
| dLoss                   | 0.0433108  |
----------------------------------------
itr #208 | 
Mem: 739.390625
Obtaining samples...
Obtaining samples for iteration 208...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5114, #subsample_inputs: 5114
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.725     |
| AbsLearnSignalNew       | 0.725     |
| AbsLearningOld          | 0.725     |
| AverageDiscountedReturn | 108       |
| AveragePhiLoss          | 0.982033  |
| AveragePolicyStd        | 0.873006  |
| AverageReturn           | 359       |
| Entropy                 | 7.68679   |
| EnvExecTime             | 3.05      |
| ExplainedVariance       | 0.555     |
| Iteration               | 208       |
| ItrTime                 | 10.4      |
| LossAfter               | 0.537731  |
| LossBefore              | 0.579131  |
| MaxReturn               | 634       |
| MeanKL                  | 0.0064269 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 43.6      |
| NumTrajs                | 21        |
| Perplexity              | 2179.37   |
| PolicyExecTime          | 0.597     |
| ProcessExecTime         | 0.0824    |
| StdReturn               | 190       |
| Time                    | 2.25e+03  |
| dLoss                   | 0.0414005 |
---------------------------------------
itr #209 | 
Mem: 739.390625
Obtaining samples...
Obtaining samples for iteration 209...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5148, #subsample_inputs: 5148
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.692      |
| AbsLearnSignalNew       | 0.692      |
| AbsLearningOld          | 0.692      |
| AverageDiscountedReturn | 118        |
| AveragePhiLoss          | 0.971386   |
| AveragePolicyStd        | 0.872158   |
| AverageReturn           | 376        |
| Entropy                 | 7.68078    |
| EnvExecTime             | 2.94       |
| ExplainedVariance       | 0.422      |
| Iteration               | 209        |
| ItrTime                 | 11.7       |
| LossAfter               | 0.0876599  |
| LossBefore              | 0.129163   |
| MaxReturn               | 585        |
| MeanKL                  | 0.00641343 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 111        |
| NumTrajs                | 22         |
| Perplexity              | 2166.31    |
| PolicyExecTime          | 0.591      |
| ProcessExecTime         | 0.0804     |
| StdReturn               | 123        |
| Time                    | 2.26e+03   |
| dLoss                   | 0.0415028  |
----------------------------------------
itr #210 | 
Mem: 739.390625
Obtaining samples...
Obtaining samples for iteration 210...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5062, #subsample_inputs: 5062
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.696      |
| AbsLearnSignalNew       | 0.696      |
| AbsLearningOld          | 0.696      |
| AverageDiscountedReturn | 127        |
| AveragePhiLoss          | 0.958698   |
| AveragePolicyStd        | 0.869432   |
| AverageReturn           | 414        |
| Entropy                 | 7.66378    |
| EnvExecTime             | 2.88       |
| ExplainedVariance       | 0.552      |
| Iteration               | 210        |
| ItrTime                 | 10.1       |
| LossAfter               | -0.958525  |
| LossBefore              | -0.886853  |
| MaxReturn               | 751        |
| MeanKL                  | 0.00990897 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 67.1       |
| NumTrajs                | 22         |
| Perplexity              | 2129.79    |
| PolicyExecTime          | 0.624      |
| ProcessExecTime         | 0.0803     |
| StdReturn               | 141        |
| Time                    | 2.27e+03   |
| dLoss                   | 0.071672   |
----------------------------------------
itr #211 | 
Mem: 739.390625
Obtaining samples...
Obtaining samples for iteration 211...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5172, #subsample_inputs: 5172
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.706      |
| AbsLearnSignalNew       | 0.706      |
| AbsLearningOld          | 0.706      |
| AverageDiscountedReturn | 119        |
| AveragePhiLoss          | 0.974192   |
| AveragePolicyStd        | 0.869097   |
| AverageReturn           | 401        |
| Entropy                 | 7.65939    |
| EnvExecTime             | 3.02       |
| ExplainedVariance       | 0.539      |
| Iteration               | 211        |
| ItrTime                 | 11.5       |
| LossAfter               | -0.781346  |
| LossBefore              | -0.728051  |
| MaxReturn               | 634        |
| MeanKL                  | 0.00987758 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 19.8       |
| NumTrajs                | 22         |
| Perplexity              | 2120.45    |
| PolicyExecTime          | 0.61       |
| ProcessExecTime         | 0.0833     |
| StdReturn               | 139        |
| Time                    | 2.28e+03   |
| dLoss                   | 0.053295   |
----------------------------------------
itr #212 | 
Mem: 739.390625
Obtaining samples...
Obtaining samples for iteration 212...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5182, #subsample_inputs: 5182
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.661      |
| AbsLearnSignalNew       | 0.661      |
| AbsLearningOld          | 0.661      |
| AverageDiscountedReturn | 118        |
| AveragePhiLoss          | 0.969792   |
| AveragePolicyStd        | 0.867089   |
| AverageReturn           | 386        |
| Entropy                 | 7.64429    |
| EnvExecTime             | 2.52       |
| ExplainedVariance       | 0.445      |
| Iteration               | 212        |
| ItrTime                 | 11         |
| LossAfter               | -0.82938   |
| LossBefore              | -0.789369  |
| MaxReturn               | 681        |
| MeanKL                  | 0.00642316 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 57.6       |
| NumTrajs                | 22         |
| Perplexity              | 2088.69    |
| PolicyExecTime          | 0.469      |
| ProcessExecTime         | 0.0631     |
| StdReturn               | 159        |
| Time                    | 2.29e+03   |
| dLoss                   | 0.0400114  |
----------------------------------------
itr #213 | 
Mem: 739.390625
Obtaining samples...
Obtaining samples for iteration 213...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5081, #subsample_inputs: 5081
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.703      |
| AbsLearnSignalNew       | 0.703      |
| AbsLearningOld          | 0.703      |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 0.969301   |
| AveragePolicyStd        | 0.861745   |
| AverageReturn           | 426        |
| Entropy                 | 7.60682    |
| EnvExecTime             | 3.06       |
| ExplainedVariance       | 0.546      |
| Iteration               | 213        |
| ItrTime                 | 10.1       |
| LossAfter               | -0.559304  |
| LossBefore              | -0.515995  |
| MaxReturn               | 634        |
| MeanKL                  | 0.00645635 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 74.3       |
| NumTrajs                | 22         |
| Perplexity              | 2011.88    |
| PolicyExecTime          | 0.614      |
| ProcessExecTime         | 0.0838     |
| StdReturn               | 144        |
| Time                    | 2.3e+03    |
| dLoss                   | 0.0433087  |
----------------------------------------
itr #214 | 
Mem: 739.390625
Obtaining samples...
Obtaining samples for iteration 214...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5072, #subsample_inputs: 5072
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.67       |
| AbsLearnSignalNew       | 0.67       |
| AbsLearningOld          | 0.67       |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 0.977454   |
| AveragePolicyStd        | 0.85731    |
| AverageReturn           | 412        |
| Entropy                 | 7.57567    |
| EnvExecTime             | 2.99       |
| ExplainedVariance       | 0.555      |
| Iteration               | 214        |
| ItrTime                 | 11.3       |
| LossAfter               | -0.575359  |
| LossBefore              | -0.523362  |
| MaxReturn               | 647        |
| MeanKL                  | 0.00991757 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 67.5       |
| NumTrajs                | 22         |
| Perplexity              | 1950.17    |
| PolicyExecTime          | 0.613      |
| ProcessExecTime         | 0.0819     |
| StdReturn               | 153        |
| Time                    | 2.31e+03   |
| dLoss                   | 0.0519972  |
----------------------------------------
itr #215 | 
Mem: 739.390625
Obtaining samples...
Obtaining samples for iteration 215...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5001, #subsample_inputs: 5001
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.715      |
| AbsLearnSignalNew       | 0.715      |
| AbsLearningOld          | 0.715      |
| AverageDiscountedReturn | 131        |
| AveragePhiLoss          | 0.966886   |
| AveragePolicyStd        | 0.859682   |
| AverageReturn           | 456        |
| Entropy                 | 7.5936     |
| EnvExecTime             | 2.65       |
| ExplainedVariance       | 0.617      |
| Iteration               | 215        |
| ItrTime                 | 9.96       |
| LossAfter               | -0.438511  |
| LossBefore              | -0.393289  |
| MaxReturn               | 636        |
| MeanKL                  | 0.00643233 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 82.7       |
| NumTrajs                | 20         |
| Perplexity              | 1985.44    |
| PolicyExecTime          | 0.524      |
| ProcessExecTime         | 0.0698     |
| StdReturn               | 133        |
| Time                    | 2.32e+03   |
| dLoss                   | 0.0452219  |
----------------------------------------
itr #216 | 
Mem: 740.343750
Obtaining samples...
Obtaining samples for iteration 216...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5007, #subsample_inputs: 5007
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.705      |
| AbsLearnSignalNew       | 0.705      |
| AbsLearningOld          | 0.705      |
| AverageDiscountedReturn | 115        |
| AveragePhiLoss          | 0.978931   |
| AveragePolicyStd        | 0.857302   |
| AverageReturn           | 355        |
| Entropy                 | 7.57812    |
| EnvExecTime             | 3.23       |
| ExplainedVariance       | 0.542      |
| Iteration               | 216        |
| ItrTime                 | 11.4       |
| LossAfter               | -0.206242  |
| LossBefore              | -0.167929  |
| MaxReturn               | 697        |
| MeanKL                  | 0.00642668 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 43.1       |
| NumTrajs                | 23         |
| Perplexity              | 1954.96    |
| PolicyExecTime          | 0.646      |
| ProcessExecTime         | 0.0858     |
| StdReturn               | 187        |
| Time                    | 2.33e+03   |
| dLoss                   | 0.0383131  |
----------------------------------------
itr #217 | 
Mem: 741.105469
Obtaining samples...
Obtaining samples for iteration 217...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5185, #subsample_inputs: 5185
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.698     |
| AbsLearnSignalNew       | 0.698     |
| AbsLearningOld          | 0.698     |
| AverageDiscountedReturn | 130       |
| AveragePhiLoss          | 0.968351  |
| AveragePolicyStd        | 0.854597  |
| AverageReturn           | 484       |
| Entropy                 | 7.5589    |
| EnvExecTime             | 2.75      |
| ExplainedVariance       | 0.444     |
| Iteration               | 217       |
| ItrTime                 | 11.1      |
| LossAfter               | -0.533317 |
| LossBefore              | -0.476342 |
| MaxReturn               | 897       |
| MeanKL                  | 0.009968  |
| MeanKLBefore            | 0.0       |
| MinReturn               | 129       |
| NumTrajs                | 20        |
| Perplexity              | 1917.73   |
| PolicyExecTime          | 0.53      |
| ProcessExecTime         | 0.0688    |
| StdReturn               | 139       |
| Time                    | 2.34e+03  |
| dLoss                   | 0.0569751 |
---------------------------------------
itr #218 | 
Mem: 742.105469
Obtaining samples...
Obtaining samples for iteration 218...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5159, #subsample_inputs: 5159
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.685      |
| AbsLearnSignalNew       | 0.685      |
| AbsLearningOld          | 0.685      |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 0.970036   |
| AveragePolicyStd        | 0.85408    |
| AverageReturn           | 459        |
| Entropy                 | 7.55467    |
| EnvExecTime             | 3.09       |
| ExplainedVariance       | 0.564      |
| Iteration               | 218        |
| ItrTime                 | 10.1       |
| LossAfter               | -0.95165   |
| LossBefore              | -0.896058  |
| MaxReturn               | 701        |
| MeanKL                  | 0.00988226 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 52.4       |
| NumTrajs                | 20         |
| Perplexity              | 1909.63    |
| PolicyExecTime          | 0.615      |
| ProcessExecTime         | 0.0844     |
| StdReturn               | 166        |
| Time                    | 2.35e+03   |
| dLoss                   | 0.0555924  |
----------------------------------------
itr #219 | 
Mem: 742.105469
Obtaining samples...
Obtaining samples for iteration 219...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5226, #subsample_inputs: 5226
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.688      |
| AbsLearnSignalNew       | 0.688      |
| AbsLearningOld          | 0.688      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 0.980577   |
| AveragePolicyStd        | 0.856781   |
| AverageReturn           | 421        |
| Entropy                 | 7.57292    |
| EnvExecTime             | 3.03       |
| ExplainedVariance       | 0.544      |
| Iteration               | 219        |
| ItrTime                 | 11.6       |
| LossAfter               | -0.195178  |
| LossBefore              | -0.151712  |
| MaxReturn               | 747        |
| MeanKL                  | 0.00652389 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 52.1       |
| NumTrajs                | 23         |
| Perplexity              | 1944.8     |
| PolicyExecTime          | 0.643      |
| ProcessExecTime         | 0.0859     |
| StdReturn               | 156        |
| Time                    | 2.37e+03   |
| dLoss                   | 0.0434663  |
----------------------------------------
itr #220 | 
Mem: 742.105469
Obtaining samples...
Obtaining samples for iteration 220...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5224, #subsample_inputs: 5224
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.691      |
| AbsLearnSignalNew       | 0.691      |
| AbsLearningOld          | 0.691      |
| AverageDiscountedReturn | 133        |
| AveragePhiLoss          | 0.973582   |
| AveragePolicyStd        | 0.852917   |
| AverageReturn           | 427        |
| Entropy                 | 7.54517    |
| EnvExecTime             | 2.64       |
| ExplainedVariance       | 0.544      |
| Iteration               | 220        |
| ItrTime                 | 10.6       |
| LossAfter               | -0.259202  |
| LossBefore              | -0.216832  |
| MaxReturn               | 594        |
| MeanKL                  | 0.00643884 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 109        |
| NumTrajs                | 23         |
| Perplexity              | 1891.58    |
| PolicyExecTime          | 0.513      |
| ProcessExecTime         | 0.0685     |
| StdReturn               | 117        |
| Time                    | 2.38e+03   |
| dLoss                   | 0.0423697  |
----------------------------------------
itr #221 | 
Mem: 742.105469
Obtaining samples...
Obtaining samples for iteration 221...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5006, #subsample_inputs: 5006
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.701      |
| AbsLearnSignalNew       | 0.701      |
| AbsLearningOld          | 0.701      |
| AverageDiscountedReturn | 130        |
| AveragePhiLoss          | 0.980936   |
| AveragePolicyStd        | 0.851084   |
| AverageReturn           | 451        |
| Entropy                 | 7.53156    |
| EnvExecTime             | 3.08       |
| ExplainedVariance       | 0.556      |
| Iteration               | 221        |
| ItrTime                 | 10.7       |
| LossAfter               | -0.857786  |
| LossBefore              | -0.817944  |
| MaxReturn               | 823        |
| MeanKL                  | 0.00643985 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 62.9       |
| NumTrajs                | 21         |
| Perplexity              | 1866.02    |
| PolicyExecTime          | 0.615      |
| ProcessExecTime         | 0.0822     |
| StdReturn               | 192        |
| Time                    | 2.39e+03   |
| dLoss                   | 0.0398425  |
----------------------------------------
itr #222 | 
Mem: 742.105469
Obtaining samples...
Obtaining samples for iteration 222...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5056, #subsample_inputs: 5056
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.682      |
| AbsLearnSignalNew       | 0.682      |
| AbsLearningOld          | 0.682      |
| AverageDiscountedReturn | 129        |
| AveragePhiLoss          | 0.968747   |
| AveragePolicyStd        | 0.850705   |
| AverageReturn           | 483        |
| Entropy                 | 7.52967    |
| EnvExecTime             | 2.93       |
| ExplainedVariance       | 0.393      |
| Iteration               | 222        |
| ItrTime                 | 11.4       |
| LossAfter               | -0.379218  |
| LossBefore              | -0.321046  |
| MaxReturn               | 943        |
| MeanKL                  | 0.00992009 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 98.7       |
| NumTrajs                | 20         |
| Perplexity              | 1862.49    |
| PolicyExecTime          | 0.618      |
| ProcessExecTime         | 0.0779     |
| StdReturn               | 190        |
| Time                    | 2.4e+03    |
| dLoss                   | 0.0581717  |
----------------------------------------
itr #223 | 
Mem: 742.105469
Obtaining samples...
Obtaining samples for iteration 223...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5142, #subsample_inputs: 5142
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.668      |
| AbsLearnSignalNew       | 0.668      |
| AbsLearningOld          | 0.668      |
| AverageDiscountedReturn | 113        |
| AveragePhiLoss          | 0.977683   |
| AveragePolicyStd        | 0.851899   |
| AverageReturn           | 353        |
| Entropy                 | 7.53824    |
| EnvExecTime             | 3.03       |
| ExplainedVariance       | 0.438      |
| Iteration               | 223        |
| ItrTime                 | 10.2       |
| LossAfter               | -0.601101  |
| LossBefore              | -0.543709  |
| MaxReturn               | 684        |
| MeanKL                  | 0.00993951 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 39.9       |
| NumTrajs                | 23         |
| Perplexity              | 1878.52    |
| PolicyExecTime          | 0.596      |
| ProcessExecTime         | 0.0807     |
| StdReturn               | 207        |
| Time                    | 2.41e+03   |
| dLoss                   | 0.0573916  |
----------------------------------------
itr #224 | 
Mem: 742.105469
Obtaining samples...
Obtaining samples for iteration 224...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5007, #subsample_inputs: 5007
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.663      |
| AbsLearnSignalNew       | 0.663      |
| AbsLearningOld          | 0.663      |
| AverageDiscountedReturn | 124        |
| AveragePhiLoss          | 0.973279   |
| AveragePolicyStd        | 0.847432   |
| AverageReturn           | 393        |
| Entropy                 | 7.50649    |
| EnvExecTime             | 3.12       |
| ExplainedVariance       | 0.405      |
| Iteration               | 224        |
| ItrTime                 | 11.3       |
| LossAfter               | 0.0665388  |
| LossBefore              | 0.123966   |
| MaxReturn               | 619        |
| MeanKL                  | 0.00651874 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 78.1       |
| NumTrajs                | 22         |
| Perplexity              | 1819.82    |
| PolicyExecTime          | 0.618      |
| ProcessExecTime         | 0.0846     |
| StdReturn               | 155        |
| Time                    | 2.42e+03   |
| dLoss                   | 0.0574277  |
----------------------------------------
itr #225 | 
Mem: 742.105469
Obtaining samples...
Obtaining samples for iteration 225...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5004, #subsample_inputs: 5004
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.707      |
| AbsLearnSignalNew       | 0.707      |
| AbsLearningOld          | 0.707      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 0.970491   |
| AveragePolicyStd        | 0.842737   |
| AverageReturn           | 433        |
| Entropy                 | 7.47351    |
| EnvExecTime             | 2.64       |
| ExplainedVariance       | 0.416      |
| Iteration               | 225        |
| ItrTime                 | 10.8       |
| LossAfter               | 0.620697   |
| LossBefore              | 0.667228   |
| MaxReturn               | 712        |
| MeanKL                  | 0.00644618 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 55.5       |
| NumTrajs                | 21         |
| Perplexity              | 1760.78    |
| PolicyExecTime          | 0.481      |
| ProcessExecTime         | 0.0635     |
| StdReturn               | 159        |
| Time                    | 2.43e+03   |
| dLoss                   | 0.0465317  |
----------------------------------------
itr #226 | 
Mem: 742.105469
Obtaining samples...
Obtaining samples for iteration 226...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5025, #subsample_inputs: 5025
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.71       |
| AbsLearnSignalNew       | 0.71       |
| AbsLearningOld          | 0.71       |
| AverageDiscountedReturn | 111        |
| AveragePhiLoss          | 0.973634   |
| AveragePolicyStd        | 0.838804   |
| AverageReturn           | 466        |
| Entropy                 | 7.44704    |
| EnvExecTime             | 3.08       |
| ExplainedVariance       | 0.5        |
| Iteration               | 226        |
| ItrTime                 | 10.2       |
| LossAfter               | -0.294099  |
| LossBefore              | -0.24122   |
| MaxReturn               | 794        |
| MeanKL                  | 0.00986196 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 44.2       |
| NumTrajs                | 18         |
| Perplexity              | 1714.77    |
| PolicyExecTime          | 0.601      |
| ProcessExecTime         | 0.0794     |
| StdReturn               | 274        |
| Time                    | 2.44e+03   |
| dLoss                   | 0.0528795  |
----------------------------------------
itr #227 | 
Mem: 742.105469
Obtaining samples...
Obtaining samples for iteration 227...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5072, #subsample_inputs: 5072
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.698      |
| AbsLearnSignalNew       | 0.698      |
| AbsLearningOld          | 0.698      |
| AverageDiscountedReturn | 110        |
| AveragePhiLoss          | 0.965048   |
| AveragePolicyStd        | 0.840363   |
| AverageReturn           | 381        |
| Entropy                 | 7.45499    |
| EnvExecTime             | 3.15       |
| ExplainedVariance       | 0.367      |
| Iteration               | 227        |
| ItrTime                 | 11.4       |
| LossAfter               | 0.142233   |
| LossBefore              | 0.202036   |
| MaxReturn               | 831        |
| MeanKL                  | 0.00997784 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 32.6       |
| NumTrajs                | 21         |
| Perplexity              | 1728.47    |
| PolicyExecTime          | 0.628      |
| ProcessExecTime         | 0.0817     |
| StdReturn               | 238        |
| Time                    | 2.45e+03   |
| dLoss                   | 0.0598025  |
----------------------------------------
itr #228 | 
Mem: 742.105469
Obtaining samples...
Obtaining samples for iteration 228...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5276, #subsample_inputs: 5276
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.722     |
| AbsLearnSignalNew       | 0.722     |
| AbsLearningOld          | 0.722     |
| AverageDiscountedReturn | 122       |
| AveragePhiLoss          | 0.983141  |
| AveragePolicyStd        | 0.843492  |
| AverageReturn           | 479       |
| Entropy                 | 7.47772   |
| EnvExecTime             | 2.9       |
| ExplainedVariance       | 0.433     |
| Iteration               | 228       |
| ItrTime                 | 10.6      |
| LossAfter               | -0.311982 |
| LossBefore              | -0.261794 |
| MaxReturn               | 776       |
| MeanKL                  | 0.0099037 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 56.6      |
| NumTrajs                | 20        |
| Perplexity              | 1768.2    |
| PolicyExecTime          | 0.566     |
| ProcessExecTime         | 0.0774    |
| StdReturn               | 189       |
| Time                    | 2.46e+03  |
| dLoss                   | 0.0501887 |
---------------------------------------
itr #229 | 
Mem: 742.105469
Obtaining samples...
Obtaining samples for iteration 229...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5152, #subsample_inputs: 5152
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.677      |
| AbsLearnSignalNew       | 0.677      |
| AbsLearningOld          | 0.677      |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 0.968702   |
| AveragePolicyStd        | 0.843029   |
| AverageReturn           | 467        |
| Entropy                 | 7.47435    |
| EnvExecTime             | 3.03       |
| ExplainedVariance       | 0.49       |
| Iteration               | 229        |
| ItrTime                 | 11.2       |
| LossAfter               | -0.600723  |
| LossBefore              | -0.556856  |
| MaxReturn               | 912        |
| MeanKL                  | 0.00643568 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 67         |
| NumTrajs                | 20         |
| Perplexity              | 1762.25    |
| PolicyExecTime          | 0.6        |
| ProcessExecTime         | 0.084      |
| StdReturn               | 210        |
| Time                    | 2.48e+03   |
| dLoss                   | 0.0438671  |
----------------------------------------
itr #230 | 
Mem: 742.105469
Obtaining samples...
Obtaining samples for iteration 230...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5240, #subsample_inputs: 5240
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.715      |
| AbsLearnSignalNew       | 0.715      |
| AbsLearningOld          | 0.715      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 0.980723   |
| AveragePolicyStd        | 0.841086   |
| AverageReturn           | 437        |
| Entropy                 | 7.4595     |
| EnvExecTime             | 2.9        |
| ExplainedVariance       | 0.52       |
| Iteration               | 230        |
| ItrTime                 | 11.4       |
| LossAfter               | -0.387661  |
| LossBefore              | -0.336195  |
| MaxReturn               | 964        |
| MeanKL                  | 0.00990414 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 72.8       |
| NumTrajs                | 21         |
| Perplexity              | 1736.28    |
| PolicyExecTime          | 0.543      |
| ProcessExecTime         | 0.0694     |
| StdReturn               | 257        |
| Time                    | 2.49e+03   |
| dLoss                   | 0.051466   |
----------------------------------------
itr #231 | 
Mem: 742.105469
Obtaining samples...
Obtaining samples for iteration 231...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5254, #subsample_inputs: 5254
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.723      |
| AbsLearnSignalNew       | 0.723      |
| AbsLearningOld          | 0.723      |
| AverageDiscountedReturn | 123        |
| AveragePhiLoss          | 0.968121   |
| AveragePolicyStd        | 0.843752   |
| AverageReturn           | 429        |
| Entropy                 | 7.47908    |
| EnvExecTime             | 3.44       |
| ExplainedVariance       | 0.498      |
| Iteration               | 231        |
| ItrTime                 | 10.8       |
| LossAfter               | -1.16099   |
| LossBefore              | -1.10595   |
| MaxReturn               | 860        |
| MeanKL                  | 0.00993935 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 31         |
| NumTrajs                | 22         |
| Perplexity              | 1770.61    |
| PolicyExecTime          | 0.674      |
| ProcessExecTime         | 0.088      |
| StdReturn               | 246        |
| Time                    | 2.5e+03    |
| dLoss                   | 0.0550463  |
----------------------------------------
itr #232 | 
Mem: 742.105469
Obtaining samples...
Obtaining samples for iteration 232...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5049, #subsample_inputs: 5049
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.726      |
| AbsLearnSignalNew       | 0.726      |
| AbsLearningOld          | 0.727      |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 0.974146   |
| AveragePolicyStd        | 0.842057   |
| AverageReturn           | 459        |
| Entropy                 | 7.46795    |
| EnvExecTime             | 3.16       |
| ExplainedVariance       | 0.416      |
| Iteration               | 232        |
| ItrTime                 | 11.4       |
| LossAfter               | -0.825345  |
| LossBefore              | -0.773291  |
| MaxReturn               | 1.01e+03   |
| MeanKL                  | 0.00992725 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 72         |
| NumTrajs                | 20         |
| Perplexity              | 1751.01    |
| PolicyExecTime          | 0.635      |
| ProcessExecTime         | 0.0819     |
| StdReturn               | 228        |
| Time                    | 2.51e+03   |
| dLoss                   | 0.052054   |
----------------------------------------
itr #233 | 
Mem: 742.105469
Obtaining samples...
Obtaining samples for iteration 233...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5075, #subsample_inputs: 5075
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.714      |
| AbsLearnSignalNew       | 0.714      |
| AbsLearningOld          | 0.714      |
| AverageDiscountedReturn | 108        |
| AveragePhiLoss          | 0.975639   |
| AveragePolicyStd        | 0.83897    |
| AverageReturn           | 413        |
| Entropy                 | 7.44639    |
| EnvExecTime             | 2.74       |
| ExplainedVariance       | 0.432      |
| Iteration               | 233        |
| ItrTime                 | 10.6       |
| LossAfter               | -0.454229  |
| LossBefore              | -0.401081  |
| MaxReturn               | 988        |
| MeanKL                  | 0.00991168 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 34.5       |
| NumTrajs                | 20         |
| Perplexity              | 1713.66    |
| PolicyExecTime          | 0.51       |
| ProcessExecTime         | 0.0663     |
| StdReturn               | 296        |
| Time                    | 2.52e+03   |
| dLoss                   | 0.0531481  |
----------------------------------------
itr #234 | 
Mem: 743.066406
Obtaining samples...
Obtaining samples for iteration 234...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5200, #subsample_inputs: 5200
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.68       |
| AbsLearnSignalNew       | 0.68       |
| AbsLearningOld          | 0.68       |
| AverageDiscountedReturn | 123        |
| AveragePhiLoss          | 0.969441   |
| AveragePolicyStd        | 0.840523   |
| AverageReturn           | 491        |
| Entropy                 | 7.45774    |
| EnvExecTime             | 3.08       |
| ExplainedVariance       | 0.3        |
| Iteration               | 234        |
| ItrTime                 | 10.7       |
| LossAfter               | -0.332253  |
| LossBefore              | -0.269505  |
| MaxReturn               | 1.14e+03   |
| MeanKL                  | 0.00999244 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 39.3       |
| NumTrajs                | 20         |
| Perplexity              | 1733.22    |
| PolicyExecTime          | 0.611      |
| ProcessExecTime         | 0.0817     |
| StdReturn               | 260        |
| Time                    | 2.53e+03   |
| dLoss                   | 0.0627472  |
----------------------------------------
itr #235 | 
Mem: 743.066406
Obtaining samples...
Obtaining samples for iteration 235...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5168, #subsample_inputs: 5168
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.715      |
| AbsLearnSignalNew       | 0.715      |
| AbsLearningOld          | 0.715      |
| AverageDiscountedReturn | 114        |
| AveragePhiLoss          | 0.981478   |
| AveragePolicyStd        | 0.84131    |
| AverageReturn           | 475        |
| Entropy                 | 7.46261    |
| EnvExecTime             | 3.19       |
| ExplainedVariance       | 0.581      |
| Iteration               | 235        |
| ItrTime                 | 11.6       |
| LossAfter               | -0.548822  |
| LossBefore              | -0.494649  |
| MaxReturn               | 1.31e+03   |
| MeanKL                  | 0.00988486 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 29.2       |
| NumTrajs                | 20         |
| Perplexity              | 1741.68    |
| PolicyExecTime          | 0.632      |
| ProcessExecTime         | 0.0834     |
| StdReturn               | 333        |
| Time                    | 2.54e+03   |
| dLoss                   | 0.0541723  |
----------------------------------------
itr #236 | 
Mem: 743.066406
Obtaining samples...
Obtaining samples for iteration 236...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5116, #subsample_inputs: 5116
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.749      |
| AbsLearnSignalNew       | 0.749      |
| AbsLearningOld          | 0.749      |
| AverageDiscountedReturn | 113        |
| AveragePhiLoss          | 0.976202   |
| AveragePolicyStd        | 0.83979    |
| AverageReturn           | 451        |
| Entropy                 | 7.45108    |
| EnvExecTime             | 3.14       |
| ExplainedVariance       | 0.555      |
| Iteration               | 236        |
| ItrTime                 | 10.7       |
| LossAfter               | -0.24924   |
| LossBefore              | -0.199547  |
| MaxReturn               | 1.14e+03   |
| MeanKL                  | 0.00999423 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 42.8       |
| NumTrajs                | 20         |
| Perplexity              | 1721.71    |
| PolicyExecTime          | 0.609      |
| ProcessExecTime         | 0.0786     |
| StdReturn               | 305        |
| Time                    | 2.55e+03   |
| dLoss                   | 0.0496928  |
----------------------------------------
itr #237 | 
Mem: 743.066406
Obtaining samples...
Obtaining samples for iteration 237...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5320, #subsample_inputs: 5320
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.715      |
| AbsLearnSignalNew       | 0.715      |
| AbsLearningOld          | 0.715      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 0.970528   |
| AveragePolicyStd        | 0.835761   |
| AverageReturn           | 580        |
| Entropy                 | 7.42171    |
| EnvExecTime             | 3.18       |
| ExplainedVariance       | 0.551      |
| Iteration               | 237        |
| ItrTime                 | 11.3       |
| LossAfter               | 0.0482474  |
| LossBefore              | 0.0921592  |
| MaxReturn               | 1.31e+03   |
| MeanKL                  | 0.00641847 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 53         |
| NumTrajs                | 18         |
| Perplexity              | 1671.89    |
| PolicyExecTime          | 0.635      |
| ProcessExecTime         | 0.0843     |
| StdReturn               | 344        |
| Time                    | 2.57e+03   |
| dLoss                   | 0.0439119  |
----------------------------------------
itr #238 | 
Mem: 743.066406
Obtaining samples...
Obtaining samples for iteration 238...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5103, #subsample_inputs: 5103
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.682      |
| AbsLearnSignalNew       | 0.682      |
| AbsLearningOld          | 0.682      |
| AverageDiscountedReturn | 123        |
| AveragePhiLoss          | 0.974257   |
| AveragePolicyStd        | 0.836299   |
| AverageReturn           | 499        |
| Entropy                 | 7.4267     |
| EnvExecTime             | 3.08       |
| ExplainedVariance       | 0.493      |
| Iteration               | 238        |
| ItrTime                 | 11.5       |
| LossAfter               | -0.140097  |
| LossBefore              | -0.0856035 |
| MaxReturn               | 1.17e+03   |
| MeanKL                  | 0.0099502  |
| MeanKLBefore            | 0.0        |
| MinReturn               | 46.1       |
| NumTrajs                | 19         |
| Perplexity              | 1680.25    |
| PolicyExecTime          | 0.592      |
| ProcessExecTime         | 0.0776     |
| StdReturn               | 270        |
| Time                    | 2.58e+03   |
| dLoss                   | 0.0544934  |
----------------------------------------
itr #239 | 
Mem: 743.066406
Obtaining samples...
Obtaining samples for iteration 239...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5120, #subsample_inputs: 5120
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.692      |
| AbsLearnSignalNew       | 0.692      |
| AbsLearningOld          | 0.692      |
| AverageDiscountedReturn | 109        |
| AveragePhiLoss          | 0.969208   |
| AveragePolicyStd        | 0.834965   |
| AverageReturn           | 462        |
| Entropy                 | 7.41638    |
| EnvExecTime             | 3.1        |
| ExplainedVariance       | 0.457      |
| Iteration               | 239        |
| ItrTime                 | 10.2       |
| LossAfter               | -0.362378  |
| LossBefore              | -0.304551  |
| MaxReturn               | 1.43e+03   |
| MeanKL                  | 0.00996635 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 53.4       |
| NumTrajs                | 18         |
| Perplexity              | 1662.99    |
| PolicyExecTime          | 0.61       |
| ProcessExecTime         | 0.0809     |
| StdReturn               | 364        |
| Time                    | 2.59e+03   |
| dLoss                   | 0.0578265  |
----------------------------------------
itr #240 | 
Mem: 743.066406
Obtaining samples...
Obtaining samples for iteration 240...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5135, #subsample_inputs: 5135
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.766      |
| AbsLearnSignalNew       | 0.766      |
| AbsLearningOld          | 0.766      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 0.977308   |
| AveragePolicyStd        | 0.835385   |
| AverageReturn           | 542        |
| Entropy                 | 7.41894    |
| EnvExecTime             | 3.19       |
| ExplainedVariance       | 0.408      |
| Iteration               | 240        |
| ItrTime                 | 11.5       |
| LossAfter               | -1.44252   |
| LossBefore              | -1.3845    |
| MaxReturn               | 979        |
| MeanKL                  | 0.00982124 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 58.3       |
| NumTrajs                | 18         |
| Perplexity              | 1667.27    |
| PolicyExecTime          | 0.642      |
| ProcessExecTime         | 0.0828     |
| StdReturn               | 287        |
| Time                    | 2.6e+03    |
| dLoss                   | 0.0580277  |
----------------------------------------
itr #241 | 
Mem: 743.066406
Obtaining samples...
Obtaining samples for iteration 241...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5748, #subsample_inputs: 5748
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.662      |
| AbsLearnSignalNew       | 0.662      |
| AbsLearningOld          | 0.662      |
| AverageDiscountedReturn | 133        |
| AveragePhiLoss          | 0.975324   |
| AveragePolicyStd        | 0.834696   |
| AverageReturn           | 682        |
| Entropy                 | 7.41389    |
| EnvExecTime             | 2.9        |
| ExplainedVariance       | -0.225     |
| Iteration               | 241        |
| ItrTime                 | 12         |
| LossAfter               | -0.695624  |
| LossBefore              | -0.650972  |
| MaxReturn               | 1.97e+03   |
| MeanKL                  | 0.00643057 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 58.4       |
| NumTrajs                | 17         |
| Perplexity              | 1658.86    |
| PolicyExecTime          | 0.553      |
| ProcessExecTime         | 0.0767     |
| StdReturn               | 417        |
| Time                    | 2.61e+03   |
| dLoss                   | 0.0446515  |
----------------------------------------
itr #242 | 
Mem: 745.632812
Obtaining samples...
Obtaining samples for iteration 242...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5067, #subsample_inputs: 5067
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.671      |
| AbsLearnSignalNew       | 0.671      |
| AbsLearningOld          | 0.672      |
| AverageDiscountedReturn | 131        |
| AveragePhiLoss          | 0.969776   |
| AveragePolicyStd        | 0.836869   |
| AverageReturn           | 558        |
| Entropy                 | 7.4303     |
| EnvExecTime             | 3.35       |
| ExplainedVariance       | 0.487      |
| Iteration               | 242        |
| ItrTime                 | 10.4       |
| LossAfter               | -0.483275  |
| LossBefore              | -0.429389  |
| MaxReturn               | 1.01e+03   |
| MeanKL                  | 0.00996697 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 69.6       |
| NumTrajs                | 18         |
| Perplexity              | 1686.32    |
| PolicyExecTime          | 0.674      |
| ProcessExecTime         | 0.0875     |
| StdReturn               | 285        |
| Time                    | 2.62e+03   |
| dLoss                   | 0.0538852  |
----------------------------------------
itr #243 | 
Mem: 745.632812
Obtaining samples...
Obtaining samples for iteration 243...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5067, #subsample_inputs: 5067
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.729      |
| AbsLearnSignalNew       | 0.729      |
| AbsLearningOld          | 0.729      |
| AverageDiscountedReturn | 102        |
| AveragePhiLoss          | 0.97413    |
| AveragePolicyStd        | 0.833928   |
| AverageReturn           | 361        |
| Entropy                 | 7.40776    |
| EnvExecTime             | 3.29       |
| ExplainedVariance       | 0.531      |
| Iteration               | 243        |
| ItrTime                 | 11.8       |
| LossAfter               | -0.817816  |
| LossBefore              | -0.776488  |
| MaxReturn               | 944        |
| MeanKL                  | 0.00642444 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 38.6       |
| NumTrajs                | 21         |
| Perplexity              | 1648.73    |
| PolicyExecTime          | 0.647      |
| ProcessExecTime         | 0.0821     |
| StdReturn               | 285        |
| Time                    | 2.63e+03   |
| dLoss                   | 0.0413277  |
----------------------------------------
itr #244 | 
Mem: 745.632812
Obtaining samples...
Obtaining samples for iteration 244...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5492, #subsample_inputs: 5492
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.475      |
| AbsLearnSignalNew       | 0.475      |
| AbsLearningOld          | 0.475      |
| AverageDiscountedReturn | 123        |
| AveragePhiLoss          | 0.966056   |
| AveragePolicyStd        | 0.832332   |
| AverageReturn           | 483        |
| Entropy                 | 7.39648    |
| EnvExecTime             | 3          |
| ExplainedVariance       | -0.39      |
| Iteration               | 244        |
| ItrTime                 | 11.8       |
| LossAfter               | -0.023859  |
| LossBefore              | 0.0468707  |
| MaxReturn               | 1.29e+03   |
| MeanKL                  | 0.00994718 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 51.2       |
| NumTrajs                | 21         |
| Perplexity              | 1630.23    |
| PolicyExecTime          | 0.575      |
| ProcessExecTime         | 0.0757     |
| StdReturn               | 319        |
| Time                    | 2.65e+03   |
| dLoss                   | 0.0707296  |
----------------------------------------
itr #245 | 
Mem: 747.976562
Obtaining samples...
Obtaining samples for iteration 245...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5226, #subsample_inputs: 5226
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.714      |
| AbsLearnSignalNew       | 0.714      |
| AbsLearningOld          | 0.714      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 0.975967   |
| AveragePolicyStd        | 0.830667   |
| AverageReturn           | 520        |
| Entropy                 | 7.38446    |
| EnvExecTime             | 3.24       |
| ExplainedVariance       | 0.554      |
| Iteration               | 245        |
| ItrTime                 | 11         |
| LossAfter               | -0.283838  |
| LossBefore              | -0.241402  |
| MaxReturn               | 1.34e+03   |
| MeanKL                  | 0.00640646 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 56.6       |
| NumTrajs                | 20         |
| Perplexity              | 1610.75    |
| PolicyExecTime          | 0.655      |
| ProcessExecTime         | 0.0848     |
| StdReturn               | 297        |
| Time                    | 2.66e+03   |
| dLoss                   | 0.0424355  |
----------------------------------------
itr #246 | 
Mem: 747.976562
Obtaining samples...
Obtaining samples for iteration 246...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5205, #subsample_inputs: 5205
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.703      |
| AbsLearnSignalNew       | 0.703      |
| AbsLearningOld          | 0.703      |
| AverageDiscountedReturn | 114        |
| AveragePhiLoss          | 0.983104   |
| AveragePolicyStd        | 0.829296   |
| AverageReturn           | 416        |
| Entropy                 | 7.37495    |
| EnvExecTime             | 3.08       |
| ExplainedVariance       | 0.469      |
| Iteration               | 246        |
| ItrTime                 | 11.6       |
| LossAfter               | -0.254353  |
| LossBefore              | -0.210582  |
| MaxReturn               | 928        |
| MeanKL                  | 0.00992608 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 43.2       |
| NumTrajs                | 21         |
| Perplexity              | 1595.51    |
| PolicyExecTime          | 0.62       |
| ProcessExecTime         | 0.0801     |
| StdReturn               | 267        |
| Time                    | 2.67e+03   |
| dLoss                   | 0.0437708  |
----------------------------------------
itr #247 | 
Mem: 748.750000
Obtaining samples...
Obtaining samples for iteration 247...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5794, #subsample_inputs: 5794
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.412      |
| AbsLearnSignalNew       | 0.412      |
| AbsLearningOld          | 0.412      |
| AverageDiscountedReturn | 116        |
| AveragePhiLoss          | 0.968234   |
| AveragePolicyStd        | 0.831734   |
| AverageReturn           | 516        |
| Entropy                 | 7.39427    |
| EnvExecTime             | 3.28       |
| ExplainedVariance       | -5.12      |
| Iteration               | 247        |
| ItrTime                 | 11.7       |
| LossAfter               | 0.176425   |
| LossBefore              | 0.221709   |
| MaxReturn               | 2.07e+03   |
| MeanKL                  | 0.00651723 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 48.7       |
| NumTrajs                | 20         |
| Perplexity              | 1626.64    |
| PolicyExecTime          | 0.645      |
| ProcessExecTime         | 0.0834     |
| StdReturn               | 503        |
| Time                    | 2.68e+03   |
| dLoss                   | 0.0452837  |
----------------------------------------
itr #248 | 
Mem: 748.750000
Obtaining samples...
Obtaining samples for iteration 248...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5220, #subsample_inputs: 5220
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.696      |
| AbsLearnSignalNew       | 0.696      |
| AbsLearningOld          | 0.696      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 0.972284   |
| AveragePolicyStd        | 0.831111   |
| AverageReturn           | 544        |
| Entropy                 | 7.3896     |
| EnvExecTime             | 3.18       |
| ExplainedVariance       | 0.484      |
| Iteration               | 248        |
| ItrTime                 | 11.1       |
| LossAfter               | -0.141698  |
| LossBefore              | -0.0873532 |
| MaxReturn               | 974        |
| MeanKL                  | 0.00643243 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 51.6       |
| NumTrajs                | 18         |
| Perplexity              | 1619.06    |
| PolicyExecTime          | 0.635      |
| ProcessExecTime         | 0.0823     |
| StdReturn               | 233        |
| Time                    | 2.69e+03   |
| dLoss                   | 0.0543452  |
----------------------------------------
itr #249 | 
Mem: 748.750000
Obtaining samples...
Obtaining samples for iteration 249...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5334, #subsample_inputs: 5334
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.667      |
| AbsLearnSignalNew       | 0.667      |
| AbsLearningOld          | 0.667      |
| AverageDiscountedReturn | 117        |
| AveragePhiLoss          | 0.975044   |
| AveragePolicyStd        | 0.829726   |
| AverageReturn           | 469        |
| Entropy                 | 7.37879    |
| EnvExecTime             | 2.86       |
| ExplainedVariance       | 0.517      |
| Iteration               | 249        |
| ItrTime                 | 11.3       |
| LossAfter               | -0.106385  |
| LossBefore              | -0.0484673 |
| MaxReturn               | 1.1e+03    |
| MeanKL                  | 0.00991821 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 64.7       |
| NumTrajs                | 20         |
| Perplexity              | 1601.65    |
| PolicyExecTime          | 0.559      |
| ProcessExecTime         | 0.074      |
| StdReturn               | 289        |
| Time                    | 2.7e+03    |
| dLoss                   | 0.0579176  |
----------------------------------------
itr #250 | 
Mem: 748.750000
Obtaining samples...
Obtaining samples for iteration 250...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5139, #subsample_inputs: 5139
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.737      |
| AbsLearnSignalNew       | 0.737      |
| AbsLearningOld          | 0.737      |
| AverageDiscountedReturn | 124        |
| AveragePhiLoss          | 0.978654   |
| AveragePolicyStd        | 0.82836    |
| AverageReturn           | 587        |
| Entropy                 | 7.36961    |
| EnvExecTime             | 3.25       |
| ExplainedVariance       | 0.375      |
| Iteration               | 250        |
| ItrTime                 | 10.7       |
| LossAfter               | -0.264578  |
| LossBefore              | -0.214279  |
| MaxReturn               | 1.22e+03   |
| MeanKL                  | 0.00994317 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 54.4       |
| NumTrajs                | 17         |
| Perplexity              | 1587.02    |
| PolicyExecTime          | 0.652      |
| ProcessExecTime         | 0.0848     |
| StdReturn               | 367        |
| Time                    | 2.71e+03   |
| dLoss                   | 0.0502988  |
----------------------------------------
itr #251 | 
Mem: 748.750000
Obtaining samples...
Obtaining samples for iteration 251...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5204, #subsample_inputs: 5204
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.704      |
| AbsLearnSignalNew       | 0.704      |
| AbsLearningOld          | 0.704      |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 0.967398   |
| AveragePolicyStd        | 0.826814   |
| AverageReturn           | 606        |
| Entropy                 | 7.35873    |
| EnvExecTime             | 3.27       |
| ExplainedVariance       | 0.446      |
| Iteration               | 251        |
| ItrTime                 | 11.6       |
| LossAfter               | -0.022296  |
| LossBefore              | 0.0326417  |
| MaxReturn               | 1.64e+03   |
| MeanKL                  | 0.00994559 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 67.1       |
| NumTrajs                | 17         |
| Perplexity              | 1569.85    |
| PolicyExecTime          | 0.667      |
| ProcessExecTime         | 0.0849     |
| StdReturn               | 363        |
| Time                    | 2.72e+03   |
| dLoss                   | 0.0549378  |
----------------------------------------
itr #252 | 
Mem: 748.750000
Obtaining samples...
Obtaining samples for iteration 252...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5143, #subsample_inputs: 5143
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.715      |
| AbsLearnSignalNew       | 0.715      |
| AbsLearningOld          | 0.715      |
| AverageDiscountedReturn | 124        |
| AveragePhiLoss          | 0.972502   |
| AveragePolicyStd        | 0.825509   |
| AverageReturn           | 590        |
| Entropy                 | 7.3494     |
| EnvExecTime             | 2.62       |
| ExplainedVariance       | 0.36       |
| Iteration               | 252        |
| ItrTime                 | 10.8       |
| LossAfter               | -0.163144  |
| LossBefore              | -0.108372  |
| MaxReturn               | 1.3e+03    |
| MeanKL                  | 0.00979836 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 93.1       |
| NumTrajs                | 15         |
| Perplexity              | 1555.26    |
| PolicyExecTime          | 0.485      |
| ProcessExecTime         | 0.0659     |
| StdReturn               | 369        |
| Time                    | 2.74e+03   |
| dLoss                   | 0.0547721  |
----------------------------------------
itr #253 | 
Mem: 748.750000
Obtaining samples...
Obtaining samples for iteration 253...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5147, #subsample_inputs: 5147
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.679      |
| AbsLearnSignalNew       | 0.679      |
| AbsLearningOld          | 0.679      |
| AverageDiscountedReturn | 101        |
| AveragePhiLoss          | 0.966506   |
| AveragePolicyStd        | 0.828137   |
| AverageReturn           | 453        |
| Entropy                 | 7.36767    |
| EnvExecTime             | 3.2        |
| ExplainedVariance       | 0.462      |
| Iteration               | 253        |
| ItrTime                 | 10.4       |
| LossAfter               | -0.655474  |
| LossBefore              | -0.598465  |
| MaxReturn               | 1.73e+03   |
| MeanKL                  | 0.00983737 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 49.4       |
| NumTrajs                | 18         |
| Perplexity              | 1583.94    |
| PolicyExecTime          | 0.614      |
| ProcessExecTime         | 0.0812     |
| StdReturn               | 472        |
| Time                    | 2.75e+03   |
| dLoss                   | 0.0570087  |
----------------------------------------
itr #254 | 
Mem: 748.750000
Obtaining samples...
Obtaining samples for iteration 254...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5342, #subsample_inputs: 5342
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.741     |
| AbsLearnSignalNew       | 0.741     |
| AbsLearningOld          | 0.741     |
| AverageDiscountedReturn | 117       |
| AveragePhiLoss          | 0.98008   |
| AveragePolicyStd        | 0.829931  |
| AverageReturn           | 530       |
| Entropy                 | 7.38194   |
| EnvExecTime             | 3.36      |
| ExplainedVariance       | 0.493     |
| Iteration               | 254       |
| ItrTime                 | 12.3      |
| LossAfter               | 0.19017   |
| LossBefore              | 0.2477    |
| MaxReturn               | 1.16e+03  |
| MeanKL                  | 0.0099296 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 74.4      |
| NumTrajs                | 18        |
| Perplexity              | 1606.71   |
| PolicyExecTime          | 0.658     |
| ProcessExecTime         | 0.0855    |
| StdReturn               | 370       |
| Time                    | 2.76e+03  |
| dLoss                   | 0.0575298 |
---------------------------------------
itr #255 | 
Mem: 748.750000
Obtaining samples...
Obtaining samples for iteration 255...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5195, #subsample_inputs: 5195
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.706      |
| AbsLearnSignalNew       | 0.706      |
| AbsLearningOld          | 0.706      |
| AverageDiscountedReturn | 114        |
| AveragePhiLoss          | 0.985797   |
| AveragePolicyStd        | 0.829461   |
| AverageReturn           | 546        |
| Entropy                 | 7.37812    |
| EnvExecTime             | 2.8        |
| ExplainedVariance       | 0.457      |
| Iteration               | 255        |
| ItrTime                 | 10.9       |
| LossAfter               | -0.73777   |
| LossBefore              | -0.690659  |
| MaxReturn               | 1.47e+03   |
| MeanKL                  | 0.00998496 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 41.5       |
| NumTrajs                | 17         |
| Perplexity              | 1600.58    |
| PolicyExecTime          | 0.522      |
| ProcessExecTime         | 0.068      |
| StdReturn               | 345        |
| Time                    | 2.77e+03   |
| dLoss                   | 0.0471109  |
----------------------------------------
itr #256 | 
Mem: 748.750000
Obtaining samples...
Obtaining samples for iteration 256...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5176, #subsample_inputs: 5176
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.708      |
| AbsLearnSignalNew       | 0.708      |
| AbsLearningOld          | 0.708      |
| AverageDiscountedReturn | 118        |
| AveragePhiLoss          | 0.971488   |
| AveragePolicyStd        | 0.830388   |
| AverageReturn           | 484        |
| Entropy                 | 7.38292    |
| EnvExecTime             | 3.24       |
| ExplainedVariance       | 0.521      |
| Iteration               | 256        |
| ItrTime                 | 10.8       |
| LossAfter               | -0.15682   |
| LossBefore              | -0.111576  |
| MaxReturn               | 1.5e+03    |
| MeanKL                  | 0.00643799 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 51.7       |
| NumTrajs                | 19         |
| Perplexity              | 1608.28    |
| PolicyExecTime          | 0.646      |
| ProcessExecTime         | 0.084      |
| StdReturn               | 352        |
| Time                    | 2.78e+03   |
| dLoss                   | 0.0452435  |
----------------------------------------
itr #257 | 
Mem: 748.750000
Obtaining samples...
Obtaining samples for iteration 257...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5451, #subsample_inputs: 5451
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.734     |
| AbsLearnSignalNew       | 0.734     |
| AbsLearningOld          | 0.734     |
| AverageDiscountedReturn | 127       |
| AveragePhiLoss          | 0.976973  |
| AveragePolicyStd        | 0.828971  |
| AverageReturn           | 722       |
| Entropy                 | 7.37308   |
| EnvExecTime             | 3.07      |
| ExplainedVariance       | 0.403     |
| Iteration               | 257       |
| ItrTime                 | 12        |
| LossAfter               | 0.318438  |
| LossBefore              | 0.356114  |
| MaxReturn               | 1.56e+03  |
| MeanKL                  | 0.0064222 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 62.8      |
| NumTrajs                | 15        |
| Perplexity              | 1592.53   |
| PolicyExecTime          | 0.629     |
| ProcessExecTime         | 0.0818    |
| StdReturn               | 447       |
| Time                    | 2.79e+03  |
| dLoss                   | 0.0376769 |
---------------------------------------
itr #258 | 
Mem: 748.750000
Obtaining samples...
Obtaining samples for iteration 258...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5127, #subsample_inputs: 5127
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.684      |
| AbsLearnSignalNew       | 0.684      |
| AbsLearningOld          | 0.684      |
| AverageDiscountedReturn | 119        |
| AveragePhiLoss          | 0.965988   |
| AveragePolicyStd        | 0.827403   |
| AverageReturn           | 737        |
| Entropy                 | 7.36243    |
| EnvExecTime             | 2.92       |
| ExplainedVariance       | 0.418      |
| Iteration               | 258        |
| ItrTime                 | 10.4       |
| LossAfter               | -0.234956  |
| LossBefore              | -0.188972  |
| MaxReturn               | 1.9e+03    |
| MeanKL                  | 0.00642664 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 48.6       |
| NumTrajs                | 14         |
| Perplexity              | 1575.66    |
| PolicyExecTime          | 0.577      |
| ProcessExecTime         | 0.0734     |
| StdReturn               | 574        |
| Time                    | 2.8e+03    |
| dLoss                   | 0.0459837  |
----------------------------------------
itr #259 | 
Mem: 748.750000
Obtaining samples...
Obtaining samples for iteration 259...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5481, #subsample_inputs: 5481
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.603      |
| AbsLearnSignalNew       | 0.603      |
| AbsLearningOld          | 0.603      |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 0.98191    |
| AveragePolicyStd        | 0.82813    |
| AverageReturn           | 740        |
| Entropy                 | 7.36697    |
| EnvExecTime             | 3.81       |
| ExplainedVariance       | 0.529      |
| Iteration               | 259        |
| ItrTime                 | 12.5       |
| LossAfter               | -1.19785   |
| LossBefore              | -1.15469   |
| MaxReturn               | 1.41e+03   |
| MeanKL                  | 0.00643162 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 65.3       |
| NumTrajs                | 16         |
| Perplexity              | 1582.83    |
| PolicyExecTime          | 0.782      |
| ProcessExecTime         | 0.0956     |
| StdReturn               | 389        |
| Time                    | 2.82e+03   |
| dLoss                   | 0.0431597  |
----------------------------------------
itr #260 | 
Mem: 748.750000
Obtaining samples...
Obtaining samples for iteration 260...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5011, #subsample_inputs: 5011
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.705      |
| AbsLearnSignalNew       | 0.705      |
| AbsLearningOld          | 0.705      |
| AverageDiscountedReturn | 119        |
| AveragePhiLoss          | 0.973575   |
| AveragePolicyStd        | 0.82771    |
| AverageReturn           | 579        |
| Entropy                 | 7.36493    |
| EnvExecTime             | 3.19       |
| ExplainedVariance       | 0.546      |
| Iteration               | 260        |
| ItrTime                 | 11.4       |
| LossAfter               | -0.37871   |
| LossBefore              | -0.324677  |
| MaxReturn               | 1.2e+03    |
| MeanKL                  | 0.00991874 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 53.8       |
| NumTrajs                | 16         |
| Perplexity              | 1579.6     |
| PolicyExecTime          | 0.628      |
| ProcessExecTime         | 0.0773     |
| StdReturn               | 351        |
| Time                    | 2.83e+03   |
| dLoss                   | 0.0540324  |
----------------------------------------
itr #261 | 
Mem: 748.750000
Obtaining samples...
Obtaining samples for iteration 261...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5130, #subsample_inputs: 5130
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.541      |
| AbsLearnSignalNew       | 0.541      |
| AbsLearningOld          | 0.541      |
| AverageDiscountedReturn | 109        |
| AveragePhiLoss          | 0.971167   |
| AveragePolicyStd        | 0.828116   |
| AverageReturn           | 787        |
| Entropy                 | 7.36858    |
| EnvExecTime             | 3.27       |
| ExplainedVariance       | -0.607     |
| Iteration               | 261        |
| ItrTime                 | 10.5       |
| LossAfter               | -0.255133  |
| LossBefore              | -0.214018  |
| MaxReturn               | 2.19e+03   |
| MeanKL                  | 0.00650404 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 43.5       |
| NumTrajs                | 12         |
| Perplexity              | 1585.38    |
| PolicyExecTime          | 0.665      |
| ProcessExecTime         | 0.0859     |
| StdReturn               | 694        |
| Time                    | 2.84e+03   |
| dLoss                   | 0.0411156  |
----------------------------------------
itr #262 | 
Mem: 748.750000
Obtaining samples...
Obtaining samples for iteration 262...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5344, #subsample_inputs: 5344
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.671      |
| AbsLearnSignalNew       | 0.671      |
| AbsLearningOld          | 0.671      |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 0.967758   |
| AveragePolicyStd        | 0.824864   |
| AverageReturn           | 569        |
| Entropy                 | 7.34594    |
| EnvExecTime             | 3.35       |
| ExplainedVariance       | 0.271      |
| Iteration               | 262        |
| ItrTime                 | 11.9       |
| LossAfter               | 0.246784   |
| LossBefore              | 0.301811   |
| MaxReturn               | 1.38e+03   |
| MeanKL                  | 0.00999519 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 36.1       |
| NumTrajs                | 18         |
| Perplexity              | 1549.89    |
| PolicyExecTime          | 0.672      |
| ProcessExecTime         | 0.0893     |
| StdReturn               | 404        |
| Time                    | 2.85e+03   |
| dLoss                   | 0.0550264  |
----------------------------------------
itr #263 | 
Mem: 748.750000
Obtaining samples...
Obtaining samples for iteration 263...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5627, #subsample_inputs: 5627
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.429      |
| AbsLearnSignalNew       | 0.429      |
| AbsLearningOld          | 0.429      |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 0.955778   |
| AveragePolicyStd        | 0.823462   |
| AverageReturn           | 595        |
| Entropy                 | 7.33584    |
| EnvExecTime             | 3.4        |
| ExplainedVariance       | -1.82      |
| Iteration               | 263        |
| ItrTime                 | 12.4       |
| LossAfter               | -0.334834  |
| LossBefore              | -0.270828  |
| MaxReturn               | 1.72e+03   |
| MeanKL                  | 0.00992825 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 44.2       |
| NumTrajs                | 17         |
| Perplexity              | 1534.32    |
| PolicyExecTime          | 0.651      |
| ProcessExecTime         | 0.0806     |
| StdReturn               | 409        |
| Time                    | 2.86e+03   |
| dLoss                   | 0.0640069  |
----------------------------------------
itr #264 | 
Mem: 753.472656
Obtaining samples...
Obtaining samples for iteration 264...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5341, #subsample_inputs: 5341
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.71       |
| AbsLearnSignalNew       | 0.71       |
| AbsLearningOld          | 0.71       |
| AverageDiscountedReturn | 106        |
| AveragePhiLoss          | 0.98403    |
| AveragePolicyStd        | 0.822953   |
| AverageReturn           | 606        |
| Entropy                 | 7.33243    |
| EnvExecTime             | 3.1        |
| ExplainedVariance       | 0.547      |
| Iteration               | 264        |
| ItrTime                 | 10.5       |
| LossAfter               | -0.180033  |
| LossBefore              | -0.136553  |
| MaxReturn               | 1.6e+03    |
| MeanKL                  | 0.00643783 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 33.3       |
| NumTrajs                | 16         |
| Perplexity              | 1529.09    |
| PolicyExecTime          | 0.621      |
| ProcessExecTime         | 0.0842     |
| StdReturn               | 477        |
| Time                    | 2.87e+03   |
| dLoss                   | 0.0434801  |
----------------------------------------
itr #265 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 265...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5105, #subsample_inputs: 5105
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.738      |
| AbsLearnSignalNew       | 0.738      |
| AbsLearningOld          | 0.738      |
| AverageDiscountedReturn | 109        |
| AveragePhiLoss          | 0.97612    |
| AveragePolicyStd        | 0.820886   |
| AverageReturn           | 479        |
| Entropy                 | 7.31843    |
| EnvExecTime             | 3.03       |
| ExplainedVariance       | 0.553      |
| Iteration               | 265        |
| ItrTime                 | 11.5       |
| LossAfter               | -0.197009  |
| LossBefore              | -0.146805  |
| MaxReturn               | 1.58e+03   |
| MeanKL                  | 0.00992094 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 25.2       |
| NumTrajs                | 18         |
| Perplexity              | 1507.84    |
| PolicyExecTime          | 0.595      |
| ProcessExecTime         | 0.0793     |
| StdReturn               | 431        |
| Time                    | 2.88e+03   |
| dLoss                   | 0.0502036  |
----------------------------------------
itr #266 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 266...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5547, #subsample_inputs: 5547
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.622      |
| AbsLearnSignalNew       | 0.622      |
| AbsLearningOld          | 0.622      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 0.960847   |
| AveragePolicyStd        | 0.820689   |
| AverageReturn           | 903        |
| Entropy                 | 7.3174     |
| EnvExecTime             | 2.91       |
| ExplainedVariance       | -0.61      |
| Iteration               | 266        |
| ItrTime                 | 11.7       |
| LossAfter               | 0.874542   |
| LossBefore              | 0.926371   |
| MaxReturn               | 2.25e+03   |
| MeanKL                  | 0.00642268 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 81.1       |
| NumTrajs                | 12         |
| Perplexity              | 1506.28    |
| PolicyExecTime          | 0.563      |
| ProcessExecTime         | 0.073      |
| StdReturn               | 569        |
| Time                    | 2.9e+03    |
| dLoss                   | 0.0518288  |
----------------------------------------
itr #267 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 267...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5074, #subsample_inputs: 5074
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.627      |
| AbsLearnSignalNew       | 0.627      |
| AbsLearningOld          | 0.627      |
| AverageDiscountedReturn | 133        |
| AveragePhiLoss          | 0.973638   |
| AveragePolicyStd        | 0.819932   |
| AverageReturn           | 719        |
| Entropy                 | 7.31239    |
| EnvExecTime             | 3.22       |
| ExplainedVariance       | 0.23       |
| Iteration               | 267        |
| ItrTime                 | 10.2       |
| LossAfter               | 0.564386   |
| LossBefore              | 0.611805   |
| MaxReturn               | 2.19e+03   |
| MeanKL                  | 0.00642751 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 48.1       |
| NumTrajs                | 14         |
| Perplexity              | 1498.76    |
| PolicyExecTime          | 0.66       |
| ProcessExecTime         | 0.0864     |
| StdReturn               | 605        |
| Time                    | 2.91e+03   |
| dLoss                   | 0.047419   |
----------------------------------------
itr #268 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 268...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5388, #subsample_inputs: 5388
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.733      |
| AbsLearnSignalNew       | 0.733      |
| AbsLearningOld          | 0.733      |
| AverageDiscountedReturn | 116        |
| AveragePhiLoss          | 0.973537   |
| AveragePolicyStd        | 0.822132   |
| AverageReturn           | 501        |
| Entropy                 | 7.32754    |
| EnvExecTime             | 3.34       |
| ExplainedVariance       | 0.451      |
| Iteration               | 268        |
| ItrTime                 | 12.2       |
| LossAfter               | 0.180758   |
| LossBefore              | 0.22325    |
| MaxReturn               | 1.36e+03   |
| MeanKL                  | 0.00651132 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 64.2       |
| NumTrajs                | 20         |
| Perplexity              | 1521.64    |
| PolicyExecTime          | 0.66       |
| ProcessExecTime         | 0.0869     |
| StdReturn               | 392        |
| Time                    | 2.92e+03   |
| dLoss                   | 0.0424925  |
----------------------------------------
itr #269 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 269...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5172, #subsample_inputs: 5172
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.614      |
| AbsLearnSignalNew       | 0.614      |
| AbsLearningOld          | 0.614      |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 0.962758   |
| AveragePolicyStd        | 0.820727   |
| AverageReturn           | 609        |
| Entropy                 | 7.31728    |
| EnvExecTime             | 3.18       |
| ExplainedVariance       | 0.305      |
| Iteration               | 269        |
| ItrTime                 | 10.9       |
| LossAfter               | -0.378508  |
| LossBefore              | -0.316209  |
| MaxReturn               | 1.77e+03   |
| MeanKL                  | 0.00994773 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 56.9       |
| NumTrajs                | 17         |
| Perplexity              | 1506.1     |
| PolicyExecTime          | 0.607      |
| ProcessExecTime         | 0.0769     |
| StdReturn               | 459        |
| Time                    | 2.93e+03   |
| dLoss                   | 0.0622983  |
----------------------------------------
itr #270 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 270...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5101, #subsample_inputs: 5101
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.707      |
| AbsLearnSignalNew       | 0.707      |
| AbsLearningOld          | 0.707      |
| AverageDiscountedReturn | 119        |
| AveragePhiLoss          | 0.983821   |
| AveragePolicyStd        | 0.81841    |
| AverageReturn           | 571        |
| Entropy                 | 7.30066    |
| EnvExecTime             | 3.24       |
| ExplainedVariance       | 0.312      |
| Iteration               | 270        |
| ItrTime                 | 11.1       |
| LossAfter               | 0.232581   |
| LossBefore              | 0.280607   |
| MaxReturn               | 2.23e+03   |
| MeanKL                  | 0.00973011 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 72.2       |
| NumTrajs                | 15         |
| Perplexity              | 1481.28    |
| PolicyExecTime          | 0.658      |
| ProcessExecTime         | 0.0848     |
| StdReturn               | 492        |
| Time                    | 2.94e+03   |
| dLoss                   | 0.0480256  |
----------------------------------------
itr #271 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 271...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5052, #subsample_inputs: 5052
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.739      |
| AbsLearnSignalNew       | 0.739      |
| AbsLearningOld          | 0.738      |
| AverageDiscountedReturn | 117        |
| AveragePhiLoss          | 0.974215   |
| AveragePolicyStd        | 0.819631   |
| AverageReturn           | 711        |
| Entropy                 | 7.30935    |
| EnvExecTime             | 2.8        |
| ExplainedVariance       | 0.511      |
| Iteration               | 271        |
| ItrTime                 | 11.2       |
| LossAfter               | 1.1521     |
| LossBefore              | 1.20934    |
| MaxReturn               | 2.1e+03    |
| MeanKL                  | 0.00981334 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 44.3       |
| NumTrajs                | 13         |
| Perplexity              | 1494.2     |
| PolicyExecTime          | 0.549      |
| ProcessExecTime         | 0.0714     |
| StdReturn               | 584        |
| Time                    | 2.95e+03   |
| dLoss                   | 0.05724    |
----------------------------------------
itr #272 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 272...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5328, #subsample_inputs: 5328
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.718     |
| AbsLearnSignalNew       | 0.718     |
| AbsLearningOld          | 0.718     |
| AverageDiscountedReturn | 130       |
| AveragePhiLoss          | 0.980572  |
| AveragePolicyStd        | 0.822203  |
| AverageReturn           | 673       |
| Entropy                 | 7.3284    |
| EnvExecTime             | 3.33      |
| ExplainedVariance       | 0.551     |
| Iteration               | 272       |
| ItrTime                 | 11        |
| LossAfter               | 1.05961   |
| LossBefore              | 1.11167   |
| MaxReturn               | 1.45e+03  |
| MeanKL                  | 0.0099528 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 58.3      |
| NumTrajs                | 17        |
| Perplexity              | 1522.95   |
| PolicyExecTime          | 0.668     |
| ProcessExecTime         | 0.0884    |
| StdReturn               | 386       |
| Time                    | 2.96e+03  |
| dLoss                   | 0.0520663 |
---------------------------------------
itr #273 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 273...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5167, #subsample_inputs: 5167
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.736      |
| AbsLearnSignalNew       | 0.736      |
| AbsLearningOld          | 0.736      |
| AverageDiscountedReturn | 133        |
| AveragePhiLoss          | 0.9719     |
| AveragePolicyStd        | 0.822131   |
| AverageReturn           | 719        |
| Entropy                 | 7.32804    |
| EnvExecTime             | 2.94       |
| ExplainedVariance       | 0.31       |
| Iteration               | 273        |
| ItrTime                 | 11.4       |
| LossAfter               | 0.402274   |
| LossBefore              | 0.455084   |
| MaxReturn               | 1.53e+03   |
| MeanKL                  | 0.00982511 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 110        |
| NumTrajs                | 14         |
| Perplexity              | 1522.39    |
| PolicyExecTime          | 0.596      |
| ProcessExecTime         | 0.0808     |
| StdReturn               | 356        |
| Time                    | 2.98e+03   |
| dLoss                   | 0.0528096  |
----------------------------------------
itr #274 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 274...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5876, #subsample_inputs: 5876
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.629      |
| AbsLearnSignalNew       | 0.629      |
| AbsLearningOld          | 0.629      |
| AverageDiscountedReturn | 112        |
| AveragePhiLoss          | 0.979331   |
| AveragePolicyStd        | 0.822704   |
| AverageReturn           | 519        |
| Entropy                 | 7.33388    |
| EnvExecTime             | 3.48       |
| ExplainedVariance       | 0.352      |
| Iteration               | 274        |
| ItrTime                 | 13         |
| LossAfter               | 0.0353304  |
| LossBefore              | 0.0975236  |
| MaxReturn               | 2.05e+03   |
| MeanKL                  | 0.00979151 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 54         |
| NumTrajs                | 20         |
| Perplexity              | 1531.31    |
| PolicyExecTime          | 0.637      |
| ProcessExecTime         | 0.0816     |
| StdReturn               | 504        |
| Time                    | 2.99e+03   |
| dLoss                   | 0.0621932  |
----------------------------------------
itr #275 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 275...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5471, #subsample_inputs: 5471
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.702      |
| AbsLearnSignalNew       | 0.702      |
| AbsLearningOld          | 0.702      |
| AverageDiscountedReturn | 124        |
| AveragePhiLoss          | 0.982095   |
| AveragePolicyStd        | 0.825647   |
| AverageReturn           | 691        |
| Entropy                 | 7.35486    |
| EnvExecTime             | 3.2        |
| ExplainedVariance       | 0.396      |
| Iteration               | 275        |
| ItrTime                 | 10.6       |
| LossAfter               | 0.546646   |
| LossBefore              | 0.59741    |
| MaxReturn               | 1.34e+03   |
| MeanKL                  | 0.00981249 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 38.7       |
| NumTrajs                | 16         |
| Perplexity              | 1563.78    |
| PolicyExecTime          | 0.639      |
| ProcessExecTime         | 0.0846     |
| StdReturn               | 380        |
| Time                    | 3e+03      |
| dLoss                   | 0.0507646  |
----------------------------------------
itr #276 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 276...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5111, #subsample_inputs: 5111
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.703      |
| AbsLearnSignalNew       | 0.703      |
| AbsLearningOld          | 0.703      |
| AverageDiscountedReturn | 101        |
| AveragePhiLoss          | 0.97516    |
| AveragePolicyStd        | 0.827444   |
| AverageReturn           | 373        |
| Entropy                 | 7.36969    |
| EnvExecTime             | 3.61       |
| ExplainedVariance       | 0.343      |
| Iteration               | 276        |
| ItrTime                 | 12         |
| LossAfter               | 0.601848   |
| LossBefore              | 0.65082    |
| MaxReturn               | 931        |
| MeanKL                  | 0.00990563 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 48.1       |
| NumTrajs                | 18         |
| Perplexity              | 1587.14    |
| PolicyExecTime          | 0.724      |
| ProcessExecTime         | 0.089      |
| StdReturn               | 288        |
| Time                    | 3.01e+03   |
| dLoss                   | 0.0489723  |
----------------------------------------
itr #277 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 277...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5031, #subsample_inputs: 5031
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.671      |
| AbsLearnSignalNew       | 0.671      |
| AbsLearningOld          | 0.671      |
| AverageDiscountedReturn | 105        |
| AveragePhiLoss          | 0.970204   |
| AveragePolicyStd        | 0.827899   |
| AverageReturn           | 587        |
| Entropy                 | 7.37338    |
| EnvExecTime             | 2.87       |
| ExplainedVariance       | 0.336      |
| Iteration               | 277        |
| ItrTime                 | 11.3       |
| LossAfter               | 0.606565   |
| LossBefore              | 0.657286   |
| MaxReturn               | 1.24e+03   |
| MeanKL                  | 0.00641113 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 35.9       |
| NumTrajs                | 14         |
| Perplexity              | 1593.01    |
| PolicyExecTime          | 0.519      |
| ProcessExecTime         | 0.0689     |
| StdReturn               | 424        |
| Time                    | 3.02e+03   |
| dLoss                   | 0.0507213  |
----------------------------------------
itr #278 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 278...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5220, #subsample_inputs: 5220
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.73       |
| AbsLearnSignalNew       | 0.73       |
| AbsLearningOld          | 0.73       |
| AverageDiscountedReturn | 107        |
| AveragePhiLoss          | 0.980757   |
| AveragePolicyStd        | 0.827071   |
| AverageReturn           | 514        |
| Entropy                 | 7.36771    |
| EnvExecTime             | 3.3        |
| ExplainedVariance       | 0.541      |
| Iteration               | 278        |
| ItrTime                 | 10.6       |
| LossAfter               | -0.0277948 |
| LossBefore              | 0.0210772  |
| MaxReturn               | 1.36e+03   |
| MeanKL                  | 0.00987203 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 38.5       |
| NumTrajs                | 16         |
| Perplexity              | 1584.0     |
| PolicyExecTime          | 0.651      |
| ProcessExecTime         | 0.0834     |
| StdReturn               | 451        |
| Time                    | 3.03e+03   |
| dLoss                   | 0.048872   |
----------------------------------------
itr #279 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 279...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5872, #subsample_inputs: 5872
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.53       |
| AbsLearnSignalNew       | 0.53       |
| AbsLearningOld          | 0.53       |
| AverageDiscountedReturn | 117        |
| AveragePhiLoss          | 0.977811   |
| AveragePolicyStd        | 0.826004   |
| AverageReturn           | 566        |
| Entropy                 | 7.36036    |
| EnvExecTime             | 3.63       |
| ExplainedVariance       | 0.226      |
| Iteration               | 279        |
| ItrTime                 | 13.1       |
| LossAfter               | 0.11137    |
| LossBefore              | 0.163862   |
| MaxReturn               | 1.87e+03   |
| MeanKL                  | 0.00990022 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 44.3       |
| NumTrajs                | 19         |
| Perplexity              | 1572.4     |
| PolicyExecTime          | 0.734      |
| ProcessExecTime         | 0.0975     |
| StdReturn               | 496        |
| Time                    | 3.05e+03   |
| dLoss                   | 0.0524915  |
----------------------------------------
itr #280 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 280...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5341, #subsample_inputs: 5341
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.729      |
| AbsLearnSignalNew       | 0.729      |
| AbsLearningOld          | 0.729      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 0.971476   |
| AveragePolicyStd        | 0.822394   |
| AverageReturn           | 593        |
| Entropy                 | 7.33417    |
| EnvExecTime             | 3.11       |
| ExplainedVariance       | 0.366      |
| Iteration               | 280        |
| ItrTime                 | 11.9       |
| LossAfter               | 0.323024   |
| LossBefore              | 0.364497   |
| MaxReturn               | 1.18e+03   |
| MeanKL                  | 0.00644339 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 53.8       |
| NumTrajs                | 15         |
| Perplexity              | 1531.76    |
| PolicyExecTime          | 0.582      |
| ProcessExecTime         | 0.0756     |
| StdReturn               | 339        |
| Time                    | 3.06e+03   |
| dLoss                   | 0.0414731  |
----------------------------------------
itr #281 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 281...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5160, #subsample_inputs: 5160
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.729      |
| AbsLearnSignalNew       | 0.729      |
| AbsLearningOld          | 0.729      |
| AverageDiscountedReturn | 123        |
| AveragePhiLoss          | 0.97411    |
| AveragePolicyStd        | 0.822664   |
| AverageReturn           | 547        |
| Entropy                 | 7.33598    |
| EnvExecTime             | 3.38       |
| ExplainedVariance       | 0.501      |
| Iteration               | 281        |
| ItrTime                 | 10.5       |
| LossAfter               | 0.132447   |
| LossBefore              | 0.187559   |
| MaxReturn               | 1.26e+03   |
| MeanKL                  | 0.00995243 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 81.8       |
| NumTrajs                | 16         |
| Perplexity              | 1534.53    |
| PolicyExecTime          | 0.667      |
| ProcessExecTime         | 0.0876     |
| StdReturn               | 382        |
| Time                    | 3.07e+03   |
| dLoss                   | 0.0551119  |
----------------------------------------
itr #282 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 282...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5155, #subsample_inputs: 5155
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.761      |
| AbsLearnSignalNew       | 0.761      |
| AbsLearningOld          | 0.761      |
| AverageDiscountedReturn | 100        |
| AveragePhiLoss          | 0.975212   |
| AveragePolicyStd        | 0.823965   |
| AverageReturn           | 475        |
| Entropy                 | 7.34568    |
| EnvExecTime             | 3.35       |
| ExplainedVariance       | 0.549      |
| Iteration               | 282        |
| ItrTime                 | 11.7       |
| LossAfter               | 0.112112   |
| LossBefore              | 0.165431   |
| MaxReturn               | 1.41e+03   |
| MeanKL                  | 0.00987118 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 49.9       |
| NumTrajs                | 18         |
| Perplexity              | 1549.49    |
| PolicyExecTime          | 0.667      |
| ProcessExecTime         | 0.0876     |
| StdReturn               | 454        |
| Time                    | 3.08e+03   |
| dLoss                   | 0.053319   |
----------------------------------------
itr #283 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 283...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5068, #subsample_inputs: 5068
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.721      |
| AbsLearnSignalNew       | 0.721      |
| AbsLearningOld          | 0.721      |
| AverageDiscountedReturn | 111        |
| AveragePhiLoss          | 0.969476   |
| AveragePolicyStd        | 0.828387   |
| AverageReturn           | 403        |
| Entropy                 | 7.37886    |
| EnvExecTime             | 2.92       |
| ExplainedVariance       | 0.362      |
| Iteration               | 283        |
| ItrTime                 | 11         |
| LossAfter               | 0.651771   |
| LossBefore              | 0.710233   |
| MaxReturn               | 754        |
| MeanKL                  | 0.00985709 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 38.1       |
| NumTrajs                | 20         |
| Perplexity              | 1601.76    |
| PolicyExecTime          | 0.528      |
| ProcessExecTime         | 0.0711     |
| StdReturn               | 262        |
| Time                    | 3.09e+03   |
| dLoss                   | 0.0584611  |
----------------------------------------
itr #284 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 284...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5201, #subsample_inputs: 5201
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.753      |
| AbsLearnSignalNew       | 0.753      |
| AbsLearningOld          | 0.753      |
| AverageDiscountedReturn | 106        |
| AveragePhiLoss          | 0.980168   |
| AveragePolicyStd        | 0.828865   |
| AverageReturn           | 476        |
| Entropy                 | 7.38317    |
| EnvExecTime             | 3.21       |
| ExplainedVariance       | 0.54       |
| Iteration               | 284        |
| ItrTime                 | 10.8       |
| LossAfter               | -0.849698  |
| LossBefore              | -0.807061  |
| MaxReturn               | 1.15e+03   |
| MeanKL                  | 0.00642745 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 40.3       |
| NumTrajs                | 18         |
| Perplexity              | 1608.68    |
| PolicyExecTime          | 0.629      |
| ProcessExecTime         | 0.0818     |
| StdReturn               | 382        |
| Time                    | 3.1e+03    |
| dLoss                   | 0.0426368  |
----------------------------------------
itr #285 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 285...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5199, #subsample_inputs: 5199
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.684      |
| AbsLearnSignalNew       | 0.684      |
| AbsLearningOld          | 0.684      |
| AverageDiscountedReturn | 119        |
| AveragePhiLoss          | 0.976612   |
| AveragePolicyStd        | 0.827329   |
| AverageReturn           | 539        |
| Entropy                 | 7.3724     |
| EnvExecTime             | 2.99       |
| ExplainedVariance       | 0.282      |
| Iteration               | 285        |
| ItrTime                 | 11.4       |
| LossAfter               | -0.310134  |
| LossBefore              | -0.265785  |
| MaxReturn               | 1.41e+03   |
| MeanKL                  | 0.00645651 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 82.6       |
| NumTrajs                | 17         |
| Perplexity              | 1591.45    |
| PolicyExecTime          | 0.594      |
| ProcessExecTime         | 0.0791     |
| StdReturn               | 382        |
| Time                    | 3.11e+03   |
| dLoss                   | 0.0443492  |
----------------------------------------
itr #286 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 286...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5131, #subsample_inputs: 5131
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.722      |
| AbsLearnSignalNew       | 0.722      |
| AbsLearningOld          | 0.722      |
| AverageDiscountedReturn | 108        |
| AveragePhiLoss          | 0.975911   |
| AveragePolicyStd        | 0.825483   |
| AverageReturn           | 519        |
| Entropy                 | 7.35857    |
| EnvExecTime             | 3.04       |
| ExplainedVariance       | 0.534      |
| Iteration               | 286        |
| ItrTime                 | 10.4       |
| LossAfter               | -0.0879714 |
| LossBefore              | -0.0257653 |
| MaxReturn               | 1.79e+03   |
| MeanKL                  | 0.00991031 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 31         |
| NumTrajs                | 17         |
| Perplexity              | 1569.59    |
| PolicyExecTime          | 0.606      |
| ProcessExecTime         | 0.0795     |
| StdReturn               | 517        |
| Time                    | 3.13e+03   |
| dLoss                   | 0.0622061  |
----------------------------------------
itr #287 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 287...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5057, #subsample_inputs: 5057
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.732      |
| AbsLearnSignalNew       | 0.732      |
| AbsLearningOld          | 0.732      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 0.970049   |
| AveragePolicyStd        | 0.825418   |
| AverageReturn           | 691        |
| Entropy                 | 7.35688    |
| EnvExecTime             | 2.8        |
| ExplainedVariance       | 0.325      |
| Iteration               | 287        |
| ItrTime                 | 10.8       |
| LossAfter               | 0.22634    |
| LossBefore              | 0.281353   |
| MaxReturn               | 1.29e+03   |
| MeanKL                  | 0.00969711 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 41.5       |
| NumTrajs                | 15         |
| Perplexity              | 1566.94    |
| PolicyExecTime          | 0.569      |
| ProcessExecTime         | 0.0789     |
| StdReturn               | 420        |
| Time                    | 3.14e+03   |
| dLoss                   | 0.0550128  |
----------------------------------------
itr #288 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 288...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5199, #subsample_inputs: 5199
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.682      |
| AbsLearnSignalNew       | 0.682      |
| AbsLearningOld          | 0.682      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 0.957196   |
| AveragePolicyStd        | 0.823398   |
| AverageReturn           | 664        |
| Entropy                 | 7.34158    |
| EnvExecTime             | 2.89       |
| ExplainedVariance       | 0.152      |
| Iteration               | 288        |
| ItrTime                 | 11.4       |
| LossAfter               | -0.473945  |
| LossBefore              | -0.417463  |
| MaxReturn               | 1.69e+03   |
| MeanKL                  | 0.00993844 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 46.2       |
| NumTrajs                | 15         |
| Perplexity              | 1543.14    |
| PolicyExecTime          | 0.624      |
| ProcessExecTime         | 0.07       |
| StdReturn               | 386        |
| Time                    | 3.15e+03   |
| dLoss                   | 0.056482   |
----------------------------------------
itr #289 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 289...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5281, #subsample_inputs: 5281
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.655      |
| AbsLearnSignalNew       | 0.655      |
| AbsLearningOld          | 0.655      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 0.973445   |
| AveragePolicyStd        | 0.824972   |
| AverageReturn           | 579        |
| Entropy                 | 7.35356    |
| EnvExecTime             | 3.48       |
| ExplainedVariance       | 0.465      |
| Iteration               | 289        |
| ItrTime                 | 10.9       |
| LossAfter               | 0.579902   |
| LossBefore              | 0.641378   |
| MaxReturn               | 1.28e+03   |
| MeanKL                  | 0.00993856 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 84.4       |
| NumTrajs                | 16         |
| Perplexity              | 1561.75    |
| PolicyExecTime          | 0.685      |
| ProcessExecTime         | 0.0893     |
| StdReturn               | 324        |
| Time                    | 3.16e+03   |
| dLoss                   | 0.0614758  |
----------------------------------------
itr #290 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 290...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5126, #subsample_inputs: 5126
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.504      |
| AbsLearnSignalNew       | 0.504      |
| AbsLearningOld          | 0.504      |
| AverageDiscountedReturn | 119        |
| AveragePhiLoss          | 0.975932   |
| AveragePolicyStd        | 0.825444   |
| AverageReturn           | 657        |
| Entropy                 | 7.35723    |
| EnvExecTime             | 3.07       |
| ExplainedVariance       | -1.48      |
| Iteration               | 290        |
| ItrTime                 | 11.5       |
| LossAfter               | 1.08068    |
| LossBefore              | 1.12321    |
| MaxReturn               | 2.17e+03   |
| MeanKL                  | 0.00642772 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 36.9       |
| NumTrajs                | 15         |
| Perplexity              | 1567.49    |
| PolicyExecTime          | 0.639      |
| ProcessExecTime         | 0.0824     |
| StdReturn               | 547        |
| Time                    | 3.17e+03   |
| dLoss                   | 0.0425318  |
----------------------------------------
itr #291 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 291...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5310, #subsample_inputs: 5310
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.685     |
| AbsLearnSignalNew       | 0.685     |
| AbsLearningOld          | 0.685     |
| AverageDiscountedReturn | 134       |
| AveragePhiLoss          | 0.967258  |
| AveragePolicyStd        | 0.826156  |
| AverageReturn           | 624       |
| Entropy                 | 7.36216   |
| EnvExecTime             | 3.1       |
| ExplainedVariance       | 0.318     |
| Iteration               | 291       |
| ItrTime                 | 11.5      |
| LossAfter               | 1.26266   |
| LossBefore              | 1.30981   |
| MaxReturn               | 1.7e+03   |
| MeanKL                  | 0.006405  |
| MeanKLBefore            | 0.0       |
| MinReturn               | 117       |
| NumTrajs                | 17        |
| Perplexity              | 1575.23   |
| PolicyExecTime          | 0.602     |
| ProcessExecTime         | 0.0769    |
| StdReturn               | 388       |
| Time                    | 3.18e+03  |
| dLoss                   | 0.0471516 |
---------------------------------------
itr #292 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 292...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5126, #subsample_inputs: 5126
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.686      |
| AbsLearnSignalNew       | 0.686      |
| AbsLearningOld          | 0.686      |
| AverageDiscountedReturn | 123        |
| AveragePhiLoss          | 0.972016   |
| AveragePolicyStd        | 0.826506   |
| AverageReturn           | 649        |
| Entropy                 | 7.36474    |
| EnvExecTime             | 3.29       |
| ExplainedVariance       | 0.489      |
| Iteration               | 292        |
| ItrTime                 | 10.9       |
| LossAfter               | 0.612956   |
| LossBefore              | 0.662381   |
| MaxReturn               | 2.08e+03   |
| MeanKL                  | 0.00641474 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 44.4       |
| NumTrajs                | 16         |
| Perplexity              | 1579.3     |
| PolicyExecTime          | 0.684      |
| ProcessExecTime         | 0.0857     |
| StdReturn               | 526        |
| Time                    | 3.19e+03   |
| dLoss                   | 0.0494248  |
----------------------------------------
itr #293 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 293...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5057, #subsample_inputs: 5057
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.687      |
| AbsLearnSignalNew       | 0.687      |
| AbsLearningOld          | 0.687      |
| AverageDiscountedReturn | 138        |
| AveragePhiLoss          | 0.975245   |
| AveragePolicyStd        | 0.826123   |
| AverageReturn           | 873        |
| Entropy                 | 7.36145    |
| EnvExecTime             | 3.35       |
| ExplainedVariance       | 0.42       |
| Iteration               | 293        |
| ItrTime                 | 12         |
| LossAfter               | 0.582732   |
| LossBefore              | 0.648588   |
| MaxReturn               | 1.81e+03   |
| MeanKL                  | 0.00997013 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 46.3       |
| NumTrajs                | 13         |
| Perplexity              | 1574.12    |
| PolicyExecTime          | 0.718      |
| ProcessExecTime         | 0.0863     |
| StdReturn               | 463        |
| Time                    | 3.21e+03   |
| dLoss                   | 0.0658562  |
----------------------------------------
itr #294 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 294...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5253, #subsample_inputs: 5253
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.691      |
| AbsLearnSignalNew       | 0.691      |
| AbsLearningOld          | 0.691      |
| AverageDiscountedReturn | 119        |
| AveragePhiLoss          | 0.976636   |
| AveragePolicyStd        | 0.827527   |
| AverageReturn           | 496        |
| Entropy                 | 7.37222    |
| EnvExecTime             | 3.15       |
| ExplainedVariance       | 0.414      |
| Iteration               | 294        |
| ItrTime                 | 11         |
| LossAfter               | 0.216117   |
| LossBefore              | 0.268644   |
| MaxReturn               | 1.25e+03   |
| MeanKL                  | 0.00990706 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 61.2       |
| NumTrajs                | 19         |
| Perplexity              | 1591.17    |
| PolicyExecTime          | 0.617      |
| ProcessExecTime         | 0.0777     |
| StdReturn               | 336        |
| Time                    | 3.22e+03   |
| dLoss                   | 0.052527   |
----------------------------------------
itr #295 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 295...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5036, #subsample_inputs: 5036
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.702      |
| AbsLearnSignalNew       | 0.702      |
| AbsLearningOld          | 0.702      |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 0.975594   |
| AveragePolicyStd        | 0.827222   |
| AverageReturn           | 576        |
| Entropy                 | 7.37042    |
| EnvExecTime             | 2.96       |
| ExplainedVariance       | 0.502      |
| Iteration               | 295        |
| ItrTime                 | 10.8       |
| LossAfter               | -0.949948  |
| LossBefore              | -0.893742  |
| MaxReturn               | 1.97e+03   |
| MeanKL                  | 0.00991715 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 54.5       |
| NumTrajs                | 16         |
| Perplexity              | 1588.3     |
| PolicyExecTime          | 0.593      |
| ProcessExecTime         | 0.0793     |
| StdReturn               | 449        |
| Time                    | 3.23e+03   |
| dLoss                   | 0.0562066  |
----------------------------------------
itr #296 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 296...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5004, #subsample_inputs: 5004
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.708      |
| AbsLearnSignalNew       | 0.708      |
| AbsLearningOld          | 0.708      |
| AverageDiscountedReturn | 105        |
| AveragePhiLoss          | 0.968572   |
| AveragePolicyStd        | 0.826447   |
| AverageReturn           | 581        |
| Entropy                 | 7.36437    |
| EnvExecTime             | 2.91       |
| ExplainedVariance       | 0.457      |
| Iteration               | 296        |
| ItrTime                 | 11.1       |
| LossAfter               | -0.148448  |
| LossBefore              | -0.0890743 |
| MaxReturn               | 1.97e+03   |
| MeanKL                  | 0.00998232 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 64         |
| NumTrajs                | 14         |
| Perplexity              | 1578.72    |
| PolicyExecTime          | 0.559      |
| ProcessExecTime         | 0.0766     |
| StdReturn               | 530        |
| Time                    | 3.24e+03   |
| dLoss                   | 0.0593734  |
----------------------------------------
itr #297 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 297...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5164, #subsample_inputs: 5164
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.677      |
| AbsLearnSignalNew       | 0.677      |
| AbsLearningOld          | 0.678      |
| AverageDiscountedReturn | 119        |
| AveragePhiLoss          | 0.97104    |
| AveragePolicyStd        | 0.829806   |
| AverageReturn           | 587        |
| Entropy                 | 7.38849    |
| EnvExecTime             | 3.24       |
| ExplainedVariance       | 0.381      |
| Iteration               | 297        |
| ItrTime                 | 10.5       |
| LossAfter               | 0.355491   |
| LossBefore              | 0.397761   |
| MaxReturn               | 2.27e+03   |
| MeanKL                  | 0.00641778 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 43.1       |
| NumTrajs                | 17         |
| Perplexity              | 1617.26    |
| PolicyExecTime          | 0.664      |
| ProcessExecTime         | 0.0857     |
| StdReturn               | 540        |
| Time                    | 3.25e+03   |
| dLoss                   | 0.0422698  |
----------------------------------------
itr #298 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 298...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5150, #subsample_inputs: 5150
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.711      |
| AbsLearnSignalNew       | 0.711      |
| AbsLearningOld          | 0.711      |
| AverageDiscountedReturn | 104        |
| AveragePhiLoss          | 0.974162   |
| AveragePolicyStd        | 0.827748   |
| AverageReturn           | 579        |
| Entropy                 | 7.37275    |
| EnvExecTime             | 3.68       |
| ExplainedVariance       | 0.487      |
| Iteration               | 298        |
| ItrTime                 | 12.3       |
| LossAfter               | 0.103073   |
| LossBefore              | 0.143585   |
| MaxReturn               | 1.92e+03   |
| MeanKL                  | 0.00643612 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 39.2       |
| NumTrajs                | 15         |
| Perplexity              | 1592.0     |
| PolicyExecTime          | 0.731      |
| ProcessExecTime         | 0.0908     |
| StdReturn               | 556        |
| Time                    | 3.26e+03   |
| dLoss                   | 0.0405124  |
----------------------------------------
itr #299 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 299...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5125, #subsample_inputs: 5125
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.737      |
| AbsLearnSignalNew       | 0.737      |
| AbsLearningOld          | 0.737      |
| AverageDiscountedReturn | 109        |
| AveragePhiLoss          | 0.969967   |
| AveragePolicyStd        | 0.828429   |
| AverageReturn           | 510        |
| Entropy                 | 7.3781     |
| EnvExecTime             | 2.91       |
| ExplainedVariance       | 0.504      |
| Iteration               | 299        |
| ItrTime                 | 11.3       |
| LossAfter               | -0.0206189 |
| LossBefore              | 0.0392353  |
| MaxReturn               | 1.28e+03   |
| MeanKL                  | 0.00988818 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 47.6       |
| NumTrajs                | 18         |
| Perplexity              | 1600.55    |
| PolicyExecTime          | 0.555      |
| ProcessExecTime         | 0.0681     |
| StdReturn               | 407        |
| Time                    | 3.27e+03   |
| dLoss                   | 0.0598541  |
----------------------------------------
itr #300 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 300...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5236, #subsample_inputs: 5236
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.755      |
| AbsLearnSignalNew       | 0.755      |
| AbsLearningOld          | 0.755      |
| AverageDiscountedReturn | 119        |
| AveragePhiLoss          | 0.978323   |
| AveragePolicyStd        | 0.83111    |
| AverageReturn           | 624        |
| Entropy                 | 7.39819    |
| EnvExecTime             | 3.53       |
| ExplainedVariance       | 0.556      |
| Iteration               | 300        |
| ItrTime                 | 10.7       |
| LossAfter               | 0.295352   |
| LossBefore              | 0.337632   |
| MaxReturn               | 1.41e+03   |
| MeanKL                  | 0.00649621 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 50.5       |
| NumTrajs                | 16         |
| Perplexity              | 1633.03    |
| PolicyExecTime          | 0.721      |
| ProcessExecTime         | 0.0908     |
| StdReturn               | 460        |
| Time                    | 3.28e+03   |
| dLoss                   | 0.0422795  |
----------------------------------------
itr #301 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 301...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5139, #subsample_inputs: 5139
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.74       |
| AbsLearnSignalNew       | 0.74       |
| AbsLearningOld          | 0.74       |
| AverageDiscountedReturn | 114        |
| AveragePhiLoss          | 0.971065   |
| AveragePolicyStd        | 0.827763   |
| AverageReturn           | 427        |
| Entropy                 | 7.3737     |
| EnvExecTime             | 3.43       |
| ExplainedVariance       | 0.522      |
| Iteration               | 301        |
| ItrTime                 | 12.1       |
| LossAfter               | 0.347635   |
| LossBefore              | 0.399108   |
| MaxReturn               | 1.62e+03   |
| MeanKL                  | 0.00993316 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 39.2       |
| NumTrajs                | 21         |
| Perplexity              | 1593.52    |
| PolicyExecTime          | 0.689      |
| ProcessExecTime         | 0.0878     |
| StdReturn               | 367        |
| Time                    | 3.3e+03    |
| dLoss                   | 0.0514737  |
----------------------------------------
itr #302 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 302...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5094, #subsample_inputs: 5094
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.731      |
| AbsLearnSignalNew       | 0.731      |
| AbsLearningOld          | 0.731      |
| AverageDiscountedReturn | 115        |
| AveragePhiLoss          | 0.971201   |
| AveragePolicyStd        | 0.830583   |
| AverageReturn           | 488        |
| Entropy                 | 7.39416    |
| EnvExecTime             | 2.72       |
| ExplainedVariance       | 0.46       |
| Iteration               | 302        |
| ItrTime                 | 10.6       |
| LossAfter               | -0.384699  |
| LossBefore              | -0.338842  |
| MaxReturn               | 1.27e+03   |
| MeanKL                  | 0.00641268 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 47         |
| NumTrajs                | 18         |
| Perplexity              | 1626.45    |
| PolicyExecTime          | 0.527      |
| ProcessExecTime         | 0.0723     |
| StdReturn               | 318        |
| Time                    | 3.31e+03   |
| dLoss                   | 0.0458571  |
----------------------------------------
itr #303 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 303...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5116, #subsample_inputs: 5116
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.735      |
| AbsLearnSignalNew       | 0.735      |
| AbsLearningOld          | 0.735      |
| AverageDiscountedReturn | 119        |
| AveragePhiLoss          | 0.972396   |
| AveragePolicyStd        | 0.830156   |
| AverageReturn           | 451        |
| Entropy                 | 7.39166    |
| EnvExecTime             | 3.13       |
| ExplainedVariance       | 0.432      |
| Iteration               | 303        |
| ItrTime                 | 11         |
| LossAfter               | 0.547243   |
| LossBefore              | 0.60399    |
| MaxReturn               | 1.09e+03   |
| MeanKL                  | 0.00995576 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 56.8       |
| NumTrajs                | 20         |
| Perplexity              | 1622.39    |
| PolicyExecTime          | 0.634      |
| ProcessExecTime         | 0.0841     |
| StdReturn               | 249        |
| Time                    | 3.32e+03   |
| dLoss                   | 0.0567465  |
----------------------------------------
itr #304 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 304...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5762, #subsample_inputs: 5762
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.529      |
| AbsLearnSignalNew       | 0.529      |
| AbsLearningOld          | 0.529      |
| AverageDiscountedReturn | 136        |
| AveragePhiLoss          | 0.976965   |
| AveragePolicyStd        | 0.831485   |
| AverageReturn           | 783        |
| Entropy                 | 7.40104    |
| EnvExecTime             | 2.97       |
| ExplainedVariance       | -0.955     |
| Iteration               | 304        |
| ItrTime                 | 12         |
| LossAfter               | -0.241354  |
| LossBefore              | -0.19042   |
| MaxReturn               | 2.14e+03   |
| MeanKL                  | 0.00994036 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 80.9       |
| NumTrajs                | 16         |
| Perplexity              | 1637.69    |
| PolicyExecTime          | 0.596      |
| ProcessExecTime         | 0.0785     |
| StdReturn               | 504        |
| Time                    | 3.33e+03   |
| dLoss                   | 0.0509334  |
----------------------------------------
itr #305 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 305...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5356, #subsample_inputs: 5356
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.692      |
| AbsLearnSignalNew       | 0.692      |
| AbsLearningOld          | 0.692      |
| AverageDiscountedReturn | 127        |
| AveragePhiLoss          | 0.984843   |
| AveragePolicyStd        | 0.83169    |
| AverageReturn           | 504        |
| Entropy                 | 7.4018     |
| EnvExecTime             | 3.47       |
| ExplainedVariance       | 0.447      |
| Iteration               | 305        |
| ItrTime                 | 11.2       |
| LossAfter               | -0.103153  |
| LossBefore              | -0.0646167 |
| MaxReturn               | 1.26e+03   |
| MeanKL                  | 0.00652951 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 58         |
| NumTrajs                | 20         |
| Perplexity              | 1638.93    |
| PolicyExecTime          | 0.697      |
| ProcessExecTime         | 0.0878     |
| StdReturn               | 319        |
| Time                    | 3.34e+03   |
| dLoss                   | 0.038536   |
----------------------------------------
itr #306 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 306...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5190, #subsample_inputs: 5190
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.756      |
| AbsLearnSignalNew       | 0.756      |
| AbsLearningOld          | 0.756      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 0.977583   |
| AveragePolicyStd        | 0.82832    |
| AverageReturn           | 654        |
| Entropy                 | 7.37713    |
| EnvExecTime             | 3.26       |
| ExplainedVariance       | 0.478      |
| Iteration               | 306        |
| ItrTime                 | 11.9       |
| LossAfter               | 0.922161   |
| LossBefore              | 0.964769   |
| MaxReturn               | 1.51e+03   |
| MeanKL                  | 0.00640605 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 59         |
| NumTrajs                | 16         |
| Perplexity              | 1598.99    |
| PolicyExecTime          | 0.671      |
| ProcessExecTime         | 0.0849     |
| StdReturn               | 430        |
| Time                    | 3.35e+03   |
| dLoss                   | 0.0426083  |
----------------------------------------
itr #307 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 307...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5099, #subsample_inputs: 5099
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.682      |
| AbsLearnSignalNew       | 0.682      |
| AbsLearningOld          | 0.681      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 0.974101   |
| AveragePolicyStd        | 0.828591   |
| AverageReturn           | 531        |
| Entropy                 | 7.37944    |
| EnvExecTime             | 3.06       |
| ExplainedVariance       | 0.451      |
| Iteration               | 307        |
| ItrTime                 | 11.5       |
| LossAfter               | 0.639112   |
| LossBefore              | 0.687617   |
| MaxReturn               | 1.22e+03   |
| MeanKL                  | 0.00641645 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 53.4       |
| NumTrajs                | 18         |
| Perplexity              | 1602.69    |
| PolicyExecTime          | 0.581      |
| ProcessExecTime         | 0.0719     |
| StdReturn               | 328        |
| Time                    | 3.36e+03   |
| dLoss                   | 0.0485058  |
----------------------------------------
itr #308 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 308...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5377, #subsample_inputs: 5377
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.743      |
| AbsLearnSignalNew       | 0.743      |
| AbsLearningOld          | 0.743      |
| AverageDiscountedReturn | 124        |
| AveragePhiLoss          | 0.975974   |
| AveragePolicyStd        | 0.829408   |
| AverageReturn           | 594        |
| Entropy                 | 7.38468    |
| EnvExecTime             | 3.31       |
| ExplainedVariance       | 0.512      |
| Iteration               | 308        |
| ItrTime                 | 10.8       |
| LossAfter               | -0.596201  |
| LossBefore              | -0.55532   |
| MaxReturn               | 1.31e+03   |
| MeanKL                  | 0.00645043 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 52.5       |
| NumTrajs                | 18         |
| Perplexity              | 1611.1     |
| PolicyExecTime          | 0.667      |
| ProcessExecTime         | 0.0862     |
| StdReturn               | 412        |
| Time                    | 3.38e+03   |
| dLoss                   | 0.040881   |
----------------------------------------
itr #309 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 309...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5072, #subsample_inputs: 5072
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.653      |
| AbsLearnSignalNew       | 0.653      |
| AbsLearningOld          | 0.653      |
| AverageDiscountedReturn | 131        |
| AveragePhiLoss          | 0.973103   |
| AveragePolicyStd        | 0.826812   |
| AverageReturn           | 614        |
| Entropy                 | 7.36662    |
| EnvExecTime             | 2.84       |
| ExplainedVariance       | 0.417      |
| Iteration               | 309        |
| ItrTime                 | 11.6       |
| LossAfter               | 0.45301    |
| LossBefore              | 0.502965   |
| MaxReturn               | 1.05e+03   |
| MeanKL                  | 0.00641428 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 64.9       |
| NumTrajs                | 17         |
| Perplexity              | 1582.28    |
| PolicyExecTime          | 0.604      |
| ProcessExecTime         | 0.0797     |
| StdReturn               | 291        |
| Time                    | 3.39e+03   |
| dLoss                   | 0.0499545  |
----------------------------------------
itr #310 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 310...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5519, #subsample_inputs: 5519
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.742      |
| AbsLearnSignalNew       | 0.742      |
| AbsLearningOld          | 0.742      |
| AverageDiscountedReturn | 102        |
| AveragePhiLoss          | 0.980613   |
| AveragePolicyStd        | 0.828031   |
| AverageReturn           | 486        |
| Entropy                 | 7.37474    |
| EnvExecTime             | 2.86       |
| ExplainedVariance       | 0.427      |
| Iteration               | 310        |
| ItrTime                 | 11.7       |
| LossAfter               | -0.170447  |
| LossBefore              | -0.128564  |
| MaxReturn               | 1.46e+03   |
| MeanKL                  | 0.00641448 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 35.9       |
| NumTrajs                | 19         |
| Perplexity              | 1595.18    |
| PolicyExecTime          | 0.536      |
| ProcessExecTime         | 0.0699     |
| StdReturn               | 444        |
| Time                    | 3.4e+03    |
| dLoss                   | 0.0418832  |
----------------------------------------
itr #311 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 311...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5055, #subsample_inputs: 5055
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.722      |
| AbsLearnSignalNew       | 0.722      |
| AbsLearningOld          | 0.722      |
| AverageDiscountedReturn | 112        |
| AveragePhiLoss          | 0.973546   |
| AveragePolicyStd        | 0.827695   |
| AverageReturn           | 478        |
| Entropy                 | 7.3725     |
| EnvExecTime             | 3.64       |
| ExplainedVariance       | 0.475      |
| Iteration               | 311        |
| ItrTime                 | 10.9       |
| LossAfter               | 0.622166   |
| LossBefore              | 0.664436   |
| MaxReturn               | 1.18e+03   |
| MeanKL                  | 0.00646408 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 64.1       |
| NumTrajs                | 18         |
| Perplexity              | 1591.61    |
| PolicyExecTime          | 0.735      |
| ProcessExecTime         | 0.0901     |
| StdReturn               | 339        |
| Time                    | 3.41e+03   |
| dLoss                   | 0.0422701  |
----------------------------------------
itr #312 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 312...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5403, #subsample_inputs: 5403
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.729      |
| AbsLearnSignalNew       | 0.729      |
| AbsLearningOld          | 0.729      |
| AverageDiscountedReturn | 117        |
| AveragePhiLoss          | 0.9715     |
| AveragePolicyStd        | 0.824119   |
| AverageReturn           | 575        |
| Entropy                 | 7.34637    |
| EnvExecTime             | 3.14       |
| ExplainedVariance       | 0.365      |
| Iteration               | 312        |
| ItrTime                 | 11.9       |
| LossAfter               | 0.45551    |
| LossBefore              | 0.508983   |
| MaxReturn               | 1.15e+03   |
| MeanKL                  | 0.00987701 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 39.6       |
| NumTrajs                | 17         |
| Perplexity              | 1550.55    |
| PolicyExecTime          | 0.639      |
| ProcessExecTime         | 0.0865     |
| StdReturn               | 331        |
| Time                    | 3.42e+03   |
| dLoss                   | 0.0534728  |
----------------------------------------
itr #313 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 313...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5045, #subsample_inputs: 5045
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.741      |
| AbsLearnSignalNew       | 0.741      |
| AbsLearningOld          | 0.741      |
| AverageDiscountedReturn | 101        |
| AveragePhiLoss          | 0.980362   |
| AveragePolicyStd        | 0.822824   |
| AverageReturn           | 440        |
| Entropy                 | 7.33633    |
| EnvExecTime             | 2.66       |
| ExplainedVariance       | 0.516      |
| Iteration               | 313        |
| ItrTime                 | 10.2       |
| LossAfter               | 0.335249   |
| LossBefore              | 0.373973   |
| MaxReturn               | 1.36e+03   |
| MeanKL                  | 0.00640471 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 38.8       |
| NumTrajs                | 19         |
| Perplexity              | 1535.06    |
| PolicyExecTime          | 0.497      |
| ProcessExecTime         | 0.0657     |
| StdReturn               | 413        |
| Time                    | 3.43e+03   |
| dLoss                   | 0.0387244  |
----------------------------------------
itr #314 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 314...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5216, #subsample_inputs: 5216
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.737      |
| AbsLearnSignalNew       | 0.737      |
| AbsLearningOld          | 0.737      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 0.97227    |
| AveragePolicyStd        | 0.82285    |
| AverageReturn           | 581        |
| Entropy                 | 7.33675    |
| EnvExecTime             | 3.25       |
| ExplainedVariance       | 0.502      |
| Iteration               | 314        |
| ItrTime                 | 11.2       |
| LossAfter               | -0.693143  |
| LossBefore              | -0.642273  |
| MaxReturn               | 1.42e+03   |
| MeanKL                  | 0.00978975 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 38.3       |
| NumTrajs                | 17         |
| Perplexity              | 1535.71    |
| PolicyExecTime          | 0.65       |
| ProcessExecTime         | 0.0845     |
| StdReturn               | 402        |
| Time                    | 3.44e+03   |
| dLoss                   | 0.0508699  |
----------------------------------------
itr #315 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 315...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5078, #subsample_inputs: 5078
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.697      |
| AbsLearnSignalNew       | 0.697      |
| AbsLearningOld          | 0.697      |
| AverageDiscountedReturn | 137        |
| AveragePhiLoss          | 0.966498   |
| AveragePolicyStd        | 0.822667   |
| AverageReturn           | 865        |
| Entropy                 | 7.33559    |
| EnvExecTime             | 2.74       |
| ExplainedVariance       | 0.5        |
| Iteration               | 315        |
| ItrTime                 | 10.9       |
| LossAfter               | -0.149887  |
| LossBefore              | -0.0981086 |
| MaxReturn               | 1.63e+03   |
| MeanKL                  | 0.00642893 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 159        |
| NumTrajs                | 13         |
| Perplexity              | 1533.93    |
| PolicyExecTime          | 0.537      |
| ProcessExecTime         | 0.0695     |
| StdReturn               | 440        |
| Time                    | 3.45e+03   |
| dLoss                   | 0.0517787  |
----------------------------------------
itr #316 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 316...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5239, #subsample_inputs: 5239
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.693      |
| AbsLearnSignalNew       | 0.693      |
| AbsLearningOld          | 0.693      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 0.965753   |
| AveragePolicyStd        | 0.821918   |
| AverageReturn           | 552        |
| Entropy                 | 7.33082    |
| EnvExecTime             | 3.1        |
| ExplainedVariance       | 0.472      |
| Iteration               | 316        |
| ItrTime                 | 10.4       |
| LossAfter               | 0.864312   |
| LossBefore              | 0.913399   |
| MaxReturn               | 1.2e+03    |
| MeanKL                  | 0.00647344 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 64.1       |
| NumTrajs                | 17         |
| Perplexity              | 1526.63    |
| PolicyExecTime          | 0.614      |
| ProcessExecTime         | 0.0818     |
| StdReturn               | 357        |
| Time                    | 3.47e+03   |
| dLoss                   | 0.049087   |
----------------------------------------
itr #317 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 317...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5162, #subsample_inputs: 5162
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.682      |
| AbsLearnSignalNew       | 0.682      |
| AbsLearningOld          | 0.682      |
| AverageDiscountedReturn | 113        |
| AveragePhiLoss          | 0.976942   |
| AveragePolicyStd        | 0.822459   |
| AverageReturn           | 597        |
| Entropy                 | 7.33503    |
| EnvExecTime             | 3.48       |
| ExplainedVariance       | 0.232      |
| Iteration               | 317        |
| ItrTime                 | 12.2       |
| LossAfter               | -0.171766  |
| LossBefore              | -0.112255  |
| MaxReturn               | 1.88e+03   |
| MeanKL                  | 0.00992446 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 50.2       |
| NumTrajs                | 15         |
| Perplexity              | 1533.07    |
| PolicyExecTime          | 0.723      |
| ProcessExecTime         | 0.09       |
| StdReturn               | 517        |
| Time                    | 3.48e+03   |
| dLoss                   | 0.0595113  |
----------------------------------------
itr #318 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 318...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5105, #subsample_inputs: 5105
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.707      |
| AbsLearnSignalNew       | 0.707      |
| AbsLearningOld          | 0.707      |
| AverageDiscountedReturn | 132        |
| AveragePhiLoss          | 0.978012   |
| AveragePolicyStd        | 0.824634   |
| AverageReturn           | 720        |
| Entropy                 | 7.34985    |
| EnvExecTime             | 2.53       |
| ExplainedVariance       | 0.369      |
| Iteration               | 318        |
| ItrTime                 | 10.7       |
| LossAfter               | 0.104647   |
| LossBefore              | 0.150288   |
| MaxReturn               | 1.74e+03   |
| MeanKL                  | 0.00643407 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 53.5       |
| NumTrajs                | 15         |
| Perplexity              | 1555.96    |
| PolicyExecTime          | 0.476      |
| ProcessExecTime         | 0.0641     |
| StdReturn               | 436        |
| Time                    | 3.49e+03   |
| dLoss                   | 0.0456417  |
----------------------------------------
itr #319 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 319...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5003, #subsample_inputs: 5003
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.665      |
| AbsLearnSignalNew       | 0.665      |
| AbsLearningOld          | 0.665      |
| AverageDiscountedReturn | 103        |
| AveragePhiLoss          | 0.984236   |
| AveragePolicyStd        | 0.824495   |
| AverageReturn           | 543        |
| Entropy                 | 7.34832    |
| EnvExecTime             | 3.45       |
| ExplainedVariance       | 0.41       |
| Iteration               | 319        |
| ItrTime                 | 11         |
| LossAfter               | 0.358037   |
| LossBefore              | 0.411331   |
| MaxReturn               | 2.64e+03   |
| MeanKL                  | 0.00990006 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 20.8       |
| NumTrajs                | 17         |
| Perplexity              | 1553.59    |
| PolicyExecTime          | 0.697      |
| ProcessExecTime         | 0.0863     |
| StdReturn               | 612        |
| Time                    | 3.5e+03    |
| dLoss                   | 0.0532939  |
----------------------------------------
itr #320 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 320...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5055, #subsample_inputs: 5055
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.737      |
| AbsLearnSignalNew       | 0.737      |
| AbsLearningOld          | 0.737      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 0.975556   |
| AveragePolicyStd        | 0.820045   |
| AverageReturn           | 574        |
| Entropy                 | 7.31401    |
| EnvExecTime             | 3.52       |
| ExplainedVariance       | 0.32       |
| Iteration               | 320        |
| ItrTime                 | 12.1       |
| LossAfter               | -0.0440574 |
| LossBefore              | 0.00806142 |
| MaxReturn               | 1.15e+03   |
| MeanKL                  | 0.00996275 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 72.4       |
| NumTrajs                | 16         |
| Perplexity              | 1501.18    |
| PolicyExecTime          | 0.711      |
| ProcessExecTime         | 0.0857     |
| StdReturn               | 289        |
| Time                    | 3.51e+03   |
| dLoss                   | 0.0521189  |
----------------------------------------
itr #321 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 321...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5483, #subsample_inputs: 5483
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.703      |
| AbsLearnSignalNew       | 0.703      |
| AbsLearningOld          | 0.703      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 0.976395   |
| AveragePolicyStd        | 0.820894   |
| AverageReturn           | 538        |
| Entropy                 | 7.32013    |
| EnvExecTime             | 3.29       |
| ExplainedVariance       | 0.356      |
| Iteration               | 321        |
| ItrTime                 | 11.8       |
| LossAfter               | -0.295889  |
| LossBefore              | -0.239133  |
| MaxReturn               | 1.61e+03   |
| MeanKL                  | 0.00997556 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 32.5       |
| NumTrajs                | 19         |
| Perplexity              | 1510.39    |
| PolicyExecTime          | 0.628      |
| ProcessExecTime         | 0.0813     |
| StdReturn               | 438        |
| Time                    | 3.52e+03   |
| dLoss                   | 0.0567565  |
----------------------------------------
itr #322 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 322...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5131, #subsample_inputs: 5131
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.787      |
| AbsLearnSignalNew       | 0.787      |
| AbsLearningOld          | 0.787      |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 0.977999   |
| AveragePolicyStd        | 0.819343   |
| AverageReturn           | 748        |
| Entropy                 | 7.30746    |
| EnvExecTime             | 3.02       |
| ExplainedVariance       | 0.525      |
| Iteration               | 322        |
| ItrTime                 | 10.6       |
| LossAfter               | 0.156562   |
| LossBefore              | 0.208613   |
| MaxReturn               | 1.76e+03   |
| MeanKL                  | 0.00988255 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 29         |
| NumTrajs                | 15         |
| Perplexity              | 1491.38    |
| PolicyExecTime          | 0.621      |
| ProcessExecTime         | 0.0807     |
| StdReturn               | 545        |
| Time                    | 3.53e+03   |
| dLoss                   | 0.0520513  |
----------------------------------------
itr #323 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 323...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5197, #subsample_inputs: 5197
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.721      |
| AbsLearnSignalNew       | 0.721      |
| AbsLearningOld          | 0.721      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 0.978421   |
| AveragePolicyStd        | 0.81575    |
| AverageReturn           | 693        |
| Entropy                 | 7.28094    |
| EnvExecTime             | 2.87       |
| ExplainedVariance       | 0.564      |
| Iteration               | 323        |
| ItrTime                 | 11.5       |
| LossAfter               | 0.0786284  |
| LossBefore              | 0.130472   |
| MaxReturn               | 1.66e+03   |
| MeanKL                  | 0.00994007 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 70.3       |
| NumTrajs                | 15         |
| Perplexity              | 1452.36    |
| PolicyExecTime          | 0.58       |
| ProcessExecTime         | 0.0777     |
| StdReturn               | 488        |
| Time                    | 3.55e+03   |
| dLoss                   | 0.0518434  |
----------------------------------------
itr #324 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 324...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5320, #subsample_inputs: 5320
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.704      |
| AbsLearnSignalNew       | 0.704      |
| AbsLearningOld          | 0.704      |
| AverageDiscountedReturn | 123        |
| AveragePhiLoss          | 0.97002    |
| AveragePolicyStd        | 0.818521   |
| AverageReturn           | 516        |
| Entropy                 | 7.30048    |
| EnvExecTime             | 3.49       |
| ExplainedVariance       | 0.502      |
| Iteration               | 324        |
| ItrTime                 | 11.1       |
| LossAfter               | -0.0715856 |
| LossBefore              | -0.0142884 |
| MaxReturn               | 1.54e+03   |
| MeanKL                  | 0.00988856 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 44.1       |
| NumTrajs                | 20         |
| Perplexity              | 1481.02    |
| PolicyExecTime          | 0.701      |
| ProcessExecTime         | 0.0899     |
| StdReturn               | 336        |
| Time                    | 3.56e+03   |
| dLoss                   | 0.0572972  |
----------------------------------------
itr #325 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 325...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5006, #subsample_inputs: 5006
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.718      |
| AbsLearnSignalNew       | 0.718      |
| AbsLearningOld          | 0.718      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 0.966429   |
| AveragePolicyStd        | 0.816228   |
| AverageReturn           | 535        |
| Entropy                 | 7.28407    |
| EnvExecTime             | 3.22       |
| ExplainedVariance       | 0.459      |
| Iteration               | 325        |
| ItrTime                 | 11.3       |
| LossAfter               | -0.475303  |
| LossBefore              | -0.416972  |
| MaxReturn               | 1.74e+03   |
| MeanKL                  | 0.00990994 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 23.4       |
| NumTrajs                | 17         |
| Perplexity              | 1456.9     |
| PolicyExecTime          | 0.646      |
| ProcessExecTime         | 0.0855     |
| StdReturn               | 372        |
| Time                    | 3.57e+03   |
| dLoss                   | 0.058331   |
----------------------------------------
itr #326 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 326...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5064, #subsample_inputs: 5064
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.707      |
| AbsLearnSignalNew       | 0.707      |
| AbsLearningOld          | 0.707      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 0.969995   |
| AveragePolicyStd        | 0.817558   |
| AverageReturn           | 562        |
| Entropy                 | 7.29329    |
| EnvExecTime             | 2.97       |
| ExplainedVariance       | 0.484      |
| Iteration               | 326        |
| ItrTime                 | 11.2       |
| LossAfter               | 0.201338   |
| LossBefore              | 0.251343   |
| MaxReturn               | 1.4e+03    |
| MeanKL                  | 0.00642359 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 67         |
| NumTrajs                | 17         |
| Perplexity              | 1470.4     |
| PolicyExecTime          | 0.563      |
| ProcessExecTime         | 0.0716     |
| StdReturn               | 371        |
| Time                    | 3.58e+03   |
| dLoss                   | 0.0500053  |
----------------------------------------
itr #327 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 327...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5318, #subsample_inputs: 5318
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
-----------------------------------------
| AbsLearnSignal          | 0.575       |
| AbsLearnSignalNew       | 0.575       |
| AbsLearningOld          | 0.574       |
| AverageDiscountedReturn | 117         |
| AveragePhiLoss          | 0.966174    |
| AveragePolicyStd        | 0.815404    |
| AverageReturn           | 609         |
| Entropy                 | 7.27663     |
| EnvExecTime             | 3.15        |
| ExplainedVariance       | -0.684      |
| Iteration               | 327         |
| ItrTime                 | 10.4        |
| LossAfter               | -0.0815512  |
| LossBefore              | -0.00347192 |
| MaxReturn               | 2.06e+03    |
| MeanKL                  | 0.00993233  |
| MeanKLBefore            | 0.0         |
| MinReturn               | 69.2        |
| NumTrajs                | 16          |
| Perplexity              | 1446.11     |
| PolicyExecTime          | 0.635       |
| ProcessExecTime         | 0.0852      |
| StdReturn               | 520         |
| Time                    | 3.59e+03    |
| dLoss                   | 0.0780793   |
-----------------------------------------
itr #328 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 328...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5045, #subsample_inputs: 5045
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.498      |
| AbsLearnSignalNew       | 0.498      |
| AbsLearningOld          | 0.498      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 0.99025    |
| AveragePolicyStd        | 0.818027   |
| AverageReturn           | 621        |
| Entropy                 | 7.2957     |
| EnvExecTime             | 3.09       |
| ExplainedVariance       | 0.149      |
| Iteration               | 328        |
| ItrTime                 | 11.6       |
| LossAfter               | 0.492927   |
| LossBefore              | 0.528478   |
| MaxReturn               | 1.77e+03   |
| MeanKL                  | 0.00641347 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 34.6       |
| NumTrajs                | 17         |
| Perplexity              | 1473.95    |
| PolicyExecTime          | 0.628      |
| ProcessExecTime         | 0.0816     |
| StdReturn               | 428        |
| Time                    | 3.6e+03    |
| dLoss                   | 0.0355516  |
----------------------------------------
itr #329 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 329...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5418, #subsample_inputs: 5418
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.691      |
| AbsLearnSignalNew       | 0.691      |
| AbsLearningOld          | 0.691      |
| AverageDiscountedReturn | 123        |
| AveragePhiLoss          | 0.980207   |
| AveragePolicyStd        | 0.815205   |
| AverageReturn           | 518        |
| Entropy                 | 7.27415    |
| EnvExecTime             | 3.21       |
| ExplainedVariance       | 0.457      |
| Iteration               | 329        |
| ItrTime                 | 11.8       |
| LossAfter               | 0.592268   |
| LossBefore              | 0.63573    |
| MaxReturn               | 1.3e+03    |
| MeanKL                  | 0.00650554 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 68.1       |
| NumTrajs                | 20         |
| Perplexity              | 1442.52    |
| PolicyExecTime          | 0.639      |
| ProcessExecTime         | 0.0838     |
| StdReturn               | 362        |
| Time                    | 3.61e+03   |
| dLoss                   | 0.0434627  |
----------------------------------------
itr #330 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 330...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5142, #subsample_inputs: 5142
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.447      |
| AbsLearnSignalNew       | 0.447      |
| AbsLearningOld          | 0.447      |
| AverageDiscountedReturn | 113        |
| AveragePhiLoss          | 0.966804   |
| AveragePolicyStd        | 0.814344   |
| AverageReturn           | 645        |
| Entropy                 | 7.26784    |
| EnvExecTime             | 3.05       |
| ExplainedVariance       | -4.58      |
| Iteration               | 330        |
| ItrTime                 | 10.5       |
| LossAfter               | 0.774381   |
| LossBefore              | 0.839788   |
| MaxReturn               | 2.23e+03   |
| MeanKL                  | 0.00648619 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 28.3       |
| NumTrajs                | 15         |
| Perplexity              | 1433.45    |
| PolicyExecTime          | 0.622      |
| ProcessExecTime         | 0.0807     |
| StdReturn               | 589        |
| Time                    | 3.62e+03   |
| dLoss                   | 0.0654069  |
----------------------------------------
itr #331 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 331...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5077, #subsample_inputs: 5077
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.684      |
| AbsLearnSignalNew       | 0.684      |
| AbsLearningOld          | 0.684      |
| AverageDiscountedReturn | 129        |
| AveragePhiLoss          | 0.970739   |
| AveragePolicyStd        | 0.814785   |
| AverageReturn           | 597        |
| Entropy                 | 7.27135    |
| EnvExecTime             | 3.25       |
| ExplainedVariance       | 0.361      |
| Iteration               | 331        |
| ItrTime                 | 11.5       |
| LossAfter               | -0.130135  |
| LossBefore              | -0.085396  |
| MaxReturn               | 1.37e+03   |
| MeanKL                  | 0.00644607 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 92.9       |
| NumTrajs                | 17         |
| Perplexity              | 1438.49    |
| PolicyExecTime          | 0.652      |
| ProcessExecTime         | 0.0804     |
| StdReturn               | 291        |
| Time                    | 3.64e+03   |
| dLoss                   | 0.0447388  |
----------------------------------------
itr #332 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 332...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5092, #subsample_inputs: 5092
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.685      |
| AbsLearnSignalNew       | 0.685      |
| AbsLearningOld          | 0.685      |
| AverageDiscountedReturn | 115        |
| AveragePhiLoss          | 0.973961   |
| AveragePolicyStd        | 0.815774   |
| AverageReturn           | 515        |
| Entropy                 | 7.27979    |
| EnvExecTime             | 3.01       |
| ExplainedVariance       | 0.499      |
| Iteration               | 332        |
| ItrTime                 | 10.4       |
| LossAfter               | -0.0601715 |
| LossBefore              | -0.002969  |
| MaxReturn               | 1.43e+03   |
| MeanKL                  | 0.00986238 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 57.3       |
| NumTrajs                | 17         |
| Perplexity              | 1450.68    |
| PolicyExecTime          | 0.594      |
| ProcessExecTime         | 0.0781     |
| StdReturn               | 455        |
| Time                    | 3.65e+03   |
| dLoss                   | 0.0572025  |
----------------------------------------
itr #333 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 333...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5123, #subsample_inputs: 5123
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.74       |
| AbsLearnSignalNew       | 0.74       |
| AbsLearningOld          | 0.74       |
| AverageDiscountedReturn | 111        |
| AveragePhiLoss          | 0.972049   |
| AveragePolicyStd        | 0.814987   |
| AverageReturn           | 502        |
| Entropy                 | 7.27535    |
| EnvExecTime             | 3.03       |
| ExplainedVariance       | 0.427      |
| Iteration               | 333        |
| ItrTime                 | 11.6       |
| LossAfter               | 0.261029   |
| LossBefore              | 0.306009   |
| MaxReturn               | 1e+03      |
| MeanKL                  | 0.00647196 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 41.6       |
| NumTrajs                | 17         |
| Perplexity              | 1444.26    |
| PolicyExecTime          | 0.618      |
| ProcessExecTime         | 0.0809     |
| StdReturn               | 330        |
| Time                    | 3.66e+03   |
| dLoss                   | 0.0449801  |
----------------------------------------
itr #334 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 334...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5174, #subsample_inputs: 5174
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.706      |
| AbsLearnSignalNew       | 0.706      |
| AbsLearningOld          | 0.706      |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 0.972325   |
| AveragePolicyStd        | 0.816216   |
| AverageReturn           | 555        |
| Entropy                 | 7.28468    |
| EnvExecTime             | 2.96       |
| ExplainedVariance       | 0.416      |
| Iteration               | 334        |
| ItrTime                 | 11.2       |
| LossAfter               | -0.0793697 |
| LossBefore              | -0.0254109 |
| MaxReturn               | 1.5e+03    |
| MeanKL                  | 0.00988782 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 44.8       |
| NumTrajs                | 18         |
| Perplexity              | 1457.79    |
| PolicyExecTime          | 0.56       |
| ProcessExecTime         | 0.0718     |
| StdReturn               | 341        |
| Time                    | 3.67e+03   |
| dLoss                   | 0.0539588  |
----------------------------------------
itr #335 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 335...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5278, #subsample_inputs: 5278
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.671      |
| AbsLearnSignalNew       | 0.671      |
| AbsLearningOld          | 0.671      |
| AverageDiscountedReturn | 119        |
| AveragePhiLoss          | 0.966471   |
| AveragePolicyStd        | 0.812577   |
| AverageReturn           | 599        |
| Entropy                 | 7.25705    |
| EnvExecTime             | 3.58       |
| ExplainedVariance       | 0.43       |
| Iteration               | 335        |
| ItrTime                 | 11.1       |
| LossAfter               | -0.265243  |
| LossBefore              | -0.219555  |
| MaxReturn               | 1.15e+03   |
| MeanKL                  | 0.00640726 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 92.9       |
| NumTrajs                | 16         |
| Perplexity              | 1418.07    |
| PolicyExecTime          | 0.732      |
| ProcessExecTime         | 0.0923     |
| StdReturn               | 286        |
| Time                    | 3.68e+03   |
| dLoss                   | 0.0456889  |
----------------------------------------
itr #336 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 336...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5047, #subsample_inputs: 5047
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.655      |
| AbsLearnSignalNew       | 0.655      |
| AbsLearningOld          | 0.655      |
| AverageDiscountedReturn | 115        |
| AveragePhiLoss          | 0.961602   |
| AveragePolicyStd        | 0.811229   |
| AverageReturn           | 525        |
| Entropy                 | 7.24682    |
| EnvExecTime             | 3.01       |
| ExplainedVariance       | -0.0291    |
| Iteration               | 336        |
| ItrTime                 | 11.4       |
| LossAfter               | -0.0748786 |
| LossBefore              | -0.0152352 |
| MaxReturn               | 1.64e+03   |
| MeanKL                  | 0.00642221 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 65.6       |
| NumTrajs                | 17         |
| Perplexity              | 1403.63    |
| PolicyExecTime          | 0.62       |
| ProcessExecTime         | 0.079      |
| StdReturn               | 406        |
| Time                    | 3.69e+03   |
| dLoss                   | 0.0596434  |
----------------------------------------
itr #337 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 337...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5036, #subsample_inputs: 5036
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.731     |
| AbsLearnSignalNew       | 0.731     |
| AbsLearningOld          | 0.731     |
| AverageDiscountedReturn | 100       |
| AveragePhiLoss          | 0.968141  |
| AveragePolicyStd        | 0.815032  |
| AverageReturn           | 496       |
| Entropy                 | 7.27469   |
| EnvExecTime             | 2.81      |
| ExplainedVariance       | 0.562     |
| Iteration               | 337       |
| ItrTime                 | 10.5      |
| LossAfter               | -0.701549 |
| LossBefore              | -0.65526  |
| MaxReturn               | 1.94e+03  |
| MeanKL                  | 0.0064182 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 57.2      |
| NumTrajs                | 16        |
| Perplexity              | 1443.31   |
| PolicyExecTime          | 0.536     |
| ProcessExecTime         | 0.0707    |
| StdReturn               | 534       |
| Time                    | 3.7e+03   |
| dLoss                   | 0.0462895 |
---------------------------------------
itr #338 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 338...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5056, #subsample_inputs: 5056
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.708      |
| AbsLearnSignalNew       | 0.708      |
| AbsLearningOld          | 0.708      |
| AverageDiscountedReturn | 119        |
| AveragePhiLoss          | 0.974797   |
| AveragePolicyStd        | 0.813527   |
| AverageReturn           | 509        |
| Entropy                 | 7.26373    |
| EnvExecTime             | 3.35       |
| ExplainedVariance       | 0.361      |
| Iteration               | 338        |
| ItrTime                 | 11.2       |
| LossAfter               | -0.598109  |
| LossBefore              | -0.542453  |
| MaxReturn               | 1.16e+03   |
| MeanKL                  | 0.00996083 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 55.8       |
| NumTrajs                | 18         |
| Perplexity              | 1427.56    |
| PolicyExecTime          | 0.674      |
| ProcessExecTime         | 0.0857     |
| StdReturn               | 323        |
| Time                    | 3.71e+03   |
| dLoss                   | 0.0556561  |
----------------------------------------
itr #339 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 339...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5307, #subsample_inputs: 5307
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.723      |
| AbsLearnSignalNew       | 0.723      |
| AbsLearningOld          | 0.723      |
| AverageDiscountedReturn | 130        |
| AveragePhiLoss          | 0.975849   |
| AveragePolicyStd        | 0.813047   |
| AverageReturn           | 705        |
| Entropy                 | 7.25952    |
| EnvExecTime             | 3.08       |
| ExplainedVariance       | 0.456      |
| Iteration               | 339        |
| ItrTime                 | 11.8       |
| LossAfter               | -0.578185  |
| LossBefore              | -0.523261  |
| MaxReturn               | 1.75e+03   |
| MeanKL                  | 0.00998305 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 33.3       |
| NumTrajs                | 15         |
| Perplexity              | 1421.58    |
| PolicyExecTime          | 0.619      |
| ProcessExecTime         | 0.0782     |
| StdReturn               | 448        |
| Time                    | 3.73e+03   |
| dLoss                   | 0.0549234  |
----------------------------------------
itr #340 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 340...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5007, #subsample_inputs: 5007
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.722      |
| AbsLearnSignalNew       | 0.722      |
| AbsLearningOld          | 0.722      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 0.964923   |
| AveragePolicyStd        | 0.81222    |
| AverageReturn           | 528        |
| Entropy                 | 7.25346    |
| EnvExecTime             | 3.21       |
| ExplainedVariance       | 0.464      |
| Iteration               | 340        |
| ItrTime                 | 10.2       |
| LossAfter               | -0.716087  |
| LossBefore              | -0.667989  |
| MaxReturn               | 1.07e+03   |
| MeanKL                  | 0.00646927 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 54.4       |
| NumTrajs                | 17         |
| Perplexity              | 1412.99    |
| PolicyExecTime          | 0.655      |
| ProcessExecTime         | 0.0812     |
| StdReturn               | 280        |
| Time                    | 3.74e+03   |
| dLoss                   | 0.0480973  |
----------------------------------------
itr #341 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 341...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5316, #subsample_inputs: 5316
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.709      |
| AbsLearnSignalNew       | 0.709      |
| AbsLearningOld          | 0.709      |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 0.974451   |
| AveragePolicyStd        | 0.8106     |
| AverageReturn           | 732        |
| Entropy                 | 7.24074    |
| EnvExecTime             | 3.09       |
| ExplainedVariance       | 0.363      |
| Iteration               | 341        |
| ItrTime                 | 11.9       |
| LossAfter               | -0.738118  |
| LossBefore              | -0.683224  |
| MaxReturn               | 1.64e+03   |
| MeanKL                  | 0.00988303 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 49.9       |
| NumTrajs                | 15         |
| Perplexity              | 1395.12    |
| PolicyExecTime          | 0.626      |
| ProcessExecTime         | 0.0837     |
| StdReturn               | 437        |
| Time                    | 3.75e+03   |
| dLoss                   | 0.0548937  |
----------------------------------------
itr #342 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 342...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5192, #subsample_inputs: 5192
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.713      |
| AbsLearnSignalNew       | 0.713      |
| AbsLearningOld          | 0.713      |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 0.982485   |
| AveragePolicyStd        | 0.806889   |
| AverageReturn           | 545        |
| Entropy                 | 7.2139     |
| EnvExecTime             | 2.77       |
| ExplainedVariance       | 0.491      |
| Iteration               | 342        |
| ItrTime                 | 10.9       |
| LossAfter               | 0.118963   |
| LossBefore              | 0.175958   |
| MaxReturn               | 1.33e+03   |
| MeanKL                  | 0.00986187 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 74.6       |
| NumTrajs                | 17         |
| Perplexity              | 1358.18    |
| PolicyExecTime          | 0.521      |
| ProcessExecTime         | 0.0673     |
| StdReturn               | 391        |
| Time                    | 3.76e+03   |
| dLoss                   | 0.0569956  |
----------------------------------------
itr #343 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 343...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5423, #subsample_inputs: 5423
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.695     |
| AbsLearnSignalNew       | 0.695     |
| AbsLearningOld          | 0.695     |
| AverageDiscountedReturn | 142       |
| AveragePhiLoss          | 0.976071  |
| AveragePolicyStd        | 0.807476  |
| AverageReturn           | 736       |
| Entropy                 | 7.21871   |
| EnvExecTime             | 3.43      |
| ExplainedVariance       | 0.401     |
| Iteration               | 343       |
| ItrTime                 | 11        |
| LossAfter               | -0.272151 |
| LossBefore              | -0.227846 |
| MaxReturn               | 1.6e+03   |
| MeanKL                  | 0.006416  |
| MeanKLBefore            | 0.0       |
| MinReturn               | 89.6      |
| NumTrajs                | 16        |
| Perplexity              | 1364.73   |
| PolicyExecTime          | 0.694     |
| ProcessExecTime         | 0.0897    |
| StdReturn               | 374       |
| Time                    | 3.77e+03  |
| dLoss                   | 0.0443052 |
---------------------------------------
itr #344 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 344...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5154, #subsample_inputs: 5154
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.685     |
| AbsLearnSignalNew       | 0.685     |
| AbsLearningOld          | 0.685     |
| AverageDiscountedReturn | 122       |
| AveragePhiLoss          | 0.982931  |
| AveragePolicyStd        | 0.806355  |
| AverageReturn           | 561       |
| Entropy                 | 7.2109    |
| EnvExecTime             | 3.26      |
| ExplainedVariance       | 0.312     |
| Iteration               | 344       |
| ItrTime                 | 11.8      |
| LossAfter               | -0.455317 |
| LossBefore              | -0.398602 |
| MaxReturn               | 1.32e+03  |
| MeanKL                  | 0.0098163 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 50.4      |
| NumTrajs                | 16        |
| Perplexity              | 1354.11   |
| PolicyExecTime          | 0.644     |
| ProcessExecTime         | 0.0832    |
| StdReturn               | 401       |
| Time                    | 3.78e+03  |
| dLoss                   | 0.0567146 |
---------------------------------------
itr #345 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 345...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5107, #subsample_inputs: 5107
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.709      |
| AbsLearnSignalNew       | 0.709      |
| AbsLearningOld          | 0.709      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 0.969487   |
| AveragePolicyStd        | 0.80697    |
| AverageReturn           | 583        |
| Entropy                 | 7.21515    |
| EnvExecTime             | 3.12       |
| ExplainedVariance       | 0.355      |
| Iteration               | 345        |
| ItrTime                 | 10.9       |
| LossAfter               | -0.311829  |
| LossBefore              | -0.251811  |
| MaxReturn               | 1.8e+03    |
| MeanKL                  | 0.00993592 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 30         |
| NumTrajs                | 16         |
| Perplexity              | 1359.88    |
| PolicyExecTime          | 0.611      |
| ProcessExecTime         | 0.0772     |
| StdReturn               | 437        |
| Time                    | 3.79e+03   |
| dLoss                   | 0.0600182  |
----------------------------------------
itr #346 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 346...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5054, #subsample_inputs: 5054
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.715      |
| AbsLearnSignalNew       | 0.715      |
| AbsLearningOld          | 0.715      |
| AverageDiscountedReturn | 101        |
| AveragePhiLoss          | 0.980045   |
| AveragePolicyStd        | 0.806414   |
| AverageReturn           | 418        |
| Entropy                 | 7.21089    |
| EnvExecTime             | 3.46       |
| ExplainedVariance       | 0.512      |
| Iteration               | 346        |
| ItrTime                 | 11.3       |
| LossAfter               | -1.07523   |
| LossBefore              | -1.03359   |
| MaxReturn               | 1.35e+03   |
| MeanKL                  | 0.00641742 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 36.6       |
| NumTrajs                | 19         |
| Perplexity              | 1354.1     |
| PolicyExecTime          | 0.686      |
| ProcessExecTime         | 0.0844     |
| StdReturn               | 368        |
| Time                    | 3.81e+03   |
| dLoss                   | 0.0416427  |
----------------------------------------
itr #347 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 347...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5092, #subsample_inputs: 5092
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.517      |
| AbsLearnSignalNew       | 0.517      |
| AbsLearningOld          | 0.517      |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 0.982859   |
| AveragePolicyStd        | 0.805602   |
| AverageReturn           | 834        |
| Entropy                 | 7.20453    |
| EnvExecTime             | 3.06       |
| ExplainedVariance       | -4.2       |
| Iteration               | 347        |
| ItrTime                 | 11.6       |
| LossAfter               | -0.579606  |
| LossBefore              | -0.527502  |
| MaxReturn               | 2.51e+03   |
| MeanKL                  | 0.00992313 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 88.7       |
| NumTrajs                | 13         |
| Perplexity              | 1345.51    |
| PolicyExecTime          | 0.609      |
| ProcessExecTime         | 0.0776     |
| StdReturn               | 707        |
| Time                    | 3.82e+03   |
| dLoss                   | 0.0521047  |
----------------------------------------
itr #348 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 348...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5378, #subsample_inputs: 5378
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.66      |
| AbsLearnSignalNew       | 0.66      |
| AbsLearningOld          | 0.66      |
| AverageDiscountedReturn | 126       |
| AveragePhiLoss          | 0.980026  |
| AveragePolicyStd        | 0.804534  |
| AverageReturn           | 761       |
| Entropy                 | 7.19617   |
| EnvExecTime             | 3.17      |
| ExplainedVariance       | 0.452     |
| Iteration               | 348       |
| ItrTime                 | 10.5      |
| LossAfter               | -0.911259 |
| LossBefore              | -0.857944 |
| MaxReturn               | 2.21e+03  |
| MeanKL                  | 0.0099112 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 53.1      |
| NumTrajs                | 14        |
| Perplexity              | 1334.32   |
| PolicyExecTime          | 0.649     |
| ProcessExecTime         | 0.0876    |
| StdReturn               | 542       |
| Time                    | 3.83e+03  |
| dLoss                   | 0.0533145 |
---------------------------------------
itr #349 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 349...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5059, #subsample_inputs: 5059
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.668      |
| AbsLearnSignalNew       | 0.668      |
| AbsLearningOld          | 0.668      |
| AverageDiscountedReturn | 106        |
| AveragePhiLoss          | 0.969794   |
| AveragePolicyStd        | 0.801581   |
| AverageReturn           | 584        |
| Entropy                 | 7.17479    |
| EnvExecTime             | 3.26       |
| ExplainedVariance       | 0.521      |
| Iteration               | 349        |
| ItrTime                 | 11.5       |
| LossAfter               | -0.973532  |
| LossBefore              | -0.910918  |
| MaxReturn               | 1.3e+03    |
| MeanKL                  | 0.00993118 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 48.1       |
| NumTrajs                | 14         |
| Perplexity              | 1306.08    |
| PolicyExecTime          | 0.632      |
| ProcessExecTime         | 0.0834     |
| StdReturn               | 395        |
| Time                    | 3.84e+03   |
| dLoss                   | 0.0626142  |
----------------------------------------
itr #350 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 350...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5395, #subsample_inputs: 5395
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.671      |
| AbsLearnSignalNew       | 0.671      |
| AbsLearningOld          | 0.671      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 0.974534   |
| AveragePolicyStd        | 0.799796   |
| AverageReturn           | 693        |
| Entropy                 | 7.16164    |
| EnvExecTime             | 2.83       |
| ExplainedVariance       | 0.469      |
| Iteration               | 350        |
| ItrTime                 | 11.4       |
| LossAfter               | -1.23999   |
| LossBefore              | -1.18994   |
| MaxReturn               | 1.56e+03   |
| MeanKL                  | 0.00640607 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 34.9       |
| NumTrajs                | 15         |
| Perplexity              | 1289.03    |
| PolicyExecTime          | 0.529      |
| ProcessExecTime         | 0.0696     |
| StdReturn               | 468        |
| Time                    | 3.85e+03   |
| dLoss                   | 0.0500485  |
----------------------------------------
itr #351 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 351...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5185, #subsample_inputs: 5185
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.696      |
| AbsLearnSignalNew       | 0.696      |
| AbsLearningOld          | 0.696      |
| AverageDiscountedReturn | 113        |
| AveragePhiLoss          | 0.976014   |
| AveragePolicyStd        | 0.797609   |
| AverageReturn           | 564        |
| Entropy                 | 7.14567    |
| EnvExecTime             | 3.44       |
| ExplainedVariance       | 0.471      |
| Iteration               | 351        |
| ItrTime                 | 11         |
| LossAfter               | -0.337138  |
| LossBefore              | -0.282656  |
| MaxReturn               | 2.07e+03   |
| MeanKL                  | 0.00987965 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 61.3       |
| NumTrajs                | 16         |
| Perplexity              | 1268.6     |
| PolicyExecTime          | 0.706      |
| ProcessExecTime         | 0.0852     |
| StdReturn               | 546        |
| Time                    | 3.86e+03   |
| dLoss                   | 0.0544828  |
----------------------------------------
itr #352 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 352...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5448, #subsample_inputs: 5448
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.7        |
| AbsLearnSignalNew       | 0.7        |
| AbsLearningOld          | 0.7        |
| AverageDiscountedReturn | 110        |
| AveragePhiLoss          | 0.975575   |
| AveragePolicyStd        | 0.796998   |
| AverageReturn           | 555        |
| Entropy                 | 7.14266    |
| EnvExecTime             | 3.23       |
| ExplainedVariance       | 0.424      |
| Iteration               | 352        |
| ItrTime                 | 11.9       |
| LossAfter               | -0.642464  |
| LossBefore              | -0.598287  |
| MaxReturn               | 1.24e+03   |
| MeanKL                  | 0.00650616 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 27.3       |
| NumTrajs                | 17         |
| Perplexity              | 1264.78    |
| PolicyExecTime          | 0.645      |
| ProcessExecTime         | 0.0846     |
| StdReturn               | 370        |
| Time                    | 3.87e+03   |
| dLoss                   | 0.0441766  |
----------------------------------------
itr #353 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 353...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5014, #subsample_inputs: 5014
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.684      |
| AbsLearnSignalNew       | 0.684      |
| AbsLearningOld          | 0.685      |
| AverageDiscountedReturn | 113        |
| AveragePhiLoss          | 0.975586   |
| AveragePolicyStd        | 0.793279   |
| AverageReturn           | 593        |
| Entropy                 | 7.11295    |
| EnvExecTime             | 2.87       |
| ExplainedVariance       | 0.481      |
| Iteration               | 353        |
| ItrTime                 | 10.7       |
| LossAfter               | -0.41245   |
| LossBefore              | -0.353991  |
| MaxReturn               | 1.67e+03   |
| MeanKL                  | 0.00994832 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 46.9       |
| NumTrajs                | 15         |
| Perplexity              | 1227.77    |
| PolicyExecTime          | 0.55       |
| ProcessExecTime         | 0.0704     |
| StdReturn               | 482        |
| Time                    | 3.88e+03   |
| dLoss                   | 0.0584593  |
----------------------------------------
itr #354 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 354...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5275, #subsample_inputs: 5275
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.622      |
| AbsLearnSignalNew       | 0.622      |
| AbsLearningOld          | 0.622      |
| AverageDiscountedReturn | 134        |
| AveragePhiLoss          | 0.972812   |
| AveragePolicyStd        | 0.792332   |
| AverageReturn           | 670        |
| Entropy                 | 7.10493    |
| EnvExecTime             | 3.68       |
| ExplainedVariance       | 0.0322     |
| Iteration               | 354        |
| ItrTime                 | 11.4       |
| LossAfter               | -0.523329  |
| LossBefore              | -0.455061  |
| MaxReturn               | 1.12e+03   |
| MeanKL                  | 0.00989563 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 36.2       |
| NumTrajs                | 17         |
| Perplexity              | 1217.96    |
| PolicyExecTime          | 0.753      |
| ProcessExecTime         | 0.0945     |
| StdReturn               | 273        |
| Time                    | 3.9e+03    |
| dLoss                   | 0.0682683  |
----------------------------------------
itr #355 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 355...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5338, #subsample_inputs: 5338
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.538     |
| AbsLearnSignalNew       | 0.538     |
| AbsLearningOld          | 0.538     |
| AverageDiscountedReturn | 118       |
| AveragePhiLoss          | 0.974047  |
| AveragePolicyStd        | 0.791773  |
| AverageReturn           | 628       |
| Entropy                 | 7.10209   |
| EnvExecTime             | 3.23      |
| ExplainedVariance       | -0.175    |
| Iteration               | 355       |
| ItrTime                 | 11.8      |
| LossAfter               | -0.746827 |
| LossBefore              | -0.691702 |
| MaxReturn               | 1.69e+03  |
| MeanKL                  | 0.009925  |
| MeanKLBefore            | 0.0       |
| MinReturn               | 54.8      |
| NumTrajs                | 16        |
| Perplexity              | 1214.5    |
| PolicyExecTime          | 0.677     |
| ProcessExecTime         | 0.0833    |
| StdReturn               | 470       |
| Time                    | 3.91e+03  |
| dLoss                   | 0.0551243 |
---------------------------------------
itr #356 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 356...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5174, #subsample_inputs: 5174
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.689     |
| AbsLearnSignalNew       | 0.689     |
| AbsLearningOld          | 0.689     |
| AverageDiscountedReturn | 119       |
| AveragePhiLoss          | 0.96629   |
| AveragePolicyStd        | 0.79344   |
| AverageReturn           | 582       |
| Entropy                 | 7.11326   |
| EnvExecTime             | 2.87      |
| ExplainedVariance       | 0.484     |
| Iteration               | 356       |
| ItrTime                 | 10.8      |
| LossAfter               | -0.679047 |
| LossBefore              | -0.620376 |
| MaxReturn               | 1.69e+03  |
| MeanKL                  | 0.009912  |
| MeanKLBefore            | 0.0       |
| MinReturn               | 63        |
| NumTrajs                | 18        |
| Perplexity              | 1228.15   |
| PolicyExecTime          | 0.565     |
| ProcessExecTime         | 0.0724    |
| StdReturn               | 491       |
| Time                    | 3.92e+03  |
| dLoss                   | 0.0586709 |
---------------------------------------
itr #357 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 357...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5233, #subsample_inputs: 5233
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.748      |
| AbsLearnSignalNew       | 0.748      |
| AbsLearningOld          | 0.748      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 0.973789   |
| AveragePolicyStd        | 0.793782   |
| AverageReturn           | 586        |
| Entropy                 | 7.11552    |
| EnvExecTime             | 3.36       |
| ExplainedVariance       | 0.361      |
| Iteration               | 357        |
| ItrTime                 | 11.4       |
| LossAfter               | -1.12483   |
| LossBefore              | -1.06956   |
| MaxReturn               | 1.31e+03   |
| MeanKL                  | 0.00996877 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 45.8       |
| NumTrajs                | 18         |
| Perplexity              | 1230.93    |
| PolicyExecTime          | 0.672      |
| ProcessExecTime         | 0.0882     |
| StdReturn               | 393        |
| Time                    | 3.93e+03   |
| dLoss                   | 0.0552742  |
----------------------------------------
itr #358 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 358...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5573, #subsample_inputs: 5573
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.729      |
| AbsLearnSignalNew       | 0.729      |
| AbsLearningOld          | 0.729      |
| AverageDiscountedReturn | 117        |
| AveragePhiLoss          | 0.97933    |
| AveragePolicyStd        | 0.791638   |
| AverageReturn           | 562        |
| Entropy                 | 7.09965    |
| EnvExecTime             | 3.48       |
| ExplainedVariance       | 0.471      |
| Iteration               | 358        |
| ItrTime                 | 12.3       |
| LossAfter               | -0.520443  |
| LossBefore              | -0.468794  |
| MaxReturn               | 1.26e+03   |
| MeanKL                  | 0.00990325 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 52.1       |
| NumTrajs                | 18         |
| Perplexity              | 1211.55    |
| PolicyExecTime          | 0.668      |
| ProcessExecTime         | 0.0871     |
| StdReturn               | 365        |
| Time                    | 3.94e+03   |
| dLoss                   | 0.0516494  |
----------------------------------------
itr #359 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 359...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5423, #subsample_inputs: 5423
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.696      |
| AbsLearnSignalNew       | 0.696      |
| AbsLearningOld          | 0.696      |
| AverageDiscountedReturn | 133        |
| AveragePhiLoss          | 0.971797   |
| AveragePolicyStd        | 0.797331   |
| AverageReturn           | 629        |
| Entropy                 | 7.14132    |
| EnvExecTime             | 3.09       |
| ExplainedVariance       | 0.417      |
| Iteration               | 359        |
| ItrTime                 | 10.8       |
| LossAfter               | -0.228304  |
| LossBefore              | -0.1727    |
| MaxReturn               | 1.1e+03    |
| MeanKL                  | 0.00980493 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 70.1       |
| NumTrajs                | 17         |
| Perplexity              | 1263.09    |
| PolicyExecTime          | 0.611      |
| ProcessExecTime         | 0.0819     |
| StdReturn               | 298        |
| Time                    | 3.95e+03   |
| dLoss                   | 0.055604   |
----------------------------------------
itr #360 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 360...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5259, #subsample_inputs: 5259
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.464      |
| AbsLearnSignalNew       | 0.464      |
| AbsLearningOld          | 0.464      |
| AverageDiscountedReturn | 109        |
| AveragePhiLoss          | 0.992414   |
| AveragePolicyStd        | 0.798586   |
| AverageReturn           | 647        |
| Entropy                 | 7.14965    |
| EnvExecTime             | 3.25       |
| ExplainedVariance       | -1.92      |
| Iteration               | 360        |
| ItrTime                 | 11.3       |
| LossAfter               | -0.0100308 |
| LossBefore              | 0.0335584  |
| MaxReturn               | 2.38e+03   |
| MeanKL                  | 0.00985587 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 44.6       |
| NumTrajs                | 16         |
| Perplexity              | 1273.66    |
| PolicyExecTime          | 0.649      |
| ProcessExecTime         | 0.0859     |
| StdReturn               | 670        |
| Time                    | 3.97e+03   |
| dLoss                   | 0.0435892  |
----------------------------------------
itr #361 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 361...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5141, #subsample_inputs: 5141
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
-----------------------------------------
| AbsLearnSignal          | 0.753       |
| AbsLearnSignalNew       | 0.753       |
| AbsLearningOld          | 0.753       |
| AverageDiscountedReturn | 128         |
| AveragePhiLoss          | 0.975535    |
| AveragePolicyStd        | 0.80081     |
| AverageReturn           | 773         |
| Entropy                 | 7.16698     |
| EnvExecTime             | 2.97        |
| ExplainedVariance       | 0.223       |
| Iteration               | 361         |
| ItrTime                 | 11.3        |
| LossAfter               | -0.00518964 |
| LossBefore              | 0.0456348   |
| MaxReturn               | 1.98e+03    |
| MeanKL                  | 0.0098325   |
| MeanKLBefore            | 0.0         |
| MinReturn               | 43.9        |
| NumTrajs                | 13          |
| Perplexity              | 1295.93     |
| PolicyExecTime          | 0.613       |
| ProcessExecTime         | 0.0747      |
| StdReturn               | 521         |
| Time                    | 3.98e+03    |
| dLoss                   | 0.0508245   |
-----------------------------------------
itr #362 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 362...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5211, #subsample_inputs: 5211
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.686      |
| AbsLearnSignalNew       | 0.686      |
| AbsLearningOld          | 0.686      |
| AverageDiscountedReturn | 107        |
| AveragePhiLoss          | 0.97022    |
| AveragePolicyStd        | 0.804539   |
| AverageReturn           | 588        |
| Entropy                 | 7.19579    |
| EnvExecTime             | 3.28       |
| ExplainedVariance       | 0.516      |
| Iteration               | 362        |
| ItrTime                 | 10.5       |
| LossAfter               | -0.977397  |
| LossBefore              | -0.933563  |
| MaxReturn               | 1.44e+03   |
| MeanKL                  | 0.00649496 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 57.7       |
| NumTrajs                | 16         |
| Perplexity              | 1333.8     |
| PolicyExecTime          | 0.66       |
| ProcessExecTime         | 0.0857     |
| StdReturn               | 453        |
| Time                    | 3.99e+03   |
| dLoss                   | 0.0438334  |
----------------------------------------
itr #363 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 363...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5280, #subsample_inputs: 5280
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.52       |
| AbsLearnSignalNew       | 0.52       |
| AbsLearningOld          | 0.52       |
| AverageDiscountedReturn | 127        |
| AveragePhiLoss          | 0.975787   |
| AveragePolicyStd        | 0.804435   |
| AverageReturn           | 836        |
| Entropy                 | 7.19574    |
| EnvExecTime             | 3.06       |
| ExplainedVariance       | -0.95      |
| Iteration               | 363        |
| ItrTime                 | 11.6       |
| LossAfter               | -0.638636  |
| LossBefore              | -0.568285  |
| MaxReturn               | 2.17e+03   |
| MeanKL                  | 0.00990807 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 63.3       |
| NumTrajs                | 13         |
| Perplexity              | 1333.74    |
| PolicyExecTime          | 0.606      |
| ProcessExecTime         | 0.0851     |
| StdReturn               | 614        |
| Time                    | 4e+03      |
| dLoss                   | 0.0703514  |
----------------------------------------
itr #364 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 364...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5624, #subsample_inputs: 5624
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.679      |
| AbsLearnSignalNew       | 0.679      |
| AbsLearningOld          | 0.679      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 0.98166    |
| AveragePolicyStd        | 0.804811   |
| AverageReturn           | 514        |
| Entropy                 | 7.19718    |
| EnvExecTime             | 3.03       |
| ExplainedVariance       | 0.377      |
| Iteration               | 364        |
| ItrTime                 | 12.3       |
| LossAfter               | -0.381908  |
| LossBefore              | -0.338857  |
| MaxReturn               | 1.55e+03   |
| MeanKL                  | 0.00644769 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 55.2       |
| NumTrajs                | 20         |
| Perplexity              | 1335.65    |
| PolicyExecTime          | 0.577      |
| ProcessExecTime         | 0.0747     |
| StdReturn               | 349        |
| Time                    | 4.01e+03   |
| dLoss                   | 0.0430509  |
----------------------------------------
itr #365 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 365...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5408, #subsample_inputs: 5408
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.652      |
| AbsLearnSignalNew       | 0.652      |
| AbsLearningOld          | 0.652      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 0.975591   |
| AveragePolicyStd        | 0.803608   |
| AverageReturn           | 762        |
| Entropy                 | 7.18762    |
| EnvExecTime             | 3.49       |
| ExplainedVariance       | 0.134      |
| Iteration               | 365        |
| ItrTime                 | 11         |
| LossAfter               | -0.510325  |
| LossBefore              | -0.454494  |
| MaxReturn               | 2.06e+03   |
| MeanKL                  | 0.00976797 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 41.4       |
| NumTrajs                | 15         |
| Perplexity              | 1322.95    |
| PolicyExecTime          | 0.71       |
| ProcessExecTime         | 0.0916     |
| StdReturn               | 594        |
| Time                    | 4.02e+03   |
| dLoss                   | 0.0558312  |
----------------------------------------
itr #366 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 366...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5174, #subsample_inputs: 5174
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.678      |
| AbsLearnSignalNew       | 0.678      |
| AbsLearningOld          | 0.678      |
| AverageDiscountedReturn | 106        |
| AveragePhiLoss          | 0.96282    |
| AveragePolicyStd        | 0.805557   |
| AverageReturn           | 532        |
| Entropy                 | 7.202      |
| EnvExecTime             | 3.58       |
| ExplainedVariance       | 0.54       |
| Iteration               | 366        |
| ItrTime                 | 12.1       |
| LossAfter               | -0.320774  |
| LossBefore              | -0.261809  |
| MaxReturn               | 1.1e+03    |
| MeanKL                  | 0.00988542 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 40.1       |
| NumTrajs                | 18         |
| Perplexity              | 1342.11    |
| PolicyExecTime          | 0.712      |
| ProcessExecTime         | 0.0902     |
| StdReturn               | 373        |
| Time                    | 4.03e+03   |
| dLoss                   | 0.0589648  |
----------------------------------------
itr #367 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 367...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5490, #subsample_inputs: 5490
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.618      |
| AbsLearnSignalNew       | 0.618      |
| AbsLearningOld          | 0.618      |
| AverageDiscountedReturn | 118        |
| AveragePhiLoss          | 0.9827     |
| AveragePolicyStd        | 0.804695   |
| AverageReturn           | 630        |
| Entropy                 | 7.196      |
| EnvExecTime             | 2.98       |
| ExplainedVariance       | -0.575     |
| Iteration               | 367        |
| ItrTime                 | 11.7       |
| LossAfter               | -0.670001  |
| LossBefore              | -0.627549  |
| MaxReturn               | 1.78e+03   |
| MeanKL                  | 0.00641222 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 48.5       |
| NumTrajs                | 13         |
| Perplexity              | 1334.08    |
| PolicyExecTime          | 0.55       |
| ProcessExecTime         | 0.0731     |
| StdReturn               | 471        |
| Time                    | 4.05e+03   |
| dLoss                   | 0.0424518  |
----------------------------------------
itr #368 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 368...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5167, #subsample_inputs: 5167
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.604      |
| AbsLearnSignalNew       | 0.604      |
| AbsLearningOld          | 0.604      |
| AverageDiscountedReturn | 146        |
| AveragePhiLoss          | 0.978451   |
| AveragePolicyStd        | 0.805719   |
| AverageReturn           | 890        |
| Entropy                 | 7.20394    |
| EnvExecTime             | 3.13       |
| ExplainedVariance       | 0.0562     |
| Iteration               | 368        |
| ItrTime                 | 10.4       |
| LossAfter               | -0.718069  |
| LossBefore              | -0.660574  |
| MaxReturn               | 2.15e+03   |
| MeanKL                  | 0.00988939 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 96.7       |
| NumTrajs                | 13         |
| Perplexity              | 1344.72    |
| PolicyExecTime          | 0.649      |
| ProcessExecTime         | 0.0848     |
| StdReturn               | 581        |
| Time                    | 4.06e+03   |
| dLoss                   | 0.0574949  |
----------------------------------------
itr #369 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 369...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5134, #subsample_inputs: 5134
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.698     |
| AbsLearnSignalNew       | 0.698     |
| AbsLearningOld          | 0.697     |
| AverageDiscountedReturn | 114       |
| AveragePhiLoss          | 0.981258  |
| AveragePolicyStd        | 0.80747   |
| AverageReturn           | 490       |
| Entropy                 | 7.21756   |
| EnvExecTime             | 3.1       |
| ExplainedVariance       | 0.486     |
| Iteration               | 369       |
| ItrTime                 | 11.6      |
| LossAfter               | 0.407053  |
| LossBefore              | 0.447397  |
| MaxReturn               | 1.23e+03  |
| MeanKL                  | 0.0064699 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 37.1      |
| NumTrajs                | 18        |
| Perplexity              | 1363.17   |
| PolicyExecTime          | 0.615     |
| ProcessExecTime         | 0.0834    |
| StdReturn               | 354       |
| Time                    | 4.07e+03  |
| dLoss                   | 0.040344  |
---------------------------------------
itr #370 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 370...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5183, #subsample_inputs: 5183
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.6        |
| AbsLearnSignalNew       | 0.6        |
| AbsLearningOld          | 0.6        |
| AverageDiscountedReturn | 112        |
| AveragePhiLoss          | 0.959702   |
| AveragePolicyStd        | 0.803058   |
| AverageReturn           | 705        |
| Entropy                 | 7.18486    |
| EnvExecTime             | 3.21       |
| ExplainedVariance       | -0.567     |
| Iteration               | 370        |
| ItrTime                 | 11.2       |
| LossAfter               | 0.168164   |
| LossBefore              | 0.211719   |
| MaxReturn               | 1.3e+03    |
| MeanKL                  | 0.00646926 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 48.9       |
| NumTrajs                | 13         |
| Perplexity              | 1319.31    |
| PolicyExecTime          | 0.615      |
| ProcessExecTime         | 0.0748     |
| StdReturn               | 483        |
| Time                    | 4.08e+03   |
| dLoss                   | 0.0435555  |
----------------------------------------
itr #371 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 371...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5130, #subsample_inputs: 5130
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.575      |
| AbsLearnSignalNew       | 0.575      |
| AbsLearningOld          | 0.575      |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 0.96638    |
| AveragePolicyStd        | 0.802951   |
| AverageReturn           | 735        |
| Entropy                 | 7.18277    |
| EnvExecTime             | 3.63       |
| ExplainedVariance       | 0.285      |
| Iteration               | 371        |
| ItrTime                 | 11.1       |
| LossAfter               | 0.0941705  |
| LossBefore              | 0.150104   |
| MaxReturn               | 1.91e+03   |
| MeanKL                  | 0.00992586 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 24.9       |
| NumTrajs                | 13         |
| Perplexity              | 1316.55    |
| PolicyExecTime          | 0.735      |
| ProcessExecTime         | 0.0894     |
| StdReturn               | 535        |
| Time                    | 4.09e+03   |
| dLoss                   | 0.0559336  |
----------------------------------------
itr #372 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 372...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5039, #subsample_inputs: 5039
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.729      |
| AbsLearnSignalNew       | 0.729      |
| AbsLearningOld          | 0.729      |
| AverageDiscountedReturn | 109        |
| AveragePhiLoss          | 0.97406    |
| AveragePolicyStd        | 0.801078   |
| AverageReturn           | 618        |
| Entropy                 | 7.16795    |
| EnvExecTime             | 3.33       |
| ExplainedVariance       | 0.473      |
| Iteration               | 372        |
| ItrTime                 | 11.8       |
| LossAfter               | -0.180516  |
| LossBefore              | -0.124358  |
| MaxReturn               | 2.28e+03   |
| MeanKL                  | 0.00999387 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 35.2       |
| NumTrajs                | 15         |
| Perplexity              | 1297.18    |
| PolicyExecTime          | 0.668      |
| ProcessExecTime         | 0.0853     |
| StdReturn               | 607        |
| Time                    | 4.1e+03    |
| dLoss                   | 0.0561577  |
----------------------------------------
itr #373 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 373...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5096, #subsample_inputs: 5096
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.716      |
| AbsLearnSignalNew       | 0.716      |
| AbsLearningOld          | 0.716      |
| AverageDiscountedReturn | 116        |
| AveragePhiLoss          | 0.979372   |
| AveragePolicyStd        | 0.799914   |
| AverageReturn           | 559        |
| Entropy                 | 7.15797    |
| EnvExecTime             | 2.83       |
| ExplainedVariance       | 0.557      |
| Iteration               | 373        |
| ItrTime                 | 10.4       |
| LossAfter               | 0.521904   |
| LossBefore              | 0.581919   |
| MaxReturn               | 1.56e+03   |
| MeanKL                  | 0.00998997 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 48.5       |
| NumTrajs                | 17         |
| Perplexity              | 1284.3     |
| PolicyExecTime          | 0.549      |
| ProcessExecTime         | 0.072      |
| StdReturn               | 498        |
| Time                    | 4.11e+03   |
| dLoss                   | 0.0600153  |
----------------------------------------
itr #374 | 
Mem: 753.675781
Obtaining samples...
Obtaining samples for iteration 374...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5630, #subsample_inputs: 5630
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.66       |
| AbsLearnSignalNew       | 0.66       |
| AbsLearningOld          | 0.66       |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 0.982245   |
| AveragePolicyStd        | 0.799911   |
| AverageReturn           | 648        |
| Entropy                 | 7.15879    |
| EnvExecTime             | 3.55       |
| ExplainedVariance       | 0.198      |
| Iteration               | 374        |
| ItrTime                 | 11.7       |
| LossAfter               | 0.770949   |
| LossBefore              | 0.828837   |
| MaxReturn               | 1.9e+03    |
| MeanKL                  | 0.00986079 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 79.3       |
| NumTrajs                | 15         |
| Perplexity              | 1285.36    |
| PolicyExecTime          | 0.706      |
| ProcessExecTime         | 0.0906     |
| StdReturn               | 462        |
| Time                    | 4.13e+03   |
| dLoss                   | 0.0578882  |
----------------------------------------
itr #375 | 
Mem: 754.152344
Obtaining samples...
Obtaining samples for iteration 375...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5075, #subsample_inputs: 5075
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.681      |
| AbsLearnSignalNew       | 0.681      |
| AbsLearningOld          | 0.681      |
| AverageDiscountedReturn | 137        |
| AveragePhiLoss          | 0.97653    |
| AveragePolicyStd        | 0.803143   |
| AverageReturn           | 748        |
| Entropy                 | 7.18085    |
| EnvExecTime             | 3.12       |
| ExplainedVariance       | 0.456      |
| Iteration               | 375        |
| ItrTime                 | 11.6       |
| LossAfter               | 2.01079    |
| LossBefore              | 2.06752    |
| MaxReturn               | 1.91e+03   |
| MeanKL                  | 0.00640964 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 66.9       |
| NumTrajs                | 14         |
| Perplexity              | 1314.02    |
| PolicyExecTime          | 0.62       |
| ProcessExecTime         | 0.0788     |
| StdReturn               | 469        |
| Time                    | 4.14e+03   |
| dLoss                   | 0.0567279  |
----------------------------------------
itr #376 | 
Mem: 754.152344
Obtaining samples...
Obtaining samples for iteration 376...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5222, #subsample_inputs: 5222
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.716      |
| AbsLearnSignalNew       | 0.716      |
| AbsLearningOld          | 0.716      |
| AverageDiscountedReturn | 118        |
| AveragePhiLoss          | 0.975444   |
| AveragePolicyStd        | 0.803206   |
| AverageReturn           | 719        |
| Entropy                 | 7.18046    |
| EnvExecTime             | 3.09       |
| ExplainedVariance       | 0.496      |
| Iteration               | 376        |
| ItrTime                 | 10.4       |
| LossAfter               | 1.47135    |
| LossBefore              | 1.5151     |
| MaxReturn               | 2.3e+03    |
| MeanKL                  | 0.00642798 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 55.1       |
| NumTrajs                | 14         |
| Perplexity              | 1313.51    |
| PolicyExecTime          | 0.608      |
| ProcessExecTime         | 0.0802     |
| StdReturn               | 681        |
| Time                    | 4.15e+03   |
| dLoss                   | 0.043745   |
----------------------------------------
itr #377 | 
Mem: 754.152344
Obtaining samples...
Obtaining samples for iteration 377...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5227, #subsample_inputs: 5227
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.716     |
| AbsLearnSignalNew       | 0.716     |
| AbsLearningOld          | 0.716     |
| AverageDiscountedReturn | 112       |
| AveragePhiLoss          | 0.973169  |
| AveragePolicyStd        | 0.804611  |
| AverageReturn           | 560       |
| Entropy                 | 7.19126   |
| EnvExecTime             | 3.85      |
| ExplainedVariance       | 0.606     |
| Iteration               | 377       |
| ItrTime                 | 12.2      |
| LossAfter               | 0.55293   |
| LossBefore              | 0.598564  |
| MaxReturn               | 2.02e+03  |
| MeanKL                  | 0.006426  |
| MeanKLBefore            | 0.0       |
| MinReturn               | 39.8      |
| NumTrajs                | 16        |
| Perplexity              | 1327.78   |
| PolicyExecTime          | 0.756     |
| ProcessExecTime         | 0.0928    |
| StdReturn               | 567       |
| Time                    | 4.16e+03  |
| dLoss                   | 0.0456341 |
---------------------------------------
itr #378 | 
Mem: 754.152344
Obtaining samples...
Obtaining samples for iteration 378...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5412, #subsample_inputs: 5412
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.701      |
| AbsLearnSignalNew       | 0.701      |
| AbsLearningOld          | 0.701      |
| AverageDiscountedReturn | 133        |
| AveragePhiLoss          | 0.965688   |
| AveragePolicyStd        | 0.803966   |
| AverageReturn           | 728        |
| Entropy                 | 7.18574    |
| EnvExecTime             | 2.93       |
| ExplainedVariance       | 0.285      |
| Iteration               | 378        |
| ItrTime                 | 11.7       |
| LossAfter               | 0.723319   |
| LossBefore              | 0.769206   |
| MaxReturn               | 2e+03      |
| MeanKL                  | 0.00643982 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 82.5       |
| NumTrajs                | 15         |
| Perplexity              | 1320.47    |
| PolicyExecTime          | 0.589      |
| ProcessExecTime         | 0.0761     |
| StdReturn               | 517        |
| Time                    | 4.17e+03   |
| dLoss                   | 0.0458863  |
----------------------------------------
itr #379 | 
Mem: 754.152344
Obtaining samples...
Obtaining samples for iteration 379...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5012, #subsample_inputs: 5012
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.689      |
| AbsLearnSignalNew       | 0.689      |
| AbsLearningOld          | 0.689      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 0.977045   |
| AveragePolicyStd        | 0.803483   |
| AverageReturn           | 493        |
| Entropy                 | 7.18201    |
| EnvExecTime             | 3.21       |
| ExplainedVariance       | 0.492      |
| Iteration               | 379        |
| ItrTime                 | 10.1       |
| LossAfter               | 0.207245   |
| LossBefore              | 0.266403   |
| MaxReturn               | 1.45e+03   |
| MeanKL                  | 0.00985238 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 67.5       |
| NumTrajs                | 19         |
| Perplexity              | 1315.55    |
| PolicyExecTime          | 0.652      |
| ProcessExecTime         | 0.0845     |
| StdReturn               | 329        |
| Time                    | 4.18e+03   |
| dLoss                   | 0.0591577  |
----------------------------------------
itr #380 | 
Mem: 754.152344
Obtaining samples...
Obtaining samples for iteration 380...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5095, #subsample_inputs: 5095
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.72       |
| AbsLearnSignalNew       | 0.72       |
| AbsLearningOld          | 0.72       |
| AverageDiscountedReturn | 129        |
| AveragePhiLoss          | 0.973001   |
| AveragePolicyStd        | 0.805596   |
| AverageReturn           | 591        |
| Entropy                 | 7.19665    |
| EnvExecTime             | 3.44       |
| ExplainedVariance       | 0.351      |
| Iteration               | 380        |
| ItrTime                 | 11.7       |
| LossAfter               | 0.509694   |
| LossBefore              | 0.564765   |
| MaxReturn               | 1.15e+03   |
| MeanKL                  | 0.00999105 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 143        |
| NumTrajs                | 16         |
| Perplexity              | 1334.95    |
| PolicyExecTime          | 0.693      |
| ProcessExecTime         | 0.0872     |
| StdReturn               | 306        |
| Time                    | 4.19e+03   |
| dLoss                   | 0.0550714  |
----------------------------------------
itr #381 | 
Mem: 754.152344
Obtaining samples...
Obtaining samples for iteration 381...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5150, #subsample_inputs: 5150
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.662      |
| AbsLearnSignalNew       | 0.662      |
| AbsLearningOld          | 0.662      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 0.98269    |
| AveragePolicyStd        | 0.802166   |
| AverageReturn           | 614        |
| Entropy                 | 7.17147    |
| EnvExecTime             | 2.86       |
| ExplainedVariance       | 0.431      |
| Iteration               | 381        |
| ItrTime                 | 11.2       |
| LossAfter               | 0.885034   |
| LossBefore              | 0.928109   |
| MaxReturn               | 1.39e+03   |
| MeanKL                  | 0.00648861 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 39.2       |
| NumTrajs                | 15         |
| Perplexity              | 1301.76    |
| PolicyExecTime          | 0.53       |
| ProcessExecTime         | 0.0699     |
| StdReturn               | 422        |
| Time                    | 4.21e+03   |
| dLoss                   | 0.0430756  |
----------------------------------------
itr #382 | 
Mem: 754.152344
Obtaining samples...
Obtaining samples for iteration 382...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5464, #subsample_inputs: 5464
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.706      |
| AbsLearnSignalNew       | 0.706      |
| AbsLearningOld          | 0.706      |
| AverageDiscountedReturn | 148        |
| AveragePhiLoss          | 0.974881   |
| AveragePolicyStd        | 0.800921   |
| AverageReturn           | 892        |
| Entropy                 | 7.16253    |
| EnvExecTime             | 3.33       |
| ExplainedVariance       | 0.459      |
| Iteration               | 382        |
| ItrTime                 | 10.9       |
| LossAfter               | 0.146124   |
| LossBefore              | 0.201211   |
| MaxReturn               | 2.23e+03   |
| MeanKL                  | 0.00989923 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 213        |
| NumTrajs                | 14         |
| Perplexity              | 1290.18    |
| PolicyExecTime          | 0.682      |
| ProcessExecTime         | 0.0888     |
| StdReturn               | 490        |
| Time                    | 4.22e+03   |
| dLoss                   | 0.0550869  |
----------------------------------------
itr #383 | 
Mem: 754.152344
Obtaining samples...
Obtaining samples for iteration 383...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5188, #subsample_inputs: 5188
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.695      |
| AbsLearnSignalNew       | 0.695      |
| AbsLearningOld          | 0.695      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 0.974591   |
| AveragePolicyStd        | 0.797921   |
| AverageReturn           | 675        |
| Entropy                 | 7.14067    |
| EnvExecTime             | 3.14       |
| ExplainedVariance       | 0.524      |
| Iteration               | 383        |
| ItrTime                 | 11.5       |
| LossAfter               | -0.171265  |
| LossBefore              | -0.126915  |
| MaxReturn               | 2.19e+03   |
| MeanKL                  | 0.00642523 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 39.4       |
| NumTrajs                | 15         |
| Perplexity              | 1262.27    |
| PolicyExecTime          | 0.625      |
| ProcessExecTime         | 0.0857     |
| StdReturn               | 527        |
| Time                    | 4.23e+03   |
| dLoss                   | 0.0443504  |
----------------------------------------
itr #384 | 
Mem: 754.152344
Obtaining samples...
Obtaining samples for iteration 384...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5046, #subsample_inputs: 5046
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.676      |
| AbsLearnSignalNew       | 0.676      |
| AbsLearningOld          | 0.676      |
| AverageDiscountedReturn | 129        |
| AveragePhiLoss          | 0.980769   |
| AveragePolicyStd        | 0.79583    |
| AverageReturn           | 670        |
| Entropy                 | 7.1242     |
| EnvExecTime             | 3.16       |
| ExplainedVariance       | 0.48       |
| Iteration               | 384        |
| ItrTime                 | 11.3       |
| LossAfter               | 0.324479   |
| LossBefore              | 0.390013   |
| MaxReturn               | 1.61e+03   |
| MeanKL                  | 0.00998333 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 63.1       |
| NumTrajs                | 15         |
| Perplexity              | 1241.65    |
| PolicyExecTime          | 0.606      |
| ProcessExecTime         | 0.0765     |
| StdReturn               | 404        |
| Time                    | 4.24e+03   |
| dLoss                   | 0.065534   |
----------------------------------------
itr #385 | 
Mem: 754.152344
Obtaining samples...
Obtaining samples for iteration 385...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5120, #subsample_inputs: 5120
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.533      |
| AbsLearnSignalNew       | 0.533      |
| AbsLearningOld          | 0.533      |
| AverageDiscountedReturn | 117        |
| AveragePhiLoss          | 0.971637   |
| AveragePolicyStd        | 0.795641   |
| AverageReturn           | 724        |
| Entropy                 | 7.12525    |
| EnvExecTime             | 2.89       |
| ExplainedVariance       | -0.946     |
| Iteration               | 385        |
| ItrTime                 | 10.4       |
| LossAfter               | 0.725391   |
| LossBefore              | 0.779515   |
| MaxReturn               | 2.04e+03   |
| MeanKL                  | 0.00991543 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 39.7       |
| NumTrajs                | 13         |
| Perplexity              | 1242.96    |
| PolicyExecTime          | 0.578      |
| ProcessExecTime         | 0.0805     |
| StdReturn               | 627        |
| Time                    | 4.25e+03   |
| dLoss                   | 0.0541242  |
----------------------------------------
itr #386 | 
Mem: 754.402344
Obtaining samples...
Obtaining samples for iteration 386...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5474, #subsample_inputs: 5474
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.685      |
| AbsLearnSignalNew       | 0.685      |
| AbsLearningOld          | 0.685      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 0.974846   |
| AveragePolicyStd        | 0.795402   |
| AverageReturn           | 700        |
| Entropy                 | 7.12358    |
| EnvExecTime             | 3.3        |
| ExplainedVariance       | 0.302      |
| Iteration               | 386        |
| ItrTime                 | 12         |
| LossAfter               | -0.335288  |
| LossBefore              | -0.287961  |
| MaxReturn               | 1.62e+03   |
| MeanKL                  | 0.00649545 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 37.4       |
| NumTrajs                | 15         |
| Perplexity              | 1240.88    |
| PolicyExecTime          | 0.653      |
| ProcessExecTime         | 0.0811     |
| StdReturn               | 378        |
| Time                    | 4.26e+03   |
| dLoss                   | 0.047327   |
----------------------------------------
itr #387 | 
Mem: 754.402344
Obtaining samples...
Obtaining samples for iteration 387...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5250, #subsample_inputs: 5250
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.683      |
| AbsLearnSignalNew       | 0.683      |
| AbsLearningOld          | 0.683      |
| AverageDiscountedReturn | 136        |
| AveragePhiLoss          | 0.977698   |
| AveragePolicyStd        | 0.792428   |
| AverageReturn           | 789        |
| Entropy                 | 7.10176    |
| EnvExecTime             | 2.96       |
| ExplainedVariance       | 0.464      |
| Iteration               | 387        |
| ItrTime                 | 10.7       |
| LossAfter               | -0.119161  |
| LossBefore              | -0.0752034 |
| MaxReturn               | 1.63e+03   |
| MeanKL                  | 0.00640784 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 75.2       |
| NumTrajs                | 14         |
| Perplexity              | 1214.1     |
| PolicyExecTime          | 0.597      |
| ProcessExecTime         | 0.0776     |
| StdReturn               | 435        |
| Time                    | 4.27e+03   |
| dLoss                   | 0.0439576  |
----------------------------------------
itr #388 | 
Mem: 754.402344
Obtaining samples...
Obtaining samples for iteration 388...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5274, #subsample_inputs: 5274
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.692      |
| AbsLearnSignalNew       | 0.692      |
| AbsLearningOld          | 0.692      |
| AverageDiscountedReturn | 118        |
| AveragePhiLoss          | 0.982784   |
| AveragePolicyStd        | 0.790376   |
| AverageReturn           | 602        |
| Entropy                 | 7.08654    |
| EnvExecTime             | 3.5        |
| ExplainedVariance       | 0.502      |
| Iteration               | 388        |
| ItrTime                 | 11.6       |
| LossAfter               | 0.424703   |
| LossBefore              | 0.476703   |
| MaxReturn               | 1.69e+03   |
| MeanKL                  | 0.00987217 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 58.1       |
| NumTrajs                | 16         |
| Perplexity              | 1195.76    |
| PolicyExecTime          | 0.707      |
| ProcessExecTime         | 0.0877     |
| StdReturn               | 487        |
| Time                    | 4.28e+03   |
| dLoss                   | 0.0520007  |
----------------------------------------
itr #389 | 
Mem: 754.402344
Obtaining samples...
Obtaining samples for iteration 389...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5119, #subsample_inputs: 5119
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.642      |
| AbsLearnSignalNew       | 0.642      |
| AbsLearningOld          | 0.642      |
| AverageDiscountedReturn | 130        |
| AveragePhiLoss          | 0.970872   |
| AveragePolicyStd        | 0.790167   |
| AverageReturn           | 731        |
| Entropy                 | 7.08529    |
| EnvExecTime             | 3.09       |
| ExplainedVariance       | 0.374      |
| Iteration               | 389        |
| ItrTime                 | 11.6       |
| LossAfter               | -0.127116  |
| LossBefore              | -0.0644386 |
| MaxReturn               | 1.64e+03   |
| MeanKL                  | 0.00998362 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 163        |
| NumTrajs                | 14         |
| Perplexity              | 1194.26    |
| PolicyExecTime          | 0.61       |
| ProcessExecTime         | 0.079      |
| StdReturn               | 409        |
| Time                    | 4.3e+03    |
| dLoss                   | 0.0626778  |
----------------------------------------
itr #390 | 
Mem: 754.402344
Obtaining samples...
Obtaining samples for iteration 390...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5085, #subsample_inputs: 5085
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.551      |
| AbsLearnSignalNew       | 0.551      |
| AbsLearningOld          | 0.551      |
| AverageDiscountedReturn | 134        |
| AveragePhiLoss          | 0.969105   |
| AveragePolicyStd        | 0.787553   |
| AverageReturn           | 846        |
| Entropy                 | 7.06527    |
| EnvExecTime             | 3.14       |
| ExplainedVariance       | -2.79      |
| Iteration               | 390        |
| ItrTime                 | 10.7       |
| LossAfter               | 0.406753   |
| LossBefore              | 0.483168   |
| MaxReturn               | 2.55e+03   |
| MeanKL                  | 0.00647935 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 251        |
| NumTrajs                | 13         |
| Perplexity              | 1170.6     |
| PolicyExecTime          | 0.639      |
| ProcessExecTime         | 0.082      |
| StdReturn               | 683        |
| Time                    | 4.31e+03   |
| dLoss                   | 0.0764158  |
----------------------------------------
itr #391 | 
Mem: 754.402344
Obtaining samples...
Obtaining samples for iteration 391...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5286, #subsample_inputs: 5286
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.626      |
| AbsLearnSignalNew       | 0.626      |
| AbsLearningOld          | 0.626      |
| AverageDiscountedReturn | 132        |
| AveragePhiLoss          | 0.971891   |
| AveragePolicyStd        | 0.788399   |
| AverageReturn           | 729        |
| Entropy                 | 7.07197    |
| EnvExecTime             | 3.27       |
| ExplainedVariance       | 0.276      |
| Iteration               | 391        |
| ItrTime                 | 11.6       |
| LossAfter               | -0.566286  |
| LossBefore              | -0.521454  |
| MaxReturn               | 1.18e+03   |
| MeanKL                  | 0.00640462 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 64.7       |
| NumTrajs                | 14         |
| Perplexity              | 1178.47    |
| PolicyExecTime          | 0.666      |
| ProcessExecTime         | 0.0862     |
| StdReturn               | 305        |
| Time                    | 4.32e+03   |
| dLoss                   | 0.0448323  |
----------------------------------------
itr #392 | 
Mem: 754.402344
Obtaining samples...
Obtaining samples for iteration 392...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5088, #subsample_inputs: 5088
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.692      |
| AbsLearnSignalNew       | 0.692      |
| AbsLearningOld          | 0.693      |
| AverageDiscountedReturn | 111        |
| AveragePhiLoss          | 0.987976   |
| AveragePolicyStd        | 0.78888    |
| AverageReturn           | 496        |
| Entropy                 | 7.07533    |
| EnvExecTime             | 2.59       |
| ExplainedVariance       | 0.486      |
| Iteration               | 392        |
| ItrTime                 | 10.7       |
| LossAfter               | 0.343847   |
| LossBefore              | 0.385485   |
| MaxReturn               | 1.18e+03   |
| MeanKL                  | 0.00643116 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 46.3       |
| NumTrajs                | 16         |
| Perplexity              | 1182.43    |
| PolicyExecTime          | 0.493      |
| ProcessExecTime         | 0.0637     |
| StdReturn               | 323        |
| Time                    | 4.33e+03   |
| dLoss                   | 0.0416378  |
----------------------------------------
itr #393 | 
Mem: 754.402344
Obtaining samples...
Obtaining samples for iteration 393...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5060, #subsample_inputs: 5060
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
-----------------------------------------
| AbsLearnSignal          | 0.717       |
| AbsLearnSignalNew       | 0.717       |
| AbsLearningOld          | 0.717       |
| AverageDiscountedReturn | 132         |
| AveragePhiLoss          | 0.978445    |
| AveragePolicyStd        | 0.786832    |
| AverageReturn           | 1.01e+03    |
| Entropy                 | 7.05976     |
| EnvExecTime             | 3.14        |
| ExplainedVariance       | 0.48        |
| Iteration               | 393         |
| ItrTime                 | 10.2        |
| LossAfter               | -0.0664557  |
| LossBefore              | -0.00512578 |
| MaxReturn               | 2.12e+03    |
| MeanKL                  | 0.00986307  |
| MeanKLBefore            | 0.0         |
| MinReturn               | 69.5        |
| NumTrajs                | 11          |
| Perplexity              | 1164.17     |
| PolicyExecTime          | 0.64        |
| ProcessExecTime         | 0.0802      |
| StdReturn               | 717         |
| Time                    | 4.34e+03    |
| dLoss                   | 0.0613299   |
-----------------------------------------
itr #394 | 
Mem: 754.402344
Obtaining samples...
Obtaining samples for iteration 394...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5252, #subsample_inputs: 5252
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.665      |
| AbsLearnSignalNew       | 0.665      |
| AbsLearningOld          | 0.665      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 0.976641   |
| AveragePolicyStd        | 0.786963   |
| AverageReturn           | 708        |
| Entropy                 | 7.06199    |
| EnvExecTime             | 3.67       |
| ExplainedVariance       | 0.509      |
| Iteration               | 394        |
| ItrTime                 | 12.3       |
| LossAfter               | -0.640209  |
| LossBefore              | -0.591666  |
| MaxReturn               | 1.98e+03   |
| MeanKL                  | 0.00643525 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 32.6       |
| NumTrajs                | 15         |
| Perplexity              | 1166.77    |
| PolicyExecTime          | 0.743      |
| ProcessExecTime         | 0.09       |
| StdReturn               | 478        |
| Time                    | 4.35e+03   |
| dLoss                   | 0.0485433  |
----------------------------------------
itr #395 | 
Mem: 754.402344
Obtaining samples...
Obtaining samples for iteration 395...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5082, #subsample_inputs: 5082
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.688      |
| AbsLearnSignalNew       | 0.688      |
| AbsLearningOld          | 0.688      |
| AverageDiscountedReturn | 111        |
| AveragePhiLoss          | 0.978924   |
| AveragePolicyStd        | 0.787095   |
| AverageReturn           | 627        |
| Entropy                 | 7.06332    |
| EnvExecTime             | 2.83       |
| ExplainedVariance       | 0.55       |
| Iteration               | 395        |
| ItrTime                 | 10.9       |
| LossAfter               | 0.493375   |
| LossBefore              | 0.540156   |
| MaxReturn               | 1.4e+03    |
| MeanKL                  | 0.00642171 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 52.3       |
| NumTrajs                | 14         |
| Perplexity              | 1168.32    |
| PolicyExecTime          | 0.521      |
| ProcessExecTime         | 0.0661     |
| StdReturn               | 472        |
| Time                    | 4.36e+03   |
| dLoss                   | 0.0467811  |
----------------------------------------
itr #396 | 
Mem: 754.402344
Obtaining samples...
Obtaining samples for iteration 396...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5182, #subsample_inputs: 5182
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.674      |
| AbsLearnSignalNew       | 0.674      |
| AbsLearningOld          | 0.674      |
| AverageDiscountedReturn | 131        |
| AveragePhiLoss          | 0.982076   |
| AveragePolicyStd        | 0.788784   |
| AverageReturn           | 629        |
| Entropy                 | 7.07758    |
| EnvExecTime             | 3.28       |
| ExplainedVariance       | 0.512      |
| Iteration               | 396        |
| ItrTime                 | 10.6       |
| LossAfter               | 0.566688   |
| LossBefore              | 0.610439   |
| MaxReturn               | 1.44e+03   |
| MeanKL                  | 0.00640832 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 77.2       |
| NumTrajs                | 16         |
| Perplexity              | 1185.1     |
| PolicyExecTime          | 0.661      |
| ProcessExecTime         | 0.0858     |
| StdReturn               | 373        |
| Time                    | 4.37e+03   |
| dLoss                   | 0.0437506  |
----------------------------------------
itr #397 | 
Mem: 754.402344
Obtaining samples...
Obtaining samples for iteration 397...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5025, #subsample_inputs: 5025
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.698      |
| AbsLearnSignalNew       | 0.698      |
| AbsLearningOld          | 0.698      |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 0.981383   |
| AveragePolicyStd        | 0.787048   |
| AverageReturn           | 812        |
| Entropy                 | 7.06471    |
| EnvExecTime             | 3.39       |
| ExplainedVariance       | 0.488      |
| Iteration               | 397        |
| ItrTime                 | 11.7       |
| LossAfter               | 0.124796   |
| LossBefore              | 0.168817   |
| MaxReturn               | 1.45e+03   |
| MeanKL                  | 0.00649362 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 48         |
| NumTrajs                | 13         |
| Perplexity              | 1169.94    |
| PolicyExecTime          | 0.681      |
| ProcessExecTime         | 0.0836     |
| StdReturn               | 470        |
| Time                    | 4.39e+03   |
| dLoss                   | 0.044021   |
----------------------------------------
itr #398 | 
Mem: 754.402344
Obtaining samples...
Obtaining samples for iteration 398...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5152, #subsample_inputs: 5152
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.611      |
| AbsLearnSignalNew       | 0.611      |
| AbsLearningOld          | 0.611      |
| AverageDiscountedReturn | 132        |
| AveragePhiLoss          | 0.96819    |
| AveragePolicyStd        | 0.786286   |
| AverageReturn           | 769        |
| Entropy                 | 7.0593     |
| EnvExecTime             | 2.93       |
| ExplainedVariance       | 0.271      |
| Iteration               | 398        |
| ItrTime                 | 10.6       |
| LossAfter               | 0.295779   |
| LossBefore              | 0.348287   |
| MaxReturn               | 2.63e+03   |
| MeanKL                  | 0.00646163 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 65.9       |
| NumTrajs                | 14         |
| Perplexity              | 1163.63    |
| PolicyExecTime          | 0.581      |
| ProcessExecTime         | 0.0737     |
| StdReturn               | 642        |
| Time                    | 4.4e+03    |
| dLoss                   | 0.0525077  |
----------------------------------------
itr #399 | 
Mem: 754.402344
Obtaining samples...
Obtaining samples for iteration 399...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5587, #subsample_inputs: 5587
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.678      |
| AbsLearnSignalNew       | 0.678      |
| AbsLearningOld          | 0.678      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 0.976553   |
| AveragePolicyStd        | 0.785216   |
| AverageReturn           | 878        |
| Entropy                 | 7.05139    |
| EnvExecTime             | 3.69       |
| ExplainedVariance       | 0.509      |
| Iteration               | 399        |
| ItrTime                 | 12.1       |
| LossAfter               | 0.510622   |
| LossBefore              | 0.564462   |
| MaxReturn               | 1.72e+03   |
| MeanKL                  | 0.00981381 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 55.5       |
| NumTrajs                | 13         |
| Perplexity              | 1154.46    |
| PolicyExecTime          | 0.741      |
| ProcessExecTime         | 0.0935     |
| StdReturn               | 555        |
| Time                    | 4.41e+03   |
| dLoss                   | 0.0538402  |
----------------------------------------
itr #400 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 400...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5000, #subsample_inputs: 5000
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.702      |
| AbsLearnSignalNew       | 0.702      |
| AbsLearningOld          | 0.702      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 0.973833   |
| AveragePolicyStd        | 0.786965   |
| AverageReturn           | 655        |
| Entropy                 | 7.06421    |
| EnvExecTime             | 3.08       |
| ExplainedVariance       | 0.512      |
| Iteration               | 400        |
| ItrTime                 | 11.4       |
| LossAfter               | 0.0787629  |
| LossBefore              | 0.122309   |
| MaxReturn               | 1.76e+03   |
| MeanKL                  | 0.00646756 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 82.9       |
| NumTrajs                | 14         |
| Perplexity              | 1169.36    |
| PolicyExecTime          | 0.639      |
| ProcessExecTime         | 0.0775     |
| StdReturn               | 542        |
| Time                    | 4.42e+03   |
| dLoss                   | 0.0435465  |
----------------------------------------
itr #401 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 401...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5280, #subsample_inputs: 5280
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.651      |
| AbsLearnSignalNew       | 0.651      |
| AbsLearningOld          | 0.651      |
| AverageDiscountedReturn | 134        |
| AveragePhiLoss          | 0.979154   |
| AveragePolicyStd        | 0.784241   |
| AverageReturn           | 677        |
| Entropy                 | 7.0449     |
| EnvExecTime             | 3.3        |
| ExplainedVariance       | 0.451      |
| Iteration               | 401        |
| ItrTime                 | 10.8       |
| LossAfter               | 0.561045   |
| LossBefore              | 0.624002   |
| MaxReturn               | 1.39e+03   |
| MeanKL                  | 0.00991827 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 53.6       |
| NumTrajs                | 17         |
| Perplexity              | 1147.0     |
| PolicyExecTime          | 0.679      |
| ProcessExecTime         | 0.0849     |
| StdReturn               | 404        |
| Time                    | 4.43e+03   |
| dLoss                   | 0.0629564  |
----------------------------------------
itr #402 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 402...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5277, #subsample_inputs: 5277
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.594      |
| AbsLearnSignalNew       | 0.594      |
| AbsLearningOld          | 0.594      |
| AverageDiscountedReturn | 124        |
| AveragePhiLoss          | 0.970516   |
| AveragePolicyStd        | 0.7832     |
| AverageReturn           | 702        |
| Entropy                 | 7.03731    |
| EnvExecTime             | 3.37       |
| ExplainedVariance       | -0.0265    |
| Iteration               | 402        |
| ItrTime                 | 12.1       |
| LossAfter               | 0.636244   |
| LossBefore              | 0.690062   |
| MaxReturn               | 2.07e+03   |
| MeanKL                  | 0.00972084 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 57.7       |
| NumTrajs                | 15         |
| Perplexity              | 1138.32    |
| PolicyExecTime          | 0.709      |
| ProcessExecTime         | 0.0872     |
| StdReturn               | 486        |
| Time                    | 4.44e+03   |
| dLoss                   | 0.0538175  |
----------------------------------------
itr #403 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 403...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5333, #subsample_inputs: 5333
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.653      |
| AbsLearnSignalNew       | 0.653      |
| AbsLearningOld          | 0.653      |
| AverageDiscountedReturn | 136        |
| AveragePhiLoss          | 0.983053   |
| AveragePolicyStd        | 0.785187   |
| AverageReturn           | 708        |
| Entropy                 | 7.05277    |
| EnvExecTime             | 3.19       |
| ExplainedVariance       | 0.451      |
| Iteration               | 403        |
| ItrTime                 | 11.9       |
| LossAfter               | -0.506239  |
| LossBefore              | -0.438609  |
| MaxReturn               | 1.16e+03   |
| MeanKL                  | 0.00997119 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 74.6       |
| NumTrajs                | 16         |
| Perplexity              | 1156.06    |
| PolicyExecTime          | 0.644      |
| ProcessExecTime         | 0.0772     |
| StdReturn               | 307        |
| Time                    | 4.46e+03   |
| dLoss                   | 0.0676293  |
----------------------------------------
itr #404 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 404...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5056, #subsample_inputs: 5056
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.352      |
| AbsLearnSignalNew       | 0.352      |
| AbsLearningOld          | 0.352      |
| AverageDiscountedReturn | 130        |
| AveragePhiLoss          | 0.970519   |
| AveragePolicyStd        | 0.785833   |
| AverageReturn           | 764        |
| Entropy                 | 7.05725    |
| EnvExecTime             | 3.16       |
| ExplainedVariance       | -13.8      |
| Iteration               | 404        |
| ItrTime                 | 10.1       |
| LossAfter               | 0.0592747  |
| LossBefore              | 0.110542   |
| MaxReturn               | 2.29e+03   |
| MeanKL                  | 0.00642177 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 49.7       |
| NumTrajs                | 14         |
| Perplexity              | 1161.25    |
| PolicyExecTime          | 0.641      |
| ProcessExecTime         | 0.0798     |
| StdReturn               | 547        |
| Time                    | 4.47e+03   |
| dLoss                   | 0.0512676  |
----------------------------------------
itr #405 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 405...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5347, #subsample_inputs: 5347
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.643      |
| AbsLearnSignalNew       | 0.643      |
| AbsLearningOld          | 0.643      |
| AverageDiscountedReturn | 136        |
| AveragePhiLoss          | 0.976406   |
| AveragePolicyStd        | 0.7858     |
| AverageReturn           | 848        |
| Entropy                 | 7.05788    |
| EnvExecTime             | 3.11       |
| ExplainedVariance       | 0.524      |
| Iteration               | 405        |
| ItrTime                 | 12.1       |
| LossAfter               | -0.339054  |
| LossBefore              | -0.291855  |
| MaxReturn               | 2.09e+03   |
| MeanKL                  | 0.00643872 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 51         |
| NumTrajs                | 14         |
| Perplexity              | 1161.98    |
| PolicyExecTime          | 0.635      |
| ProcessExecTime         | 0.0839     |
| StdReturn               | 558        |
| Time                    | 4.48e+03   |
| dLoss                   | 0.0471992  |
----------------------------------------
itr #406 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 406...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5303, #subsample_inputs: 5303
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.693      |
| AbsLearnSignalNew       | 0.693      |
| AbsLearningOld          | 0.693      |
| AverageDiscountedReturn | 131        |
| AveragePhiLoss          | 0.968444   |
| AveragePolicyStd        | 0.784738   |
| AverageReturn           | 708        |
| Entropy                 | 7.04953    |
| EnvExecTime             | 2.97       |
| ExplainedVariance       | 0.514      |
| Iteration               | 406        |
| ItrTime                 | 11.6       |
| LossAfter               | 0.232053   |
| LossBefore              | 0.289319   |
| MaxReturn               | 1.48e+03   |
| MeanKL                  | 0.00998111 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 60.2       |
| NumTrajs                | 16         |
| Perplexity              | 1152.31    |
| PolicyExecTime          | 0.581      |
| ProcessExecTime         | 0.0758     |
| StdReturn               | 402        |
| Time                    | 4.49e+03   |
| dLoss                   | 0.0572655  |
----------------------------------------
itr #407 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 407...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5412, #subsample_inputs: 5412
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.447      |
| AbsLearnSignalNew       | 0.447      |
| AbsLearningOld          | 0.447      |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 0.976027   |
| AveragePolicyStd        | 0.783453   |
| AverageReturn           | 697        |
| Entropy                 | 7.04086    |
| EnvExecTime             | 3.11       |
| ExplainedVariance       | -3.78      |
| Iteration               | 407        |
| ItrTime                 | 10.7       |
| LossAfter               | -0.24447   |
| LossBefore              | -0.169246  |
| MaxReturn               | 2.18e+03   |
| MeanKL                  | 0.00976861 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 25.2       |
| NumTrajs                | 15         |
| Perplexity              | 1142.36    |
| PolicyExecTime          | 0.63       |
| ProcessExecTime         | 0.0824     |
| StdReturn               | 657        |
| Time                    | 4.5e+03    |
| dLoss                   | 0.0752248  |
----------------------------------------
itr #408 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 408...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5086, #subsample_inputs: 5086
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.719     |
| AbsLearnSignalNew       | 0.719     |
| AbsLearningOld          | 0.719     |
| AverageDiscountedReturn | 142       |
| AveragePhiLoss          | 0.97597   |
| AveragePolicyStd        | 0.783347  |
| AverageReturn           | 1.19e+03  |
| Entropy                 | 7.0392    |
| EnvExecTime             | 2.95      |
| ExplainedVariance       | 0.425     |
| Iteration               | 408       |
| ItrTime                 | 11.4      |
| LossAfter               | 0.769868  |
| LossBefore              | 0.812665  |
| MaxReturn               | 2.26e+03  |
| MeanKL                  | 0.0064652 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 429       |
| NumTrajs                | 9         |
| Perplexity              | 1140.47   |
| PolicyExecTime          | 0.601     |
| ProcessExecTime         | 0.0784    |
| StdReturn               | 605       |
| Time                    | 4.51e+03  |
| dLoss                   | 0.0427973 |
---------------------------------------
itr #409 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 409...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5116, #subsample_inputs: 5116
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.669      |
| AbsLearnSignalNew       | 0.669      |
| AbsLearningOld          | 0.668      |
| AverageDiscountedReturn | 127        |
| AveragePhiLoss          | 0.966769   |
| AveragePolicyStd        | 0.782601   |
| AverageReturn           | 568        |
| Entropy                 | 7.03249    |
| EnvExecTime             | 2.96       |
| ExplainedVariance       | 0.469      |
| Iteration               | 409        |
| ItrTime                 | 10.5       |
| LossAfter               | 0.168754   |
| LossBefore              | 0.225416   |
| MaxReturn               | 1.4e+03    |
| MeanKL                  | 0.00990066 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 53.6       |
| NumTrajs                | 18         |
| Perplexity              | 1132.85    |
| PolicyExecTime          | 0.612      |
| ProcessExecTime         | 0.0766     |
| StdReturn               | 358        |
| Time                    | 4.52e+03   |
| dLoss                   | 0.0566622  |
----------------------------------------
itr #410 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 410...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5413, #subsample_inputs: 5413
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.716      |
| AbsLearnSignalNew       | 0.716      |
| AbsLearningOld          | 0.716      |
| AverageDiscountedReturn | 139        |
| AveragePhiLoss          | 0.973346   |
| AveragePolicyStd        | 0.787237   |
| AverageReturn           | 827        |
| Entropy                 | 7.06818    |
| EnvExecTime             | 3.28       |
| ExplainedVariance       | 0.509      |
| Iteration               | 410        |
| ItrTime                 | 11.4       |
| LossAfter               | -0.255317  |
| LossBefore              | -0.205735  |
| MaxReturn               | 1.5e+03    |
| MeanKL                  | 0.00641359 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 72.2       |
| NumTrajs                | 15         |
| Perplexity              | 1174.0     |
| PolicyExecTime          | 0.673      |
| ProcessExecTime         | 0.0902     |
| StdReturn               | 394        |
| Time                    | 4.53e+03   |
| dLoss                   | 0.0495824  |
----------------------------------------
itr #411 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 411...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5144, #subsample_inputs: 5144
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.471      |
| AbsLearnSignalNew       | 0.471      |
| AbsLearningOld          | 0.471      |
| AverageDiscountedReturn | 137        |
| AveragePhiLoss          | 0.979717   |
| AveragePolicyStd        | 0.785602   |
| AverageReturn           | 1.05e+03   |
| Entropy                 | 7.0567     |
| EnvExecTime             | 2.83       |
| ExplainedVariance       | -4.87      |
| Iteration               | 411        |
| ItrTime                 | 11.3       |
| LossAfter               | -0.0460087 |
| LossBefore              | 0.00362688 |
| MaxReturn               | 2.2e+03    |
| MeanKL                  | 0.00652293 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 36.3       |
| NumTrajs                | 11         |
| Perplexity              | 1160.61    |
| PolicyExecTime          | 0.576      |
| ProcessExecTime         | 0.0752     |
| StdReturn               | 600        |
| Time                    | 4.55e+03   |
| dLoss                   | 0.0496356  |
----------------------------------------
itr #412 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 412...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5103, #subsample_inputs: 5103
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.633      |
| AbsLearnSignalNew       | 0.633      |
| AbsLearningOld          | 0.632      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 0.97691    |
| AveragePolicyStd        | 0.784444   |
| AverageReturn           | 641        |
| Entropy                 | 7.04881    |
| EnvExecTime             | 3.27       |
| ExplainedVariance       | 0.526      |
| Iteration               | 412        |
| ItrTime                 | 10.3       |
| LossAfter               | 0.0227149  |
| LossBefore              | 0.0892457  |
| MaxReturn               | 1.56e+03   |
| MeanKL                  | 0.00999579 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 67.7       |
| NumTrajs                | 15         |
| Perplexity              | 1151.48    |
| PolicyExecTime          | 0.648      |
| ProcessExecTime         | 0.086      |
| StdReturn               | 492        |
| Time                    | 4.56e+03   |
| dLoss                   | 0.0665308  |
----------------------------------------
itr #413 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 413...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5073, #subsample_inputs: 5073
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.656      |
| AbsLearnSignalNew       | 0.656      |
| AbsLearningOld          | 0.656      |
| AverageDiscountedReturn | 124        |
| AveragePhiLoss          | 0.968225   |
| AveragePolicyStd        | 0.784057   |
| AverageReturn           | 666        |
| Entropy                 | 7.04582    |
| EnvExecTime             | 3.43       |
| ExplainedVariance       | 0.433      |
| Iteration               | 413        |
| ItrTime                 | 12         |
| LossAfter               | 0.418734   |
| LossBefore              | 0.468221   |
| MaxReturn               | 1.17e+03   |
| MeanKL                  | 0.00640572 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 60.6       |
| NumTrajs                | 15         |
| Perplexity              | 1148.05    |
| PolicyExecTime          | 0.7        |
| ProcessExecTime         | 0.0869     |
| StdReturn               | 330        |
| Time                    | 4.57e+03   |
| dLoss                   | 0.0494872  |
----------------------------------------
itr #414 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 414...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5531, #subsample_inputs: 5531
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.615      |
| AbsLearnSignalNew       | 0.615      |
| AbsLearningOld          | 0.615      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 0.974813   |
| AveragePolicyStd        | 0.784881   |
| AverageReturn           | 675        |
| Entropy                 | 7.05231    |
| EnvExecTime             | 3.43       |
| ExplainedVariance       | 0.239      |
| Iteration               | 414        |
| ItrTime                 | 12.2       |
| LossAfter               | 0.875893   |
| LossBefore              | 0.921998   |
| MaxReturn               | 1.79e+03   |
| MeanKL                  | 0.00641149 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 61.6       |
| NumTrajs                | 16         |
| Perplexity              | 1155.53    |
| PolicyExecTime          | 0.661      |
| ProcessExecTime         | 0.0829     |
| StdReturn               | 510        |
| Time                    | 4.58e+03   |
| dLoss                   | 0.0461043  |
----------------------------------------
itr #415 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 415...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5263, #subsample_inputs: 5263
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.71       |
| AbsLearnSignalNew       | 0.71       |
| AbsLearningOld          | 0.71       |
| AverageDiscountedReturn | 129        |
| AveragePhiLoss          | 0.983435   |
| AveragePolicyStd        | 0.784473   |
| AverageReturn           | 623        |
| Entropy                 | 7.04936    |
| EnvExecTime             | 3.39       |
| ExplainedVariance       | 0.497      |
| Iteration               | 415        |
| ItrTime                 | 10.9       |
| LossAfter               | 0.662844   |
| LossBefore              | 0.72282    |
| MaxReturn               | 1.37e+03   |
| MeanKL                  | 0.00995918 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 45.8       |
| NumTrajs                | 17         |
| Perplexity              | 1152.12    |
| PolicyExecTime          | 0.67       |
| ProcessExecTime         | 0.0887     |
| StdReturn               | 390        |
| Time                    | 4.59e+03   |
| dLoss                   | 0.0599751  |
----------------------------------------
itr #416 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 416...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5089, #subsample_inputs: 5089
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.708      |
| AbsLearnSignalNew       | 0.708      |
| AbsLearningOld          | 0.708      |
| AverageDiscountedReturn | 112        |
| AveragePhiLoss          | 0.979137   |
| AveragePolicyStd        | 0.783871   |
| AverageReturn           | 579        |
| Entropy                 | 7.04471    |
| EnvExecTime             | 3.35       |
| ExplainedVariance       | 0.538      |
| Iteration               | 416        |
| ItrTime                 | 11.6       |
| LossAfter               | 0.311263   |
| LossBefore              | 0.362604   |
| MaxReturn               | 1.41e+03   |
| MeanKL                  | 0.00990237 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 51         |
| NumTrajs                | 16         |
| Perplexity              | 1146.77    |
| PolicyExecTime          | 0.677      |
| ProcessExecTime         | 0.0842     |
| StdReturn               | 410        |
| Time                    | 4.6e+03    |
| dLoss                   | 0.0513414  |
----------------------------------------
itr #417 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 417...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5028, #subsample_inputs: 5028
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.687      |
| AbsLearnSignalNew       | 0.687      |
| AbsLearningOld          | 0.687      |
| AverageDiscountedReturn | 119        |
| AveragePhiLoss          | 0.969581   |
| AveragePolicyStd        | 0.784197   |
| AverageReturn           | 589        |
| Entropy                 | 7.04624    |
| EnvExecTime             | 2.39       |
| ExplainedVariance       | 0.461      |
| Iteration               | 417        |
| ItrTime                 | 10.7       |
| LossAfter               | 0.0666899  |
| LossBefore              | 0.125882   |
| MaxReturn               | 1.31e+03   |
| MeanKL                  | 0.00997235 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 31.8       |
| NumTrajs                | 16         |
| Perplexity              | 1148.54    |
| PolicyExecTime          | 0.444      |
| ProcessExecTime         | 0.0605     |
| StdReturn               | 438        |
| Time                    | 4.61e+03   |
| dLoss                   | 0.0591923  |
----------------------------------------
itr #418 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 418...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5385, #subsample_inputs: 5385
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.586      |
| AbsLearnSignalNew       | 0.586      |
| AbsLearningOld          | 0.586      |
| AverageDiscountedReturn | 118        |
| AveragePhiLoss          | 0.976891   |
| AveragePolicyStd        | 0.784506   |
| AverageReturn           | 615        |
| Entropy                 | 7.05013    |
| EnvExecTime             | 3.54       |
| ExplainedVariance       | -0.223     |
| Iteration               | 418        |
| ItrTime                 | 11.3       |
| LossAfter               | 0.273469   |
| LossBefore              | 0.337554   |
| MaxReturn               | 2.21e+03   |
| MeanKL                  | 0.00992845 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 31.1       |
| NumTrajs                | 17         |
| Perplexity              | 1153.01    |
| PolicyExecTime          | 0.752      |
| ProcessExecTime         | 0.0924     |
| StdReturn               | 594        |
| Time                    | 4.63e+03   |
| dLoss                   | 0.0640858  |
----------------------------------------
itr #419 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 419...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5111, #subsample_inputs: 5111
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.728      |
| AbsLearnSignalNew       | 0.728      |
| AbsLearningOld          | 0.728      |
| AverageDiscountedReturn | 119        |
| AveragePhiLoss          | 0.982097   |
| AveragePolicyStd        | 0.784282   |
| AverageReturn           | 592        |
| Entropy                 | 7.04776    |
| EnvExecTime             | 3.35       |
| ExplainedVariance       | 0.554      |
| Iteration               | 419        |
| ItrTime                 | 11.8       |
| LossAfter               | 0.206159   |
| LossBefore              | 0.264713   |
| MaxReturn               | 1.57e+03   |
| MeanKL                  | 0.00986112 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 51         |
| NumTrajs                | 16         |
| Perplexity              | 1150.28    |
| PolicyExecTime          | 0.696      |
| ProcessExecTime         | 0.0863     |
| StdReturn               | 424        |
| Time                    | 4.64e+03   |
| dLoss                   | 0.058554   |
----------------------------------------
itr #420 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 420...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5222, #subsample_inputs: 5222
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.734      |
| AbsLearnSignalNew       | 0.734      |
| AbsLearningOld          | 0.734      |
| AverageDiscountedReturn | 139        |
| AveragePhiLoss          | 0.966152   |
| AveragePolicyStd        | 0.785521   |
| AverageReturn           | 840        |
| Entropy                 | 7.05763    |
| EnvExecTime             | 2.9        |
| ExplainedVariance       | 0.471      |
| Iteration               | 420        |
| ItrTime                 | 10.6       |
| LossAfter               | 0.61197    |
| LossBefore              | 0.671297   |
| MaxReturn               | 1.86e+03   |
| MeanKL                  | 0.00996376 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 465        |
| NumTrajs                | 14         |
| Perplexity              | 1161.69    |
| PolicyExecTime          | 0.569      |
| ProcessExecTime         | 0.0746     |
| StdReturn               | 396        |
| Time                    | 4.65e+03   |
| dLoss                   | 0.0593261  |
----------------------------------------
itr #421 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 421...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5152, #subsample_inputs: 5152
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.638      |
| AbsLearnSignalNew       | 0.638      |
| AbsLearningOld          | 0.638      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 0.976615   |
| AveragePolicyStd        | 0.783928   |
| AverageReturn           | 690        |
| Entropy                 | 7.04585    |
| EnvExecTime             | 3.49       |
| ExplainedVariance       | 0.526      |
| Iteration               | 421        |
| ItrTime                 | 11.5       |
| LossAfter               | 0.334013   |
| LossBefore              | 0.380723   |
| MaxReturn               | 1.68e+03   |
| MeanKL                  | 0.00641777 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 33.5       |
| NumTrajs                | 14         |
| Perplexity              | 1148.08    |
| PolicyExecTime          | 0.714      |
| ProcessExecTime         | 0.0884     |
| StdReturn               | 471        |
| Time                    | 4.66e+03   |
| dLoss                   | 0.0467099  |
----------------------------------------
itr #422 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 422...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5035, #subsample_inputs: 5035
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.632      |
| AbsLearnSignalNew       | 0.632      |
| AbsLearningOld          | 0.632      |
| AverageDiscountedReturn | 129        |
| AveragePhiLoss          | 0.977955   |
| AveragePolicyStd        | 0.782855   |
| AverageReturn           | 659        |
| Entropy                 | 7.03674    |
| EnvExecTime             | 2.7        |
| ExplainedVariance       | 0.417      |
| Iteration               | 422        |
| ItrTime                 | 11.2       |
| LossAfter               | 0.353322   |
| LossBefore              | 0.416288   |
| MaxReturn               | 1.11e+03   |
| MeanKL                  | 0.00984713 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 36.5       |
| NumTrajs                | 16         |
| Perplexity              | 1137.68    |
| PolicyExecTime          | 0.556      |
| ProcessExecTime         | 0.0707     |
| StdReturn               | 381        |
| Time                    | 4.67e+03   |
| dLoss                   | 0.0629657  |
----------------------------------------
itr #423 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 423...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5014, #subsample_inputs: 5014
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.71       |
| AbsLearnSignalNew       | 0.71       |
| AbsLearningOld          | 0.71       |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 0.975792   |
| AveragePolicyStd        | 0.782421   |
| AverageReturn           | 657        |
| Entropy                 | 7.0333     |
| EnvExecTime             | 3.09       |
| ExplainedVariance       | 0.557      |
| Iteration               | 423        |
| ItrTime                 | 10         |
| LossAfter               | 0.300329   |
| LossBefore              | 0.355567   |
| MaxReturn               | 1.66e+03   |
| MeanKL                  | 0.00998363 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 51.9       |
| NumTrajs                | 16         |
| Perplexity              | 1133.76    |
| PolicyExecTime          | 0.641      |
| ProcessExecTime         | 0.0823     |
| StdReturn               | 481        |
| Time                    | 4.68e+03   |
| dLoss                   | 0.0552379  |
----------------------------------------
itr #424 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 424...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5005, #subsample_inputs: 5005
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.737      |
| AbsLearnSignalNew       | 0.737      |
| AbsLearningOld          | 0.737      |
| AverageDiscountedReturn | 106        |
| AveragePhiLoss          | 0.970825   |
| AveragePolicyStd        | 0.783081   |
| AverageReturn           | 420        |
| Entropy                 | 7.03754    |
| EnvExecTime             | 3.18       |
| ExplainedVariance       | 0.405      |
| Iteration               | 424        |
| ItrTime                 | 11.5       |
| LossAfter               | 0.217712   |
| LossBefore              | 0.274613   |
| MaxReturn               | 1.06e+03   |
| MeanKL                  | 0.00977001 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 47.7       |
| NumTrajs                | 19         |
| Perplexity              | 1138.59    |
| PolicyExecTime          | 0.639      |
| ProcessExecTime         | 0.0825     |
| StdReturn               | 323        |
| Time                    | 4.69e+03   |
| dLoss                   | 0.0569011  |
----------------------------------------
itr #425 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 425...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5112, #subsample_inputs: 5112
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.603      |
| AbsLearnSignalNew       | 0.603      |
| AbsLearningOld          | 0.602      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 0.968917   |
| AveragePolicyStd        | 0.784213   |
| AverageReturn           | 670        |
| Entropy                 | 7.045      |
| EnvExecTime             | 2.78       |
| ExplainedVariance       | 0.25       |
| Iteration               | 425        |
| ItrTime                 | 10.8       |
| LossAfter               | -0.405845  |
| LossBefore              | -0.337403  |
| MaxReturn               | 1.65e+03   |
| MeanKL                  | 0.00999939 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 48.8       |
| NumTrajs                | 16         |
| Perplexity              | 1147.1     |
| PolicyExecTime          | 0.53       |
| ProcessExecTime         | 0.067      |
| StdReturn               | 456        |
| Time                    | 4.7e+03    |
| dLoss                   | 0.0684427  |
----------------------------------------
itr #426 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 426...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5220, #subsample_inputs: 5220
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.745      |
| AbsLearnSignalNew       | 0.745      |
| AbsLearningOld          | 0.745      |
| AverageDiscountedReturn | 140        |
| AveragePhiLoss          | 0.97344    |
| AveragePolicyStd        | 0.784027   |
| AverageReturn           | 739        |
| Entropy                 | 7.04255    |
| EnvExecTime             | 2.76       |
| ExplainedVariance       | 0.491      |
| Iteration               | 426        |
| ItrTime                 | 10.3       |
| LossAfter               | 0.278921   |
| LossBefore              | 0.337629   |
| MaxReturn               | 1.64e+03   |
| MeanKL                  | 0.00999021 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 43.9       |
| NumTrajs                | 16         |
| Perplexity              | 1144.3     |
| PolicyExecTime          | 0.562      |
| ProcessExecTime         | 0.076      |
| StdReturn               | 444        |
| Time                    | 4.71e+03   |
| dLoss                   | 0.058708   |
----------------------------------------
itr #427 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 427...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5294, #subsample_inputs: 5294
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.685      |
| AbsLearnSignalNew       | 0.685      |
| AbsLearningOld          | 0.685      |
| AverageDiscountedReturn | 132        |
| AveragePhiLoss          | 0.975667   |
| AveragePolicyStd        | 0.782958   |
| AverageReturn           | 659        |
| Entropy                 | 7.03492    |
| EnvExecTime             | 3.09       |
| ExplainedVariance       | 0.583      |
| Iteration               | 427        |
| ItrTime                 | 11.8       |
| LossAfter               | -0.473399  |
| LossBefore              | -0.417659  |
| MaxReturn               | 1.42e+03   |
| MeanKL                  | 0.00997075 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 76.7       |
| NumTrajs                | 17         |
| Perplexity              | 1135.6     |
| PolicyExecTime          | 0.636      |
| ProcessExecTime         | 0.0834     |
| StdReturn               | 337        |
| Time                    | 4.73e+03   |
| dLoss                   | 0.05574    |
----------------------------------------
itr #428 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 428...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5237, #subsample_inputs: 5237
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.668      |
| AbsLearnSignalNew       | 0.668      |
| AbsLearningOld          | 0.668      |
| AverageDiscountedReturn | 129        |
| AveragePhiLoss          | 0.9775     |
| AveragePolicyStd        | 0.784534   |
| AverageReturn           | 637        |
| Entropy                 | 7.04682    |
| EnvExecTime             | 3.05       |
| ExplainedVariance       | 0.506      |
| Iteration               | 428        |
| ItrTime                 | 10.6       |
| LossAfter               | 0.431092   |
| LossBefore              | 0.47661    |
| MaxReturn               | 1.53e+03   |
| MeanKL                  | 0.00645927 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 45.3       |
| NumTrajs                | 17         |
| Perplexity              | 1149.2     |
| PolicyExecTime          | 0.605      |
| ProcessExecTime         | 0.0794     |
| StdReturn               | 397        |
| Time                    | 4.74e+03   |
| dLoss                   | 0.045518   |
----------------------------------------
itr #429 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 429...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5345, #subsample_inputs: 5345
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.542      |
| AbsLearnSignalNew       | 0.542      |
| AbsLearningOld          | 0.542      |
| AverageDiscountedReturn | 118        |
| AveragePhiLoss          | 0.965688   |
| AveragePolicyStd        | 0.781797   |
| AverageReturn           | 670        |
| Entropy                 | 7.02467    |
| EnvExecTime             | 3.06       |
| ExplainedVariance       | -1.35      |
| Iteration               | 429        |
| ItrTime                 | 11.3       |
| LossAfter               | 0.415994   |
| LossBefore              | 0.480145   |
| MaxReturn               | 1.9e+03    |
| MeanKL                  | 0.00999968 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 63.5       |
| NumTrajs                | 15         |
| Perplexity              | 1124.03    |
| PolicyExecTime          | 0.611      |
| ProcessExecTime         | 0.0837     |
| StdReturn               | 542        |
| Time                    | 4.75e+03   |
| dLoss                   | 0.0641505  |
----------------------------------------
itr #430 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 430...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5061, #subsample_inputs: 5061
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.703      |
| AbsLearnSignalNew       | 0.703      |
| AbsLearningOld          | 0.703      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 0.977371   |
| AveragePolicyStd        | 0.781924   |
| AverageReturn           | 652        |
| Entropy                 | 7.02502    |
| EnvExecTime             | 2.85       |
| ExplainedVariance       | 0.542      |
| Iteration               | 430        |
| ItrTime                 | 11.2       |
| LossAfter               | 0.493722   |
| LossBefore              | 0.542345   |
| MaxReturn               | 1.52e+03   |
| MeanKL                  | 0.00642673 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 29.1       |
| NumTrajs                | 16         |
| Perplexity              | 1124.41    |
| PolicyExecTime          | 0.566      |
| ProcessExecTime         | 0.0699     |
| StdReturn               | 415        |
| Time                    | 4.76e+03   |
| dLoss                   | 0.0486239  |
----------------------------------------
itr #431 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 431...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5253, #subsample_inputs: 5253
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.69       |
| AbsLearnSignalNew       | 0.69       |
| AbsLearningOld          | 0.69       |
| AverageDiscountedReturn | 113        |
| AveragePhiLoss          | 0.980442   |
| AveragePolicyStd        | 0.782821   |
| AverageReturn           | 463        |
| Entropy                 | 7.03268    |
| EnvExecTime             | 3.18       |
| ExplainedVariance       | 0.501      |
| Iteration               | 431        |
| ItrTime                 | 10.3       |
| LossAfter               | 0.821065   |
| LossBefore              | 0.879054   |
| MaxReturn               | 1.23e+03   |
| MeanKL                  | 0.00992283 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 46.3       |
| NumTrajs                | 20         |
| Perplexity              | 1133.06    |
| PolicyExecTime          | 0.633      |
| ProcessExecTime         | 0.0837     |
| StdReturn               | 300        |
| Time                    | 4.77e+03   |
| dLoss                   | 0.0579886  |
----------------------------------------
itr #432 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 432...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5504, #subsample_inputs: 5504
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.674      |
| AbsLearnSignalNew       | 0.674      |
| AbsLearningOld          | 0.674      |
| AverageDiscountedReturn | 111        |
| AveragePhiLoss          | 0.983709   |
| AveragePolicyStd        | 0.783166   |
| AverageReturn           | 536        |
| Entropy                 | 7.03587    |
| EnvExecTime             | 3.19       |
| ExplainedVariance       | 0.0953     |
| Iteration               | 432        |
| ItrTime                 | 11.9       |
| LossAfter               | 0.812691   |
| LossBefore              | 0.855221   |
| MaxReturn               | 1.86e+03   |
| MeanKL                  | 0.00641899 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 25.2       |
| NumTrajs                | 19         |
| Perplexity              | 1136.69    |
| PolicyExecTime          | 0.658      |
| ProcessExecTime         | 0.088      |
| StdReturn               | 447        |
| Time                    | 4.78e+03   |
| dLoss                   | 0.0425302  |
----------------------------------------
itr #433 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 433...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5121, #subsample_inputs: 5121
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.676      |
| AbsLearnSignalNew       | 0.676      |
| AbsLearningOld          | 0.676      |
| AverageDiscountedReturn | 132        |
| AveragePhiLoss          | 0.970334   |
| AveragePolicyStd        | 0.780583   |
| AverageReturn           | 808        |
| Entropy                 | 7.01507    |
| EnvExecTime             | 2.78       |
| ExplainedVariance       | 0.502      |
| Iteration               | 433        |
| ItrTime                 | 11.4       |
| LossAfter               | 0.518404   |
| LossBefore              | 0.565449   |
| MaxReturn               | 2.39e+03   |
| MeanKL                  | 0.00642079 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 63.6       |
| NumTrajs                | 14         |
| Perplexity              | 1113.28    |
| PolicyExecTime          | 0.547      |
| ProcessExecTime         | 0.0689     |
| StdReturn               | 548        |
| Time                    | 4.79e+03   |
| dLoss                   | 0.0470459  |
----------------------------------------
itr #434 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 434...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5747, #subsample_inputs: 5747
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.709      |
| AbsLearnSignalNew       | 0.709      |
| AbsLearningOld          | 0.709      |
| AverageDiscountedReturn | 138        |
| AveragePhiLoss          | 0.984796   |
| AveragePolicyStd        | 0.780128   |
| AverageReturn           | 974        |
| Entropy                 | 7.01019    |
| EnvExecTime             | 3.52       |
| ExplainedVariance       | 0.559      |
| Iteration               | 434        |
| ItrTime                 | 11.5       |
| LossAfter               | 0.0111637  |
| LossBefore              | 0.0519751  |
| MaxReturn               | 2.23e+03   |
| MeanKL                  | 0.00644019 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 79.1       |
| NumTrajs                | 13         |
| Perplexity              | 1107.87    |
| PolicyExecTime          | 0.745      |
| ProcessExecTime         | 0.095      |
| StdReturn               | 750        |
| Time                    | 4.81e+03   |
| dLoss                   | 0.0408114  |
----------------------------------------
itr #435 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 435...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5775, #subsample_inputs: 5775
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.689      |
| AbsLearnSignalNew       | 0.689      |
| AbsLearningOld          | 0.689      |
| AverageDiscountedReturn | 135        |
| AveragePhiLoss          | 0.979004   |
| AveragePolicyStd        | 0.779891   |
| AverageReturn           | 799        |
| Entropy                 | 7.00895    |
| EnvExecTime             | 3.58       |
| ExplainedVariance       | 0.572      |
| Iteration               | 435        |
| ItrTime                 | 12.7       |
| LossAfter               | 0.0557482  |
| LossBefore              | 0.107537   |
| MaxReturn               | 2.19e+03   |
| MeanKL                  | 0.00641895 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 269        |
| NumTrajs                | 15         |
| Perplexity              | 1106.49    |
| PolicyExecTime          | 0.713      |
| ProcessExecTime         | 0.0937     |
| StdReturn               | 464        |
| Time                    | 4.82e+03   |
| dLoss                   | 0.0517885  |
----------------------------------------
itr #436 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 436...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5122, #subsample_inputs: 5122
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.728     |
| AbsLearnSignalNew       | 0.728     |
| AbsLearningOld          | 0.727     |
| AverageDiscountedReturn | 137       |
| AveragePhiLoss          | 0.97821   |
| AveragePolicyStd        | 0.778703  |
| AverageReturn           | 773       |
| Entropy                 | 6.99992   |
| EnvExecTime             | 2.59      |
| ExplainedVariance       | 0.612     |
| Iteration               | 436       |
| ItrTime                 | 10.6      |
| LossAfter               | 0.686414  |
| LossBefore              | 0.740391  |
| MaxReturn               | 1.19e+03  |
| MeanKL                  | 0.0098821 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 447       |
| NumTrajs                | 15        |
| Perplexity              | 1096.55   |
| PolicyExecTime          | 0.5       |
| ProcessExecTime         | 0.0686    |
| StdReturn               | 202       |
| Time                    | 4.83e+03  |
| dLoss                   | 0.0539776 |
---------------------------------------
itr #437 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 437...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5268, #subsample_inputs: 5268
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.62       |
| AbsLearnSignalNew       | 0.62       |
| AbsLearningOld          | 0.62       |
| AverageDiscountedReturn | 140        |
| AveragePhiLoss          | 0.974314   |
| AveragePolicyStd        | 0.778999   |
| AverageReturn           | 893        |
| Entropy                 | 7.00291    |
| EnvExecTime             | 3.13       |
| ExplainedVariance       | 0.35       |
| Iteration               | 437        |
| ItrTime                 | 10.9       |
| LossAfter               | -0.569676  |
| LossBefore              | -0.529267  |
| MaxReturn               | 1.9e+03    |
| MeanKL                  | 0.00641866 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 55.1       |
| NumTrajs                | 13         |
| Perplexity              | 1099.83    |
| PolicyExecTime          | 0.655      |
| ProcessExecTime         | 0.0831     |
| StdReturn               | 507        |
| Time                    | 4.84e+03   |
| dLoss                   | 0.0404095  |
----------------------------------------
itr #438 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 438...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5370, #subsample_inputs: 5370
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.698     |
| AbsLearnSignalNew       | 0.698     |
| AbsLearningOld          | 0.697     |
| AverageDiscountedReturn | 135       |
| AveragePhiLoss          | 0.968522  |
| AveragePolicyStd        | 0.777058  |
| AverageReturn           | 845       |
| Entropy                 | 6.98792   |
| EnvExecTime             | 3.33      |
| ExplainedVariance       | 0.568     |
| Iteration               | 438       |
| ItrTime                 | 12        |
| LossAfter               | -0.479847 |
| LossBefore              | -0.417356 |
| MaxReturn               | 1.79e+03  |
| MeanKL                  | 0.009959  |
| MeanKLBefore            | 0.0       |
| MinReturn               | 48.5      |
| NumTrajs                | 14        |
| Perplexity              | 1083.47   |
| PolicyExecTime          | 0.69      |
| ProcessExecTime         | 0.0837    |
| StdReturn               | 422       |
| Time                    | 4.85e+03  |
| dLoss                   | 0.0624909 |
---------------------------------------
itr #439 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 439...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5311, #subsample_inputs: 5311
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.685      |
| AbsLearnSignalNew       | 0.685      |
| AbsLearningOld          | 0.685      |
| AverageDiscountedReturn | 130        |
| AveragePhiLoss          | 0.982316   |
| AveragePolicyStd        | 0.777304   |
| AverageReturn           | 785        |
| Entropy                 | 6.99062    |
| EnvExecTime             | 3.06       |
| ExplainedVariance       | 0.35       |
| Iteration               | 439        |
| ItrTime                 | 11         |
| LossAfter               | -0.886545  |
| LossBefore              | -0.841863  |
| MaxReturn               | 1.83e+03   |
| MeanKL                  | 0.00647554 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 83.5       |
| NumTrajs                | 14         |
| Perplexity              | 1086.39    |
| PolicyExecTime          | 0.611      |
| ProcessExecTime         | 0.081      |
| StdReturn               | 417        |
| Time                    | 4.86e+03   |
| dLoss                   | 0.044682   |
----------------------------------------
itr #440 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 440...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5201, #subsample_inputs: 5201
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.679      |
| AbsLearnSignalNew       | 0.679      |
| AbsLearningOld          | 0.679      |
| AverageDiscountedReturn | 138        |
| AveragePhiLoss          | 0.975164   |
| AveragePolicyStd        | 0.775627   |
| AverageReturn           | 1.11e+03   |
| Entropy                 | 6.97762    |
| EnvExecTime             | 3.2        |
| ExplainedVariance       | 0.558      |
| Iteration               | 440        |
| ItrTime                 | 11.2       |
| LossAfter               | -1.17037   |
| LossBefore              | -1.12724   |
| MaxReturn               | 2.49e+03   |
| MeanKL                  | 0.00650906 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 69.6       |
| NumTrajs                | 11         |
| Perplexity              | 1072.36    |
| PolicyExecTime          | 0.702      |
| ProcessExecTime         | 0.0838     |
| StdReturn               | 713        |
| Time                    | 4.87e+03   |
| dLoss                   | 0.0431335  |
----------------------------------------
itr #441 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 441...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5324, #subsample_inputs: 5324
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.642      |
| AbsLearnSignalNew       | 0.642      |
| AbsLearningOld          | 0.642      |
| AverageDiscountedReturn | 130        |
| AveragePhiLoss          | 0.967374   |
| AveragePolicyStd        | 0.772127   |
| AverageReturn           | 663        |
| Entropy                 | 6.95016    |
| EnvExecTime             | 3.11       |
| ExplainedVariance       | 0.388      |
| Iteration               | 441        |
| ItrTime                 | 12.1       |
| LossAfter               | -0.963706  |
| LossBefore              | -0.917698  |
| MaxReturn               | 1.35e+03   |
| MeanKL                  | 0.00644445 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 381        |
| NumTrajs                | 15         |
| Perplexity              | 1043.31    |
| PolicyExecTime          | 0.623      |
| ProcessExecTime         | 0.076      |
| StdReturn               | 280        |
| Time                    | 4.89e+03   |
| dLoss                   | 0.0460085  |
----------------------------------------
itr #442 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 442...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5235, #subsample_inputs: 5235
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.552      |
| AbsLearnSignalNew       | 0.552      |
| AbsLearningOld          | 0.553      |
| AverageDiscountedReturn | 116        |
| AveragePhiLoss          | 0.98145    |
| AveragePolicyStd        | 0.770301   |
| AverageReturn           | 832        |
| Entropy                 | 6.93669    |
| EnvExecTime             | 3.05       |
| ExplainedVariance       | -0.0453    |
| Iteration               | 442        |
| ItrTime                 | 10.3       |
| LossAfter               | -0.449263  |
| LossBefore              | -0.402791  |
| MaxReturn               | 2.21e+03   |
| MeanKL                  | 0.00999237 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 61.3       |
| NumTrajs                | 12         |
| Perplexity              | 1029.36    |
| PolicyExecTime          | 0.619      |
| ProcessExecTime         | 0.0796     |
| StdReturn               | 706        |
| Time                    | 4.9e+03    |
| dLoss                   | 0.046472   |
----------------------------------------
itr #443 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 443...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5398, #subsample_inputs: 5398
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.705      |
| AbsLearnSignalNew       | 0.705      |
| AbsLearningOld          | 0.705      |
| AverageDiscountedReturn | 132        |
| AveragePhiLoss          | 0.973873   |
| AveragePolicyStd        | 0.771633   |
| AverageReturn           | 808        |
| Entropy                 | 6.94794    |
| EnvExecTime             | 2.93       |
| ExplainedVariance       | 0.392      |
| Iteration               | 443        |
| ItrTime                 | 11.7       |
| LossAfter               | -0.132599  |
| LossBefore              | -0.077832  |
| MaxReturn               | 1.9e+03    |
| MeanKL                  | 0.00994264 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 279        |
| NumTrajs                | 14         |
| Perplexity              | 1041.0     |
| PolicyExecTime          | 0.598      |
| ProcessExecTime         | 0.0809     |
| StdReturn               | 448        |
| Time                    | 4.91e+03   |
| dLoss                   | 0.0547667  |
----------------------------------------
itr #444 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 444...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5143, #subsample_inputs: 5143
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.593      |
| AbsLearnSignalNew       | 0.593      |
| AbsLearningOld          | 0.593      |
| AverageDiscountedReturn | 127        |
| AveragePhiLoss          | 0.970008   |
| AveragePolicyStd        | 0.770035   |
| AverageReturn           | 719        |
| Entropy                 | 6.93491    |
| EnvExecTime             | 2.76       |
| ExplainedVariance       | 0.358      |
| Iteration               | 444        |
| ItrTime                 | 11.3       |
| LossAfter               | 0.480223   |
| LossBefore              | 0.529448   |
| MaxReturn               | 1.65e+03   |
| MeanKL                  | 0.00651802 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 80.1       |
| NumTrajs                | 14         |
| Perplexity              | 1027.53    |
| PolicyExecTime          | 0.526      |
| ProcessExecTime         | 0.069      |
| StdReturn               | 397        |
| Time                    | 4.92e+03   |
| dLoss                   | 0.0492247  |
----------------------------------------
itr #445 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 445...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5175, #subsample_inputs: 5175
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.672      |
| AbsLearnSignalNew       | 0.672      |
| AbsLearningOld          | 0.672      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 0.978593   |
| AveragePolicyStd        | 0.77018    |
| AverageReturn           | 700        |
| Entropy                 | 6.93528    |
| EnvExecTime             | 2.99       |
| ExplainedVariance       | 0.495      |
| Iteration               | 445        |
| ItrTime                 | 10.3       |
| LossAfter               | 0.877329   |
| LossBefore              | 0.932829   |
| MaxReturn               | 1.32e+03   |
| MeanKL                  | 0.00985513 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 69.4       |
| NumTrajs                | 15         |
| Perplexity              | 1027.91    |
| PolicyExecTime          | 0.615      |
| ProcessExecTime         | 0.0819     |
| StdReturn               | 407        |
| Time                    | 4.93e+03   |
| dLoss                   | 0.0554996  |
----------------------------------------
itr #446 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 446...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5714, #subsample_inputs: 5714
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.599      |
| AbsLearnSignalNew       | 0.599      |
| AbsLearningOld          | 0.599      |
| AverageDiscountedReturn | 115        |
| AveragePhiLoss          | 0.982094   |
| AveragePolicyStd        | 0.771163   |
| AverageReturn           | 552        |
| Entropy                 | 6.94289    |
| EnvExecTime             | 3.65       |
| ExplainedVariance       | -0.0762    |
| Iteration               | 446        |
| ItrTime                 | 12.9       |
| LossAfter               | 1.25101    |
| LossBefore              | 1.29853    |
| MaxReturn               | 1.71e+03   |
| MeanKL                  | 0.00645919 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 49.9       |
| NumTrajs                | 19         |
| Perplexity              | 1035.76    |
| PolicyExecTime          | 0.736      |
| ProcessExecTime         | 0.0979     |
| StdReturn               | 438        |
| Time                    | 4.94e+03   |
| dLoss                   | 0.0475186  |
----------------------------------------
itr #447 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 447...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5213, #subsample_inputs: 5213
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.658      |
| AbsLearnSignalNew       | 0.658      |
| AbsLearningOld          | 0.658      |
| AverageDiscountedReturn | 132        |
| AveragePhiLoss          | 0.977333   |
| AveragePolicyStd        | 0.770778   |
| AverageReturn           | 611        |
| Entropy                 | 6.93907    |
| EnvExecTime             | 2.99       |
| ExplainedVariance       | 0.239      |
| Iteration               | 447        |
| ItrTime                 | 11.1       |
| LossAfter               | 1.24926    |
| LossBefore              | 1.29329    |
| MaxReturn               | 1.37e+03   |
| MeanKL                  | 0.00645411 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 135        |
| NumTrajs                | 17         |
| Perplexity              | 1031.82    |
| PolicyExecTime          | 0.573      |
| ProcessExecTime         | 0.0736     |
| StdReturn               | 295        |
| Time                    | 4.95e+03   |
| dLoss                   | 0.0440285  |
----------------------------------------
itr #448 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 448...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5858, #subsample_inputs: 5858
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.755      |
| AbsLearnSignalNew       | 0.755      |
| AbsLearningOld          | 0.755      |
| AverageDiscountedReturn | 152        |
| AveragePhiLoss          | 0.984304   |
| AveragePolicyStd        | 0.767693   |
| AverageReturn           | 1.01e+03   |
| Entropy                 | 6.9157     |
| EnvExecTime             | 3.28       |
| ExplainedVariance       | 0.522      |
| Iteration               | 448        |
| ItrTime                 | 11.4       |
| LossAfter               | 0.779691   |
| LossBefore              | 0.831295   |
| MaxReturn               | 2.02e+03   |
| MeanKL                  | 0.00974759 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 384        |
| NumTrajs                | 14         |
| Perplexity              | 1007.98    |
| PolicyExecTime          | 0.666      |
| ProcessExecTime         | 0.093      |
| StdReturn               | 483        |
| Time                    | 4.97e+03   |
| dLoss                   | 0.0516044  |
----------------------------------------
itr #449 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 449...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5084, #subsample_inputs: 5084
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.549      |
| AbsLearnSignalNew       | 0.549      |
| AbsLearningOld          | 0.549      |
| AverageDiscountedReturn | 119        |
| AveragePhiLoss          | 0.972494   |
| AveragePolicyStd        | 0.768111   |
| AverageReturn           | 553        |
| Entropy                 | 6.91897    |
| EnvExecTime             | 3.26       |
| ExplainedVariance       | 0.304      |
| Iteration               | 449        |
| ItrTime                 | 11.7       |
| LossAfter               | 0.214554   |
| LossBefore              | 0.270455   |
| MaxReturn               | 1.52e+03   |
| MeanKL                  | 0.00990341 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 75.5       |
| NumTrajs                | 17         |
| Perplexity              | 1011.27    |
| PolicyExecTime          | 0.677      |
| ProcessExecTime         | 0.0843     |
| StdReturn               | 329        |
| Time                    | 4.98e+03   |
| dLoss                   | 0.0559017  |
----------------------------------------
itr #450 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 450...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5331, #subsample_inputs: 5331
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.7        |
| AbsLearnSignalNew       | 0.7        |
| AbsLearningOld          | 0.7        |
| AverageDiscountedReturn | 138        |
| AveragePhiLoss          | 0.979775   |
| AveragePolicyStd        | 0.767713   |
| AverageReturn           | 904        |
| Entropy                 | 6.91728    |
| EnvExecTime             | 2.9        |
| ExplainedVariance       | 0.466      |
| Iteration               | 450        |
| ItrTime                 | 10.8       |
| LossAfter               | -0.344379  |
| LossBefore              | -0.299432  |
| MaxReturn               | 1.83e+03   |
| MeanKL                  | 0.00641202 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 333        |
| NumTrajs                | 13         |
| Perplexity              | 1009.57    |
| PolicyExecTime          | 0.584      |
| ProcessExecTime         | 0.0776     |
| StdReturn               | 414        |
| Time                    | 4.99e+03   |
| dLoss                   | 0.0449473  |
----------------------------------------
itr #451 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 451...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5158, #subsample_inputs: 5158
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.645      |
| AbsLearnSignalNew       | 0.645      |
| AbsLearningOld          | 0.645      |
| AverageDiscountedReturn | 123        |
| AveragePhiLoss          | 0.976156   |
| AveragePolicyStd        | 0.766834   |
| AverageReturn           | 766        |
| Entropy                 | 6.91048    |
| EnvExecTime             | 3.23       |
| ExplainedVariance       | 0.572      |
| Iteration               | 451        |
| ItrTime                 | 11.6       |
| LossAfter               | 0.146494   |
| LossBefore              | 0.211334   |
| MaxReturn               | 1.84e+03   |
| MeanKL                  | 0.00997908 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 43.9       |
| NumTrajs                | 14         |
| Perplexity              | 1002.73    |
| PolicyExecTime          | 0.66       |
| ProcessExecTime         | 0.086      |
| StdReturn               | 486        |
| Time                    | 5e+03      |
| dLoss                   | 0.0648398  |
----------------------------------------
itr #452 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 452...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5085, #subsample_inputs: 5085
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.581      |
| AbsLearnSignalNew       | 0.581      |
| AbsLearningOld          | 0.581      |
| AverageDiscountedReturn | 135        |
| AveragePhiLoss          | 0.972888   |
| AveragePolicyStd        | 0.768908   |
| AverageReturn           | 1.03e+03   |
| Entropy                 | 6.92678    |
| EnvExecTime             | 2.58       |
| ExplainedVariance       | -0.0213    |
| Iteration               | 452        |
| ItrTime                 | 11         |
| LossAfter               | 0.610853   |
| LossBefore              | 0.652386   |
| MaxReturn               | 2.41e+03   |
| MeanKL                  | 0.00640487 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 239        |
| NumTrajs                | 11         |
| Perplexity              | 1019.2     |
| PolicyExecTime          | 0.53       |
| ProcessExecTime         | 0.0698     |
| StdReturn               | 751        |
| Time                    | 5.01e+03   |
| dLoss                   | 0.0415334  |
----------------------------------------
itr #453 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 453...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5282, #subsample_inputs: 5282
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.57       |
| AbsLearnSignalNew       | 0.57       |
| AbsLearningOld          | 0.57       |
| AverageDiscountedReturn | 111        |
| AveragePhiLoss          | 0.973808   |
| AveragePolicyStd        | 0.769189   |
| AverageReturn           | 481        |
| Entropy                 | 6.92997    |
| EnvExecTime             | 3.32       |
| ExplainedVariance       | 0.215      |
| Iteration               | 453        |
| ItrTime                 | 10.6       |
| LossAfter               | -0.230383  |
| LossBefore              | -0.172249  |
| MaxReturn               | 1.27e+03   |
| MeanKL                  | 0.00642325 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 68         |
| NumTrajs                | 18         |
| Perplexity              | 1022.46    |
| PolicyExecTime          | 0.658      |
| ProcessExecTime         | 0.0866     |
| StdReturn               | 346        |
| Time                    | 5.02e+03   |
| dLoss                   | 0.0581345  |
----------------------------------------
itr #454 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 454...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5044, #subsample_inputs: 5044
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.75       |
| AbsLearnSignalNew       | 0.75       |
| AbsLearningOld          | 0.75       |
| AverageDiscountedReturn | 127        |
| AveragePhiLoss          | 0.974151   |
| AveragePolicyStd        | 0.767622   |
| AverageReturn           | 759        |
| Entropy                 | 6.91749    |
| EnvExecTime             | 3.16       |
| ExplainedVariance       | 0.516      |
| Iteration               | 454        |
| ItrTime                 | 11.7       |
| LossAfter               | 1.37469    |
| LossBefore              | 1.42982    |
| MaxReturn               | 2.28e+03   |
| MeanKL                  | 0.00994073 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 59.9       |
| NumTrajs                | 14         |
| Perplexity              | 1009.78    |
| PolicyExecTime          | 0.641      |
| ProcessExecTime         | 0.0831     |
| StdReturn               | 571        |
| Time                    | 5.03e+03   |
| dLoss                   | 0.055135   |
----------------------------------------
itr #455 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 455...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5314, #subsample_inputs: 5314
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.691      |
| AbsLearnSignalNew       | 0.691      |
| AbsLearningOld          | 0.691      |
| AverageDiscountedReturn | 133        |
| AveragePhiLoss          | 0.973298   |
| AveragePolicyStd        | 0.769786   |
| AverageReturn           | 687        |
| Entropy                 | 6.93472    |
| EnvExecTime             | 3          |
| ExplainedVariance       | 0.449      |
| Iteration               | 455        |
| ItrTime                 | 11.8       |
| LossAfter               | 0.178125   |
| LossBefore              | 0.22604    |
| MaxReturn               | 1.85e+03   |
| MeanKL                  | 0.00645038 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 78.8       |
| NumTrajs                | 16         |
| Perplexity              | 1027.33    |
| PolicyExecTime          | 0.578      |
| ProcessExecTime         | 0.0722     |
| StdReturn               | 444        |
| Time                    | 5.05e+03   |
| dLoss                   | 0.0479157  |
----------------------------------------
itr #456 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 456...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5306, #subsample_inputs: 5306
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.701      |
| AbsLearnSignalNew       | 0.701      |
| AbsLearningOld          | 0.701      |
| AverageDiscountedReturn | 136        |
| AveragePhiLoss          | 0.972618   |
| AveragePolicyStd        | 0.768904   |
| AverageReturn           | 750        |
| Entropy                 | 6.92777    |
| EnvExecTime             | 3.58       |
| ExplainedVariance       | 0.512      |
| Iteration               | 456        |
| ItrTime                 | 11.1       |
| LossAfter               | 0.755098   |
| LossBefore              | 0.810593   |
| MaxReturn               | 1.33e+03   |
| MeanKL                  | 0.00995039 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 81.7       |
| NumTrajs                | 16         |
| Perplexity              | 1020.21    |
| PolicyExecTime          | 0.731      |
| ProcessExecTime         | 0.092      |
| StdReturn               | 372        |
| Time                    | 5.06e+03   |
| dLoss                   | 0.0554951  |
----------------------------------------
itr #457 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 457...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5318, #subsample_inputs: 5318
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.69       |
| AbsLearnSignalNew       | 0.69       |
| AbsLearningOld          | 0.69       |
| AverageDiscountedReturn | 119        |
| AveragePhiLoss          | 0.980495   |
| AveragePolicyStd        | 0.768428   |
| AverageReturn           | 600        |
| Entropy                 | 6.9245     |
| EnvExecTime             | 3.28       |
| ExplainedVariance       | 0.478      |
| Iteration               | 457        |
| ItrTime                 | 12.3       |
| LossAfter               | 0.592283   |
| LossBefore              | 0.634112   |
| MaxReturn               | 1.45e+03   |
| MeanKL                  | 0.00645807 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 43.5       |
| NumTrajs                | 18         |
| Perplexity              | 1016.89    |
| PolicyExecTime          | 0.689      |
| ProcessExecTime         | 0.0868     |
| StdReturn               | 418        |
| Time                    | 5.07e+03   |
| dLoss                   | 0.0418286  |
----------------------------------------
itr #458 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 458...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5123, #subsample_inputs: 5123
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.755      |
| AbsLearnSignalNew       | 0.755      |
| AbsLearningOld          | 0.755      |
| AverageDiscountedReturn | 129        |
| AveragePhiLoss          | 0.972198   |
| AveragePolicyStd        | 0.765971   |
| AverageReturn           | 612        |
| Entropy                 | 6.9053     |
| EnvExecTime             | 2.8        |
| ExplainedVariance       | 0.369      |
| Iteration               | 458        |
| ItrTime                 | 10.8       |
| LossAfter               | 0.649863   |
| LossBefore              | 0.711538   |
| MaxReturn               | 1.44e+03   |
| MeanKL                  | 0.00993321 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 83.1       |
| NumTrajs                | 16         |
| Perplexity              | 997.551    |
| PolicyExecTime          | 0.532      |
| ProcessExecTime         | 0.0689     |
| StdReturn               | 394        |
| Time                    | 5.08e+03   |
| dLoss                   | 0.061675   |
----------------------------------------
itr #459 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 459...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5024, #subsample_inputs: 5024
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.672      |
| AbsLearnSignalNew       | 0.672      |
| AbsLearningOld          | 0.672      |
| AverageDiscountedReturn | 142        |
| AveragePhiLoss          | 0.980571   |
| AveragePolicyStd        | 0.767341   |
| AverageReturn           | 752        |
| Entropy                 | 6.91635    |
| EnvExecTime             | 3.64       |
| ExplainedVariance       | 0.416      |
| Iteration               | 459        |
| ItrTime                 | 11.2       |
| LossAfter               | 0.372489   |
| LossBefore              | 0.432754   |
| MaxReturn               | 1.49e+03   |
| MeanKL                  | 0.00996623 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 344        |
| NumTrajs                | 15         |
| Perplexity              | 1008.63    |
| PolicyExecTime          | 0.754      |
| ProcessExecTime         | 0.0919     |
| StdReturn               | 398        |
| Time                    | 5.09e+03   |
| dLoss                   | 0.0602651  |
----------------------------------------
itr #460 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 460...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5032, #subsample_inputs: 5032
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.699      |
| AbsLearnSignalNew       | 0.699      |
| AbsLearningOld          | 0.699      |
| AverageDiscountedReturn | 132        |
| AveragePhiLoss          | 0.977955   |
| AveragePolicyStd        | 0.766074   |
| AverageReturn           | 620        |
| Entropy                 | 6.90602    |
| EnvExecTime             | 3.12       |
| ExplainedVariance       | 0.448      |
| Iteration               | 460        |
| ItrTime                 | 11.9       |
| LossAfter               | 0.18934    |
| LossBefore              | 0.243539   |
| MaxReturn               | 1.87e+03   |
| MeanKL                  | 0.00973232 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 52.6       |
| NumTrajs                | 17         |
| Perplexity              | 998.268    |
| PolicyExecTime          | 0.656      |
| ProcessExecTime         | 0.0805     |
| StdReturn               | 435        |
| Time                    | 5.1e+03    |
| dLoss                   | 0.0541999  |
----------------------------------------
itr #461 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 461...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5189, #subsample_inputs: 5189
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.663      |
| AbsLearnSignalNew       | 0.663      |
| AbsLearningOld          | 0.664      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 0.971203   |
| AveragePolicyStd        | 0.768113   |
| AverageReturn           | 650        |
| Entropy                 | 6.92166    |
| EnvExecTime             | 3.02       |
| ExplainedVariance       | 0.487      |
| Iteration               | 461        |
| ItrTime                 | 10.6       |
| LossAfter               | 0.194763   |
| LossBefore              | 0.260635   |
| MaxReturn               | 1.82e+03   |
| MeanKL                  | 0.00994323 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 43.7       |
| NumTrajs                | 16         |
| Perplexity              | 1014.0     |
| PolicyExecTime          | 0.624      |
| ProcessExecTime         | 0.0794     |
| StdReturn               | 542        |
| Time                    | 5.11e+03   |
| dLoss                   | 0.0658715  |
----------------------------------------
itr #462 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 462...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5439, #subsample_inputs: 5439
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.734      |
| AbsLearnSignalNew       | 0.734      |
| AbsLearningOld          | 0.734      |
| AverageDiscountedReturn | 140        |
| AveragePhiLoss          | 0.9722     |
| AveragePolicyStd        | 0.769453   |
| AverageReturn           | 716        |
| Entropy                 | 6.93181    |
| EnvExecTime             | 3.16       |
| ExplainedVariance       | 0.363      |
| Iteration               | 462        |
| ItrTime                 | 11.6       |
| LossAfter               | 0.280702   |
| LossBefore              | 0.321896   |
| MaxReturn               | 2.03e+03   |
| MeanKL                  | 0.00645085 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 314        |
| NumTrajs                | 16         |
| Perplexity              | 1024.35    |
| PolicyExecTime          | 0.643      |
| ProcessExecTime         | 0.0832     |
| StdReturn               | 469        |
| Time                    | 5.13e+03   |
| dLoss                   | 0.0411942  |
----------------------------------------
itr #463 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 463...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5223, #subsample_inputs: 5223
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.673      |
| AbsLearnSignalNew       | 0.673      |
| AbsLearningOld          | 0.674      |
| AverageDiscountedReturn | 133        |
| AveragePhiLoss          | 0.986107   |
| AveragePolicyStd        | 0.769831   |
| AverageReturn           | 731        |
| Entropy                 | 6.93438    |
| EnvExecTime             | 3.09       |
| ExplainedVariance       | 0.461      |
| Iteration               | 463        |
| ItrTime                 | 11.9       |
| LossAfter               | -0.0799709 |
| LossBefore              | -0.0215881 |
| MaxReturn               | 1.98e+03   |
| MeanKL                  | 0.00998939 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 62.3       |
| NumTrajs                | 15         |
| Perplexity              | 1026.99    |
| PolicyExecTime          | 0.634      |
| ProcessExecTime         | 0.0767     |
| StdReturn               | 466        |
| Time                    | 5.14e+03   |
| dLoss                   | 0.0583827  |
----------------------------------------
itr #464 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 464...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5008, #subsample_inputs: 5008
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.618      |
| AbsLearnSignalNew       | 0.618      |
| AbsLearningOld          | 0.618      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 0.972413   |
| AveragePolicyStd        | 0.767007   |
| AverageReturn           | 548        |
| Entropy                 | 6.9132     |
| EnvExecTime             | 3.01       |
| ExplainedVariance       | 0.395      |
| Iteration               | 464        |
| ItrTime                 | 10.2       |
| LossAfter               | -0.20832   |
| LossBefore              | -0.113581  |
| MaxReturn               | 1.26e+03   |
| MeanKL                  | 0.00985431 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 82.1       |
| NumTrajs                | 17         |
| Perplexity              | 1005.46    |
| PolicyExecTime          | 0.619      |
| ProcessExecTime         | 0.0815     |
| StdReturn               | 324        |
| Time                    | 5.15e+03   |
| dLoss                   | 0.0947398  |
----------------------------------------
itr #465 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 465...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5027, #subsample_inputs: 5027
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.673      |
| AbsLearnSignalNew       | 0.673      |
| AbsLearningOld          | 0.673      |
| AverageDiscountedReturn | 142        |
| AveragePhiLoss          | 0.972551   |
| AveragePolicyStd        | 0.768649   |
| AverageReturn           | 828        |
| Entropy                 | 6.92611    |
| EnvExecTime             | 3.27       |
| ExplainedVariance       | 0.289      |
| Iteration               | 465        |
| ItrTime                 | 11.9       |
| LossAfter               | -0.633517  |
| LossBefore              | -0.579219  |
| MaxReturn               | 1.86e+03   |
| MeanKL                  | 0.00995772 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 196        |
| NumTrajs                | 13         |
| Perplexity              | 1018.52    |
| PolicyExecTime          | 0.664      |
| ProcessExecTime         | 0.0837     |
| StdReturn               | 455        |
| Time                    | 5.16e+03   |
| dLoss                   | 0.0542979  |
----------------------------------------
itr #466 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 466...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5484, #subsample_inputs: 5484
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.683      |
| AbsLearnSignalNew       | 0.683      |
| AbsLearningOld          | 0.683      |
| AverageDiscountedReturn | 129        |
| AveragePhiLoss          | 0.979642   |
| AveragePolicyStd        | 0.76819    |
| AverageReturn           | 782        |
| Entropy                 | 6.922      |
| EnvExecTime             | 2.89       |
| ExplainedVariance       | 0.526      |
| Iteration               | 466        |
| ItrTime                 | 11.3       |
| LossAfter               | -0.20355   |
| LossBefore              | -0.14657   |
| MaxReturn               | 1.45e+03   |
| MeanKL                  | 0.00993533 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 50.9       |
| NumTrajs                | 15         |
| Perplexity              | 1014.35    |
| PolicyExecTime          | 0.566      |
| ProcessExecTime         | 0.0744     |
| StdReturn               | 410        |
| Time                    | 5.17e+03   |
| dLoss                   | 0.0569795  |
----------------------------------------
itr #467 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 467...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5193, #subsample_inputs: 5193
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.64       |
| AbsLearnSignalNew       | 0.64       |
| AbsLearningOld          | 0.64       |
| AverageDiscountedReturn | 135        |
| AveragePhiLoss          | 0.975328   |
| AveragePolicyStd        | 0.764426   |
| AverageReturn           | 752        |
| Entropy                 | 6.89241    |
| EnvExecTime             | 3.13       |
| ExplainedVariance       | 0.0268     |
| Iteration               | 467        |
| ItrTime                 | 10.6       |
| LossAfter               | 0.225725   |
| LossBefore              | 0.289917   |
| MaxReturn               | 2.56e+03   |
| MeanKL                  | 0.00997998 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 82.2       |
| NumTrajs                | 15         |
| Perplexity              | 984.775    |
| PolicyExecTime          | 0.646      |
| ProcessExecTime         | 0.0839     |
| StdReturn               | 554        |
| Time                    | 5.18e+03   |
| dLoss                   | 0.0641924  |
----------------------------------------
itr #468 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 468...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5208, #subsample_inputs: 5208
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.644      |
| AbsLearnSignalNew       | 0.644      |
| AbsLearningOld          | 0.644      |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 0.973293   |
| AveragePolicyStd        | 0.763776   |
| AverageReturn           | 492        |
| Entropy                 | 6.88814    |
| EnvExecTime             | 3.05       |
| ExplainedVariance       | 0.422      |
| Iteration               | 468        |
| ItrTime                 | 11.5       |
| LossAfter               | 0.72016    |
| LossBefore              | 0.785659   |
| MaxReturn               | 1e+03      |
| MeanKL                  | 0.00986349 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 55.5       |
| NumTrajs                | 20         |
| Perplexity              | 980.579    |
| PolicyExecTime          | 0.606      |
| ProcessExecTime         | 0.0783     |
| StdReturn               | 263        |
| Time                    | 5.19e+03   |
| dLoss                   | 0.0654983  |
----------------------------------------
itr #469 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 469...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5446, #subsample_inputs: 5446
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.657      |
| AbsLearnSignalNew       | 0.657      |
| AbsLearningOld          | 0.657      |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 0.990869   |
| AveragePolicyStd        | 0.76224    |
| AverageReturn           | 708        |
| Entropy                 | 6.87617    |
| EnvExecTime             | 3.34       |
| ExplainedVariance       | 0.316      |
| Iteration               | 469        |
| ItrTime                 | 11.8       |
| LossAfter               | 1.07783    |
| LossBefore              | 1.12254    |
| MaxReturn               | 1.5e+03    |
| MeanKL                  | 0.00640375 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 42.6       |
| NumTrajs                | 16         |
| Perplexity              | 968.913    |
| PolicyExecTime          | 0.676      |
| ProcessExecTime         | 0.0859     |
| StdReturn               | 431        |
| Time                    | 5.21e+03   |
| dLoss                   | 0.0447154  |
----------------------------------------
itr #470 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 470...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5044, #subsample_inputs: 5044
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.577      |
| AbsLearnSignalNew       | 0.577      |
| AbsLearningOld          | 0.577      |
| AverageDiscountedReturn | 137        |
| AveragePhiLoss          | 0.981229   |
| AveragePolicyStd        | 0.761611   |
| AverageReturn           | 1.16e+03   |
| Entropy                 | 6.87054    |
| EnvExecTime             | 2.99       |
| ExplainedVariance       | -1.27      |
| Iteration               | 470        |
| ItrTime                 | 10.9       |
| LossAfter               | 0.826019   |
| LossBefore              | 0.875903   |
| MaxReturn               | 2.54e+03   |
| MeanKL                  | 0.00641506 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 432        |
| NumTrajs                | 10         |
| Perplexity              | 963.469    |
| PolicyExecTime          | 0.623      |
| ProcessExecTime         | 0.0803     |
| StdReturn               | 593        |
| Time                    | 5.22e+03   |
| dLoss                   | 0.0498847  |
----------------------------------------
itr #471 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 471...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5668, #subsample_inputs: 5668
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.655      |
| AbsLearnSignalNew       | 0.655      |
| AbsLearningOld          | 0.655      |
| AverageDiscountedReturn | 138        |
| AveragePhiLoss          | 0.981651   |
| AveragePolicyStd        | 0.759794   |
| AverageReturn           | 790        |
| Entropy                 | 6.85657    |
| EnvExecTime             | 3.13       |
| ExplainedVariance       | 0.502      |
| Iteration               | 471        |
| ItrTime                 | 12.2       |
| LossAfter               | -0.23998   |
| LossBefore              | -0.191923  |
| MaxReturn               | 2.23e+03   |
| MeanKL                  | 0.00642191 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 95.5       |
| NumTrajs                | 16         |
| Perplexity              | 950.099    |
| PolicyExecTime          | 0.669      |
| ProcessExecTime         | 0.0812     |
| StdReturn               | 500        |
| Time                    | 5.23e+03   |
| dLoss                   | 0.0480575  |
----------------------------------------
itr #472 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 472...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5436, #subsample_inputs: 5436
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.72       |
| AbsLearnSignalNew       | 0.72       |
| AbsLearningOld          | 0.72       |
| AverageDiscountedReturn | 139        |
| AveragePhiLoss          | 0.982141   |
| AveragePolicyStd        | 0.761788   |
| AverageReturn           | 793        |
| Entropy                 | 6.87261    |
| EnvExecTime             | 2.99       |
| ExplainedVariance       | 0.686      |
| Iteration               | 472        |
| ItrTime                 | 10.7       |
| LossAfter               | 1.18494    |
| LossBefore              | 1.2399     |
| MaxReturn               | 2.05e+03   |
| MeanKL                  | 0.00989673 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 286        |
| NumTrajs                | 16         |
| Perplexity              | 965.466    |
| PolicyExecTime          | 0.618      |
| ProcessExecTime         | 0.0807     |
| StdReturn               | 473        |
| Time                    | 5.24e+03   |
| dLoss                   | 0.0549606  |
----------------------------------------
itr #473 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 473...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5179, #subsample_inputs: 5179
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.712      |
| AbsLearnSignalNew       | 0.712      |
| AbsLearningOld          | 0.712      |
| AverageDiscountedReturn | 152        |
| AveragePhiLoss          | 0.983461   |
| AveragePolicyStd        | 0.760691   |
| AverageReturn           | 835        |
| Entropy                 | 6.8638     |
| EnvExecTime             | 3.25       |
| ExplainedVariance       | 0.345      |
| Iteration               | 473        |
| ItrTime                 | 11.9       |
| LossAfter               | 1.36413    |
| LossBefore              | 1.40349    |
| MaxReturn               | 2.37e+03   |
| MeanKL                  | 0.00642127 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 270        |
| NumTrajs                | 15         |
| Perplexity              | 956.996    |
| PolicyExecTime          | 0.702      |
| ProcessExecTime         | 0.0883     |
| StdReturn               | 546        |
| Time                    | 5.25e+03   |
| dLoss                   | 0.0393604  |
----------------------------------------
itr #474 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 474...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5091, #subsample_inputs: 5091
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.622      |
| AbsLearnSignalNew       | 0.622      |
| AbsLearningOld          | 0.622      |
| AverageDiscountedReturn | 130        |
| AveragePhiLoss          | 0.963787   |
| AveragePolicyStd        | 0.760069   |
| AverageReturn           | 679        |
| Entropy                 | 6.85934    |
| EnvExecTime             | 2.87       |
| ExplainedVariance       | 0.287      |
| Iteration               | 474        |
| ItrTime                 | 11.1       |
| LossAfter               | 0.681847   |
| LossBefore              | 0.761942   |
| MaxReturn               | 1.33e+03   |
| MeanKL                  | 0.00993987 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 26         |
| NumTrajs                | 15         |
| Perplexity              | 952.736    |
| PolicyExecTime          | 0.547      |
| ProcessExecTime         | 0.0696     |
| StdReturn               | 369        |
| Time                    | 5.26e+03   |
| dLoss                   | 0.0800954  |
----------------------------------------
itr #475 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 475...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5575, #subsample_inputs: 5575
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.528      |
| AbsLearnSignalNew       | 0.528      |
| AbsLearningOld          | 0.528      |
| AverageDiscountedReturn | 133        |
| AveragePhiLoss          | 0.980082   |
| AveragePolicyStd        | 0.761201   |
| AverageReturn           | 755        |
| Entropy                 | 6.86904    |
| EnvExecTime             | 3.34       |
| ExplainedVariance       | -0.299     |
| Iteration               | 475        |
| ItrTime                 | 11.2       |
| LossAfter               | 0.661236   |
| LossBefore              | 0.701152   |
| MaxReturn               | 2.77e+03   |
| MeanKL                  | 0.00649307 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 123        |
| NumTrajs                | 16         |
| Perplexity              | 962.029    |
| PolicyExecTime          | 0.69       |
| ProcessExecTime         | 0.091      |
| StdReturn               | 642        |
| Time                    | 5.27e+03   |
| dLoss                   | 0.0399159  |
----------------------------------------
itr #476 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 476...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5527, #subsample_inputs: 5527
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.674      |
| AbsLearnSignalNew       | 0.674      |
| AbsLearningOld          | 0.674      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 0.982297   |
| AveragePolicyStd        | 0.758869   |
| AverageReturn           | 632        |
| Entropy                 | 6.85068    |
| EnvExecTime             | 3.36       |
| ExplainedVariance       | 0.426      |
| Iteration               | 476        |
| ItrTime                 | 12.5       |
| LossAfter               | 1.11744    |
| LossBefore              | 1.15978    |
| MaxReturn               | 2.33e+03   |
| MeanKL                  | 0.00645942 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 92.3       |
| NumTrajs                | 18         |
| Perplexity              | 944.523    |
| PolicyExecTime          | 0.703      |
| ProcessExecTime         | 0.0899     |
| StdReturn               | 502        |
| Time                    | 5.29e+03   |
| dLoss                   | 0.042333   |
----------------------------------------
itr #477 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 477...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5061, #subsample_inputs: 5061
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.694     |
| AbsLearnSignalNew       | 0.694     |
| AbsLearningOld          | 0.694     |
| AverageDiscountedReturn | 136       |
| AveragePhiLoss          | 0.985369  |
| AveragePolicyStd        | 0.757172  |
| AverageReturn           | 613       |
| Entropy                 | 6.83826   |
| EnvExecTime             | 2.67      |
| ExplainedVariance       | 0.454     |
| Iteration               | 477       |
| ItrTime                 | 10.6      |
| LossAfter               | -0.295176 |
| LossBefore              | -0.240167 |
| MaxReturn               | 1.07e+03  |
| MeanKL                  | 0.0098193 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 60.6      |
| NumTrajs                | 18        |
| Perplexity              | 932.865   |
| PolicyExecTime          | 0.521     |
| ProcessExecTime         | 0.0676    |
| StdReturn               | 276       |
| Time                    | 5.3e+03   |
| dLoss                   | 0.0550086 |
---------------------------------------
itr #478 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 478...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5058, #subsample_inputs: 5058
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.658      |
| AbsLearnSignalNew       | 0.658      |
| AbsLearningOld          | 0.658      |
| AverageDiscountedReturn | 135        |
| AveragePhiLoss          | 0.977951   |
| AveragePolicyStd        | 0.75698    |
| AverageReturn           | 725        |
| Entropy                 | 6.83682    |
| EnvExecTime             | 2.8        |
| ExplainedVariance       | 0.244      |
| Iteration               | 478        |
| ItrTime                 | 10.6       |
| LossAfter               | 0.130312   |
| LossBefore              | 0.183638   |
| MaxReturn               | 1.81e+03   |
| MeanKL                  | 0.00645599 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 65.5       |
| NumTrajs                | 16         |
| Perplexity              | 931.522    |
| PolicyExecTime          | 0.586      |
| ProcessExecTime         | 0.0777     |
| StdReturn               | 466        |
| Time                    | 5.31e+03   |
| dLoss                   | 0.0533256  |
----------------------------------------
itr #479 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 479...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5058, #subsample_inputs: 5058
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.536      |
| AbsLearnSignalNew       | 0.536      |
| AbsLearningOld          | 0.536      |
| AverageDiscountedReturn | 132        |
| AveragePhiLoss          | 0.974283   |
| AveragePolicyStd        | 0.755844   |
| AverageReturn           | 774        |
| Entropy                 | 6.8274     |
| EnvExecTime             | 3.01       |
| ExplainedVariance       | -0.49      |
| Iteration               | 479        |
| ItrTime                 | 11.4       |
| LossAfter               | 0.314739   |
| LossBefore              | 0.35779    |
| MaxReturn               | 2.24e+03   |
| MeanKL                  | 0.00646533 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 77.2       |
| NumTrajs                | 14         |
| Perplexity              | 922.785    |
| PolicyExecTime          | 0.623      |
| ProcessExecTime         | 0.0769     |
| StdReturn               | 543        |
| Time                    | 5.32e+03   |
| dLoss                   | 0.0430509  |
----------------------------------------
itr #480 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 480...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5256, #subsample_inputs: 5256
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.666      |
| AbsLearnSignalNew       | 0.666      |
| AbsLearningOld          | 0.666      |
| AverageDiscountedReturn | 138        |
| AveragePhiLoss          | 0.972328   |
| AveragePolicyStd        | 0.755379   |
| AverageReturn           | 767        |
| Entropy                 | 6.82376    |
| EnvExecTime             | 3.18       |
| ExplainedVariance       | 0.481      |
| Iteration               | 480        |
| ItrTime                 | 10.5       |
| LossAfter               | -0.474414  |
| LossBefore              | -0.416755  |
| MaxReturn               | 1.3e+03    |
| MeanKL                  | 0.00985556 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 358        |
| NumTrajs                | 15         |
| Perplexity              | 919.436    |
| PolicyExecTime          | 0.647      |
| ProcessExecTime         | 0.0835     |
| StdReturn               | 250        |
| Time                    | 5.33e+03   |
| dLoss                   | 0.0576585  |
----------------------------------------
itr #481 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 481...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5190, #subsample_inputs: 5190
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.683      |
| AbsLearnSignalNew       | 0.683      |
| AbsLearningOld          | 0.683      |
| AverageDiscountedReturn | 144        |
| AveragePhiLoss          | 0.986697   |
| AveragePolicyStd        | 0.758521   |
| AverageReturn           | 782        |
| Entropy                 | 6.84788    |
| EnvExecTime             | 3.17       |
| ExplainedVariance       | 0.466      |
| Iteration               | 481        |
| ItrTime                 | 11.5       |
| LossAfter               | -0.482442  |
| LossBefore              | -0.439351  |
| MaxReturn               | 1.54e+03   |
| MeanKL                  | 0.00641295 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 62.5       |
| NumTrajs                | 15         |
| Perplexity              | 941.878    |
| PolicyExecTime          | 0.656      |
| ProcessExecTime         | 0.0821     |
| StdReturn               | 443        |
| Time                    | 5.34e+03   |
| dLoss                   | 0.0430906  |
----------------------------------------
itr #482 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 482...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5208, #subsample_inputs: 5208
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.637      |
| AbsLearnSignalNew       | 0.637      |
| AbsLearningOld          | 0.637      |
| AverageDiscountedReturn | 127        |
| AveragePhiLoss          | 0.96802    |
| AveragePolicyStd        | 0.757541   |
| AverageReturn           | 616        |
| Entropy                 | 6.83993    |
| EnvExecTime             | 2.94       |
| ExplainedVariance       | 0.317      |
| Iteration               | 482        |
| ItrTime                 | 11.3       |
| LossAfter               | -0.362605  |
| LossBefore              | -0.311604  |
| MaxReturn               | 1.73e+03   |
| MeanKL                  | 0.00643575 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 55.6       |
| NumTrajs                | 17         |
| Perplexity              | 934.424    |
| PolicyExecTime          | 0.595      |
| ProcessExecTime         | 0.0717     |
| StdReturn               | 364        |
| Time                    | 5.35e+03   |
| dLoss                   | 0.0510009  |
----------------------------------------
itr #483 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 483...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5329, #subsample_inputs: 5329
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.726      |
| AbsLearnSignalNew       | 0.726      |
| AbsLearningOld          | 0.726      |
| AverageDiscountedReturn | 146        |
| AveragePhiLoss          | 0.981143   |
| AveragePolicyStd        | 0.755845   |
| AverageReturn           | 678        |
| Entropy                 | 6.82714    |
| EnvExecTime             | 3.37       |
| ExplainedVariance       | 0.459      |
| Iteration               | 483        |
| ItrTime                 | 10.6       |
| LossAfter               | -0.940008  |
| LossBefore              | -0.896101  |
| MaxReturn               | 1.23e+03   |
| MeanKL                  | 0.00642385 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 143        |
| NumTrajs                | 18         |
| Perplexity              | 922.548    |
| PolicyExecTime          | 0.697      |
| ProcessExecTime         | 0.088      |
| StdReturn               | 287        |
| Time                    | 5.36e+03   |
| dLoss                   | 0.0439066  |
----------------------------------------
itr #484 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 484...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5118, #subsample_inputs: 5118
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.645      |
| AbsLearnSignalNew       | 0.645      |
| AbsLearningOld          | 0.645      |
| AverageDiscountedReturn | 112        |
| AveragePhiLoss          | 0.979826   |
| AveragePolicyStd        | 0.756445   |
| AverageReturn           | 617        |
| Entropy                 | 6.83193    |
| EnvExecTime             | 2.94       |
| ExplainedVariance       | 0.362      |
| Iteration               | 484        |
| ItrTime                 | 11.3       |
| LossAfter               | -0.915148  |
| LossBefore              | -0.85966   |
| MaxReturn               | 1.99e+03   |
| MeanKL                  | 0.00990007 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 50.7       |
| NumTrajs                | 17         |
| Perplexity              | 926.976    |
| PolicyExecTime          | 0.595      |
| ProcessExecTime         | 0.0779     |
| StdReturn               | 563        |
| Time                    | 5.38e+03   |
| dLoss                   | 0.0554881  |
----------------------------------------
itr #485 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 485...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5231, #subsample_inputs: 5231
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.709      |
| AbsLearnSignalNew       | 0.709      |
| AbsLearningOld          | 0.709      |
| AverageDiscountedReturn | 130        |
| AveragePhiLoss          | 0.976706   |
| AveragePolicyStd        | 0.755896   |
| AverageReturn           | 730        |
| Entropy                 | 6.82849    |
| EnvExecTime             | 3.15       |
| ExplainedVariance       | 0.331      |
| Iteration               | 485        |
| ItrTime                 | 11.4       |
| LossAfter               | 0.789034   |
| LossBefore              | 0.833387   |
| MaxReturn               | 1.38e+03   |
| MeanKL                  | 0.00640934 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 91.4       |
| NumTrajs                | 15         |
| Perplexity              | 923.797    |
| PolicyExecTime          | 0.624      |
| ProcessExecTime         | 0.0772     |
| StdReturn               | 403        |
| Time                    | 5.39e+03   |
| dLoss                   | 0.0443533  |
----------------------------------------
itr #486 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 486...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5139, #subsample_inputs: 5139
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.682      |
| AbsLearnSignalNew       | 0.682      |
| AbsLearningOld          | 0.682      |
| AverageDiscountedReturn | 139        |
| AveragePhiLoss          | 0.976801   |
| AveragePolicyStd        | 0.755189   |
| AverageReturn           | 544        |
| Entropy                 | 6.82312    |
| EnvExecTime             | 3.3        |
| ExplainedVariance       | -0.0112    |
| Iteration               | 486        |
| ItrTime                 | 10.7       |
| LossAfter               | 0.674734   |
| LossBefore              | 0.71888    |
| MaxReturn               | 1.2e+03    |
| MeanKL                  | 0.00650733 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 304        |
| NumTrajs                | 20         |
| Perplexity              | 918.851    |
| PolicyExecTime          | 0.682      |
| ProcessExecTime         | 0.0878     |
| StdReturn               | 206        |
| Time                    | 5.4e+03    |
| dLoss                   | 0.0441459  |
----------------------------------------
itr #487 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 487...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5037, #subsample_inputs: 5037
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.61       |
| AbsLearnSignalNew       | 0.61       |
| AbsLearningOld          | 0.61       |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 0.975422   |
| AveragePolicyStd        | 0.751995   |
| AverageReturn           | 502        |
| Entropy                 | 6.79732    |
| EnvExecTime             | 3.01       |
| ExplainedVariance       | 0.343      |
| Iteration               | 487        |
| ItrTime                 | 11.2       |
| LossAfter               | 0.483491   |
| LossBefore              | 0.52739    |
| MaxReturn               | 1.11e+03   |
| MeanKL                  | 0.00640444 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 64.2       |
| NumTrajs                | 20         |
| Perplexity              | 895.443    |
| PolicyExecTime          | 0.617      |
| ProcessExecTime         | 0.079      |
| StdReturn               | 267        |
| Time                    | 5.41e+03   |
| dLoss                   | 0.043899   |
----------------------------------------
itr #488 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 488...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5379, #subsample_inputs: 5379
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.429      |
| AbsLearnSignalNew       | 0.429      |
| AbsLearningOld          | 0.429      |
| AverageDiscountedReturn | 123        |
| AveragePhiLoss          | 0.978608   |
| AveragePolicyStd        | 0.751671   |
| AverageReturn           | 856        |
| Entropy                 | 6.79466    |
| EnvExecTime             | 3.08       |
| ExplainedVariance       | -15.8      |
| Iteration               | 488        |
| ItrTime                 | 11         |
| LossAfter               | -0.214142  |
| LossBefore              | -0.15642   |
| MaxReturn               | 2.07e+03   |
| MeanKL                  | 0.00989431 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 65         |
| NumTrajs                | 13         |
| Perplexity              | 893.066    |
| PolicyExecTime          | 0.63       |
| ProcessExecTime         | 0.0808     |
| StdReturn               | 604        |
| Time                    | 5.42e+03   |
| dLoss                   | 0.0577219  |
----------------------------------------
itr #489 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 489...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5204, #subsample_inputs: 5204
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.741      |
| AbsLearnSignalNew       | 0.741      |
| AbsLearningOld          | 0.741      |
| AverageDiscountedReturn | 147        |
| AveragePhiLoss          | 0.983723   |
| AveragePolicyStd        | 0.750913   |
| AverageReturn           | 701        |
| Entropy                 | 6.78813    |
| EnvExecTime             | 3.05       |
| ExplainedVariance       | 0.292      |
| Iteration               | 489        |
| ItrTime                 | 11.3       |
| LossAfter               | 0.249299   |
| LossBefore              | 0.302391   |
| MaxReturn               | 1.16e+03   |
| MeanKL                  | 0.00990278 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 285        |
| NumTrajs                | 17         |
| Perplexity              | 887.248    |
| PolicyExecTime          | 0.631      |
| ProcessExecTime         | 0.0837     |
| StdReturn               | 260        |
| Time                    | 5.43e+03   |
| dLoss                   | 0.0530918  |
----------------------------------------
itr #490 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 490...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5044, #subsample_inputs: 5044
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.557      |
| AbsLearnSignalNew       | 0.557      |
| AbsLearningOld          | 0.557      |
| AverageDiscountedReturn | 124        |
| AveragePhiLoss          | 0.973695   |
| AveragePolicyStd        | 0.750752   |
| AverageReturn           | 581        |
| Entropy                 | 6.78546    |
| EnvExecTime             | 2.8        |
| ExplainedVariance       | 0.259      |
| Iteration               | 490        |
| ItrTime                 | 11.2       |
| LossAfter               | -0.39424   |
| LossBefore              | -0.347357  |
| MaxReturn               | 1.39e+03   |
| MeanKL                  | 0.00642346 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 64         |
| NumTrajs                | 18         |
| Perplexity              | 884.888    |
| PolicyExecTime          | 0.533      |
| ProcessExecTime         | 0.0701     |
| StdReturn               | 426        |
| Time                    | 5.44e+03   |
| dLoss                   | 0.0468838  |
----------------------------------------
itr #491 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 491...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5189, #subsample_inputs: 5189
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.697      |
| AbsLearnSignalNew       | 0.697      |
| AbsLearningOld          | 0.697      |
| AverageDiscountedReturn | 124        |
| AveragePhiLoss          | 0.986028   |
| AveragePolicyStd        | 0.748468   |
| AverageReturn           | 550        |
| Entropy                 | 6.76753    |
| EnvExecTime             | 3.3        |
| ExplainedVariance       | 0.428      |
| Iteration               | 491        |
| ItrTime                 | 10.4       |
| LossAfter               | 0.157651   |
| LossBefore              | 0.21489    |
| MaxReturn               | 1.23e+03   |
| MeanKL                  | 0.00981646 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 52.8       |
| NumTrajs                | 18         |
| Perplexity              | 869.164    |
| PolicyExecTime          | 0.651      |
| ProcessExecTime         | 0.086      |
| StdReturn               | 306        |
| Time                    | 5.45e+03   |
| dLoss                   | 0.0572399  |
----------------------------------------
itr #492 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 492...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5161, #subsample_inputs: 5161
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.717      |
| AbsLearnSignalNew       | 0.717      |
| AbsLearningOld          | 0.717      |
| AverageDiscountedReturn | 141        |
| AveragePhiLoss          | 0.972324   |
| AveragePolicyStd        | 0.75207    |
| AverageReturn           | 729        |
| Entropy                 | 6.79612    |
| EnvExecTime             | 3.28       |
| ExplainedVariance       | 0.286      |
| Iteration               | 492        |
| ItrTime                 | 11.7       |
| LossAfter               | 0.758732   |
| LossBefore              | 0.815482   |
| MaxReturn               | 1.23e+03   |
| MeanKL                  | 0.00993913 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 197        |
| NumTrajs                | 15         |
| Perplexity              | 894.369    |
| PolicyExecTime          | 0.67       |
| ProcessExecTime         | 0.0862     |
| StdReturn               | 334        |
| Time                    | 5.47e+03   |
| dLoss                   | 0.05675    |
----------------------------------------
itr #493 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 493...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5175, #subsample_inputs: 5175
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.647      |
| AbsLearnSignalNew       | 0.647      |
| AbsLearningOld          | 0.647      |
| AverageDiscountedReturn | 142        |
| AveragePhiLoss          | 0.982088   |
| AveragePolicyStd        | 0.749339   |
| AverageReturn           | 697        |
| Entropy                 | 6.77531    |
| EnvExecTime             | 2.89       |
| ExplainedVariance       | 0.458      |
| Iteration               | 493        |
| ItrTime                 | 11         |
| LossAfter               | -0.180511  |
| LossBefore              | -0.113235  |
| MaxReturn               | 1.52e+03   |
| MeanKL                  | 0.00996559 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 102        |
| NumTrajs                | 17         |
| Perplexity              | 875.953    |
| PolicyExecTime          | 0.552      |
| ProcessExecTime         | 0.0719     |
| StdReturn               | 395        |
| Time                    | 5.48e+03   |
| dLoss                   | 0.067276   |
----------------------------------------
itr #494 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 494...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5347, #subsample_inputs: 5347
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.659      |
| AbsLearnSignalNew       | 0.659      |
| AbsLearningOld          | 0.659      |
| AverageDiscountedReturn | 140        |
| AveragePhiLoss          | 0.972988   |
| AveragePolicyStd        | 0.749729   |
| AverageReturn           | 877        |
| Entropy                 | 6.77907    |
| EnvExecTime             | 3.24       |
| ExplainedVariance       | 0.219      |
| Iteration               | 494        |
| ItrTime                 | 11.1       |
| LossAfter               | -0.266963  |
| LossBefore              | -0.224436  |
| MaxReturn               | 2.2e+03    |
| MeanKL                  | 0.00649515 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 56.8       |
| NumTrajs                | 14         |
| Perplexity              | 879.254    |
| PolicyExecTime          | 0.666      |
| ProcessExecTime         | 0.0866     |
| StdReturn               | 549        |
| Time                    | 5.49e+03   |
| dLoss                   | 0.0425271  |
----------------------------------------
itr #495 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 495...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5140, #subsample_inputs: 5140
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.658      |
| AbsLearnSignalNew       | 0.658      |
| AbsLearningOld          | 0.658      |
| AverageDiscountedReturn | 134        |
| AveragePhiLoss          | 0.966159   |
| AveragePolicyStd        | 0.748191   |
| AverageReturn           | 735        |
| Entropy                 | 6.76737    |
| EnvExecTime             | 2.9        |
| ExplainedVariance       | 0.47       |
| Iteration               | 495        |
| ItrTime                 | 11.2       |
| LossAfter               | 0.412209   |
| LossBefore              | 0.474719   |
| MaxReturn               | 1.71e+03   |
| MeanKL                  | 0.00987884 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 104        |
| NumTrajs                | 15         |
| Perplexity              | 869.023    |
| PolicyExecTime          | 0.598      |
| ProcessExecTime         | 0.0791     |
| StdReturn               | 384        |
| Time                    | 5.5e+03    |
| dLoss                   | 0.0625093  |
----------------------------------------
itr #496 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 496...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5321, #subsample_inputs: 5321
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.659      |
| AbsLearnSignalNew       | 0.659      |
| AbsLearningOld          | 0.659      |
| AverageDiscountedReturn | 135        |
| AveragePhiLoss          | 0.984423   |
| AveragePolicyStd        | 0.747415   |
| AverageReturn           | 652        |
| Entropy                 | 6.76094    |
| EnvExecTime             | 2.95       |
| ExplainedVariance       | 0.463      |
| Iteration               | 496        |
| ItrTime                 | 10.6       |
| LossAfter               | 0.503755   |
| LossBefore              | 0.544574   |
| MaxReturn               | 1.68e+03   |
| MeanKL                  | 0.00643021 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 156        |
| NumTrajs                | 17         |
| Perplexity              | 863.449    |
| PolicyExecTime          | 0.587      |
| ProcessExecTime         | 0.0766     |
| StdReturn               | 416        |
| Time                    | 5.51e+03   |
| dLoss                   | 0.040819   |
----------------------------------------
itr #497 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 497...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5923, #subsample_inputs: 5923
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.709      |
| AbsLearnSignalNew       | 0.709      |
| AbsLearningOld          | 0.709      |
| AverageDiscountedReturn | 124        |
| AveragePhiLoss          | 0.987019   |
| AveragePolicyStd        | 0.746315   |
| AverageReturn           | 623        |
| Entropy                 | 6.75195    |
| EnvExecTime             | 4.04       |
| ExplainedVariance       | 0.431      |
| Iteration               | 497        |
| ItrTime                 | 12.9       |
| LossAfter               | -0.258129  |
| LossBefore              | -0.208402  |
| MaxReturn               | 2.31e+03   |
| MeanKL                  | 0.00986253 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 39.7       |
| NumTrajs                | 19         |
| Perplexity              | 855.728    |
| PolicyExecTime          | 0.83       |
| ProcessExecTime         | 0.102      |
| StdReturn               | 528        |
| Time                    | 5.52e+03   |
| dLoss                   | 0.0497269  |
----------------------------------------
itr #498 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 498...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5009, #subsample_inputs: 5009
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.712      |
| AbsLearnSignalNew       | 0.712      |
| AbsLearningOld          | 0.712      |
| AverageDiscountedReturn | 152        |
| AveragePhiLoss          | 0.974122   |
| AveragePolicyStd        | 0.745529   |
| AverageReturn           | 961        |
| Entropy                 | 6.74575    |
| EnvExecTime             | 3.03       |
| ExplainedVariance       | 0.487      |
| Iteration               | 498        |
| ItrTime                 | 11.2       |
| LossAfter               | 0.65616    |
| LossBefore              | 0.701026   |
| MaxReturn               | 1.65e+03   |
| MeanKL                  | 0.00646827 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 457        |
| NumTrajs                | 13         |
| Perplexity              | 850.44     |
| PolicyExecTime          | 0.621      |
| ProcessExecTime         | 0.081      |
| StdReturn               | 407        |
| Time                    | 5.53e+03   |
| dLoss                   | 0.0448651  |
----------------------------------------
itr #499 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 499...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5187, #subsample_inputs: 5187
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.664      |
| AbsLearnSignalNew       | 0.664      |
| AbsLearningOld          | 0.664      |
| AverageDiscountedReturn | 139        |
| AveragePhiLoss          | 0.983908   |
| AveragePolicyStd        | 0.743622   |
| AverageReturn           | 1.08e+03   |
| Entropy                 | 6.73021    |
| EnvExecTime             | 3.1        |
| ExplainedVariance       | 0.424      |
| Iteration               | 499        |
| ItrTime                 | 10.4       |
| LossAfter               | -0.189771  |
| LossBefore              | -0.128814  |
| MaxReturn               | 2.3e+03    |
| MeanKL                  | 0.00991696 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 115        |
| NumTrajs                | 10         |
| Perplexity              | 837.323    |
| PolicyExecTime          | 0.635      |
| ProcessExecTime         | 0.0777     |
| StdReturn               | 723        |
| Time                    | 5.55e+03   |
| dLoss                   | 0.060957   |
----------------------------------------
itr #500 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 500...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5198, #subsample_inputs: 5198
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.668      |
| AbsLearnSignalNew       | 0.668      |
| AbsLearningOld          | 0.668      |
| AverageDiscountedReturn | 144        |
| AveragePhiLoss          | 0.972789   |
| AveragePolicyStd        | 0.742911   |
| AverageReturn           | 692        |
| Entropy                 | 6.72469    |
| EnvExecTime             | 3.23       |
| ExplainedVariance       | 0.457      |
| Iteration               | 500        |
| ItrTime                 | 11.9       |
| LossAfter               | -0.451786  |
| LossBefore              | -0.392549  |
| MaxReturn               | 1.53e+03   |
| MeanKL                  | 0.00992478 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 61.4       |
| NumTrajs                | 17         |
| Perplexity              | 832.712    |
| PolicyExecTime          | 0.673      |
| ProcessExecTime         | 0.0861     |
| StdReturn               | 335        |
| Time                    | 5.56e+03   |
| dLoss                   | 0.059237   |
----------------------------------------
itr #501 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 501...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5143, #subsample_inputs: 5143
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.678     |
| AbsLearnSignalNew       | 0.678     |
| AbsLearningOld          | 0.678     |
| AverageDiscountedReturn | 143       |
| AveragePhiLoss          | 0.972497  |
| AveragePolicyStd        | 0.741719  |
| AverageReturn           | 740       |
| Entropy                 | 6.71473   |
| EnvExecTime             | 2.94      |
| ExplainedVariance       | 0.496     |
| Iteration               | 501       |
| ItrTime                 | 11.5      |
| LossAfter               | -1.57044  |
| LossBefore              | -1.51983  |
| MaxReturn               | 2.04e+03  |
| MeanKL                  | 0.0064144 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 48.1      |
| NumTrajs                | 16        |
| Perplexity              | 824.46    |
| PolicyExecTime          | 0.587     |
| ProcessExecTime         | 0.0705    |
| StdReturn               | 495       |
| Time                    | 5.57e+03  |
| dLoss                   | 0.0506099 |
---------------------------------------
itr #502 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 502...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5398, #subsample_inputs: 5398
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.713      |
| AbsLearnSignalNew       | 0.713      |
| AbsLearningOld          | 0.713      |
| AverageDiscountedReturn | 146        |
| AveragePhiLoss          | 0.97858    |
| AveragePolicyStd        | 0.740525   |
| AverageReturn           | 870        |
| Entropy                 | 6.70499    |
| EnvExecTime             | 3.24       |
| ExplainedVariance       | 0.439      |
| Iteration               | 502        |
| ItrTime                 | 10.8       |
| LossAfter               | -0.640054  |
| LossBefore              | -0.596594  |
| MaxReturn               | 1.66e+03   |
| MeanKL                  | 0.00640949 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 462        |
| NumTrajs                | 14         |
| Perplexity              | 816.47     |
| PolicyExecTime          | 0.673      |
| ProcessExecTime         | 0.0868     |
| StdReturn               | 405        |
| Time                    | 5.58e+03   |
| dLoss                   | 0.0434595  |
----------------------------------------
itr #503 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 503...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5445, #subsample_inputs: 5445
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.669      |
| AbsLearnSignalNew       | 0.669      |
| AbsLearningOld          | 0.669      |
| AverageDiscountedReturn | 152        |
| AveragePhiLoss          | 0.973069   |
| AveragePolicyStd        | 0.739195   |
| AverageReturn           | 844        |
| Entropy                 | 6.69381    |
| EnvExecTime             | 3.2        |
| ExplainedVariance       | 0.513      |
| Iteration               | 503        |
| ItrTime                 | 12.1       |
| LossAfter               | 0.432533   |
| LossBefore              | 0.4956     |
| MaxReturn               | 1.86e+03   |
| MeanKL                  | 0.00990935 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 46.7       |
| NumTrajs                | 16         |
| Perplexity              | 807.393    |
| PolicyExecTime          | 0.659      |
| ProcessExecTime         | 0.0866     |
| StdReturn               | 424        |
| Time                    | 5.59e+03   |
| dLoss                   | 0.0630675  |
----------------------------------------
itr #504 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 504...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5150, #subsample_inputs: 5150
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.612     |
| AbsLearnSignalNew       | 0.612     |
| AbsLearningOld          | 0.612     |
| AverageDiscountedReturn | 147       |
| AveragePhiLoss          | 0.975923  |
| AveragePolicyStd        | 0.73867   |
| AverageReturn           | 964       |
| Entropy                 | 6.68918   |
| EnvExecTime             | 2.74      |
| ExplainedVariance       | -0.0677   |
| Iteration               | 504       |
| ItrTime                 | 10.7      |
| LossAfter               | 0.0290528 |
| LossBefore              | 0.0680523 |
| MaxReturn               | 2.2e+03   |
| MeanKL                  | 0.0064716 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 441       |
| NumTrajs                | 12        |
| Perplexity              | 803.663   |
| PolicyExecTime          | 0.527     |
| ProcessExecTime         | 0.0671    |
| StdReturn               | 544       |
| Time                    | 5.6e+03   |
| dLoss                   | 0.0389995 |
---------------------------------------
itr #505 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 505...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5262, #subsample_inputs: 5262
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.645      |
| AbsLearnSignalNew       | 0.645      |
| AbsLearningOld          | 0.645      |
| AverageDiscountedReturn | 147        |
| AveragePhiLoss          | 0.981319   |
| AveragePolicyStd        | 0.737688   |
| AverageReturn           | 851        |
| Entropy                 | 6.68116    |
| EnvExecTime             | 3.2        |
| ExplainedVariance       | 0.454      |
| Iteration               | 505        |
| ItrTime                 | 10.8       |
| LossAfter               | 1.01586    |
| LossBefore              | 1.06042    |
| MaxReturn               | 1.5e+03    |
| MeanKL                  | 0.00643821 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 144        |
| NumTrajs                | 13         |
| Perplexity              | 797.244    |
| PolicyExecTime          | 0.655      |
| ProcessExecTime         | 0.0847     |
| StdReturn               | 323        |
| Time                    | 5.61e+03   |
| dLoss                   | 0.0445673  |
----------------------------------------
itr #506 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 506...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5225, #subsample_inputs: 5225
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.686      |
| AbsLearnSignalNew       | 0.686      |
| AbsLearningOld          | 0.686      |
| AverageDiscountedReturn | 138        |
| AveragePhiLoss          | 0.980772   |
| AveragePolicyStd        | 0.735735   |
| AverageReturn           | 788        |
| Entropy                 | 6.6656     |
| EnvExecTime             | 2.96       |
| ExplainedVariance       | 0.416      |
| Iteration               | 506        |
| ItrTime                 | 11.6       |
| LossAfter               | 0.190917   |
| LossBefore              | 0.246461   |
| MaxReturn               | 1.65e+03   |
| MeanKL                  | 0.00996664 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 87.2       |
| NumTrajs                | 15         |
| Perplexity              | 784.938    |
| PolicyExecTime          | 0.619      |
| ProcessExecTime         | 0.0829     |
| StdReturn               | 478        |
| Time                    | 5.63e+03   |
| dLoss                   | 0.0555433  |
----------------------------------------
itr #507 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 507...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5286, #subsample_inputs: 5286
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.647      |
| AbsLearnSignalNew       | 0.647      |
| AbsLearningOld          | 0.647      |
| AverageDiscountedReturn | 143        |
| AveragePhiLoss          | 0.984005   |
| AveragePolicyStd        | 0.737314   |
| AverageReturn           | 672        |
| Entropy                 | 6.67896    |
| EnvExecTime             | 3.13       |
| ExplainedVariance       | 0.251      |
| Iteration               | 507        |
| ItrTime                 | 11         |
| LossAfter               | 0.215693   |
| LossBefore              | 0.271366   |
| MaxReturn               | 1.9e+03    |
| MeanKL                  | 0.00997426 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 430        |
| NumTrajs                | 17         |
| Perplexity              | 795.495    |
| PolicyExecTime          | 0.621      |
| ProcessExecTime         | 0.0797     |
| StdReturn               | 353        |
| Time                    | 5.64e+03   |
| dLoss                   | 0.0556735  |
----------------------------------------
itr #508 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 508...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5183, #subsample_inputs: 5183
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.585      |
| AbsLearnSignalNew       | 0.585      |
| AbsLearningOld          | 0.585      |
| AverageDiscountedReturn | 136        |
| AveragePhiLoss          | 0.974063   |
| AveragePolicyStd        | 0.736262   |
| AverageReturn           | 968        |
| Entropy                 | 6.67035    |
| EnvExecTime             | 3.01       |
| ExplainedVariance       | 0.396      |
| Iteration               | 508        |
| ItrTime                 | 11.2       |
| LossAfter               | 0.140432   |
| LossBefore              | 0.183286   |
| MaxReturn               | 1.98e+03   |
| MeanKL                  | 0.00641264 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 274        |
| NumTrajs                | 12         |
| Perplexity              | 788.671    |
| PolicyExecTime          | 0.632      |
| ProcessExecTime         | 0.0826     |
| StdReturn               | 546        |
| Time                    | 5.65e+03   |
| dLoss                   | 0.0428548  |
----------------------------------------
itr #509 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 509...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5159, #subsample_inputs: 5159
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.671      |
| AbsLearnSignalNew       | 0.671      |
| AbsLearningOld          | 0.671      |
| AverageDiscountedReturn | 141        |
| AveragePhiLoss          | 0.984316   |
| AveragePolicyStd        | 0.734343   |
| AverageReturn           | 838        |
| Entropy                 | 6.65516    |
| EnvExecTime             | 3          |
| ExplainedVariance       | 0.456      |
| Iteration               | 509        |
| ItrTime                 | 11.4       |
| LossAfter               | 0.0353378  |
| LossBefore              | 0.091625   |
| MaxReturn               | 1.77e+03   |
| MeanKL                  | 0.00989517 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 48.5       |
| NumTrajs                | 14         |
| Perplexity              | 776.782    |
| PolicyExecTime          | 0.613      |
| ProcessExecTime         | 0.0736     |
| StdReturn               | 429        |
| Time                    | 5.66e+03   |
| dLoss                   | 0.0562872  |
----------------------------------------
itr #510 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 510...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5071, #subsample_inputs: 5071
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.685      |
| AbsLearnSignalNew       | 0.685      |
| AbsLearningOld          | 0.685      |
| AverageDiscountedReturn | 134        |
| AveragePhiLoss          | 0.965495   |
| AveragePolicyStd        | 0.735533   |
| AverageReturn           | 705        |
| Entropy                 | 6.66467    |
| EnvExecTime             | 3.43       |
| ExplainedVariance       | 0.294      |
| Iteration               | 510        |
| ItrTime                 | 10.4       |
| LossAfter               | 0.170726   |
| LossBefore              | 0.231705   |
| MaxReturn               | 2.42e+03   |
| MeanKL                  | 0.00994547 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 91.8       |
| NumTrajs                | 15         |
| Perplexity              | 784.202    |
| PolicyExecTime          | 0.704      |
| ProcessExecTime         | 0.0875     |
| StdReturn               | 558        |
| Time                    | 5.67e+03   |
| dLoss                   | 0.0609791  |
----------------------------------------
itr #511 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 511...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5189, #subsample_inputs: 5189
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.576      |
| AbsLearnSignalNew       | 0.576      |
| AbsLearningOld          | 0.576      |
| AverageDiscountedReturn | 136        |
| AveragePhiLoss          | 0.975184   |
| AveragePolicyStd        | 0.735735   |
| AverageReturn           | 802        |
| Entropy                 | 6.66607    |
| EnvExecTime             | 3.37       |
| ExplainedVariance       | 0.308      |
| Iteration               | 511        |
| ItrTime                 | 11.9       |
| LossAfter               | 0.443678   |
| LossBefore              | 0.572551   |
| MaxReturn               | 1.4e+03    |
| MeanKL                  | 0.00993668 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 96.3       |
| NumTrajs                | 14         |
| Perplexity              | 785.302    |
| PolicyExecTime          | 0.687      |
| ProcessExecTime         | 0.0878     |
| StdReturn               | 382        |
| Time                    | 5.68e+03   |
| dLoss                   | 0.128874   |
----------------------------------------
itr #512 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 512...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5073, #subsample_inputs: 5073
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.488     |
| AbsLearnSignalNew       | 0.488     |
| AbsLearningOld          | 0.488     |
| AverageDiscountedReturn | 139       |
| AveragePhiLoss          | 0.968814  |
| AveragePolicyStd        | 0.735462  |
| AverageReturn           | 807       |
| Entropy                 | 6.66417   |
| EnvExecTime             | 2.77      |
| ExplainedVariance       | -0.987    |
| Iteration               | 512       |
| ItrTime                 | 11.3      |
| LossAfter               | 0.428321  |
| LossBefore              | 0.47134   |
| MaxReturn               | 2.11e+03  |
| MeanKL                  | 0.0064442 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 376       |
| NumTrajs                | 14        |
| Perplexity              | 783.812   |
| PolicyExecTime          | 0.53      |
| ProcessExecTime         | 0.0726    |
| StdReturn               | 486       |
| Time                    | 5.69e+03  |
| dLoss                   | 0.043019  |
---------------------------------------
itr #513 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 513...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5085, #subsample_inputs: 5085
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.734      |
| AbsLearnSignalNew       | 0.734      |
| AbsLearningOld          | 0.734      |
| AverageDiscountedReturn | 140        |
| AveragePhiLoss          | 0.969684   |
| AveragePolicyStd        | 0.73569    |
| AverageReturn           | 831        |
| Entropy                 | 6.66573    |
| EnvExecTime             | 3.01       |
| ExplainedVariance       | 0.532      |
| Iteration               | 513        |
| ItrTime                 | 10.4       |
| LossAfter               | 0.352937   |
| LossBefore              | 0.414072   |
| MaxReturn               | 1.94e+03   |
| MeanKL                  | 0.00986126 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 301        |
| NumTrajs                | 14         |
| Perplexity              | 785.038    |
| PolicyExecTime          | 0.617      |
| ProcessExecTime         | 0.0801     |
| StdReturn               | 422        |
| Time                    | 5.7e+03    |
| dLoss                   | 0.0611355  |
----------------------------------------
itr #514 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 514...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5163, #subsample_inputs: 5163
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.597     |
| AbsLearnSignalNew       | 0.597     |
| AbsLearningOld          | 0.597     |
| AverageDiscountedReturn | 123       |
| AveragePhiLoss          | 0.978766  |
| AveragePolicyStd        | 0.736828  |
| AverageReturn           | 662       |
| Entropy                 | 6.67532   |
| EnvExecTime             | 2.95      |
| ExplainedVariance       | 0.392     |
| Iteration               | 514       |
| ItrTime                 | 11.4      |
| LossAfter               | 0.522864  |
| LossBefore              | 0.567609  |
| MaxReturn               | 1.21e+03  |
| MeanKL                  | 0.0064393 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 43.1      |
| NumTrajs                | 15        |
| Perplexity              | 792.604   |
| PolicyExecTime          | 0.59      |
| ProcessExecTime         | 0.0771    |
| StdReturn               | 402       |
| Time                    | 5.72e+03  |
| dLoss                   | 0.0447454 |
---------------------------------------
itr #515 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 515...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5420, #subsample_inputs: 5420
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.661      |
| AbsLearnSignalNew       | 0.661      |
| AbsLearningOld          | 0.661      |
| AverageDiscountedReturn | 148        |
| AveragePhiLoss          | 0.981368   |
| AveragePolicyStd        | 0.732926   |
| AverageReturn           | 763        |
| Entropy                 | 6.64285    |
| EnvExecTime             | 3.31       |
| ExplainedVariance       | 0.481      |
| Iteration               | 515        |
| ItrTime                 | 11.3       |
| LossAfter               | 0.413996   |
| LossBefore              | 0.458326   |
| MaxReturn               | 2.09e+03   |
| MeanKL                  | 0.00641134 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 93.1       |
| NumTrajs                | 17         |
| Perplexity              | 767.275    |
| PolicyExecTime          | 0.667      |
| ProcessExecTime         | 0.087      |
| StdReturn               | 459        |
| Time                    | 5.73e+03   |
| dLoss                   | 0.0443293  |
----------------------------------------
itr #516 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 516...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5010, #subsample_inputs: 5010
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.614      |
| AbsLearnSignalNew       | 0.614      |
| AbsLearningOld          | 0.614      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 0.975517   |
| AveragePolicyStd        | 0.732578   |
| AverageReturn           | 713        |
| Entropy                 | 6.64002    |
| EnvExecTime             | 3.22       |
| ExplainedVariance       | 0.283      |
| Iteration               | 516        |
| ItrTime                 | 11.3       |
| LossAfter               | 0.809954   |
| LossBefore              | 0.861791   |
| MaxReturn               | 2.19e+03   |
| MeanKL                  | 0.00996893 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 52.3       |
| NumTrajs                | 14         |
| Perplexity              | 765.109    |
| PolicyExecTime          | 0.668      |
| ProcessExecTime         | 0.0826     |
| StdReturn               | 526        |
| Time                    | 5.74e+03   |
| dLoss                   | 0.0518367  |
----------------------------------------
itr #517 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 517...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5145, #subsample_inputs: 5145
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.719      |
| AbsLearnSignalNew       | 0.719      |
| AbsLearningOld          | 0.719      |
| AverageDiscountedReturn | 119        |
| AveragePhiLoss          | 0.982749   |
| AveragePolicyStd        | 0.731085   |
| AverageReturn           | 655        |
| Entropy                 | 6.62676    |
| EnvExecTime             | 2.75       |
| ExplainedVariance       | 0.512      |
| Iteration               | 517        |
| ItrTime                 | 11.2       |
| LossAfter               | -0.360914  |
| LossBefore              | -0.313754  |
| MaxReturn               | 2.21e+03   |
| MeanKL                  | 0.00642709 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 65.8       |
| NumTrajs                | 15         |
| Perplexity              | 755.034    |
| PolicyExecTime          | 0.526      |
| ProcessExecTime         | 0.0686     |
| StdReturn               | 625        |
| Time                    | 5.75e+03   |
| dLoss                   | 0.0471595  |
----------------------------------------
itr #518 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 518...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5016, #subsample_inputs: 5016
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.715     |
| AbsLearnSignalNew       | 0.715     |
| AbsLearningOld          | 0.715     |
| AverageDiscountedReturn | 122       |
| AveragePhiLoss          | 0.983181  |
| AveragePolicyStd        | 0.732057  |
| AverageReturn           | 635       |
| Entropy                 | 6.63461   |
| EnvExecTime             | 3.17      |
| ExplainedVariance       | 0.542     |
| Iteration               | 518       |
| ItrTime                 | 10.1      |
| LossAfter               | 0.225071  |
| LossBefore              | 0.284337  |
| MaxReturn               | 1.59e+03  |
| MeanKL                  | 0.0098937 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 36        |
| NumTrajs                | 16        |
| Perplexity              | 760.982   |
| PolicyExecTime          | 0.614     |
| ProcessExecTime         | 0.0804    |
| StdReturn               | 428       |
| Time                    | 5.76e+03  |
| dLoss                   | 0.0592661 |
---------------------------------------
itr #519 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 519...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5025, #subsample_inputs: 5025
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.698      |
| AbsLearnSignalNew       | 0.698      |
| AbsLearningOld          | 0.698      |
| AverageDiscountedReturn | 139        |
| AveragePhiLoss          | 0.975707   |
| AveragePolicyStd        | 0.733357   |
| AverageReturn           | 723        |
| Entropy                 | 6.64423    |
| EnvExecTime             | 3.24       |
| ExplainedVariance       | 0.292      |
| Iteration               | 519        |
| ItrTime                 | 11.6       |
| LossAfter               | -0.243626  |
| LossBefore              | -0.184129  |
| MaxReturn               | 1.25e+03   |
| MeanKL                  | 0.00996573 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 93.9       |
| NumTrajs                | 15         |
| Perplexity              | 768.341    |
| PolicyExecTime          | 0.654      |
| ProcessExecTime         | 0.0808     |
| StdReturn               | 344        |
| Time                    | 5.77e+03   |
| dLoss                   | 0.0594972  |
----------------------------------------
itr #520 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 520...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5090, #subsample_inputs: 5090
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.694      |
| AbsLearnSignalNew       | 0.694      |
| AbsLearningOld          | 0.695      |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 0.978111   |
| AveragePolicyStd        | 0.734155   |
| AverageReturn           | 537        |
| Entropy                 | 6.65056    |
| EnvExecTime             | 3.05       |
| ExplainedVariance       | 0.502      |
| Iteration               | 520        |
| ItrTime                 | 11.2       |
| LossAfter               | 0.465487   |
| LossBefore              | 0.512448   |
| MaxReturn               | 1.61e+03   |
| MeanKL                  | 0.00643098 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 68.1       |
| NumTrajs                | 18         |
| Perplexity              | 773.217    |
| PolicyExecTime          | 0.56       |
| ProcessExecTime         | 0.0704     |
| StdReturn               | 416        |
| Time                    | 5.78e+03   |
| dLoss                   | 0.0469607  |
----------------------------------------
itr #521 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 521...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5298, #subsample_inputs: 5298
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.759      |
| AbsLearnSignalNew       | 0.759      |
| AbsLearningOld          | 0.759      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 0.978614   |
| AveragePolicyStd        | 0.73265    |
| AverageReturn           | 529        |
| Entropy                 | 6.63846    |
| EnvExecTime             | 3.28       |
| ExplainedVariance       | 0.516      |
| Iteration               | 521        |
| ItrTime                 | 11.2       |
| LossAfter               | 0.172924   |
| LossBefore              | 0.231641   |
| MaxReturn               | 1.38e+03   |
| MeanKL                  | 0.00998713 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 58.4       |
| NumTrajs                | 19         |
| Perplexity              | 763.916    |
| PolicyExecTime          | 0.641      |
| ProcessExecTime         | 0.0863     |
| StdReturn               | 388        |
| Time                    | 5.79e+03   |
| dLoss                   | 0.0587169  |
----------------------------------------
itr #522 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 522...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5297, #subsample_inputs: 5297
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.702      |
| AbsLearnSignalNew       | 0.702      |
| AbsLearningOld          | 0.702      |
| AverageDiscountedReturn | 127        |
| AveragePhiLoss          | 0.988546   |
| AveragePolicyStd        | 0.73384    |
| AverageReturn           | 511        |
| Entropy                 | 6.64854    |
| EnvExecTime             | 3.13       |
| ExplainedVariance       | 0.38       |
| Iteration               | 522        |
| ItrTime                 | 12.1       |
| LossAfter               | 1.13136    |
| LossBefore              | 1.17727    |
| MaxReturn               | 1e+03      |
| MeanKL                  | 0.00643377 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 94.9       |
| NumTrajs                | 19         |
| Perplexity              | 771.656    |
| PolicyExecTime          | 0.633      |
| ProcessExecTime         | 0.0824     |
| StdReturn               | 261        |
| Time                    | 5.81e+03   |
| dLoss                   | 0.0459093  |
----------------------------------------
itr #523 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 523...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5455, #subsample_inputs: 5455
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.452      |
| AbsLearnSignalNew       | 0.452      |
| AbsLearningOld          | 0.452      |
| AverageDiscountedReturn | 133        |
| AveragePhiLoss          | 0.976375   |
| AveragePolicyStd        | 0.734243   |
| AverageReturn           | 810        |
| Entropy                 | 6.65134    |
| EnvExecTime             | 3.04       |
| ExplainedVariance       | -1.56      |
| Iteration               | 523        |
| ItrTime                 | 11         |
| LossAfter               | 0.566055   |
| LossBefore              | 0.61431    |
| MaxReturn               | 2.31e+03   |
| MeanKL                  | 0.00973825 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 79.6       |
| NumTrajs                | 15         |
| Perplexity              | 773.822    |
| PolicyExecTime          | 0.627      |
| ProcessExecTime         | 0.081      |
| StdReturn               | 554        |
| Time                    | 5.82e+03   |
| dLoss                   | 0.0482543  |
----------------------------------------
itr #524 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 524...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5578, #subsample_inputs: 5578
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.702      |
| AbsLearnSignalNew       | 0.702      |
| AbsLearningOld          | 0.702      |
| AverageDiscountedReturn | 140        |
| AveragePhiLoss          | 0.982141   |
| AveragePolicyStd        | 0.736082   |
| AverageReturn           | 882        |
| Entropy                 | 6.6664     |
| EnvExecTime             | 3.43       |
| ExplainedVariance       | 0.547      |
| Iteration               | 524        |
| ItrTime                 | 11.8       |
| LossAfter               | 0.675353   |
| LossBefore              | 0.716832   |
| MaxReturn               | 1.87e+03   |
| MeanKL                  | 0.00643888 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 92.8       |
| NumTrajs                | 14         |
| Perplexity              | 785.564    |
| PolicyExecTime          | 0.695      |
| ProcessExecTime         | 0.0882     |
| StdReturn               | 466        |
| Time                    | 5.83e+03   |
| dLoss                   | 0.0414792  |
----------------------------------------
itr #525 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 525...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5091, #subsample_inputs: 5091
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.632      |
| AbsLearnSignalNew       | 0.632      |
| AbsLearningOld          | 0.632      |
| AverageDiscountedReturn | 138        |
| AveragePhiLoss          | 0.971584   |
| AveragePolicyStd        | 0.734924   |
| AverageReturn           | 669        |
| Entropy                 | 6.65632    |
| EnvExecTime             | 2.7        |
| ExplainedVariance       | 0.517      |
| Iteration               | 525        |
| ItrTime                 | 11         |
| LossAfter               | 1.04192    |
| LossBefore              | 1.10845    |
| MaxReturn               | 1.35e+03   |
| MeanKL                  | 0.00994178 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 69.2       |
| NumTrajs                | 17         |
| Perplexity              | 777.681    |
| PolicyExecTime          | 0.534      |
| ProcessExecTime         | 0.0718     |
| StdReturn               | 348        |
| Time                    | 5.84e+03   |
| dLoss                   | 0.0665348  |
----------------------------------------
itr #526 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 526...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5273, #subsample_inputs: 5273
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.7        |
| AbsLearnSignalNew       | 0.7        |
| AbsLearningOld          | 0.7        |
| AverageDiscountedReturn | 132        |
| AveragePhiLoss          | 0.978236   |
| AveragePolicyStd        | 0.734119   |
| AverageReturn           | 706        |
| Entropy                 | 6.64987    |
| EnvExecTime             | 3.07       |
| ExplainedVariance       | 0.53       |
| Iteration               | 526        |
| ItrTime                 | 10.4       |
| LossAfter               | 1.26743    |
| LossBefore              | 1.32218    |
| MaxReturn               | 1.49e+03   |
| MeanKL                  | 0.00998875 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 49.2       |
| NumTrajs                | 16         |
| Perplexity              | 772.68     |
| PolicyExecTime          | 0.614      |
| ProcessExecTime         | 0.0814     |
| StdReturn               | 478        |
| Time                    | 5.85e+03   |
| dLoss                   | 0.054742   |
----------------------------------------
itr #527 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 527...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5254, #subsample_inputs: 5254
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.741      |
| AbsLearnSignalNew       | 0.741      |
| AbsLearningOld          | 0.741      |
| AverageDiscountedReturn | 131        |
| AveragePhiLoss          | 0.980736   |
| AveragePolicyStd        | 0.735061   |
| AverageReturn           | 786        |
| Entropy                 | 6.65809    |
| EnvExecTime             | 3.33       |
| ExplainedVariance       | 0.596      |
| Iteration               | 527        |
| ItrTime                 | 12.1       |
| LossAfter               | 1.51736    |
| LossBefore              | 1.55718    |
| MaxReturn               | 2.15e+03   |
| MeanKL                  | 0.00644717 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 52.9       |
| NumTrajs                | 15         |
| Perplexity              | 779.064    |
| PolicyExecTime          | 0.673      |
| ProcessExecTime         | 0.0862     |
| StdReturn               | 530        |
| Time                    | 5.86e+03   |
| dLoss                   | 0.0398139  |
----------------------------------------
itr #528 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 528...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5267, #subsample_inputs: 5267
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.694      |
| AbsLearnSignalNew       | 0.694      |
| AbsLearningOld          | 0.694      |
| AverageDiscountedReturn | 133        |
| AveragePhiLoss          | 0.963391   |
| AveragePolicyStd        | 0.734744   |
| AverageReturn           | 538        |
| Entropy                 | 6.65534    |
| EnvExecTime             | 2.82       |
| ExplainedVariance       | 0.294      |
| Iteration               | 528        |
| ItrTime                 | 11.4       |
| LossAfter               | 0.745119   |
| LossBefore              | 0.809047   |
| MaxReturn               | 902        |
| MeanKL                  | 0.00997668 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 80.9       |
| NumTrajs                | 19         |
| Perplexity              | 776.918    |
| PolicyExecTime          | 0.522      |
| ProcessExecTime         | 0.0684     |
| StdReturn               | 227        |
| Time                    | 5.88e+03   |
| dLoss                   | 0.0639281  |
----------------------------------------
itr #529 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 529...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5286, #subsample_inputs: 5286
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.703      |
| AbsLearnSignalNew       | 0.703      |
| AbsLearningOld          | 0.703      |
| AverageDiscountedReturn | 132        |
| AveragePhiLoss          | 0.990456   |
| AveragePolicyStd        | 0.734447   |
| AverageReturn           | 595        |
| Entropy                 | 6.65126    |
| EnvExecTime             | 3          |
| ExplainedVariance       | 0.294      |
| Iteration               | 529        |
| ItrTime                 | 10.6       |
| LossAfter               | 0.746818   |
| LossBefore              | 0.790082   |
| MaxReturn               | 1.17e+03   |
| MeanKL                  | 0.00649461 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 58.5       |
| NumTrajs                | 18         |
| Perplexity              | 773.762    |
| PolicyExecTime          | 0.625      |
| ProcessExecTime         | 0.0833     |
| StdReturn               | 338        |
| Time                    | 5.89e+03   |
| dLoss                   | 0.0432635  |
----------------------------------------
itr #530 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 530...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5062, #subsample_inputs: 5062
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.752      |
| AbsLearnSignalNew       | 0.752      |
| AbsLearningOld          | 0.752      |
| AverageDiscountedReturn | 136        |
| AveragePhiLoss          | 0.980869   |
| AveragePolicyStd        | 0.732991   |
| AverageReturn           | 641        |
| Entropy                 | 6.63899    |
| EnvExecTime             | 2.93       |
| ExplainedVariance       | 0.439      |
| Iteration               | 530        |
| ItrTime                 | 11.6       |
| LossAfter               | 1.09395    |
| LossBefore              | 1.13913    |
| MaxReturn               | 1.82e+03   |
| MeanKL                  | 0.00648369 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 62.9       |
| NumTrajs                | 17         |
| Perplexity              | 764.321    |
| PolicyExecTime          | 0.577      |
| ProcessExecTime         | 0.0768     |
| StdReturn               | 413        |
| Time                    | 5.9e+03    |
| dLoss                   | 0.0451859  |
----------------------------------------
itr #531 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 531...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5058, #subsample_inputs: 5058
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.684      |
| AbsLearnSignalNew       | 0.684      |
| AbsLearningOld          | 0.684      |
| AverageDiscountedReturn | 137        |
| AveragePhiLoss          | 0.977039   |
| AveragePolicyStd        | 0.7306     |
| AverageReturn           | 625        |
| Entropy                 | 6.61892    |
| EnvExecTime             | 2.69       |
| ExplainedVariance       | 0.442      |
| Iteration               | 531        |
| ItrTime                 | 9.91       |
| LossAfter               | 1.35151    |
| LossBefore              | 1.39546    |
| MaxReturn               | 1.35e+03   |
| MeanKL                  | 0.00641272 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 155        |
| NumTrajs                | 17         |
| Perplexity              | 749.134    |
| PolicyExecTime          | 0.53       |
| ProcessExecTime         | 0.0708     |
| StdReturn               | 269        |
| Time                    | 5.91e+03   |
| dLoss                   | 0.0439481  |
----------------------------------------
itr #532 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 532...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5289, #subsample_inputs: 5289
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.725      |
| AbsLearnSignalNew       | 0.725      |
| AbsLearningOld          | 0.725      |
| AverageDiscountedReturn | 147        |
| AveragePhiLoss          | 0.986      |
| AveragePolicyStd        | 0.728502   |
| AverageReturn           | 856        |
| Entropy                 | 6.60162    |
| EnvExecTime             | 3.23       |
| ExplainedVariance       | 0.491      |
| Iteration               | 532        |
| ItrTime                 | 11.7       |
| LossAfter               | 1.51147    |
| LossBefore              | 1.56359    |
| MaxReturn               | 1.55e+03   |
| MeanKL                  | 0.00983276 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 201        |
| NumTrajs                | 15         |
| Perplexity              | 736.29     |
| PolicyExecTime          | 0.655      |
| ProcessExecTime         | 0.0842     |
| StdReturn               | 363        |
| Time                    | 5.92e+03   |
| dLoss                   | 0.0521125  |
----------------------------------------
itr #533 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 533...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5153, #subsample_inputs: 5153
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.738      |
| AbsLearnSignalNew       | 0.738      |
| AbsLearningOld          | 0.738      |
| AverageDiscountedReturn | 153        |
| AveragePhiLoss          | 0.981461   |
| AveragePolicyStd        | 0.729593   |
| AverageReturn           | 876        |
| Entropy                 | 6.61063    |
| EnvExecTime             | 2.67       |
| ExplainedVariance       | 0.305      |
| Iteration               | 533        |
| ItrTime                 | 11.2       |
| LossAfter               | 1.32344    |
| LossBefore              | 1.37422    |
| MaxReturn               | 1.98e+03   |
| MeanKL                  | 0.00995266 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 374        |
| NumTrajs                | 14         |
| Perplexity              | 742.949    |
| PolicyExecTime          | 0.536      |
| ProcessExecTime         | 0.0659     |
| StdReturn               | 376        |
| Time                    | 5.93e+03   |
| dLoss                   | 0.0507767  |
----------------------------------------
itr #534 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 534...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5226, #subsample_inputs: 5226
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.606      |
| AbsLearnSignalNew       | 0.606      |
| AbsLearningOld          | 0.606      |
| AverageDiscountedReturn | 127        |
| AveragePhiLoss          | 0.982059   |
| AveragePolicyStd        | 0.730887   |
| AverageReturn           | 518        |
| Entropy                 | 6.6197     |
| EnvExecTime             | 3.13       |
| ExplainedVariance       | 0.333      |
| Iteration               | 534        |
| ItrTime                 | 10.6       |
| LossAfter               | 1.70377    |
| LossBefore              | 1.75679    |
| MaxReturn               | 1.15e+03   |
| MeanKL                  | 0.00997362 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 82.9       |
| NumTrajs                | 19         |
| Perplexity              | 749.724    |
| PolicyExecTime          | 0.627      |
| ProcessExecTime         | 0.0843     |
| StdReturn               | 325        |
| Time                    | 5.94e+03   |
| dLoss                   | 0.0530171  |
----------------------------------------
itr #535 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 535...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5145, #subsample_inputs: 5145
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.603      |
| AbsLearnSignalNew       | 0.603      |
| AbsLearningOld          | 0.603      |
| AverageDiscountedReturn | 142        |
| AveragePhiLoss          | 0.969608   |
| AveragePolicyStd        | 0.728379   |
| AverageReturn           | 818        |
| Entropy                 | 6.59829    |
| EnvExecTime             | 2.88       |
| ExplainedVariance       | -0.767     |
| Iteration               | 535        |
| ItrTime                 | 11.7       |
| LossAfter               | 1.59988    |
| LossBefore              | 1.64838    |
| MaxReturn               | 2.07e+03   |
| MeanKL                  | 0.00641361 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 81.6       |
| NumTrajs                | 15         |
| Perplexity              | 733.842    |
| PolicyExecTime          | 0.608      |
| ProcessExecTime         | 0.0799     |
| StdReturn               | 525        |
| Time                    | 5.95e+03   |
| dLoss                   | 0.0484995  |
----------------------------------------
itr #536 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 536...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5087, #subsample_inputs: 5087
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.69      |
| AbsLearnSignalNew       | 0.69      |
| AbsLearningOld          | 0.69      |
| AverageDiscountedReturn | 140       |
| AveragePhiLoss          | 0.970346  |
| AveragePolicyStd        | 0.730718  |
| AverageReturn           | 621       |
| Entropy                 | 6.61795   |
| EnvExecTime             | 3.24      |
| ExplainedVariance       | 0.482     |
| Iteration               | 536       |
| ItrTime                 | 11.1      |
| LossAfter               | 1.67185   |
| LossBefore              | 1.71891   |
| MaxReturn               | 1.27e+03  |
| MeanKL                  | 0.0064515 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 83.3      |
| NumTrajs                | 18        |
| Perplexity              | 748.407   |
| PolicyExecTime          | 0.648     |
| ProcessExecTime         | 0.0825    |
| StdReturn               | 330       |
| Time                    | 5.96e+03  |
| dLoss                   | 0.0470594 |
---------------------------------------
itr #537 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 537...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5151, #subsample_inputs: 5151
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.648      |
| AbsLearnSignalNew       | 0.648      |
| AbsLearningOld          | 0.648      |
| AverageDiscountedReturn | 134        |
| AveragePhiLoss          | 0.977563   |
| AveragePolicyStd        | 0.729935   |
| AverageReturn           | 572        |
| Entropy                 | 6.61101    |
| EnvExecTime             | 3.2        |
| ExplainedVariance       | 0.504      |
| Iteration               | 537        |
| ItrTime                 | 11.7       |
| LossAfter               | 2.25349    |
| LossBefore              | 2.31477    |
| MaxReturn               | 1.06e+03   |
| MeanKL                  | 0.00984832 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 93.2       |
| NumTrajs                | 18         |
| Perplexity              | 743.23     |
| PolicyExecTime          | 0.634      |
| ProcessExecTime         | 0.0832     |
| StdReturn               | 247        |
| Time                    | 5.98e+03   |
| dLoss                   | 0.0612774  |
----------------------------------------
itr #538 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 538...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5247, #subsample_inputs: 5247
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.69      |
| AbsLearnSignalNew       | 0.69      |
| AbsLearningOld          | 0.69      |
| AverageDiscountedReturn | 123       |
| AveragePhiLoss          | 0.97122   |
| AveragePolicyStd        | 0.730818  |
| AverageReturn           | 719       |
| Entropy                 | 6.6172    |
| EnvExecTime             | 3.01      |
| ExplainedVariance       | 0.408     |
| Iteration               | 538       |
| ItrTime                 | 11.5      |
| LossAfter               | 0.909249  |
| LossBefore              | 0.967135  |
| MaxReturn               | 2.52e+03  |
| MeanKL                  | 0.0099445 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 54.4      |
| NumTrajs                | 15        |
| Perplexity              | 747.848   |
| PolicyExecTime          | 0.582     |
| ProcessExecTime         | 0.0762    |
| StdReturn               | 692       |
| Time                    | 5.99e+03  |
| dLoss                   | 0.0578853 |
---------------------------------------
itr #539 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 539...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5960, #subsample_inputs: 5960
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.692      |
| AbsLearnSignalNew       | 0.692      |
| AbsLearningOld          | 0.692      |
| AverageDiscountedReturn | 124        |
| AveragePhiLoss          | 0.977747   |
| AveragePolicyStd        | 0.728825   |
| AverageReturn           | 803        |
| Entropy                 | 6.60193    |
| EnvExecTime             | 3.61       |
| ExplainedVariance       | 0.511      |
| Iteration               | 539        |
| ItrTime                 | 11.8       |
| LossAfter               | 1.58754    |
| LossBefore              | 1.6284     |
| MaxReturn               | 2.33e+03   |
| MeanKL                  | 0.00641129 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 47.8       |
| NumTrajs                | 16         |
| Perplexity              | 736.513    |
| PolicyExecTime          | 0.735      |
| ProcessExecTime         | 0.0975     |
| StdReturn               | 649        |
| Time                    | 6e+03      |
| dLoss                   | 0.0408578  |
----------------------------------------
itr #540 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 540...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5089, #subsample_inputs: 5089
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.692      |
| AbsLearnSignalNew       | 0.692      |
| AbsLearningOld          | 0.692      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 0.973719   |
| AveragePolicyStd        | 0.727913   |
| AverageReturn           | 503        |
| Entropy                 | 6.59394    |
| EnvExecTime             | 3.37       |
| ExplainedVariance       | 0.431      |
| Iteration               | 540        |
| ItrTime                 | 11.8       |
| LossAfter               | 0.543205   |
| LossBefore              | 0.600209   |
| MaxReturn               | 890        |
| MeanKL                  | 0.00995446 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 67.7       |
| NumTrajs                | 19         |
| Perplexity              | 730.652    |
| PolicyExecTime          | 0.659      |
| ProcessExecTime         | 0.084      |
| StdReturn               | 268        |
| Time                    | 6.01e+03   |
| dLoss                   | 0.0570044  |
----------------------------------------
itr #541 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 541...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5006, #subsample_inputs: 5006
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.71       |
| AbsLearnSignalNew       | 0.71       |
| AbsLearningOld          | 0.71       |
| AverageDiscountedReturn | 136        |
| AveragePhiLoss          | 0.972472   |
| AveragePolicyStd        | 0.7271     |
| AverageReturn           | 594        |
| Entropy                 | 6.58695    |
| EnvExecTime             | 2.57       |
| ExplainedVariance       | 0.34       |
| Iteration               | 541        |
| ItrTime                 | 11         |
| LossAfter               | 1.44107    |
| LossBefore              | 1.49952    |
| MaxReturn               | 1.05e+03   |
| MeanKL                  | 0.00986075 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 134        |
| NumTrajs                | 18         |
| Perplexity              | 725.561    |
| PolicyExecTime          | 0.47       |
| ProcessExecTime         | 0.0634     |
| StdReturn               | 282        |
| Time                    | 6.02e+03   |
| dLoss                   | 0.0584551  |
----------------------------------------
itr #542 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 542...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5145, #subsample_inputs: 5145
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.69       |
| AbsLearnSignalNew       | 0.69       |
| AbsLearningOld          | 0.69       |
| AverageDiscountedReturn | 134        |
| AveragePhiLoss          | 0.983134   |
| AveragePolicyStd        | 0.727137   |
| AverageReturn           | 656        |
| Entropy                 | 6.58686    |
| EnvExecTime             | 3.19       |
| ExplainedVariance       | 0.392      |
| Iteration               | 542        |
| ItrTime                 | 10.5       |
| LossAfter               | 0.712917   |
| LossBefore              | 0.757793   |
| MaxReturn               | 1.14e+03   |
| MeanKL                  | 0.00646912 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 46.5       |
| NumTrajs                | 17         |
| Perplexity              | 725.502    |
| PolicyExecTime          | 0.642      |
| ProcessExecTime         | 0.0814     |
| StdReturn               | 281        |
| Time                    | 6.03e+03   |
| dLoss                   | 0.0448759  |
----------------------------------------
itr #543 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 543...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5013, #subsample_inputs: 5013
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.628      |
| AbsLearnSignalNew       | 0.628      |
| AbsLearningOld          | 0.628      |
| AverageDiscountedReturn | 113        |
| AveragePhiLoss          | 0.986101   |
| AveragePolicyStd        | 0.725296   |
| AverageReturn           | 557        |
| Entropy                 | 6.57148    |
| EnvExecTime             | 3.44       |
| ExplainedVariance       | 0.416      |
| Iteration               | 543        |
| ItrTime                 | 11.9       |
| LossAfter               | 0.83564    |
| LossBefore              | 0.881944   |
| MaxReturn               | 1.44e+03   |
| MeanKL                  | 0.00995992 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 61.2       |
| NumTrajs                | 16         |
| Perplexity              | 714.426    |
| PolicyExecTime          | 0.673      |
| ProcessExecTime         | 0.0866     |
| StdReturn               | 433        |
| Time                    | 6.05e+03   |
| dLoss                   | 0.0463032  |
----------------------------------------
itr #544 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 544...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5426, #subsample_inputs: 5426
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.693      |
| AbsLearnSignalNew       | 0.693      |
| AbsLearningOld          | 0.693      |
| AverageDiscountedReturn | 118        |
| AveragePhiLoss          | 0.978668   |
| AveragePolicyStd        | 0.724621   |
| AverageReturn           | 638        |
| Entropy                 | 6.56791    |
| EnvExecTime             | 2.87       |
| ExplainedVariance       | 0.473      |
| Iteration               | 544        |
| ItrTime                 | 11.3       |
| LossAfter               | 1.39924    |
| LossBefore              | 1.45426    |
| MaxReturn               | 1.83e+03   |
| MeanKL                  | 0.00986476 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 63         |
| NumTrajs                | 17         |
| Perplexity              | 711.878    |
| PolicyExecTime          | 0.539      |
| ProcessExecTime         | 0.0712     |
| StdReturn               | 545        |
| Time                    | 6.06e+03   |
| dLoss                   | 0.0550231  |
----------------------------------------
itr #545 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 545...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5264, #subsample_inputs: 5264
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.732      |
| AbsLearnSignalNew       | 0.732      |
| AbsLearningOld          | 0.732      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 0.978177   |
| AveragePolicyStd        | 0.725015   |
| AverageReturn           | 572        |
| Entropy                 | 6.57078    |
| EnvExecTime             | 3.67       |
| ExplainedVariance       | 0.38       |
| Iteration               | 545        |
| ItrTime                 | 11.4       |
| LossAfter               | 1.65661    |
| LossBefore              | 1.70094    |
| MaxReturn               | 2.15e+03   |
| MeanKL                  | 0.00641903 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 50         |
| NumTrajs                | 18         |
| Perplexity              | 713.929    |
| PolicyExecTime          | 0.734      |
| ProcessExecTime         | 0.0931     |
| StdReturn               | 490        |
| Time                    | 6.07e+03   |
| dLoss                   | 0.0443335  |
----------------------------------------
itr #546 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 546...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5199, #subsample_inputs: 5199
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.689      |
| AbsLearnSignalNew       | 0.689      |
| AbsLearningOld          | 0.689      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 0.982782   |
| AveragePolicyStd        | 0.726043   |
| AverageReturn           | 658        |
| Entropy                 | 6.57891    |
| EnvExecTime             | 4.14       |
| ExplainedVariance       | 0.554      |
| Iteration               | 546        |
| ItrTime                 | 13.1       |
| LossAfter               | 0.816324   |
| LossBefore              | 0.865267   |
| MaxReturn               | 1.88e+03   |
| MeanKL                  | 0.00997361 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 64.2       |
| NumTrajs                | 17         |
| Perplexity              | 719.758    |
| PolicyExecTime          | 0.858      |
| ProcessExecTime         | 0.0963     |
| StdReturn               | 466        |
| Time                    | 6.08e+03   |
| dLoss                   | 0.0489436  |
----------------------------------------
itr #547 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 547...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5277, #subsample_inputs: 5277
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.443      |
| AbsLearnSignalNew       | 0.443      |
| AbsLearningOld          | 0.443      |
| AverageDiscountedReturn | 132        |
| AveragePhiLoss          | 0.980385   |
| AveragePolicyStd        | 0.723492   |
| AverageReturn           | 704        |
| Entropy                 | 6.55726    |
| EnvExecTime             | 3.17       |
| ExplainedVariance       | -3.39      |
| Iteration               | 547        |
| ItrTime                 | 11.7       |
| LossAfter               | 0.488174   |
| LossBefore              | 0.531931   |
| MaxReturn               | 2.27e+03   |
| MeanKL                  | 0.00995294 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 82.6       |
| NumTrajs                | 16         |
| Perplexity              | 704.339    |
| PolicyExecTime          | 0.621      |
| ProcessExecTime         | 0.0762     |
| StdReturn               | 500        |
| Time                    | 6.09e+03   |
| dLoss                   | 0.0437568  |
----------------------------------------
itr #548 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 548...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5165, #subsample_inputs: 5165
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.667      |
| AbsLearnSignalNew       | 0.667      |
| AbsLearningOld          | 0.667      |
| AverageDiscountedReturn | 139        |
| AveragePhiLoss          | 0.977279   |
| AveragePolicyStd        | 0.722371   |
| AverageReturn           | 604        |
| Entropy                 | 6.54928    |
| EnvExecTime             | 2.92       |
| ExplainedVariance       | 0.53       |
| Iteration               | 548        |
| ItrTime                 | 10.6       |
| LossAfter               | 0.370388   |
| LossBefore              | 0.421729   |
| MaxReturn               | 1.77e+03   |
| MeanKL                  | 0.00642654 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 56.6       |
| NumTrajs                | 19         |
| Perplexity              | 698.74     |
| PolicyExecTime          | 0.59       |
| ProcessExecTime         | 0.0794     |
| StdReturn               | 360        |
| Time                    | 6.1e+03    |
| dLoss                   | 0.0513408  |
----------------------------------------
itr #549 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 549...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5248, #subsample_inputs: 5248
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.503      |
| AbsLearnSignalNew       | 0.503      |
| AbsLearningOld          | 0.503      |
| AverageDiscountedReturn | 138        |
| AveragePhiLoss          | 0.976192   |
| AveragePolicyStd        | 0.723439   |
| AverageReturn           | 979        |
| Entropy                 | 6.55789    |
| EnvExecTime             | 3.18       |
| ExplainedVariance       | -4.42      |
| Iteration               | 549        |
| ItrTime                 | 11.8       |
| LossAfter               | 0.493628   |
| LossBefore              | 0.532233   |
| MaxReturn               | 2.2e+03    |
| MeanKL                  | 0.00640575 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 77.5       |
| NumTrajs                | 12         |
| Perplexity              | 704.78     |
| PolicyExecTime          | 0.668      |
| ProcessExecTime         | 0.0803     |
| StdReturn               | 630        |
| Time                    | 6.12e+03   |
| dLoss                   | 0.0386044  |
----------------------------------------
itr #550 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 550...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5603, #subsample_inputs: 5603
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.648      |
| AbsLearnSignalNew       | 0.648      |
| AbsLearningOld          | 0.648      |
| AverageDiscountedReturn | 129        |
| AveragePhiLoss          | 0.975068   |
| AveragePolicyStd        | 0.723759   |
| AverageReturn           | 834        |
| Entropy                 | 6.56049    |
| EnvExecTime             | 3.15       |
| ExplainedVariance       | 0.469      |
| Iteration               | 550        |
| ItrTime                 | 11.4       |
| LossAfter               | 0.887589   |
| LossBefore              | 0.93531    |
| MaxReturn               | 2.11e+03   |
| MeanKL                  | 0.00642617 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 157        |
| NumTrajs                | 14         |
| Perplexity              | 706.615    |
| PolicyExecTime          | 0.615      |
| ProcessExecTime         | 0.079      |
| StdReturn               | 518        |
| Time                    | 6.13e+03   |
| dLoss                   | 0.0477211  |
----------------------------------------
itr #551 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 551...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5274, #subsample_inputs: 5274
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.682      |
| AbsLearnSignalNew       | 0.682      |
| AbsLearningOld          | 0.682      |
| AverageDiscountedReturn | 135        |
| AveragePhiLoss          | 0.973434   |
| AveragePolicyStd        | 0.723645   |
| AverageReturn           | 590        |
| Entropy                 | 6.56034    |
| EnvExecTime             | 3.18       |
| ExplainedVariance       | 0.394      |
| Iteration               | 551        |
| ItrTime                 | 11.3       |
| LossAfter               | -0.318934  |
| LossBefore              | -0.257009  |
| MaxReturn               | 1.11e+03   |
| MeanKL                  | 0.00995785 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 49.8       |
| NumTrajs                | 19         |
| Perplexity              | 706.509    |
| PolicyExecTime          | 0.648      |
| ProcessExecTime         | 0.083      |
| StdReturn               | 272        |
| Time                    | 6.14e+03   |
| dLoss                   | 0.0619253  |
----------------------------------------
itr #552 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 552...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5077, #subsample_inputs: 5077
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.693     |
| AbsLearnSignalNew       | 0.693     |
| AbsLearningOld          | 0.693     |
| AverageDiscountedReturn | 138       |
| AveragePhiLoss          | 0.972878  |
| AveragePolicyStd        | 0.723808  |
| AverageReturn           | 563       |
| Entropy                 | 6.56227   |
| EnvExecTime             | 3         |
| ExplainedVariance       | 0.448     |
| Iteration               | 552       |
| ItrTime                 | 11.7      |
| LossAfter               | 0.390041  |
| LossBefore              | 0.435523  |
| MaxReturn               | 1.29e+03  |
| MeanKL                  | 0.0064053 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 74.5      |
| NumTrajs                | 19        |
| Perplexity              | 707.877   |
| PolicyExecTime          | 0.627     |
| ProcessExecTime         | 0.0765    |
| StdReturn               | 269       |
| Time                    | 6.15e+03  |
| dLoss                   | 0.0454819 |
---------------------------------------
itr #553 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 553...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5440, #subsample_inputs: 5440
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.716      |
| AbsLearnSignalNew       | 0.716      |
| AbsLearningOld          | 0.716      |
| AverageDiscountedReturn | 124        |
| AveragePhiLoss          | 0.985428   |
| AveragePolicyStd        | 0.723816   |
| AverageReturn           | 706        |
| Entropy                 | 6.5628     |
| EnvExecTime             | 3.19       |
| ExplainedVariance       | 0.517      |
| Iteration               | 553        |
| ItrTime                 | 11         |
| LossAfter               | 0.485756   |
| LossBefore              | 0.535193   |
| MaxReturn               | 2.1e+03    |
| MeanKL                  | 0.00989269 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 65.7       |
| NumTrajs                | 16         |
| Perplexity              | 708.251    |
| PolicyExecTime          | 0.657      |
| ProcessExecTime         | 0.082      |
| StdReturn               | 592        |
| Time                    | 6.16e+03   |
| dLoss                   | 0.0494377  |
----------------------------------------
itr #554 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 554...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5128, #subsample_inputs: 5128
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.727     |
| AbsLearnSignalNew       | 0.727     |
| AbsLearningOld          | 0.727     |
| AverageDiscountedReturn | 120       |
| AveragePhiLoss          | 0.976299  |
| AveragePolicyStd        | 0.725249  |
| AverageReturn           | 546       |
| Entropy                 | 6.57451   |
| EnvExecTime             | 3.35      |
| ExplainedVariance       | 0.529     |
| Iteration               | 554       |
| ItrTime                 | 11.7      |
| LossAfter               | 0.842203  |
| LossBefore              | 0.888211  |
| MaxReturn               | 1.5e+03   |
| MeanKL                  | 0.0064091 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 59.6      |
| NumTrajs                | 18        |
| Perplexity              | 716.594   |
| PolicyExecTime          | 0.669     |
| ProcessExecTime         | 0.087     |
| StdReturn               | 418       |
| Time                    | 6.17e+03  |
| dLoss                   | 0.0460078 |
---------------------------------------
itr #555 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 555...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5238, #subsample_inputs: 5238
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.735      |
| AbsLearnSignalNew       | 0.735      |
| AbsLearningOld          | 0.735      |
| AverageDiscountedReturn | 141        |
| AveragePhiLoss          | 0.971022   |
| AveragePolicyStd        | 0.722466   |
| AverageReturn           | 705        |
| Entropy                 | 6.55177    |
| EnvExecTime             | 2.96       |
| ExplainedVariance       | 0.232      |
| Iteration               | 555        |
| ItrTime                 | 11.6       |
| LossAfter               | 0.749694   |
| LossBefore              | 0.805244   |
| MaxReturn               | 1.4e+03    |
| MeanKL                  | 0.00995128 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 229        |
| NumTrajs                | 16         |
| Perplexity              | 700.486    |
| PolicyExecTime          | 0.567      |
| ProcessExecTime         | 0.0717     |
| StdReturn               | 316        |
| Time                    | 6.19e+03   |
| dLoss                   | 0.0555498  |
----------------------------------------
itr #556 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 556...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5222, #subsample_inputs: 5222
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.655      |
| AbsLearnSignalNew       | 0.655      |
| AbsLearningOld          | 0.655      |
| AverageDiscountedReturn | 123        |
| AveragePhiLoss          | 0.979187   |
| AveragePolicyStd        | 0.7198     |
| AverageReturn           | 506        |
| Entropy                 | 6.5299     |
| EnvExecTime             | 3.62       |
| ExplainedVariance       | 0.435      |
| Iteration               | 556        |
| ItrTime                 | 10.9       |
| LossAfter               | 0.501626   |
| LossBefore              | 0.554722   |
| MaxReturn               | 1.72e+03   |
| MeanKL                  | 0.00974379 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 95.7       |
| NumTrajs                | 19         |
| Perplexity              | 685.329    |
| PolicyExecTime          | 0.741      |
| ProcessExecTime         | 0.0927     |
| StdReturn               | 399        |
| Time                    | 6.2e+03    |
| dLoss                   | 0.0530956  |
----------------------------------------
itr #557 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 557...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5156, #subsample_inputs: 5156
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.684      |
| AbsLearnSignalNew       | 0.684      |
| AbsLearningOld          | 0.684      |
| AverageDiscountedReturn | 144        |
| AveragePhiLoss          | 0.972481   |
| AveragePolicyStd        | 0.719649   |
| AverageReturn           | 682        |
| Entropy                 | 6.52797    |
| EnvExecTime             | 3.04       |
| ExplainedVariance       | 0.297      |
| Iteration               | 557        |
| ItrTime                 | 11.6       |
| LossAfter               | 1.0967     |
| LossBefore              | 1.1447     |
| MaxReturn               | 1.14e+03   |
| MeanKL                  | 0.00643326 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 297        |
| NumTrajs                | 17         |
| Perplexity              | 684.005    |
| PolicyExecTime          | 0.623      |
| ProcessExecTime         | 0.0813     |
| StdReturn               | 248        |
| Time                    | 6.21e+03   |
| dLoss                   | 0.0480045  |
----------------------------------------
itr #558 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 558...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5086, #subsample_inputs: 5086
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.52       |
| AbsLearnSignalNew       | 0.52       |
| AbsLearningOld          | 0.52       |
| AverageDiscountedReturn | 113        |
| AveragePhiLoss          | 0.957137   |
| AveragePolicyStd        | 0.71984    |
| AverageReturn           | 451        |
| Entropy                 | 6.52887    |
| EnvExecTime             | 2.89       |
| ExplainedVariance       | -0.0217    |
| Iteration               | 558        |
| ItrTime                 | 10.8       |
| LossAfter               | 0.715263   |
| LossBefore              | 0.779423   |
| MaxReturn               | 1.24e+03   |
| MeanKL                  | 0.00996322 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 54         |
| NumTrajs                | 19         |
| Perplexity              | 684.624    |
| PolicyExecTime          | 0.556      |
| ProcessExecTime         | 0.0743     |
| StdReturn               | 308        |
| Time                    | 6.22e+03   |
| dLoss                   | 0.0641595  |
----------------------------------------
itr #559 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 559...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5178, #subsample_inputs: 5178
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.754      |
| AbsLearnSignalNew       | 0.754      |
| AbsLearningOld          | 0.754      |
| AverageDiscountedReturn | 114        |
| AveragePhiLoss          | 0.983752   |
| AveragePolicyStd        | 0.719709   |
| AverageReturn           | 490        |
| Entropy                 | 6.52902    |
| EnvExecTime             | 3.36       |
| ExplainedVariance       | 0.563      |
| Iteration               | 559        |
| ItrTime                 | 11.5       |
| LossAfter               | 0.100128   |
| LossBefore              | 0.151134   |
| MaxReturn               | 1.25e+03   |
| MeanKL                  | 0.00991543 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 56.1       |
| NumTrajs                | 19         |
| Perplexity              | 684.726    |
| PolicyExecTime          | 0.659      |
| ProcessExecTime         | 0.0854     |
| StdReturn               | 419        |
| Time                    | 6.23e+03   |
| dLoss                   | 0.051006   |
----------------------------------------
itr #560 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 560...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5039, #subsample_inputs: 5039
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.727      |
| AbsLearnSignalNew       | 0.727      |
| AbsLearningOld          | 0.727      |
| AverageDiscountedReturn | 137        |
| AveragePhiLoss          | 0.976891   |
| AveragePolicyStd        | 0.718595   |
| AverageReturn           | 680        |
| Entropy                 | 6.51982    |
| EnvExecTime             | 3.17       |
| ExplainedVariance       | 0.219      |
| Iteration               | 560        |
| ItrTime                 | 11.5       |
| LossAfter               | 0.485982   |
| LossBefore              | 0.537827   |
| MaxReturn               | 2.05e+03   |
| MeanKL                  | 0.00999599 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 29.4       |
| NumTrajs                | 16         |
| Perplexity              | 678.458    |
| PolicyExecTime          | 0.631      |
| ProcessExecTime         | 0.0775     |
| StdReturn               | 519        |
| Time                    | 6.24e+03   |
| dLoss                   | 0.0518448  |
----------------------------------------
itr #561 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 561...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5210, #subsample_inputs: 5210
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.709      |
| AbsLearnSignalNew       | 0.709      |
| AbsLearningOld          | 0.709      |
| AverageDiscountedReturn | 143        |
| AveragePhiLoss          | 0.983553   |
| AveragePolicyStd        | 0.716783   |
| AverageReturn           | 754        |
| Entropy                 | 6.50494    |
| EnvExecTime             | 3.01       |
| ExplainedVariance       | 0.496      |
| Iteration               | 561        |
| ItrTime                 | 10.4       |
| LossAfter               | -0.789711  |
| LossBefore              | -0.748538  |
| MaxReturn               | 1.45e+03   |
| MeanKL                  | 0.00648693 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 36.3       |
| NumTrajs                | 16         |
| Perplexity              | 668.433    |
| PolicyExecTime          | 0.624      |
| ProcessExecTime         | 0.0823     |
| StdReturn               | 411        |
| Time                    | 6.25e+03   |
| dLoss                   | 0.0411727  |
----------------------------------------
itr #562 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 562...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5343, #subsample_inputs: 5343
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.672      |
| AbsLearnSignalNew       | 0.672      |
| AbsLearningOld          | 0.672      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 0.984175   |
| AveragePolicyStd        | 0.713188   |
| AverageReturn           | 596        |
| Entropy                 | 6.4749     |
| EnvExecTime             | 3.29       |
| ExplainedVariance       | 0.431      |
| Iteration               | 562        |
| ItrTime                 | 12         |
| LossAfter               | 0.234795   |
| LossBefore              | 0.280563   |
| MaxReturn               | 1.79e+03   |
| MeanKL                  | 0.00999658 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 62         |
| NumTrajs                | 18         |
| Perplexity              | 648.653    |
| PolicyExecTime          | 0.654      |
| ProcessExecTime         | 0.0864     |
| StdReturn               | 452        |
| Time                    | 6.26e+03   |
| dLoss                   | 0.0457671  |
----------------------------------------
itr #563 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 563...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5335, #subsample_inputs: 5335
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.733     |
| AbsLearnSignalNew       | 0.733     |
| AbsLearningOld          | 0.733     |
| AverageDiscountedReturn | 137       |
| AveragePhiLoss          | 0.972384  |
| AveragePolicyStd        | 0.709972  |
| AverageReturn           | 815       |
| Entropy                 | 6.44731   |
| EnvExecTime             | 3.44      |
| ExplainedVariance       | 0.348     |
| Iteration               | 563       |
| ItrTime                 | 12.3      |
| LossAfter               | -0.576452 |
| LossBefore              | -0.521768 |
| MaxReturn               | 1.33e+03  |
| MeanKL                  | 0.0099589 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 81.5      |
| NumTrajs                | 14        |
| Perplexity              | 631.001   |
| PolicyExecTime          | 0.672     |
| ProcessExecTime         | 0.0801    |
| StdReturn               | 341       |
| Time                    | 6.28e+03  |
| dLoss                   | 0.0546832 |
---------------------------------------
itr #564 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 564...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5182, #subsample_inputs: 5182
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.699      |
| AbsLearnSignalNew       | 0.699      |
| AbsLearningOld          | 0.699      |
| AverageDiscountedReturn | 136        |
| AveragePhiLoss          | 0.982981   |
| AveragePolicyStd        | 0.712674   |
| AverageReturn           | 763        |
| Entropy                 | 6.46993    |
| EnvExecTime             | 3.41       |
| ExplainedVariance       | 0.342      |
| Iteration               | 564        |
| ItrTime                 | 10.8       |
| LossAfter               | -1.00142   |
| LossBefore              | -0.957307  |
| MaxReturn               | 1.51e+03   |
| MeanKL                  | 0.00648667 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 89.5       |
| NumTrajs                | 15         |
| Perplexity              | 645.44     |
| PolicyExecTime          | 0.694      |
| ProcessExecTime         | 0.0891     |
| StdReturn               | 449        |
| Time                    | 6.29e+03   |
| dLoss                   | 0.0441151  |
----------------------------------------
itr #565 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 565...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5003, #subsample_inputs: 5003
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.546      |
| AbsLearnSignalNew       | 0.546      |
| AbsLearningOld          | 0.546      |
| AverageDiscountedReturn | 131        |
| AveragePhiLoss          | 0.978904   |
| AveragePolicyStd        | 0.709859   |
| AverageReturn           | 1.1e+03    |
| Entropy                 | 6.44656    |
| EnvExecTime             | 3.13       |
| ExplainedVariance       | -0.000288  |
| Iteration               | 565        |
| ItrTime                 | 11.5       |
| LossAfter               | -0.207353  |
| LossBefore              | -0.15662   |
| MaxReturn               | 2.49e+03   |
| MeanKL                  | 0.00990004 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 79.8       |
| NumTrajs                | 10         |
| Perplexity              | 630.532    |
| PolicyExecTime          | 0.637      |
| ProcessExecTime         | 0.0828     |
| StdReturn               | 820        |
| Time                    | 6.3e+03    |
| dLoss                   | 0.0507331  |
----------------------------------------
itr #566 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 566...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5292, #subsample_inputs: 5292
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.662      |
| AbsLearnSignalNew       | 0.662      |
| AbsLearningOld          | 0.662      |
| AverageDiscountedReturn | 130        |
| AveragePhiLoss          | 0.990152   |
| AveragePolicyStd        | 0.709448   |
| AverageReturn           | 750        |
| Entropy                 | 6.44199    |
| EnvExecTime             | 2.77       |
| ExplainedVariance       | 0.501      |
| Iteration               | 566        |
| ItrTime                 | 11         |
| LossAfter               | -0.590557  |
| LossBefore              | -0.544549  |
| MaxReturn               | 1.79e+03   |
| MeanKL                  | 0.00646858 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 50         |
| NumTrajs                | 16         |
| Perplexity              | 627.652    |
| PolicyExecTime          | 0.532      |
| ProcessExecTime         | 0.0702     |
| StdReturn               | 482        |
| Time                    | 6.31e+03   |
| dLoss                   | 0.0460081  |
----------------------------------------
itr #567 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 567...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5437, #subsample_inputs: 5437
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.697      |
| AbsLearnSignalNew       | 0.697      |
| AbsLearningOld          | 0.697      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 0.98034    |
| AveragePolicyStd        | 0.708137   |
| AverageReturn           | 822        |
| Entropy                 | 6.43128    |
| EnvExecTime             | 3.39       |
| ExplainedVariance       | 0.49       |
| Iteration               | 567        |
| ItrTime                 | 11.2       |
| LossAfter               | 0.38082    |
| LossBefore              | 0.428437   |
| MaxReturn               | 1.74e+03   |
| MeanKL                  | 0.00994141 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 50.1       |
| NumTrajs                | 14         |
| Perplexity              | 620.965    |
| PolicyExecTime          | 0.695      |
| ProcessExecTime         | 0.0886     |
| StdReturn               | 552        |
| Time                    | 6.32e+03   |
| dLoss                   | 0.047617   |
----------------------------------------
itr #568 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 568...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5121, #subsample_inputs: 5121
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.677      |
| AbsLearnSignalNew       | 0.677      |
| AbsLearningOld          | 0.677      |
| AverageDiscountedReturn | 135        |
| AveragePhiLoss          | 0.986257   |
| AveragePolicyStd        | 0.70988    |
| AverageReturn           | 719        |
| Entropy                 | 6.446      |
| EnvExecTime             | 3.82       |
| ExplainedVariance       | 0.457      |
| Iteration               | 568        |
| ItrTime                 | 12.4       |
| LossAfter               | 0.985009   |
| LossBefore              | 1.03824    |
| MaxReturn               | 1.59e+03   |
| MeanKL                  | 0.00995648 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 89.5       |
| NumTrajs                | 15         |
| Perplexity              | 630.178    |
| PolicyExecTime          | 0.775      |
| ProcessExecTime         | 0.0887     |
| StdReturn               | 383        |
| Time                    | 6.33e+03   |
| dLoss                   | 0.0532272  |
----------------------------------------
itr #569 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 569...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5298, #subsample_inputs: 5298
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.665      |
| AbsLearnSignalNew       | 0.665      |
| AbsLearningOld          | 0.665      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 0.979525   |
| AveragePolicyStd        | 0.708974   |
| AverageReturn           | 610        |
| Entropy                 | 6.43811    |
| EnvExecTime             | 3.01       |
| ExplainedVariance       | 0.463      |
| Iteration               | 569        |
| ItrTime                 | 11.3       |
| LossAfter               | -0.1846    |
| LossBefore              | -0.128117  |
| MaxReturn               | 1.18e+03   |
| MeanKL                  | 0.00974344 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 77.5       |
| NumTrajs                | 17         |
| Perplexity              | 625.222    |
| PolicyExecTime          | 0.56       |
| ProcessExecTime         | 0.0701     |
| StdReturn               | 303        |
| Time                    | 6.35e+03   |
| dLoss                   | 0.0564832  |
----------------------------------------
itr #570 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 570...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5027, #subsample_inputs: 5027
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.655      |
| AbsLearnSignalNew       | 0.655      |
| AbsLearningOld          | 0.655      |
| AverageDiscountedReturn | 130        |
| AveragePhiLoss          | 0.971736   |
| AveragePolicyStd        | 0.710689   |
| AverageReturn           | 702        |
| Entropy                 | 6.45287    |
| EnvExecTime             | 3.51       |
| ExplainedVariance       | 0.383      |
| Iteration               | 570        |
| ItrTime                 | 11.1       |
| LossAfter               | 0.128597   |
| LossBefore              | 0.204913   |
| MaxReturn               | 1.76e+03   |
| MeanKL                  | 0.00988737 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 96.8       |
| NumTrajs                | 14         |
| Perplexity              | 634.518    |
| PolicyExecTime          | 0.715      |
| ProcessExecTime         | 0.0876     |
| StdReturn               | 476        |
| Time                    | 6.36e+03   |
| dLoss                   | 0.0763161  |
----------------------------------------
itr #571 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 571...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5167, #subsample_inputs: 5167
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.676      |
| AbsLearnSignalNew       | 0.676      |
| AbsLearningOld          | 0.676      |
| AverageDiscountedReturn | 136        |
| AveragePhiLoss          | 0.986274   |
| AveragePolicyStd        | 0.711847   |
| AverageReturn           | 746        |
| Entropy                 | 6.46239    |
| EnvExecTime             | 3.32       |
| ExplainedVariance       | 0.446      |
| Iteration               | 571        |
| ItrTime                 | 12.1       |
| LossAfter               | 0.308493   |
| LossBefore              | 0.350332   |
| MaxReturn               | 2.09e+03   |
| MeanKL                  | 0.00641992 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 63.5       |
| NumTrajs                | 15         |
| Perplexity              | 640.589    |
| PolicyExecTime          | 0.659      |
| ProcessExecTime         | 0.0825     |
| StdReturn               | 473        |
| Time                    | 6.37e+03   |
| dLoss                   | 0.0418393  |
----------------------------------------
itr #572 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 572...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5235, #subsample_inputs: 5235
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.739      |
| AbsLearnSignalNew       | 0.739      |
| AbsLearningOld          | 0.739      |
| AverageDiscountedReturn | 144        |
| AveragePhiLoss          | 0.977878   |
| AveragePolicyStd        | 0.711336   |
| AverageReturn           | 694        |
| Entropy                 | 6.45848    |
| EnvExecTime             | 2.89       |
| ExplainedVariance       | 0.584      |
| Iteration               | 572        |
| ItrTime                 | 10.6       |
| LossAfter               | 0.137791   |
| LossBefore              | 0.198751   |
| MaxReturn               | 1.06e+03   |
| MeanKL                  | 0.00994548 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 253        |
| NumTrajs                | 17         |
| Perplexity              | 638.088    |
| PolicyExecTime          | 0.588      |
| ProcessExecTime         | 0.0745     |
| StdReturn               | 270        |
| Time                    | 6.38e+03   |
| dLoss                   | 0.06096    |
----------------------------------------
itr #573 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 573...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5021, #subsample_inputs: 5021
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.654      |
| AbsLearnSignalNew       | 0.654      |
| AbsLearningOld          | 0.654      |
| AverageDiscountedReturn | 131        |
| AveragePhiLoss          | 0.972557   |
| AveragePolicyStd        | 0.711749   |
| AverageReturn           | 610        |
| Entropy                 | 6.46209    |
| EnvExecTime             | 3.22       |
| ExplainedVariance       | 0.44       |
| Iteration               | 573        |
| ItrTime                 | 11.2       |
| LossAfter               | 0.68877    |
| LossBefore              | 0.742011   |
| MaxReturn               | 1.37e+03   |
| MeanKL                  | 0.00640591 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 66.2       |
| NumTrajs                | 17         |
| Perplexity              | 640.398    |
| PolicyExecTime          | 0.665      |
| ProcessExecTime         | 0.0845     |
| StdReturn               | 371        |
| Time                    | 6.39e+03   |
| dLoss                   | 0.0532413  |
----------------------------------------
itr #574 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 574...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5033, #subsample_inputs: 5033
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.67       |
| AbsLearnSignalNew       | 0.67       |
| AbsLearningOld          | 0.67       |
| AverageDiscountedReturn | 113        |
| AveragePhiLoss          | 0.979644   |
| AveragePolicyStd        | 0.710149   |
| AverageReturn           | 529        |
| Entropy                 | 6.449      |
| EnvExecTime             | 2.98       |
| ExplainedVariance       | 0.495      |
| Iteration               | 574        |
| ItrTime                 | 11.2       |
| LossAfter               | 0.68501    |
| LossBefore              | 0.734132   |
| MaxReturn               | 1.73e+03   |
| MeanKL                  | 0.00991909 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 38.3       |
| NumTrajs                | 18         |
| Perplexity              | 632.07     |
| PolicyExecTime          | 0.566      |
| ProcessExecTime         | 0.0743     |
| StdReturn               | 455        |
| Time                    | 6.4e+03    |
| dLoss                   | 0.049121   |
----------------------------------------
itr #575 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 575...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5212, #subsample_inputs: 5212
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.571      |
| AbsLearnSignalNew       | 0.571      |
| AbsLearningOld          | 0.571      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 0.976972   |
| AveragePolicyStd        | 0.709242   |
| AverageReturn           | 750        |
| Entropy                 | 6.44309    |
| EnvExecTime             | 3.15       |
| ExplainedVariance       | -0.902     |
| Iteration               | 575        |
| ItrTime                 | 10.4       |
| LossAfter               | -0.0278231 |
| LossBefore              | 0.0136617  |
| MaxReturn               | 2.39e+03   |
| MeanKL                  | 0.00643852 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 44.2       |
| NumTrajs                | 14         |
| Perplexity              | 628.347    |
| PolicyExecTime          | 0.636      |
| ProcessExecTime         | 0.0818     |
| StdReturn               | 641        |
| Time                    | 6.41e+03   |
| dLoss                   | 0.0414848  |
----------------------------------------
itr #576 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 576...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5722, #subsample_inputs: 5722
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.728     |
| AbsLearnSignalNew       | 0.728     |
| AbsLearningOld          | 0.729     |
| AverageDiscountedReturn | 138       |
| AveragePhiLoss          | 0.979398  |
| AveragePolicyStd        | 0.708789  |
| AverageReturn           | 1.07e+03  |
| Entropy                 | 6.43877   |
| EnvExecTime             | 3.9       |
| ExplainedVariance       | 0.563     |
| Iteration               | 576       |
| ItrTime                 | 13.3      |
| LossAfter               | 0.484894  |
| LossBefore              | 0.53678   |
| MaxReturn               | 2.37e+03  |
| MeanKL                  | 0.0099891 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 35.2      |
| NumTrajs                | 13        |
| Perplexity              | 625.635   |
| PolicyExecTime          | 0.828     |
| ProcessExecTime         | 0.102     |
| StdReturn               | 645       |
| Time                    | 6.43e+03  |
| dLoss                   | 0.0518862 |
---------------------------------------
itr #577 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 577...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5052, #subsample_inputs: 5052
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.683      |
| AbsLearnSignalNew       | 0.683      |
| AbsLearningOld          | 0.683      |
| AverageDiscountedReturn | 131        |
| AveragePhiLoss          | 0.974025   |
| AveragePolicyStd        | 0.708789   |
| AverageReturn           | 823        |
| Entropy                 | 6.43798    |
| EnvExecTime             | 3.09       |
| ExplainedVariance       | 0.519      |
| Iteration               | 577        |
| ItrTime                 | 11.3       |
| LossAfter               | 1.28811    |
| LossBefore              | 1.34076    |
| MaxReturn               | 2.51e+03   |
| MeanKL                  | 0.00994321 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 155        |
| NumTrajs                | 13         |
| Perplexity              | 625.14     |
| PolicyExecTime          | 0.588      |
| ProcessExecTime         | 0.074      |
| StdReturn               | 596        |
| Time                    | 6.44e+03   |
| dLoss                   | 0.0526466  |
----------------------------------------
itr #578 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 578...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5210, #subsample_inputs: 5210
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.703      |
| AbsLearnSignalNew       | 0.703      |
| AbsLearningOld          | 0.703      |
| AverageDiscountedReturn | 127        |
| AveragePhiLoss          | 0.980425   |
| AveragePolicyStd        | 0.709092   |
| AverageReturn           | 576        |
| Entropy                 | 6.44011    |
| EnvExecTime             | 3.41       |
| ExplainedVariance       | 0.514      |
| Iteration               | 578        |
| ItrTime                 | 10.5       |
| LossAfter               | 0.669403   |
| LossBefore              | 0.720772   |
| MaxReturn               | 2.29e+03   |
| MeanKL                  | 0.00988613 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 59         |
| NumTrajs                | 18         |
| Perplexity              | 626.478    |
| PolicyExecTime          | 0.666      |
| ProcessExecTime         | 0.0834     |
| StdReturn               | 496        |
| Time                    | 6.45e+03   |
| dLoss                   | 0.0513691  |
----------------------------------------
itr #579 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 579...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5230, #subsample_inputs: 5230
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.732      |
| AbsLearnSignalNew       | 0.732      |
| AbsLearningOld          | 0.732      |
| AverageDiscountedReturn | 127        |
| AveragePhiLoss          | 0.973065   |
| AveragePolicyStd        | 0.706867   |
| AverageReturn           | 961        |
| Entropy                 | 6.41985    |
| EnvExecTime             | 3.69       |
| ExplainedVariance       | 0.339      |
| Iteration               | 579        |
| ItrTime                 | 12.5       |
| LossAfter               | 1.60805    |
| LossBefore              | 1.6483     |
| MaxReturn               | 2.1e+03    |
| MeanKL                  | 0.00649641 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 70         |
| NumTrajs                | 11         |
| Perplexity              | 613.911    |
| PolicyExecTime          | 0.744      |
| ProcessExecTime         | 0.0938     |
| StdReturn               | 559        |
| Time                    | 6.46e+03   |
| dLoss                   | 0.0402585  |
----------------------------------------
itr #580 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 580...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5292, #subsample_inputs: 5292
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.676      |
| AbsLearnSignalNew       | 0.676      |
| AbsLearningOld          | 0.676      |
| AverageDiscountedReturn | 124        |
| AveragePhiLoss          | 0.977849   |
| AveragePolicyStd        | 0.706216   |
| AverageReturn           | 612        |
| Entropy                 | 6.41485    |
| EnvExecTime             | 3          |
| ExplainedVariance       | 0.449      |
| Iteration               | 580        |
| ItrTime                 | 11.6       |
| LossAfter               | 1.23948    |
| LossBefore              | 1.29738    |
| MaxReturn               | 1.35e+03   |
| MeanKL                  | 0.00985536 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 48.6       |
| NumTrajs                | 17         |
| Perplexity              | 610.85     |
| PolicyExecTime          | 0.553      |
| ProcessExecTime         | 0.0702     |
| StdReturn               | 413        |
| Time                    | 6.47e+03   |
| dLoss                   | 0.0578923  |
----------------------------------------
itr #581 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 581...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5318, #subsample_inputs: 5318
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.706      |
| AbsLearnSignalNew       | 0.706      |
| AbsLearningOld          | 0.706      |
| AverageDiscountedReturn | 148        |
| AveragePhiLoss          | 0.981084   |
| AveragePolicyStd        | 0.705757   |
| AverageReturn           | 1.08e+03   |
| Entropy                 | 6.41148    |
| EnvExecTime             | 3.57       |
| ExplainedVariance       | 0.3        |
| Iteration               | 581        |
| ItrTime                 | 11.1       |
| LossAfter               | 1.24074    |
| LossBefore              | 1.29269    |
| MaxReturn               | 1.83e+03   |
| MeanKL                  | 0.00985651 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 61.1       |
| NumTrajs                | 11         |
| Perplexity              | 608.796    |
| PolicyExecTime          | 0.723      |
| ProcessExecTime         | 0.0922     |
| StdReturn               | 499        |
| Time                    | 6.48e+03   |
| dLoss                   | 0.0519495  |
----------------------------------------
itr #582 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 582...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5681, #subsample_inputs: 5681
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.689      |
| AbsLearnSignalNew       | 0.689      |
| AbsLearningOld          | 0.689      |
| AverageDiscountedReturn | 137        |
| AveragePhiLoss          | 0.981916   |
| AveragePolicyStd        | 0.706603   |
| AverageReturn           | 911        |
| Entropy                 | 6.41961    |
| EnvExecTime             | 3.63       |
| ExplainedVariance       | 0.215      |
| Iteration               | 582        |
| ItrTime                 | 12.8       |
| LossAfter               | -0.0569492 |
| LossBefore              | -0.0153257 |
| MaxReturn               | 2.22e+03   |
| MeanKL                  | 0.00646617 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 135        |
| NumTrajs                | 14         |
| Perplexity              | 613.764    |
| PolicyExecTime          | 0.736      |
| ProcessExecTime         | 0.096      |
| StdReturn               | 613        |
| Time                    | 6.5e+03    |
| dLoss                   | 0.0416236  |
----------------------------------------
itr #583 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 583...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5065, #subsample_inputs: 5065
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.662      |
| AbsLearnSignalNew       | 0.662      |
| AbsLearningOld          | 0.662      |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 0.983885   |
| AveragePolicyStd        | 0.705357   |
| AverageReturn           | 682        |
| Entropy                 | 6.4094     |
| EnvExecTime             | 2.85       |
| ExplainedVariance       | 0.521      |
| Iteration               | 583        |
| ItrTime                 | 11         |
| LossAfter               | -0.513757  |
| LossBefore              | -0.461962  |
| MaxReturn               | 1.81e+03   |
| MeanKL                  | 0.00987064 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 35.2       |
| NumTrajs                | 15         |
| Perplexity              | 607.531    |
| PolicyExecTime          | 0.508      |
| ProcessExecTime         | 0.0662     |
| StdReturn               | 534        |
| Time                    | 6.51e+03   |
| dLoss                   | 0.0517944  |
----------------------------------------
itr #584 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 584...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5099, #subsample_inputs: 5099
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.66       |
| AbsLearnSignalNew       | 0.66       |
| AbsLearningOld          | 0.66       |
| AverageDiscountedReturn | 143        |
| AveragePhiLoss          | 0.977944   |
| AveragePolicyStd        | 0.704406   |
| AverageReturn           | 975        |
| Entropy                 | 6.40164    |
| EnvExecTime             | 3.46       |
| ExplainedVariance       | 0.353      |
| Iteration               | 584        |
| ItrTime                 | 10.8       |
| LossAfter               | 1.9884     |
| LossBefore              | 2.0312     |
| MaxReturn               | 2.34e+03   |
| MeanKL                  | 0.00641528 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 96.5       |
| NumTrajs                | 12         |
| Perplexity              | 602.832    |
| PolicyExecTime          | 0.707      |
| ProcessExecTime         | 0.0852     |
| StdReturn               | 634        |
| Time                    | 6.52e+03   |
| dLoss                   | 0.0427992  |
----------------------------------------
itr #585 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 585...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5114, #subsample_inputs: 5114
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.68       |
| AbsLearnSignalNew       | 0.68       |
| AbsLearningOld          | 0.68       |
| AverageDiscountedReturn | 144        |
| AveragePhiLoss          | 0.975428   |
| AveragePolicyStd        | 0.703036   |
| AverageReturn           | 782        |
| Entropy                 | 6.38877    |
| EnvExecTime             | 3.1        |
| ExplainedVariance       | 0.458      |
| Iteration               | 585        |
| ItrTime                 | 11.9       |
| LossAfter               | 0.844501   |
| LossBefore              | 0.885496   |
| MaxReturn               | 1.83e+03   |
| MeanKL                  | 0.00645316 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 61.2       |
| NumTrajs                | 15         |
| Perplexity              | 595.127    |
| PolicyExecTime          | 0.631      |
| ProcessExecTime         | 0.083      |
| StdReturn               | 438        |
| Time                    | 6.53e+03   |
| dLoss                   | 0.0409946  |
----------------------------------------
itr #586 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 586...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5318, #subsample_inputs: 5318
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.655     |
| AbsLearnSignalNew       | 0.655     |
| AbsLearningOld          | 0.655     |
| AverageDiscountedReturn | 138       |
| AveragePhiLoss          | 0.984327  |
| AveragePolicyStd        | 0.701304  |
| AverageReturn           | 1.36e+03  |
| Entropy                 | 6.37439   |
| EnvExecTime             | 3.17      |
| ExplainedVariance       | 0.264     |
| Iteration               | 586       |
| ItrTime                 | 11.2      |
| LossAfter               | 0.726402  |
| LossBefore              | 0.763675  |
| MaxReturn               | 2.62e+03  |
| MeanKL                  | 0.006453  |
| MeanKLBefore            | 0.0       |
| MinReturn               | 67.2      |
| NumTrajs                | 9         |
| Perplexity              | 586.627   |
| PolicyExecTime          | 0.624     |
| ProcessExecTime         | 0.0766    |
| StdReturn               | 828       |
| Time                    | 6.54e+03  |
| dLoss                   | 0.0372736 |
---------------------------------------
itr #587 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 587...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5245, #subsample_inputs: 5245
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.595      |
| AbsLearnSignalNew       | 0.595      |
| AbsLearningOld          | 0.595      |
| AverageDiscountedReturn | 138        |
| AveragePhiLoss          | 0.979623   |
| AveragePolicyStd        | 0.701047   |
| AverageReturn           | 758        |
| Entropy                 | 6.37193    |
| EnvExecTime             | 3.28       |
| ExplainedVariance       | 0.359      |
| Iteration               | 587        |
| ItrTime                 | 11.1       |
| LossAfter               | 0.819129   |
| LossBefore              | 0.874485   |
| MaxReturn               | 2e+03      |
| MeanKL                  | 0.00977615 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 71.6       |
| NumTrajs                | 14         |
| Perplexity              | 585.188    |
| PolicyExecTime          | 0.647      |
| ProcessExecTime         | 0.084      |
| StdReturn               | 491        |
| Time                    | 6.55e+03   |
| dLoss                   | 0.0553564  |
----------------------------------------
itr #588 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 588...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5746, #subsample_inputs: 5746
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.695      |
| AbsLearnSignalNew       | 0.695      |
| AbsLearningOld          | 0.695      |
| AverageDiscountedReturn | 131        |
| AveragePhiLoss          | 0.979125   |
| AveragePolicyStd        | 0.704635   |
| AverageReturn           | 911        |
| Entropy                 | 6.40327    |
| EnvExecTime             | 3.4        |
| ExplainedVariance       | 0.375      |
| Iteration               | 588        |
| ItrTime                 | 12.8       |
| LossAfter               | 1.22671    |
| LossBefore              | 1.26752    |
| MaxReturn               | 2.43e+03   |
| MeanKL                  | 0.00644296 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 64.9       |
| NumTrajs                | 14         |
| Perplexity              | 603.814    |
| PolicyExecTime          | 0.683      |
| ProcessExecTime         | 0.088      |
| StdReturn               | 730        |
| Time                    | 6.57e+03   |
| dLoss                   | 0.0408077  |
----------------------------------------
itr #589 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 589...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5092, #subsample_inputs: 5092
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.675      |
| AbsLearnSignalNew       | 0.675      |
| AbsLearningOld          | 0.675      |
| AverageDiscountedReturn | 127        |
| AveragePhiLoss          | 0.977106   |
| AveragePolicyStd        | 0.704358   |
| AverageReturn           | 752        |
| Entropy                 | 6.40081    |
| EnvExecTime             | 3.17       |
| ExplainedVariance       | 0.545      |
| Iteration               | 589        |
| ItrTime                 | 10.6       |
| LossAfter               | 1.43348    |
| LossBefore              | 1.48917    |
| MaxReturn               | 2.01e+03   |
| MeanKL                  | 0.00981239 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 42.8       |
| NumTrajs                | 14         |
| Perplexity              | 602.332    |
| PolicyExecTime          | 0.639      |
| ProcessExecTime         | 0.0802     |
| StdReturn               | 533        |
| Time                    | 6.58e+03   |
| dLoss                   | 0.055687   |
----------------------------------------
itr #590 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 590...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5601, #subsample_inputs: 5601
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.685      |
| AbsLearnSignalNew       | 0.685      |
| AbsLearningOld          | 0.685      |
| AverageDiscountedReturn | 132        |
| AveragePhiLoss          | 0.981486   |
| AveragePolicyStd        | 0.704377   |
| AverageReturn           | 808        |
| Entropy                 | 6.40115    |
| EnvExecTime             | 3.42       |
| ExplainedVariance       | 0.49       |
| Iteration               | 590        |
| ItrTime                 | 12         |
| LossAfter               | 1.37295    |
| LossBefore              | 1.42772    |
| MaxReturn               | 2.05e+03   |
| MeanKL                  | 0.00987284 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 67.5       |
| NumTrajs                | 14         |
| Perplexity              | 602.54     |
| PolicyExecTime          | 0.676      |
| ProcessExecTime         | 0.0882     |
| StdReturn               | 567        |
| Time                    | 6.59e+03   |
| dLoss                   | 0.0547619  |
----------------------------------------
itr #591 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 591...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5162, #subsample_inputs: 5162
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.703      |
| AbsLearnSignalNew       | 0.703      |
| AbsLearningOld          | 0.703      |
| AverageDiscountedReturn | 139        |
| AveragePhiLoss          | 0.975333   |
| AveragePolicyStd        | 0.706853   |
| AverageReturn           | 1.1e+03    |
| Entropy                 | 6.42238    |
| EnvExecTime             | 3.01       |
| ExplainedVariance       | 0.531      |
| Iteration               | 591        |
| ItrTime                 | 11.6       |
| LossAfter               | 1.8396     |
| LossBefore              | 1.88874    |
| MaxReturn               | 2.27e+03   |
| MeanKL                  | 0.00995313 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 115        |
| NumTrajs                | 10         |
| Perplexity              | 615.465    |
| PolicyExecTime          | 0.611      |
| ProcessExecTime         | 0.0746     |
| StdReturn               | 688        |
| Time                    | 6.6e+03    |
| dLoss                   | 0.0491382  |
----------------------------------------
itr #592 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 592...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5730, #subsample_inputs: 5730
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.682      |
| AbsLearnSignalNew       | 0.682      |
| AbsLearningOld          | 0.682      |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 0.983376   |
| AveragePolicyStd        | 0.706859   |
| AverageReturn           | 845        |
| Entropy                 | 6.4226     |
| EnvExecTime             | 3.57       |
| ExplainedVariance       | 0.541      |
| Iteration               | 592        |
| ItrTime                 | 11.7       |
| LossAfter               | 0.848914   |
| LossBefore              | 0.891519   |
| MaxReturn               | 1.92e+03   |
| MeanKL                  | 0.00640233 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 71.4       |
| NumTrajs                | 15         |
| Perplexity              | 615.601    |
| PolicyExecTime          | 0.714      |
| ProcessExecTime         | 0.0935     |
| StdReturn               | 606        |
| Time                    | 6.61e+03   |
| dLoss                   | 0.042605   |
----------------------------------------
itr #593 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 593...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5147, #subsample_inputs: 5147
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.725      |
| AbsLearnSignalNew       | 0.725      |
| AbsLearningOld          | 0.725      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 0.967797   |
| AveragePolicyStd        | 0.705871   |
| AverageReturn           | 613        |
| Entropy                 | 6.41413    |
| EnvExecTime             | 3.77       |
| ExplainedVariance       | 0.487      |
| Iteration               | 593        |
| ItrTime                 | 12         |
| LossAfter               | 0.441712   |
| LossBefore              | 0.490889   |
| MaxReturn               | 1.54e+03   |
| MeanKL                  | 0.00642063 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 78.3       |
| NumTrajs                | 16         |
| Perplexity              | 610.411    |
| PolicyExecTime          | 0.751      |
| ProcessExecTime         | 0.0917     |
| StdReturn               | 451        |
| Time                    | 6.62e+03   |
| dLoss                   | 0.0491771  |
----------------------------------------
itr #594 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 594...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5020, #subsample_inputs: 5020
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.683      |
| AbsLearnSignalNew       | 0.683      |
| AbsLearningOld          | 0.683      |
| AverageDiscountedReturn | 137        |
| AveragePhiLoss          | 0.970155   |
| AveragePolicyStd        | 0.705694   |
| AverageReturn           | 869        |
| Entropy                 | 6.41291    |
| EnvExecTime             | 3.27       |
| ExplainedVariance       | 0.324      |
| Iteration               | 594        |
| ItrTime                 | 11.7       |
| LossAfter               | -0.174577  |
| LossBefore              | -0.111273  |
| MaxReturn               | 1.98e+03   |
| MeanKL                  | 0.00992883 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 66.3       |
| NumTrajs                | 13         |
| Perplexity              | 609.666    |
| PolicyExecTime          | 0.647      |
| ProcessExecTime         | 0.0809     |
| StdReturn               | 477        |
| Time                    | 6.64e+03   |
| dLoss                   | 0.0633036  |
----------------------------------------
itr #595 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 595...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5057, #subsample_inputs: 5057
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.705      |
| AbsLearnSignalNew       | 0.705      |
| AbsLearningOld          | 0.705      |
| AverageDiscountedReturn | 135        |
| AveragePhiLoss          | 0.975979   |
| AveragePolicyStd        | 0.705418   |
| AverageReturn           | 732        |
| Entropy                 | 6.41024    |
| EnvExecTime             | 2.81       |
| ExplainedVariance       | 0.566      |
| Iteration               | 595        |
| ItrTime                 | 9.63       |
| LossAfter               | 0.0704474  |
| LossBefore              | 0.125988   |
| MaxReturn               | 1.56e+03   |
| MeanKL                  | 0.00986816 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 77         |
| NumTrajs                | 15         |
| Perplexity              | 608.038    |
| PolicyExecTime          | 0.557      |
| ProcessExecTime         | 0.0782     |
| StdReturn               | 389        |
| Time                    | 6.65e+03   |
| dLoss                   | 0.0555411  |
----------------------------------------
itr #596 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 596...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5065, #subsample_inputs: 5065
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.656      |
| AbsLearnSignalNew       | 0.656      |
| AbsLearningOld          | 0.656      |
| AverageDiscountedReturn | 129        |
| AveragePhiLoss          | 0.981488   |
| AveragePolicyStd        | 0.70698    |
| AverageReturn           | 879        |
| Entropy                 | 6.42376    |
| EnvExecTime             | 3.05       |
| ExplainedVariance       | 0.481      |
| Iteration               | 596        |
| ItrTime                 | 11.3       |
| LossAfter               | 0.108766   |
| LossBefore              | 0.157704   |
| MaxReturn               | 2.07e+03   |
| MeanKL                  | 0.00989855 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 77.5       |
| NumTrajs                | 12         |
| Perplexity              | 616.318    |
| PolicyExecTime          | 0.604      |
| ProcessExecTime         | 0.0776     |
| StdReturn               | 642        |
| Time                    | 6.66e+03   |
| dLoss                   | 0.0489382  |
----------------------------------------
itr #597 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 597...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5181, #subsample_inputs: 5181
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.69       |
| AbsLearnSignalNew       | 0.69       |
| AbsLearningOld          | 0.69       |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 0.970732   |
| AveragePolicyStd        | 0.704748   |
| AverageReturn           | 669        |
| Entropy                 | 6.40528    |
| EnvExecTime             | 2.99       |
| ExplainedVariance       | 0.462      |
| Iteration               | 597        |
| ItrTime                 | 11         |
| LossAfter               | 0.135039   |
| LossBefore              | 0.192126   |
| MaxReturn               | 1.84e+03   |
| MeanKL                  | 0.00988687 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 47.3       |
| NumTrajs                | 16         |
| Perplexity              | 605.032    |
| PolicyExecTime          | 0.571      |
| ProcessExecTime         | 0.0769     |
| StdReturn               | 434        |
| Time                    | 6.67e+03   |
| dLoss                   | 0.0570876  |
----------------------------------------
itr #598 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 598...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5021, #subsample_inputs: 5021
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.644      |
| AbsLearnSignalNew       | 0.644      |
| AbsLearningOld          | 0.644      |
| AverageDiscountedReturn | 127        |
| AveragePhiLoss          | 0.971464   |
| AveragePolicyStd        | 0.706512   |
| AverageReturn           | 728        |
| Entropy                 | 6.42036    |
| EnvExecTime             | 3.26       |
| ExplainedVariance       | 0.399      |
| Iteration               | 598        |
| ItrTime                 | 10.9       |
| LossAfter               | 0.174065   |
| LossBefore              | 0.222189   |
| MaxReturn               | 2.06e+03   |
| MeanKL                  | 0.00644496 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 66.2       |
| NumTrajs                | 14         |
| Perplexity              | 614.224    |
| PolicyExecTime          | 0.645      |
| ProcessExecTime         | 0.0816     |
| StdReturn               | 491        |
| Time                    | 6.68e+03   |
| dLoss                   | 0.0481246  |
----------------------------------------
itr #599 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 599...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5066, #subsample_inputs: 5066
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.691      |
| AbsLearnSignalNew       | 0.691      |
| AbsLearningOld          | 0.691      |
| AverageDiscountedReturn | 127        |
| AveragePhiLoss          | 0.982793   |
| AveragePolicyStd        | 0.703508   |
| AverageReturn           | 507        |
| Entropy                 | 6.39531    |
| EnvExecTime             | 2.83       |
| ExplainedVariance       | 0.442      |
| Iteration               | 599        |
| ItrTime                 | 11.2       |
| LossAfter               | 0.369926   |
| LossBefore              | 0.409171   |
| MaxReturn               | 1.08e+03   |
| MeanKL                  | 0.00640896 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 80.6       |
| NumTrajs                | 17         |
| Perplexity              | 599.031    |
| PolicyExecTime          | 0.537      |
| ProcessExecTime         | 0.0711     |
| StdReturn               | 294        |
| Time                    | 6.69e+03   |
| dLoss                   | 0.0392456  |
----------------------------------------
itr #600 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 600...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5235, #subsample_inputs: 5235
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.414      |
| AbsLearnSignalNew       | 0.414      |
| AbsLearningOld          | 0.414      |
| AverageDiscountedReturn | 140        |
| AveragePhiLoss          | 0.977673   |
| AveragePolicyStd        | 0.703248   |
| AverageReturn           | 1.01e+03   |
| Entropy                 | 6.39368    |
| EnvExecTime             | 3.07       |
| ExplainedVariance       | -18.4      |
| Iteration               | 600        |
| ItrTime                 | 10.2       |
| LossAfter               | -0.335311  |
| LossBefore              | -0.297767  |
| MaxReturn               | 2.31e+03   |
| MeanKL                  | 0.00640695 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 77.6       |
| NumTrajs                | 11         |
| Perplexity              | 598.051    |
| PolicyExecTime          | 0.618      |
| ProcessExecTime         | 0.0815     |
| StdReturn               | 666        |
| Time                    | 6.7e+03    |
| dLoss                   | 0.0375445  |
----------------------------------------
itr #601 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 601...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5182, #subsample_inputs: 5182
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.66       |
| AbsLearnSignalNew       | 0.66       |
| AbsLearningOld          | 0.66       |
| AverageDiscountedReturn | 132        |
| AveragePhiLoss          | 0.988026   |
| AveragePolicyStd        | 0.703914   |
| AverageReturn           | 790        |
| Entropy                 | 6.39938    |
| EnvExecTime             | 3.43       |
| ExplainedVariance       | 0.517      |
| Iteration               | 601        |
| ItrTime                 | 12.1       |
| LossAfter               | -0.15655   |
| LossBefore              | -0.098225  |
| MaxReturn               | 2.1e+03    |
| MeanKL                  | 0.00999224 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 63.4       |
| NumTrajs                | 13         |
| Perplexity              | 601.472    |
| PolicyExecTime          | 0.681      |
| ProcessExecTime         | 0.0872     |
| StdReturn               | 542        |
| Time                    | 6.71e+03   |
| dLoss                   | 0.0583248  |
----------------------------------------
itr #602 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 602...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5022, #subsample_inputs: 5022
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.705      |
| AbsLearnSignalNew       | 0.705      |
| AbsLearningOld          | 0.705      |
| AverageDiscountedReturn | 143        |
| AveragePhiLoss          | 0.978832   |
| AveragePolicyStd        | 0.701252   |
| AverageReturn           | 914        |
| Entropy                 | 6.37736    |
| EnvExecTime             | 2.76       |
| ExplainedVariance       | 0.497      |
| Iteration               | 602        |
| ItrTime                 | 11.1       |
| LossAfter               | -0.30858   |
| LossBefore              | -0.256661  |
| MaxReturn               | 1.68e+03   |
| MeanKL                  | 0.00997401 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 248        |
| NumTrajs                | 12         |
| Perplexity              | 588.37     |
| PolicyExecTime          | 0.523      |
| ProcessExecTime         | 0.0663     |
| StdReturn               | 394        |
| Time                    | 6.73e+03   |
| dLoss                   | 0.0519188  |
----------------------------------------
itr #603 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 603...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5263, #subsample_inputs: 5263
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.677      |
| AbsLearnSignalNew       | 0.677      |
| AbsLearningOld          | 0.677      |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 0.984887   |
| AveragePolicyStd        | 0.698741   |
| AverageReturn           | 707        |
| Entropy                 | 6.356      |
| EnvExecTime             | 3.88       |
| ExplainedVariance       | 0.549      |
| Iteration               | 603        |
| ItrTime                 | 11.4       |
| LossAfter               | 0.319356   |
| LossBefore              | 0.368786   |
| MaxReturn               | 1.45e+03   |
| MeanKL                  | 0.00996268 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 62.9       |
| NumTrajs                | 16         |
| Perplexity              | 575.938    |
| PolicyExecTime          | 0.771      |
| ProcessExecTime         | 0.0925     |
| StdReturn               | 469        |
| Time                    | 6.74e+03   |
| dLoss                   | 0.0494302  |
----------------------------------------
itr #604 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 604...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5046, #subsample_inputs: 5046
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.596      |
| AbsLearnSignalNew       | 0.596      |
| AbsLearningOld          | 0.596      |
| AverageDiscountedReturn | 136        |
| AveragePhiLoss          | 0.979721   |
| AveragePolicyStd        | 0.697074   |
| AverageReturn           | 874        |
| Entropy                 | 6.34096    |
| EnvExecTime             | 3.34       |
| ExplainedVariance       | 0.0616     |
| Iteration               | 604        |
| ItrTime                 | 11.6       |
| LossAfter               | 0.671576   |
| LossBefore              | 0.713296   |
| MaxReturn               | 2.03e+03   |
| MeanKL                  | 0.00642263 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 88.8       |
| NumTrajs                | 13         |
| Perplexity              | 567.341    |
| PolicyExecTime          | 0.679      |
| ProcessExecTime         | 0.0834     |
| StdReturn               | 607        |
| Time                    | 6.75e+03   |
| dLoss                   | 0.0417208  |
----------------------------------------
itr #605 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 605...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5268, #subsample_inputs: 5268
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.716      |
| AbsLearnSignalNew       | 0.716      |
| AbsLearningOld          | 0.716      |
| AverageDiscountedReturn | 134        |
| AveragePhiLoss          | 0.98367    |
| AveragePolicyStd        | 0.697424   |
| AverageReturn           | 783        |
| Entropy                 | 6.34382    |
| EnvExecTime             | 3.25       |
| ExplainedVariance       | 0.282      |
| Iteration               | 605        |
| ItrTime                 | 11.6       |
| LossAfter               | 0.691932   |
| LossBefore              | 0.744656   |
| MaxReturn               | 2.4e+03    |
| MeanKL                  | 0.00990834 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 69.1       |
| NumTrajs                | 14         |
| Perplexity              | 568.965    |
| PolicyExecTime          | 0.614      |
| ProcessExecTime         | 0.077      |
| StdReturn               | 670        |
| Time                    | 6.76e+03   |
| dLoss                   | 0.0527243  |
----------------------------------------
itr #606 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 606...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5058, #subsample_inputs: 5058
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.673     |
| AbsLearnSignalNew       | 0.673     |
| AbsLearningOld          | 0.673     |
| AverageDiscountedReturn | 152       |
| AveragePhiLoss          | 0.976792  |
| AveragePolicyStd        | 0.696917  |
| AverageReturn           | 989       |
| Entropy                 | 6.33917   |
| EnvExecTime             | 3.57      |
| ExplainedVariance       | 0.154     |
| Iteration               | 606       |
| ItrTime                 | 11.4      |
| LossAfter               | -0.299989 |
| LossBefore              | -0.245554 |
| MaxReturn               | 2.07e+03  |
| MeanKL                  | 0.0099479 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 580       |
| NumTrajs                | 12        |
| Perplexity              | 566.326   |
| PolicyExecTime          | 0.729     |
| ProcessExecTime         | 0.088     |
| StdReturn               | 450       |
| Time                    | 6.77e+03  |
| dLoss                   | 0.0544352 |
---------------------------------------
itr #607 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 607...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5104, #subsample_inputs: 5104
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.589     |
| AbsLearnSignalNew       | 0.589     |
| AbsLearningOld          | 0.589     |
| AverageDiscountedReturn | 128       |
| AveragePhiLoss          | 0.975247  |
| AveragePolicyStd        | 0.695895  |
| AverageReturn           | 891       |
| Entropy                 | 6.33043   |
| EnvExecTime             | 3         |
| ExplainedVariance       | 0.424     |
| Iteration               | 607       |
| ItrTime                 | 11.7      |
| LossAfter               | 0.802423  |
| LossBefore              | 0.863859  |
| MaxReturn               | 1.94e+03  |
| MeanKL                  | 0.0099499 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 62.7      |
| NumTrajs                | 12        |
| Perplexity              | 561.397   |
| PolicyExecTime          | 0.649     |
| ProcessExecTime         | 0.0759    |
| StdReturn               | 504       |
| Time                    | 6.78e+03  |
| dLoss                   | 0.0614358 |
---------------------------------------
itr #608 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 608...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5476, #subsample_inputs: 5476
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.67      |
| AbsLearnSignalNew       | 0.67      |
| AbsLearningOld          | 0.67      |
| AverageDiscountedReturn | 125       |
| AveragePhiLoss          | 0.985096  |
| AveragePolicyStd        | 0.694071  |
| AverageReturn           | 631       |
| Entropy                 | 6.31443   |
| EnvExecTime             | 3.04      |
| ExplainedVariance       | 0.448     |
| Iteration               | 608       |
| ItrTime                 | 11.1      |
| LossAfter               | 1.2961    |
| LossBefore              | 1.33482   |
| MaxReturn               | 1.55e+03  |
| MeanKL                  | 0.0064192 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 53.5      |
| NumTrajs                | 17        |
| Perplexity              | 552.486   |
| PolicyExecTime          | 0.601     |
| ProcessExecTime         | 0.0802    |
| StdReturn               | 422       |
| Time                    | 6.79e+03  |
| dLoss                   | 0.0387282 |
---------------------------------------
itr #609 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 609...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5862, #subsample_inputs: 5862
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.663      |
| AbsLearnSignalNew       | 0.663      |
| AbsLearningOld          | 0.663      |
| AverageDiscountedReturn | 130        |
| AveragePhiLoss          | 0.979276   |
| AveragePolicyStd        | 0.694804   |
| AverageReturn           | 667        |
| Entropy                 | 6.32091    |
| EnvExecTime             | 3.72       |
| ExplainedVariance       | 0.0832     |
| Iteration               | 609        |
| ItrTime                 | 12.7       |
| LossAfter               | 0.835476   |
| LossBefore              | 0.873467   |
| MaxReturn               | 2.08e+03   |
| MeanKL                  | 0.00647039 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 56.1       |
| NumTrajs                | 18         |
| Perplexity              | 556.078    |
| PolicyExecTime          | 0.733      |
| ProcessExecTime         | 0.0975     |
| StdReturn               | 480        |
| Time                    | 6.81e+03   |
| dLoss                   | 0.0379916  |
----------------------------------------
itr #610 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 610...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5324, #subsample_inputs: 5324
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.697      |
| AbsLearnSignalNew       | 0.697      |
| AbsLearningOld          | 0.697      |
| AverageDiscountedReturn | 161        |
| AveragePhiLoss          | 0.97428    |
| AveragePolicyStd        | 0.693682   |
| AverageReturn           | 984        |
| Entropy                 | 6.31157    |
| EnvExecTime             | 3.1        |
| ExplainedVariance       | 0.397      |
| Iteration               | 610        |
| ItrTime                 | 11.8       |
| LossAfter               | 0.809132   |
| LossBefore              | 0.862872   |
| MaxReturn               | 2.44e+03   |
| MeanKL                  | 0.00995434 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 547        |
| NumTrajs                | 13         |
| Perplexity              | 550.911    |
| PolicyExecTime          | 0.63       |
| ProcessExecTime         | 0.0807     |
| StdReturn               | 494        |
| Time                    | 6.82e+03   |
| dLoss                   | 0.0537404  |
----------------------------------------
itr #611 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 611...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5281, #subsample_inputs: 5281
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.621     |
| AbsLearnSignalNew       | 0.621     |
| AbsLearningOld          | 0.621     |
| AverageDiscountedReturn | 139       |
| AveragePhiLoss          | 0.978429  |
| AveragePolicyStd        | 0.69264   |
| AverageReturn           | 851       |
| Entropy                 | 6.30273   |
| EnvExecTime             | 3.48      |
| ExplainedVariance       | 0.307     |
| Iteration               | 611       |
| ItrTime                 | 11.2      |
| LossAfter               | 0.703709  |
| LossBefore              | 0.74372   |
| MaxReturn               | 1.95e+03  |
| MeanKL                  | 0.0064142 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 48.2      |
| NumTrajs                | 14        |
| Perplexity              | 546.058   |
| PolicyExecTime          | 0.699     |
| ProcessExecTime         | 0.0863    |
| StdReturn               | 539       |
| Time                    | 6.83e+03  |
| dLoss                   | 0.040011  |
---------------------------------------
itr #612 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 612...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5377, #subsample_inputs: 5377
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.705      |
| AbsLearnSignalNew       | 0.705      |
| AbsLearningOld          | 0.705      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 0.984519   |
| AveragePolicyStd        | 0.693361   |
| AverageReturn           | 811        |
| Entropy                 | 6.30951    |
| EnvExecTime             | 3.19       |
| ExplainedVariance       | 0.512      |
| Iteration               | 612        |
| ItrTime                 | 11.8       |
| LossAfter               | 0.641334   |
| LossBefore              | 0.693139   |
| MaxReturn               | 2.12e+03   |
| MeanKL                  | 0.00995893 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 48.5       |
| NumTrajs                | 14         |
| Perplexity              | 549.775    |
| PolicyExecTime          | 0.659      |
| ProcessExecTime         | 0.0856     |
| StdReturn               | 608        |
| Time                    | 6.84e+03   |
| dLoss                   | 0.0518055  |
----------------------------------------
itr #613 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 613...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5032, #subsample_inputs: 5032
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.656      |
| AbsLearnSignalNew       | 0.656      |
| AbsLearningOld          | 0.656      |
| AverageDiscountedReturn | 139        |
| AveragePhiLoss          | 0.986005   |
| AveragePolicyStd        | 0.694954   |
| AverageReturn           | 867        |
| Entropy                 | 6.32412    |
| EnvExecTime             | 2.82       |
| ExplainedVariance       | 0.494      |
| Iteration               | 613        |
| ItrTime                 | 11         |
| LossAfter               | 1.04865    |
| LossBefore              | 1.09291    |
| MaxReturn               | 2.07e+03   |
| MeanKL                  | 0.00642849 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 73         |
| NumTrajs                | 13         |
| Perplexity              | 557.866    |
| PolicyExecTime          | 0.558      |
| ProcessExecTime         | 0.0734     |
| StdReturn               | 589        |
| Time                    | 6.85e+03   |
| dLoss                   | 0.0442572  |
----------------------------------------
itr #614 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 614...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5161, #subsample_inputs: 5161
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.708      |
| AbsLearnSignalNew       | 0.708      |
| AbsLearningOld          | 0.708      |
| AverageDiscountedReturn | 141        |
| AveragePhiLoss          | 0.980395   |
| AveragePolicyStd        | 0.694441   |
| AverageReturn           | 803        |
| Entropy                 | 6.31846    |
| EnvExecTime             | 2.95       |
| ExplainedVariance       | 0.353      |
| Iteration               | 614        |
| ItrTime                 | 10.2       |
| LossAfter               | 0.151664   |
| LossBefore              | 0.195164   |
| MaxReturn               | 2.68e+03   |
| MeanKL                  | 0.00643164 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 56.7       |
| NumTrajs                | 15         |
| Perplexity              | 554.721    |
| PolicyExecTime          | 0.583      |
| ProcessExecTime         | 0.0787     |
| StdReturn               | 584        |
| Time                    | 6.86e+03   |
| dLoss                   | 0.0435005  |
----------------------------------------
itr #615 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 615...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5421, #subsample_inputs: 5421
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.738      |
| AbsLearnSignalNew       | 0.738      |
| AbsLearningOld          | 0.738      |
| AverageDiscountedReturn | 136        |
| AveragePhiLoss          | 0.979393   |
| AveragePolicyStd        | 0.693073   |
| AverageReturn           | 995        |
| Entropy                 | 6.30762    |
| EnvExecTime             | 3.46       |
| ExplainedVariance       | 0.37       |
| Iteration               | 615        |
| ItrTime                 | 12.7       |
| LossAfter               | -0.0291452 |
| LossBefore              | 0.0235015  |
| MaxReturn               | 2.44e+03   |
| MeanKL                  | 0.00993557 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 334        |
| NumTrajs                | 12         |
| Perplexity              | 548.74     |
| PolicyExecTime          | 0.705      |
| ProcessExecTime         | 0.0891     |
| StdReturn               | 646        |
| Time                    | 6.88e+03   |
| dLoss                   | 0.0526467  |
----------------------------------------
itr #616 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 616...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5052, #subsample_inputs: 5052
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.71       |
| AbsLearnSignalNew       | 0.71       |
| AbsLearningOld          | 0.71       |
| AverageDiscountedReturn | 147        |
| AveragePhiLoss          | 0.982597   |
| AveragePolicyStd        | 0.695392   |
| AverageReturn           | 836        |
| Entropy                 | 6.32682    |
| EnvExecTime             | 2.68       |
| ExplainedVariance       | 0.42       |
| Iteration               | 616        |
| ItrTime                 | 10.9       |
| LossAfter               | 0.379419   |
| LossBefore              | 0.422687   |
| MaxReturn               | 1.35e+03   |
| MeanKL                  | 0.00644434 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 407        |
| NumTrajs                | 14         |
| Perplexity              | 559.375    |
| PolicyExecTime          | 0.507      |
| ProcessExecTime         | 0.0664     |
| StdReturn               | 283        |
| Time                    | 6.89e+03   |
| dLoss                   | 0.0432678  |
----------------------------------------
itr #617 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 617...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5108, #subsample_inputs: 5108
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.64       |
| AbsLearnSignalNew       | 0.64       |
| AbsLearningOld          | 0.64       |
| AverageDiscountedReturn | 147        |
| AveragePhiLoss          | 0.973499   |
| AveragePolicyStd        | 0.695786   |
| AverageReturn           | 966        |
| Entropy                 | 6.33013    |
| EnvExecTime             | 3.41       |
| ExplainedVariance       | -0.344     |
| Iteration               | 617        |
| ItrTime                 | 10.9       |
| LossAfter               | 0.296434   |
| LossBefore              | 0.364297   |
| MaxReturn               | 1.94e+03   |
| MeanKL                  | 0.00998819 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 330        |
| NumTrajs                | 12         |
| Perplexity              | 561.228    |
| PolicyExecTime          | 0.705      |
| ProcessExecTime         | 0.0878     |
| StdReturn               | 476        |
| Time                    | 6.9e+03    |
| dLoss                   | 0.0678623  |
----------------------------------------
itr #618 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 618...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5419, #subsample_inputs: 5419
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.612      |
| AbsLearnSignalNew       | 0.612      |
| AbsLearningOld          | 0.612      |
| AverageDiscountedReturn | 112        |
| AveragePhiLoss          | 0.987123   |
| AveragePolicyStd        | 0.694429   |
| AverageReturn           | 667        |
| Entropy                 | 6.31801    |
| EnvExecTime             | 3.53       |
| ExplainedVariance       | 0.404      |
| Iteration               | 618        |
| ItrTime                 | 12.7       |
| LossAfter               | 0.369986   |
| LossBefore              | 0.409212   |
| MaxReturn               | 2.22e+03   |
| MeanKL                  | 0.00642265 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 43.7       |
| NumTrajs                | 14         |
| Perplexity              | 554.469    |
| PolicyExecTime          | 0.714      |
| ProcessExecTime         | 0.0882     |
| StdReturn               | 661        |
| Time                    | 6.91e+03   |
| dLoss                   | 0.0392262  |
----------------------------------------
itr #619 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 619...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5105, #subsample_inputs: 5105
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.703      |
| AbsLearnSignalNew       | 0.703      |
| AbsLearningOld          | 0.703      |
| AverageDiscountedReturn | 139        |
| AveragePhiLoss          | 0.968095   |
| AveragePolicyStd        | 0.694589   |
| AverageReturn           | 930        |
| Entropy                 | 6.32008    |
| EnvExecTime             | 2.9        |
| ExplainedVariance       | 0.334      |
| Iteration               | 619        |
| ItrTime                 | 10.4       |
| LossAfter               | 0.891286   |
| LossBefore              | 0.947559   |
| MaxReturn               | 2.04e+03   |
| MeanKL                  | 0.00993163 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 104        |
| NumTrajs                | 12         |
| Perplexity              | 555.617    |
| PolicyExecTime          | 0.563      |
| ProcessExecTime         | 0.0742     |
| StdReturn               | 571        |
| Time                    | 6.92e+03   |
| dLoss                   | 0.0562738  |
----------------------------------------
itr #620 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 620...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5180, #subsample_inputs: 5180
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.604      |
| AbsLearnSignalNew       | 0.604      |
| AbsLearningOld          | 0.604      |
| AverageDiscountedReturn | 141        |
| AveragePhiLoss          | 0.9833     |
| AveragePolicyStd        | 0.695015   |
| AverageReturn           | 920        |
| Entropy                 | 6.3236     |
| EnvExecTime             | 3.16       |
| ExplainedVariance       | 0.432      |
| Iteration               | 620        |
| ItrTime                 | 11.2       |
| LossAfter               | 0.595546   |
| LossBefore              | 0.650841   |
| MaxReturn               | 1.86e+03   |
| MeanKL                  | 0.00998179 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 273        |
| NumTrajs                | 12         |
| Perplexity              | 557.577    |
| PolicyExecTime          | 0.634      |
| ProcessExecTime         | 0.0808     |
| StdReturn               | 499        |
| Time                    | 6.93e+03   |
| dLoss                   | 0.0552949  |
----------------------------------------
itr #621 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 621...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5183, #subsample_inputs: 5183
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.681      |
| AbsLearnSignalNew       | 0.681      |
| AbsLearningOld          | 0.681      |
| AverageDiscountedReturn | 134        |
| AveragePhiLoss          | 0.98048    |
| AveragePolicyStd        | 0.694745   |
| AverageReturn           | 838        |
| Entropy                 | 6.32194    |
| EnvExecTime             | 2.88       |
| ExplainedVariance       | 0.471      |
| Iteration               | 621        |
| ItrTime                 | 11.6       |
| LossAfter               | 0.572244   |
| LossBefore              | 0.624721   |
| MaxReturn               | 2.23e+03   |
| MeanKL                  | 0.00984808 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 257        |
| NumTrajs                | 13         |
| Perplexity              | 556.653    |
| PolicyExecTime          | 0.588      |
| ProcessExecTime         | 0.0745     |
| StdReturn               | 628        |
| Time                    | 6.95e+03   |
| dLoss                   | 0.0524763  |
----------------------------------------
itr #622 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 622...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5141, #subsample_inputs: 5141
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.655      |
| AbsLearnSignalNew       | 0.655      |
| AbsLearningOld          | 0.655      |
| AverageDiscountedReturn | 147        |
| AveragePhiLoss          | 0.971131   |
| AveragePolicyStd        | 0.696906   |
| AverageReturn           | 892        |
| Entropy                 | 6.34126    |
| EnvExecTime             | 3.47       |
| ExplainedVariance       | 0.359      |
| Iteration               | 622        |
| ItrTime                 | 10.6       |
| LossAfter               | -0.155643  |
| LossBefore              | -0.104978  |
| MaxReturn               | 1.49e+03   |
| MeanKL                  | 0.00642718 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 282        |
| NumTrajs                | 13         |
| Perplexity              | 567.508    |
| PolicyExecTime          | 0.717      |
| ProcessExecTime         | 0.0892     |
| StdReturn               | 416        |
| Time                    | 6.96e+03   |
| dLoss                   | 0.0506651  |
----------------------------------------
itr #623 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 623...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5043, #subsample_inputs: 5043
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.524      |
| AbsLearnSignalNew       | 0.524      |
| AbsLearningOld          | 0.524      |
| AverageDiscountedReturn | 157        |
| AveragePhiLoss          | 0.979443   |
| AveragePolicyStd        | 0.695817   |
| AverageReturn           | 1.2e+03    |
| Entropy                 | 6.3317     |
| EnvExecTime             | 3.13       |
| ExplainedVariance       | -2.09      |
| Iteration               | 623        |
| ItrTime                 | 10.1       |
| LossAfter               | -0.0657347 |
| LossBefore              | -0.0169664 |
| MaxReturn               | 2.25e+03   |
| MeanKL                  | 0.0064605  |
| MeanKLBefore            | 0.0        |
| MinReturn               | 578        |
| NumTrajs                | 10         |
| Perplexity              | 562.109    |
| PolicyExecTime          | 0.647      |
| ProcessExecTime         | 0.0833     |
| StdReturn               | 456        |
| Time                    | 6.97e+03   |
| dLoss                   | 0.0487683  |
----------------------------------------
itr #624 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 624...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5107, #subsample_inputs: 5107
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.656      |
| AbsLearnSignalNew       | 0.656      |
| AbsLearningOld          | 0.656      |
| AverageDiscountedReturn | 143        |
| AveragePhiLoss          | 0.969199   |
| AveragePolicyStd        | 0.695597   |
| AverageReturn           | 813        |
| Entropy                 | 6.32954    |
| EnvExecTime             | 2.93       |
| ExplainedVariance       | 0.45       |
| Iteration               | 624        |
| ItrTime                 | 9.12       |
| LossAfter               | 0.341368   |
| LossBefore              | 0.39529    |
| MaxReturn               | 1.59e+03   |
| MeanKL                  | 0.00988854 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 170        |
| NumTrajs                | 14         |
| Perplexity              | 560.897    |
| PolicyExecTime          | 0.533      |
| ProcessExecTime         | 0.0699     |
| StdReturn               | 420        |
| Time                    | 6.98e+03   |
| dLoss                   | 0.0539227  |
----------------------------------------
itr #625 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 625...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5377, #subsample_inputs: 5377
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.727      |
| AbsLearnSignalNew       | 0.727      |
| AbsLearningOld          | 0.727      |
| AverageDiscountedReturn | 137        |
| AveragePhiLoss          | 0.985906   |
| AveragePolicyStd        | 0.694486   |
| AverageReturn           | 954        |
| Entropy                 | 6.31932    |
| EnvExecTime             | 2.85       |
| ExplainedVariance       | 0.386      |
| Iteration               | 625        |
| ItrTime                 | 9.28       |
| LossAfter               | 0.199198   |
| LossBefore              | 0.238949   |
| MaxReturn               | 2.01e+03   |
| MeanKL                  | 0.00640348 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 51.6       |
| NumTrajs                | 13         |
| Perplexity              | 555.194    |
| PolicyExecTime          | 0.532      |
| ProcessExecTime         | 0.067      |
| StdReturn               | 559        |
| Time                    | 6.98e+03   |
| dLoss                   | 0.0397517  |
----------------------------------------
itr #626 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 626...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5034, #subsample_inputs: 5034
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.696      |
| AbsLearnSignalNew       | 0.696      |
| AbsLearningOld          | 0.696      |
| AverageDiscountedReturn | 134        |
| AveragePhiLoss          | 0.974786   |
| AveragePolicyStd        | 0.694173   |
| AverageReturn           | 816        |
| Entropy                 | 6.31674    |
| EnvExecTime             | 2.73       |
| ExplainedVariance       | 0.217      |
| Iteration               | 626        |
| ItrTime                 | 8.79       |
| LossAfter               | 0.0703078  |
| LossBefore              | 0.113656   |
| MaxReturn               | 1.74e+03   |
| MeanKL                  | 0.00647951 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 51.4       |
| NumTrajs                | 13         |
| Perplexity              | 553.766    |
| PolicyExecTime          | 0.498      |
| ProcessExecTime         | 0.0634     |
| StdReturn               | 488        |
| Time                    | 6.99e+03   |
| dLoss                   | 0.0433486  |
----------------------------------------
itr #627 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 627...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5017, #subsample_inputs: 5017
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
-----------------------------------------
| AbsLearnSignal          | 0.637       |
| AbsLearnSignalNew       | 0.637       |
| AbsLearningOld          | 0.637       |
| AverageDiscountedReturn | 140         |
| AveragePhiLoss          | 0.98363     |
| AveragePolicyStd        | 0.693581    |
| AverageReturn           | 743         |
| Entropy                 | 6.31191     |
| EnvExecTime             | 2.68        |
| ExplainedVariance       | 0.518       |
| Iteration               | 627         |
| ItrTime                 | 8.86        |
| LossAfter               | -0.00611485 |
| LossBefore              | 0.0321384   |
| MaxReturn               | 1.42e+03    |
| MeanKL                  | 0.00643348  |
| MeanKLBefore            | 0.0         |
| MinReturn               | 83.5        |
| NumTrajs                | 14          |
| Perplexity              | 551.097     |
| PolicyExecTime          | 0.483       |
| ProcessExecTime         | 0.0653      |
| StdReturn               | 381         |
| Time                    | 7e+03       |
| dLoss                   | 0.0382532   |
-----------------------------------------
itr #628 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 628...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5486, #subsample_inputs: 5486
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.594      |
| AbsLearnSignalNew       | 0.594      |
| AbsLearningOld          | 0.594      |
| AverageDiscountedReturn | 152        |
| AveragePhiLoss          | 0.974103   |
| AveragePolicyStd        | 0.689833   |
| AverageReturn           | 1e+03      |
| Entropy                 | 6.27897    |
| EnvExecTime             | 2.91       |
| ExplainedVariance       | -0.226     |
| Iteration               | 628        |
| ItrTime                 | 9.73       |
| LossAfter               | -0.231438  |
| LossBefore              | -0.170884  |
| MaxReturn               | 2.18e+03   |
| MeanKL                  | 0.00992056 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 270        |
| NumTrajs                | 13         |
| Perplexity              | 533.241    |
| PolicyExecTime          | 0.566      |
| ProcessExecTime         | 0.0703     |
| StdReturn               | 507        |
| Time                    | 7.01e+03   |
| dLoss                   | 0.0605542  |
----------------------------------------
itr #629 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 629...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5143, #subsample_inputs: 5143
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.674      |
| AbsLearnSignalNew       | 0.674      |
| AbsLearningOld          | 0.674      |
| AverageDiscountedReturn | 138        |
| AveragePhiLoss          | 0.982291   |
| AveragePolicyStd        | 0.689826   |
| AverageReturn           | 841        |
| Entropy                 | 6.27796    |
| EnvExecTime             | 3.36       |
| ExplainedVariance       | 0.544      |
| Iteration               | 629        |
| ItrTime                 | 11.2       |
| LossAfter               | 0.315205   |
| LossBefore              | 0.355033   |
| MaxReturn               | 1.64e+03   |
| MeanKL                  | 0.00643788 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 68.3       |
| NumTrajs                | 13         |
| Perplexity              | 532.7      |
| PolicyExecTime          | 0.599      |
| ProcessExecTime         | 0.0755     |
| StdReturn               | 457        |
| Time                    | 7.02e+03   |
| dLoss                   | 0.0398285  |
----------------------------------------
itr #630 | 
Mem: 757.484375
Obtaining samples...
Obtaining samples for iteration 630...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 400 iterations
