output_formats ['stdout', 'log', 'json', 'tensorboard']
Logging to exp_ec2/cfpo-Walker2d-v1-1-batch_size=5000-learning_rate=0.001-max_length=1000-pf_phi_lam_option=ones-pf_iter=800-baseline=linear-pf_lr=0.0001-pf_cls=Qprop-seed=1-use_gradient_vr=True-vs_form=None-pf_hidden_sizes=100x100
Setting seed to 1
Setting seed to 2
Setting seed to 3
Setting seed to 4
observation space: Box(17,)
action space: Box(6,)
use_gradient_vr is True
pf_learning_rate is 0.0001
observation space: Box(17,)
action space: Box(6,)
observation space: Box(17,)
action space: Box(6,)
observation space: Box(17,)
action space: Box(6,)
observation space: Box(17,)
action space: Box(6,)
observation space: Box(17,)
action space: Box(6,)
qf is None
using gradient as variance reduction
parameter of phi Phinet/obs_h0/W:0, shape=(17, 100)
parameter of phi Phinet/obs_h0/b:0, shape=(100,)
parameter of phi Phinet/act_h0/W:0, shape=(6, 100)
parameter of phi Phinet/act_h0/b:0, shape=(100,)
parameter of phi Phinet/h1/W:0, shape=(100, 100)
parameter of phi Phinet/h1/b:0, shape=(100,)
parameter of phi Phinet/output/W:0, shape=(100, 1)
parameter of phi Phinet/output/b:0, shape=(1,)
No checkpoint exp_ec2/cfpo-Walker2d-v1-1-batch_size=5000-learning_rate=0.001-max_length=1000-pf_phi_lam_option=ones-pf_iter=800-baseline=linear-pf_lr=0.0001-pf_cls=Qprop-seed=1-use_gradient_vr=True-vs_form=None-pf_hidden_sizes=100x100/params.chk
itr #0 | 
Mem: 271.546875
Obtaining samples...
Obtaining samples for iteration 0...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5016, #subsample_inputs: 5016
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.766      |
| AbsLearnSignalNew       | 0.766      |
| AbsLearningOld          | 0.765      |
| AverageDiscountedReturn | -2.07      |
| AveragePhiLoss          | 8.01581    |
| AveragePolicyStd        | 1.0        |
| AverageReturn           | -2.56      |
| Entropy                 | 8.51363    |
| EnvExecTime             | 2.63       |
| ExplainedVariance       | 8.46e-10   |
| Iteration               | 0          |
| ItrTime                 | 17.5       |
| LossAfter               | -1.56217   |
| LossBefore              | -1.49165   |
| MaxReturn               | 15.5       |
| MeanKL                  | 0.00647375 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -12.5      |
| NumTrajs                | 330        |
| Perplexity              | 4982.22    |
| PolicyExecTime          | 0.574      |
| ProcessExecTime         | 0.0967     |
| StdReturn               | 3.76       |
| Time                    | 17.5       |
| dLoss                   | 0.0705146  |
----------------------------------------
itr #1 | 
Mem: 627.632812
Obtaining samples...
Obtaining samples for iteration 1...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5011, #subsample_inputs: 5011
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.727      |
| AbsLearnSignalNew       | 0.727      |
| AbsLearningOld          | 0.725      |
| AverageDiscountedReturn | -0.959     |
| AveragePhiLoss          | 7.62441    |
| AveragePolicyStd        | 0.999146   |
| AverageReturn           | -1.44      |
| Entropy                 | 8.50849    |
| EnvExecTime             | 2.4        |
| ExplainedVariance       | 0.321      |
| Iteration               | 1          |
| ItrTime                 | 17.8       |
| LossAfter               | -0.0484565 |
| LossBefore              | 0.0183338  |
| MaxReturn               | 13.5       |
| MeanKL                  | 0.00640602 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -13.4      |
| NumTrajs                | 303        |
| Perplexity              | 4956.68    |
| PolicyExecTime          | 0.518      |
| ProcessExecTime         | 0.0858     |
| StdReturn               | 4.08       |
| Time                    | 35.4       |
| dLoss                   | 0.0667904  |
----------------------------------------
itr #2 | 
Mem: 645.281250
Obtaining samples...
Obtaining samples for iteration 2...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5016, #subsample_inputs: 5016
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.706      |
| AbsLearnSignalNew       | 0.706      |
| AbsLearningOld          | 0.708      |
| AverageDiscountedReturn | -0.501     |
| AveragePhiLoss          | 7.36932    |
| AveragePolicyStd        | 0.998376   |
| AverageReturn           | -0.949     |
| Entropy                 | 8.5038     |
| EnvExecTime             | 2.3        |
| ExplainedVariance       | 0.258      |
| Iteration               | 2          |
| ItrTime                 | 17.3       |
| LossAfter               | 0.805905   |
| LossBefore              | 0.866779   |
| MaxReturn               | 32         |
| MeanKL                  | 0.00655376 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -13.3      |
| NumTrajs                | 291        |
| Perplexity              | 4933.48    |
| PolicyExecTime          | 0.48       |
| ProcessExecTime         | 0.0798     |
| StdReturn               | 4.76       |
| Time                    | 52.8       |
| dLoss                   | 0.0608743  |
----------------------------------------
itr #3 | 
Mem: 657.871094
Obtaining samples...
Obtaining samples for iteration 3...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5018, #subsample_inputs: 5018
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.705      |
| AbsLearnSignalNew       | 0.705      |
| AbsLearningOld          | 0.707      |
| AverageDiscountedReturn | 0.232      |
| AveragePhiLoss          | 7.11469    |
| AveragePolicyStd        | 0.997236   |
| AverageReturn           | -0.113     |
| Entropy                 | 8.49685    |
| EnvExecTime             | 2.51       |
| ExplainedVariance       | 0.251      |
| Iteration               | 3          |
| ItrTime                 | 16.9       |
| LossAfter               | 0.686659   |
| LossBefore              | 0.750949   |
| MaxReturn               | 22.5       |
| MeanKL                  | 0.00654266 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -15.2      |
| NumTrajs                | 283        |
| Perplexity              | 4899.33    |
| PolicyExecTime          | 0.56       |
| ProcessExecTime         | 0.0936     |
| StdReturn               | 5.14       |
| Time                    | 69.9       |
| dLoss                   | 0.0642898  |
----------------------------------------
itr #4 | 
Mem: 664.035156
Obtaining samples...
Obtaining samples for iteration 4...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5007, #subsample_inputs: 5007
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.713      |
| AbsLearnSignalNew       | 0.713      |
| AbsLearningOld          | 0.714      |
| AverageDiscountedReturn | 1.51       |
| AveragePhiLoss          | 7.39561    |
| AveragePolicyStd        | 0.995612   |
| AverageReturn           | 1.28       |
| Entropy                 | 8.48693    |
| EnvExecTime             | 2.45       |
| ExplainedVariance       | 0.226      |
| Iteration               | 4          |
| ItrTime                 | 17.8       |
| LossAfter               | -0.287346  |
| LossBefore              | -0.224452  |
| MaxReturn               | 38.5       |
| MeanKL                  | 0.00642247 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -9.35      |
| NumTrajs                | 251        |
| Perplexity              | 4850.96    |
| PolicyExecTime          | 0.563      |
| ProcessExecTime         | 0.0909     |
| StdReturn               | 6.71       |
| Time                    | 87.8       |
| dLoss                   | 0.0628946  |
----------------------------------------
itr #5 | 
Mem: 670.996094
Obtaining samples...
Obtaining samples for iteration 5...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5002, #subsample_inputs: 5002
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.705      |
| AbsLearnSignalNew       | 0.705      |
| AbsLearningOld          | 0.705      |
| AverageDiscountedReturn | 2.96       |
| AveragePhiLoss          | 7.48831    |
| AveragePolicyStd        | 0.9944     |
| AverageReturn           | 2.95       |
| Entropy                 | 8.47956    |
| EnvExecTime             | 2.13       |
| ExplainedVariance       | 0.257      |
| Iteration               | 5          |
| ItrTime                 | 17.1       |
| LossAfter               | -0.202424  |
| LossBefore              | -0.140287  |
| MaxReturn               | 41.6       |
| MeanKL                  | 0.00645216 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -10.4      |
| NumTrajs                | 239        |
| Perplexity              | 4815.32    |
| PolicyExecTime          | 0.44       |
| ProcessExecTime         | 0.0722     |
| StdReturn               | 7.59       |
| Time                    | 105        |
| dLoss                   | 0.0621371  |
----------------------------------------
itr #6 | 
Mem: 671.253906
Obtaining samples...
Obtaining samples for iteration 6...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5020, #subsample_inputs: 5020
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.711      |
| AbsLearnSignalNew       | 0.711      |
| AbsLearningOld          | 0.711      |
| AverageDiscountedReturn | 4.8        |
| AveragePhiLoss          | 7.73265    |
| AveragePolicyStd        | 0.989994   |
| AverageReturn           | 4.96       |
| Entropy                 | 8.45286    |
| EnvExecTime             | 2.42       |
| ExplainedVariance       | 0.264      |
| Iteration               | 6          |
| ItrTime                 | 16.9       |
| LossAfter               | 0.0241943  |
| LossBefore              | 0.0964652  |
| MaxReturn               | 73.1       |
| MeanKL                  | 0.00996952 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -19.2      |
| NumTrajs                | 194        |
| Perplexity              | 4688.48    |
| PolicyExecTime          | 0.573      |
| ProcessExecTime         | 0.0885     |
| StdReturn               | 10.8       |
| Time                    | 122        |
| dLoss                   | 0.0722709  |
----------------------------------------
itr #7 | 
Mem: 673.054688
Obtaining samples...
Obtaining samples for iteration 7...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5006, #subsample_inputs: 5006
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.674      |
| AbsLearnSignalNew       | 0.674      |
| AbsLearningOld          | 0.675      |
| AverageDiscountedReturn | 7.32       |
| AveragePhiLoss          | 8.17778    |
| AveragePolicyStd        | 0.98923    |
| AverageReturn           | 7.9        |
| Entropy                 | 8.44816    |
| EnvExecTime             | 2.38       |
| ExplainedVariance       | -0.0244    |
| Iteration               | 7          |
| ItrTime                 | 17.5       |
| LossAfter               | 0.30576    |
| LossBefore              | 0.362098   |
| MaxReturn               | 88.1       |
| MeanKL                  | 0.00649847 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -47.9      |
| NumTrajs                | 159        |
| Perplexity              | 4666.49    |
| PolicyExecTime          | 0.543      |
| ProcessExecTime         | 0.0829     |
| StdReturn               | 14.4       |
| Time                    | 140        |
| dLoss                   | 0.0563376  |
----------------------------------------
itr #8 | 
Mem: 675.113281
Obtaining samples...
Obtaining samples for iteration 8...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5063, #subsample_inputs: 5063
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.749      |
| AbsLearnSignalNew       | 0.749      |
| AbsLearningOld          | 0.749      |
| AverageDiscountedReturn | 9.6        |
| AveragePhiLoss          | 7.8608     |
| AveragePolicyStd        | 0.987468   |
| AverageReturn           | 11.7       |
| Entropy                 | 8.4374     |
| EnvExecTime             | 2.12       |
| ExplainedVariance       | 0.22       |
| Iteration               | 8          |
| ItrTime                 | 17.6       |
| LossAfter               | -0.258229  |
| LossBefore              | -0.200508  |
| MaxReturn               | 126        |
| MeanKL                  | 0.00645879 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -7.18      |
| NumTrajs                | 152        |
| Perplexity              | 4616.54    |
| PolicyExecTime          | 0.46       |
| ProcessExecTime         | 0.0699     |
| StdReturn               | 20.7       |
| Time                    | 157        |
| dLoss                   | 0.0577209  |
----------------------------------------
itr #9 | 
Mem: 677.425781
Obtaining samples...
Obtaining samples for iteration 9...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5005, #subsample_inputs: 5005
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.682      |
| AbsLearnSignalNew       | 0.682      |
| AbsLearningOld          | 0.683      |
| AverageDiscountedReturn | 13.6       |
| AveragePhiLoss          | 7.93609    |
| AveragePolicyStd        | 0.98353    |
| AverageReturn           | 17.7       |
| Entropy                 | 8.41319    |
| EnvExecTime             | 2.28       |
| ExplainedVariance       | -0.12      |
| Iteration               | 9          |
| ItrTime                 | 16.6       |
| LossAfter               | -0.753847  |
| LossBefore              | -0.679929  |
| MaxReturn               | 226        |
| MeanKL                  | 0.00996377 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -25.3      |
| NumTrajs                | 119        |
| Perplexity              | 4506.1     |
| PolicyExecTime          | 0.52       |
| ProcessExecTime         | 0.0788     |
| StdReturn               | 32.5       |
| Time                    | 174        |
| dLoss                   | 0.0739182  |
----------------------------------------
itr #10 | 
Mem: 678.199219
Obtaining samples...
Obtaining samples for iteration 10...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5076, #subsample_inputs: 5076
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.646     |
| AbsLearnSignalNew       | 0.646     |
| AbsLearningOld          | 0.646     |
| AverageDiscountedReturn | 18        |
| AveragePhiLoss          | 7.96504   |
| AveragePolicyStd        | 0.980508  |
| AverageReturn           | 23.6      |
| Entropy                 | 8.39462   |
| EnvExecTime             | 2.46      |
| ExplainedVariance       | 0.169     |
| Iteration               | 10        |
| ItrTime                 | 17.9      |
| LossAfter               | 0.260806  |
| LossBefore              | 0.31064   |
| MaxReturn               | 227       |
| MeanKL                  | 0.00644   |
| MeanKLBefore            | 0.0       |
| MinReturn               | -9.5      |
| NumTrajs                | 103       |
| Perplexity              | 4423.19   |
| PolicyExecTime          | 0.587     |
| ProcessExecTime         | 0.0863    |
| StdReturn               | 35.8      |
| Time                    | 192       |
| dLoss                   | 0.0498342 |
---------------------------------------
itr #11 | 
Mem: 679.484375
Obtaining samples...
Obtaining samples for iteration 11...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5049, #subsample_inputs: 5049
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.589      |
| AbsLearnSignalNew       | 0.589      |
| AbsLearningOld          | 0.59       |
| AverageDiscountedReturn | 16.7       |
| AveragePhiLoss          | 8.40797    |
| AveragePolicyStd        | 0.97788    |
| AverageReturn           | 22.1       |
| Entropy                 | 8.37846    |
| EnvExecTime             | 2.15       |
| ExplainedVariance       | -0.56      |
| Iteration               | 11         |
| ItrTime                 | 17.2       |
| LossAfter               | -1.27308   |
| LossBefore              | -1.19714   |
| MaxReturn               | 275        |
| MeanKL                  | 0.00995374 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -11.3      |
| NumTrajs                | 98         |
| Perplexity              | 4352.28    |
| PolicyExecTime          | 0.46       |
| ProcessExecTime         | 0.0664     |
| StdReturn               | 37         |
| Time                    | 209        |
| dLoss                   | 0.0759425  |
----------------------------------------
itr #12 | 
Mem: 684.625000
Obtaining samples...
Obtaining samples for iteration 12...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5003, #subsample_inputs: 5003
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.717      |
| AbsLearnSignalNew       | 0.717      |
| AbsLearningOld          | 0.717      |
| AverageDiscountedReturn | 25.1       |
| AveragePhiLoss          | 8.14371    |
| AveragePolicyStd        | 0.976499   |
| AverageReturn           | 38.1       |
| Entropy                 | 8.36967    |
| EnvExecTime             | 2.41       |
| ExplainedVariance       | 0.165      |
| Iteration               | 12         |
| ItrTime                 | 17.1       |
| LossAfter               | -0.689337  |
| LossBefore              | -0.637553  |
| MaxReturn               | 269        |
| MeanKL                  | 0.00649592 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -2.97      |
| NumTrajs                | 85         |
| Perplexity              | 4314.23    |
| PolicyExecTime          | 0.571      |
| ProcessExecTime         | 0.0826     |
| StdReturn               | 57.1       |
| Time                    | 227        |
| dLoss                   | 0.0517839  |
----------------------------------------
itr #13 | 
Mem: 688.488281
Obtaining samples...
Obtaining samples for iteration 13...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5002, #subsample_inputs: 5002
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.773      |
| AbsLearnSignalNew       | 0.773      |
| AbsLearningOld          | 0.773      |
| AverageDiscountedReturn | 29.6       |
| AveragePhiLoss          | 8.13777    |
| AveragePolicyStd        | 0.974866   |
| AverageReturn           | 46.4       |
| Entropy                 | 8.35958    |
| EnvExecTime             | 2.41       |
| ExplainedVariance       | 0.292      |
| Iteration               | 13         |
| ItrTime                 | 17.5       |
| LossAfter               | 0.556201   |
| LossBefore              | 0.611672   |
| MaxReturn               | 281        |
| MeanKL                  | 0.00652364 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -31.6      |
| NumTrajs                | 64         |
| Perplexity              | 4270.9     |
| PolicyExecTime          | 0.578      |
| ProcessExecTime         | 0.0797     |
| StdReturn               | 63.5       |
| Time                    | 244        |
| dLoss                   | 0.0554703  |
----------------------------------------
itr #14 | 
Mem: 690.808594
Obtaining samples...
Obtaining samples for iteration 14...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5059, #subsample_inputs: 5059
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.793      |
| AbsLearnSignalNew       | 0.793      |
| AbsLearningOld          | 0.793      |
| AverageDiscountedReturn | 28.1       |
| AveragePhiLoss          | 8.48053    |
| AveragePolicyStd        | 0.971136   |
| AverageReturn           | 47.2       |
| Entropy                 | 8.33642    |
| EnvExecTime             | 2.06       |
| ExplainedVariance       | 0.28       |
| Iteration               | 14         |
| ItrTime                 | 17.3       |
| LossAfter               | 1.90793    |
| LossBefore              | 1.95989    |
| MaxReturn               | 337        |
| MeanKL                  | 0.00640564 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -15.1      |
| NumTrajs                | 69         |
| Perplexity              | 4173.12    |
| PolicyExecTime          | 0.451      |
| ProcessExecTime         | 0.0652     |
| StdReturn               | 72.3       |
| Time                    | 262        |
| dLoss                   | 0.0519611  |
----------------------------------------
itr #15 | 
Mem: 690.808594
Obtaining samples...
Obtaining samples for iteration 15...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5150, #subsample_inputs: 5150
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.698      |
| AbsLearnSignalNew       | 0.698      |
| AbsLearningOld          | 0.698      |
| AverageDiscountedReturn | 31         |
| AveragePhiLoss          | 8.67299    |
| AveragePolicyStd        | 0.968576   |
| AverageReturn           | 53.9       |
| Entropy                 | 8.32023    |
| EnvExecTime             | 2.44       |
| ExplainedVariance       | -0.0919    |
| Iteration               | 15         |
| ItrTime                 | 17.2       |
| LossAfter               | 2.64132    |
| LossBefore              | 2.71284    |
| MaxReturn               | 425        |
| MeanKL                  | 0.00959593 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -40.7      |
| NumTrajs                | 57         |
| Perplexity              | 4106.1     |
| PolicyExecTime          | 0.564      |
| ProcessExecTime         | 0.0815     |
| StdReturn               | 81.4       |
| Time                    | 279        |
| dLoss                   | 0.0715156  |
----------------------------------------
itr #16 | 
Mem: 710.097656
Obtaining samples...
Obtaining samples for iteration 16...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5154, #subsample_inputs: 5154
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.797      |
| AbsLearnSignalNew       | 0.797      |
| AbsLearningOld          | 0.797      |
| AverageDiscountedReturn | 40         |
| AveragePhiLoss          | 8.32541    |
| AveragePolicyStd        | 0.96844    |
| AverageReturn           | 66.2       |
| Entropy                 | 8.31923    |
| EnvExecTime             | 2.53       |
| ExplainedVariance       | 0.261      |
| Iteration               | 16         |
| ItrTime                 | 18         |
| LossAfter               | 1.46046    |
| LossBefore              | 1.52172    |
| MaxReturn               | 335        |
| MeanKL                  | 0.00974949 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -18.3      |
| NumTrajs                | 50         |
| Perplexity              | 4102.01    |
| PolicyExecTime          | 0.611      |
| ProcessExecTime         | 0.0842     |
| StdReturn               | 76.2       |
| Time                    | 297        |
| dLoss                   | 0.0612671  |
----------------------------------------
itr #17 | 
Mem: 710.871094
Obtaining samples...
Obtaining samples for iteration 17...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5208, #subsample_inputs: 5208
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.796      |
| AbsLearnSignalNew       | 0.796      |
| AbsLearningOld          | 0.796      |
| AverageDiscountedReturn | 42.2       |
| AveragePhiLoss          | 8.55156    |
| AveragePolicyStd        | 0.968903   |
| AverageReturn           | 80         |
| Entropy                 | 8.32194    |
| EnvExecTime             | 2.5        |
| ExplainedVariance       | 0.347      |
| Iteration               | 17         |
| ItrTime                 | 18.1       |
| LossAfter               | -0.234959  |
| LossBefore              | -0.172889  |
| MaxReturn               | 383        |
| MeanKL                  | 0.00992698 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -24.4      |
| NumTrajs                | 46         |
| Perplexity              | 4113.12    |
| PolicyExecTime          | 0.551      |
| ProcessExecTime         | 0.0721     |
| StdReturn               | 103        |
| Time                    | 315        |
| dLoss                   | 0.0620703  |
----------------------------------------
itr #18 | 
Mem: 711.386719
Obtaining samples...
Obtaining samples for iteration 18...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5082, #subsample_inputs: 5082
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.799      |
| AbsLearnSignalNew       | 0.799      |
| AbsLearningOld          | 0.799      |
| AverageDiscountedReturn | 48.2       |
| AveragePhiLoss          | 8.59681    |
| AveragePolicyStd        | 0.96417    |
| AverageReturn           | 107        |
| Entropy                 | 8.29265    |
| EnvExecTime             | 2.4        |
| ExplainedVariance       | 0.304      |
| Iteration               | 18         |
| ItrTime                 | 17         |
| LossAfter               | -0.168029  |
| LossBefore              | -0.102412  |
| MaxReturn               | 401        |
| MeanKL                  | 0.00989037 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -1.07      |
| NumTrajs                | 38         |
| Perplexity              | 3994.4     |
| PolicyExecTime          | 0.554      |
| ProcessExecTime         | 0.0773     |
| StdReturn               | 112        |
| Time                    | 332        |
| dLoss                   | 0.0656168  |
----------------------------------------
itr #19 | 
Mem: 711.386719
Obtaining samples...
Obtaining samples for iteration 19...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5123, #subsample_inputs: 5123
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.791      |
| AbsLearnSignalNew       | 0.791      |
| AbsLearningOld          | 0.792      |
| AverageDiscountedReturn | 47.7       |
| AveragePhiLoss          | 8.62244    |
| AveragePolicyStd        | 0.963819   |
| AverageReturn           | 89.1       |
| Entropy                 | 8.29043    |
| EnvExecTime             | 2.51       |
| ExplainedVariance       | 0.31       |
| Iteration               | 19         |
| ItrTime                 | 17.9       |
| LossAfter               | -0.45091   |
| LossBefore              | -0.396233  |
| MaxReturn               | 374        |
| MeanKL                  | 0.00644236 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -16.1      |
| NumTrajs                | 39         |
| Perplexity              | 3985.56    |
| PolicyExecTime          | 0.588      |
| ProcessExecTime         | 0.0817     |
| StdReturn               | 99.6       |
| Time                    | 350        |
| dLoss                   | 0.0546777  |
----------------------------------------
itr #20 | 
Mem: 711.902344
Obtaining samples...
Obtaining samples for iteration 20...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5171, #subsample_inputs: 5171
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.796      |
| AbsLearnSignalNew       | 0.796      |
| AbsLearningOld          | 0.795      |
| AverageDiscountedReturn | 50.7       |
| AveragePhiLoss          | 8.56744    |
| AveragePolicyStd        | 0.964984   |
| AverageReturn           | 91.8       |
| Entropy                 | 8.29758    |
| EnvExecTime             | 2.22       |
| ExplainedVariance       | 0.325      |
| Iteration               | 20         |
| ItrTime                 | 17.8       |
| LossAfter               | -0.77343   |
| LossBefore              | -0.721217  |
| MaxReturn               | 379        |
| MeanKL                  | 0.00645167 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -20.2      |
| NumTrajs                | 39         |
| Perplexity              | 4014.13    |
| PolicyExecTime          | 0.485      |
| ProcessExecTime         | 0.0673     |
| StdReturn               | 92.1       |
| Time                    | 368        |
| dLoss                   | 0.0522137  |
----------------------------------------
itr #21 | 
Mem: 718.339844
Obtaining samples...
Obtaining samples for iteration 21...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5061, #subsample_inputs: 5061
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.782      |
| AbsLearnSignalNew       | 0.782      |
| AbsLearningOld          | 0.782      |
| AverageDiscountedReturn | 56.4       |
| AveragePhiLoss          | 8.63986    |
| AveragePolicyStd        | 0.964907   |
| AverageReturn           | 125        |
| Entropy                 | 8.29704    |
| EnvExecTime             | 2.4        |
| ExplainedVariance       | 0.298      |
| Iteration               | 21         |
| ItrTime                 | 16.8       |
| LossAfter               | 0.042324   |
| LossBefore              | 0.0934423  |
| MaxReturn               | 418        |
| MeanKL                  | 0.00641082 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -15.5      |
| NumTrajs                | 30         |
| Perplexity              | 4011.99    |
| PolicyExecTime          | 0.56       |
| ProcessExecTime         | 0.0766     |
| StdReturn               | 118        |
| Time                    | 385        |
| dLoss                   | 0.0511183  |
----------------------------------------
itr #22 | 
Mem: 718.339844
Obtaining samples...
Obtaining samples for iteration 22...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5091, #subsample_inputs: 5091
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.814      |
| AbsLearnSignalNew       | 0.814      |
| AbsLearningOld          | 0.814      |
| AverageDiscountedReturn | 65.3       |
| AveragePhiLoss          | 8.40459    |
| AveragePolicyStd        | 0.963388   |
| AverageReturn           | 137        |
| Entropy                 | 8.28722    |
| EnvExecTime             | 2.53       |
| ExplainedVariance       | 0.369      |
| Iteration               | 22         |
| ItrTime                 | 17.9       |
| LossAfter               | -1.41358   |
| LossBefore              | -1.35168   |
| MaxReturn               | 365        |
| MeanKL                  | 0.00987501 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -5.79      |
| NumTrajs                | 32         |
| Perplexity              | 3972.77    |
| PolicyExecTime          | 0.61       |
| ProcessExecTime         | 0.0827     |
| StdReturn               | 115        |
| Time                    | 403        |
| dLoss                   | 0.0618966  |
----------------------------------------
itr #23 | 
Mem: 720.144531
Obtaining samples...
Obtaining samples for iteration 23...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5056, #subsample_inputs: 5056
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.577     |
| AbsLearnSignalNew       | 0.577     |
| AbsLearningOld          | 0.577     |
| AverageDiscountedReturn | 62.5      |
| AveragePhiLoss          | 7.85439   |
| AveragePolicyStd        | 0.961786  |
| AverageReturn           | 147       |
| Entropy                 | 8.27738   |
| EnvExecTime             | 2.08      |
| ExplainedVariance       | -0.754    |
| Iteration               | 23        |
| ItrTime                 | 17.1      |
| LossAfter               | -0.147321 |
| LossBefore              | -0.100355 |
| MaxReturn               | 750       |
| MeanKL                  | 0.0064049 |
| MeanKLBefore            | 0.0       |
| MinReturn               | -20.1     |
| NumTrajs                | 30        |
| Perplexity              | 3933.89   |
| PolicyExecTime          | 0.444     |
| ProcessExecTime         | 0.0615    |
| StdReturn               | 151       |
| Time                    | 420       |
| dLoss                   | 0.0469662 |
---------------------------------------
itr #24 | 
Mem: 720.144531
Obtaining samples...
Obtaining samples for iteration 24...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5376, #subsample_inputs: 5376
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.773      |
| AbsLearnSignalNew       | 0.773      |
| AbsLearningOld          | 0.773      |
| AverageDiscountedReturn | 66.6       |
| AveragePhiLoss          | 8.71049    |
| AveragePolicyStd        | 0.961928   |
| AverageReturn           | 145        |
| Entropy                 | 8.27793    |
| EnvExecTime             | 2.78       |
| ExplainedVariance       | 0.389      |
| Iteration               | 24         |
| ItrTime                 | 18.1       |
| LossAfter               | 0.167355   |
| LossBefore              | 0.227002   |
| MaxReturn               | 460        |
| MeanKL                  | 0.00998297 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 8.62       |
| NumTrajs                | 30         |
| Perplexity              | 3936.04    |
| PolicyExecTime          | 0.653      |
| ProcessExecTime         | 0.0875     |
| StdReturn               | 120        |
| Time                    | 439        |
| dLoss                   | 0.0596472  |
----------------------------------------
itr #25 | 
Mem: 722.207031
Obtaining samples...
Obtaining samples for iteration 25...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5223, #subsample_inputs: 5223
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.79      |
| AbsLearnSignalNew       | 0.79      |
| AbsLearningOld          | 0.789     |
| AverageDiscountedReturn | 61        |
| AveragePhiLoss          | 8.5798    |
| AveragePolicyStd        | 0.959252  |
| AverageReturn           | 129       |
| Entropy                 | 8.26112   |
| EnvExecTime             | 2.67      |
| ExplainedVariance       | 0.338     |
| Iteration               | 25        |
| ItrTime                 | 18.3      |
| LossAfter               | -0.108286 |
| LossBefore              | -0.048546 |
| MaxReturn               | 337       |
| MeanKL                  | 0.0097873 |
| MeanKLBefore            | 0.0       |
| MinReturn               | -28.7     |
| NumTrajs                | 34        |
| Perplexity              | 3870.44   |
| PolicyExecTime          | 0.632     |
| ProcessExecTime         | 0.0843    |
| StdReturn               | 110       |
| Time                    | 457       |
| dLoss                   | 0.0597402 |
---------------------------------------
itr #26 | 
Mem: 724.011719
Obtaining samples...
Obtaining samples for iteration 26...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5049, #subsample_inputs: 5049
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.778      |
| AbsLearnSignalNew       | 0.778      |
| AbsLearningOld          | 0.778      |
| AverageDiscountedReturn | 57.8       |
| AveragePhiLoss          | 8.40674    |
| AveragePolicyStd        | 0.958617   |
| AverageReturn           | 118        |
| Entropy                 | 8.25693    |
| EnvExecTime             | 2.49       |
| ExplainedVariance       | 0.333      |
| Iteration               | 26         |
| ItrTime                 | 17.9       |
| LossAfter               | 0.00559938 |
| LossBefore              | 0.0524534  |
| MaxReturn               | 437        |
| MeanKL                  | 0.00643274 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -14.5      |
| NumTrajs                | 32         |
| Perplexity              | 3854.24    |
| PolicyExecTime          | 0.53       |
| ProcessExecTime         | 0.0707     |
| StdReturn               | 116        |
| Time                    | 475        |
| dLoss                   | 0.046854   |
----------------------------------------
itr #27 | 
Mem: 724.011719
Obtaining samples...
Obtaining samples for iteration 27...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5027, #subsample_inputs: 5027
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.772      |
| AbsLearnSignalNew       | 0.772      |
| AbsLearningOld          | 0.772      |
| AverageDiscountedReturn | 77.1       |
| AveragePhiLoss          | 8.85689    |
| AveragePolicyStd        | 0.9573     |
| AverageReturn           | 185        |
| Entropy                 | 8.2486     |
| EnvExecTime             | 2.56       |
| ExplainedVariance       | 0.361      |
| Iteration               | 27         |
| ItrTime                 | 17         |
| LossAfter               | -0.523868  |
| LossBefore              | -0.460548  |
| MaxReturn               | 363        |
| MeanKL                  | 0.00995764 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -3.72      |
| NumTrajs                | 27         |
| Perplexity              | 3822.27    |
| PolicyExecTime          | 0.595      |
| ProcessExecTime         | 0.0803     |
| StdReturn               | 126        |
| Time                    | 492        |
| dLoss                   | 0.0633196  |
----------------------------------------
itr #28 | 
Mem: 724.011719
Obtaining samples...
Obtaining samples for iteration 28...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5058, #subsample_inputs: 5058
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.764      |
| AbsLearnSignalNew       | 0.764      |
| AbsLearningOld          | 0.764      |
| AverageDiscountedReturn | 75         |
| AveragePhiLoss          | 8.60397    |
| AveragePolicyStd        | 0.957714   |
| AverageReturn           | 217        |
| Entropy                 | 8.25125    |
| EnvExecTime             | 2.39       |
| ExplainedVariance       | 0.323      |
| Iteration               | 28         |
| ItrTime                 | 17.8       |
| LossAfter               | 0.394883   |
| LossBefore              | 0.457661   |
| MaxReturn               | 585        |
| MeanKL                  | 0.00988364 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 3.22       |
| NumTrajs                | 23         |
| Perplexity              | 3832.42    |
| PolicyExecTime          | 0.584      |
| ProcessExecTime         | 0.0778     |
| StdReturn               | 154        |
| Time                    | 510        |
| dLoss                   | 0.0627782  |
----------------------------------------
itr #29 | 
Mem: 724.011719
Obtaining samples...
Obtaining samples for iteration 29...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5091, #subsample_inputs: 5091
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.787      |
| AbsLearnSignalNew       | 0.787      |
| AbsLearningOld          | 0.787      |
| AverageDiscountedReturn | 88.3       |
| AveragePhiLoss          | 8.75447    |
| AveragePolicyStd        | 0.954096   |
| AverageReturn           | 219        |
| Entropy                 | 8.22848    |
| EnvExecTime             | 2.16       |
| ExplainedVariance       | 0.379      |
| Iteration               | 29         |
| ItrTime                 | 17.2       |
| LossAfter               | 0.580885   |
| LossBefore              | 0.642986   |
| MaxReturn               | 448        |
| MeanKL                  | 0.00999178 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -1.83      |
| NumTrajs                | 28         |
| Perplexity              | 3746.14    |
| PolicyExecTime          | 0.464      |
| ProcessExecTime         | 0.0637     |
| StdReturn               | 119        |
| Time                    | 527        |
| dLoss                   | 0.0621014  |
----------------------------------------
itr #30 | 
Mem: 726.070312
Obtaining samples...
Obtaining samples for iteration 30...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5122, #subsample_inputs: 5122
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.707      |
| AbsLearnSignalNew       | 0.707      |
| AbsLearningOld          | 0.707      |
| AverageDiscountedReturn | 76.6       |
| AveragePhiLoss          | 8.77887    |
| AveragePolicyStd        | 0.953146   |
| AverageReturn           | 207        |
| Entropy                 | 8.22245    |
| EnvExecTime             | 2.87       |
| ExplainedVariance       | 0.117      |
| Iteration               | 30         |
| ItrTime                 | 17.8       |
| LossAfter               | 0.58099    |
| LossBefore              | 0.650468   |
| MaxReturn               | 595        |
| MeanKL                  | 0.00997239 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 13.6       |
| NumTrajs                | 25         |
| Perplexity              | 3723.61    |
| PolicyExecTime          | 0.665      |
| ProcessExecTime         | 0.0864     |
| StdReturn               | 157        |
| Time                    | 545        |
| dLoss                   | 0.0694785  |
----------------------------------------
itr #31 | 
Mem: 726.187500
Obtaining samples...
Obtaining samples for iteration 31...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5161, #subsample_inputs: 5161
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.768      |
| AbsLearnSignalNew       | 0.768      |
| AbsLearningOld          | 0.768      |
| AverageDiscountedReturn | 87.5       |
| AveragePhiLoss          | 8.84771    |
| AveragePolicyStd        | 0.952649   |
| AverageReturn           | 228        |
| Entropy                 | 8.21971    |
| EnvExecTime             | 2.5        |
| ExplainedVariance       | 0.369      |
| Iteration               | 31         |
| ItrTime                 | 17.9       |
| LossAfter               | -0.286245  |
| LossBefore              | -0.224315  |
| MaxReturn               | 471        |
| MeanKL                  | 0.00981358 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 22.8       |
| NumTrajs                | 25         |
| Perplexity              | 3713.41    |
| PolicyExecTime          | 0.58       |
| ProcessExecTime         | 0.0792     |
| StdReturn               | 123        |
| Time                    | 563        |
| dLoss                   | 0.0619305  |
----------------------------------------
itr #32 | 
Mem: 731.082031
Obtaining samples...
Obtaining samples for iteration 32...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5106, #subsample_inputs: 5106
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.746      |
| AbsLearnSignalNew       | 0.746      |
| AbsLearningOld          | 0.746      |
| AverageDiscountedReturn | 88.8       |
| AveragePhiLoss          | 8.92319    |
| AveragePolicyStd        | 0.95101    |
| AverageReturn           | 234        |
| Entropy                 | 8.20947    |
| EnvExecTime             | 2.76       |
| ExplainedVariance       | 0.438      |
| Iteration               | 32         |
| ItrTime                 | 18         |
| LossAfter               | 0.500619   |
| LossBefore              | 0.563926   |
| MaxReturn               | 551        |
| MeanKL                  | 0.00991513 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 5.31       |
| NumTrajs                | 27         |
| Perplexity              | 3675.58    |
| PolicyExecTime          | 0.596      |
| ProcessExecTime         | 0.0762     |
| StdReturn               | 144        |
| Time                    | 581        |
| dLoss                   | 0.0633075  |
----------------------------------------
itr #33 | 
Mem: 731.597656
Obtaining samples...
Obtaining samples for iteration 33...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5129, #subsample_inputs: 5129
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.734      |
| AbsLearnSignalNew       | 0.734      |
| AbsLearningOld          | 0.734      |
| AverageDiscountedReturn | 93         |
| AveragePhiLoss          | 9.05152    |
| AveragePolicyStd        | 0.948397   |
| AverageReturn           | 236        |
| Entropy                 | 8.19281    |
| EnvExecTime             | 2.83       |
| ExplainedVariance       | 0.393      |
| Iteration               | 33         |
| ItrTime                 | 17.5       |
| LossAfter               | 0.547571   |
| LossBefore              | 0.60883    |
| MaxReturn               | 480        |
| MeanKL                  | 0.00976552 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 4.41       |
| NumTrajs                | 27         |
| Perplexity              | 3614.86    |
| PolicyExecTime          | 0.648      |
| ProcessExecTime         | 0.0856     |
| StdReturn               | 122        |
| Time                    | 599        |
| dLoss                   | 0.061259   |
----------------------------------------
itr #34 | 
Mem: 732.625000
Obtaining samples...
Obtaining samples for iteration 34...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5137, #subsample_inputs: 5137
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.726     |
| AbsLearnSignalNew       | 0.726     |
| AbsLearningOld          | 0.726     |
| AverageDiscountedReturn | 99.2      |
| AveragePhiLoss          | 9.53201   |
| AveragePolicyStd        | 0.947767  |
| AverageReturn           | 237       |
| Entropy                 | 8.18884   |
| EnvExecTime             | 2.73      |
| ExplainedVariance       | 0.375     |
| Iteration               | 34        |
| ItrTime                 | 18.5      |
| LossAfter               | 1.60786   |
| LossBefore              | 1.66952   |
| MaxReturn               | 663       |
| MeanKL                  | 0.0099686 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 60        |
| NumTrajs                | 28        |
| Perplexity              | 3600.55   |
| PolicyExecTime          | 0.638     |
| ProcessExecTime         | 0.081     |
| StdReturn               | 112       |
| Time                    | 618       |
| dLoss                   | 0.0616542 |
---------------------------------------
itr #35 | 
Mem: 732.625000
Obtaining samples...
Obtaining samples for iteration 35...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5147, #subsample_inputs: 5147
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.768      |
| AbsLearnSignalNew       | 0.768      |
| AbsLearningOld          | 0.768      |
| AverageDiscountedReturn | 89.7       |
| AveragePhiLoss          | 8.9981     |
| AveragePolicyStd        | 0.946393   |
| AverageReturn           | 254        |
| Entropy                 | 8.18031    |
| EnvExecTime             | 2.49       |
| ExplainedVariance       | 0.378      |
| Iteration               | 35         |
| ItrTime                 | 17.6       |
| LossAfter               | -0.419671  |
| LossBefore              | -0.358171  |
| MaxReturn               | 512        |
| MeanKL                  | 0.00996394 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 31.9       |
| NumTrajs                | 23         |
| Perplexity              | 3569.96    |
| PolicyExecTime          | 0.528      |
| ProcessExecTime         | 0.0689     |
| StdReturn               | 150        |
| Time                    | 635        |
| dLoss                   | 0.0615004  |
----------------------------------------
itr #36 | 
Mem: 732.625000
Obtaining samples...
Obtaining samples for iteration 36...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5011, #subsample_inputs: 5011
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.742      |
| AbsLearnSignalNew       | 0.742      |
| AbsLearningOld          | 0.742      |
| AverageDiscountedReturn | 86.5       |
| AveragePhiLoss          | 9.20242    |
| AveragePolicyStd        | 0.944935   |
| AverageReturn           | 229        |
| Entropy                 | 8.17092    |
| EnvExecTime             | 2.85       |
| ExplainedVariance       | 0.414      |
| Iteration               | 36         |
| ItrTime                 | 17.3       |
| LossAfter               | -0.354255  |
| LossBefore              | -0.295578  |
| MaxReturn               | 715        |
| MeanKL                  | 0.00979568 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -10.3      |
| NumTrajs                | 24         |
| Perplexity              | 3536.6     |
| PolicyExecTime          | 0.638      |
| ProcessExecTime         | 0.0874     |
| StdReturn               | 157        |
| Time                    | 653        |
| dLoss                   | 0.0586773  |
----------------------------------------
itr #37 | 
Mem: 732.625000
Obtaining samples...
Obtaining samples for iteration 37...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5136, #subsample_inputs: 5136
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.775      |
| AbsLearnSignalNew       | 0.775      |
| AbsLearningOld          | 0.775      |
| AverageDiscountedReturn | 95.9       |
| AveragePhiLoss          | 9.02033    |
| AveragePolicyStd        | 0.945414   |
| AverageReturn           | 251        |
| Entropy                 | 8.1741     |
| EnvExecTime             | 2.48       |
| ExplainedVariance       | 0.367      |
| Iteration               | 37         |
| ItrTime                 | 18.1       |
| LossAfter               | -0.334333  |
| LossBefore              | -0.274947  |
| MaxReturn               | 585        |
| MeanKL                  | 0.00984264 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 38.4       |
| NumTrajs                | 22         |
| Perplexity              | 3547.85    |
| PolicyExecTime          | 0.572      |
| ProcessExecTime         | 0.0765     |
| StdReturn               | 121        |
| Time                    | 671        |
| dLoss                   | 0.0593854  |
----------------------------------------
itr #38 | 
Mem: 732.625000
Obtaining samples...
Obtaining samples for iteration 38...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5034, #subsample_inputs: 5034
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.759      |
| AbsLearnSignalNew       | 0.759      |
| AbsLearningOld          | 0.759      |
| AverageDiscountedReturn | 97.9       |
| AveragePhiLoss          | 9.09761    |
| AveragePolicyStd        | 0.945465   |
| AverageReturn           | 265        |
| Entropy                 | 8.17435    |
| EnvExecTime             | 2.45       |
| ExplainedVariance       | 0.38       |
| Iteration               | 38         |
| ItrTime                 | 17.2       |
| LossAfter               | 0.53908    |
| LossBefore              | 0.599509   |
| MaxReturn               | 576        |
| MeanKL                  | 0.00990134 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 7.43       |
| NumTrajs                | 24         |
| Perplexity              | 3548.76    |
| PolicyExecTime          | 0.538      |
| ProcessExecTime         | 0.0707     |
| StdReturn               | 132        |
| Time                    | 688        |
| dLoss                   | 0.060429   |
----------------------------------------
itr #39 | 
Mem: 732.625000
Obtaining samples...
Obtaining samples for iteration 39...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5157, #subsample_inputs: 5157
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.336      |
| AbsLearnSignalNew       | 0.336      |
| AbsLearningOld          | 0.336      |
| AverageDiscountedReturn | 96.8       |
| AveragePhiLoss          | 8.60779    |
| AveragePolicyStd        | 0.945269   |
| AverageReturn           | 298        |
| Entropy                 | 8.17306    |
| EnvExecTime             | 2.92       |
| ExplainedVariance       | -74.1      |
| Iteration               | 39         |
| ItrTime                 | 17.7       |
| LossAfter               | -0.764576  |
| LossBefore              | -0.715914  |
| MaxReturn               | 927        |
| MeanKL                  | 0.00993158 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 19.9       |
| NumTrajs                | 21         |
| Perplexity              | 3544.19    |
| PolicyExecTime          | 0.662      |
| ProcessExecTime         | 0.0877     |
| StdReturn               | 178        |
| Time                    | 706        |
| dLoss                   | 0.0486625  |
----------------------------------------
itr #40 | 
Mem: 732.625000
Obtaining samples...
Obtaining samples for iteration 40...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5106, #subsample_inputs: 5106
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.748      |
| AbsLearnSignalNew       | 0.748      |
| AbsLearningOld          | 0.748      |
| AverageDiscountedReturn | 98.7       |
| AveragePhiLoss          | 9.1337     |
| AveragePolicyStd        | 0.945482   |
| AverageReturn           | 285        |
| Entropy                 | 8.1743     |
| EnvExecTime             | 2.69       |
| ExplainedVariance       | 0.446      |
| Iteration               | 40         |
| ItrTime                 | 18.1       |
| LossAfter               | -0.423127  |
| LossBefore              | -0.359117  |
| MaxReturn               | 695        |
| MeanKL                  | 0.00996432 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 51.8       |
| NumTrajs                | 21         |
| Perplexity              | 3548.57    |
| PolicyExecTime          | 0.631      |
| ProcessExecTime         | 0.0758     |
| StdReturn               | 145        |
| Time                    | 724        |
| dLoss                   | 0.0640099  |
----------------------------------------
itr #41 | 
Mem: 732.625000
Obtaining samples...
Obtaining samples for iteration 41...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5231, #subsample_inputs: 5231
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.75       |
| AbsLearnSignalNew       | 0.75       |
| AbsLearningOld          | 0.75       |
| AverageDiscountedReturn | 90.5       |
| AveragePhiLoss          | 9.16133    |
| AveragePolicyStd        | 0.94818    |
| AverageReturn           | 227        |
| Entropy                 | 8.19131    |
| EnvExecTime             | 2.41       |
| ExplainedVariance       | 0.438      |
| Iteration               | 41         |
| ItrTime                 | 17.6       |
| LossAfter               | 0.0416056  |
| LossBefore              | 0.107109   |
| MaxReturn               | 432        |
| MeanKL                  | 0.00970107 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 4.3        |
| NumTrajs                | 24         |
| Perplexity              | 3609.44    |
| PolicyExecTime          | 0.519      |
| ProcessExecTime         | 0.0687     |
| StdReturn               | 121        |
| Time                    | 742        |
| dLoss                   | 0.0655032  |
----------------------------------------
itr #42 | 
Mem: 732.625000
Obtaining samples...
Obtaining samples for iteration 42...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5232, #subsample_inputs: 5232
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.749     |
| AbsLearnSignalNew       | 0.749     |
| AbsLearningOld          | 0.749     |
| AverageDiscountedReturn | 99.1      |
| AveragePhiLoss          | 9.09058   |
| AveragePolicyStd        | 0.946855  |
| AverageReturn           | 262       |
| Entropy                 | 8.18303   |
| EnvExecTime             | 2.67      |
| ExplainedVariance       | 0.409     |
| Iteration               | 42        |
| ItrTime                 | 17.7      |
| LossAfter               | -0.322566 |
| LossBefore              | -0.258645 |
| MaxReturn               | 718       |
| MeanKL                  | 0.0099847 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 53.2      |
| NumTrajs                | 23        |
| Perplexity              | 3579.7    |
| PolicyExecTime          | 0.617     |
| ProcessExecTime         | 0.085     |
| StdReturn               | 141       |
| Time                    | 760       |
| dLoss                   | 0.0639212 |
---------------------------------------
itr #43 | 
Mem: 732.625000
Obtaining samples...
Obtaining samples for iteration 43...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5112, #subsample_inputs: 5112
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.762      |
| AbsLearnSignalNew       | 0.762      |
| AbsLearningOld          | 0.762      |
| AverageDiscountedReturn | 94.7       |
| AveragePhiLoss          | 9.12746    |
| AveragePolicyStd        | 0.946249   |
| AverageReturn           | 268        |
| Entropy                 | 8.1797     |
| EnvExecTime             | 2.53       |
| ExplainedVariance       | 0.432      |
| Iteration               | 43         |
| ItrTime                 | 17.9       |
| LossAfter               | -0.434322  |
| LossBefore              | -0.376271  |
| MaxReturn               | 578        |
| MeanKL                  | 0.00963178 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -4.77      |
| NumTrajs                | 24         |
| Perplexity              | 3567.8     |
| PolicyExecTime          | 0.561      |
| ProcessExecTime         | 0.0754     |
| StdReturn               | 143        |
| Time                    | 778        |
| dLoss                   | 0.0580506  |
----------------------------------------
itr #44 | 
Mem: 732.625000
Obtaining samples...
Obtaining samples for iteration 44...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5041, #subsample_inputs: 5041
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.79       |
| AbsLearnSignalNew       | 0.79       |
| AbsLearningOld          | 0.79       |
| AverageDiscountedReturn | 91.2       |
| AveragePhiLoss          | 8.91021    |
| AveragePolicyStd        | 0.947969   |
| AverageReturn           | 257        |
| Entropy                 | 8.19125    |
| EnvExecTime             | 2.35       |
| ExplainedVariance       | 0.449      |
| Iteration               | 44         |
| ItrTime                 | 17         |
| LossAfter               | 0.890661   |
| LossBefore              | 0.93911    |
| MaxReturn               | 610        |
| MeanKL                  | 0.00643547 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 27.2       |
| NumTrajs                | 23         |
| Perplexity              | 3609.23    |
| PolicyExecTime          | 0.52       |
| ProcessExecTime         | 0.0681     |
| StdReturn               | 145        |
| Time                    | 795        |
| dLoss                   | 0.0484492  |
----------------------------------------
itr #45 | 
Mem: 732.625000
Obtaining samples...
Obtaining samples for iteration 45...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5000, #subsample_inputs: 5000
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.731      |
| AbsLearnSignalNew       | 0.731      |
| AbsLearningOld          | 0.731      |
| AverageDiscountedReturn | 94.4       |
| AveragePhiLoss          | 9.35643    |
| AveragePolicyStd        | 0.945984   |
| AverageReturn           | 260        |
| Entropy                 | 8.17889    |
| EnvExecTime             | 2.57       |
| ExplainedVariance       | 0.47       |
| Iteration               | 45         |
| ItrTime                 | 17.4       |
| LossAfter               | 0.52336    |
| LossBefore              | 0.584299   |
| MaxReturn               | 516        |
| MeanKL                  | 0.00971706 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -9.78      |
| NumTrajs                | 22         |
| Perplexity              | 3564.91    |
| PolicyExecTime          | 0.585      |
| ProcessExecTime         | 0.0801     |
| StdReturn               | 123        |
| Time                    | 812        |
| dLoss                   | 0.0609387  |
----------------------------------------
itr #46 | 
Mem: 732.625000
Obtaining samples...
Obtaining samples for iteration 46...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5063, #subsample_inputs: 5063
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.76       |
| AbsLearnSignalNew       | 0.76       |
| AbsLearningOld          | 0.76       |
| AverageDiscountedReturn | 91.8       |
| AveragePhiLoss          | 9.27458    |
| AveragePolicyStd        | 0.9457     |
| AverageReturn           | 240        |
| Entropy                 | 8.17705    |
| EnvExecTime             | 2.78       |
| ExplainedVariance       | 0.4        |
| Iteration               | 46         |
| ItrTime                 | 18.4       |
| LossAfter               | 0.959655   |
| LossBefore              | 1.0225     |
| MaxReturn               | 557        |
| MeanKL                  | 0.00992745 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 22.1       |
| NumTrajs                | 25         |
| Perplexity              | 3558.34    |
| PolicyExecTime          | 0.638      |
| ProcessExecTime         | 0.0771     |
| StdReturn               | 142        |
| Time                    | 831        |
| dLoss                   | 0.0628443  |
----------------------------------------
itr #47 | 
Mem: 732.625000
Obtaining samples...
Obtaining samples for iteration 47...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5045, #subsample_inputs: 5045
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.49       |
| AbsLearnSignalNew       | 0.49       |
| AbsLearningOld          | 0.49       |
| AverageDiscountedReturn | 92.6       |
| AveragePhiLoss          | 9.66085    |
| AveragePolicyStd        | 0.943754   |
| AverageReturn           | 276        |
| Entropy                 | 8.16471    |
| EnvExecTime             | 2.37       |
| ExplainedVariance       | -1.32      |
| Iteration               | 47         |
| ItrTime                 | 17.4       |
| LossAfter               | 0.0174115  |
| LossBefore              | 0.091103   |
| MaxReturn               | 750        |
| MeanKL                  | 0.00994757 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 7.38       |
| NumTrajs                | 20         |
| Perplexity              | 3514.69    |
| PolicyExecTime          | 0.521      |
| ProcessExecTime         | 0.0698     |
| StdReturn               | 163        |
| Time                    | 849        |
| dLoss                   | 0.0736915  |
----------------------------------------
itr #48 | 
Mem: 732.625000
Obtaining samples...
Obtaining samples for iteration 48...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5265, #subsample_inputs: 5265
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.769      |
| AbsLearnSignalNew       | 0.769      |
| AbsLearningOld          | 0.769      |
| AverageDiscountedReturn | 93.6       |
| AveragePhiLoss          | 9.12316    |
| AveragePolicyStd        | 0.944295   |
| AverageReturn           | 253        |
| Entropy                 | 8.16797    |
| EnvExecTime             | 3.01       |
| ExplainedVariance       | 0.526      |
| Iteration               | 48         |
| ItrTime                 | 18.3       |
| LossAfter               | -0.0432641 |
| LossBefore              | 0.013634   |
| MaxReturn               | 570        |
| MeanKL                  | 0.00985855 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 20.5       |
| NumTrajs                | 23         |
| Perplexity              | 3526.17    |
| PolicyExecTime          | 0.673      |
| ProcessExecTime         | 0.0888     |
| StdReturn               | 139        |
| Time                    | 867        |
| dLoss                   | 0.0568982  |
----------------------------------------
itr #49 | 
Mem: 732.625000
Obtaining samples...
Obtaining samples for iteration 49...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5082, #subsample_inputs: 5082
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.738      |
| AbsLearnSignalNew       | 0.738      |
| AbsLearningOld          | 0.738      |
| AverageDiscountedReturn | 94.3       |
| AveragePhiLoss          | 9.04042    |
| AveragePolicyStd        | 0.94541    |
| AverageReturn           | 231        |
| Entropy                 | 8.1751     |
| EnvExecTime             | 2.45       |
| ExplainedVariance       | 0.394      |
| Iteration               | 49         |
| ItrTime                 | 17.9       |
| LossAfter               | 1.4846     |
| LossBefore              | 1.54272    |
| MaxReturn               | 547        |
| MeanKL                  | 0.00989387 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 4.5        |
| NumTrajs                | 25         |
| Perplexity              | 3551.39    |
| PolicyExecTime          | 0.543      |
| ProcessExecTime         | 0.0743     |
| StdReturn               | 121        |
| Time                    | 885        |
| dLoss                   | 0.0581241  |
----------------------------------------
itr #50 | 
Mem: 732.625000
Obtaining samples...
Obtaining samples for iteration 50...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5250, #subsample_inputs: 5250
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.767      |
| AbsLearnSignalNew       | 0.767      |
| AbsLearningOld          | 0.766      |
| AverageDiscountedReturn | 96.1       |
| AveragePhiLoss          | 9.07114    |
| AveragePolicyStd        | 0.947415   |
| AverageReturn           | 278        |
| Entropy                 | 8.18758    |
| EnvExecTime             | 2.55       |
| ExplainedVariance       | 0.432      |
| Iteration               | 50         |
| ItrTime                 | 17.6       |
| LossAfter               | -0.0275648 |
| LossBefore              | 0.016734   |
| MaxReturn               | 663        |
| MeanKL                  | 0.0064895  |
| MeanKLBefore            | 0.0        |
| MinReturn               | 48         |
| NumTrajs                | 21         |
| Perplexity              | 3596.0     |
| PolicyExecTime          | 0.544      |
| ProcessExecTime         | 0.0724     |
| StdReturn               | 140        |
| Time                    | 903        |
| dLoss                   | 0.0442988  |
----------------------------------------
itr #51 | 
Mem: 732.625000
Obtaining samples...
Obtaining samples for iteration 51...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5135, #subsample_inputs: 5135
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.771      |
| AbsLearnSignalNew       | 0.771      |
| AbsLearningOld          | 0.771      |
| AverageDiscountedReturn | 93.7       |
| AveragePhiLoss          | 9.26661    |
| AveragePolicyStd        | 0.945749   |
| AverageReturn           | 239        |
| Entropy                 | 8.17691    |
| EnvExecTime             | 2.88       |
| ExplainedVariance       | 0.409      |
| Iteration               | 51         |
| ItrTime                 | 17.8       |
| LossAfter               | 0.515725   |
| LossBefore              | 0.574082   |
| MaxReturn               | 426        |
| MeanKL                  | 0.00983506 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 47.6       |
| NumTrajs                | 24         |
| Perplexity              | 3557.85    |
| PolicyExecTime          | 0.646      |
| ProcessExecTime         | 0.0861     |
| StdReturn               | 116        |
| Time                    | 921        |
| dLoss                   | 0.0583568  |
----------------------------------------
itr #52 | 
Mem: 732.707031
Obtaining samples...
Obtaining samples for iteration 52...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5095, #subsample_inputs: 5095
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.682      |
| AbsLearnSignalNew       | 0.682      |
| AbsLearningOld          | 0.682      |
| AverageDiscountedReturn | 85.6       |
| AveragePhiLoss          | 9.49825    |
| AveragePolicyStd        | 0.944945   |
| AverageReturn           | 242        |
| Entropy                 | 8.17159    |
| EnvExecTime             | 2.63       |
| ExplainedVariance       | 0.145      |
| Iteration               | 52         |
| ItrTime                 | 18.2       |
| LossAfter               | -0.052258  |
| LossBefore              | 0.00376375 |
| MaxReturn               | 847        |
| MeanKL                  | 0.00978815 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -2.77      |
| NumTrajs                | 24         |
| Perplexity              | 3538.97    |
| PolicyExecTime          | 0.607      |
| ProcessExecTime         | 0.0791     |
| StdReturn               | 177        |
| Time                    | 939        |
| dLoss                   | 0.0560218  |
----------------------------------------
itr #53 | 
Mem: 732.707031
Obtaining samples...
Obtaining samples for iteration 53...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5267, #subsample_inputs: 5267
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.755      |
| AbsLearnSignalNew       | 0.755      |
| AbsLearningOld          | 0.755      |
| AverageDiscountedReturn | 101        |
| AveragePhiLoss          | 9.41513    |
| AveragePolicyStd        | 0.944157   |
| AverageReturn           | 323        |
| Entropy                 | 8.16594    |
| EnvExecTime             | 2.79       |
| ExplainedVariance       | 0.506      |
| Iteration               | 53         |
| ItrTime                 | 18.3       |
| LossAfter               | 0.586806   |
| LossBefore              | 0.647496   |
| MaxReturn               | 653        |
| MeanKL                  | 0.00985943 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 59.3       |
| NumTrajs                | 20         |
| Perplexity              | 3519.02    |
| PolicyExecTime          | 0.59       |
| ProcessExecTime         | 0.0782     |
| StdReturn               | 148        |
| Time                    | 957        |
| dLoss                   | 0.0606896  |
----------------------------------------
itr #54 | 
Mem: 735.796875
Obtaining samples...
Obtaining samples for iteration 54...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5038, #subsample_inputs: 5038
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.687      |
| AbsLearnSignalNew       | 0.687      |
| AbsLearningOld          | 0.687      |
| AverageDiscountedReturn | 101        |
| AveragePhiLoss          | 9.15662    |
| AveragePolicyStd        | 0.945126   |
| AverageReturn           | 316        |
| Entropy                 | 8.17212    |
| EnvExecTime             | 2.67       |
| ExplainedVariance       | 0.439      |
| Iteration               | 54         |
| ItrTime                 | 17.4       |
| LossAfter               | 1.45024    |
| LossBefore              | 1.50553    |
| MaxReturn               | 695        |
| MeanKL                  | 0.00643462 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 42.7       |
| NumTrajs                | 19         |
| Perplexity              | 3540.85    |
| PolicyExecTime          | 0.603      |
| ProcessExecTime         | 0.0839     |
| StdReturn               | 156        |
| Time                    | 975        |
| dLoss                   | 0.05529    |
----------------------------------------
itr #55 | 
Mem: 735.796875
Obtaining samples...
Obtaining samples for iteration 55...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5301, #subsample_inputs: 5301
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.737      |
| AbsLearnSignalNew       | 0.737      |
| AbsLearningOld          | 0.738      |
| AverageDiscountedReturn | 102        |
| AveragePhiLoss          | 9.45369    |
| AveragePolicyStd        | 0.944094   |
| AverageReturn           | 246        |
| Entropy                 | 8.16563    |
| EnvExecTime             | 2.68       |
| ExplainedVariance       | 0.567      |
| Iteration               | 55         |
| ItrTime                 | 18.7       |
| LossAfter               | 1.47017    |
| LossBefore              | 1.52875    |
| MaxReturn               | 493        |
| MeanKL                  | 0.00998054 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 10.5       |
| NumTrajs                | 28         |
| Perplexity              | 3517.93    |
| PolicyExecTime          | 0.602      |
| ProcessExecTime         | 0.0777     |
| StdReturn               | 103        |
| Time                    | 994        |
| dLoss                   | 0.0585804  |
----------------------------------------
itr #56 | 
Mem: 735.796875
Obtaining samples...
Obtaining samples for iteration 56...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5211, #subsample_inputs: 5211
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.639      |
| AbsLearnSignalNew       | 0.639      |
| AbsLearningOld          | 0.639      |
| AverageDiscountedReturn | 96.1       |
| AveragePhiLoss          | 8.8865     |
| AveragePolicyStd        | 0.943124   |
| AverageReturn           | 275        |
| Entropy                 | 8.15971    |
| EnvExecTime             | 2.41       |
| ExplainedVariance       | -0.033     |
| Iteration               | 56         |
| ItrTime                 | 17.4       |
| LossAfter               | -0.0505842 |
| LossBefore              | 0.0165269  |
| MaxReturn               | 736        |
| MeanKL                  | 0.00988646 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 15.9       |
| NumTrajs                | 23         |
| Perplexity              | 3497.17    |
| PolicyExecTime          | 0.518      |
| ProcessExecTime         | 0.0707     |
| StdReturn               | 159        |
| Time                    | 1.01e+03   |
| dLoss                   | 0.0671112  |
----------------------------------------
itr #57 | 
Mem: 735.796875
Obtaining samples...
Obtaining samples for iteration 57...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5007, #subsample_inputs: 5007
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.751     |
| AbsLearnSignalNew       | 0.751     |
| AbsLearningOld          | 0.751     |
| AverageDiscountedReturn | 100       |
| AveragePhiLoss          | 9.42159   |
| AveragePolicyStd        | 0.941471  |
| AverageReturn           | 268       |
| Entropy                 | 8.1491    |
| EnvExecTime             | 2.73      |
| ExplainedVariance       | 0.489     |
| Iteration               | 57        |
| ItrTime                 | 17.7      |
| LossAfter               | 0.293972  |
| LossBefore              | 0.346148  |
| MaxReturn               | 546       |
| MeanKL                  | 0.0064808 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 79.3      |
| NumTrajs                | 23        |
| Perplexity              | 3460.26   |
| PolicyExecTime          | 0.612     |
| ProcessExecTime         | 0.0809    |
| StdReturn               | 112       |
| Time                    | 1.03e+03  |
| dLoss                   | 0.0521757 |
---------------------------------------
itr #58 | 
Mem: 735.796875
Obtaining samples...
Obtaining samples for iteration 58...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5223, #subsample_inputs: 5223
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.715      |
| AbsLearnSignalNew       | 0.715      |
| AbsLearningOld          | 0.715      |
| AverageDiscountedReturn | 110        |
| AveragePhiLoss          | 9.01849    |
| AveragePolicyStd        | 0.94201    |
| AverageReturn           | 355        |
| Entropy                 | 8.15218    |
| EnvExecTime             | 2.5        |
| ExplainedVariance       | 0.447      |
| Iteration               | 58         |
| ItrTime                 | 18.1       |
| LossAfter               | 0.10752    |
| LossBefore              | 0.165723   |
| MaxReturn               | 646        |
| MeanKL                  | 0.00998129 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 207        |
| NumTrajs                | 21         |
| Perplexity              | 3470.93    |
| PolicyExecTime          | 0.544      |
| ProcessExecTime         | 0.0708     |
| StdReturn               | 115        |
| Time                    | 1.05e+03   |
| dLoss                   | 0.058203   |
----------------------------------------
itr #59 | 
Mem: 735.796875
Obtaining samples...
Obtaining samples for iteration 59...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5084, #subsample_inputs: 5084
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.736      |
| AbsLearnSignalNew       | 0.736      |
| AbsLearningOld          | 0.736      |
| AverageDiscountedReturn | 94.2       |
| AveragePhiLoss          | 9.11654    |
| AveragePolicyStd        | 0.942088   |
| AverageReturn           | 225        |
| Entropy                 | 8.15289    |
| EnvExecTime             | 2.79       |
| ExplainedVariance       | 0.432      |
| Iteration               | 59         |
| ItrTime                 | 18         |
| LossAfter               | 0.993633   |
| LossBefore              | 1.0396     |
| MaxReturn               | 422        |
| MeanKL                  | 0.00645265 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 47.9       |
| NumTrajs                | 27         |
| Perplexity              | 3473.41    |
| PolicyExecTime          | 0.583      |
| ProcessExecTime         | 0.077      |
| StdReturn               | 115        |
| Time                    | 1.07e+03   |
| dLoss                   | 0.0459687  |
----------------------------------------
itr #60 | 
Mem: 735.796875
Obtaining samples...
Obtaining samples for iteration 60...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5027, #subsample_inputs: 5027
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.744      |
| AbsLearnSignalNew       | 0.744      |
| AbsLearningOld          | 0.744      |
| AverageDiscountedReturn | 106        |
| AveragePhiLoss          | 9.49216    |
| AveragePolicyStd        | 0.941135   |
| AverageReturn           | 307        |
| Entropy                 | 8.14654    |
| EnvExecTime             | 2.84       |
| ExplainedVariance       | 0.46       |
| Iteration               | 60         |
| ItrTime                 | 17.3       |
| LossAfter               | -0.0871353 |
| LossBefore              | -0.0378803 |
| MaxReturn               | 468        |
| MeanKL                  | 0.00641637 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 35         |
| NumTrajs                | 22         |
| Perplexity              | 3451.41    |
| PolicyExecTime          | 0.648      |
| ProcessExecTime         | 0.0834     |
| StdReturn               | 105        |
| Time                    | 1.08e+03   |
| dLoss                   | 0.049255   |
----------------------------------------
itr #61 | 
Mem: 735.796875
Obtaining samples...
Obtaining samples for iteration 61...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5076, #subsample_inputs: 5076
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.707      |
| AbsLearnSignalNew       | 0.707      |
| AbsLearningOld          | 0.707      |
| AverageDiscountedReturn | 105        |
| AveragePhiLoss          | 8.91584    |
| AveragePolicyStd        | 0.942062   |
| AverageReturn           | 292        |
| Entropy                 | 8.15234    |
| EnvExecTime             | 2.41       |
| ExplainedVariance       | 0.393      |
| Iteration               | 61         |
| ItrTime                 | 17.8       |
| LossAfter               | -0.716967  |
| LossBefore              | -0.658252  |
| MaxReturn               | 628        |
| MeanKL                  | 0.00996333 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 143        |
| NumTrajs                | 22         |
| Perplexity              | 3471.5     |
| PolicyExecTime          | 0.531      |
| ProcessExecTime         | 0.0694     |
| StdReturn               | 120        |
| Time                    | 1.1e+03    |
| dLoss                   | 0.0587149  |
----------------------------------------
itr #62 | 
Mem: 735.796875
Obtaining samples...
Obtaining samples for iteration 62...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5034, #subsample_inputs: 5034
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.718      |
| AbsLearnSignalNew       | 0.718      |
| AbsLearningOld          | 0.718      |
| AverageDiscountedReturn | 95.8       |
| AveragePhiLoss          | 9.09589    |
| AveragePolicyStd        | 0.943      |
| AverageReturn           | 247        |
| Entropy                 | 8.1581     |
| EnvExecTime             | 2.53       |
| ExplainedVariance       | 0.475      |
| Iteration               | 62         |
| ItrTime                 | 17         |
| LossAfter               | 0.330514   |
| LossBefore              | 0.380432   |
| MaxReturn               | 520        |
| MeanKL                  | 0.00645584 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 19.3       |
| NumTrajs                | 24         |
| Perplexity              | 3491.56    |
| PolicyExecTime          | 0.531      |
| ProcessExecTime         | 0.0723     |
| StdReturn               | 127        |
| Time                    | 1.12e+03   |
| dLoss                   | 0.0499182  |
----------------------------------------
itr #63 | 
Mem: 735.796875
Obtaining samples...
Obtaining samples for iteration 63...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5005, #subsample_inputs: 5005
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.743      |
| AbsLearnSignalNew       | 0.743      |
| AbsLearningOld          | 0.743      |
| AverageDiscountedReturn | 105        |
| AveragePhiLoss          | 9.03399    |
| AveragePolicyStd        | 0.942583   |
| AverageReturn           | 300        |
| Entropy                 | 8.15543    |
| EnvExecTime             | 2.7        |
| ExplainedVariance       | 0.587      |
| Iteration               | 63         |
| ItrTime                 | 18.2       |
| LossAfter               | 0.934242   |
| LossBefore              | 0.985363   |
| MaxReturn               | 500        |
| MeanKL                  | 0.00646662 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 17         |
| NumTrajs                | 23         |
| Perplexity              | 3482.25    |
| PolicyExecTime          | 0.594      |
| ProcessExecTime         | 0.0797     |
| StdReturn               | 103        |
| Time                    | 1.14e+03   |
| dLoss                   | 0.0511209  |
----------------------------------------
itr #64 | 
Mem: 735.796875
Obtaining samples...
Obtaining samples for iteration 64...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5175, #subsample_inputs: 5175
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.674     |
| AbsLearnSignalNew       | 0.674     |
| AbsLearningOld          | 0.674     |
| AverageDiscountedReturn | 108       |
| AveragePhiLoss          | 9.16218   |
| AveragePolicyStd        | 0.940723  |
| AverageReturn           | 304       |
| Entropy                 | 8.14373   |
| EnvExecTime             | 2.55      |
| ExplainedVariance       | 0.352     |
| Iteration               | 64        |
| ItrTime                 | 17.8      |
| LossAfter               | 1.71076   |
| LossBefore              | 1.76716   |
| MaxReturn               | 632       |
| MeanKL                  | 0.0098649 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 82.1      |
| NumTrajs                | 23        |
| Perplexity              | 3441.73   |
| PolicyExecTime          | 0.529     |
| ProcessExecTime         | 0.0694    |
| StdReturn               | 121       |
| Time                    | 1.15e+03  |
| dLoss                   | 0.0564041 |
---------------------------------------
itr #65 | 
Mem: 735.835938
Obtaining samples...
Obtaining samples for iteration 65...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5055, #subsample_inputs: 5055
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.722      |
| AbsLearnSignalNew       | 0.722      |
| AbsLearningOld          | 0.721      |
| AverageDiscountedReturn | 99.7       |
| AveragePhiLoss          | 9.12323    |
| AveragePolicyStd        | 0.939602   |
| AverageReturn           | 276        |
| Entropy                 | 8.13641    |
| EnvExecTime             | 2.7        |
| ExplainedVariance       | 0.532      |
| Iteration               | 65         |
| ItrTime                 | 17.4       |
| LossAfter               | 2.24274    |
| LossBefore              | 2.30235    |
| MaxReturn               | 469        |
| MeanKL                  | 0.00975263 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 46.3       |
| NumTrajs                | 22         |
| Perplexity              | 3416.64    |
| PolicyExecTime          | 0.591      |
| ProcessExecTime         | 0.0775     |
| StdReturn               | 112        |
| Time                    | 1.17e+03   |
| dLoss                   | 0.0596144  |
----------------------------------------
itr #66 | 
Mem: 736.609375
Obtaining samples...
Obtaining samples for iteration 66...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5075, #subsample_inputs: 5075
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.742      |
| AbsLearnSignalNew       | 0.742      |
| AbsLearningOld          | 0.742      |
| AverageDiscountedReturn | 103        |
| AveragePhiLoss          | 9.06201    |
| AveragePolicyStd        | 0.939941   |
| AverageReturn           | 293        |
| Entropy                 | 8.13829    |
| EnvExecTime             | 2.73       |
| ExplainedVariance       | 0.537      |
| Iteration               | 66         |
| ItrTime                 | 18         |
| LossAfter               | 0.945102   |
| LossBefore              | 1.00187    |
| MaxReturn               | 533        |
| MeanKL                  | 0.00998761 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 24.8       |
| NumTrajs                | 22         |
| Perplexity              | 3423.06    |
| PolicyExecTime          | 0.608      |
| ProcessExecTime         | 0.0816     |
| StdReturn               | 115        |
| Time                    | 1.19e+03   |
| dLoss                   | 0.0567706  |
----------------------------------------
itr #67 | 
Mem: 736.609375
Obtaining samples...
Obtaining samples for iteration 67...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5088, #subsample_inputs: 5088
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.737      |
| AbsLearnSignalNew       | 0.737      |
| AbsLearningOld          | 0.737      |
| AverageDiscountedReturn | 111        |
| AveragePhiLoss          | 9.19432    |
| AveragePolicyStd        | 0.938242   |
| AverageReturn           | 313        |
| Entropy                 | 8.12766    |
| EnvExecTime             | 2.61       |
| ExplainedVariance       | 0.511      |
| Iteration               | 67         |
| ItrTime                 | 18.2       |
| LossAfter               | -0.666727  |
| LossBefore              | -0.617705  |
| MaxReturn               | 619        |
| MeanKL                  | 0.00643619 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 133        |
| NumTrajs                | 24         |
| Perplexity              | 3386.85    |
| PolicyExecTime          | 0.531      |
| ProcessExecTime         | 0.0675     |
| StdReturn               | 110        |
| Time                    | 1.21e+03   |
| dLoss                   | 0.0490213  |
----------------------------------------
itr #68 | 
Mem: 736.867188
Obtaining samples...
Obtaining samples for iteration 68...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5025, #subsample_inputs: 5025
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.645      |
| AbsLearnSignalNew       | 0.645      |
| AbsLearningOld          | 0.645      |
| AverageDiscountedReturn | 106        |
| AveragePhiLoss          | 8.97586    |
| AveragePolicyStd        | 0.938586   |
| AverageReturn           | 277        |
| Entropy                 | 8.12978    |
| EnvExecTime             | 2.69       |
| ExplainedVariance       | 0.446      |
| Iteration               | 68         |
| ItrTime                 | 17.1       |
| LossAfter               | -0.385759  |
| LossBefore              | -0.34079   |
| MaxReturn               | 771        |
| MeanKL                  | 0.00653376 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 33.4       |
| NumTrajs                | 24         |
| Perplexity              | 3394.07    |
| PolicyExecTime          | 0.584      |
| ProcessExecTime         | 0.0763     |
| StdReturn               | 139        |
| Time                    | 1.23e+03   |
| dLoss                   | 0.0449694  |
----------------------------------------
itr #69 | 
Mem: 736.867188
Obtaining samples...
Obtaining samples for iteration 69...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5010, #subsample_inputs: 5010
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.72      |
| AbsLearnSignalNew       | 0.72      |
| AbsLearningOld          | 0.72      |
| AverageDiscountedReturn | 107       |
| AveragePhiLoss          | 9.49591   |
| AveragePolicyStd        | 0.939879  |
| AverageReturn           | 301       |
| Entropy                 | 8.1382    |
| EnvExecTime             | 2.66      |
| ExplainedVariance       | 0.502     |
| Iteration               | 69        |
| ItrTime                 | 18        |
| LossAfter               | -0.433635 |
| LossBefore              | -0.385194 |
| MaxReturn               | 474       |
| MeanKL                  | 0.0065338 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 28.6      |
| NumTrajs                | 22        |
| Perplexity              | 3422.74   |
| PolicyExecTime          | 0.613     |
| ProcessExecTime         | 0.079     |
| StdReturn               | 98.8      |
| Time                    | 1.24e+03  |
| dLoss                   | 0.0484413 |
---------------------------------------
itr #70 | 
Mem: 736.867188
Obtaining samples...
Obtaining samples for iteration 70...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5020, #subsample_inputs: 5020
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.704      |
| AbsLearnSignalNew       | 0.704      |
| AbsLearningOld          | 0.704      |
| AverageDiscountedReturn | 105        |
| AveragePhiLoss          | 8.86777    |
| AveragePolicyStd        | 0.937046   |
| AverageReturn           | 318        |
| Entropy                 | 8.11979    |
| EnvExecTime             | 2.51       |
| ExplainedVariance       | 0.398      |
| Iteration               | 70         |
| ItrTime                 | 17.4       |
| LossAfter               | -0.6187    |
| LossBefore              | -0.556765  |
| MaxReturn               | 721        |
| MeanKL                  | 0.00991843 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 67.5       |
| NumTrajs                | 21         |
| Perplexity              | 3360.3     |
| PolicyExecTime          | 0.506      |
| ProcessExecTime         | 0.0673     |
| StdReturn               | 147        |
| Time                    | 1.26e+03   |
| dLoss                   | 0.0619343  |
----------------------------------------
itr #71 | 
Mem: 736.867188
Obtaining samples...
Obtaining samples for iteration 71...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5246, #subsample_inputs: 5246
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.712      |
| AbsLearnSignalNew       | 0.712      |
| AbsLearningOld          | 0.712      |
| AverageDiscountedReturn | 108        |
| AveragePhiLoss          | 9.52533    |
| AveragePolicyStd        | 0.940272   |
| AverageReturn           | 298        |
| Entropy                 | 8.14035    |
| EnvExecTime             | 2.95       |
| ExplainedVariance       | 0.518      |
| Iteration               | 71         |
| ItrTime                 | 18.1       |
| LossAfter               | 0.618632   |
| LossBefore              | 0.674545   |
| MaxReturn               | 525        |
| MeanKL                  | 0.00997847 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 56.3       |
| NumTrajs                | 23         |
| Perplexity              | 3430.13    |
| PolicyExecTime          | 0.669      |
| ProcessExecTime         | 0.0908     |
| StdReturn               | 103        |
| Time                    | 1.28e+03   |
| dLoss                   | 0.0559127  |
----------------------------------------
itr #72 | 
Mem: 737.382812
Obtaining samples...
Obtaining samples for iteration 72...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5364, #subsample_inputs: 5364
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.719      |
| AbsLearnSignalNew       | 0.719      |
| AbsLearningOld          | 0.719      |
| AverageDiscountedReturn | 108        |
| AveragePhiLoss          | 9.52621    |
| AveragePolicyStd        | 0.940357   |
| AverageReturn           | 314        |
| Entropy                 | 8.14058    |
| EnvExecTime             | 2.89       |
| ExplainedVariance       | 0.408      |
| Iteration               | 72         |
| ItrTime                 | 18.9       |
| LossAfter               | 0.17356    |
| LossBefore              | 0.231893   |
| MaxReturn               | 565        |
| MeanKL                  | 0.00991317 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 116        |
| NumTrajs                | 24         |
| Perplexity              | 3430.91    |
| PolicyExecTime          | 0.627      |
| ProcessExecTime         | 0.0834     |
| StdReturn               | 102        |
| Time                    | 1.3e+03    |
| dLoss                   | 0.058333   |
----------------------------------------
itr #73 | 
Mem: 737.382812
Obtaining samples...
Obtaining samples for iteration 73...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5007, #subsample_inputs: 5007
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.698      |
| AbsLearnSignalNew       | 0.698      |
| AbsLearningOld          | 0.698      |
| AverageDiscountedReturn | 105        |
| AveragePhiLoss          | 9.43997    |
| AveragePolicyStd        | 0.941577   |
| AverageReturn           | 302        |
| Entropy                 | 8.14771    |
| EnvExecTime             | 2.31       |
| ExplainedVariance       | 0.605      |
| Iteration               | 73         |
| ItrTime                 | 17.2       |
| LossAfter               | 0.809948   |
| LossBefore              | 0.858871   |
| MaxReturn               | 618        |
| MeanKL                  | 0.00645081 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 41.5       |
| NumTrajs                | 24         |
| Perplexity              | 3455.44    |
| PolicyExecTime          | 0.477      |
| ProcessExecTime         | 0.0661     |
| StdReturn               | 129        |
| Time                    | 1.32e+03   |
| dLoss                   | 0.0489232  |
----------------------------------------
itr #74 | 
Mem: 737.925781
Obtaining samples...
Obtaining samples for iteration 74...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5255, #subsample_inputs: 5255
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.672      |
| AbsLearnSignalNew       | 0.672      |
| AbsLearningOld          | 0.673      |
| AverageDiscountedReturn | 107        |
| AveragePhiLoss          | 8.86074    |
| AveragePolicyStd        | 0.943218   |
| AverageReturn           | 306        |
| Entropy                 | 8.15803    |
| EnvExecTime             | 3          |
| ExplainedVariance       | 0.617      |
| Iteration               | 74         |
| ItrTime                 | 18         |
| LossAfter               | 0.877479   |
| LossBefore              | 0.934307   |
| MaxReturn               | 648        |
| MeanKL                  | 0.00992969 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 18.7       |
| NumTrajs                | 25         |
| Perplexity              | 3491.3     |
| PolicyExecTime          | 0.676      |
| ProcessExecTime         | 0.0863     |
| StdReturn               | 137        |
| Time                    | 1.33e+03   |
| dLoss                   | 0.0568284  |
----------------------------------------
itr #75 | 
Mem: 738.953125
Obtaining samples...
Obtaining samples for iteration 75...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5235, #subsample_inputs: 5235
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.701      |
| AbsLearnSignalNew       | 0.701      |
| AbsLearningOld          | 0.701      |
| AverageDiscountedReturn | 103        |
| AveragePhiLoss          | 8.87507    |
| AveragePolicyStd        | 0.942912   |
| AverageReturn           | 299        |
| Entropy                 | 8.15628    |
| EnvExecTime             | 2.63       |
| ExplainedVariance       | 0.622      |
| Iteration               | 75         |
| ItrTime                 | 18.4       |
| LossAfter               | 0.158835   |
| LossBefore              | 0.207503   |
| MaxReturn               | 539        |
| MeanKL                  | 0.00645797 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 38.5       |
| NumTrajs                | 25         |
| Perplexity              | 3485.21    |
| PolicyExecTime          | 0.589      |
| ProcessExecTime         | 0.0788     |
| StdReturn               | 127        |
| Time                    | 1.35e+03   |
| dLoss                   | 0.0486674  |
----------------------------------------
itr #76 | 
Mem: 741.015625
Obtaining samples...
Obtaining samples for iteration 76...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5025, #subsample_inputs: 5025
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.666      |
| AbsLearnSignalNew       | 0.666      |
| AbsLearningOld          | 0.666      |
| AverageDiscountedReturn | 99.2       |
| AveragePhiLoss          | 9.7043     |
| AveragePolicyStd        | 0.94348    |
| AverageReturn           | 294        |
| Entropy                 | 8.16015    |
| EnvExecTime             | 2.39       |
| ExplainedVariance       | 0.421      |
| Iteration               | 76         |
| ItrTime                 | 16.9       |
| LossAfter               | 0.762649   |
| LossBefore              | 0.827973   |
| MaxReturn               | 755        |
| MeanKL                  | 0.00994462 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 25         |
| NumTrajs                | 22         |
| Perplexity              | 3498.71    |
| PolicyExecTime          | 0.495      |
| ProcessExecTime         | 0.0665     |
| StdReturn               | 167        |
| Time                    | 1.37e+03   |
| dLoss                   | 0.0653237  |
----------------------------------------
itr #77 | 
Mem: 741.015625
Obtaining samples...
Obtaining samples for iteration 77...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5016, #subsample_inputs: 5016
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.727     |
| AbsLearnSignalNew       | 0.727     |
| AbsLearningOld          | 0.727     |
| AverageDiscountedReturn | 98.6      |
| AveragePhiLoss          | 9.53826   |
| AveragePolicyStd        | 0.944501  |
| AverageReturn           | 273       |
| Entropy                 | 8.16713   |
| EnvExecTime             | 2.7       |
| ExplainedVariance       | 0.375     |
| Iteration               | 77        |
| ItrTime                 | 17.7      |
| LossAfter               | 0.255896  |
| LossBefore              | 0.319652  |
| MaxReturn               | 704       |
| MeanKL                  | 0.0098282 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 13.9      |
| NumTrajs                | 21        |
| Perplexity              | 3523.22   |
| PolicyExecTime          | 0.602     |
| ProcessExecTime         | 0.0805    |
| StdReturn               | 147       |
| Time                    | 1.39e+03  |
| dLoss                   | 0.0637563 |
---------------------------------------
itr #78 | 
Mem: 741.015625
Obtaining samples...
Obtaining samples for iteration 78...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5108, #subsample_inputs: 5108
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.777      |
| AbsLearnSignalNew       | 0.777      |
| AbsLearningOld          | 0.777      |
| AverageDiscountedReturn | 107        |
| AveragePhiLoss          | 9.30395    |
| AveragePolicyStd        | 0.945829   |
| AverageReturn           | 280        |
| Entropy                 | 8.17506    |
| EnvExecTime             | 2.47       |
| ExplainedVariance       | 0.472      |
| Iteration               | 78         |
| ItrTime                 | 17.8       |
| LossAfter               | 0.675168   |
| LossBefore              | 0.72444    |
| MaxReturn               | 503        |
| MeanKL                  | 0.00648198 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 65.1       |
| NumTrajs                | 26         |
| Perplexity              | 3551.26    |
| PolicyExecTime          | 0.542      |
| ProcessExecTime         | 0.0658     |
| StdReturn               | 107        |
| Time                    | 1.4e+03    |
| dLoss                   | 0.0492712  |
----------------------------------------
itr #79 | 
Mem: 741.015625
Obtaining samples...
Obtaining samples for iteration 79...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5219, #subsample_inputs: 5219
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.667      |
| AbsLearnSignalNew       | 0.667      |
| AbsLearningOld          | 0.667      |
| AverageDiscountedReturn | 110        |
| AveragePhiLoss          | 9.77757    |
| AveragePolicyStd        | 0.946562   |
| AverageReturn           | 318        |
| Entropy                 | 8.17957    |
| EnvExecTime             | 2.83       |
| ExplainedVariance       | 0.469      |
| Iteration               | 79         |
| ItrTime                 | 17.9       |
| LossAfter               | 0.865651   |
| LossBefore              | 0.915847   |
| MaxReturn               | 731        |
| MeanKL                  | 0.00641247 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 71.1       |
| NumTrajs                | 24         |
| Perplexity              | 3567.32    |
| PolicyExecTime          | 0.604      |
| ProcessExecTime         | 0.0812     |
| StdReturn               | 132        |
| Time                    | 1.42e+03   |
| dLoss                   | 0.0501961  |
----------------------------------------
itr #80 | 
Mem: 741.015625
Obtaining samples...
Obtaining samples for iteration 80...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5063, #subsample_inputs: 5063
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.686      |
| AbsLearnSignalNew       | 0.686      |
| AbsLearningOld          | 0.686      |
| AverageDiscountedReturn | 107        |
| AveragePhiLoss          | 9.17251    |
| AveragePolicyStd        | 0.946494   |
| AverageReturn           | 320        |
| Entropy                 | 8.17876    |
| EnvExecTime             | 2.86       |
| ExplainedVariance       | 0.586      |
| Iteration               | 80         |
| ItrTime                 | 17.9       |
| LossAfter               | 1.45492    |
| LossBefore              | 1.51566    |
| MaxReturn               | 566        |
| MeanKL                  | 0.00984823 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 26.3       |
| NumTrajs                | 23         |
| Perplexity              | 3564.45    |
| PolicyExecTime          | 0.627      |
| ProcessExecTime         | 0.0831     |
| StdReturn               | 140        |
| Time                    | 1.44e+03   |
| dLoss                   | 0.0607395  |
----------------------------------------
itr #81 | 
Mem: 741.015625
Obtaining samples...
Obtaining samples for iteration 81...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5279, #subsample_inputs: 5279
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.685     |
| AbsLearnSignalNew       | 0.685     |
| AbsLearningOld          | 0.685     |
| AverageDiscountedReturn | 111       |
| AveragePhiLoss          | 9.50549   |
| AveragePolicyStd        | 0.946517  |
| AverageReturn           | 329       |
| Entropy                 | 8.17963   |
| EnvExecTime             | 2.74      |
| ExplainedVariance       | 0.583     |
| Iteration               | 81        |
| ItrTime                 | 18.5      |
| LossAfter               | 0.218358  |
| LossBefore              | 0.267692  |
| MaxReturn               | 503       |
| MeanKL                  | 0.006466  |
| MeanKLBefore            | 0.0       |
| MinReturn               | 181       |
| NumTrajs                | 23        |
| Perplexity              | 3567.52   |
| PolicyExecTime          | 0.607     |
| ProcessExecTime         | 0.0743    |
| StdReturn               | 83.7      |
| Time                    | 1.46e+03  |
| dLoss                   | 0.0493339 |
---------------------------------------
itr #82 | 
Mem: 741.015625
Obtaining samples...
Obtaining samples for iteration 82...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5157, #subsample_inputs: 5157
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.702      |
| AbsLearnSignalNew       | 0.702      |
| AbsLearningOld          | 0.702      |
| AverageDiscountedReturn | 107        |
| AveragePhiLoss          | 9.34056    |
| AveragePolicyStd        | 0.945122   |
| AverageReturn           | 305        |
| Entropy                 | 8.17032    |
| EnvExecTime             | 2.56       |
| ExplainedVariance       | 0.401      |
| Iteration               | 82         |
| ItrTime                 | 17.3       |
| LossAfter               | 0.479868   |
| LossBefore              | 0.541484   |
| MaxReturn               | 520        |
| MeanKL                  | 0.00999898 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 36.5       |
| NumTrajs                | 24         |
| Perplexity              | 3534.46    |
| PolicyExecTime          | 0.55       |
| ProcessExecTime         | 0.0731     |
| StdReturn               | 114        |
| Time                    | 1.48e+03   |
| dLoss                   | 0.061616   |
----------------------------------------
itr #83 | 
Mem: 741.015625
Obtaining samples...
Obtaining samples for iteration 83...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5063, #subsample_inputs: 5063
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.46      |
| AbsLearnSignalNew       | 0.46      |
| AbsLearningOld          | 0.46      |
| AverageDiscountedReturn | 102       |
| AveragePhiLoss          | 8.71502   |
| AveragePolicyStd        | 0.945108  |
| AverageReturn           | 296       |
| Entropy                 | 8.17054   |
| EnvExecTime             | 2.79      |
| ExplainedVariance       | -1.54     |
| Iteration               | 83        |
| ItrTime                 | 18        |
| LossAfter               | 0.205322  |
| LossBefore              | 0.268342  |
| MaxReturn               | 996       |
| MeanKL                  | 0.0064248 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 52.1      |
| NumTrajs                | 21        |
| Perplexity              | 3535.24   |
| PolicyExecTime          | 0.588     |
| ProcessExecTime         | 0.0822    |
| StdReturn               | 191       |
| Time                    | 1.49e+03  |
| dLoss                   | 0.0630205 |
---------------------------------------
itr #84 | 
Mem: 741.015625
Obtaining samples...
Obtaining samples for iteration 84...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5001, #subsample_inputs: 5001
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.727      |
| AbsLearnSignalNew       | 0.727      |
| AbsLearningOld          | 0.727      |
| AverageDiscountedReturn | 106        |
| AveragePhiLoss          | 9.22735    |
| AveragePolicyStd        | 0.944315   |
| AverageReturn           | 297        |
| Entropy                 | 8.16531    |
| EnvExecTime             | 2.33       |
| ExplainedVariance       | 0.51       |
| Iteration               | 84         |
| ItrTime                 | 17.2       |
| LossAfter               | 0.656107   |
| LossBefore              | 0.720505   |
| MaxReturn               | 583        |
| MeanKL                  | 0.00993714 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 36.9       |
| NumTrajs                | 25         |
| Perplexity              | 3516.82    |
| PolicyExecTime          | 0.469      |
| ProcessExecTime         | 0.0643     |
| StdReturn               | 131        |
| Time                    | 1.51e+03   |
| dLoss                   | 0.0643974  |
----------------------------------------
itr #85 | 
Mem: 741.015625
Obtaining samples...
Obtaining samples for iteration 85...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5036, #subsample_inputs: 5036
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.66       |
| AbsLearnSignalNew       | 0.66       |
| AbsLearningOld          | 0.66       |
| AverageDiscountedReturn | 102        |
| AveragePhiLoss          | 9.76805    |
| AveragePolicyStd        | 0.943941   |
| AverageReturn           | 294        |
| Entropy                 | 8.16378    |
| EnvExecTime             | 2.77       |
| ExplainedVariance       | 0.546      |
| Iteration               | 85         |
| ItrTime                 | 17.2       |
| LossAfter               | -0.363657  |
| LossBefore              | -0.305617  |
| MaxReturn               | 486        |
| MeanKL                  | 0.00998848 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 26.9       |
| NumTrajs                | 23         |
| Perplexity              | 3511.43    |
| PolicyExecTime          | 0.59       |
| ProcessExecTime         | 0.0812     |
| StdReturn               | 121        |
| Time                    | 1.53e+03   |
| dLoss                   | 0.05804    |
----------------------------------------
itr #86 | 
Mem: 741.015625
Obtaining samples...
Obtaining samples for iteration 86...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5054, #subsample_inputs: 5054
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.638      |
| AbsLearnSignalNew       | 0.638      |
| AbsLearningOld          | 0.638      |
| AverageDiscountedReturn | 101        |
| AveragePhiLoss          | 10.0394    |
| AveragePolicyStd        | 0.93956    |
| AverageReturn           | 280        |
| Entropy                 | 8.13582    |
| EnvExecTime             | 2.57       |
| ExplainedVariance       | 0.0617     |
| Iteration               | 86         |
| ItrTime                 | 17.9       |
| LossAfter               | 0.0352405  |
| LossBefore              | 0.111447   |
| MaxReturn               | 687        |
| MeanKL                  | 0.00987815 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 43.7       |
| NumTrajs                | 22         |
| Perplexity              | 3414.61    |
| PolicyExecTime          | 0.555      |
| ProcessExecTime         | 0.0746     |
| StdReturn               | 157        |
| Time                    | 1.55e+03   |
| dLoss                   | 0.076206   |
----------------------------------------
itr #87 | 
Mem: 741.015625
Obtaining samples...
Obtaining samples for iteration 87...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5221, #subsample_inputs: 5221
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.723      |
| AbsLearnSignalNew       | 0.723      |
| AbsLearningOld          | 0.723      |
| AverageDiscountedReturn | 112        |
| AveragePhiLoss          | 9.5015     |
| AveragePolicyStd        | 0.940202   |
| AverageReturn           | 303        |
| Entropy                 | 8.14024    |
| EnvExecTime             | 2.83       |
| ExplainedVariance       | 0.5        |
| Iteration               | 87         |
| ItrTime                 | 18.1       |
| LossAfter               | 0.889855   |
| LossBefore              | 0.950131   |
| MaxReturn               | 483        |
| MeanKL                  | 0.00990543 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 101        |
| NumTrajs                | 26         |
| Perplexity              | 3429.75    |
| PolicyExecTime          | 0.598      |
| ProcessExecTime         | 0.0745     |
| StdReturn               | 84.5       |
| Time                    | 1.57e+03   |
| dLoss                   | 0.0602764  |
----------------------------------------
itr #88 | 
Mem: 741.015625
Obtaining samples...
Obtaining samples for iteration 88...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5080, #subsample_inputs: 5080
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.515      |
| AbsLearnSignalNew       | 0.515      |
| AbsLearningOld          | 0.515      |
| AverageDiscountedReturn | 97.7       |
| AveragePhiLoss          | 9.20613    |
| AveragePolicyStd        | 0.940875   |
| AverageReturn           | 303        |
| Entropy                 | 8.14437    |
| EnvExecTime             | 2.76       |
| ExplainedVariance       | -0.621     |
| Iteration               | 88         |
| ItrTime                 | 17.5       |
| LossAfter               | 0.677438   |
| LossBefore              | 0.732802   |
| MaxReturn               | 737        |
| MeanKL                  | 0.00976378 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 32.9       |
| NumTrajs                | 20         |
| Perplexity              | 3443.92    |
| PolicyExecTime          | 0.601      |
| ProcessExecTime         | 0.0806     |
| StdReturn               | 162        |
| Time                    | 1.58e+03   |
| dLoss                   | 0.0553648  |
----------------------------------------
itr #89 | 
Mem: 741.015625
Obtaining samples...
Obtaining samples for iteration 89...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5592, #subsample_inputs: 5592
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.714      |
| AbsLearnSignalNew       | 0.714      |
| AbsLearningOld          | 0.714      |
| AverageDiscountedReturn | 106        |
| AveragePhiLoss          | 9.53802    |
| AveragePolicyStd        | 0.940261   |
| AverageReturn           | 323        |
| Entropy                 | 8.14073    |
| EnvExecTime             | 2.99       |
| ExplainedVariance       | 0.558      |
| Iteration               | 89         |
| ItrTime                 | 19.5       |
| LossAfter               | 0.794626   |
| LossBefore              | 0.852587   |
| MaxReturn               | 717        |
| MeanKL                  | 0.00998835 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 35.2       |
| NumTrajs                | 23         |
| Perplexity              | 3431.41    |
| PolicyExecTime          | 0.672      |
| ProcessExecTime         | 0.0834     |
| StdReturn               | 146        |
| Time                    | 1.6e+03    |
| dLoss                   | 0.0579607  |
----------------------------------------
itr #90 | 
Mem: 743.406250
Obtaining samples...
Obtaining samples for iteration 90...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5164, #subsample_inputs: 5164
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.714      |
| AbsLearnSignalNew       | 0.714      |
| AbsLearningOld          | 0.714      |
| AverageDiscountedReturn | 108        |
| AveragePhiLoss          | 9.44307    |
| AveragePolicyStd        | 0.937605   |
| AverageReturn           | 305        |
| Entropy                 | 8.12406    |
| EnvExecTime             | 2.63       |
| ExplainedVariance       | 0.586      |
| Iteration               | 90         |
| ItrTime                 | 18.1       |
| LossAfter               | 0.334402   |
| LossBefore              | 0.383201   |
| MaxReturn               | 770        |
| MeanKL                  | 0.00642081 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 83.5       |
| NumTrajs                | 24         |
| Perplexity              | 3374.68    |
| PolicyExecTime          | 0.529      |
| ProcessExecTime         | 0.0694     |
| StdReturn               | 129        |
| Time                    | 1.62e+03   |
| dLoss                   | 0.0487991  |
----------------------------------------
itr #91 | 
Mem: 743.406250
Obtaining samples...
Obtaining samples for iteration 91...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5268, #subsample_inputs: 5268
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.711      |
| AbsLearnSignalNew       | 0.711      |
| AbsLearningOld          | 0.71       |
| AverageDiscountedReturn | 112        |
| AveragePhiLoss          | 9.27129    |
| AveragePolicyStd        | 0.936986   |
| AverageReturn           | 307        |
| Entropy                 | 8.12009    |
| EnvExecTime             | 2.71       |
| ExplainedVariance       | 0.676      |
| Iteration               | 91         |
| ItrTime                 | 17.7       |
| LossAfter               | 0.600244   |
| LossBefore              | 0.659637   |
| MaxReturn               | 437        |
| MeanKL                  | 0.00993874 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 182        |
| NumTrajs                | 26         |
| Perplexity              | 3361.31    |
| PolicyExecTime          | 0.597      |
| ProcessExecTime         | 0.0826     |
| StdReturn               | 76.3       |
| Time                    | 1.64e+03   |
| dLoss                   | 0.059393   |
----------------------------------------
itr #92 | 
Mem: 743.406250
Obtaining samples...
Obtaining samples for iteration 92...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5016, #subsample_inputs: 5016
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.699      |
| AbsLearnSignalNew       | 0.699      |
| AbsLearningOld          | 0.699      |
| AverageDiscountedReturn | 106        |
| AveragePhiLoss          | 9.52827    |
| AveragePolicyStd        | 0.936311   |
| AverageReturn           | 287        |
| Entropy                 | 8.1162     |
| EnvExecTime             | 2.61       |
| ExplainedVariance       | 0.534      |
| Iteration               | 92         |
| ItrTime                 | 17.9       |
| LossAfter               | 0.0125647  |
| LossBefore              | 0.0599739  |
| MaxReturn               | 529        |
| MeanKL                  | 0.00640402 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 56         |
| NumTrajs                | 24         |
| Perplexity              | 3348.26    |
| PolicyExecTime          | 0.56       |
| ProcessExecTime         | 0.0758     |
| StdReturn               | 103        |
| Time                    | 1.66e+03   |
| dLoss                   | 0.0474092  |
----------------------------------------
itr #93 | 
Mem: 743.406250
Obtaining samples...
Obtaining samples for iteration 93...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5044, #subsample_inputs: 5044
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.7        |
| AbsLearnSignalNew       | 0.7        |
| AbsLearningOld          | 0.7        |
| AverageDiscountedReturn | 106        |
| AveragePhiLoss          | 9.55047    |
| AveragePolicyStd        | 0.936167   |
| AverageReturn           | 272        |
| Entropy                 | 8.1155     |
| EnvExecTime             | 2.53       |
| ExplainedVariance       | 0.612      |
| Iteration               | 93         |
| ItrTime                 | 17.4       |
| LossAfter               | 0.482029   |
| LossBefore              | 0.53043    |
| MaxReturn               | 445        |
| MeanKL                  | 0.00655218 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 34.6       |
| NumTrajs                | 27         |
| Perplexity              | 3345.92    |
| PolicyExecTime          | 0.519      |
| ProcessExecTime         | 0.0677     |
| StdReturn               | 97         |
| Time                    | 1.67e+03   |
| dLoss                   | 0.0484018  |
----------------------------------------
itr #94 | 
Mem: 743.406250
Obtaining samples...
Obtaining samples for iteration 94...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5254, #subsample_inputs: 5254
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.667      |
| AbsLearnSignalNew       | 0.667      |
| AbsLearningOld          | 0.667      |
| AverageDiscountedReturn | 107        |
| AveragePhiLoss          | 9.40667    |
| AveragePolicyStd        | 0.935032   |
| AverageReturn           | 299        |
| Entropy                 | 8.10834    |
| EnvExecTime             | 2.75       |
| ExplainedVariance       | 0.542      |
| Iteration               | 94         |
| ItrTime                 | 18         |
| LossAfter               | 0.72091    |
| LossBefore              | 0.769595   |
| MaxReturn               | 514        |
| MeanKL                  | 0.00643189 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 56.9       |
| NumTrajs                | 24         |
| Perplexity              | 3322.05    |
| PolicyExecTime          | 0.598      |
| ProcessExecTime         | 0.0808     |
| StdReturn               | 101        |
| Time                    | 1.69e+03   |
| dLoss                   | 0.0486843  |
----------------------------------------
itr #95 | 
Mem: 743.933594
Obtaining samples...
Obtaining samples for iteration 95...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5173, #subsample_inputs: 5173
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.706      |
| AbsLearnSignalNew       | 0.706      |
| AbsLearningOld          | 0.706      |
| AverageDiscountedReturn | 106        |
| AveragePhiLoss          | 9.85799    |
| AveragePolicyStd        | 0.935335   |
| AverageReturn           | 315        |
| Entropy                 | 8.11025    |
| EnvExecTime             | 2.74       |
| ExplainedVariance       | 0.513      |
| Iteration               | 95         |
| ItrTime                 | 18.1       |
| LossAfter               | 0.0985097  |
| LossBefore              | 0.159155   |
| MaxReturn               | 588        |
| MeanKL                  | 0.00999663 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 38.9       |
| NumTrajs                | 22         |
| Perplexity              | 3328.42    |
| PolicyExecTime          | 0.591      |
| ProcessExecTime         | 0.0758     |
| StdReturn               | 125        |
| Time                    | 1.71e+03   |
| dLoss                   | 0.0606457  |
----------------------------------------
itr #96 | 
Mem: 743.933594
Obtaining samples...
Obtaining samples for iteration 96...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5200, #subsample_inputs: 5200
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.656     |
| AbsLearnSignalNew       | 0.656     |
| AbsLearningOld          | 0.656     |
| AverageDiscountedReturn | 107       |
| AveragePhiLoss          | 9.99598   |
| AveragePolicyStd        | 0.93715   |
| AverageReturn           | 316       |
| Entropy                 | 8.12161   |
| EnvExecTime             | 2.51      |
| ExplainedVariance       | 0.549     |
| Iteration               | 96        |
| ItrTime                 | 17.9      |
| LossAfter               | -0.36326  |
| LossBefore              | -0.317227 |
| MaxReturn               | 500       |
| MeanKL                  | 0.0064323 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 73        |
| NumTrajs                | 23        |
| Perplexity              | 3366.44   |
| PolicyExecTime          | 0.508     |
| ProcessExecTime         | 0.0669    |
| StdReturn               | 114       |
| Time                    | 1.73e+03  |
| dLoss                   | 0.0460328 |
---------------------------------------
itr #97 | 
Mem: 745.738281
Obtaining samples...
Obtaining samples for iteration 97...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5124, #subsample_inputs: 5124
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.659      |
| AbsLearnSignalNew       | 0.659      |
| AbsLearningOld          | 0.658      |
| AverageDiscountedReturn | 107        |
| AveragePhiLoss          | 9.695      |
| AveragePolicyStd        | 0.936453   |
| AverageReturn           | 307        |
| Entropy                 | 8.11711    |
| EnvExecTime             | 2.82       |
| ExplainedVariance       | 0.551      |
| Iteration               | 97         |
| ItrTime                 | 17.5       |
| LossAfter               | -0.433002  |
| LossBefore              | -0.381607  |
| MaxReturn               | 473        |
| MeanKL                  | 0.00651471 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 77.8       |
| NumTrajs                | 23         |
| Perplexity              | 3351.33    |
| PolicyExecTime          | 0.609      |
| ProcessExecTime         | 0.0829     |
| StdReturn               | 93.1       |
| Time                    | 1.75e+03   |
| dLoss                   | 0.051395   |
----------------------------------------
itr #98 | 
Mem: 745.738281
Obtaining samples...
Obtaining samples for iteration 98...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5001, #subsample_inputs: 5001
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.661      |
| AbsLearnSignalNew       | 0.661      |
| AbsLearningOld          | 0.661      |
| AverageDiscountedReturn | 106        |
| AveragePhiLoss          | 9.65782    |
| AveragePolicyStd        | 0.934905   |
| AverageReturn           | 269        |
| Entropy                 | 8.10693    |
| EnvExecTime             | 2.62       |
| ExplainedVariance       | 0.579      |
| Iteration               | 98         |
| ItrTime                 | 18         |
| LossAfter               | -0.910223  |
| LossBefore              | -0.860753  |
| MaxReturn               | 440        |
| MeanKL                  | 0.00654105 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 58.1       |
| NumTrajs                | 27         |
| Perplexity              | 3317.37    |
| PolicyExecTime          | 0.556      |
| ProcessExecTime         | 0.0757     |
| StdReturn               | 91.7       |
| Time                    | 1.76e+03   |
| dLoss                   | 0.0494701  |
----------------------------------------
itr #99 | 
Mem: 745.738281
Obtaining samples...
Obtaining samples for iteration 99...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5118, #subsample_inputs: 5118
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.685      |
| AbsLearnSignalNew       | 0.685      |
| AbsLearningOld          | 0.685      |
| AverageDiscountedReturn | 105        |
| AveragePhiLoss          | 9.31775    |
| AveragePolicyStd        | 0.934166   |
| AverageReturn           | 268        |
| Entropy                 | 8.1024     |
| EnvExecTime             | 2.51       |
| ExplainedVariance       | 0.583      |
| Iteration               | 99         |
| ItrTime                 | 17.1       |
| LossAfter               | -0.863891  |
| LossBefore              | -0.805106  |
| MaxReturn               | 374        |
| MeanKL                  | 0.00999301 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 48         |
| NumTrajs                | 28         |
| Perplexity              | 3302.39    |
| PolicyExecTime          | 0.516      |
| ProcessExecTime         | 0.0716     |
| StdReturn               | 94.9       |
| Time                    | 1.78e+03   |
| dLoss                   | 0.0587851  |
----------------------------------------
itr #100 | 
Mem: 745.738281
Obtaining samples...
Obtaining samples for iteration 100...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5028, #subsample_inputs: 5028
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.568      |
| AbsLearnSignalNew       | 0.568      |
| AbsLearningOld          | 0.568      |
| AverageDiscountedReturn | 97.3       |
| AveragePhiLoss          | 9.35755    |
| AveragePolicyStd        | 0.933826   |
| AverageReturn           | 252        |
| Entropy                 | 8.10059    |
| EnvExecTime             | 3.15       |
| ExplainedVariance       | -0.508     |
| Iteration               | 100        |
| ItrTime                 | 17.9       |
| LossAfter               | -0.136011  |
| LossBefore              | -0.0623755 |
| MaxReturn               | 712        |
| MeanKL                  | 0.00989504 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 29.9       |
| NumTrajs                | 25         |
| Perplexity              | 3296.4     |
| PolicyExecTime          | 0.685      |
| ProcessExecTime         | 0.0893     |
| StdReturn               | 137        |
| Time                    | 1.8e+03    |
| dLoss                   | 0.0736356  |
----------------------------------------
itr #101 | 
Mem: 745.738281
Obtaining samples...
Obtaining samples for iteration 101...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5086, #subsample_inputs: 5086
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.708     |
| AbsLearnSignalNew       | 0.708     |
| AbsLearningOld          | 0.708     |
| AverageDiscountedReturn | 109       |
| AveragePhiLoss          | 9.32202   |
| AveragePolicyStd        | 0.931752  |
| AverageReturn           | 280       |
| Entropy                 | 8.08763   |
| EnvExecTime             | 2.49      |
| ExplainedVariance       | 0.591     |
| Iteration               | 101       |
| ItrTime                 | 17.9      |
| LossAfter               | -1.04058  |
| LossBefore              | -0.982439 |
| MaxReturn               | 530       |
| MeanKL                  | 0.00989   |
| MeanKLBefore            | 0.0       |
| MinReturn               | 112       |
| NumTrajs                | 27        |
| Perplexity              | 3253.98   |
| PolicyExecTime          | 0.543     |
| ProcessExecTime         | 0.0678    |
| StdReturn               | 85.6      |
| Time                    | 1.82e+03  |
| dLoss                   | 0.058146  |
---------------------------------------
itr #102 | 
Mem: 745.996094
Obtaining samples...
Obtaining samples for iteration 102...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5034, #subsample_inputs: 5034
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.681      |
| AbsLearnSignalNew       | 0.681      |
| AbsLearningOld          | 0.681      |
| AverageDiscountedReturn | 93         |
| AveragePhiLoss          | 9.71796    |
| AveragePolicyStd        | 0.932232   |
| AverageReturn           | 254        |
| Entropy                 | 8.09059    |
| EnvExecTime             | 2.54       |
| ExplainedVariance       | 0.463      |
| Iteration               | 102        |
| ItrTime                 | 17.5       |
| LossAfter               | -1.58861   |
| LossBefore              | -1.53776   |
| MaxReturn               | 542        |
| MeanKL                  | 0.00646248 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 40.2       |
| NumTrajs                | 23         |
| Perplexity              | 3263.61    |
| PolicyExecTime          | 0.532      |
| ProcessExecTime         | 0.0724     |
| StdReturn               | 138        |
| Time                    | 1.84e+03   |
| dLoss                   | 0.0508484  |
----------------------------------------
itr #103 | 
Mem: 745.996094
Obtaining samples...
Obtaining samples for iteration 103...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5163, #subsample_inputs: 5163
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.736      |
| AbsLearnSignalNew       | 0.736      |
| AbsLearningOld          | 0.736      |
| AverageDiscountedReturn | 105        |
| AveragePhiLoss          | 9.72639    |
| AveragePolicyStd        | 0.932316   |
| AverageReturn           | 272        |
| Entropy                 | 8.09111    |
| EnvExecTime             | 2.74       |
| ExplainedVariance       | 0.575      |
| Iteration               | 103        |
| ItrTime                 | 18.5       |
| LossAfter               | -0.727794  |
| LossBefore              | -0.677342  |
| MaxReturn               | 541        |
| MeanKL                  | 0.00649019 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 19.7       |
| NumTrajs                | 27         |
| Perplexity              | 3265.31    |
| PolicyExecTime          | 0.603      |
| ProcessExecTime         | 0.0826     |
| StdReturn               | 106        |
| Time                    | 1.85e+03   |
| dLoss                   | 0.0504524  |
----------------------------------------
itr #104 | 
Mem: 746.253906
Obtaining samples...
Obtaining samples for iteration 104...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5027, #subsample_inputs: 5027
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.723      |
| AbsLearnSignalNew       | 0.723      |
| AbsLearningOld          | 0.723      |
| AverageDiscountedReturn | 106        |
| AveragePhiLoss          | 9.52922    |
| AveragePolicyStd        | 0.932677   |
| AverageReturn           | 281        |
| Entropy                 | 8.09371    |
| EnvExecTime             | 2.64       |
| ExplainedVariance       | 0.592      |
| Iteration               | 104        |
| ItrTime                 | 17.8       |
| LossAfter               | 0.41214    |
| LossBefore              | 0.471804   |
| MaxReturn               | 499        |
| MeanKL                  | 0.00989102 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 45.1       |
| NumTrajs                | 26         |
| Perplexity              | 3273.8     |
| PolicyExecTime          | 0.551      |
| ProcessExecTime         | 0.0728     |
| StdReturn               | 101        |
| Time                    | 1.87e+03   |
| dLoss                   | 0.0596645  |
----------------------------------------
itr #105 | 
Mem: 747.800781
Obtaining samples...
Obtaining samples for iteration 105...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5172, #subsample_inputs: 5172
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.681     |
| AbsLearnSignalNew       | 0.681     |
| AbsLearningOld          | 0.681     |
| AverageDiscountedReturn | 107       |
| AveragePhiLoss          | 9.59868   |
| AveragePolicyStd        | 0.932334  |
| AverageReturn           | 313       |
| Entropy                 | 8.09155   |
| EnvExecTime             | 2.71      |
| ExplainedVariance       | 0.629     |
| Iteration               | 105       |
| ItrTime                 | 17.5      |
| LossAfter               | 0.0459016 |
| LossBefore              | 0.103459  |
| MaxReturn               | 488       |
| MeanKL                  | 0.0098922 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 28.9      |
| NumTrajs                | 24        |
| Perplexity              | 3266.75   |
| PolicyExecTime          | 0.585     |
| ProcessExecTime         | 0.0781    |
| StdReturn               | 100       |
| Time                    | 1.89e+03  |
| dLoss                   | 0.0575576 |
---------------------------------------
itr #106 | 
Mem: 750.121094
Obtaining samples...
Obtaining samples for iteration 106...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5149, #subsample_inputs: 5149
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.694      |
| AbsLearnSignalNew       | 0.694      |
| AbsLearningOld          | 0.695      |
| AverageDiscountedReturn | 109        |
| AveragePhiLoss          | 10.1767    |
| AveragePolicyStd        | 0.932842   |
| AverageReturn           | 311        |
| Entropy                 | 8.09476    |
| EnvExecTime             | 2.81       |
| ExplainedVariance       | 0.697      |
| Iteration               | 106        |
| ItrTime                 | 18.1       |
| LossAfter               | 0.403381   |
| LossBefore              | 0.453643   |
| MaxReturn               | 500        |
| MeanKL                  | 0.00644584 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 51.8       |
| NumTrajs                | 25         |
| Perplexity              | 3277.27    |
| PolicyExecTime          | 0.627      |
| ProcessExecTime         | 0.0845     |
| StdReturn               | 103        |
| Time                    | 1.91e+03   |
| dLoss                   | 0.0502621  |
----------------------------------------
itr #107 | 
Mem: 750.121094
Obtaining samples...
Obtaining samples for iteration 107...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5026, #subsample_inputs: 5026
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.64       |
| AbsLearnSignalNew       | 0.64       |
| AbsLearningOld          | 0.64       |
| AverageDiscountedReturn | 110        |
| AveragePhiLoss          | 10.5581    |
| AveragePolicyStd        | 0.93203    |
| AverageReturn           | 317        |
| Entropy                 | 8.08944    |
| EnvExecTime             | 2.59       |
| ExplainedVariance       | 0.719      |
| Iteration               | 107        |
| ItrTime                 | 17.7       |
| LossAfter               | -1.3392    |
| LossBefore              | -1.29125   |
| MaxReturn               | 595        |
| MeanKL                  | 0.00651777 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 55.6       |
| NumTrajs                | 24         |
| Perplexity              | 3259.86    |
| PolicyExecTime          | 0.508      |
| ProcessExecTime         | 0.0666     |
| StdReturn               | 103        |
| Time                    | 1.93e+03   |
| dLoss                   | 0.0479501  |
----------------------------------------
itr #108 | 
Mem: 750.121094
Obtaining samples...
Obtaining samples for iteration 108...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5079, #subsample_inputs: 5079
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.616      |
| AbsLearnSignalNew       | 0.616      |
| AbsLearningOld          | 0.616      |
| AverageDiscountedReturn | 111        |
| AveragePhiLoss          | 9.92316    |
| AveragePolicyStd        | 0.930308   |
| AverageReturn           | 296        |
| Entropy                 | 8.07835    |
| EnvExecTime             | 2.78       |
| ExplainedVariance       | 0.659      |
| Iteration               | 108        |
| ItrTime                 | 17.3       |
| LossAfter               | -0.593481  |
| LossBefore              | -0.55011   |
| MaxReturn               | 508        |
| MeanKL                  | 0.00651479 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 82.6       |
| NumTrajs                | 26         |
| Perplexity              | 3223.92    |
| PolicyExecTime          | 0.603      |
| ProcessExecTime         | 0.0807     |
| StdReturn               | 93.7       |
| Time                    | 1.94e+03   |
| dLoss                   | 0.043371   |
----------------------------------------
itr #109 | 
Mem: 750.121094
Obtaining samples...
Obtaining samples for iteration 109...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5063, #subsample_inputs: 5063
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.668      |
| AbsLearnSignalNew       | 0.668      |
| AbsLearningOld          | 0.668      |
| AverageDiscountedReturn | 105        |
| AveragePhiLoss          | 9.59996    |
| AveragePolicyStd        | 0.929067   |
| AverageReturn           | 268        |
| Entropy                 | 8.07019    |
| EnvExecTime             | 2.65       |
| ExplainedVariance       | 0.56       |
| Iteration               | 109        |
| ItrTime                 | 17.9       |
| LossAfter               | -1.07296   |
| LossBefore              | -1.01175   |
| MaxReturn               | 419        |
| MeanKL                  | 0.00994415 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 59.3       |
| NumTrajs                | 26         |
| Perplexity              | 3197.71    |
| PolicyExecTime          | 0.583      |
| ProcessExecTime         | 0.0778     |
| StdReturn               | 82.4       |
| Time                    | 1.96e+03   |
| dLoss                   | 0.0612091  |
----------------------------------------
itr #110 | 
Mem: 750.121094
Obtaining samples...
Obtaining samples for iteration 110...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5081, #subsample_inputs: 5081
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.617      |
| AbsLearnSignalNew       | 0.617      |
| AbsLearningOld          | 0.617      |
| AverageDiscountedReturn | 112        |
| AveragePhiLoss          | 9.29701    |
| AveragePolicyStd        | 0.928274   |
| AverageReturn           | 298        |
| Entropy                 | 8.06523    |
| EnvExecTime             | 2.58       |
| ExplainedVariance       | 0.51       |
| Iteration               | 110        |
| ItrTime                 | 17.5       |
| LossAfter               | -0.65231   |
| LossBefore              | -0.602877  |
| MaxReturn               | 516        |
| MeanKL                  | 0.00646068 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 165        |
| NumTrajs                | 26         |
| Perplexity              | 3181.88    |
| PolicyExecTime          | 0.526      |
| ProcessExecTime         | 0.0681     |
| StdReturn               | 79.6       |
| Time                    | 1.98e+03   |
| dLoss                   | 0.049433   |
----------------------------------------
itr #111 | 
Mem: 750.121094
Obtaining samples...
Obtaining samples for iteration 111...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5194, #subsample_inputs: 5194
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.652      |
| AbsLearnSignalNew       | 0.652      |
| AbsLearningOld          | 0.651      |
| AverageDiscountedReturn | 108        |
| AveragePhiLoss          | 10.036     |
| AveragePolicyStd        | 0.926794   |
| AverageReturn           | 307        |
| Entropy                 | 8.05565    |
| EnvExecTime             | 2.97       |
| ExplainedVariance       | 0.535      |
| Iteration               | 111        |
| ItrTime                 | 18         |
| LossAfter               | -1.25136   |
| LossBefore              | -1.19921   |
| MaxReturn               | 679        |
| MeanKL                  | 0.00642958 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 42.4       |
| NumTrajs                | 24         |
| Perplexity              | 3151.57    |
| PolicyExecTime          | 0.64       |
| ProcessExecTime         | 0.0866     |
| StdReturn               | 132        |
| Time                    | 2e+03      |
| dLoss                   | 0.0521508  |
----------------------------------------
itr #112 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 112...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5191, #subsample_inputs: 5191
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.756      |
| AbsLearnSignalNew       | 0.756      |
| AbsLearningOld          | 0.756      |
| AverageDiscountedReturn | 114        |
| AveragePhiLoss          | 9.45911    |
| AveragePolicyStd        | 0.925873   |
| AverageReturn           | 351        |
| Entropy                 | 8.04972    |
| EnvExecTime             | 2.99       |
| ExplainedVariance       | 0.789      |
| Iteration               | 112        |
| ItrTime                 | 18.5       |
| LossAfter               | -1.35146   |
| LossBefore              | -1.30332   |
| MaxReturn               | 644        |
| MeanKL                  | 0.00650851 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 212        |
| NumTrajs                | 23         |
| Perplexity              | 3132.91    |
| PolicyExecTime          | 0.613      |
| ProcessExecTime         | 0.0805     |
| StdReturn               | 98.4       |
| Time                    | 2.02e+03   |
| dLoss                   | 0.0481361  |
----------------------------------------
itr #113 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 113...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5032, #subsample_inputs: 5032
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.595      |
| AbsLearnSignalNew       | 0.595      |
| AbsLearningOld          | 0.594      |
| AverageDiscountedReturn | 115        |
| AveragePhiLoss          | 9.86338    |
| AveragePolicyStd        | 0.92414    |
| AverageReturn           | 307        |
| Entropy                 | 8.03862    |
| EnvExecTime             | 2.62       |
| ExplainedVariance       | 0.602      |
| Iteration               | 113        |
| ItrTime                 | 17.4       |
| LossAfter               | -2.12922   |
| LossBefore              | -2.08177   |
| MaxReturn               | 473        |
| MeanKL                  | 0.00647549 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 169        |
| NumTrajs                | 26         |
| Perplexity              | 3098.33    |
| PolicyExecTime          | 0.528      |
| ProcessExecTime         | 0.0702     |
| StdReturn               | 65.9       |
| Time                    | 2.03e+03   |
| dLoss                   | 0.0474501  |
----------------------------------------
itr #114 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 114...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5147, #subsample_inputs: 5147
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.67       |
| AbsLearnSignalNew       | 0.67       |
| AbsLearningOld          | 0.67       |
| AverageDiscountedReturn | 110        |
| AveragePhiLoss          | 9.81912    |
| AveragePolicyStd        | 0.923672   |
| AverageReturn           | 286        |
| Entropy                 | 8.03523    |
| EnvExecTime             | 2.89       |
| ExplainedVariance       | 0.578      |
| Iteration               | 114        |
| ItrTime                 | 17.7       |
| LossAfter               | -0.289913  |
| LossBefore              | -0.2418    |
| MaxReturn               | 545        |
| MeanKL                  | 0.00647024 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 46.9       |
| NumTrajs                | 28         |
| Perplexity              | 3087.86    |
| PolicyExecTime          | 0.606      |
| ProcessExecTime         | 0.0837     |
| StdReturn               | 98.4       |
| Time                    | 2.05e+03   |
| dLoss                   | 0.0481134  |
----------------------------------------
itr #115 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 115...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5130, #subsample_inputs: 5130
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.689      |
| AbsLearnSignalNew       | 0.689      |
| AbsLearningOld          | 0.689      |
| AverageDiscountedReturn | 116        |
| AveragePhiLoss          | 10.3446    |
| AveragePolicyStd        | 0.922079   |
| AverageReturn           | 299        |
| Entropy                 | 8.02459    |
| EnvExecTime             | 2.8        |
| ExplainedVariance       | 0.74       |
| Iteration               | 115        |
| ItrTime                 | 18.3       |
| LossAfter               | 0.546649   |
| LossBefore              | 0.607953   |
| MaxReturn               | 398        |
| MeanKL                  | 0.00989854 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 158        |
| NumTrajs                | 28         |
| Perplexity              | 3055.18    |
| PolicyExecTime          | 0.599      |
| ProcessExecTime         | 0.0787     |
| StdReturn               | 60.3       |
| Time                    | 2.07e+03   |
| dLoss                   | 0.0613039  |
----------------------------------------
itr #116 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 116...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5259, #subsample_inputs: 5259
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.663      |
| AbsLearnSignalNew       | 0.663      |
| AbsLearningOld          | 0.663      |
| AverageDiscountedReturn | 98.5       |
| AveragePhiLoss          | 10.132     |
| AveragePolicyStd        | 0.92156    |
| AverageReturn           | 272        |
| Entropy                 | 8.02164    |
| EnvExecTime             | 2.61       |
| ExplainedVariance       | 0.475      |
| Iteration               | 116        |
| ItrTime                 | 17.8       |
| LossAfter               | 1.48567    |
| LossBefore              | 1.54514    |
| MaxReturn               | 501        |
| MeanKL                  | 0.00999894 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 41.9       |
| NumTrajs                | 26         |
| Perplexity              | 3046.15    |
| PolicyExecTime          | 0.535      |
| ProcessExecTime         | 0.0745     |
| StdReturn               | 134        |
| Time                    | 2.09e+03   |
| dLoss                   | 0.059467   |
----------------------------------------
itr #117 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 117...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5077, #subsample_inputs: 5077
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.681      |
| AbsLearnSignalNew       | 0.681      |
| AbsLearningOld          | 0.681      |
| AverageDiscountedReturn | 103        |
| AveragePhiLoss          | 10.1993    |
| AveragePolicyStd        | 0.919664   |
| AverageReturn           | 281        |
| Entropy                 | 8.00911    |
| EnvExecTime             | 2.83       |
| ExplainedVariance       | 0.468      |
| Iteration               | 117        |
| ItrTime                 | 17.6       |
| LossAfter               | 0.237077   |
| LossBefore              | 0.284225   |
| MaxReturn               | 556        |
| MeanKL                  | 0.00642561 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 58         |
| NumTrajs                | 24         |
| Perplexity              | 3008.23    |
| PolicyExecTime          | 0.602      |
| ProcessExecTime         | 0.0825     |
| StdReturn               | 127        |
| Time                    | 2.1e+03    |
| dLoss                   | 0.0471478  |
----------------------------------------
itr #118 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 118...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5380, #subsample_inputs: 5380
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.734      |
| AbsLearnSignalNew       | 0.734      |
| AbsLearningOld          | 0.734      |
| AverageDiscountedReturn | 105        |
| AveragePhiLoss          | 10.2685    |
| AveragePolicyStd        | 0.918088   |
| AverageReturn           | 268        |
| Entropy                 | 7.99852    |
| EnvExecTime             | 2.98       |
| ExplainedVariance       | 0.529      |
| Iteration               | 118        |
| ItrTime                 | 19         |
| LossAfter               | 0.784015   |
| LossBefore              | 0.842707   |
| MaxReturn               | 471        |
| MeanKL                  | 0.00988314 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 54.2       |
| NumTrajs                | 28         |
| Perplexity              | 2976.56    |
| PolicyExecTime          | 0.614      |
| ProcessExecTime         | 0.0811     |
| StdReturn               | 112        |
| Time                    | 2.12e+03   |
| dLoss                   | 0.0586921  |
----------------------------------------
itr #119 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 119...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5068, #subsample_inputs: 5068
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.659      |
| AbsLearnSignalNew       | 0.659      |
| AbsLearningOld          | 0.659      |
| AverageDiscountedReturn | 113        |
| AveragePhiLoss          | 9.64818    |
| AveragePolicyStd        | 0.91915    |
| AverageReturn           | 310        |
| Entropy                 | 8.00591    |
| EnvExecTime             | 2.48       |
| ExplainedVariance       | 0.579      |
| Iteration               | 119        |
| ItrTime                 | 17.4       |
| LossAfter               | -0.649897  |
| LossBefore              | -0.587132  |
| MaxReturn               | 466        |
| MeanKL                  | 0.00993605 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 197        |
| NumTrajs                | 25         |
| Perplexity              | 2998.64    |
| PolicyExecTime          | 0.501      |
| ProcessExecTime         | 0.0661     |
| StdReturn               | 69.7       |
| Time                    | 2.14e+03   |
| dLoss                   | 0.0627651  |
----------------------------------------
itr #120 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 120...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5162, #subsample_inputs: 5162
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.72       |
| AbsLearnSignalNew       | 0.72       |
| AbsLearningOld          | 0.719      |
| AverageDiscountedReturn | 112        |
| AveragePhiLoss          | 10.1586    |
| AveragePolicyStd        | 0.918822   |
| AverageReturn           | 306        |
| Entropy                 | 8.00401    |
| EnvExecTime             | 2.97       |
| ExplainedVariance       | 0.559      |
| Iteration               | 120        |
| ItrTime                 | 17.8       |
| LossAfter               | 0.383297   |
| LossBefore              | 0.440682   |
| MaxReturn               | 568        |
| MeanKL                  | 0.00974791 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 114        |
| NumTrajs                | 25         |
| Perplexity              | 2992.93    |
| PolicyExecTime          | 0.639      |
| ProcessExecTime         | 0.0861     |
| StdReturn               | 109        |
| Time                    | 2.16e+03   |
| dLoss                   | 0.0573853  |
----------------------------------------
itr #121 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 121...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5011, #subsample_inputs: 5011
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.655      |
| AbsLearnSignalNew       | 0.655      |
| AbsLearningOld          | 0.655      |
| AverageDiscountedReturn | 106        |
| AveragePhiLoss          | 10.0491    |
| AveragePolicyStd        | 0.920217   |
| AverageReturn           | 302        |
| Entropy                 | 8.01313    |
| EnvExecTime             | 2.66       |
| ExplainedVariance       | 0.536      |
| Iteration               | 121        |
| ItrTime                 | 17.9       |
| LossAfter               | 0.630021   |
| LossBefore              | 0.691956   |
| MaxReturn               | 500        |
| MeanKL                  | 0.00982235 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 41.5       |
| NumTrajs                | 23         |
| Perplexity              | 3020.36    |
| PolicyExecTime          | 0.568      |
| ProcessExecTime         | 0.0752     |
| StdReturn               | 98.5       |
| Time                    | 2.18e+03   |
| dLoss                   | 0.0619349  |
----------------------------------------
itr #122 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 122...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5016, #subsample_inputs: 5016
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.694      |
| AbsLearnSignalNew       | 0.694      |
| AbsLearningOld          | 0.694      |
| AverageDiscountedReturn | 107        |
| AveragePhiLoss          | 10.2859    |
| AveragePolicyStd        | 0.92175    |
| AverageReturn           | 277        |
| Entropy                 | 8.02319    |
| EnvExecTime             | 2.54       |
| ExplainedVariance       | 0.628      |
| Iteration               | 122        |
| ItrTime                 | 17.2       |
| LossAfter               | 1.11143    |
| LossBefore              | 1.17375    |
| MaxReturn               | 452        |
| MeanKL                  | 0.00999288 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 37.9       |
| NumTrajs                | 27         |
| Perplexity              | 3050.91    |
| PolicyExecTime          | 0.512      |
| ProcessExecTime         | 0.0709     |
| StdReturn               | 97.5       |
| Time                    | 2.19e+03   |
| dLoss                   | 0.06232    |
----------------------------------------
itr #123 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 123...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5147, #subsample_inputs: 5147
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.644      |
| AbsLearnSignalNew       | 0.644      |
| AbsLearningOld          | 0.644      |
| AverageDiscountedReturn | 108        |
| AveragePhiLoss          | 9.64731    |
| AveragePolicyStd        | 0.925041   |
| AverageReturn           | 288        |
| Entropy                 | 8.04441    |
| EnvExecTime             | 2.82       |
| ExplainedVariance       | 0.476      |
| Iteration               | 123        |
| ItrTime                 | 18         |
| LossAfter               | 0.639558   |
| LossBefore              | 0.695355   |
| MaxReturn               | 581        |
| MeanKL                  | 0.00986511 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 76.5       |
| NumTrajs                | 26         |
| Perplexity              | 3116.33    |
| PolicyExecTime          | 0.599      |
| ProcessExecTime         | 0.0837     |
| StdReturn               | 102        |
| Time                    | 2.21e+03   |
| dLoss                   | 0.0557969  |
----------------------------------------
itr #124 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 124...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5062, #subsample_inputs: 5062
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.764      |
| AbsLearnSignalNew       | 0.764      |
| AbsLearningOld          | 0.764      |
| AverageDiscountedReturn | 113        |
| AveragePhiLoss          | 9.90658    |
| AveragePolicyStd        | 0.926548   |
| AverageReturn           | 329        |
| Entropy                 | 8.05424    |
| EnvExecTime             | 2.48       |
| ExplainedVariance       | 0.723      |
| Iteration               | 124        |
| ItrTime                 | 17.5       |
| LossAfter               | 0.857536   |
| LossBefore              | 0.920589   |
| MaxReturn               | 443        |
| MeanKL                  | 0.00998447 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 230        |
| NumTrajs                | 24         |
| Perplexity              | 3147.12    |
| PolicyExecTime          | 0.531      |
| ProcessExecTime         | 0.0688     |
| StdReturn               | 58.1       |
| Time                    | 2.23e+03   |
| dLoss                   | 0.0630527  |
----------------------------------------
itr #125 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 125...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5156, #subsample_inputs: 5156
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.568      |
| AbsLearnSignalNew       | 0.568      |
| AbsLearningOld          | 0.568      |
| AverageDiscountedReturn | 111        |
| AveragePhiLoss          | 9.59653    |
| AveragePolicyStd        | 0.92559    |
| AverageReturn           | 310        |
| Entropy                 | 8.04811    |
| EnvExecTime             | 2.57       |
| ExplainedVariance       | 0.327      |
| Iteration               | 125        |
| ItrTime                 | 18         |
| LossAfter               | 0.317352   |
| LossBefore              | 0.360477   |
| MaxReturn               | 537        |
| MeanKL                  | 0.00650283 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 66.4       |
| NumTrajs                | 24         |
| Perplexity              | 3127.87    |
| PolicyExecTime          | 0.535      |
| ProcessExecTime         | 0.0721     |
| StdReturn               | 91.3       |
| Time                    | 2.25e+03   |
| dLoss                   | 0.0431244  |
----------------------------------------
itr #126 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 126...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5015, #subsample_inputs: 5015
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.715     |
| AbsLearnSignalNew       | 0.715     |
| AbsLearningOld          | 0.715     |
| AverageDiscountedReturn | 103       |
| AveragePhiLoss          | 9.83109   |
| AveragePolicyStd        | 0.925121  |
| AverageReturn           | 257       |
| Entropy                 | 8.04513   |
| EnvExecTime             | 2.67      |
| ExplainedVariance       | 0.579     |
| Iteration               | 126       |
| ItrTime                 | 17.8      |
| LossAfter               | 0.0882941 |
| LossBefore              | 0.149542  |
| MaxReturn               | 375       |
| MeanKL                  | 0.0097964 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 34.8      |
| NumTrajs                | 26        |
| Perplexity              | 3118.57   |
| PolicyExecTime          | 0.577     |
| ProcessExecTime         | 0.079     |
| StdReturn               | 96.9      |
| Time                    | 2.27e+03  |
| dLoss                   | 0.0612479 |
---------------------------------------
itr #127 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 127...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5165, #subsample_inputs: 5165
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.713      |
| AbsLearnSignalNew       | 0.713      |
| AbsLearningOld          | 0.714      |
| AverageDiscountedReturn | 107        |
| AveragePhiLoss          | 9.6115     |
| AveragePolicyStd        | 0.92539    |
| AverageReturn           | 284        |
| Entropy                 | 8.04679    |
| EnvExecTime             | 2.42       |
| ExplainedVariance       | 0.44       |
| Iteration               | 127        |
| ItrTime                 | 18         |
| LossAfter               | 0.0163775  |
| LossBefore              | 0.0646865  |
| MaxReturn               | 517        |
| MeanKL                  | 0.00642392 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 41.2       |
| NumTrajs                | 27         |
| Perplexity              | 3123.75    |
| PolicyExecTime          | 0.476      |
| ProcessExecTime         | 0.0641     |
| StdReturn               | 106        |
| Time                    | 2.28e+03   |
| dLoss                   | 0.048309   |
----------------------------------------
itr #128 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 128...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5028, #subsample_inputs: 5028
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.703     |
| AbsLearnSignalNew       | 0.703     |
| AbsLearningOld          | 0.703     |
| AverageDiscountedReturn | 110       |
| AveragePhiLoss          | 9.41523   |
| AveragePolicyStd        | 0.924404  |
| AverageReturn           | 331       |
| Entropy                 | 8.04049   |
| EnvExecTime             | 2.74      |
| ExplainedVariance       | 0.645     |
| Iteration               | 128       |
| ItrTime                 | 17.1      |
| LossAfter               | -0.610373 |
| LossBefore              | -0.5499   |
| MaxReturn               | 521       |
| MeanKL                  | 0.0098641 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 74.4      |
| NumTrajs                | 23        |
| Perplexity              | 3104.14   |
| PolicyExecTime          | 0.58      |
| ProcessExecTime         | 0.0777    |
| StdReturn               | 97        |
| Time                    | 2.3e+03   |
| dLoss                   | 0.060473  |
---------------------------------------
itr #129 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 129...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5110, #subsample_inputs: 5110
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.695      |
| AbsLearnSignalNew       | 0.695      |
| AbsLearningOld          | 0.695      |
| AverageDiscountedReturn | 112        |
| AveragePhiLoss          | 9.68837    |
| AveragePolicyStd        | 0.924806   |
| AverageReturn           | 282        |
| Entropy                 | 8.04292    |
| EnvExecTime             | 2.63       |
| ExplainedVariance       | 0.705      |
| Iteration               | 129        |
| ItrTime                 | 18.2       |
| LossAfter               | -0.448859  |
| LossBefore              | -0.400428  |
| MaxReturn               | 434        |
| MeanKL                  | 0.00653637 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 41.3       |
| NumTrajs                | 29         |
| Perplexity              | 3111.7     |
| PolicyExecTime          | 0.587      |
| ProcessExecTime         | 0.0786     |
| StdReturn               | 84.7       |
| Time                    | 2.32e+03   |
| dLoss                   | 0.0484313  |
----------------------------------------
itr #130 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 130...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5072, #subsample_inputs: 5072
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.696      |
| AbsLearnSignalNew       | 0.696      |
| AbsLearningOld          | 0.697      |
| AverageDiscountedReturn | 110        |
| AveragePhiLoss          | 10.13      |
| AveragePolicyStd        | 0.923386   |
| AverageReturn           | 291        |
| Entropy                 | 8.03346    |
| EnvExecTime             | 2.36       |
| ExplainedVariance       | 0.656      |
| Iteration               | 130        |
| ItrTime                 | 17.2       |
| LossAfter               | 0.260989   |
| LossBefore              | 0.324409   |
| MaxReturn               | 495        |
| MeanKL                  | 0.00998816 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 72.7       |
| NumTrajs                | 27         |
| Perplexity              | 3082.4     |
| PolicyExecTime          | 0.475      |
| ProcessExecTime         | 0.064      |
| StdReturn               | 86.4       |
| Time                    | 2.34e+03   |
| dLoss                   | 0.06342    |
----------------------------------------
itr #131 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 131...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5099, #subsample_inputs: 5099
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.668      |
| AbsLearnSignalNew       | 0.668      |
| AbsLearningOld          | 0.668      |
| AverageDiscountedReturn | 105        |
| AveragePhiLoss          | 10.195     |
| AveragePolicyStd        | 0.923387   |
| AverageReturn           | 270        |
| Entropy                 | 8.03357    |
| EnvExecTime             | 2.8        |
| ExplainedVariance       | 0.489      |
| Iteration               | 131        |
| ItrTime                 | 17.6       |
| LossAfter               | -0.203794  |
| LossBefore              | -0.142565  |
| MaxReturn               | 609        |
| MeanKL                  | 0.00981191 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 40.7       |
| NumTrajs                | 27         |
| Perplexity              | 3082.73    |
| PolicyExecTime          | 0.588      |
| ProcessExecTime         | 0.0815     |
| StdReturn               | 110        |
| Time                    | 2.36e+03   |
| dLoss                   | 0.0612286  |
----------------------------------------
itr #132 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 132...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5045, #subsample_inputs: 5045
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.698      |
| AbsLearnSignalNew       | 0.698      |
| AbsLearningOld          | 0.697      |
| AverageDiscountedReturn | 108        |
| AveragePhiLoss          | 10.0941    |
| AveragePolicyStd        | 0.922293   |
| AverageReturn           | 289        |
| Entropy                 | 8.02657    |
| EnvExecTime             | 2.76       |
| ExplainedVariance       | 0.58       |
| Iteration               | 132        |
| ItrTime                 | 18         |
| LossAfter               | -1.03312   |
| LossBefore              | -0.986149  |
| MaxReturn               | 501        |
| MeanKL                  | 0.00644303 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 46.7       |
| NumTrajs                | 27         |
| Perplexity              | 3061.22    |
| PolicyExecTime          | 0.57       |
| ProcessExecTime         | 0.0739     |
| StdReturn               | 108        |
| Time                    | 2.37e+03   |
| dLoss                   | 0.0469738  |
----------------------------------------
itr #133 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 133...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5098, #subsample_inputs: 5098
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.696      |
| AbsLearnSignalNew       | 0.696      |
| AbsLearningOld          | 0.696      |
| AverageDiscountedReturn | 113        |
| AveragePhiLoss          | 9.72215    |
| AveragePolicyStd        | 0.921053   |
| AverageReturn           | 328        |
| Entropy                 | 8.01865    |
| EnvExecTime             | 2.48       |
| ExplainedVariance       | 0.685      |
| Iteration               | 133        |
| ItrTime                 | 17.2       |
| LossAfter               | -0.612556  |
| LossBefore              | -0.554585  |
| MaxReturn               | 503        |
| MeanKL                  | 0.00999824 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 194        |
| NumTrajs                | 24         |
| Perplexity              | 3037.07    |
| PolicyExecTime          | 0.511      |
| ProcessExecTime         | 0.0696     |
| StdReturn               | 85.2       |
| Time                    | 2.39e+03   |
| dLoss                   | 0.057971   |
----------------------------------------
itr #134 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 134...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5081, #subsample_inputs: 5081
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.677      |
| AbsLearnSignalNew       | 0.677      |
| AbsLearningOld          | 0.677      |
| AverageDiscountedReturn | 101        |
| AveragePhiLoss          | 10.0805    |
| AveragePolicyStd        | 0.921151   |
| AverageReturn           | 253        |
| Entropy                 | 8.01892    |
| EnvExecTime             | 2.96       |
| ExplainedVariance       | 0.52       |
| Iteration               | 134        |
| ItrTime                 | 17.9       |
| LossAfter               | -0.685632  |
| LossBefore              | -0.640751  |
| MaxReturn               | 475        |
| MeanKL                  | 0.00641193 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 39.7       |
| NumTrajs                | 28         |
| Perplexity              | 3037.9     |
| PolicyExecTime          | 0.635      |
| ProcessExecTime         | 0.0847     |
| StdReturn               | 124        |
| Time                    | 2.41e+03   |
| dLoss                   | 0.0448813  |
----------------------------------------
itr #135 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 135...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5083, #subsample_inputs: 5083
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.667      |
| AbsLearnSignalNew       | 0.667      |
| AbsLearningOld          | 0.667      |
| AverageDiscountedReturn | 105        |
| AveragePhiLoss          | 10.1696    |
| AveragePolicyStd        | 0.921035   |
| AverageReturn           | 287        |
| Entropy                 | 8.01817    |
| EnvExecTime             | 2.55       |
| ExplainedVariance       | 0.462      |
| Iteration               | 135        |
| ItrTime                 | 17.9       |
| LossAfter               | -0.0153508 |
| LossBefore              | 0.0321194  |
| MaxReturn               | 466        |
| MeanKL                  | 0.0064917  |
| MeanKLBefore            | 0.0        |
| MinReturn               | 45.6       |
| NumTrajs                | 25         |
| Perplexity              | 3035.6     |
| PolicyExecTime          | 0.523      |
| ProcessExecTime         | 0.0658     |
| StdReturn               | 108        |
| Time                    | 2.43e+03   |
| dLoss                   | 0.0474702  |
----------------------------------------
itr #136 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 136...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5264, #subsample_inputs: 5264
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.698      |
| AbsLearnSignalNew       | 0.698      |
| AbsLearningOld          | 0.698      |
| AverageDiscountedReturn | 109        |
| AveragePhiLoss          | 10.2868    |
| AveragePolicyStd        | 0.917138   |
| AverageReturn           | 305        |
| Entropy                 | 7.99221    |
| EnvExecTime             | 2.68       |
| ExplainedVariance       | 0.632      |
| Iteration               | 136        |
| ItrTime                 | 17.6       |
| LossAfter               | 0.929037   |
| LossBefore              | 0.978398   |
| MaxReturn               | 486        |
| MeanKL                  | 0.00654905 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 3.12       |
| NumTrajs                | 27         |
| Perplexity              | 2957.83    |
| PolicyExecTime          | 0.564      |
| ProcessExecTime         | 0.0776     |
| StdReturn               | 103        |
| Time                    | 2.44e+03   |
| dLoss                   | 0.0493612  |
----------------------------------------
itr #137 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 137...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5179, #subsample_inputs: 5179
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.677      |
| AbsLearnSignalNew       | 0.677      |
| AbsLearningOld          | 0.677      |
| AverageDiscountedReturn | 107        |
| AveragePhiLoss          | 10.0836    |
| AveragePolicyStd        | 0.914011   |
| AverageReturn           | 327        |
| Entropy                 | 7.97166    |
| EnvExecTime             | 2.92       |
| ExplainedVariance       | 0.529      |
| Iteration               | 137        |
| ItrTime                 | 18.6       |
| LossAfter               | 1.12018    |
| LossBefore              | 1.17563    |
| MaxReturn               | 607        |
| MeanKL                  | 0.00997582 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 80.3       |
| NumTrajs                | 22         |
| Perplexity              | 2897.65    |
| PolicyExecTime          | 0.642      |
| ProcessExecTime         | 0.0855     |
| StdReturn               | 115        |
| Time                    | 2.46e+03   |
| dLoss                   | 0.0554469  |
----------------------------------------
itr #138 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 138...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5261, #subsample_inputs: 5261
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.739      |
| AbsLearnSignalNew       | 0.739      |
| AbsLearningOld          | 0.739      |
| AverageDiscountedReturn | 113        |
| AveragePhiLoss          | 10.2657    |
| AveragePolicyStd        | 0.915116   |
| AverageReturn           | 297        |
| Entropy                 | 7.97881    |
| EnvExecTime             | 2.55       |
| ExplainedVariance       | 0.639      |
| Iteration               | 138        |
| ItrTime                 | 17.8       |
| LossAfter               | 1.07665    |
| LossBefore              | 1.12543    |
| MaxReturn               | 516        |
| MeanKL                  | 0.00642229 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 128        |
| NumTrajs                | 27         |
| Perplexity              | 2918.45    |
| PolicyExecTime          | 0.494      |
| ProcessExecTime         | 0.0681     |
| StdReturn               | 87.2       |
| Time                    | 2.48e+03   |
| dLoss                   | 0.0487801  |
----------------------------------------
itr #139 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 139...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5148, #subsample_inputs: 5148
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.654      |
| AbsLearnSignalNew       | 0.654      |
| AbsLearningOld          | 0.654      |
| AverageDiscountedReturn | 111        |
| AveragePhiLoss          | 10.4601    |
| AveragePolicyStd        | 0.915628   |
| AverageReturn           | 298        |
| Entropy                 | 7.98225    |
| EnvExecTime             | 2.82       |
| ExplainedVariance       | 0.615      |
| Iteration               | 139        |
| ItrTime                 | 17.5       |
| LossAfter               | -0.567108  |
| LossBefore              | -0.51703   |
| MaxReturn               | 447        |
| MeanKL                  | 0.00649151 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 48.6       |
| NumTrajs                | 27         |
| Perplexity              | 2928.53    |
| PolicyExecTime          | 0.618      |
| ProcessExecTime         | 0.0861     |
| StdReturn               | 88.7       |
| Time                    | 2.5e+03    |
| dLoss                   | 0.0500783  |
----------------------------------------
itr #140 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 140...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5053, #subsample_inputs: 5053
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.633      |
| AbsLearnSignalNew       | 0.633      |
| AbsLearningOld          | 0.633      |
| AverageDiscountedReturn | 113        |
| AveragePhiLoss          | 9.69507    |
| AveragePolicyStd        | 0.91786    |
| AverageReturn           | 316        |
| Entropy                 | 7.99686    |
| EnvExecTime             | 2.57       |
| ExplainedVariance       | 0.586      |
| Iteration               | 140        |
| ItrTime                 | 17.7       |
| LossAfter               | 0.524728   |
| LossBefore              | 0.58128    |
| MaxReturn               | 506        |
| MeanKL                  | 0.00999472 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 124        |
| NumTrajs                | 24         |
| Perplexity              | 2971.6     |
| PolicyExecTime          | 0.54       |
| ProcessExecTime         | 0.0708     |
| StdReturn               | 83         |
| Time                    | 2.52e+03   |
| dLoss                   | 0.0565524  |
----------------------------------------
itr #141 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 141...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5101, #subsample_inputs: 5101
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.669      |
| AbsLearnSignalNew       | 0.669      |
| AbsLearningOld          | 0.669      |
| AverageDiscountedReturn | 103        |
| AveragePhiLoss          | 10.4004    |
| AveragePolicyStd        | 0.919431   |
| AverageReturn           | 288        |
| Entropy                 | 8.00628    |
| EnvExecTime             | 2.59       |
| ExplainedVariance       | 0.462      |
| Iteration               | 141        |
| ItrTime                 | 17.2       |
| LossAfter               | 0.381762   |
| LossBefore              | 0.440173   |
| MaxReturn               | 489        |
| MeanKL                  | 0.00992639 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 14.1       |
| NumTrajs                | 26         |
| Perplexity              | 2999.75    |
| PolicyExecTime          | 0.568      |
| ProcessExecTime         | 0.0747     |
| StdReturn               | 120        |
| Time                    | 2.53e+03   |
| dLoss                   | 0.0584117  |
----------------------------------------
itr #142 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 142...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5021, #subsample_inputs: 5021
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.689      |
| AbsLearnSignalNew       | 0.689      |
| AbsLearningOld          | 0.689      |
| AverageDiscountedReturn | 105        |
| AveragePhiLoss          | 10.5287    |
| AveragePolicyStd        | 0.919142   |
| AverageReturn           | 298        |
| Entropy                 | 8.00467    |
| EnvExecTime             | 2.68       |
| ExplainedVariance       | 0.603      |
| Iteration               | 142        |
| ItrTime                 | 17.7       |
| LossAfter               | -0.636886  |
| LossBefore              | -0.577045  |
| MaxReturn               | 535        |
| MeanKL                  | 0.00985411 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 6.22       |
| NumTrajs                | 25         |
| Perplexity              | 2994.91    |
| PolicyExecTime          | 0.599      |
| ProcessExecTime         | 0.0775     |
| StdReturn               | 117        |
| Time                    | 2.55e+03   |
| dLoss                   | 0.059841   |
----------------------------------------
itr #143 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 143...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5083, #subsample_inputs: 5083
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.679      |
| AbsLearnSignalNew       | 0.679      |
| AbsLearningOld          | 0.679      |
| AverageDiscountedReturn | 107        |
| AveragePhiLoss          | 9.80629    |
| AveragePolicyStd        | 0.917933   |
| AverageReturn           | 299        |
| Entropy                 | 7.99654    |
| EnvExecTime             | 2.6        |
| ExplainedVariance       | 0.597      |
| Iteration               | 143        |
| ItrTime                 | 17.3       |
| LossAfter               | -0.417582  |
| LossBefore              | -0.357745  |
| MaxReturn               | 466        |
| MeanKL                  | 0.00994629 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 62.8       |
| NumTrajs                | 25         |
| Perplexity              | 2970.66    |
| PolicyExecTime          | 0.542      |
| ProcessExecTime         | 0.0728     |
| StdReturn               | 96.9       |
| Time                    | 2.57e+03   |
| dLoss                   | 0.0598368  |
----------------------------------------
itr #144 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 144...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5033, #subsample_inputs: 5033
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.664      |
| AbsLearnSignalNew       | 0.664      |
| AbsLearningOld          | 0.664      |
| AverageDiscountedReturn | 105        |
| AveragePhiLoss          | 10.2849    |
| AveragePolicyStd        | 0.918529   |
| AverageReturn           | 284        |
| Entropy                 | 7.99996    |
| EnvExecTime             | 2.78       |
| ExplainedVariance       | 0.416      |
| Iteration               | 144        |
| ItrTime                 | 17.6       |
| LossAfter               | 0.616083   |
| LossBefore              | 0.677321   |
| MaxReturn               | 508        |
| MeanKL                  | 0.00979301 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 61.7       |
| NumTrajs                | 24         |
| Perplexity              | 2980.83    |
| PolicyExecTime          | 0.598      |
| ProcessExecTime         | 0.0823     |
| StdReturn               | 100        |
| Time                    | 2.59e+03   |
| dLoss                   | 0.0612386  |
----------------------------------------
itr #145 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 145...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5091, #subsample_inputs: 5091
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.689      |
| AbsLearnSignalNew       | 0.689      |
| AbsLearningOld          | 0.689      |
| AverageDiscountedReturn | 106        |
| AveragePhiLoss          | 9.75806    |
| AveragePolicyStd        | 0.919212   |
| AverageReturn           | 287        |
| Entropy                 | 8.0047     |
| EnvExecTime             | 2.47       |
| ExplainedVariance       | 0.591      |
| Iteration               | 145        |
| ItrTime                 | 17.7       |
| LossAfter               | -0.106542  |
| LossBefore              | -0.0472887 |
| MaxReturn               | 438        |
| MeanKL                  | 0.00991578 |
| MeanKLBefore            | 0.0        |
| MinReturn               | -2.04      |
| NumTrajs                | 28         |
| Perplexity              | 2995.0     |
| PolicyExecTime          | 0.519      |
| ProcessExecTime         | 0.0684     |
| StdReturn               | 102        |
| Time                    | 2.6e+03    |
| dLoss                   | 0.059253   |
----------------------------------------
itr #146 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 146...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5053, #subsample_inputs: 5053
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.634      |
| AbsLearnSignalNew       | 0.634      |
| AbsLearningOld          | 0.634      |
| AverageDiscountedReturn | 113        |
| AveragePhiLoss          | 9.58426    |
| AveragePolicyStd        | 0.915891   |
| AverageReturn           | 315        |
| Entropy                 | 7.98276    |
| EnvExecTime             | 2.81       |
| ExplainedVariance       | 0.623      |
| Iteration               | 146        |
| ItrTime                 | 17.5       |
| LossAfter               | 0.284559   |
| LossBefore              | 0.330339   |
| MaxReturn               | 539        |
| MeanKL                  | 0.00640992 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 47.2       |
| NumTrajs                | 25         |
| Perplexity              | 2930.02    |
| PolicyExecTime          | 0.596      |
| ProcessExecTime         | 0.0822     |
| StdReturn               | 101        |
| Time                    | 2.62e+03   |
| dLoss                   | 0.045779   |
----------------------------------------
itr #147 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 147...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5074, #subsample_inputs: 5074
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.668      |
| AbsLearnSignalNew       | 0.668      |
| AbsLearningOld          | 0.668      |
| AverageDiscountedReturn | 113        |
| AveragePhiLoss          | 10.5544    |
| AveragePolicyStd        | 0.917701   |
| AverageReturn           | 307        |
| Entropy                 | 7.99531    |
| EnvExecTime             | 2.87       |
| ExplainedVariance       | 0.556      |
| Iteration               | 147        |
| ItrTime                 | 18.8       |
| LossAfter               | 0.481969   |
| LossBefore              | 0.547728   |
| MaxReturn               | 519        |
| MeanKL                  | 0.00960154 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 98.8       |
| NumTrajs                | 25         |
| Perplexity              | 2967.01    |
| PolicyExecTime          | 0.603      |
| ProcessExecTime         | 0.0811     |
| StdReturn               | 85.8       |
| Time                    | 2.64e+03   |
| dLoss                   | 0.0657587  |
----------------------------------------
itr #148 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 148...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5012, #subsample_inputs: 5012
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.669      |
| AbsLearnSignalNew       | 0.669      |
| AbsLearningOld          | 0.669      |
| AverageDiscountedReturn | 114        |
| AveragePhiLoss          | 10.021     |
| AveragePolicyStd        | 0.920876   |
| AverageReturn           | 306        |
| Entropy                 | 8.01586    |
| EnvExecTime             | 2.73       |
| ExplainedVariance       | 0.642      |
| Iteration               | 148        |
| ItrTime                 | 17.3       |
| LossAfter               | 0.248628   |
| LossBefore              | 0.315122   |
| MaxReturn               | 504        |
| MeanKL                  | 0.00979024 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 63.5       |
| NumTrajs                | 26         |
| Perplexity              | 3028.62    |
| PolicyExecTime          | 0.573      |
| ProcessExecTime         | 0.0782     |
| StdReturn               | 85.9       |
| Time                    | 2.66e+03   |
| dLoss                   | 0.0664941  |
----------------------------------------
itr #149 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 149...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5035, #subsample_inputs: 5035
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.665      |
| AbsLearnSignalNew       | 0.665      |
| AbsLearningOld          | 0.665      |
| AverageDiscountedReturn | 109        |
| AveragePhiLoss          | 10.3786    |
| AveragePolicyStd        | 0.921044   |
| AverageReturn           | 309        |
| Entropy                 | 8.01651    |
| EnvExecTime             | 3.14       |
| ExplainedVariance       | 0.548      |
| Iteration               | 149        |
| ItrTime                 | 18.5       |
| LossAfter               | 0.390146   |
| LossBefore              | 0.452804   |
| MaxReturn               | 545        |
| MeanKL                  | 0.00989047 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 86.7       |
| NumTrajs                | 24         |
| Perplexity              | 3030.58    |
| PolicyExecTime          | 0.689      |
| ProcessExecTime         | 0.0855     |
| StdReturn               | 122        |
| Time                    | 2.68e+03   |
| dLoss                   | 0.0626583  |
----------------------------------------
itr #150 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 150...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5065, #subsample_inputs: 5065
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.668      |
| AbsLearnSignalNew       | 0.668      |
| AbsLearningOld          | 0.668      |
| AverageDiscountedReturn | 104        |
| AveragePhiLoss          | 10.3495    |
| AveragePolicyStd        | 0.917152   |
| AverageReturn           | 305        |
| Entropy                 | 7.99105    |
| EnvExecTime             | 2.42       |
| ExplainedVariance       | 0.393      |
| Iteration               | 150        |
| ItrTime                 | 16.9       |
| LossAfter               | 0.0746352  |
| LossBefore              | 0.140046   |
| MaxReturn               | 654        |
| MeanKL                  | 0.00990644 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 33         |
| NumTrajs                | 23         |
| Perplexity              | 2954.39    |
| PolicyExecTime          | 0.489      |
| ProcessExecTime         | 0.0667     |
| StdReturn               | 133        |
| Time                    | 2.69e+03   |
| dLoss                   | 0.0654109  |
----------------------------------------
itr #151 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 151...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5065, #subsample_inputs: 5065
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.689      |
| AbsLearnSignalNew       | 0.689      |
| AbsLearningOld          | 0.689      |
| AverageDiscountedReturn | 112        |
| AveragePhiLoss          | 9.88946    |
| AveragePolicyStd        | 0.915755   |
| AverageReturn           | 312        |
| Entropy                 | 7.98163    |
| EnvExecTime             | 2.83       |
| ExplainedVariance       | 0.571      |
| Iteration               | 151        |
| ItrTime                 | 18         |
| LossAfter               | 0.951149   |
| LossBefore              | 1.01088    |
| MaxReturn               | 508        |
| MeanKL                  | 0.00998465 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 45.8       |
| NumTrajs                | 24         |
| Perplexity              | 2926.7     |
| PolicyExecTime          | 0.589      |
| ProcessExecTime         | 0.0826     |
| StdReturn               | 92.5       |
| Time                    | 2.71e+03   |
| dLoss                   | 0.0597283  |
----------------------------------------
itr #152 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 152...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5024, #subsample_inputs: 5024
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.703      |
| AbsLearnSignalNew       | 0.703      |
| AbsLearningOld          | 0.702      |
| AverageDiscountedReturn | 112        |
| AveragePhiLoss          | 9.91631    |
| AveragePolicyStd        | 0.916519   |
| AverageReturn           | 304        |
| Entropy                 | 7.98665    |
| EnvExecTime             | 2.5        |
| ExplainedVariance       | 0.604      |
| Iteration               | 152        |
| ItrTime                 | 17.5       |
| LossAfter               | -0.253824  |
| LossBefore              | -0.187502  |
| MaxReturn               | 541        |
| MeanKL                  | 0.00983752 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 86.8       |
| NumTrajs                | 25         |
| Perplexity              | 2941.42    |
| PolicyExecTime          | 0.487      |
| ProcessExecTime         | 0.0656     |
| StdReturn               | 91.7       |
| Time                    | 2.73e+03   |
| dLoss                   | 0.0663219  |
----------------------------------------
itr #153 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 153...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5011, #subsample_inputs: 5011
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.663      |
| AbsLearnSignalNew       | 0.663      |
| AbsLearningOld          | 0.663      |
| AverageDiscountedReturn | 112        |
| AveragePhiLoss          | 10.251     |
| AveragePolicyStd        | 0.91847    |
| AverageReturn           | 332        |
| Entropy                 | 7.99992    |
| EnvExecTime             | 2.8        |
| ExplainedVariance       | 0.501      |
| Iteration               | 153        |
| ItrTime                 | 17.7       |
| LossAfter               | 0.647551   |
| LossBefore              | 0.717878   |
| MaxReturn               | 530        |
| MeanKL                  | 0.00979094 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 152        |
| NumTrajs                | 23         |
| Perplexity              | 2980.73    |
| PolicyExecTime          | 0.592      |
| ProcessExecTime         | 0.0815     |
| StdReturn               | 93         |
| Time                    | 2.75e+03   |
| dLoss                   | 0.070327   |
----------------------------------------
itr #154 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 154...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5126, #subsample_inputs: 5126
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.625      |
| AbsLearnSignalNew       | 0.625      |
| AbsLearningOld          | 0.625      |
| AverageDiscountedReturn | 107        |
| AveragePhiLoss          | 9.78135    |
| AveragePolicyStd        | 0.918524   |
| AverageReturn           | 257        |
| Entropy                 | 7.99992    |
| EnvExecTime             | 2.6        |
| ExplainedVariance       | 0.599      |
| Iteration               | 154        |
| ItrTime                 | 17.9       |
| LossAfter               | -0.107645  |
| LossBefore              | -0.0534872 |
| MaxReturn               | 536        |
| MeanKL                  | 0.00981832 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 4.27       |
| NumTrajs                | 31         |
| Perplexity              | 2980.73    |
| PolicyExecTime          | 0.558      |
| ProcessExecTime         | 0.0722     |
| StdReturn               | 98.2       |
| Time                    | 2.77e+03   |
| dLoss                   | 0.054158   |
----------------------------------------
itr #155 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 155...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5186, #subsample_inputs: 5186
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.708      |
| AbsLearnSignalNew       | 0.708      |
| AbsLearningOld          | 0.708      |
| AverageDiscountedReturn | 111        |
| AveragePhiLoss          | 9.78324    |
| AveragePolicyStd        | 0.91967    |
| AverageReturn           | 277        |
| Entropy                 | 8.00709    |
| EnvExecTime             | 2.67       |
| ExplainedVariance       | 0.61       |
| Iteration               | 155        |
| ItrTime                 | 17.6       |
| LossAfter               | 0.252881   |
| LossBefore              | 0.301089   |
| MaxReturn               | 450        |
| MeanKL                  | 0.00646705 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 42.6       |
| NumTrajs                | 30         |
| Perplexity              | 3002.17    |
| PolicyExecTime          | 0.558      |
| ProcessExecTime         | 0.0752     |
| StdReturn               | 88.6       |
| Time                    | 2.78e+03   |
| dLoss                   | 0.0482077  |
----------------------------------------
itr #156 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 156...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5117, #subsample_inputs: 5117
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.627      |
| AbsLearnSignalNew       | 0.627      |
| AbsLearningOld          | 0.627      |
| AverageDiscountedReturn | 112        |
| AveragePhiLoss          | 9.86834    |
| AveragePolicyStd        | 0.918307   |
| AverageReturn           | 304        |
| Entropy                 | 7.99845    |
| EnvExecTime             | 2.86       |
| ExplainedVariance       | 0.563      |
| Iteration               | 156        |
| ItrTime                 | 18.4       |
| LossAfter               | 2.0398     |
| LossBefore              | 2.09207    |
| MaxReturn               | 446        |
| MeanKL                  | 0.00642989 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 82.6       |
| NumTrajs                | 25         |
| Perplexity              | 2976.33    |
| PolicyExecTime          | 0.586      |
| ProcessExecTime         | 0.081      |
| StdReturn               | 82.8       |
| Time                    | 2.8e+03    |
| dLoss                   | 0.0522661  |
----------------------------------------
itr #157 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 157...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5138, #subsample_inputs: 5138
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.663      |
| AbsLearnSignalNew       | 0.663      |
| AbsLearningOld          | 0.663      |
| AverageDiscountedReturn | 110        |
| AveragePhiLoss          | 10.6       |
| AveragePolicyStd        | 0.919668   |
| AverageReturn           | 325        |
| Entropy                 | 8.00686    |
| EnvExecTime             | 2.54       |
| ExplainedVariance       | 0.44       |
| Iteration               | 157        |
| ItrTime                 | 17.1       |
| LossAfter               | 1.28979    |
| LossBefore              | 1.34828    |
| MaxReturn               | 567        |
| MeanKL                  | 0.00979176 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 67.5       |
| NumTrajs                | 24         |
| Perplexity              | 3001.46    |
| PolicyExecTime          | 0.519      |
| ProcessExecTime         | 0.0691     |
| StdReturn               | 118        |
| Time                    | 2.82e+03   |
| dLoss                   | 0.0584817  |
----------------------------------------
itr #158 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 158...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5046, #subsample_inputs: 5046
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.679      |
| AbsLearnSignalNew       | 0.679      |
| AbsLearningOld          | 0.679      |
| AverageDiscountedReturn | 101        |
| AveragePhiLoss          | 9.59115    |
| AveragePolicyStd        | 0.919877   |
| AverageReturn           | 246        |
| Entropy                 | 8.00826    |
| EnvExecTime             | 2.79       |
| ExplainedVariance       | 0.463      |
| Iteration               | 158        |
| ItrTime                 | 17.8       |
| LossAfter               | -1.45024   |
| LossBefore              | -1.38718   |
| MaxReturn               | 464        |
| MeanKL                  | 0.00994086 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 49.8       |
| NumTrajs                | 29         |
| Perplexity              | 3005.69    |
| PolicyExecTime          | 0.6        |
| ProcessExecTime         | 0.0794     |
| StdReturn               | 127        |
| Time                    | 2.84e+03   |
| dLoss                   | 0.0630561  |
----------------------------------------
itr #159 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 159...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5064, #subsample_inputs: 5064
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.76       |
| AbsLearnSignalNew       | 0.76       |
| AbsLearningOld          | 0.76       |
| AverageDiscountedReturn | 104        |
| AveragePhiLoss          | 10.2987    |
| AveragePolicyStd        | 0.918697   |
| AverageReturn           | 273        |
| Entropy                 | 8.00033    |
| EnvExecTime             | 2.38       |
| ExplainedVariance       | 0.503      |
| Iteration               | 159        |
| ItrTime                 | 17         |
| LossAfter               | -1.65653   |
| LossBefore              | -1.59774   |
| MaxReturn               | 430        |
| MeanKL                  | 0.00986566 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 37.4       |
| NumTrajs                | 27         |
| Perplexity              | 2981.96    |
| PolicyExecTime          | 0.474      |
| ProcessExecTime         | 0.0625     |
| StdReturn               | 109        |
| Time                    | 2.85e+03   |
| dLoss                   | 0.0587986  |
----------------------------------------
itr #160 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 160...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5095, #subsample_inputs: 5095
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.714      |
| AbsLearnSignalNew       | 0.714      |
| AbsLearningOld          | 0.714      |
| AverageDiscountedReturn | 117        |
| AveragePhiLoss          | 9.98683    |
| AveragePolicyStd        | 0.917188   |
| AverageReturn           | 306        |
| Entropy                 | 7.99085    |
| EnvExecTime             | 2.76       |
| ExplainedVariance       | 0.67       |
| Iteration               | 160        |
| ItrTime                 | 18         |
| LossAfter               | -0.717197  |
| LossBefore              | -0.666056  |
| MaxReturn               | 448        |
| MeanKL                  | 0.00645594 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 180        |
| NumTrajs                | 28         |
| Perplexity              | 2953.81    |
| PolicyExecTime          | 0.589      |
| ProcessExecTime         | 0.0808     |
| StdReturn               | 64.2       |
| Time                    | 2.87e+03   |
| dLoss                   | 0.0511404  |
----------------------------------------
itr #161 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 161...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5113, #subsample_inputs: 5113
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.603      |
| AbsLearnSignalNew       | 0.603      |
| AbsLearningOld          | 0.603      |
| AverageDiscountedReturn | 104        |
| AveragePhiLoss          | 10.4806    |
| AveragePolicyStd        | 0.915128   |
| AverageReturn           | 268        |
| Entropy                 | 7.97708    |
| EnvExecTime             | 2.6        |
| ExplainedVariance       | 0.0707     |
| Iteration               | 161        |
| ItrTime                 | 17.9       |
| LossAfter               | -0.95771   |
| LossBefore              | -0.914034  |
| MaxReturn               | 480        |
| MeanKL                  | 0.00640583 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 41.4       |
| NumTrajs                | 27         |
| Perplexity              | 2913.42    |
| PolicyExecTime          | 0.501      |
| ProcessExecTime         | 0.0664     |
| StdReturn               | 117        |
| Time                    | 2.89e+03   |
| dLoss                   | 0.0436764  |
----------------------------------------
itr #162 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 162...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5360, #subsample_inputs: 5360
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.696      |
| AbsLearnSignalNew       | 0.696      |
| AbsLearningOld          | 0.696      |
| AverageDiscountedReturn | 114        |
| AveragePhiLoss          | 10.0664    |
| AveragePolicyStd        | 0.91368    |
| AverageReturn           | 327        |
| Entropy                 | 7.96753    |
| EnvExecTime             | 2.94       |
| ExplainedVariance       | 0.465      |
| Iteration               | 162        |
| ItrTime                 | 18.4       |
| LossAfter               | 1.26203    |
| LossBefore              | 1.30785    |
| MaxReturn               | 536        |
| MeanKL                  | 0.00644465 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 59.2       |
| NumTrajs                | 27         |
| Perplexity              | 2885.71    |
| PolicyExecTime          | 0.612      |
| ProcessExecTime         | 0.084      |
| StdReturn               | 99.6       |
| Time                    | 2.91e+03   |
| dLoss                   | 0.045821   |
----------------------------------------
itr #163 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 163...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5148, #subsample_inputs: 5148
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.631     |
| AbsLearnSignalNew       | 0.631     |
| AbsLearningOld          | 0.631     |
| AverageDiscountedReturn | 112       |
| AveragePhiLoss          | 10.3947   |
| AveragePolicyStd        | 0.913403  |
| AverageReturn           | 288       |
| Entropy                 | 7.96594   |
| EnvExecTime             | 3.01      |
| ExplainedVariance       | 0.519     |
| Iteration               | 163       |
| ItrTime                 | 18.4      |
| LossAfter               | 0.042933  |
| LossBefore              | 0.0958905 |
| MaxReturn               | 614       |
| MeanKL                  | 0.0064234 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 0.661     |
| NumTrajs                | 29        |
| Perplexity              | 2881.13   |
| PolicyExecTime          | 0.622     |
| ProcessExecTime         | 0.0804    |
| StdReturn               | 114       |
| Time                    | 2.93e+03  |
| dLoss                   | 0.0529575 |
---------------------------------------
itr #164 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 164...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5244, #subsample_inputs: 5244
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.705      |
| AbsLearnSignalNew       | 0.705      |
| AbsLearningOld          | 0.705      |
| AverageDiscountedReturn | 114        |
| AveragePhiLoss          | 10.3641    |
| AveragePolicyStd        | 0.912977   |
| AverageReturn           | 339        |
| Entropy                 | 7.96331    |
| EnvExecTime             | 2.7        |
| ExplainedVariance       | 0.654      |
| Iteration               | 164        |
| ItrTime                 | 18.2       |
| LossAfter               | 1.19672    |
| LossBefore              | 1.24774    |
| MaxReturn               | 530        |
| MeanKL                  | 0.00646751 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 40.8       |
| NumTrajs                | 25         |
| Perplexity              | 2873.57    |
| PolicyExecTime          | 0.537      |
| ProcessExecTime         | 0.0694     |
| StdReturn               | 101        |
| Time                    | 2.95e+03   |
| dLoss                   | 0.05102    |
----------------------------------------
itr #165 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 165...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5233, #subsample_inputs: 5233
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.573      |
| AbsLearnSignalNew       | 0.573      |
| AbsLearningOld          | 0.573      |
| AverageDiscountedReturn | 114        |
| AveragePhiLoss          | 10.106     |
| AveragePolicyStd        | 0.912684   |
| AverageReturn           | 294        |
| Entropy                 | 7.96113    |
| EnvExecTime             | 2.81       |
| ExplainedVariance       | 0.484      |
| Iteration               | 165        |
| ItrTime                 | 18.1       |
| LossAfter               | -0.328451  |
| LossBefore              | -0.273812  |
| MaxReturn               | 417        |
| MeanKL                  | 0.00992585 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 67.2       |
| NumTrajs                | 29         |
| Perplexity              | 2867.3     |
| PolicyExecTime          | 0.609      |
| ProcessExecTime         | 0.0853     |
| StdReturn               | 83.6       |
| Time                    | 2.96e+03   |
| dLoss                   | 0.0546391  |
----------------------------------------
itr #166 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 166...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5078, #subsample_inputs: 5078
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.701      |
| AbsLearnSignalNew       | 0.701      |
| AbsLearningOld          | 0.701      |
| AverageDiscountedReturn | 109        |
| AveragePhiLoss          | 10.2624    |
| AveragePolicyStd        | 0.915678   |
| AverageReturn           | 312        |
| Entropy                 | 7.98096    |
| EnvExecTime             | 2.62       |
| ExplainedVariance       | 0.483      |
| Iteration               | 166        |
| ItrTime                 | 18         |
| LossAfter               | 0.42623    |
| LossBefore              | 0.4902     |
| MaxReturn               | 615        |
| MeanKL                  | 0.00991167 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 72         |
| NumTrajs                | 24         |
| Perplexity              | 2924.74    |
| PolicyExecTime          | 0.522      |
| ProcessExecTime         | 0.0663     |
| StdReturn               | 118        |
| Time                    | 2.98e+03   |
| dLoss                   | 0.0639697  |
----------------------------------------
itr #167 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 167...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5115, #subsample_inputs: 5115
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.716      |
| AbsLearnSignalNew       | 0.716      |
| AbsLearningOld          | 0.716      |
| AverageDiscountedReturn | 117        |
| AveragePhiLoss          | 9.76046    |
| AveragePolicyStd        | 0.914667   |
| AverageReturn           | 322        |
| Entropy                 | 7.973      |
| EnvExecTime             | 2.81       |
| ExplainedVariance       | 0.687      |
| Iteration               | 167        |
| ItrTime                 | 17.5       |
| LossAfter               | 0.238333   |
| LossBefore              | 0.28725    |
| MaxReturn               | 482        |
| MeanKL                  | 0.00641412 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 169        |
| NumTrajs                | 26         |
| Perplexity              | 2901.56    |
| PolicyExecTime          | 0.598      |
| ProcessExecTime         | 0.0794     |
| StdReturn               | 68.6       |
| Time                    | 3e+03      |
| dLoss                   | 0.0489168  |
----------------------------------------
itr #168 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 168...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5036, #subsample_inputs: 5036
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.611      |
| AbsLearnSignalNew       | 0.611      |
| AbsLearningOld          | 0.61       |
| AverageDiscountedReturn | 116        |
| AveragePhiLoss          | 10.3753    |
| AveragePolicyStd        | 0.913362   |
| AverageReturn           | 295        |
| Entropy                 | 7.96446    |
| EnvExecTime             | 2.39       |
| ExplainedVariance       | 0.691      |
| Iteration               | 168        |
| ItrTime                 | 17.6       |
| LossAfter               | -0.217288  |
| LossBefore              | -0.155696  |
| MaxReturn               | 572        |
| MeanKL                  | 0.00978358 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 27.3       |
| NumTrajs                | 29         |
| Perplexity              | 2876.87    |
| PolicyExecTime          | 0.489      |
| ProcessExecTime         | 0.0647     |
| StdReturn               | 86.3       |
| Time                    | 3.02e+03   |
| dLoss                   | 0.061592   |
----------------------------------------
itr #169 | 
Mem: 751.925781
Obtaining samples...
Obtaining samples for iteration 169...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5069, #subsample_inputs: 5069
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.651      |
| AbsLearnSignalNew       | 0.651      |
| AbsLearningOld          | 0.651      |
| AverageDiscountedReturn | 112        |
| AveragePhiLoss          | 10.5532    |
| AveragePolicyStd        | 0.913069   |
| AverageReturn           | 292        |
| Entropy                 | 7.96257    |
| EnvExecTime             | 2.69       |
| ExplainedVariance       | 0.527      |
| Iteration               | 169        |
| ItrTime                 | 17.6       |
| LossAfter               | -0.425387  |
| LossBefore              | -0.367124  |
| MaxReturn               | 467        |
| MeanKL                  | 0.00986947 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 67.9       |
| NumTrajs                | 27         |
| Perplexity              | 2871.44    |
| PolicyExecTime          | 0.575      |
| ProcessExecTime         | 0.0805     |
| StdReturn               | 93.7       |
| Time                    | 3.04e+03   |
| dLoss                   | 0.0582631  |
----------------------------------------
itr #170 | 
Mem: 752.804688
Obtaining samples...
Obtaining samples for iteration 170...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5008, #subsample_inputs: 5008
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.685      |
| AbsLearnSignalNew       | 0.685      |
| AbsLearningOld          | 0.684      |
| AverageDiscountedReturn | 113        |
| AveragePhiLoss          | 10.0578    |
| AveragePolicyStd        | 0.914126   |
| AverageReturn           | 317        |
| Entropy                 | 7.97022    |
| EnvExecTime             | 2.26       |
| ExplainedVariance       | 0.609      |
| Iteration               | 170        |
| ItrTime                 | 17.2       |
| LossAfter               | -1.07947   |
| LossBefore              | -1.03164   |
| MaxReturn               | 502        |
| MeanKL                  | 0.00646361 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 58.7       |
| NumTrajs                | 25         |
| Perplexity              | 2893.5     |
| PolicyExecTime          | 0.449      |
| ProcessExecTime         | 0.0613     |
| StdReturn               | 94.3       |
| Time                    | 3.05e+03   |
| dLoss                   | 0.0478268  |
----------------------------------------
itr #171 | 
Mem: 752.804688
Obtaining samples...
Obtaining samples for iteration 171...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5081, #subsample_inputs: 5081
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.693      |
| AbsLearnSignalNew       | 0.693      |
| AbsLearningOld          | 0.693      |
| AverageDiscountedReturn | 115        |
| AveragePhiLoss          | 10.1441    |
| AveragePolicyStd        | 0.910323   |
| AverageReturn           | 299        |
| Entropy                 | 7.94526    |
| EnvExecTime             | 2.86       |
| ExplainedVariance       | 0.644      |
| Iteration               | 171        |
| ItrTime                 | 17.4       |
| LossAfter               | 0.314875   |
| LossBefore              | 0.37413    |
| MaxReturn               | 398        |
| MeanKL                  | 0.00988284 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 127        |
| NumTrajs                | 27         |
| Perplexity              | 2822.16    |
| PolicyExecTime          | 0.605      |
| ProcessExecTime         | 0.0829     |
| StdReturn               | 61.4       |
| Time                    | 3.07e+03   |
| dLoss                   | 0.0592548  |
----------------------------------------
itr #172 | 
Mem: 752.804688
Obtaining samples...
Obtaining samples for iteration 172...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5132, #subsample_inputs: 5132
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.468      |
| AbsLearnSignalNew       | 0.468      |
| AbsLearningOld          | 0.468      |
| AverageDiscountedReturn | 115        |
| AveragePhiLoss          | 11.6895    |
| AveragePolicyStd        | 0.910641   |
| AverageReturn           | 316        |
| Entropy                 | 7.94761    |
| EnvExecTime             | 2.9        |
| ExplainedVariance       | -1.12      |
| Iteration               | 172        |
| ItrTime                 | 18.3       |
| LossAfter               | 0.261851   |
| LossBefore              | 0.311469   |
| MaxReturn               | 481        |
| MeanKL                  | 0.00647023 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 85.1       |
| NumTrajs                | 25         |
| Perplexity              | 2828.81    |
| PolicyExecTime          | 0.638      |
| ProcessExecTime         | 0.0772     |
| StdReturn               | 89.2       |
| Time                    | 3.09e+03   |
| dLoss                   | 0.049618   |
----------------------------------------
itr #173 | 
Mem: 752.804688
Obtaining samples...
Obtaining samples for iteration 173...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5178, #subsample_inputs: 5178
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.689      |
| AbsLearnSignalNew       | 0.689      |
| AbsLearningOld          | 0.689      |
| AverageDiscountedReturn | 109        |
| AveragePhiLoss          | 10.886     |
| AveragePolicyStd        | 0.907734   |
| AverageReturn           | 280        |
| Entropy                 | 7.92805    |
| EnvExecTime             | 2.66       |
| ExplainedVariance       | 0.546      |
| Iteration               | 173        |
| ItrTime                 | 17.3       |
| LossAfter               | 0.222991   |
| LossBefore              | 0.28205    |
| MaxReturn               | 446        |
| MeanKL                  | 0.00998582 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 26.4       |
| NumTrajs                | 27         |
| Perplexity              | 2774.02    |
| PolicyExecTime          | 0.546      |
| ProcessExecTime         | 0.0733     |
| StdReturn               | 99.1       |
| Time                    | 3.11e+03   |
| dLoss                   | 0.0590582  |
----------------------------------------
itr #174 | 
Mem: 752.804688
Obtaining samples...
Obtaining samples for iteration 174...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5059, #subsample_inputs: 5059
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.574      |
| AbsLearnSignalNew       | 0.574      |
| AbsLearningOld          | 0.574      |
| AverageDiscountedReturn | 110        |
| AveragePhiLoss          | 10.8208    |
| AveragePolicyStd        | 0.905948   |
| AverageReturn           | 324        |
| Entropy                 | 7.91533    |
| EnvExecTime             | 2.82       |
| ExplainedVariance       | 0.048      |
| Iteration               | 174        |
| ItrTime                 | 17.8       |
| LossAfter               | 0.851989   |
| LossBefore              | 0.90514    |
| MaxReturn               | 577        |
| MeanKL                  | 0.00650345 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 39.3       |
| NumTrajs                | 24         |
| Perplexity              | 2738.94    |
| PolicyExecTime          | 0.615      |
| ProcessExecTime         | 0.0828     |
| StdReturn               | 125        |
| Time                    | 3.12e+03   |
| dLoss                   | 0.0531511  |
----------------------------------------
itr #175 | 
Mem: 752.804688
Obtaining samples...
Obtaining samples for iteration 175...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5070, #subsample_inputs: 5070
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.693      |
| AbsLearnSignalNew       | 0.693      |
| AbsLearningOld          | 0.692      |
| AverageDiscountedReturn | 112        |
| AveragePhiLoss          | 10.5889    |
| AveragePolicyStd        | 0.903663   |
| AverageReturn           | 309        |
| Entropy                 | 7.89994    |
| EnvExecTime             | 2.42       |
| ExplainedVariance       | 0.539      |
| Iteration               | 175        |
| ItrTime                 | 17.5       |
| LossAfter               | -0.727444  |
| LossBefore              | -0.678557  |
| MaxReturn               | 724        |
| MeanKL                  | 0.00642199 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 93.1       |
| NumTrajs                | 25         |
| Perplexity              | 2697.13    |
| PolicyExecTime          | 0.467      |
| ProcessExecTime         | 0.0628     |
| StdReturn               | 128        |
| Time                    | 3.14e+03   |
| dLoss                   | 0.0488876  |
----------------------------------------
itr #176 | 
Mem: 752.804688
Obtaining samples...
Obtaining samples for iteration 176...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5143, #subsample_inputs: 5143
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.734      |
| AbsLearnSignalNew       | 0.734      |
| AbsLearningOld          | 0.734      |
| AverageDiscountedReturn | 117        |
| AveragePhiLoss          | 11.6811    |
| AveragePolicyStd        | 0.901798   |
| AverageReturn           | 319        |
| Entropy                 | 7.88697    |
| EnvExecTime             | 2.87       |
| ExplainedVariance       | 0.645      |
| Iteration               | 176        |
| ItrTime                 | 17.8       |
| LossAfter               | -0.632708  |
| LossBefore              | -0.570246  |
| MaxReturn               | 413        |
| MeanKL                  | 0.00984553 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 78.1       |
| NumTrajs                | 27         |
| Perplexity              | 2662.36    |
| PolicyExecTime          | 0.603      |
| ProcessExecTime         | 0.0832     |
| StdReturn               | 73.6       |
| Time                    | 3.16e+03   |
| dLoss                   | 0.0624618  |
----------------------------------------
itr #177 | 
Mem: 752.804688
Obtaining samples...
Obtaining samples for iteration 177...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5207, #subsample_inputs: 5207
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.71       |
| AbsLearnSignalNew       | 0.71       |
| AbsLearningOld          | 0.71       |
| AverageDiscountedReturn | 118        |
| AveragePhiLoss          | 11.0314    |
| AveragePolicyStd        | 0.902375   |
| AverageReturn           | 329        |
| Entropy                 | 7.89025    |
| EnvExecTime             | 2.62       |
| ExplainedVariance       | 0.68       |
| Iteration               | 177        |
| ItrTime                 | 18.2       |
| LossAfter               | -0.211013  |
| LossBefore              | -0.146415  |
| MaxReturn               | 545        |
| MeanKL                  | 0.00992365 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 174        |
| NumTrajs                | 26         |
| Perplexity              | 2671.1     |
| PolicyExecTime          | 0.535      |
| ProcessExecTime         | 0.0717     |
| StdReturn               | 85.6       |
| Time                    | 3.18e+03   |
| dLoss                   | 0.064598   |
----------------------------------------
itr #178 | 
Mem: 752.804688
Obtaining samples...
Obtaining samples for iteration 178...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5169, #subsample_inputs: 5169
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.692      |
| AbsLearnSignalNew       | 0.692      |
| AbsLearningOld          | 0.692      |
| AverageDiscountedReturn | 104        |
| AveragePhiLoss          | 10.2867    |
| AveragePolicyStd        | 0.90121    |
| AverageReturn           | 262        |
| Entropy                 | 7.88263    |
| EnvExecTime             | 2.71       |
| ExplainedVariance       | 0.457      |
| Iteration               | 178        |
| ItrTime                 | 17.6       |
| LossAfter               | -0.743818  |
| LossBefore              | -0.696525  |
| MaxReturn               | 466        |
| MeanKL                  | 0.00648078 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 47.3       |
| NumTrajs                | 27         |
| Perplexity              | 2650.84    |
| PolicyExecTime          | 0.55       |
| ProcessExecTime         | 0.0768     |
| StdReturn               | 110        |
| Time                    | 3.2e+03    |
| dLoss                   | 0.0472928  |
----------------------------------------
itr #179 | 
Mem: 752.804688
Obtaining samples...
Obtaining samples for iteration 179...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5052, #subsample_inputs: 5052
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.748      |
| AbsLearnSignalNew       | 0.748      |
| AbsLearningOld          | 0.748      |
| AverageDiscountedReturn | 101        |
| AveragePhiLoss          | 10.8378    |
| AveragePolicyStd        | 0.900375   |
| AverageReturn           | 277        |
| Entropy                 | 7.87747    |
| EnvExecTime             | 2.88       |
| ExplainedVariance       | 0.497      |
| Iteration               | 179        |
| ItrTime                 | 18.1       |
| LossAfter               | -0.459356  |
| LossBefore              | -0.408423  |
| MaxReturn               | 473        |
| MeanKL                  | 0.00643166 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 54.7       |
| NumTrajs                | 24         |
| Perplexity              | 2637.2     |
| PolicyExecTime          | 0.595      |
| ProcessExecTime         | 0.077      |
| StdReturn               | 126        |
| Time                    | 3.21e+03   |
| dLoss                   | 0.0509335  |
----------------------------------------
itr #180 | 
Mem: 752.804688
Obtaining samples...
Obtaining samples for iteration 180...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5116, #subsample_inputs: 5116
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.723      |
| AbsLearnSignalNew       | 0.723      |
| AbsLearningOld          | 0.723      |
| AverageDiscountedReturn | 113        |
| AveragePhiLoss          | 10.596     |
| AveragePolicyStd        | 0.901664   |
| AverageReturn           | 307        |
| Entropy                 | 7.88575    |
| EnvExecTime             | 2.67       |
| ExplainedVariance       | 0.44       |
| Iteration               | 180        |
| ItrTime                 | 17.5       |
| LossAfter               | 0.512178   |
| LossBefore              | 0.576195   |
| MaxReturn               | 503        |
| MeanKL                  | 0.00994246 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 95.7       |
| NumTrajs                | 26         |
| Perplexity              | 2659.13    |
| PolicyExecTime          | 0.542      |
| ProcessExecTime         | 0.0695     |
| StdReturn               | 99.7       |
| Time                    | 3.23e+03   |
| dLoss                   | 0.0640175  |
----------------------------------------
itr #181 | 
Mem: 752.804688
Obtaining samples...
Obtaining samples for iteration 181...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5133, #subsample_inputs: 5133
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.73       |
| AbsLearnSignalNew       | 0.73       |
| AbsLearningOld          | 0.73       |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 10.5847    |
| AveragePolicyStd        | 0.900681   |
| AverageReturn           | 348        |
| Entropy                 | 7.8801     |
| EnvExecTime             | 2.89       |
| ExplainedVariance       | 0.706      |
| Iteration               | 181        |
| ItrTime                 | 17.9       |
| LossAfter               | -0.660206  |
| LossBefore              | -0.596879  |
| MaxReturn               | 446        |
| MeanKL                  | 0.00994281 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 264        |
| NumTrajs                | 25         |
| Perplexity              | 2644.12    |
| PolicyExecTime          | 0.624      |
| ProcessExecTime         | 0.0842     |
| StdReturn               | 55         |
| Time                    | 3.25e+03   |
| dLoss                   | 0.0633271  |
----------------------------------------
itr #182 | 
Mem: 752.804688
Obtaining samples...
Obtaining samples for iteration 182...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5128, #subsample_inputs: 5128
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.597      |
| AbsLearnSignalNew       | 0.597      |
| AbsLearningOld          | 0.598      |
| AverageDiscountedReturn | 117        |
| AveragePhiLoss          | 11.1757    |
| AveragePolicyStd        | 0.898393   |
| AverageReturn           | 310        |
| Entropy                 | 7.86545    |
| EnvExecTime             | 2.57       |
| ExplainedVariance       | 0.46       |
| Iteration               | 182        |
| ItrTime                 | 17.7       |
| LossAfter               | 0.318873   |
| LossBefore              | 0.365895   |
| MaxReturn               | 443        |
| MeanKL                  | 0.00646067 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 58.8       |
| NumTrajs                | 27         |
| Perplexity              | 2605.67    |
| PolicyExecTime          | 0.516      |
| ProcessExecTime         | 0.0672     |
| StdReturn               | 79.8       |
| Time                    | 3.27e+03   |
| dLoss                   | 0.0470223  |
----------------------------------------
itr #183 | 
Mem: 752.804688
Obtaining samples...
Obtaining samples for iteration 183...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5274, #subsample_inputs: 5274
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.627     |
| AbsLearnSignalNew       | 0.627     |
| AbsLearningOld          | 0.627     |
| AverageDiscountedReturn | 120       |
| AveragePhiLoss          | 11.1169   |
| AveragePolicyStd        | 0.898463  |
| AverageReturn           | 342       |
| Entropy                 | 7.86593   |
| EnvExecTime             | 3.13      |
| ExplainedVariance       | 0.426     |
| Iteration               | 183       |
| ItrTime                 | 18.4      |
| LossAfter               | 0.105989  |
| LossBefore              | 0.1678    |
| MaxReturn               | 664       |
| MeanKL                  | 0.0099711 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 220       |
| NumTrajs                | 26        |
| Perplexity              | 2606.93   |
| PolicyExecTime          | 0.664     |
| ProcessExecTime         | 0.0863    |
| StdReturn               | 92        |
| Time                    | 3.29e+03  |
| dLoss                   | 0.0618109 |
---------------------------------------
itr #184 | 
Mem: 752.804688
Obtaining samples...
Obtaining samples for iteration 184...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5208, #subsample_inputs: 5208
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.666      |
| AbsLearnSignalNew       | 0.666      |
| AbsLearningOld          | 0.666      |
| AverageDiscountedReturn | 112        |
| AveragePhiLoss          | 11.0725    |
| AveragePolicyStd        | 0.898163   |
| AverageReturn           | 311        |
| Entropy                 | 7.8638     |
| EnvExecTime             | 2.68       |
| ExplainedVariance       | 0.385      |
| Iteration               | 184        |
| ItrTime                 | 18.2       |
| LossAfter               | 0.637462   |
| LossBefore              | 0.694083   |
| MaxReturn               | 488        |
| MeanKL                  | 0.00965389 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 51.6       |
| NumTrajs                | 26         |
| Perplexity              | 2601.39    |
| PolicyExecTime          | 0.604      |
| ProcessExecTime         | 0.078      |
| StdReturn               | 117        |
| Time                    | 3.3e+03    |
| dLoss                   | 0.056621   |
----------------------------------------
itr #185 | 
Mem: 752.804688
Obtaining samples...
Obtaining samples for iteration 185...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5016, #subsample_inputs: 5016
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.704      |
| AbsLearnSignalNew       | 0.704      |
| AbsLearningOld          | 0.704      |
| AverageDiscountedReturn | 119        |
| AveragePhiLoss          | 11.0634    |
| AveragePolicyStd        | 0.897077   |
| AverageReturn           | 327        |
| Entropy                 | 7.85605    |
| EnvExecTime             | 2.61       |
| ExplainedVariance       | 0.639      |
| Iteration               | 185        |
| ItrTime                 | 17.3       |
| LossAfter               | -0.061254  |
| LossBefore              | 0.00850274 |
| MaxReturn               | 464        |
| MeanKL                  | 0.0099632  |
| MeanKLBefore            | 0.0        |
| MinReturn               | 208        |
| NumTrajs                | 25         |
| Perplexity              | 2581.31    |
| PolicyExecTime          | 0.508      |
| ProcessExecTime         | 0.0668     |
| StdReturn               | 72.2       |
| Time                    | 3.32e+03   |
| dLoss                   | 0.0697568  |
----------------------------------------
itr #186 | 
Mem: 752.804688
Obtaining samples...
Obtaining samples for iteration 186...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5101, #subsample_inputs: 5101
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.704      |
| AbsLearnSignalNew       | 0.704      |
| AbsLearningOld          | 0.704      |
| AverageDiscountedReturn | 116        |
| AveragePhiLoss          | 11.1238    |
| AveragePolicyStd        | 0.898391   |
| AverageReturn           | 319        |
| Entropy                 | 7.86456    |
| EnvExecTime             | 2.85       |
| ExplainedVariance       | 0.648      |
| Iteration               | 186        |
| ItrTime                 | 18.5       |
| LossAfter               | -0.40868   |
| LossBefore              | -0.358023  |
| MaxReturn               | 446        |
| MeanKL                  | 0.00642679 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 62.8       |
| NumTrajs                | 26         |
| Perplexity              | 2603.35    |
| PolicyExecTime          | 0.599      |
| ProcessExecTime         | 0.0831     |
| StdReturn               | 78.7       |
| Time                    | 3.34e+03   |
| dLoss                   | 0.0506566  |
----------------------------------------
itr #187 | 
Mem: 754.093750
Obtaining samples...
Obtaining samples for iteration 187...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5090, #subsample_inputs: 5090
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.639      |
| AbsLearnSignalNew       | 0.639      |
| AbsLearningOld          | 0.639      |
| AverageDiscountedReturn | 119        |
| AveragePhiLoss          | 11.7169    |
| AveragePolicyStd        | 0.89663    |
| AverageReturn           | 315        |
| Entropy                 | 7.85266    |
| EnvExecTime             | 2.54       |
| ExplainedVariance       | 0.647      |
| Iteration               | 187        |
| ItrTime                 | 17.4       |
| LossAfter               | 0.327559   |
| LossBefore              | 0.39163    |
| MaxReturn               | 407        |
| MeanKL                  | 0.00994324 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 27.8       |
| NumTrajs                | 27         |
| Perplexity              | 2572.56    |
| PolicyExecTime          | 0.499      |
| ProcessExecTime         | 0.0662     |
| StdReturn               | 73.8       |
| Time                    | 3.36e+03   |
| dLoss                   | 0.064071   |
----------------------------------------
itr #188 | 
Mem: 754.093750
Obtaining samples...
Obtaining samples for iteration 188...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5043, #subsample_inputs: 5043
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.617     |
| AbsLearnSignalNew       | 0.617     |
| AbsLearningOld          | 0.617     |
| AverageDiscountedReturn | 119       |
| AveragePhiLoss          | 10.6188   |
| AveragePolicyStd        | 0.89743   |
| AverageReturn           | 361       |
| Entropy                 | 7.85708   |
| EnvExecTime             | 2.85      |
| ExplainedVariance       | 0.355     |
| Iteration               | 188       |
| ItrTime                 | 18.5      |
| LossAfter               | -1.12841  |
| LossBefore              | -1.07773  |
| MaxReturn               | 500       |
| MeanKL                  | 0.006513  |
| MeanKLBefore            | 0.0       |
| MinReturn               | 150       |
| NumTrajs                | 23        |
| Perplexity              | 2583.96   |
| PolicyExecTime          | 0.619     |
| ProcessExecTime         | 0.0847    |
| StdReturn               | 83.8      |
| Time                    | 3.38e+03  |
| dLoss                   | 0.0506809 |
---------------------------------------
itr #189 | 
Mem: 754.093750
Obtaining samples...
Obtaining samples for iteration 189...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5167, #subsample_inputs: 5167
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.67       |
| AbsLearnSignalNew       | 0.67       |
| AbsLearningOld          | 0.671      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 11.887     |
| AveragePolicyStd        | 0.895635   |
| AverageReturn           | 316        |
| Entropy                 | 7.84517    |
| EnvExecTime             | 2.47       |
| ExplainedVariance       | 0.668      |
| Iteration               | 189        |
| ItrTime                 | 18.3       |
| LossAfter               | -0.0167633 |
| LossBefore              | 0.0789347  |
| MaxReturn               | 492        |
| MeanKL                  | 0.00977128 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 103        |
| NumTrajs                | 28         |
| Perplexity              | 2553.36    |
| PolicyExecTime          | 0.506      |
| ProcessExecTime         | 0.0677     |
| StdReturn               | 73.8       |
| Time                    | 3.39e+03   |
| dLoss                   | 0.095698   |
----------------------------------------
itr #190 | 
Mem: 754.093750
Obtaining samples...
Obtaining samples for iteration 190...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5057, #subsample_inputs: 5057
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.654     |
| AbsLearnSignalNew       | 0.654     |
| AbsLearningOld          | 0.654     |
| AverageDiscountedReturn | 113       |
| AveragePhiLoss          | 11.3173   |
| AveragePolicyStd        | 0.894242  |
| AverageReturn           | 295       |
| Entropy                 | 7.83676   |
| EnvExecTime             | 2.7       |
| ExplainedVariance       | 0.498     |
| Iteration               | 190       |
| ItrTime                 | 17.3      |
| LossAfter               | 0.356932  |
| LossBefore              | 0.404652  |
| MaxReturn               | 506       |
| MeanKL                  | 0.006474  |
| MeanKLBefore            | 0.0       |
| MinReturn               | 0.428     |
| NumTrajs                | 28        |
| Perplexity              | 2531.99   |
| PolicyExecTime          | 0.566     |
| ProcessExecTime         | 0.0746    |
| StdReturn               | 111       |
| Time                    | 3.41e+03  |
| dLoss                   | 0.0477196 |
---------------------------------------
itr #191 | 
Mem: 754.093750
Obtaining samples...
Obtaining samples for iteration 191...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5067, #subsample_inputs: 5067
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.723      |
| AbsLearnSignalNew       | 0.723      |
| AbsLearningOld          | 0.723      |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 11.4323    |
| AveragePolicyStd        | 0.890625   |
| AverageReturn           | 324        |
| Entropy                 | 7.81185    |
| EnvExecTime             | 2.62       |
| ExplainedVariance       | 0.62       |
| Iteration               | 191        |
| ItrTime                 | 18         |
| LossAfter               | 0.201972   |
| LossBefore              | 0.251712   |
| MaxReturn               | 486        |
| MeanKL                  | 0.00644774 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 99.1       |
| NumTrajs                | 27         |
| Perplexity              | 2469.7     |
| PolicyExecTime          | 0.565      |
| ProcessExecTime         | 0.0759     |
| StdReturn               | 70.6       |
| Time                    | 3.43e+03   |
| dLoss                   | 0.04974    |
----------------------------------------
itr #192 | 
Mem: 754.093750
Obtaining samples...
Obtaining samples for iteration 192...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5124, #subsample_inputs: 5124
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.659      |
| AbsLearnSignalNew       | 0.659      |
| AbsLearningOld          | 0.659      |
| AverageDiscountedReturn | 112        |
| AveragePhiLoss          | 11.429     |
| AveragePolicyStd        | 0.886633   |
| AverageReturn           | 279        |
| Entropy                 | 7.78513    |
| EnvExecTime             | 2.42       |
| ExplainedVariance       | 0.537      |
| Iteration               | 192        |
| ItrTime                 | 17.2       |
| LossAfter               | 0.791638   |
| LossBefore              | 0.849705   |
| MaxReturn               | 401        |
| MeanKL                  | 0.00996228 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 30         |
| NumTrajs                | 29         |
| Perplexity              | 2404.58    |
| PolicyExecTime          | 0.479      |
| ProcessExecTime         | 0.0655     |
| StdReturn               | 107        |
| Time                    | 3.45e+03   |
| dLoss                   | 0.058067   |
----------------------------------------
itr #193 | 
Mem: 754.093750
Obtaining samples...
Obtaining samples for iteration 193...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5094, #subsample_inputs: 5094
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.713      |
| AbsLearnSignalNew       | 0.713      |
| AbsLearningOld          | 0.713      |
| AverageDiscountedReturn | 119        |
| AveragePhiLoss          | 11.3926    |
| AveragePolicyStd        | 0.887201   |
| AverageReturn           | 320        |
| Entropy                 | 7.78888    |
| EnvExecTime             | 2.92       |
| ExplainedVariance       | 0.613      |
| Iteration               | 193        |
| ItrTime                 | 18.1       |
| LossAfter               | 0.408229   |
| LossBefore              | 0.474293   |
| MaxReturn               | 431        |
| MeanKL                  | 0.00995256 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 42.8       |
| NumTrajs                | 27         |
| Perplexity              | 2413.61    |
| PolicyExecTime          | 0.619      |
| ProcessExecTime         | 0.0838     |
| StdReturn               | 82.5       |
| Time                    | 3.47e+03   |
| dLoss                   | 0.0660648  |
----------------------------------------
itr #194 | 
Mem: 754.093750
Obtaining samples...
Obtaining samples for iteration 194...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5094, #subsample_inputs: 5094
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.646      |
| AbsLearnSignalNew       | 0.646      |
| AbsLearningOld          | 0.645      |
| AverageDiscountedReturn | 114        |
| AveragePhiLoss          | 11.6299    |
| AveragePolicyStd        | 0.885606   |
| AverageReturn           | 332        |
| Entropy                 | 7.77838    |
| EnvExecTime             | 2.6        |
| ExplainedVariance       | 0.546      |
| Iteration               | 194        |
| ItrTime                 | 18.1       |
| LossAfter               | 0.840811   |
| LossBefore              | 0.906314   |
| MaxReturn               | 561        |
| MeanKL                  | 0.00972669 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 42.8       |
| NumTrajs                | 24         |
| Perplexity              | 2388.4     |
| PolicyExecTime          | 0.519      |
| ProcessExecTime         | 0.0687     |
| StdReturn               | 123        |
| Time                    | 3.48e+03   |
| dLoss                   | 0.0655029  |
----------------------------------------
itr #195 | 
Mem: 754.093750
Obtaining samples...
Obtaining samples for iteration 195...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5070, #subsample_inputs: 5070
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.671      |
| AbsLearnSignalNew       | 0.671      |
| AbsLearningOld          | 0.67       |
| AverageDiscountedReturn | 119        |
| AveragePhiLoss          | 11.2587    |
| AveragePolicyStd        | 0.885438   |
| AverageReturn           | 326        |
| Entropy                 | 7.77766    |
| EnvExecTime             | 2.79       |
| ExplainedVariance       | 0.594      |
| Iteration               | 195        |
| ItrTime                 | 17.4       |
| LossAfter               | 1.16155    |
| LossBefore              | 1.22398    |
| MaxReturn               | 492        |
| MeanKL                  | 0.00999623 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 58.4       |
| NumTrajs                | 26         |
| Perplexity              | 2386.68    |
| PolicyExecTime          | 0.589      |
| ProcessExecTime         | 0.0774     |
| StdReturn               | 96.6       |
| Time                    | 3.5e+03    |
| dLoss                   | 0.06243    |
----------------------------------------
itr #196 | 
Mem: 754.093750
Obtaining samples...
Obtaining samples for iteration 196...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5223, #subsample_inputs: 5223
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.674      |
| AbsLearnSignalNew       | 0.674      |
| AbsLearningOld          | 0.674      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 11.1523    |
| AveragePolicyStd        | 0.882527   |
| AverageReturn           | 338        |
| Entropy                 | 7.75758    |
| EnvExecTime             | 2.63       |
| ExplainedVariance       | 0.612      |
| Iteration               | 196        |
| ItrTime                 | 18.5       |
| LossAfter               | 1.50376    |
| LossBefore              | 1.55177    |
| MaxReturn               | 468        |
| MeanKL                  | 0.00647158 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 83.8       |
| NumTrajs                | 26         |
| Perplexity              | 2339.25    |
| PolicyExecTime          | 0.554      |
| ProcessExecTime         | 0.0705     |
| StdReturn               | 93.5       |
| Time                    | 3.52e+03   |
| dLoss                   | 0.0480049  |
----------------------------------------
itr #197 | 
Mem: 754.093750
Obtaining samples...
Obtaining samples for iteration 197...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5055, #subsample_inputs: 5055
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.689      |
| AbsLearnSignalNew       | 0.689      |
| AbsLearningOld          | 0.69       |
| AverageDiscountedReturn | 117        |
| AveragePhiLoss          | 11.7697    |
| AveragePolicyStd        | 0.880924   |
| AverageReturn           | 331        |
| Entropy                 | 7.74658    |
| EnvExecTime             | 2.74       |
| ExplainedVariance       | 0.538      |
| Iteration               | 197        |
| ItrTime                 | 17.5       |
| LossAfter               | 0.300045   |
| LossBefore              | 0.349687   |
| MaxReturn               | 453        |
| MeanKL                  | 0.00642578 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 81.5       |
| NumTrajs                | 25         |
| Perplexity              | 2313.64    |
| PolicyExecTime          | 0.541      |
| ProcessExecTime         | 0.0714     |
| StdReturn               | 92.1       |
| Time                    | 3.54e+03   |
| dLoss                   | 0.049642   |
----------------------------------------
itr #198 | 
Mem: 754.093750
Obtaining samples...
Obtaining samples for iteration 198...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5146, #subsample_inputs: 5146
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.659      |
| AbsLearnSignalNew       | 0.659      |
| AbsLearningOld          | 0.659      |
| AverageDiscountedReturn | 112        |
| AveragePhiLoss          | 12.2368    |
| AveragePolicyStd        | 0.879317   |
| AverageReturn           | 321        |
| Entropy                 | 7.73528    |
| EnvExecTime             | 3.04       |
| ExplainedVariance       | 0.497      |
| Iteration               | 198        |
| ItrTime                 | 18.3       |
| LossAfter               | 0.546375   |
| LossBefore              | 0.599395   |
| MaxReturn               | 603        |
| MeanKL                  | 0.00650808 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 74.8       |
| NumTrajs                | 25         |
| Perplexity              | 2287.66    |
| PolicyExecTime          | 0.647      |
| ProcessExecTime         | 0.0837     |
| StdReturn               | 125        |
| Time                    | 3.56e+03   |
| dLoss                   | 0.0530204  |
----------------------------------------
itr #199 | 
Mem: 754.093750
Obtaining samples...
Obtaining samples for iteration 199...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5125, #subsample_inputs: 5125
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.675      |
| AbsLearnSignalNew       | 0.675      |
| AbsLearningOld          | 0.675      |
| AverageDiscountedReturn | 118        |
| AveragePhiLoss          | 11.0953    |
| AveragePolicyStd        | 0.878581   |
| AverageReturn           | 324        |
| Entropy                 | 7.73054    |
| EnvExecTime             | 2.66       |
| ExplainedVariance       | 0.557      |
| Iteration               | 199        |
| ItrTime                 | 18         |
| LossAfter               | -0.485869  |
| LossBefore              | -0.425209  |
| MaxReturn               | 527        |
| MeanKL                  | 0.00991884 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 64.2       |
| NumTrajs                | 26         |
| Perplexity              | 2276.84    |
| PolicyExecTime          | 0.513      |
| ProcessExecTime         | 0.0677     |
| StdReturn               | 103        |
| Time                    | 3.57e+03   |
| dLoss                   | 0.0606595  |
----------------------------------------
itr #200 | 
Mem: 754.093750
Obtaining samples...
Obtaining samples for iteration 200...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5020, #subsample_inputs: 5020
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.728      |
| AbsLearnSignalNew       | 0.728      |
| AbsLearningOld          | 0.728      |
| AverageDiscountedReturn | 123        |
| AveragePhiLoss          | 11.9585    |
| AveragePolicyStd        | 0.876983   |
| AverageReturn           | 357        |
| Entropy                 | 7.71984    |
| EnvExecTime             | 2.84       |
| ExplainedVariance       | 0.598      |
| Iteration               | 200        |
| ItrTime                 | 17.7       |
| LossAfter               | -0.307627  |
| LossBefore              | -0.248239  |
| MaxReturn               | 528        |
| MeanKL                  | 0.00995973 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 66         |
| NumTrajs                | 24         |
| Perplexity              | 2252.59    |
| PolicyExecTime          | 0.599      |
| ProcessExecTime         | 0.0807     |
| StdReturn               | 101        |
| Time                    | 3.59e+03   |
| dLoss                   | 0.0593882  |
----------------------------------------
itr #201 | 
Mem: 754.093750
Obtaining samples...
Obtaining samples for iteration 201...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5067, #subsample_inputs: 5067
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.676     |
| AbsLearnSignalNew       | 0.676     |
| AbsLearningOld          | 0.676     |
| AverageDiscountedReturn | 119       |
| AveragePhiLoss          | 11.1383   |
| AveragePolicyStd        | 0.877086  |
| AverageReturn           | 319       |
| Entropy                 | 7.71983   |
| EnvExecTime             | 2.66      |
| ExplainedVariance       | 0.561     |
| Iteration               | 201       |
| ItrTime                 | 18        |
| LossAfter               | 1.58172   |
| LossBefore              | 1.64956   |
| MaxReturn               | 492       |
| MeanKL                  | 0.0099081 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 84.9      |
| NumTrajs                | 26        |
| Perplexity              | 2252.58   |
| PolicyExecTime          | 0.57      |
| ProcessExecTime         | 0.0741    |
| StdReturn               | 91.3      |
| Time                    | 3.61e+03  |
| dLoss                   | 0.0678457 |
---------------------------------------
itr #202 | 
Mem: 754.093750
Obtaining samples...
Obtaining samples for iteration 202...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5127, #subsample_inputs: 5127
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.682      |
| AbsLearnSignalNew       | 0.682      |
| AbsLearningOld          | 0.682      |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 11.4357    |
| AveragePolicyStd        | 0.875443   |
| AverageReturn           | 360        |
| Entropy                 | 7.70882    |
| EnvExecTime             | 2.87       |
| ExplainedVariance       | 0.602      |
| Iteration               | 202        |
| ItrTime                 | 17.4       |
| LossAfter               | 0.546648   |
| LossBefore              | 0.593695   |
| MaxReturn               | 544        |
| MeanKL                  | 0.00648823 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 99.1       |
| NumTrajs                | 24         |
| Perplexity              | 2227.91    |
| PolicyExecTime          | 0.584      |
| ProcessExecTime         | 0.0763     |
| StdReturn               | 93.6       |
| Time                    | 3.63e+03   |
| dLoss                   | 0.0470473  |
----------------------------------------
itr #203 | 
Mem: 754.093750
Obtaining samples...
Obtaining samples for iteration 203...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5125, #subsample_inputs: 5125
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.65       |
| AbsLearnSignalNew       | 0.65       |
| AbsLearningOld          | 0.65       |
| AverageDiscountedReturn | 115        |
| AveragePhiLoss          | 12.3819    |
| AveragePolicyStd        | 0.873763   |
| AverageReturn           | 323        |
| Entropy                 | 7.69746    |
| EnvExecTime             | 3.04       |
| ExplainedVariance       | 0.493      |
| Iteration               | 203        |
| ItrTime                 | 18.7       |
| LossAfter               | 1.14538    |
| LossBefore              | 1.20635    |
| MaxReturn               | 495        |
| MeanKL                  | 0.00996605 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 63.7       |
| NumTrajs                | 25         |
| Perplexity              | 2202.75    |
| PolicyExecTime          | 0.644      |
| ProcessExecTime         | 0.085      |
| StdReturn               | 111        |
| Time                    | 3.65e+03   |
| dLoss                   | 0.0609627  |
----------------------------------------
itr #204 | 
Mem: 754.093750
Obtaining samples...
Obtaining samples for iteration 204...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5061, #subsample_inputs: 5061
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.746      |
| AbsLearnSignalNew       | 0.746      |
| AbsLearningOld          | 0.746      |
| AverageDiscountedReturn | 116        |
| AveragePhiLoss          | 12.0208    |
| AveragePolicyStd        | 0.87491    |
| AverageReturn           | 312        |
| Entropy                 | 7.7054     |
| EnvExecTime             | 2.54       |
| ExplainedVariance       | 0.56       |
| Iteration               | 204        |
| ItrTime                 | 17.6       |
| LossAfter               | 0.505789   |
| LossBefore              | 0.566269   |
| MaxReturn               | 471        |
| MeanKL                  | 0.00986071 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 40.3       |
| NumTrajs                | 26         |
| Perplexity              | 2220.31    |
| PolicyExecTime          | 0.474      |
| ProcessExecTime         | 0.0635     |
| StdReturn               | 114        |
| Time                    | 3.66e+03   |
| dLoss                   | 0.0604796  |
----------------------------------------
itr #205 | 
Mem: 754.093750
Obtaining samples...
Obtaining samples for iteration 205...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5177, #subsample_inputs: 5177
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.721      |
| AbsLearnSignalNew       | 0.721      |
| AbsLearningOld          | 0.721      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 11.4055    |
| AveragePolicyStd        | 0.874925   |
| AverageReturn           | 331        |
| Entropy                 | 7.70536    |
| EnvExecTime             | 3.17       |
| ExplainedVariance       | 0.644      |
| Iteration               | 205        |
| ItrTime                 | 18.2       |
| LossAfter               | 0.359091   |
| LossBefore              | 0.415956   |
| MaxReturn               | 502        |
| MeanKL                  | 0.00989257 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 64.9       |
| NumTrajs                | 26         |
| Perplexity              | 2220.22    |
| PolicyExecTime          | 0.647      |
| ProcessExecTime         | 0.0865     |
| StdReturn               | 92         |
| Time                    | 3.68e+03   |
| dLoss                   | 0.0568649  |
----------------------------------------
itr #206 | 
Mem: 754.093750
Obtaining samples...
Obtaining samples for iteration 206...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5166, #subsample_inputs: 5166
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.682      |
| AbsLearnSignalNew       | 0.682      |
| AbsLearningOld          | 0.682      |
| AverageDiscountedReturn | 124        |
| AveragePhiLoss          | 12.0672    |
| AveragePolicyStd        | 0.874461   |
| AverageReturn           | 369        |
| Entropy                 | 7.70233    |
| EnvExecTime             | 2.79       |
| ExplainedVariance       | 0.526      |
| Iteration               | 206        |
| ItrTime                 | 18.4       |
| LossAfter               | -0.475424  |
| LossBefore              | -0.406894  |
| MaxReturn               | 621        |
| MeanKL                  | 0.00989741 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 154        |
| NumTrajs                | 24         |
| Perplexity              | 2213.51    |
| PolicyExecTime          | 0.582      |
| ProcessExecTime         | 0.076      |
| StdReturn               | 95.4       |
| Time                    | 3.7e+03    |
| dLoss                   | 0.06853    |
----------------------------------------
itr #207 | 
Mem: 754.093750
Obtaining samples...
Obtaining samples for iteration 207...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5022, #subsample_inputs: 5022
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.688      |
| AbsLearnSignalNew       | 0.688      |
| AbsLearningOld          | 0.687      |
| AverageDiscountedReturn | 114        |
| AveragePhiLoss          | 11.7165    |
| AveragePolicyStd        | 0.873125   |
| AverageReturn           | 360        |
| Entropy                 | 7.69271    |
| EnvExecTime             | 2.87       |
| ExplainedVariance       | 0.477      |
| Iteration               | 207        |
| ItrTime                 | 17.7       |
| LossAfter               | 1.46758    |
| LossBefore              | 1.52561    |
| MaxReturn               | 569        |
| MeanKL                  | 0.00990449 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 96.6       |
| NumTrajs                | 22         |
| Perplexity              | 2192.31    |
| PolicyExecTime          | 0.547      |
| ProcessExecTime         | 0.0712     |
| StdReturn               | 145        |
| Time                    | 3.72e+03   |
| dLoss                   | 0.0580322  |
----------------------------------------
itr #208 | 
Mem: 754.093750
Obtaining samples...
Obtaining samples for iteration 208...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5338, #subsample_inputs: 5338
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.689      |
| AbsLearnSignalNew       | 0.689      |
| AbsLearningOld          | 0.689      |
| AverageDiscountedReturn | 123        |
| AveragePhiLoss          | 12.3476    |
| AveragePolicyStd        | 0.871108   |
| AverageReturn           | 347        |
| Entropy                 | 7.67981    |
| EnvExecTime             | 2.91       |
| ExplainedVariance       | 0.529      |
| Iteration               | 208        |
| ItrTime                 | 18.6       |
| LossAfter               | 0.139311   |
| LossBefore              | 0.191489   |
| MaxReturn               | 521        |
| MeanKL                  | 0.00643123 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 105        |
| NumTrajs                | 26         |
| Perplexity              | 2164.2     |
| PolicyExecTime          | 0.615      |
| ProcessExecTime         | 0.0832     |
| StdReturn               | 97.8       |
| Time                    | 3.74e+03   |
| dLoss                   | 0.0521776  |
----------------------------------------
itr #209 | 
Mem: 754.093750
Obtaining samples...
Obtaining samples for iteration 209...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5134, #subsample_inputs: 5134
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.718      |
| AbsLearnSignalNew       | 0.718      |
| AbsLearningOld          | 0.717      |
| AverageDiscountedReturn | 116        |
| AveragePhiLoss          | 12.0929    |
| AveragePolicyStd        | 0.869145   |
| AverageReturn           | 356        |
| Entropy                 | 7.66651    |
| EnvExecTime             | 2.67       |
| ExplainedVariance       | 0.536      |
| Iteration               | 209        |
| ItrTime                 | 17.7       |
| LossAfter               | 0.185669   |
| LossBefore              | 0.228621   |
| MaxReturn               | 548        |
| MeanKL                  | 0.00648588 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 58.3       |
| NumTrajs                | 23         |
| Perplexity              | 2135.61    |
| PolicyExecTime          | 0.532      |
| ProcessExecTime         | 0.0702     |
| StdReturn               | 141        |
| Time                    | 3.76e+03   |
| dLoss                   | 0.0429519  |
----------------------------------------
itr #210 | 
Mem: 754.093750
Obtaining samples...
Obtaining samples for iteration 210...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5054, #subsample_inputs: 5054
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.71       |
| AbsLearnSignalNew       | 0.71       |
| AbsLearningOld          | 0.71       |
| AverageDiscountedReturn | 110        |
| AveragePhiLoss          | 12.2008    |
| AveragePolicyStd        | 0.868057   |
| AverageReturn           | 317        |
| Entropy                 | 7.6586     |
| EnvExecTime             | 2.96       |
| ExplainedVariance       | 0.507      |
| Iteration               | 210        |
| ItrTime                 | 17.7       |
| LossAfter               | 0.236934   |
| LossBefore              | 0.287948   |
| MaxReturn               | 554        |
| MeanKL                  | 0.00640664 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 57         |
| NumTrajs                | 23         |
| Perplexity              | 2118.78    |
| PolicyExecTime          | 0.593      |
| ProcessExecTime         | 0.0773     |
| StdReturn               | 134        |
| Time                    | 3.77e+03   |
| dLoss                   | 0.0510138  |
----------------------------------------
itr #211 | 
Mem: 754.093750
Obtaining samples...
Obtaining samples for iteration 211...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5236, #subsample_inputs: 5236
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.749      |
| AbsLearnSignalNew       | 0.749      |
| AbsLearningOld          | 0.749      |
| AverageDiscountedReturn | 116        |
| AveragePhiLoss          | 12.6126    |
| AveragePolicyStd        | 0.868193   |
| AverageReturn           | 334        |
| Entropy                 | 7.65962    |
| EnvExecTime             | 2.98       |
| ExplainedVariance       | 0.574      |
| Iteration               | 211        |
| ItrTime                 | 18.7       |
| LossAfter               | 0.419679   |
| LossBefore              | 0.481278   |
| MaxReturn               | 529        |
| MeanKL                  | 0.00999375 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 70.2       |
| NumTrajs                | 24         |
| Perplexity              | 2120.96    |
| PolicyExecTime          | 0.616      |
| ProcessExecTime         | 0.0792     |
| StdReturn               | 114        |
| Time                    | 3.79e+03   |
| dLoss                   | 0.0615993  |
----------------------------------------
itr #212 | 
Mem: 754.093750
Obtaining samples...
Obtaining samples for iteration 212...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5214, #subsample_inputs: 5214
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.638      |
| AbsLearnSignalNew       | 0.638      |
| AbsLearningOld          | 0.639      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 12.1874    |
| AveragePolicyStd        | 0.869224   |
| AverageReturn           | 342        |
| Entropy                 | 7.66566    |
| EnvExecTime             | 2.4        |
| ExplainedVariance       | 0.225      |
| Iteration               | 212        |
| ItrTime                 | 17.8       |
| LossAfter               | 0.115182   |
| LossBefore              | 0.159344   |
| MaxReturn               | 610        |
| MeanKL                  | 0.00644524 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 64.3       |
| NumTrajs                | 26         |
| Perplexity              | 2133.8     |
| PolicyExecTime          | 0.463      |
| ProcessExecTime         | 0.0648     |
| StdReturn               | 95.7       |
| Time                    | 3.81e+03   |
| dLoss                   | 0.0441624  |
----------------------------------------
itr #213 | 
Mem: 754.093750
Obtaining samples...
Obtaining samples for iteration 213...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5032, #subsample_inputs: 5032
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.643      |
| AbsLearnSignalNew       | 0.643      |
| AbsLearningOld          | 0.642      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 12.0626    |
| AveragePolicyStd        | 0.870298   |
| AverageReturn           | 371        |
| Entropy                 | 7.6734     |
| EnvExecTime             | 2.93       |
| ExplainedVariance       | 0.593      |
| Iteration               | 213        |
| ItrTime                 | 17.5       |
| LossAfter               | -0.0127174 |
| LossBefore              | 0.0487373  |
| MaxReturn               | 599        |
| MeanKL                  | 0.00992793 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 87.1       |
| NumTrajs                | 24         |
| Perplexity              | 2150.37    |
| PolicyExecTime          | 0.617      |
| ProcessExecTime         | 0.0853     |
| StdReturn               | 110        |
| Time                    | 3.83e+03   |
| dLoss                   | 0.0614547  |
----------------------------------------
itr #214 | 
Mem: 754.093750
Obtaining samples...
Obtaining samples for iteration 214...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5141, #subsample_inputs: 5141
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.684      |
| AbsLearnSignalNew       | 0.684      |
| AbsLearningOld          | 0.684      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 12.0416    |
| AveragePolicyStd        | 0.868355   |
| AverageReturn           | 353        |
| Entropy                 | 7.65909    |
| EnvExecTime             | 2.75       |
| ExplainedVariance       | 0.537      |
| Iteration               | 214        |
| ItrTime                 | 18.6       |
| LossAfter               | 0.327312   |
| LossBefore              | 0.389184   |
| MaxReturn               | 668        |
| MeanKL                  | 0.00991814 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 75.2       |
| NumTrajs                | 26         |
| Perplexity              | 2119.83    |
| PolicyExecTime          | 0.548      |
| ProcessExecTime         | 0.0714     |
| StdReturn               | 118        |
| Time                    | 3.85e+03   |
| dLoss                   | 0.0618719  |
----------------------------------------
itr #215 | 
Mem: 754.093750
Obtaining samples...
Obtaining samples for iteration 215...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5063, #subsample_inputs: 5063
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.708      |
| AbsLearnSignalNew       | 0.708      |
| AbsLearningOld          | 0.708      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 12.2095    |
| AveragePolicyStd        | 0.86946    |
| AverageReturn           | 367        |
| Entropy                 | 7.66651    |
| EnvExecTime             | 2.81       |
| ExplainedVariance       | 0.563      |
| Iteration               | 215        |
| ItrTime                 | 17.3       |
| LossAfter               | 0.957804   |
| LossBefore              | 1.01841    |
| MaxReturn               | 598        |
| MeanKL                  | 0.00983956 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 62.9       |
| NumTrajs                | 24         |
| Perplexity              | 2135.61    |
| PolicyExecTime          | 0.571      |
| ProcessExecTime         | 0.0777     |
| StdReturn               | 133        |
| Time                    | 3.86e+03   |
| dLoss                   | 0.060601   |
----------------------------------------
itr #216 | 
Mem: 754.847656
Obtaining samples...
Obtaining samples for iteration 216...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5048, #subsample_inputs: 5048
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.688      |
| AbsLearnSignalNew       | 0.688      |
| AbsLearningOld          | 0.688      |
| AverageDiscountedReturn | 124        |
| AveragePhiLoss          | 11.8026    |
| AveragePolicyStd        | 0.871973   |
| AverageReturn           | 378        |
| Entropy                 | 7.68343    |
| EnvExecTime             | 2.65       |
| ExplainedVariance       | 0.611      |
| Iteration               | 216        |
| ItrTime                 | 17.5       |
| LossAfter               | -0.226491  |
| LossBefore              | -0.176673  |
| MaxReturn               | 583        |
| MeanKL                  | 0.00644575 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 108        |
| NumTrajs                | 23         |
| Perplexity              | 2172.06    |
| PolicyExecTime          | 0.55       |
| ProcessExecTime         | 0.0732     |
| StdReturn               | 103        |
| Time                    | 3.88e+03   |
| dLoss                   | 0.0498178  |
----------------------------------------
itr #217 | 
Mem: 755.277344
Obtaining samples...
Obtaining samples for iteration 217...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5028, #subsample_inputs: 5028
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.702      |
| AbsLearnSignalNew       | 0.702      |
| AbsLearningOld          | 0.702      |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 11.9698    |
| AveragePolicyStd        | 0.872307   |
| AverageReturn           | 395        |
| Entropy                 | 7.6856     |
| EnvExecTime             | 2.62       |
| ExplainedVariance       | 0.626      |
| Iteration               | 217        |
| ItrTime                 | 17.1       |
| LossAfter               | -0.763001  |
| LossBefore              | -0.687568  |
| MaxReturn               | 597        |
| MeanKL                  | 0.00999131 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 306        |
| NumTrajs                | 23         |
| Perplexity              | 2176.76    |
| PolicyExecTime          | 0.533      |
| ProcessExecTime         | 0.0732     |
| StdReturn               | 82.7       |
| Time                    | 3.9e+03    |
| dLoss                   | 0.0754334  |
----------------------------------------
itr #218 | 
Mem: 755.296875
Obtaining samples...
Obtaining samples for iteration 218...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5051, #subsample_inputs: 5051
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.655     |
| AbsLearnSignalNew       | 0.655     |
| AbsLearningOld          | 0.655     |
| AverageDiscountedReturn | 114       |
| AveragePhiLoss          | 12.3062   |
| AveragePolicyStd        | 0.869134  |
| AverageReturn           | 325       |
| Entropy                 | 7.66387   |
| EnvExecTime             | 2.78      |
| ExplainedVariance       | 0.379     |
| Iteration               | 218       |
| ItrTime                 | 18.5      |
| LossAfter               | -0.829284 |
| LossBefore              | -0.778649 |
| MaxReturn               | 578       |
| MeanKL                  | 0.0064575 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 42.2      |
| NumTrajs                | 24        |
| Perplexity              | 2129.99   |
| PolicyExecTime          | 0.565     |
| ProcessExecTime         | 0.0758    |
| StdReturn               | 140       |
| Time                    | 3.92e+03  |
| dLoss                   | 0.0506343 |
---------------------------------------
itr #219 | 
Mem: 755.296875
Obtaining samples...
Obtaining samples for iteration 219...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5066, #subsample_inputs: 5066
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.742      |
| AbsLearnSignalNew       | 0.742      |
| AbsLearningOld          | 0.742      |
| AverageDiscountedReturn | 124        |
| AveragePhiLoss          | 12.4544    |
| AveragePolicyStd        | 0.867676   |
| AverageReturn           | 362        |
| Entropy                 | 7.65371    |
| EnvExecTime             | 2.51       |
| ExplainedVariance       | 0.455      |
| Iteration               | 219        |
| ItrTime                 | 16.9       |
| LossAfter               | -0.163489  |
| LossBefore              | -0.097166  |
| MaxReturn               | 666        |
| MeanKL                  | 0.00993724 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 67         |
| NumTrajs                | 24         |
| Perplexity              | 2108.45    |
| PolicyExecTime          | 0.481      |
| ProcessExecTime         | 0.064      |
| StdReturn               | 138        |
| Time                    | 3.93e+03   |
| dLoss                   | 0.0663231  |
----------------------------------------
itr #220 | 
Mem: 755.296875
Obtaining samples...
Obtaining samples for iteration 220...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5044, #subsample_inputs: 5044
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.748      |
| AbsLearnSignalNew       | 0.748      |
| AbsLearningOld          | 0.748      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 12.1635    |
| AveragePolicyStd        | 0.866533   |
| AverageReturn           | 379        |
| Entropy                 | 7.64547    |
| EnvExecTime             | 2.84       |
| ExplainedVariance       | 0.485      |
| Iteration               | 220        |
| ItrTime                 | 17.9       |
| LossAfter               | -0.149028  |
| LossBefore              | -0.0974582 |
| MaxReturn               | 505        |
| MeanKL                  | 0.00642477 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 114        |
| NumTrajs                | 23         |
| Perplexity              | 2091.14    |
| PolicyExecTime          | 0.582      |
| ProcessExecTime         | 0.0806     |
| StdReturn               | 84.8       |
| Time                    | 3.95e+03   |
| dLoss                   | 0.0515699  |
----------------------------------------
itr #221 | 
Mem: 755.296875
Obtaining samples...
Obtaining samples for iteration 221...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5136, #subsample_inputs: 5136
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.655      |
| AbsLearnSignalNew       | 0.655      |
| AbsLearningOld          | 0.655      |
| AverageDiscountedReturn | 118        |
| AveragePhiLoss          | 11.9317    |
| AveragePolicyStd        | 0.864557   |
| AverageReturn           | 353        |
| Entropy                 | 7.63149    |
| EnvExecTime             | 2.58       |
| ExplainedVariance       | 0.414      |
| Iteration               | 221        |
| ItrTime                 | 17.3       |
| LossAfter               | 0.453727   |
| LossBefore              | 0.516609   |
| MaxReturn               | 635        |
| MeanKL                  | 0.00991405 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 55.6       |
| NumTrajs                | 24         |
| Perplexity              | 2062.13    |
| PolicyExecTime          | 0.476      |
| ProcessExecTime         | 0.0646     |
| StdReturn               | 146        |
| Time                    | 3.97e+03   |
| dLoss                   | 0.0628825  |
----------------------------------------
itr #222 | 
Mem: 755.296875
Obtaining samples...
Obtaining samples for iteration 222...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5109, #subsample_inputs: 5109
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.726     |
| AbsLearnSignalNew       | 0.726     |
| AbsLearningOld          | 0.726     |
| AverageDiscountedReturn | 128       |
| AveragePhiLoss          | 11.8359   |
| AveragePolicyStd        | 0.865333  |
| AverageReturn           | 371       |
| Entropy                 | 7.63636   |
| EnvExecTime             | 2.77      |
| ExplainedVariance       | 0.518     |
| Iteration               | 222       |
| ItrTime                 | 17.8      |
| LossAfter               | 0.266443  |
| LossBefore              | 0.315257  |
| MaxReturn               | 493       |
| MeanKL                  | 0.006482  |
| MeanKLBefore            | 0.0       |
| MinReturn               | 265       |
| NumTrajs                | 25        |
| Perplexity              | 2072.2    |
| PolicyExecTime          | 0.583     |
| ProcessExecTime         | 0.0784    |
| StdReturn               | 64.7      |
| Time                    | 3.99e+03  |
| dLoss                   | 0.0488139 |
---------------------------------------
itr #223 | 
Mem: 755.296875
Obtaining samples...
Obtaining samples for iteration 223...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5159, #subsample_inputs: 5159
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.668      |
| AbsLearnSignalNew       | 0.668      |
| AbsLearningOld          | 0.668      |
| AverageDiscountedReturn | 124        |
| AveragePhiLoss          | 12.7552    |
| AveragePolicyStd        | 0.862993   |
| AverageReturn           | 351        |
| Entropy                 | 7.61979    |
| EnvExecTime             | 2.65       |
| ExplainedVariance       | 0.382      |
| Iteration               | 223        |
| ItrTime                 | 18.1       |
| LossAfter               | -1.05118   |
| LossBefore              | -0.993185  |
| MaxReturn               | 568        |
| MeanKL                  | 0.00989634 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 122        |
| NumTrajs                | 25         |
| Perplexity              | 2038.14    |
| PolicyExecTime          | 0.54       |
| ProcessExecTime         | 0.0643     |
| StdReturn               | 106        |
| Time                    | 4.01e+03   |
| dLoss                   | 0.0579944  |
----------------------------------------
itr #224 | 
Mem: 755.296875
Obtaining samples...
Obtaining samples for iteration 224...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5067, #subsample_inputs: 5067
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.678      |
| AbsLearnSignalNew       | 0.678      |
| AbsLearningOld          | 0.678      |
| AverageDiscountedReturn | 117        |
| AveragePhiLoss          | 11.8246    |
| AveragePolicyStd        | 0.863792   |
| AverageReturn           | 375        |
| Entropy                 | 7.62454    |
| EnvExecTime             | 2.94       |
| ExplainedVariance       | 0.488      |
| Iteration               | 224        |
| ItrTime                 | 17.5       |
| LossAfter               | -0.560435  |
| LossBefore              | -0.504171  |
| MaxReturn               | 557        |
| MeanKL                  | 0.00990923 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 66.4       |
| NumTrajs                | 22         |
| Perplexity              | 2047.84    |
| PolicyExecTime          | 0.614      |
| ProcessExecTime         | 0.0784     |
| StdReturn               | 126        |
| Time                    | 4.02e+03   |
| dLoss                   | 0.0562643  |
----------------------------------------
itr #225 | 
Mem: 755.296875
Obtaining samples...
Obtaining samples for iteration 225...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5067, #subsample_inputs: 5067
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.687      |
| AbsLearnSignalNew       | 0.687      |
| AbsLearningOld          | 0.687      |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 11.8197    |
| AveragePolicyStd        | 0.867711   |
| AverageReturn           | 378        |
| Entropy                 | 7.65138    |
| EnvExecTime             | 2.39       |
| ExplainedVariance       | 0.556      |
| Iteration               | 225        |
| ItrTime                 | 17.4       |
| LossAfter               | -0.835642  |
| LossBefore              | -0.766827  |
| MaxReturn               | 586        |
| MeanKL                  | 0.00994031 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 50         |
| NumTrajs                | 23         |
| Perplexity              | 2103.54    |
| PolicyExecTime          | 0.454      |
| ProcessExecTime         | 0.062      |
| StdReturn               | 123        |
| Time                    | 4.04e+03   |
| dLoss                   | 0.0688151  |
----------------------------------------
itr #226 | 
Mem: 755.296875
Obtaining samples...
Obtaining samples for iteration 226...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5185, #subsample_inputs: 5185
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.703      |
| AbsLearnSignalNew       | 0.703      |
| AbsLearningOld          | 0.703      |
| AverageDiscountedReturn | 127        |
| AveragePhiLoss          | 12.1554    |
| AveragePolicyStd        | 0.868316   |
| AverageReturn           | 401        |
| Entropy                 | 7.65582    |
| EnvExecTime             | 2.91       |
| ExplainedVariance       | 0.534      |
| Iteration               | 226        |
| ItrTime                 | 17.9       |
| LossAfter               | 0.949354   |
| LossBefore              | 0.999569   |
| MaxReturn               | 660        |
| MeanKL                  | 0.00646156 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 74.6       |
| NumTrajs                | 23         |
| Perplexity              | 2112.91    |
| PolicyExecTime          | 0.619      |
| ProcessExecTime         | 0.083      |
| StdReturn               | 111        |
| Time                    | 4.06e+03   |
| dLoss                   | 0.0502151  |
----------------------------------------
itr #227 | 
Mem: 755.296875
Obtaining samples...
Obtaining samples for iteration 227...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5024, #subsample_inputs: 5024
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.689     |
| AbsLearnSignalNew       | 0.689     |
| AbsLearningOld          | 0.689     |
| AverageDiscountedReturn | 126       |
| AveragePhiLoss          | 12.0135   |
| AveragePolicyStd        | 0.863667  |
| AverageReturn           | 386       |
| Entropy                 | 7.62213   |
| EnvExecTime             | 2.75      |
| ExplainedVariance       | 0.601     |
| Iteration               | 227       |
| ItrTime                 | 17.5      |
| LossAfter               | 0.797651  |
| LossBefore              | 0.847085  |
| MaxReturn               | 540       |
| MeanKL                  | 0.0064152 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 172       |
| NumTrajs                | 23        |
| Perplexity              | 2042.9    |
| PolicyExecTime          | 0.573     |
| ProcessExecTime         | 0.0698    |
| StdReturn               | 84.2      |
| Time                    | 4.08e+03  |
| dLoss                   | 0.0494335 |
---------------------------------------
itr #228 | 
Mem: 755.296875
Obtaining samples...
Obtaining samples for iteration 228...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5046, #subsample_inputs: 5046
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.648      |
| AbsLearnSignalNew       | 0.648      |
| AbsLearningOld          | 0.648      |
| AverageDiscountedReturn | 119        |
| AveragePhiLoss          | 11.8626    |
| AveragePolicyStd        | 0.864202   |
| AverageReturn           | 334        |
| Entropy                 | 7.62615    |
| EnvExecTime             | 2.58       |
| ExplainedVariance       | 0.498      |
| Iteration               | 228        |
| ItrTime                 | 17.1       |
| LossAfter               | 1.42287    |
| LossBefore              | 1.46998    |
| MaxReturn               | 512        |
| MeanKL                  | 0.00646175 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 81         |
| NumTrajs                | 25         |
| Perplexity              | 2051.15    |
| PolicyExecTime          | 0.527      |
| ProcessExecTime         | 0.0688     |
| StdReturn               | 112        |
| Time                    | 4.09e+03   |
| dLoss                   | 0.0471058  |
----------------------------------------
itr #229 | 
Mem: 755.296875
Obtaining samples...
Obtaining samples for iteration 229...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5048, #subsample_inputs: 5048
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.678      |
| AbsLearnSignalNew       | 0.678      |
| AbsLearningOld          | 0.678      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 12.6488    |
| AveragePolicyStd        | 0.862764   |
| AverageReturn           | 405        |
| Entropy                 | 7.6157     |
| EnvExecTime             | 2.71       |
| ExplainedVariance       | 0.458      |
| Iteration               | 229        |
| ItrTime                 | 17.5       |
| LossAfter               | 0.617393   |
| LossBefore              | 0.668011   |
| MaxReturn               | 914        |
| MeanKL                  | 0.00642155 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 49.6       |
| NumTrajs                | 21         |
| Perplexity              | 2029.82    |
| PolicyExecTime          | 0.539      |
| ProcessExecTime         | 0.0727     |
| StdReturn               | 166        |
| Time                    | 4.11e+03   |
| dLoss                   | 0.0506174  |
----------------------------------------
itr #230 | 
Mem: 755.296875
Obtaining samples...
Obtaining samples for iteration 230...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5128, #subsample_inputs: 5128
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.678      |
| AbsLearnSignalNew       | 0.678      |
| AbsLearningOld          | 0.678      |
| AverageDiscountedReturn | 129        |
| AveragePhiLoss          | 11.8533    |
| AveragePolicyStd        | 0.862637   |
| AverageReturn           | 378        |
| Entropy                 | 7.61455    |
| EnvExecTime             | 2.64       |
| ExplainedVariance       | 0.561      |
| Iteration               | 230        |
| ItrTime                 | 17.3       |
| LossAfter               | -0.866575  |
| LossBefore              | -0.818029  |
| MaxReturn               | 503        |
| MeanKL                  | 0.00647594 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 236        |
| NumTrajs                | 25         |
| Perplexity              | 2027.49    |
| PolicyExecTime          | 0.543      |
| ProcessExecTime         | 0.0704     |
| StdReturn               | 71.6       |
| Time                    | 4.13e+03   |
| dLoss                   | 0.0485461  |
----------------------------------------
itr #231 | 
Mem: 755.296875
Obtaining samples...
Obtaining samples for iteration 231...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5118, #subsample_inputs: 5118
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.697      |
| AbsLearnSignalNew       | 0.697      |
| AbsLearningOld          | 0.697      |
| AverageDiscountedReturn | 131        |
| AveragePhiLoss          | 11.9026    |
| AveragePolicyStd        | 0.859389   |
| AverageReturn           | 397        |
| Entropy                 | 7.59194    |
| EnvExecTime             | 2.94       |
| ExplainedVariance       | 0.601      |
| Iteration               | 231        |
| ItrTime                 | 18.2       |
| LossAfter               | -0.90665   |
| LossBefore              | -0.85382   |
| MaxReturn               | 591        |
| MeanKL                  | 0.00640798 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 266        |
| NumTrajs                | 24         |
| Perplexity              | 1982.16    |
| PolicyExecTime          | 0.633      |
| ProcessExecTime         | 0.0826     |
| StdReturn               | 98.1       |
| Time                    | 4.15e+03   |
| dLoss                   | 0.0528297  |
----------------------------------------
itr #232 | 
Mem: 755.957031
Obtaining samples...
Obtaining samples for iteration 232...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5106, #subsample_inputs: 5106
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.661      |
| AbsLearnSignalNew       | 0.661      |
| AbsLearningOld          | 0.661      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 11.7729    |
| AveragePolicyStd        | 0.857833   |
| AverageReturn           | 395        |
| Entropy                 | 7.58067    |
| EnvExecTime             | 2.71       |
| ExplainedVariance       | 0.3        |
| Iteration               | 232        |
| ItrTime                 | 17.8       |
| LossAfter               | -0.37292   |
| LossBefore              | -0.311281  |
| MaxReturn               | 706        |
| MeanKL                  | 0.00999882 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 81.5       |
| NumTrajs                | 21         |
| Perplexity              | 1959.94    |
| PolicyExecTime          | 0.514      |
| ProcessExecTime         | 0.0674     |
| StdReturn               | 162        |
| Time                    | 4.16e+03   |
| dLoss                   | 0.0616392  |
----------------------------------------
itr #233 | 
Mem: 756.207031
Obtaining samples...
Obtaining samples for iteration 233...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5138, #subsample_inputs: 5138
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.689      |
| AbsLearnSignalNew       | 0.689      |
| AbsLearningOld          | 0.689      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 12.0484    |
| AveragePolicyStd        | 0.860438   |
| AverageReturn           | 400        |
| Entropy                 | 7.59877    |
| EnvExecTime             | 2.81       |
| ExplainedVariance       | 0.462      |
| Iteration               | 233        |
| ItrTime                 | 17.5       |
| LossAfter               | -0.162459  |
| LossBefore              | -0.0950285 |
| MaxReturn               | 576        |
| MeanKL                  | 0.00997481 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 87.8       |
| NumTrajs                | 23         |
| Perplexity              | 1995.73    |
| PolicyExecTime          | 0.581      |
| ProcessExecTime         | 0.0773     |
| StdReturn               | 91.8       |
| Time                    | 4.18e+03   |
| dLoss                   | 0.0674301  |
----------------------------------------
itr #234 | 
Mem: 756.207031
Obtaining samples...
Obtaining samples for iteration 234...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5153, #subsample_inputs: 5153
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.647      |
| AbsLearnSignalNew       | 0.647      |
| AbsLearningOld          | 0.647      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 11.9656    |
| AveragePolicyStd        | 0.857098   |
| AverageReturn           | 377        |
| Entropy                 | 7.57615    |
| EnvExecTime             | 2.74       |
| ExplainedVariance       | 0.604      |
| Iteration               | 234        |
| ItrTime                 | 17.9       |
| LossAfter               | -0.493871  |
| LossBefore              | -0.440558  |
| MaxReturn               | 631        |
| MeanKL                  | 0.00647114 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 85.9       |
| NumTrajs                | 24         |
| Perplexity              | 1951.11    |
| PolicyExecTime          | 0.546      |
| ProcessExecTime         | 0.0693     |
| StdReturn               | 97.8       |
| Time                    | 4.2e+03    |
| dLoss                   | 0.0533125  |
----------------------------------------
itr #235 | 
Mem: 756.457031
Obtaining samples...
Obtaining samples for iteration 235...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5072, #subsample_inputs: 5072
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.629      |
| AbsLearnSignalNew       | 0.629      |
| AbsLearningOld          | 0.629      |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 12.9607    |
| AveragePolicyStd        | 0.855696   |
| AverageReturn           | 375        |
| Entropy                 | 7.56699    |
| EnvExecTime             | 2.68       |
| ExplainedVariance       | 0.597      |
| Iteration               | 235        |
| ItrTime                 | 17.1       |
| LossAfter               | 1.0231     |
| LossBefore              | 1.136      |
| MaxReturn               | 542        |
| MeanKL                  | 0.00999874 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 98.1       |
| NumTrajs                | 24         |
| Perplexity              | 1933.32    |
| PolicyExecTime          | 0.553      |
| ProcessExecTime         | 0.0745     |
| StdReturn               | 88.3       |
| Time                    | 4.22e+03   |
| dLoss                   | 0.112908   |
----------------------------------------
itr #236 | 
Mem: 756.566406
Obtaining samples...
Obtaining samples for iteration 236...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5038, #subsample_inputs: 5038
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.653      |
| AbsLearnSignalNew       | 0.653      |
| AbsLearningOld          | 0.653      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 12.6449    |
| AveragePolicyStd        | 0.856683   |
| AverageReturn           | 386        |
| Entropy                 | 7.57443    |
| EnvExecTime             | 2.72       |
| ExplainedVariance       | 0.544      |
| Iteration               | 236        |
| ItrTime                 | 18.1       |
| LossAfter               | 0.832448   |
| LossBefore              | 0.892483   |
| MaxReturn               | 719        |
| MeanKL                  | 0.00973381 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 140        |
| NumTrajs                | 23         |
| Perplexity              | 1947.75    |
| PolicyExecTime          | 0.554      |
| ProcessExecTime         | 0.0724     |
| StdReturn               | 125        |
| Time                    | 4.24e+03   |
| dLoss                   | 0.060035   |
----------------------------------------
itr #237 | 
Mem: 756.566406
Obtaining samples...
Obtaining samples for iteration 237...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5034, #subsample_inputs: 5034
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.681      |
| AbsLearnSignalNew       | 0.681      |
| AbsLearningOld          | 0.681      |
| AverageDiscountedReturn | 131        |
| AveragePhiLoss          | 12.1159    |
| AveragePolicyStd        | 0.85643    |
| AverageReturn           | 461        |
| Entropy                 | 7.57277    |
| EnvExecTime             | 2.58       |
| ExplainedVariance       | 0.59       |
| Iteration               | 237        |
| ItrTime                 | 17.1       |
| LossAfter               | 0.801326   |
| LossBefore              | 0.86674    |
| MaxReturn               | 655        |
| MeanKL                  | 0.00989212 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 321        |
| NumTrajs                | 20         |
| Perplexity              | 1944.51    |
| PolicyExecTime          | 0.511      |
| ProcessExecTime         | 0.0683     |
| StdReturn               | 100        |
| Time                    | 4.25e+03   |
| dLoss                   | 0.0654136  |
----------------------------------------
itr #238 | 
Mem: 756.566406
Obtaining samples...
Obtaining samples for iteration 238...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5018, #subsample_inputs: 5018
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.664      |
| AbsLearnSignalNew       | 0.664      |
| AbsLearningOld          | 0.664      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 12.3683    |
| AveragePolicyStd        | 0.857884   |
| AverageReturn           | 373        |
| Entropy                 | 7.58208    |
| EnvExecTime             | 2.74       |
| ExplainedVariance       | 0.456      |
| Iteration               | 238        |
| ItrTime                 | 17.8       |
| LossAfter               | 0.0634445  |
| LossBefore              | 0.11315    |
| MaxReturn               | 572        |
| MeanKL                  | 0.00641098 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 44.7       |
| NumTrajs                | 24         |
| Perplexity              | 1962.7     |
| PolicyExecTime          | 0.56       |
| ProcessExecTime         | 0.0774     |
| StdReturn               | 128        |
| Time                    | 4.27e+03   |
| dLoss                   | 0.0497057  |
----------------------------------------
itr #239 | 
Mem: 756.566406
Obtaining samples...
Obtaining samples for iteration 239...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5006, #subsample_inputs: 5006
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.681      |
| AbsLearnSignalNew       | 0.681      |
| AbsLearningOld          | 0.681      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 12.1484    |
| AveragePolicyStd        | 0.858706   |
| AverageReturn           | 352        |
| Entropy                 | 7.58755    |
| EnvExecTime             | 2.66       |
| ExplainedVariance       | 0.542      |
| Iteration               | 239        |
| ItrTime                 | 17.2       |
| LossAfter               | -0.175395  |
| LossBefore              | -0.122708  |
| MaxReturn               | 532        |
| MeanKL                  | 0.00992371 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 53.5       |
| NumTrajs                | 24         |
| Perplexity              | 1973.47    |
| PolicyExecTime          | 0.496      |
| ProcessExecTime         | 0.0657     |
| StdReturn               | 113        |
| Time                    | 4.29e+03   |
| dLoss                   | 0.0526875  |
----------------------------------------
itr #240 | 
Mem: 757.804688
Obtaining samples...
Obtaining samples for iteration 240...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5058, #subsample_inputs: 5058
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.681      |
| AbsLearnSignalNew       | 0.681      |
| AbsLearningOld          | 0.681      |
| AverageDiscountedReturn | 117        |
| AveragePhiLoss          | 12.4476    |
| AveragePolicyStd        | 0.858616   |
| AverageReturn           | 364        |
| Entropy                 | 7.5857     |
| EnvExecTime             | 2.93       |
| ExplainedVariance       | 0.512      |
| Iteration               | 240        |
| ItrTime                 | 18         |
| LossAfter               | -0.0771535 |
| LossBefore              | -0.0173521 |
| MaxReturn               | 539        |
| MeanKL                  | 0.00992033 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 62.8       |
| NumTrajs                | 22         |
| Perplexity              | 1969.83    |
| PolicyExecTime          | 0.6        |
| ProcessExecTime         | 0.0823     |
| StdReturn               | 125        |
| Time                    | 4.31e+03   |
| dLoss                   | 0.0598013  |
----------------------------------------
itr #241 | 
Mem: 757.804688
Obtaining samples...
Obtaining samples for iteration 241...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5079, #subsample_inputs: 5079
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.694      |
| AbsLearnSignalNew       | 0.694      |
| AbsLearningOld          | 0.694      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 12.1343    |
| AveragePolicyStd        | 0.857627   |
| AverageReturn           | 375        |
| Entropy                 | 7.57892    |
| EnvExecTime             | 2.5        |
| ExplainedVariance       | 0.523      |
| Iteration               | 241        |
| ItrTime                 | 17.3       |
| LossAfter               | -0.386088  |
| LossBefore              | -0.325041  |
| MaxReturn               | 608        |
| MeanKL                  | 0.00994681 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 63.1       |
| NumTrajs                | 23         |
| Perplexity              | 1956.51    |
| PolicyExecTime          | 0.475      |
| ProcessExecTime         | 0.0613     |
| StdReturn               | 135        |
| Time                    | 4.32e+03   |
| dLoss                   | 0.0610468  |
----------------------------------------
itr #242 | 
Mem: 757.851562
Obtaining samples...
Obtaining samples for iteration 242...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5064, #subsample_inputs: 5064
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.714     |
| AbsLearnSignalNew       | 0.714     |
| AbsLearningOld          | 0.715     |
| AverageDiscountedReturn | 128       |
| AveragePhiLoss          | 12.6199   |
| AveragePolicyStd        | 0.856386  |
| AverageReturn           | 387       |
| Entropy                 | 7.56948   |
| EnvExecTime             | 2.85      |
| ExplainedVariance       | 0.395     |
| Iteration               | 242       |
| ItrTime                 | 17.3      |
| LossAfter               | 0.308196  |
| LossBefore              | 0.372038  |
| MaxReturn               | 711       |
| MeanKL                  | 0.0099933 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 238       |
| NumTrajs                | 24        |
| Perplexity              | 1938.12   |
| PolicyExecTime          | 0.577     |
| ProcessExecTime         | 0.0794    |
| StdReturn               | 97.8      |
| Time                    | 4.34e+03  |
| dLoss                   | 0.0638422 |
---------------------------------------
itr #243 | 
Mem: 758.449219
Obtaining samples...
Obtaining samples for iteration 243...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5004, #subsample_inputs: 5004
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.653      |
| AbsLearnSignalNew       | 0.653      |
| AbsLearningOld          | 0.653      |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 12.5879    |
| AveragePolicyStd        | 0.854254   |
| AverageReturn           | 389        |
| Entropy                 | 7.5538     |
| EnvExecTime             | 2.44       |
| ExplainedVariance       | 0.274      |
| Iteration               | 243        |
| ItrTime                 | 17.2       |
| LossAfter               | -0.284108  |
| LossBefore              | -0.222069  |
| MaxReturn               | 675        |
| MeanKL                  | 0.00997226 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 47.9       |
| NumTrajs                | 23         |
| Perplexity              | 1907.98    |
| PolicyExecTime          | 0.485      |
| ProcessExecTime         | 0.0644     |
| StdReturn               | 124        |
| Time                    | 4.36e+03   |
| dLoss                   | 0.0620392  |
----------------------------------------
itr #244 | 
Mem: 758.945312
Obtaining samples...
Obtaining samples for iteration 244...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5216, #subsample_inputs: 5216
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.606      |
| AbsLearnSignalNew       | 0.606      |
| AbsLearningOld          | 0.606      |
| AverageDiscountedReturn | 124        |
| AveragePhiLoss          | 13.3334    |
| AveragePolicyStd        | 0.852864   |
| AverageReturn           | 397        |
| Entropy                 | 7.54494    |
| EnvExecTime             | 2.99       |
| ExplainedVariance       | 0.426      |
| Iteration               | 244        |
| ItrTime                 | 17.8       |
| LossAfter               | 1.29528    |
| LossBefore              | 1.36438    |
| MaxReturn               | 625        |
| MeanKL                  | 0.00990919 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 111        |
| NumTrajs                | 23         |
| Perplexity              | 1891.14    |
| PolicyExecTime          | 0.604      |
| ProcessExecTime         | 0.0795     |
| StdReturn               | 120        |
| Time                    | 4.38e+03   |
| dLoss                   | 0.069092   |
----------------------------------------
itr #245 | 
Mem: 758.945312
Obtaining samples...
Obtaining samples for iteration 245...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5163, #subsample_inputs: 5163
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.644      |
| AbsLearnSignalNew       | 0.644      |
| AbsLearningOld          | 0.644      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 12.5704    |
| AveragePolicyStd        | 0.852371   |
| AverageReturn           | 359        |
| Entropy                 | 7.54065    |
| EnvExecTime             | 2.78       |
| ExplainedVariance       | 0.513      |
| Iteration               | 245        |
| ItrTime                 | 18.2       |
| LossAfter               | 1.22897    |
| LossBefore              | 1.28329    |
| MaxReturn               | 573        |
| MeanKL                  | 0.00976543 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 46.3       |
| NumTrajs                | 25         |
| Perplexity              | 1883.06    |
| PolicyExecTime          | 0.571      |
| ProcessExecTime         | 0.0756     |
| StdReturn               | 124        |
| Time                    | 4.39e+03   |
| dLoss                   | 0.0543133  |
----------------------------------------
itr #246 | 
Mem: 759.195312
Obtaining samples...
Obtaining samples for iteration 246...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5220, #subsample_inputs: 5220
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.722      |
| AbsLearnSignalNew       | 0.722      |
| AbsLearningOld          | 0.722      |
| AverageDiscountedReturn | 124        |
| AveragePhiLoss          | 12.6306    |
| AveragePolicyStd        | 0.85434    |
| AverageReturn           | 392        |
| Entropy                 | 7.55531    |
| EnvExecTime             | 2.89       |
| ExplainedVariance       | 0.581      |
| Iteration               | 246        |
| ItrTime                 | 17.7       |
| LossAfter               | -0.303178  |
| LossBefore              | -0.240472  |
| MaxReturn               | 567        |
| MeanKL                  | 0.00979306 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 132        |
| NumTrajs                | 22         |
| Perplexity              | 1910.87    |
| PolicyExecTime          | 0.585      |
| ProcessExecTime         | 0.0723     |
| StdReturn               | 114        |
| Time                    | 4.41e+03   |
| dLoss                   | 0.0627061  |
----------------------------------------
itr #247 | 
Mem: 759.195312
Obtaining samples...
Obtaining samples for iteration 247...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5061, #subsample_inputs: 5061
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.7        |
| AbsLearnSignalNew       | 0.7        |
| AbsLearningOld          | 0.7        |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 12.8128    |
| AveragePolicyStd        | 0.853098   |
| AverageReturn           | 388        |
| Entropy                 | 7.54626    |
| EnvExecTime             | 2.96       |
| ExplainedVariance       | 0.517      |
| Iteration               | 247        |
| ItrTime                 | 18.5       |
| LossAfter               | 0.337407   |
| LossBefore              | 0.396697   |
| MaxReturn               | 622        |
| MeanKL                  | 0.00989617 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 68.3       |
| NumTrajs                | 24         |
| Perplexity              | 1893.65    |
| PolicyExecTime          | 0.616      |
| ProcessExecTime         | 0.08       |
| StdReturn               | 112        |
| Time                    | 4.43e+03   |
| dLoss                   | 0.0592894  |
----------------------------------------
itr #248 | 
Mem: 759.195312
Obtaining samples...
Obtaining samples for iteration 248...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5138, #subsample_inputs: 5138
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.657      |
| AbsLearnSignalNew       | 0.657      |
| AbsLearningOld          | 0.657      |
| AverageDiscountedReturn | 111        |
| AveragePhiLoss          | 12.3501    |
| AveragePolicyStd        | 0.848454   |
| AverageReturn           | 322        |
| Entropy                 | 7.51353    |
| EnvExecTime             | 2.58       |
| ExplainedVariance       | 0.413      |
| Iteration               | 248        |
| ItrTime                 | 17.6       |
| LossAfter               | -0.684217  |
| LossBefore              | -0.63854   |
| MaxReturn               | 616        |
| MeanKL                  | 0.00651751 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 30.6       |
| NumTrajs                | 24         |
| Perplexity              | 1832.66    |
| PolicyExecTime          | 0.489      |
| ProcessExecTime         | 0.0625     |
| StdReturn               | 154        |
| Time                    | 4.45e+03   |
| dLoss                   | 0.0456778  |
----------------------------------------
itr #249 | 
Mem: 759.195312
Obtaining samples...
Obtaining samples for iteration 249...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5160, #subsample_inputs: 5160
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.733      |
| AbsLearnSignalNew       | 0.733      |
| AbsLearningOld          | 0.733      |
| AverageDiscountedReturn | 123        |
| AveragePhiLoss          | 12.8605    |
| AveragePolicyStd        | 0.847494   |
| AverageReturn           | 393        |
| Entropy                 | 7.50701    |
| EnvExecTime             | 2.92       |
| ExplainedVariance       | 0.432      |
| Iteration               | 249        |
| ItrTime                 | 18         |
| LossAfter               | -0.367575  |
| LossBefore              | -0.305397  |
| MaxReturn               | 635        |
| MeanKL                  | 0.00996272 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 62.6       |
| NumTrajs                | 23         |
| Perplexity              | 1820.76    |
| PolicyExecTime          | 0.613      |
| ProcessExecTime         | 0.0794     |
| StdReturn               | 132        |
| Time                    | 4.47e+03   |
| dLoss                   | 0.0621781  |
----------------------------------------
itr #250 | 
Mem: 759.195312
Obtaining samples...
Obtaining samples for iteration 250...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5119, #subsample_inputs: 5119
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.632      |
| AbsLearnSignalNew       | 0.632      |
| AbsLearningOld          | 0.632      |
| AverageDiscountedReturn | 129        |
| AveragePhiLoss          | 12.757     |
| AveragePolicyStd        | 0.847753   |
| AverageReturn           | 421        |
| Entropy                 | 7.50861    |
| EnvExecTime             | 2.61       |
| ExplainedVariance       | 0.592      |
| Iteration               | 250        |
| ItrTime                 | 18         |
| LossAfter               | -0.222659  |
| LossBefore              | -0.152832  |
| MaxReturn               | 656        |
| MeanKL                  | 0.00998098 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 272        |
| NumTrajs                | 22         |
| Perplexity              | 1823.67    |
| PolicyExecTime          | 0.544      |
| ProcessExecTime         | 0.0683     |
| StdReturn               | 84.9       |
| Time                    | 4.49e+03   |
| dLoss                   | 0.0698275  |
----------------------------------------
itr #251 | 
Mem: 760.437500
Obtaining samples...
Obtaining samples for iteration 251...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5026, #subsample_inputs: 5026
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.732      |
| AbsLearnSignalNew       | 0.732      |
| AbsLearningOld          | 0.732      |
| AverageDiscountedReturn | 107        |
| AveragePhiLoss          | 13.6785    |
| AveragePolicyStd        | 0.848405   |
| AverageReturn           | 321        |
| Entropy                 | 7.51362    |
| EnvExecTime             | 2.78       |
| ExplainedVariance       | 0.266      |
| Iteration               | 251        |
| ItrTime                 | 17.2       |
| LossAfter               | -0.544602  |
| LossBefore              | -0.496979  |
| MaxReturn               | 566        |
| MeanKL                  | 0.00640464 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 66.5       |
| NumTrajs                | 22         |
| Perplexity              | 1832.84    |
| PolicyExecTime          | 0.565      |
| ProcessExecTime         | 0.0711     |
| StdReturn               | 164        |
| Time                    | 4.5e+03    |
| dLoss                   | 0.0476234  |
----------------------------------------
itr #252 | 
Mem: 760.437500
Obtaining samples...
Obtaining samples for iteration 252...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5084, #subsample_inputs: 5084
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.724      |
| AbsLearnSignalNew       | 0.724      |
| AbsLearningOld          | 0.724      |
| AverageDiscountedReturn | 127        |
| AveragePhiLoss          | 12.4431    |
| AveragePolicyStd        | 0.846466   |
| AverageReturn           | 391        |
| Entropy                 | 7.49747    |
| EnvExecTime             | 2.84       |
| ExplainedVariance       | 0.306      |
| Iteration               | 252        |
| ItrTime                 | 17.9       |
| LossAfter               | -0.534839  |
| LossBefore              | -0.470677  |
| MaxReturn               | 693        |
| MeanKL                  | 0.00984363 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 56.2       |
| NumTrajs                | 24         |
| Perplexity              | 1803.47    |
| PolicyExecTime          | 0.606      |
| ProcessExecTime         | 0.079      |
| StdReturn               | 144        |
| Time                    | 4.52e+03   |
| dLoss                   | 0.0641615  |
----------------------------------------
itr #253 | 
Mem: 760.437500
Obtaining samples...
Obtaining samples for iteration 253...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5107, #subsample_inputs: 5107
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.678      |
| AbsLearnSignalNew       | 0.678      |
| AbsLearningOld          | 0.678      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 13.5199    |
| AveragePolicyStd        | 0.849587   |
| AverageReturn           | 388        |
| Entropy                 | 7.51773    |
| EnvExecTime             | 2.48       |
| ExplainedVariance       | 0.49       |
| Iteration               | 253        |
| ItrTime                 | 17         |
| LossAfter               | 0.871796   |
| LossBefore              | 0.936094   |
| MaxReturn               | 631        |
| MeanKL                  | 0.00991085 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 112        |
| NumTrajs                | 23         |
| Perplexity              | 1840.38    |
| PolicyExecTime          | 0.475      |
| ProcessExecTime         | 0.0632     |
| StdReturn               | 124        |
| Time                    | 4.54e+03   |
| dLoss                   | 0.0642977  |
----------------------------------------
itr #254 | 
Mem: 760.437500
Obtaining samples...
Obtaining samples for iteration 254...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5092, #subsample_inputs: 5092
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
-----------------------------------------
| AbsLearnSignal          | 0.693       |
| AbsLearnSignalNew       | 0.693       |
| AbsLearningOld          | 0.693       |
| AverageDiscountedReturn | 129         |
| AveragePhiLoss          | 13.0641     |
| AveragePolicyStd        | 0.849615    |
| AverageReturn           | 423         |
| Entropy                 | 7.51505     |
| EnvExecTime             | 3.12        |
| ExplainedVariance       | 0.523       |
| Iteration               | 254         |
| ItrTime                 | 18.2        |
| LossAfter               | -0.00237465 |
| LossBefore              | 0.0440604   |
| MaxReturn               | 669         |
| MeanKL                  | 0.00641058  |
| MeanKLBefore            | 0.0         |
| MinReturn               | 110         |
| NumTrajs                | 21          |
| Perplexity              | 1835.46     |
| PolicyExecTime          | 0.638       |
| ProcessExecTime         | 0.0818      |
| StdReturn               | 148         |
| Time                    | 4.56e+03    |
| dLoss                   | 0.0464351   |
-----------------------------------------
itr #255 | 
Mem: 760.437500
Obtaining samples...
Obtaining samples for iteration 255...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5030, #subsample_inputs: 5030
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.719      |
| AbsLearnSignalNew       | 0.719      |
| AbsLearningOld          | 0.719      |
| AverageDiscountedReturn | 123        |
| AveragePhiLoss          | 13.5446    |
| AveragePolicyStd        | 0.847539   |
| AverageReturn           | 373        |
| Entropy                 | 7.49849    |
| EnvExecTime             | 2.35       |
| ExplainedVariance       | 0.443      |
| Iteration               | 255        |
| ItrTime                 | 16.8       |
| LossAfter               | -1.08746   |
| LossBefore              | -1.02439   |
| MaxReturn               | 686        |
| MeanKL                  | 0.00993027 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 87.5       |
| NumTrajs                | 23         |
| Perplexity              | 1805.31    |
| PolicyExecTime          | 0.438      |
| ProcessExecTime         | 0.0603     |
| StdReturn               | 150        |
| Time                    | 4.57e+03   |
| dLoss                   | 0.0630777  |
----------------------------------------
itr #256 | 
Mem: 760.437500
Obtaining samples...
Obtaining samples for iteration 256...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5259, #subsample_inputs: 5259
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.697     |
| AbsLearnSignalNew       | 0.697     |
| AbsLearningOld          | 0.697     |
| AverageDiscountedReturn | 129       |
| AveragePhiLoss          | 13.2583   |
| AveragePolicyStd        | 0.849709  |
| AverageReturn           | 459       |
| Entropy                 | 7.51334   |
| EnvExecTime             | 2.88      |
| ExplainedVariance       | 0.336     |
| Iteration               | 256       |
| ItrTime                 | 18.1      |
| LossAfter               | 0.128518  |
| LossBefore              | 0.196043  |
| MaxReturn               | 1.04e+03  |
| MeanKL                  | 0.0099219 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 44.3      |
| NumTrajs                | 22        |
| Perplexity              | 1832.33   |
| PolicyExecTime          | 0.598     |
| ProcessExecTime         | 0.0819    |
| StdReturn               | 184       |
| Time                    | 4.59e+03  |
| dLoss                   | 0.0675253 |
---------------------------------------
itr #257 | 
Mem: 760.437500
Obtaining samples...
Obtaining samples for iteration 257...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5081, #subsample_inputs: 5081
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.682      |
| AbsLearnSignalNew       | 0.682      |
| AbsLearningOld          | 0.682      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 14.0654    |
| AveragePolicyStd        | 0.848966   |
| AverageReturn           | 372        |
| Entropy                 | 7.50902    |
| EnvExecTime             | 2.51       |
| ExplainedVariance       | 0.412      |
| Iteration               | 257        |
| ItrTime                 | 18.3       |
| LossAfter               | -1.18603   |
| LossBefore              | -1.14095   |
| MaxReturn               | 573        |
| MeanKL                  | 0.00652735 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 63.1       |
| NumTrajs                | 23         |
| Perplexity              | 1824.42    |
| PolicyExecTime          | 0.485      |
| ProcessExecTime         | 0.0641     |
| StdReturn               | 134        |
| Time                    | 4.61e+03   |
| dLoss                   | 0.0450751  |
----------------------------------------
itr #258 | 
Mem: 760.437500
Obtaining samples...
Obtaining samples for iteration 258...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5307, #subsample_inputs: 5307
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.693      |
| AbsLearnSignalNew       | 0.693      |
| AbsLearningOld          | 0.693      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 12.8276    |
| AveragePolicyStd        | 0.846793   |
| AverageReturn           | 387        |
| Entropy                 | 7.4933     |
| EnvExecTime             | 3.11       |
| ExplainedVariance       | 0.506      |
| Iteration               | 258        |
| ItrTime                 | 18         |
| LossAfter               | 0.130776   |
| LossBefore              | 0.190189   |
| MaxReturn               | 603        |
| MeanKL                  | 0.00986038 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 82.1       |
| NumTrajs                | 23         |
| Perplexity              | 1795.96    |
| PolicyExecTime          | 0.624      |
| ProcessExecTime         | 0.081      |
| StdReturn               | 137        |
| Time                    | 4.63e+03   |
| dLoss                   | 0.0594131  |
----------------------------------------
itr #259 | 
Mem: 760.437500
Obtaining samples...
Obtaining samples for iteration 259...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5130, #subsample_inputs: 5130
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.694      |
| AbsLearnSignalNew       | 0.694      |
| AbsLearningOld          | 0.694      |
| AverageDiscountedReturn | 115        |
| AveragePhiLoss          | 13.4258    |
| AveragePolicyStd        | 0.850335   |
| AverageReturn           | 375        |
| Entropy                 | 7.51985    |
| EnvExecTime             | 2.8        |
| ExplainedVariance       | 0.53       |
| Iteration               | 259        |
| ItrTime                 | 18.1       |
| LossAfter               | 1.15701    |
| LossBefore              | 1.21941    |
| MaxReturn               | 618        |
| MeanKL                  | 0.00998967 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 54.1       |
| NumTrajs                | 22         |
| Perplexity              | 1844.3     |
| PolicyExecTime          | 0.575      |
| ProcessExecTime         | 0.0738     |
| StdReturn               | 160        |
| Time                    | 4.65e+03   |
| dLoss                   | 0.0623935  |
----------------------------------------
itr #260 | 
Mem: 760.437500
Obtaining samples...
Obtaining samples for iteration 260...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5013, #subsample_inputs: 5013
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.629      |
| AbsLearnSignalNew       | 0.629      |
| AbsLearningOld          | 0.629      |
| AverageDiscountedReturn | 117        |
| AveragePhiLoss          | 13.1392    |
| AveragePolicyStd        | 0.852167   |
| AverageReturn           | 420        |
| Entropy                 | 7.53316    |
| EnvExecTime             | 2.84       |
| ExplainedVariance       | 0.26       |
| Iteration               | 260        |
| ItrTime                 | 18.1       |
| LossAfter               | -0.0040422 |
| LossBefore              | 0.0639506  |
| MaxReturn               | 878        |
| MeanKL                  | 0.00991148 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 47.6       |
| NumTrajs                | 19         |
| Perplexity              | 1869.01    |
| PolicyExecTime          | 0.537      |
| ProcessExecTime         | 0.0683     |
| StdReturn               | 197        |
| Time                    | 4.66e+03   |
| dLoss                   | 0.0679928  |
----------------------------------------
itr #261 | 
Mem: 760.437500
Obtaining samples...
Obtaining samples for iteration 261...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5013, #subsample_inputs: 5013
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.704      |
| AbsLearnSignalNew       | 0.704      |
| AbsLearningOld          | 0.704      |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 12.8685    |
| AveragePolicyStd        | 0.855017   |
| AverageReturn           | 388        |
| Entropy                 | 7.55123    |
| EnvExecTime             | 2.87       |
| ExplainedVariance       | 0.417      |
| Iteration               | 261        |
| ItrTime                 | 17.4       |
| LossAfter               | 1.0634     |
| LossBefore              | 1.11261    |
| MaxReturn               | 928        |
| MeanKL                  | 0.00644977 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 41.7       |
| NumTrajs                | 23         |
| Perplexity              | 1903.09    |
| PolicyExecTime          | 0.602      |
| ProcessExecTime         | 0.0767     |
| StdReturn               | 186        |
| Time                    | 4.68e+03   |
| dLoss                   | 0.0492104  |
----------------------------------------
itr #262 | 
Mem: 760.437500
Obtaining samples...
Obtaining samples for iteration 262...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5127, #subsample_inputs: 5127
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.703      |
| AbsLearnSignalNew       | 0.703      |
| AbsLearningOld          | 0.703      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 12.3841    |
| AveragePolicyStd        | 0.853483   |
| AverageReturn           | 454        |
| Entropy                 | 7.54127    |
| EnvExecTime             | 2.6        |
| ExplainedVariance       | 0.414      |
| Iteration               | 262        |
| ItrTime                 | 17.8       |
| LossAfter               | 0.824128   |
| LossBefore              | 0.891594   |
| MaxReturn               | 796        |
| MeanKL                  | 0.00996752 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 70.9       |
| NumTrajs                | 20         |
| Perplexity              | 1884.22    |
| PolicyExecTime          | 0.531      |
| ProcessExecTime         | 0.0677     |
| StdReturn               | 151        |
| Time                    | 4.7e+03    |
| dLoss                   | 0.0674659  |
----------------------------------------
itr #263 | 
Mem: 760.437500
Obtaining samples...
Obtaining samples for iteration 263...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5137, #subsample_inputs: 5137
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.691      |
| AbsLearnSignalNew       | 0.691      |
| AbsLearningOld          | 0.691      |
| AverageDiscountedReturn | 130        |
| AveragePhiLoss          | 13.6866    |
| AveragePolicyStd        | 0.852848   |
| AverageReturn           | 431        |
| Entropy                 | 7.53771    |
| EnvExecTime             | 2.71       |
| ExplainedVariance       | 0.514      |
| Iteration               | 263        |
| ItrTime                 | 17.5       |
| LossAfter               | -0.348541  |
| LossBefore              | -0.283996  |
| MaxReturn               | 673        |
| MeanKL                  | 0.00997548 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 67         |
| NumTrajs                | 22         |
| Perplexity              | 1877.53    |
| PolicyExecTime          | 0.548      |
| ProcessExecTime         | 0.0746     |
| StdReturn               | 130        |
| Time                    | 4.72e+03   |
| dLoss                   | 0.0645455  |
----------------------------------------
itr #264 | 
Mem: 760.437500
Obtaining samples...
Obtaining samples for iteration 264...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5180, #subsample_inputs: 5180
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.687      |
| AbsLearnSignalNew       | 0.687      |
| AbsLearningOld          | 0.687      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 13.6461    |
| AveragePolicyStd        | 0.852187   |
| AverageReturn           | 387        |
| Entropy                 | 7.53221    |
| EnvExecTime             | 2.78       |
| ExplainedVariance       | 0.486      |
| Iteration               | 264        |
| ItrTime                 | 18.2       |
| LossAfter               | -0.178129  |
| LossBefore              | -0.117218  |
| MaxReturn               | 653        |
| MeanKL                  | 0.00974703 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 86.5       |
| NumTrajs                | 23         |
| Perplexity              | 1867.22    |
| PolicyExecTime          | 0.585      |
| ProcessExecTime         | 0.0766     |
| StdReturn               | 135        |
| Time                    | 4.74e+03   |
| dLoss                   | 0.0609105  |
----------------------------------------
itr #265 | 
Mem: 760.437500
Obtaining samples...
Obtaining samples for iteration 265...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5229, #subsample_inputs: 5229
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.721      |
| AbsLearnSignalNew       | 0.721      |
| AbsLearningOld          | 0.721      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 13.3669    |
| AveragePolicyStd        | 0.851999   |
| AverageReturn           | 421        |
| Entropy                 | 7.52992    |
| EnvExecTime             | 2.61       |
| ExplainedVariance       | 0.503      |
| Iteration               | 265        |
| ItrTime                 | 17.9       |
| LossAfter               | -0.815279  |
| LossBefore              | -0.752294  |
| MaxReturn               | 640        |
| MeanKL                  | 0.00984175 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 89         |
| NumTrajs                | 22         |
| Perplexity              | 1862.96    |
| PolicyExecTime          | 0.497      |
| ProcessExecTime         | 0.0635     |
| StdReturn               | 123        |
| Time                    | 4.75e+03   |
| dLoss                   | 0.0629852  |
----------------------------------------
itr #266 | 
Mem: 760.437500
Obtaining samples...
Obtaining samples for iteration 266...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5113, #subsample_inputs: 5113
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.708      |
| AbsLearnSignalNew       | 0.708      |
| AbsLearningOld          | 0.708      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 13.4792    |
| AveragePolicyStd        | 0.850035   |
| AverageReturn           | 426        |
| Entropy                 | 7.51403    |
| EnvExecTime             | 2.96       |
| ExplainedVariance       | 0.482      |
| Iteration               | 266        |
| ItrTime                 | 17.5       |
| LossAfter               | 1.36196    |
| LossBefore              | 1.41283    |
| MaxReturn               | 735        |
| MeanKL                  | 0.00641022 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 59.5       |
| NumTrajs                | 21         |
| Perplexity              | 1833.59    |
| PolicyExecTime          | 0.609      |
| ProcessExecTime         | 0.0801     |
| StdReturn               | 142        |
| Time                    | 4.77e+03   |
| dLoss                   | 0.050863   |
----------------------------------------
itr #267 | 
Mem: 760.437500
Obtaining samples...
Obtaining samples for iteration 267...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5139, #subsample_inputs: 5139
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.702      |
| AbsLearnSignalNew       | 0.702      |
| AbsLearningOld          | 0.702      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 13.784     |
| AveragePolicyStd        | 0.84925    |
| AverageReturn           | 393        |
| Entropy                 | 7.50937    |
| EnvExecTime             | 2.65       |
| ExplainedVariance       | 0.552      |
| Iteration               | 267        |
| ItrTime                 | 18.3       |
| LossAfter               | 0.678474   |
| LossBefore              | 0.744979   |
| MaxReturn               | 689        |
| MeanKL                  | 0.00991485 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 72.5       |
| NumTrajs                | 23         |
| Perplexity              | 1825.06    |
| PolicyExecTime          | 0.574      |
| ProcessExecTime         | 0.0722     |
| StdReturn               | 124        |
| Time                    | 4.79e+03   |
| dLoss                   | 0.0665042  |
----------------------------------------
itr #268 | 
Mem: 760.437500
Obtaining samples...
Obtaining samples for iteration 268...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5039, #subsample_inputs: 5039
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.712      |
| AbsLearnSignalNew       | 0.712      |
| AbsLearningOld          | 0.712      |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 13.2733    |
| AveragePolicyStd        | 0.850314   |
| AverageReturn           | 389        |
| Entropy                 | 7.5164     |
| EnvExecTime             | 2.75       |
| ExplainedVariance       | 0.502      |
| Iteration               | 268        |
| ItrTime                 | 17.3       |
| LossAfter               | -0.555061  |
| LossBefore              | -0.501363  |
| MaxReturn               | 565        |
| MeanKL                  | 0.00648637 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 38         |
| NumTrajs                | 22         |
| Perplexity              | 1837.94    |
| PolicyExecTime          | 0.57       |
| ProcessExecTime         | 0.0729     |
| StdReturn               | 136        |
| Time                    | 4.81e+03   |
| dLoss                   | 0.0536978  |
----------------------------------------
itr #269 | 
Mem: 760.437500
Obtaining samples...
Obtaining samples for iteration 269...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5182, #subsample_inputs: 5182
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.685      |
| AbsLearnSignalNew       | 0.685      |
| AbsLearningOld          | 0.685      |
| AverageDiscountedReturn | 127        |
| AveragePhiLoss          | 13.7601    |
| AveragePolicyStd        | 0.850345   |
| AverageReturn           | 430        |
| Entropy                 | 7.516      |
| EnvExecTime             | 2.78       |
| ExplainedVariance       | 0.386      |
| Iteration               | 269        |
| ItrTime                 | 18.2       |
| LossAfter               | -0.045293  |
| LossBefore              | 0.0171763  |
| MaxReturn               | 752        |
| MeanKL                  | 0.00987674 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 243        |
| NumTrajs                | 22         |
| Perplexity              | 1837.2     |
| PolicyExecTime          | 0.588      |
| ProcessExecTime         | 0.0735     |
| StdReturn               | 119        |
| Time                    | 4.83e+03   |
| dLoss                   | 0.0624693  |
----------------------------------------
itr #270 | 
Mem: 760.437500
Obtaining samples...
Obtaining samples for iteration 270...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5165, #subsample_inputs: 5165
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.649      |
| AbsLearnSignalNew       | 0.649      |
| AbsLearningOld          | 0.649      |
| AverageDiscountedReturn | 132        |
| AveragePhiLoss          | 12.7946    |
| AveragePolicyStd        | 0.850751   |
| AverageReturn           | 438        |
| Entropy                 | 7.51973    |
| EnvExecTime             | 2.54       |
| ExplainedVariance       | 0.508      |
| Iteration               | 270        |
| ItrTime                 | 17.1       |
| LossAfter               | 0.240501   |
| LossBefore              | 0.300573   |
| MaxReturn               | 631        |
| MeanKL                  | 0.00991691 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 94.6       |
| NumTrajs                | 22         |
| Perplexity              | 1844.07    |
| PolicyExecTime          | 0.516      |
| ProcessExecTime         | 0.0681     |
| StdReturn               | 109        |
| Time                    | 4.84e+03   |
| dLoss                   | 0.060072   |
----------------------------------------
itr #271 | 
Mem: 760.437500
Obtaining samples...
Obtaining samples for iteration 271...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5051, #subsample_inputs: 5051
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.709      |
| AbsLearnSignalNew       | 0.709      |
| AbsLearningOld          | 0.709      |
| AverageDiscountedReturn | 129        |
| AveragePhiLoss          | 14.0043    |
| AveragePolicyStd        | 0.853467   |
| AverageReturn           | 423        |
| Entropy                 | 7.53661    |
| EnvExecTime             | 2.89       |
| ExplainedVariance       | 0.619      |
| Iteration               | 271        |
| ItrTime                 | 18.2       |
| LossAfter               | -0.932068  |
| LossBefore              | -0.876866  |
| MaxReturn               | 576        |
| MeanKL                  | 0.00643434 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 73         |
| NumTrajs                | 22         |
| Perplexity              | 1875.47    |
| PolicyExecTime          | 0.592      |
| ProcessExecTime         | 0.0811     |
| StdReturn               | 110        |
| Time                    | 4.86e+03   |
| dLoss                   | 0.0552029  |
----------------------------------------
itr #272 | 
Mem: 760.437500
Obtaining samples...
Obtaining samples for iteration 272...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5121, #subsample_inputs: 5121
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.664      |
| AbsLearnSignalNew       | 0.664      |
| AbsLearningOld          | 0.665      |
| AverageDiscountedReturn | 124        |
| AveragePhiLoss          | 13.6608    |
| AveragePolicyStd        | 0.853398   |
| AverageReturn           | 416        |
| Entropy                 | 7.53491    |
| EnvExecTime             | 2.59       |
| ExplainedVariance       | 0.383      |
| Iteration               | 272        |
| ItrTime                 | 17.7       |
| LossAfter               | 0.492264   |
| LossBefore              | 0.548172   |
| MaxReturn               | 802        |
| MeanKL                  | 0.00641986 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 111        |
| NumTrajs                | 22         |
| Perplexity              | 1872.27    |
| PolicyExecTime          | 0.517      |
| ProcessExecTime         | 0.0647     |
| StdReturn               | 170        |
| Time                    | 4.88e+03   |
| dLoss                   | 0.0559079  |
----------------------------------------
itr #273 | 
Mem: 760.437500
Obtaining samples...
Obtaining samples for iteration 273...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5120, #subsample_inputs: 5120
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.696     |
| AbsLearnSignalNew       | 0.696     |
| AbsLearningOld          | 0.696     |
| AverageDiscountedReturn | 135       |
| AveragePhiLoss          | 13.0151   |
| AveragePolicyStd        | 0.852116  |
| AverageReturn           | 441       |
| Entropy                 | 7.52738   |
| EnvExecTime             | 2.87      |
| ExplainedVariance       | 0.477     |
| Iteration               | 273       |
| ItrTime                 | 18.2      |
| LossAfter               | 0.135899  |
| LossBefore              | 0.198915  |
| MaxReturn               | 701       |
| MeanKL                  | 0.0098874 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 109       |
| NumTrajs                | 22        |
| Perplexity              | 1858.22   |
| PolicyExecTime          | 0.585     |
| ProcessExecTime         | 0.0799    |
| StdReturn               | 135       |
| Time                    | 4.9e+03   |
| dLoss                   | 0.0630159 |
---------------------------------------
itr #274 | 
Mem: 760.437500
Obtaining samples...
Obtaining samples for iteration 274...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5065, #subsample_inputs: 5065
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.697      |
| AbsLearnSignalNew       | 0.697      |
| AbsLearningOld          | 0.697      |
| AverageDiscountedReturn | 133        |
| AveragePhiLoss          | 12.8009    |
| AveragePolicyStd        | 0.853681   |
| AverageReturn           | 441        |
| Entropy                 | 7.53875    |
| EnvExecTime             | 2.44       |
| ExplainedVariance       | 0.537      |
| Iteration               | 274        |
| ItrTime                 | 17.9       |
| LossAfter               | -0.516848  |
| LossBefore              | -0.47177   |
| MaxReturn               | 742        |
| MeanKL                  | 0.00641894 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 44.1       |
| NumTrajs                | 22         |
| Perplexity              | 1879.48    |
| PolicyExecTime          | 0.489      |
| ProcessExecTime         | 0.0643     |
| StdReturn               | 132        |
| Time                    | 4.91e+03   |
| dLoss                   | 0.0450778  |
----------------------------------------
itr #275 | 
Mem: 760.437500
Obtaining samples...
Obtaining samples for iteration 275...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5218, #subsample_inputs: 5218
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.657      |
| AbsLearnSignalNew       | 0.657      |
| AbsLearningOld          | 0.657      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 12.579     |
| AveragePolicyStd        | 0.850733   |
| AverageReturn           | 390        |
| Entropy                 | 7.51755    |
| EnvExecTime             | 2.9        |
| ExplainedVariance       | 0.544      |
| Iteration               | 275        |
| ItrTime                 | 18.1       |
| LossAfter               | 1.37575    |
| LossBefore              | 1.43934    |
| MaxReturn               | 647        |
| MeanKL                  | 0.00985985 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 52.2       |
| NumTrajs                | 24         |
| Perplexity              | 1840.05    |
| PolicyExecTime          | 0.586      |
| ProcessExecTime         | 0.0773     |
| StdReturn               | 139        |
| Time                    | 4.93e+03   |
| dLoss                   | 0.0635868  |
----------------------------------------
itr #276 | 
Mem: 760.437500
Obtaining samples...
Obtaining samples for iteration 276...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5111, #subsample_inputs: 5111
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.688      |
| AbsLearnSignalNew       | 0.688      |
| AbsLearningOld          | 0.688      |
| AverageDiscountedReturn | 132        |
| AveragePhiLoss          | 12.798     |
| AveragePolicyStd        | 0.853075   |
| AverageReturn           | 443        |
| Entropy                 | 7.53033    |
| EnvExecTime             | 2.57       |
| ExplainedVariance       | 0.581      |
| Iteration               | 276        |
| ItrTime                 | 17.6       |
| LossAfter               | 0.938339   |
| LossBefore              | 0.998807   |
| MaxReturn               | 848        |
| MeanKL                  | 0.00994899 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 48.5       |
| NumTrajs                | 22         |
| Perplexity              | 1863.72    |
| PolicyExecTime          | 0.546      |
| ProcessExecTime         | 0.0669     |
| StdReturn               | 141        |
| Time                    | 4.95e+03   |
| dLoss                   | 0.0604677  |
----------------------------------------
itr #277 | 
Mem: 760.437500
Obtaining samples...
Obtaining samples for iteration 277...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5246, #subsample_inputs: 5246
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.68       |
| AbsLearnSignalNew       | 0.68       |
| AbsLearningOld          | 0.68       |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 13.4483    |
| AveragePolicyStd        | 0.852504   |
| AverageReturn           | 420        |
| Entropy                 | 7.52666    |
| EnvExecTime             | 2.93       |
| ExplainedVariance       | 0.551      |
| Iteration               | 277        |
| ItrTime                 | 17.8       |
| LossAfter               | -0.398318  |
| LossBefore              | -0.338306  |
| MaxReturn               | 638        |
| MeanKL                  | 0.00976174 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 83.1       |
| NumTrajs                | 22         |
| Perplexity              | 1856.9     |
| PolicyExecTime          | 0.607      |
| ProcessExecTime         | 0.0772     |
| StdReturn               | 125        |
| Time                    | 4.97e+03   |
| dLoss                   | 0.0600118  |
----------------------------------------
itr #278 | 
Mem: 760.437500
Obtaining samples...
Obtaining samples for iteration 278...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5339, #subsample_inputs: 5339
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.688      |
| AbsLearnSignalNew       | 0.688      |
| AbsLearningOld          | 0.688      |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 13.6583    |
| AveragePolicyStd        | 0.852096   |
| AverageReturn           | 404        |
| Entropy                 | 7.52348    |
| EnvExecTime             | 2.93       |
| ExplainedVariance       | 0.436      |
| Iteration               | 278        |
| ItrTime                 | 19         |
| LossAfter               | -0.835248  |
| LossBefore              | -0.770671  |
| MaxReturn               | 648        |
| MeanKL                  | 0.00996798 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 58.5       |
| NumTrajs                | 22         |
| Perplexity              | 1850.99    |
| PolicyExecTime          | 0.615      |
| ProcessExecTime         | 0.0794     |
| StdReturn               | 175        |
| Time                    | 4.99e+03   |
| dLoss                   | 0.0645773  |
----------------------------------------
itr #279 | 
Mem: 760.437500
Obtaining samples...
Obtaining samples for iteration 279...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5116, #subsample_inputs: 5116
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.714      |
| AbsLearnSignalNew       | 0.714      |
| AbsLearningOld          | 0.714      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 12.5111    |
| AveragePolicyStd        | 0.853899   |
| AverageReturn           | 408        |
| Entropy                 | 7.53647    |
| EnvExecTime             | 2.48       |
| ExplainedVariance       | 0.411      |
| Iteration               | 279        |
| ItrTime                 | 17.5       |
| LossAfter               | -1.76374   |
| LossBefore              | -1.71389   |
| MaxReturn               | 860        |
| MeanKL                  | 0.00642656 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 80.9       |
| NumTrajs                | 23         |
| Perplexity              | 1875.2     |
| PolicyExecTime          | 0.474      |
| ProcessExecTime         | 0.0622     |
| StdReturn               | 170        |
| Time                    | 5.01e+03   |
| dLoss                   | 0.0498431  |
----------------------------------------
itr #280 | 
Mem: 760.437500
Obtaining samples...
Obtaining samples for iteration 280...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5019, #subsample_inputs: 5019
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.716      |
| AbsLearnSignalNew       | 0.716      |
| AbsLearningOld          | 0.716      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 13.3898    |
| AveragePolicyStd        | 0.85335    |
| AverageReturn           | 425        |
| Entropy                 | 7.53187    |
| EnvExecTime             | 2.81       |
| ExplainedVariance       | 0.5        |
| Iteration               | 280        |
| ItrTime                 | 17.5       |
| LossAfter               | 0.604265   |
| LossBefore              | 0.655092   |
| MaxReturn               | 681        |
| MeanKL                  | 0.00642559 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 63.7       |
| NumTrajs                | 20         |
| Perplexity              | 1866.59    |
| PolicyExecTime          | 0.578      |
| ProcessExecTime         | 0.0755     |
| StdReturn               | 143        |
| Time                    | 5.02e+03   |
| dLoss                   | 0.0508272  |
----------------------------------------
itr #281 | 
Mem: 760.437500
Obtaining samples...
Obtaining samples for iteration 281...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5180, #subsample_inputs: 5180
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.637      |
| AbsLearnSignalNew       | 0.637      |
| AbsLearningOld          | 0.637      |
| AverageDiscountedReturn | 123        |
| AveragePhiLoss          | 12.4516    |
| AveragePolicyStd        | 0.853568   |
| AverageReturn           | 442        |
| Entropy                 | 7.53422    |
| EnvExecTime             | 2.64       |
| ExplainedVariance       | 0.408      |
| Iteration               | 281        |
| ItrTime                 | 18.2       |
| LossAfter               | 0.1018     |
| LossBefore              | 0.164543   |
| MaxReturn               | 697        |
| MeanKL                  | 0.00993005 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 97.7       |
| NumTrajs                | 20         |
| Perplexity              | 1870.99    |
| PolicyExecTime          | 0.518      |
| ProcessExecTime         | 0.0665     |
| StdReturn               | 148        |
| Time                    | 5.04e+03   |
| dLoss                   | 0.0627427  |
----------------------------------------
itr #282 | 
Mem: 760.437500
Obtaining samples...
Obtaining samples for iteration 282...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5070, #subsample_inputs: 5070
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.705      |
| AbsLearnSignalNew       | 0.705      |
| AbsLearningOld          | 0.705      |
| AverageDiscountedReturn | 127        |
| AveragePhiLoss          | 12.976     |
| AveragePolicyStd        | 0.852095   |
| AverageReturn           | 394        |
| Entropy                 | 7.52272    |
| EnvExecTime             | 2.85       |
| ExplainedVariance       | 0.567      |
| Iteration               | 282        |
| ItrTime                 | 17.7       |
| LossAfter               | -0.532106  |
| LossBefore              | -0.480465  |
| MaxReturn               | 696        |
| MeanKL                  | 0.00645556 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 109        |
| NumTrajs                | 23         |
| Perplexity              | 1849.59    |
| PolicyExecTime          | 0.588      |
| ProcessExecTime         | 0.0779     |
| StdReturn               | 110        |
| Time                    | 5.06e+03   |
| dLoss                   | 0.0516409  |
----------------------------------------
itr #283 | 
Mem: 760.437500
Obtaining samples...
Obtaining samples for iteration 283...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5116, #subsample_inputs: 5116
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.657     |
| AbsLearnSignalNew       | 0.657     |
| AbsLearningOld          | 0.658     |
| AverageDiscountedReturn | 130       |
| AveragePhiLoss          | 13.1809   |
| AveragePolicyStd        | 0.850266  |
| AverageReturn           | 452       |
| Entropy                 | 7.50903   |
| EnvExecTime             | 2.62      |
| ExplainedVariance       | 0.464     |
| Iteration               | 283       |
| ItrTime                 | 18.1      |
| LossAfter               | -0.357146 |
| LossBefore              | -0.293786 |
| MaxReturn               | 982       |
| MeanKL                  | 0.009938  |
| MeanKLBefore            | 0.0       |
| MinReturn               | 110       |
| NumTrajs                | 21        |
| Perplexity              | 1824.44   |
| PolicyExecTime          | 0.534     |
| ProcessExecTime         | 0.0708    |
| StdReturn               | 168       |
| Time                    | 5.08e+03  |
| dLoss                   | 0.0633598 |
---------------------------------------
itr #284 | 
Mem: 760.437500
Obtaining samples...
Obtaining samples for iteration 284...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5095, #subsample_inputs: 5095
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.668      |
| AbsLearnSignalNew       | 0.668      |
| AbsLearningOld          | 0.667      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 13.3946    |
| AveragePolicyStd        | 0.851116   |
| AverageReturn           | 393        |
| Entropy                 | 7.51305    |
| EnvExecTime             | 2.64       |
| ExplainedVariance       | 0.34       |
| Iteration               | 284        |
| ItrTime                 | 17.9       |
| LossAfter               | 0.724201   |
| LossBefore              | 0.774616   |
| MaxReturn               | 601        |
| MeanKL                  | 0.00640428 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 74.7       |
| NumTrajs                | 21         |
| Perplexity              | 1831.78    |
| PolicyExecTime          | 0.528      |
| ProcessExecTime         | 0.0699     |
| StdReturn               | 132        |
| Time                    | 5.1e+03    |
| dLoss                   | 0.0504144  |
----------------------------------------
itr #285 | 
Mem: 760.437500
Obtaining samples...
Obtaining samples for iteration 285...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5099, #subsample_inputs: 5099
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.709      |
| AbsLearnSignalNew       | 0.709      |
| AbsLearningOld          | 0.709      |
| AverageDiscountedReturn | 116        |
| AveragePhiLoss          | 13.4583    |
| AveragePolicyStd        | 0.847536   |
| AverageReturn           | 371        |
| Entropy                 | 7.48802    |
| EnvExecTime             | 3.1        |
| ExplainedVariance       | 0.452      |
| Iteration               | 285        |
| ItrTime                 | 18.3       |
| LossAfter               | 0.216232   |
| LossBefore              | 0.264703   |
| MaxReturn               | 631        |
| MeanKL                  | 0.00642344 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 84.9       |
| NumTrajs                | 22         |
| Perplexity              | 1786.52    |
| PolicyExecTime          | 0.633      |
| ProcessExecTime         | 0.0795     |
| StdReturn               | 154        |
| Time                    | 5.11e+03   |
| dLoss                   | 0.0484718  |
----------------------------------------
itr #286 | 
Mem: 760.437500
Obtaining samples...
Obtaining samples for iteration 286...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5221, #subsample_inputs: 5221
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.724      |
| AbsLearnSignalNew       | 0.724      |
| AbsLearningOld          | 0.724      |
| AverageDiscountedReturn | 129        |
| AveragePhiLoss          | 12.9732    |
| AveragePolicyStd        | 0.84779    |
| AverageReturn           | 414        |
| Entropy                 | 7.49081    |
| EnvExecTime             | 2.56       |
| ExplainedVariance       | 0.409      |
| Iteration               | 286        |
| ItrTime                 | 18.3       |
| LossAfter               | -0.0156795 |
| LossBefore              | 0.0476141  |
| MaxReturn               | 663        |
| MeanKL                  | 0.00994761 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 277        |
| NumTrajs                | 23         |
| Perplexity              | 1791.51    |
| PolicyExecTime          | 0.482      |
| ProcessExecTime         | 0.0637     |
| StdReturn               | 99.6       |
| Time                    | 5.13e+03   |
| dLoss                   | 0.0632936  |
----------------------------------------
itr #287 | 
Mem: 760.437500
Obtaining samples...
Obtaining samples for iteration 287...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5160, #subsample_inputs: 5160
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.634      |
| AbsLearnSignalNew       | 0.634      |
| AbsLearningOld          | 0.635      |
| AverageDiscountedReturn | 129        |
| AveragePhiLoss          | 12.7774    |
| AveragePolicyStd        | 0.848418   |
| AverageReturn           | 399        |
| Entropy                 | 7.49544    |
| EnvExecTime             | 2.93       |
| ExplainedVariance       | 0.608      |
| Iteration               | 287        |
| ItrTime                 | 18         |
| LossAfter               | 0.115601   |
| LossBefore              | 0.17691    |
| MaxReturn               | 654        |
| MeanKL                  | 0.00971481 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 242        |
| NumTrajs                | 24         |
| Perplexity              | 1799.82    |
| PolicyExecTime          | 0.633      |
| ProcessExecTime         | 0.083      |
| StdReturn               | 93.2       |
| Time                    | 5.15e+03   |
| dLoss                   | 0.0613089  |
----------------------------------------
itr #288 | 
Mem: 761.644531
Obtaining samples...
Obtaining samples for iteration 288...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5004, #subsample_inputs: 5004
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.651      |
| AbsLearnSignalNew       | 0.651      |
| AbsLearningOld          | 0.651      |
| AverageDiscountedReturn | 123        |
| AveragePhiLoss          | 14.1715    |
| AveragePolicyStd        | 0.85187    |
| AverageReturn           | 404        |
| Entropy                 | 7.52101    |
| EnvExecTime             | 2.64       |
| ExplainedVariance       | 0.388      |
| Iteration               | 288        |
| ItrTime                 | 17.8       |
| LossAfter               | -0.236984  |
| LossBefore              | -0.188324  |
| MaxReturn               | 657        |
| MeanKL                  | 0.00642735 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 73.2       |
| NumTrajs                | 22         |
| Perplexity              | 1846.43    |
| PolicyExecTime          | 0.535      |
| ProcessExecTime         | 0.0671     |
| StdReturn               | 147        |
| Time                    | 5.17e+03   |
| dLoss                   | 0.0486594  |
----------------------------------------
itr #289 | 
Mem: 761.644531
Obtaining samples...
Obtaining samples for iteration 289...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5179, #subsample_inputs: 5179
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.649     |
| AbsLearnSignalNew       | 0.649     |
| AbsLearningOld          | 0.649     |
| AverageDiscountedReturn | 128       |
| AveragePhiLoss          | 13.4915   |
| AveragePolicyStd        | 0.849655  |
| AverageReturn           | 471       |
| Entropy                 | 7.50539   |
| EnvExecTime             | 2.8       |
| ExplainedVariance       | 0.506     |
| Iteration               | 289       |
| ItrTime                 | 17.4      |
| LossAfter               | -1.0569   |
| LossBefore              | -0.996749 |
| MaxReturn               | 1.28e+03  |
| MeanKL                  | 0.0098916 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 71.6      |
| NumTrajs                | 21        |
| Perplexity              | 1817.82   |
| PolicyExecTime          | 0.562     |
| ProcessExecTime         | 0.0749    |
| StdReturn               | 236       |
| Time                    | 5.19e+03  |
| dLoss                   | 0.0601538 |
---------------------------------------
itr #290 | 
Mem: 761.644531
Obtaining samples...
Obtaining samples for iteration 290...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5008, #subsample_inputs: 5008
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.695      |
| AbsLearnSignalNew       | 0.695      |
| AbsLearningOld          | 0.696      |
| AverageDiscountedReturn | 130        |
| AveragePhiLoss          | 13.0952    |
| AveragePolicyStd        | 0.849655   |
| AverageReturn           | 433        |
| Entropy                 | 7.50705    |
| EnvExecTime             | 2.79       |
| ExplainedVariance       | 0.517      |
| Iteration               | 290        |
| ItrTime                 | 18.2       |
| LossAfter               | -1.29488   |
| LossBefore              | -1.24709   |
| MaxReturn               | 693        |
| MeanKL                  | 0.00642952 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 50         |
| NumTrajs                | 22         |
| Perplexity              | 1820.83    |
| PolicyExecTime          | 0.601      |
| ProcessExecTime         | 0.0774     |
| StdReturn               | 156        |
| Time                    | 5.2e+03    |
| dLoss                   | 0.0477967  |
----------------------------------------
itr #291 | 
Mem: 761.644531
Obtaining samples...
Obtaining samples for iteration 291...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5003, #subsample_inputs: 5003
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.693      |
| AbsLearnSignalNew       | 0.693      |
| AbsLearningOld          | 0.693      |
| AverageDiscountedReturn | 123        |
| AveragePhiLoss          | 13.9047    |
| AveragePolicyStd        | 0.846946   |
| AverageReturn           | 422        |
| Entropy                 | 7.48895    |
| EnvExecTime             | 2.4        |
| ExplainedVariance       | 0.521      |
| Iteration               | 291        |
| ItrTime                 | 17.2       |
| LossAfter               | -0.470779  |
| LossBefore              | -0.419908  |
| MaxReturn               | 691        |
| MeanKL                  | 0.00645495 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 23         |
| NumTrajs                | 21         |
| Perplexity              | 1788.18    |
| PolicyExecTime          | 0.464      |
| ProcessExecTime         | 0.0608     |
| StdReturn               | 163        |
| Time                    | 5.22e+03   |
| dLoss                   | 0.0508714  |
----------------------------------------
itr #292 | 
Mem: 761.644531
Obtaining samples...
Obtaining samples for iteration 292...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5429, #subsample_inputs: 5429
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.66       |
| AbsLearnSignalNew       | 0.66       |
| AbsLearningOld          | 0.66       |
| AverageDiscountedReturn | 124        |
| AveragePhiLoss          | 14.1582    |
| AveragePolicyStd        | 0.845989   |
| AverageReturn           | 392        |
| Entropy                 | 7.48127    |
| EnvExecTime             | 3.09       |
| ExplainedVariance       | 0.496      |
| Iteration               | 292        |
| ItrTime                 | 19.2       |
| LossAfter               | -0.524291  |
| LossBefore              | -0.464437  |
| MaxReturn               | 675        |
| MeanKL                  | 0.00991383 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 66.5       |
| NumTrajs                | 24         |
| Perplexity              | 1774.48    |
| PolicyExecTime          | 0.667      |
| ProcessExecTime         | 0.0883     |
| StdReturn               | 154        |
| Time                    | 5.24e+03   |
| dLoss                   | 0.0598538  |
----------------------------------------
itr #293 | 
Mem: 761.644531
Obtaining samples...
Obtaining samples for iteration 293...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5232, #subsample_inputs: 5232
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.719      |
| AbsLearnSignalNew       | 0.719      |
| AbsLearningOld          | 0.719      |
| AverageDiscountedReturn | 116        |
| AveragePhiLoss          | 14.0287    |
| AveragePolicyStd        | 0.847605   |
| AverageReturn           | 399        |
| Entropy                 | 7.4927     |
| EnvExecTime             | 2.8        |
| ExplainedVariance       | 0.5        |
| Iteration               | 293        |
| ItrTime                 | 18.3       |
| LossAfter               | 0.653267   |
| LossBefore              | 0.71286    |
| MaxReturn               | 649        |
| MeanKL                  | 0.00998322 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 82.7       |
| NumTrajs                | 21         |
| Perplexity              | 1794.89    |
| PolicyExecTime          | 0.528      |
| ProcessExecTime         | 0.0669     |
| StdReturn               | 145        |
| Time                    | 5.26e+03   |
| dLoss                   | 0.0595932  |
----------------------------------------
itr #294 | 
Mem: 761.644531
Obtaining samples...
Obtaining samples for iteration 294...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5013, #subsample_inputs: 5013
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.685     |
| AbsLearnSignalNew       | 0.685     |
| AbsLearningOld          | 0.685     |
| AverageDiscountedReturn | 128       |
| AveragePhiLoss          | 13.9633   |
| AveragePolicyStd        | 0.84473   |
| AverageReturn           | 456       |
| Entropy                 | 7.47026   |
| EnvExecTime             | 2.78      |
| ExplainedVariance       | 0.432     |
| Iteration               | 294       |
| ItrTime                 | 17.7      |
| LossAfter               | -0.658262 |
| LossBefore              | -0.595209 |
| MaxReturn               | 798       |
| MeanKL                  | 0.0099466 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 298       |
| NumTrajs                | 20        |
| Perplexity              | 1755.06   |
| PolicyExecTime          | 0.572     |
| ProcessExecTime         | 0.0774    |
| StdReturn               | 122       |
| Time                    | 5.28e+03  |
| dLoss                   | 0.0630533 |
---------------------------------------
itr #295 | 
Mem: 761.644531
Obtaining samples...
Obtaining samples for iteration 295...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5174, #subsample_inputs: 5174
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.677      |
| AbsLearnSignalNew       | 0.677      |
| AbsLearningOld          | 0.677      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 13.9474    |
| AveragePolicyStd        | 0.843901   |
| AverageReturn           | 376        |
| Entropy                 | 7.4635     |
| EnvExecTime             | 2.7        |
| ExplainedVariance       | 0.38       |
| Iteration               | 295        |
| ItrTime                 | 18.5       |
| LossAfter               | -2.29806   |
| LossBefore              | -2.24051   |
| MaxReturn               | 661        |
| MeanKL                  | 0.00987371 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 59.3       |
| NumTrajs                | 24         |
| Perplexity              | 1743.24    |
| PolicyExecTime          | 0.535      |
| ProcessExecTime         | 0.0712     |
| StdReturn               | 167        |
| Time                    | 5.3e+03    |
| dLoss                   | 0.0575442  |
----------------------------------------
itr #296 | 
Mem: 761.644531
Obtaining samples...
Obtaining samples for iteration 296...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5023, #subsample_inputs: 5023
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.444      |
| AbsLearnSignalNew       | 0.444      |
| AbsLearningOld          | 0.444      |
| AverageDiscountedReturn | 130        |
| AveragePhiLoss          | 11.7291    |
| AveragePolicyStd        | 0.844287   |
| AverageReturn           | 501        |
| Entropy                 | 7.46399    |
| EnvExecTime             | 2.47       |
| ExplainedVariance       | -2.66      |
| Iteration               | 296        |
| ItrTime                 | 16.8       |
| LossAfter               | -2.80954   |
| LossBefore              | -2.75692   |
| MaxReturn               | 1.23e+03   |
| MeanKL                  | 0.00644696 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 72.8       |
| NumTrajs                | 19         |
| Perplexity              | 1744.09    |
| PolicyExecTime          | 0.5        |
| ProcessExecTime         | 0.0634     |
| StdReturn               | 267        |
| Time                    | 5.31e+03   |
| dLoss                   | 0.0526125  |
----------------------------------------
itr #297 | 
Mem: 761.644531
Obtaining samples...
Obtaining samples for iteration 297...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5017, #subsample_inputs: 5017
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.665      |
| AbsLearnSignalNew       | 0.665      |
| AbsLearningOld          | 0.665      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 13.5103    |
| AveragePolicyStd        | 0.8416     |
| AverageReturn           | 378        |
| Entropy                 | 7.44516    |
| EnvExecTime             | 2.95       |
| ExplainedVariance       | 0.443      |
| Iteration               | 297        |
| ItrTime                 | 17.9       |
| LossAfter               | -1.245     |
| LossBefore              | -1.18859   |
| MaxReturn               | 545        |
| MeanKL                  | 0.00992112 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 81.2       |
| NumTrajs                | 22         |
| Perplexity              | 1711.56    |
| PolicyExecTime          | 0.61       |
| ProcessExecTime         | 0.0778     |
| StdReturn               | 117        |
| Time                    | 5.33e+03   |
| dLoss                   | 0.05641    |
----------------------------------------
itr #298 | 
Mem: 763.187500
Obtaining samples...
Obtaining samples for iteration 298...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5122, #subsample_inputs: 5122
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.698      |
| AbsLearnSignalNew       | 0.698      |
| AbsLearningOld          | 0.698      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 13.8335    |
| AveragePolicyStd        | 0.838189   |
| AverageReturn           | 405        |
| Entropy                 | 7.42043    |
| EnvExecTime             | 2.7        |
| ExplainedVariance       | 0.492      |
| Iteration               | 298        |
| ItrTime                 | 17.8       |
| LossAfter               | -1.80956   |
| LossBefore              | -1.7504    |
| MaxReturn               | 723        |
| MeanKL                  | 0.00997049 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 45.1       |
| NumTrajs                | 23         |
| Perplexity              | 1669.76    |
| PolicyExecTime          | 0.523      |
| ProcessExecTime         | 0.0652     |
| StdReturn               | 145        |
| Time                    | 5.35e+03   |
| dLoss                   | 0.0591573  |
----------------------------------------
itr #299 | 
Mem: 763.187500
Obtaining samples...
Obtaining samples for iteration 299...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5124, #subsample_inputs: 5124
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.644      |
| AbsLearnSignalNew       | 0.644      |
| AbsLearningOld          | 0.644      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 13.9206    |
| AveragePolicyStd        | 0.836087   |
| AverageReturn           | 390        |
| Entropy                 | 7.4041     |
| EnvExecTime             | 2.97       |
| ExplainedVariance       | 0.432      |
| Iteration               | 299        |
| ItrTime                 | 17.6       |
| LossAfter               | -2.474     |
| LossBefore              | -2.42447   |
| MaxReturn               | 695        |
| MeanKL                  | 0.00641544 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 65.3       |
| NumTrajs                | 22         |
| Perplexity              | 1642.7     |
| PolicyExecTime          | 0.61       |
| ProcessExecTime         | 0.0785     |
| StdReturn               | 138        |
| Time                    | 5.37e+03   |
| dLoss                   | 0.0495298  |
----------------------------------------
itr #300 | 
Mem: 763.187500
Obtaining samples...
Obtaining samples for iteration 300...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5101, #subsample_inputs: 5101
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.715      |
| AbsLearnSignalNew       | 0.715      |
| AbsLearningOld          | 0.715      |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 14.2293    |
| AveragePolicyStd        | 0.833643   |
| AverageReturn           | 446        |
| Entropy                 | 7.38884    |
| EnvExecTime             | 2.83       |
| ExplainedVariance       | 0.456      |
| Iteration               | 300        |
| ItrTime                 | 17.8       |
| LossAfter               | -2.90826   |
| LossBefore              | -2.85544   |
| MaxReturn               | 677        |
| MeanKL                  | 0.00645472 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 65.5       |
| NumTrajs                | 20         |
| Perplexity              | 1617.82    |
| PolicyExecTime          | 0.59       |
| ProcessExecTime         | 0.0744     |
| StdReturn               | 158        |
| Time                    | 5.38e+03   |
| dLoss                   | 0.0528212  |
----------------------------------------
itr #301 | 
Mem: 763.187500
Obtaining samples...
Obtaining samples for iteration 301...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5183, #subsample_inputs: 5183
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.631      |
| AbsLearnSignalNew       | 0.631      |
| AbsLearningOld          | 0.631      |
| AverageDiscountedReturn | 135        |
| AveragePhiLoss          | 14.6459    |
| AveragePolicyStd        | 0.832247   |
| AverageReturn           | 479        |
| Entropy                 | 7.38029    |
| EnvExecTime             | 2.75       |
| ExplainedVariance       | 0.486      |
| Iteration               | 301        |
| ItrTime                 | 17.3       |
| LossAfter               | -0.688607  |
| LossBefore              | -0.621076  |
| MaxReturn               | 658        |
| MeanKL                  | 0.00995848 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 350        |
| NumTrajs                | 21         |
| Perplexity              | 1604.06    |
| PolicyExecTime          | 0.556      |
| ProcessExecTime         | 0.0713     |
| StdReturn               | 93.1       |
| Time                    | 5.4e+03    |
| dLoss                   | 0.0675311  |
----------------------------------------
itr #302 | 
Mem: 763.187500
Obtaining samples...
Obtaining samples for iteration 302...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5112, #subsample_inputs: 5112
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.655      |
| AbsLearnSignalNew       | 0.655      |
| AbsLearningOld          | 0.655      |
| AverageDiscountedReturn | 129        |
| AveragePhiLoss          | 14.3734    |
| AveragePolicyStd        | 0.831474   |
| AverageReturn           | 468        |
| Entropy                 | 7.3768     |
| EnvExecTime             | 3          |
| ExplainedVariance       | 0.4        |
| Iteration               | 302        |
| ItrTime                 | 18.4       |
| LossAfter               | -1.1957    |
| LossBefore              | -1.12735   |
| MaxReturn               | 765        |
| MeanKL                  | 0.00997426 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 101        |
| NumTrajs                | 20         |
| Perplexity              | 1598.47    |
| PolicyExecTime          | 0.627      |
| ProcessExecTime         | 0.0833     |
| StdReturn               | 149        |
| Time                    | 5.42e+03   |
| dLoss                   | 0.0683467  |
----------------------------------------
itr #303 | 
Mem: 763.187500
Obtaining samples...
Obtaining samples for iteration 303...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5122, #subsample_inputs: 5122
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.711     |
| AbsLearnSignalNew       | 0.711     |
| AbsLearningOld          | 0.711     |
| AverageDiscountedReturn | 128       |
| AveragePhiLoss          | 14.6526   |
| AveragePolicyStd        | 0.832716  |
| AverageReturn           | 461       |
| Entropy                 | 7.38784   |
| EnvExecTime             | 2.48      |
| ExplainedVariance       | 0.411     |
| Iteration               | 303       |
| ItrTime                 | 17.7      |
| LossAfter               | -0.937194 |
| LossBefore              | -0.887182 |
| MaxReturn               | 756       |
| MeanKL                  | 0.0064172 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 38.3      |
| NumTrajs                | 21        |
| Perplexity              | 1616.21   |
| PolicyExecTime          | 0.468     |
| ProcessExecTime         | 0.0644    |
| StdReturn               | 149       |
| Time                    | 5.44e+03  |
| dLoss                   | 0.0500115 |
---------------------------------------
itr #304 | 
Mem: 763.187500
Obtaining samples...
Obtaining samples for iteration 304...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5097, #subsample_inputs: 5097
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.681      |
| AbsLearnSignalNew       | 0.681      |
| AbsLearningOld          | 0.681      |
| AverageDiscountedReturn | 129        |
| AveragePhiLoss          | 14.8462    |
| AveragePolicyStd        | 0.83059    |
| AverageReturn           | 425        |
| Entropy                 | 7.3735     |
| EnvExecTime             | 3.01       |
| ExplainedVariance       | 0.471      |
| Iteration               | 304        |
| ItrTime                 | 17.5       |
| LossAfter               | -1.0057    |
| LossBefore              | -0.954448  |
| MaxReturn               | 846        |
| MeanKL                  | 0.00645327 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 97.2       |
| NumTrajs                | 22         |
| Perplexity              | 1593.21    |
| PolicyExecTime          | 0.626      |
| ProcessExecTime         | 0.0819     |
| StdReturn               | 153        |
| Time                    | 5.46e+03   |
| dLoss                   | 0.0512499  |
----------------------------------------
itr #305 | 
Mem: 763.187500
Obtaining samples...
Obtaining samples for iteration 305...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5151, #subsample_inputs: 5151
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.709      |
| AbsLearnSignalNew       | 0.709      |
| AbsLearningOld          | 0.709      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 13.7639    |
| AveragePolicyStd        | 0.828266   |
| AverageReturn           | 408        |
| Entropy                 | 7.35752    |
| EnvExecTime             | 2.79       |
| ExplainedVariance       | 0.416      |
| Iteration               | 305        |
| ItrTime                 | 18.2       |
| LossAfter               | -1.15192   |
| LossBefore              | -1.08773   |
| MaxReturn               | 640        |
| MeanKL                  | 0.00998911 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 47.6       |
| NumTrajs                | 22         |
| Perplexity              | 1567.94    |
| PolicyExecTime          | 0.573      |
| ProcessExecTime         | 0.0709     |
| StdReturn               | 172        |
| Time                    | 5.47e+03   |
| dLoss                   | 0.0641901  |
----------------------------------------
itr #306 | 
Mem: 763.187500
Obtaining samples...
Obtaining samples for iteration 306...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5073, #subsample_inputs: 5073
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.693      |
| AbsLearnSignalNew       | 0.693      |
| AbsLearningOld          | 0.693      |
| AverageDiscountedReturn | 115        |
| AveragePhiLoss          | 14.6155    |
| AveragePolicyStd        | 0.82882    |
| AverageReturn           | 379        |
| Entropy                 | 7.3641     |
| EnvExecTime             | 2.79       |
| ExplainedVariance       | 0.464      |
| Iteration               | 306        |
| ItrTime                 | 17.2       |
| LossAfter               | -1.01784   |
| LossBefore              | -0.957143  |
| MaxReturn               | 686        |
| MeanKL                  | 0.00996526 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 35.3       |
| NumTrajs                | 22         |
| Perplexity              | 1578.29    |
| PolicyExecTime          | 0.561      |
| ProcessExecTime         | 0.0713     |
| StdReturn               | 180        |
| Time                    | 5.49e+03   |
| dLoss                   | 0.0606977  |
----------------------------------------
itr #307 | 
Mem: 763.187500
Obtaining samples...
Obtaining samples for iteration 307...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5155, #subsample_inputs: 5155
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.714      |
| AbsLearnSignalNew       | 0.714      |
| AbsLearningOld          | 0.714      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 14.452     |
| AveragePolicyStd        | 0.829209   |
| AverageReturn           | 407        |
| Entropy                 | 7.36512    |
| EnvExecTime             | 3.04       |
| ExplainedVariance       | 0.384      |
| Iteration               | 307        |
| ItrTime                 | 18.4       |
| LossAfter               | -0.0206438 |
| LossBefore              | 0.0255206  |
| MaxReturn               | 607        |
| MeanKL                  | 0.00646123 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 58.4       |
| NumTrajs                | 23         |
| Perplexity              | 1579.91    |
| PolicyExecTime          | 0.625      |
| ProcessExecTime         | 0.0815     |
| StdReturn               | 139        |
| Time                    | 5.51e+03   |
| dLoss                   | 0.0461644  |
----------------------------------------
itr #308 | 
Mem: 763.433594
Obtaining samples...
Obtaining samples for iteration 308...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5136, #subsample_inputs: 5136
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.69       |
| AbsLearnSignalNew       | 0.69       |
| AbsLearningOld          | 0.69       |
| AverageDiscountedReturn | 127        |
| AveragePhiLoss          | 14.2728    |
| AveragePolicyStd        | 0.825977   |
| AverageReturn           | 415        |
| Entropy                 | 7.34378    |
| EnvExecTime             | 2.53       |
| ExplainedVariance       | 0.486      |
| Iteration               | 308        |
| ItrTime                 | 16.8       |
| LossAfter               | -1.5905    |
| LossBefore              | -1.52609   |
| MaxReturn               | 643        |
| MeanKL                  | 0.00972285 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 112        |
| NumTrajs                | 22         |
| Perplexity              | 1546.55    |
| PolicyExecTime          | 0.503      |
| ProcessExecTime         | 0.0659     |
| StdReturn               | 124        |
| Time                    | 5.53e+03   |
| dLoss                   | 0.0644027  |
----------------------------------------
itr #309 | 
Mem: 763.433594
Obtaining samples...
Obtaining samples for iteration 309...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5227, #subsample_inputs: 5227
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.682      |
| AbsLearnSignalNew       | 0.682      |
| AbsLearningOld          | 0.682      |
| AverageDiscountedReturn | 129        |
| AveragePhiLoss          | 14.6545    |
| AveragePolicyStd        | 0.824553   |
| AverageReturn           | 421        |
| Entropy                 | 7.33427    |
| EnvExecTime             | 3.04       |
| ExplainedVariance       | 0.38       |
| Iteration               | 309        |
| ItrTime                 | 18.7       |
| LossAfter               | -1.79952   |
| LossBefore              | -1.74992   |
| MaxReturn               | 724        |
| MeanKL                  | 0.00647772 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 226        |
| NumTrajs                | 23         |
| Perplexity              | 1531.91    |
| PolicyExecTime          | 0.656      |
| ProcessExecTime         | 0.0825     |
| StdReturn               | 127        |
| Time                    | 5.54e+03   |
| dLoss                   | 0.0496004  |
----------------------------------------
itr #310 | 
Mem: 763.433594
Obtaining samples...
Obtaining samples for iteration 310...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5095, #subsample_inputs: 5095
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.674      |
| AbsLearnSignalNew       | 0.674      |
| AbsLearningOld          | 0.674      |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 13.9119    |
| AveragePolicyStd        | 0.822562   |
| AverageReturn           | 356        |
| Entropy                 | 7.31988    |
| EnvExecTime             | 2.56       |
| ExplainedVariance       | 0.452      |
| Iteration               | 310        |
| ItrTime                 | 18         |
| LossAfter               | -0.346429  |
| LossBefore              | -0.29721   |
| MaxReturn               | 556        |
| MeanKL                  | 0.00643897 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 52.8       |
| NumTrajs                | 25         |
| Perplexity              | 1510.03    |
| PolicyExecTime          | 0.485      |
| ProcessExecTime         | 0.0629     |
| StdReturn               | 132        |
| Time                    | 5.56e+03   |
| dLoss                   | 0.0492191  |
----------------------------------------
itr #311 | 
Mem: 763.433594
Obtaining samples...
Obtaining samples for iteration 311...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5036, #subsample_inputs: 5036
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.696      |
| AbsLearnSignalNew       | 0.696      |
| AbsLearningOld          | 0.696      |
| AverageDiscountedReturn | 131        |
| AveragePhiLoss          | 13.8878    |
| AveragePolicyStd        | 0.823694   |
| AverageReturn           | 489        |
| Entropy                 | 7.32805    |
| EnvExecTime             | 2.92       |
| ExplainedVariance       | -0.00195   |
| Iteration               | 311        |
| ItrTime                 | 17.9       |
| LossAfter               | -1.58103   |
| LossBefore              | -1.51396   |
| MaxReturn               | 724        |
| MeanKL                  | 0.00995874 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 171        |
| NumTrajs                | 20         |
| Perplexity              | 1522.41    |
| PolicyExecTime          | 0.62       |
| ProcessExecTime         | 0.0802     |
| StdReturn               | 150        |
| Time                    | 5.58e+03   |
| dLoss                   | 0.0670744  |
----------------------------------------
itr #312 | 
Mem: 763.433594
Obtaining samples...
Obtaining samples for iteration 312...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5118, #subsample_inputs: 5118
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.62       |
| AbsLearnSignalNew       | 0.62       |
| AbsLearningOld          | 0.62       |
| AverageDiscountedReturn | 118        |
| AveragePhiLoss          | 14.718     |
| AveragePolicyStd        | 0.825688   |
| AverageReturn           | 430        |
| Entropy                 | 7.34168    |
| EnvExecTime             | 2.52       |
| ExplainedVariance       | 0.3        |
| Iteration               | 312        |
| ItrTime                 | 17.6       |
| LossAfter               | -1.3398    |
| LossBefore              | -1.24605   |
| MaxReturn               | 608        |
| MeanKL                  | 0.00990474 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 29         |
| NumTrajs                | 20         |
| Perplexity              | 1543.3     |
| PolicyExecTime          | 0.514      |
| ProcessExecTime         | 0.0675     |
| StdReturn               | 148        |
| Time                    | 5.6e+03    |
| dLoss                   | 0.093755   |
----------------------------------------
itr #313 | 
Mem: 763.433594
Obtaining samples...
Obtaining samples for iteration 313...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5137, #subsample_inputs: 5137
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.672      |
| AbsLearnSignalNew       | 0.672      |
| AbsLearningOld          | 0.672      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 14.0625    |
| AveragePolicyStd        | 0.826293   |
| AverageReturn           | 402        |
| Entropy                 | 7.34626    |
| EnvExecTime             | 2.7        |
| ExplainedVariance       | 0.442      |
| Iteration               | 313        |
| ItrTime                 | 17.6       |
| LossAfter               | -0.248139  |
| LossBefore              | -0.196655  |
| MaxReturn               | 690        |
| MeanKL                  | 0.00645573 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 80         |
| NumTrajs                | 23         |
| Perplexity              | 1550.39    |
| PolicyExecTime          | 0.545      |
| ProcessExecTime         | 0.0727     |
| StdReturn               | 144        |
| Time                    | 5.62e+03   |
| dLoss                   | 0.051484   |
----------------------------------------
itr #314 | 
Mem: 763.433594
Obtaining samples...
Obtaining samples for iteration 314...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5021, #subsample_inputs: 5021
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.645      |
| AbsLearnSignalNew       | 0.645      |
| AbsLearningOld          | 0.645      |
| AverageDiscountedReturn | 114        |
| AveragePhiLoss          | 14.5291    |
| AveragePolicyStd        | 0.824849   |
| AverageReturn           | 360        |
| Entropy                 | 7.33706    |
| EnvExecTime             | 2.82       |
| ExplainedVariance       | 0.418      |
| Iteration               | 314        |
| ItrTime                 | 18.5       |
| LossAfter               | -0.763028  |
| LossBefore              | -0.698062  |
| MaxReturn               | 700        |
| MeanKL                  | 0.00656159 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 59.9       |
| NumTrajs                | 22         |
| Perplexity              | 1536.19    |
| PolicyExecTime          | 0.595      |
| ProcessExecTime         | 0.0758     |
| StdReturn               | 159        |
| Time                    | 5.64e+03   |
| dLoss                   | 0.0649669  |
----------------------------------------
itr #315 | 
Mem: 763.433594
Obtaining samples...
Obtaining samples for iteration 315...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5273, #subsample_inputs: 5273
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.694      |
| AbsLearnSignalNew       | 0.694      |
| AbsLearningOld          | 0.695      |
| AverageDiscountedReturn | 132        |
| AveragePhiLoss          | 13.1956    |
| AveragePolicyStd        | 0.825321   |
| AverageReturn           | 423        |
| Entropy                 | 7.34022    |
| EnvExecTime             | 2.57       |
| ExplainedVariance       | 0.438      |
| Iteration               | 315        |
| ItrTime                 | 17.8       |
| LossAfter               | 0.350928   |
| LossBefore              | 0.415693   |
| MaxReturn               | 653        |
| MeanKL                  | 0.00988466 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 191        |
| NumTrajs                | 24         |
| Perplexity              | 1541.05    |
| PolicyExecTime          | 0.5        |
| ProcessExecTime         | 0.0649     |
| StdReturn               | 114        |
| Time                    | 5.65e+03   |
| dLoss                   | 0.0647648  |
----------------------------------------
itr #316 | 
Mem: 763.949219
Obtaining samples...
Obtaining samples for iteration 316...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5135, #subsample_inputs: 5135
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.678      |
| AbsLearnSignalNew       | 0.678      |
| AbsLearningOld          | 0.678      |
| AverageDiscountedReturn | 114        |
| AveragePhiLoss          | 14.1554    |
| AveragePolicyStd        | 0.827398   |
| AverageReturn           | 365        |
| Entropy                 | 7.35758    |
| EnvExecTime             | 3          |
| ExplainedVariance       | 0.305      |
| Iteration               | 316        |
| ItrTime                 | 17.7       |
| LossAfter               | 0.489478   |
| LossBefore              | 0.537757   |
| MaxReturn               | 922        |
| MeanKL                  | 0.00640586 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 40.9       |
| NumTrajs                | 23         |
| Perplexity              | 1568.03    |
| PolicyExecTime          | 0.627      |
| ProcessExecTime         | 0.0795     |
| StdReturn               | 200        |
| Time                    | 5.67e+03   |
| dLoss                   | 0.0482786  |
----------------------------------------
itr #317 | 
Mem: 763.949219
Obtaining samples...
Obtaining samples for iteration 317...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5114, #subsample_inputs: 5114
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.697      |
| AbsLearnSignalNew       | 0.697      |
| AbsLearningOld          | 0.697      |
| AverageDiscountedReturn | 123        |
| AveragePhiLoss          | 14.3763    |
| AveragePolicyStd        | 0.82768    |
| AverageReturn           | 416        |
| Entropy                 | 7.35839    |
| EnvExecTime             | 2.63       |
| ExplainedVariance       | 0.426      |
| Iteration               | 317        |
| ItrTime                 | 18.3       |
| LossAfter               | 0.32347    |
| LossBefore              | 0.386474   |
| MaxReturn               | 781        |
| MeanKL                  | 0.00990249 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 42.6       |
| NumTrajs                | 22         |
| Perplexity              | 1569.31    |
| PolicyExecTime          | 0.523      |
| ProcessExecTime         | 0.0695     |
| StdReturn               | 197        |
| Time                    | 5.69e+03   |
| dLoss                   | 0.0630039  |
----------------------------------------
itr #318 | 
Mem: 763.949219
Obtaining samples...
Obtaining samples for iteration 318...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5031, #subsample_inputs: 5031
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.716      |
| AbsLearnSignalNew       | 0.716      |
| AbsLearningOld          | 0.716      |
| AverageDiscountedReturn | 119        |
| AveragePhiLoss          | 13.9376    |
| AveragePolicyStd        | 0.827748   |
| AverageReturn           | 385        |
| Entropy                 | 7.35809    |
| EnvExecTime             | 2.63       |
| ExplainedVariance       | 0.415      |
| Iteration               | 318        |
| ItrTime                 | 17.1       |
| LossAfter               | 0.413005   |
| LossBefore              | 0.478411   |
| MaxReturn               | 906        |
| MeanKL                  | 0.00992445 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 38.8       |
| NumTrajs                | 23         |
| Perplexity              | 1568.84    |
| PolicyExecTime          | 0.538      |
| ProcessExecTime         | 0.0697     |
| StdReturn               | 186        |
| Time                    | 5.71e+03   |
| dLoss                   | 0.0654068  |
----------------------------------------
itr #319 | 
Mem: 763.949219
Obtaining samples...
Obtaining samples for iteration 319...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5252, #subsample_inputs: 5252
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.607      |
| AbsLearnSignalNew       | 0.607      |
| AbsLearningOld          | 0.607      |
| AverageDiscountedReturn | 118        |
| AveragePhiLoss          | 13.7322    |
| AveragePolicyStd        | 0.824012   |
| AverageReturn           | 414        |
| Entropy                 | 7.32994    |
| EnvExecTime             | 3.16       |
| ExplainedVariance       | -0.386     |
| Iteration               | 319        |
| ItrTime                 | 18.9       |
| LossAfter               | -2.00076   |
| LossBefore              | -1.9238    |
| MaxReturn               | 1.21e+03   |
| MeanKL                  | 0.00977384 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 45.8       |
| NumTrajs                | 23         |
| Perplexity              | 1525.29    |
| PolicyExecTime          | 0.696      |
| ProcessExecTime         | 0.0843     |
| StdReturn               | 273        |
| Time                    | 5.73e+03   |
| dLoss                   | 0.0769626  |
----------------------------------------
itr #320 | 
Mem: 763.949219
Obtaining samples...
Obtaining samples for iteration 320...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5057, #subsample_inputs: 5057
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.713      |
| AbsLearnSignalNew       | 0.713      |
| AbsLearningOld          | 0.713      |
| AverageDiscountedReturn | 129        |
| AveragePhiLoss          | 14.8753    |
| AveragePolicyStd        | 0.823954   |
| AverageReturn           | 462        |
| Entropy                 | 7.33001    |
| EnvExecTime             | 2.4        |
| ExplainedVariance       | 0.453      |
| Iteration               | 320        |
| ItrTime                 | 17.1       |
| LossAfter               | 0.295404   |
| LossBefore              | 0.360024   |
| MaxReturn               | 1.25e+03   |
| MeanKL                  | 0.00993832 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 52.1       |
| NumTrajs                | 21         |
| Perplexity              | 1525.39    |
| PolicyExecTime          | 0.458      |
| ProcessExecTime         | 0.0611     |
| StdReturn               | 255        |
| Time                    | 5.74e+03   |
| dLoss                   | 0.0646205  |
----------------------------------------
itr #321 | 
Mem: 763.949219
Obtaining samples...
Obtaining samples for iteration 321...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5077, #subsample_inputs: 5077
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.7        |
| AbsLearnSignalNew       | 0.7        |
| AbsLearningOld          | 0.7        |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 15.0635    |
| AveragePolicyStd        | 0.823995   |
| AverageReturn           | 403        |
| Entropy                 | 7.32951    |
| EnvExecTime             | 3.11       |
| ExplainedVariance       | 0.413      |
| Iteration               | 321        |
| ItrTime                 | 17.8       |
| LossAfter               | -1.54252   |
| LossBefore              | -1.48969   |
| MaxReturn               | 796        |
| MeanKL                  | 0.00641149 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 81.9       |
| NumTrajs                | 22         |
| Perplexity              | 1524.63    |
| PolicyExecTime          | 0.632      |
| ProcessExecTime         | 0.0834     |
| StdReturn               | 168        |
| Time                    | 5.76e+03   |
| dLoss                   | 0.0528333  |
----------------------------------------
itr #322 | 
Mem: 763.949219
Obtaining samples...
Obtaining samples for iteration 322...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5069, #subsample_inputs: 5069
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.71       |
| AbsLearnSignalNew       | 0.71       |
| AbsLearningOld          | 0.71       |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 13.856     |
| AveragePolicyStd        | 0.82201    |
| AverageReturn           | 412        |
| Entropy                 | 7.3144     |
| EnvExecTime             | 2.6        |
| ExplainedVariance       | 0.4        |
| Iteration               | 322        |
| ItrTime                 | 18.2       |
| LossAfter               | -1.24955   |
| LossBefore              | -1.18663   |
| MaxReturn               | 762        |
| MeanKL                  | 0.00994323 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 49.5       |
| NumTrajs                | 22         |
| Perplexity              | 1501.77    |
| PolicyExecTime          | 0.511      |
| ProcessExecTime         | 0.067      |
| StdReturn               | 190        |
| Time                    | 5.78e+03   |
| dLoss                   | 0.0629215  |
----------------------------------------
itr #323 | 
Mem: 763.949219
Obtaining samples...
Obtaining samples for iteration 323...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5425, #subsample_inputs: 5425
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.658      |
| AbsLearnSignalNew       | 0.658      |
| AbsLearningOld          | 0.658      |
| AverageDiscountedReturn | 133        |
| AveragePhiLoss          | 14.9902    |
| AveragePolicyStd        | 0.823134   |
| AverageReturn           | 473        |
| Entropy                 | 7.32257    |
| EnvExecTime             | 2.91       |
| ExplainedVariance       | 0.285      |
| Iteration               | 323        |
| ItrTime                 | 18.5       |
| LossAfter               | 0.147084   |
| LossBefore              | 0.196613   |
| MaxReturn               | 649        |
| MeanKL                  | 0.00645995 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 40.2       |
| NumTrajs                | 22         |
| Perplexity              | 1514.09    |
| PolicyExecTime          | 0.588      |
| ProcessExecTime         | 0.0814     |
| StdReturn               | 141        |
| Time                    | 5.8e+03    |
| dLoss                   | 0.0495292  |
----------------------------------------
itr #324 | 
Mem: 763.949219
Obtaining samples...
Obtaining samples for iteration 324...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5059, #subsample_inputs: 5059
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.679      |
| AbsLearnSignalNew       | 0.679      |
| AbsLearningOld          | 0.679      |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 14.3657    |
| AveragePolicyStd        | 0.824862   |
| AverageReturn           | 446        |
| Entropy                 | 7.33521    |
| EnvExecTime             | 2.78       |
| ExplainedVariance       | 0.479      |
| Iteration               | 324        |
| ItrTime                 | 17.9       |
| LossAfter               | -0.978915  |
| LossBefore              | -0.914302  |
| MaxReturn               | 800        |
| MeanKL                  | 0.00998038 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 58.7       |
| NumTrajs                | 20         |
| Perplexity              | 1533.35    |
| PolicyExecTime          | 0.586      |
| ProcessExecTime         | 0.0766     |
| StdReturn               | 143        |
| Time                    | 5.82e+03   |
| dLoss                   | 0.0646126  |
----------------------------------------
itr #325 | 
Mem: 763.949219
Obtaining samples...
Obtaining samples for iteration 325...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5026, #subsample_inputs: 5026
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.674      |
| AbsLearnSignalNew       | 0.674      |
| AbsLearningOld          | 0.675      |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 13.4777    |
| AveragePolicyStd        | 0.824921   |
| AverageReturn           | 398        |
| Entropy                 | 7.33574    |
| EnvExecTime             | 2.61       |
| ExplainedVariance       | 0.41       |
| Iteration               | 325        |
| ItrTime                 | 17.1       |
| LossAfter               | 0.205695   |
| LossBefore              | 0.263233   |
| MaxReturn               | 658        |
| MeanKL                  | 0.00982558 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 78.8       |
| NumTrajs                | 22         |
| Perplexity              | 1534.16    |
| PolicyExecTime          | 0.507      |
| ProcessExecTime         | 0.0666     |
| StdReturn               | 167        |
| Time                    | 5.83e+03   |
| dLoss                   | 0.0575378  |
----------------------------------------
itr #326 | 
Mem: 763.949219
Obtaining samples...
Obtaining samples for iteration 326...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5253, #subsample_inputs: 5253
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.703     |
| AbsLearnSignalNew       | 0.703     |
| AbsLearningOld          | 0.703     |
| AverageDiscountedReturn | 129       |
| AveragePhiLoss          | 14.4717   |
| AveragePolicyStd        | 0.823993  |
| AverageReturn           | 481       |
| Entropy                 | 7.3293    |
| EnvExecTime             | 2.92      |
| ExplainedVariance       | 0.318     |
| Iteration               | 326       |
| ItrTime                 | 18.7      |
| LossAfter               | -0.249004 |
| LossBefore              | -0.183529 |
| MaxReturn               | 1e+03     |
| MeanKL                  | 0.0099512 |
| MeanKLBefore            | 0.0       |
| MinReturn               | 93.6      |
| NumTrajs                | 21        |
| Perplexity              | 1524.31   |
| PolicyExecTime          | 0.596     |
| ProcessExecTime         | 0.0806    |
| StdReturn               | 193       |
| Time                    | 5.85e+03  |
| dLoss                   | 0.0654745 |
---------------------------------------
itr #327 | 
Mem: 763.949219
Obtaining samples...
Obtaining samples for iteration 327...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5198, #subsample_inputs: 5198
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.703      |
| AbsLearnSignalNew       | 0.703      |
| AbsLearningOld          | 0.704      |
| AverageDiscountedReturn | 129        |
| AveragePhiLoss          | 14.3608    |
| AveragePolicyStd        | 0.823007   |
| AverageReturn           | 444        |
| Entropy                 | 7.32257    |
| EnvExecTime             | 2.6        |
| ExplainedVariance       | 0.481      |
| Iteration               | 327        |
| ItrTime                 | 18.5       |
| LossAfter               | 1.52206    |
| LossBefore              | 1.5795     |
| MaxReturn               | 685        |
| MeanKL                  | 0.00995997 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 267        |
| NumTrajs                | 22         |
| Perplexity              | 1514.09    |
| PolicyExecTime          | 0.524      |
| ProcessExecTime         | 0.0662     |
| StdReturn               | 115        |
| Time                    | 5.87e+03   |
| dLoss                   | 0.0574497  |
----------------------------------------
itr #328 | 
Mem: 763.949219
Obtaining samples...
Obtaining samples for iteration 328...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5020, #subsample_inputs: 5020
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.649      |
| AbsLearnSignalNew       | 0.649      |
| AbsLearningOld          | 0.649      |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 14.2362    |
| AveragePolicyStd        | 0.822664   |
| AverageReturn           | 433        |
| Entropy                 | 7.3196     |
| EnvExecTime             | 2.8        |
| ExplainedVariance       | 0.371      |
| Iteration               | 328        |
| ItrTime                 | 17.7       |
| LossAfter               | 0.843906   |
| LossBefore              | 0.899824   |
| MaxReturn               | 693        |
| MeanKL                  | 0.00996087 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 65.4       |
| NumTrajs                | 21         |
| Perplexity              | 1509.6     |
| PolicyExecTime          | 0.572      |
| ProcessExecTime         | 0.0745     |
| StdReturn               | 135        |
| Time                    | 5.89e+03   |
| dLoss                   | 0.0559172  |
----------------------------------------
itr #329 | 
Mem: 763.949219
Obtaining samples...
Obtaining samples for iteration 329...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5206, #subsample_inputs: 5206
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.425      |
| AbsLearnSignalNew       | 0.425      |
| AbsLearningOld          | 0.425      |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 13.6621    |
| AveragePolicyStd        | 0.823934   |
| AverageReturn           | 467        |
| Entropy                 | 7.32857    |
| EnvExecTime             | 2.89       |
| ExplainedVariance       | -1.8       |
| Iteration               | 329        |
| ItrTime                 | 18.5       |
| LossAfter               | 1.14641    |
| LossBefore              | 1.19414    |
| MaxReturn               | 900        |
| MeanKL                  | 0.00991673 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 309        |
| NumTrajs                | 20         |
| Perplexity              | 1523.21    |
| PolicyExecTime          | 0.606      |
| ProcessExecTime         | 0.0817     |
| StdReturn               | 134        |
| Time                    | 5.91e+03   |
| dLoss                   | 0.0477321  |
----------------------------------------
itr #330 | 
Mem: 763.949219
Obtaining samples...
Obtaining samples for iteration 330...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5394, #subsample_inputs: 5394
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.618      |
| AbsLearnSignalNew       | 0.618      |
| AbsLearningOld          | 0.618      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 14.4497    |
| AveragePolicyStd        | 0.824711   |
| AverageReturn           | 498        |
| Entropy                 | 7.33423    |
| EnvExecTime             | 2.71       |
| ExplainedVariance       | 0.428      |
| Iteration               | 330        |
| ItrTime                 | 19         |
| LossAfter               | 0.657053   |
| LossBefore              | 0.726548   |
| MaxReturn               | 947        |
| MeanKL                  | 0.00995648 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 29.6       |
| NumTrajs                | 20         |
| Perplexity              | 1531.85    |
| PolicyExecTime          | 0.518      |
| ProcessExecTime         | 0.0696     |
| StdReturn               | 215        |
| Time                    | 5.93e+03   |
| dLoss                   | 0.0694954  |
----------------------------------------
itr #331 | 
Mem: 763.949219
Obtaining samples...
Obtaining samples for iteration 331...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5130, #subsample_inputs: 5130
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.703      |
| AbsLearnSignalNew       | 0.703      |
| AbsLearningOld          | 0.703      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 15.2528    |
| AveragePolicyStd        | 0.8273     |
| AverageReturn           | 428        |
| Entropy                 | 7.35398    |
| EnvExecTime             | 2.97       |
| ExplainedVariance       | 0.481      |
| Iteration               | 331        |
| ItrTime                 | 18.4       |
| LossAfter               | 1.72984    |
| LossBefore              | 1.77729    |
| MaxReturn               | 734        |
| MeanKL                  | 0.00642642 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 43.7       |
| NumTrajs                | 21         |
| Perplexity              | 1562.4     |
| PolicyExecTime          | 0.611      |
| ProcessExecTime         | 0.0775     |
| StdReturn               | 194        |
| Time                    | 5.94e+03   |
| dLoss                   | 0.0474445  |
----------------------------------------
itr #332 | 
Mem: 763.949219
Obtaining samples...
Obtaining samples for iteration 332...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5143, #subsample_inputs: 5143
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.626      |
| AbsLearnSignalNew       | 0.626      |
| AbsLearningOld          | 0.626      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 14.9452    |
| AveragePolicyStd        | 0.828065   |
| AverageReturn           | 433        |
| Entropy                 | 7.35929    |
| EnvExecTime             | 2.92       |
| ExplainedVariance       | 0.353      |
| Iteration               | 332        |
| ItrTime                 | 19.1       |
| LossAfter               | 1.19142    |
| LossBefore              | 1.25233    |
| MaxReturn               | 870        |
| MeanKL                  | 0.00992088 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 35.6       |
| NumTrajs                | 22         |
| Perplexity              | 1570.73    |
| PolicyExecTime          | 0.615      |
| ProcessExecTime         | 0.0791     |
| StdReturn               | 163        |
| Time                    | 5.96e+03   |
| dLoss                   | 0.0609151  |
----------------------------------------
itr #333 | 
Mem: 763.949219
Obtaining samples...
Obtaining samples for iteration 333...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5269, #subsample_inputs: 5269
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.664      |
| AbsLearnSignalNew       | 0.664      |
| AbsLearningOld          | 0.664      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 14.2926    |
| AveragePolicyStd        | 0.827396   |
| AverageReturn           | 442        |
| Entropy                 | 7.35405    |
| EnvExecTime             | 2.57       |
| ExplainedVariance       | 0.423      |
| Iteration               | 333        |
| ItrTime                 | 17.8       |
| LossAfter               | 0.7581     |
| LossBefore              | 0.81907    |
| MaxReturn               | 727        |
| MeanKL                  | 0.00996951 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 50.8       |
| NumTrajs                | 21         |
| Perplexity              | 1562.5     |
| PolicyExecTime          | 0.486      |
| ProcessExecTime         | 0.0654     |
| StdReturn               | 167        |
| Time                    | 5.98e+03   |
| dLoss                   | 0.0609703  |
----------------------------------------
itr #334 | 
Mem: 764.281250
Obtaining samples...
Obtaining samples for iteration 334...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5115, #subsample_inputs: 5115
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
-----------------------------------------
| AbsLearnSignal          | 0.718       |
| AbsLearnSignalNew       | 0.718       |
| AbsLearningOld          | 0.718       |
| AverageDiscountedReturn | 125         |
| AveragePhiLoss          | 14.4542     |
| AveragePolicyStd        | 0.824582    |
| AverageReturn           | 424         |
| Entropy                 | 7.33453     |
| EnvExecTime             | 2.91        |
| ExplainedVariance       | 0.497       |
| Iteration               | 334         |
| ItrTime                 | 18.3        |
| LossAfter               | -0.0635999  |
| LossBefore              | -0.00393239 |
| MaxReturn               | 644         |
| MeanKL                  | 0.00991221  |
| MeanKLBefore            | 0.0         |
| MinReturn               | 67.8        |
| NumTrajs                | 21          |
| Perplexity              | 1532.31     |
| PolicyExecTime          | 0.619       |
| ProcessExecTime         | 0.0806      |
| StdReturn               | 134         |
| Time                    | 6e+03       |
| dLoss                   | 0.0596675   |
-----------------------------------------
itr #335 | 
Mem: 764.281250
Obtaining samples...
Obtaining samples for iteration 335...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5011, #subsample_inputs: 5011
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.688      |
| AbsLearnSignalNew       | 0.688      |
| AbsLearningOld          | 0.688      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 15.0999    |
| AveragePolicyStd        | 0.825186   |
| AverageReturn           | 405        |
| Entropy                 | 7.33784    |
| EnvExecTime             | 2.35       |
| ExplainedVariance       | 0.454      |
| Iteration               | 335        |
| ItrTime                 | 17.5       |
| LossAfter               | -0.824212  |
| LossBefore              | -0.756377  |
| MaxReturn               | 661        |
| MeanKL                  | 0.00992126 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 58.3       |
| NumTrajs                | 22         |
| Perplexity              | 1537.39    |
| PolicyExecTime          | 0.463      |
| ProcessExecTime         | 0.0609     |
| StdReturn               | 157        |
| Time                    | 6.02e+03   |
| dLoss                   | 0.0678353  |
----------------------------------------
itr #336 | 
Mem: 764.281250
Obtaining samples...
Obtaining samples for iteration 336...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5031, #subsample_inputs: 5031
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.705      |
| AbsLearnSignalNew       | 0.705      |
| AbsLearningOld          | 0.705      |
| AverageDiscountedReturn | 120        |
| AveragePhiLoss          | 14.8676    |
| AveragePolicyStd        | 0.824301   |
| AverageReturn           | 361        |
| Entropy                 | 7.33023    |
| EnvExecTime             | 2.8        |
| ExplainedVariance       | 0.471      |
| Iteration               | 336        |
| ItrTime                 | 17.3       |
| LossAfter               | -1.142     |
| LossBefore              | -1.08191   |
| MaxReturn               | 558        |
| MeanKL                  | 0.00999379 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 44.8       |
| NumTrajs                | 24         |
| Perplexity              | 1525.73    |
| PolicyExecTime          | 0.582      |
| ProcessExecTime         | 0.0771     |
| StdReturn               | 152        |
| Time                    | 6.03e+03   |
| dLoss                   | 0.0600946  |
----------------------------------------
itr #337 | 
Mem: 764.281250
Obtaining samples...
Obtaining samples for iteration 337...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5301, #subsample_inputs: 5301
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.669      |
| AbsLearnSignalNew       | 0.669      |
| AbsLearningOld          | 0.668      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 14.3035    |
| AveragePolicyStd        | 0.823209   |
| AverageReturn           | 454        |
| Entropy                 | 7.32101    |
| EnvExecTime             | 2.62       |
| ExplainedVariance       | 0.368      |
| Iteration               | 337        |
| ItrTime                 | 18.2       |
| LossAfter               | -0.637873  |
| LossBefore              | -0.586309  |
| MaxReturn               | 925        |
| MeanKL                  | 0.00644082 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 37.9       |
| NumTrajs                | 22         |
| Perplexity              | 1511.73    |
| PolicyExecTime          | 0.538      |
| ProcessExecTime         | 0.0697     |
| StdReturn               | 185        |
| Time                    | 6.05e+03   |
| dLoss                   | 0.0515634  |
----------------------------------------
itr #338 | 
Mem: 764.281250
Obtaining samples...
Obtaining samples for iteration 338...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5163, #subsample_inputs: 5163
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.702      |
| AbsLearnSignalNew       | 0.702      |
| AbsLearningOld          | 0.702      |
| AverageDiscountedReturn | 124        |
| AveragePhiLoss          | 14.6426    |
| AveragePolicyStd        | 0.823088   |
| AverageReturn           | 410        |
| Entropy                 | 7.32123    |
| EnvExecTime             | 2.72       |
| ExplainedVariance       | 0.525      |
| Iteration               | 338        |
| ItrTime                 | 17.9       |
| LossAfter               | 0.881547   |
| LossBefore              | 0.929378   |
| MaxReturn               | 658        |
| MeanKL                  | 0.00641005 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 26.6       |
| NumTrajs                | 23         |
| Perplexity              | 1512.06    |
| PolicyExecTime          | 0.565      |
| ProcessExecTime         | 0.0748     |
| StdReturn               | 135        |
| Time                    | 6.07e+03   |
| dLoss                   | 0.0478309  |
----------------------------------------
itr #339 | 
Mem: 764.281250
Obtaining samples...
Obtaining samples for iteration 339...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5132, #subsample_inputs: 5132
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.622      |
| AbsLearnSignalNew       | 0.622      |
| AbsLearningOld          | 0.622      |
| AverageDiscountedReturn | 130        |
| AveragePhiLoss          | 14.8799    |
| AveragePolicyStd        | 0.823288   |
| AverageReturn           | 443        |
| Entropy                 | 7.322      |
| EnvExecTime             | 2.34       |
| ExplainedVariance       | 0.335      |
| Iteration               | 339        |
| ItrTime                 | 18         |
| LossAfter               | -0.038493  |
| LossBefore              | 0.0252727  |
| MaxReturn               | 833        |
| MeanKL                  | 0.00642317 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 39.7       |
| NumTrajs                | 22         |
| Perplexity              | 1513.22    |
| PolicyExecTime          | 0.491      |
| ProcessExecTime         | 0.0657     |
| StdReturn               | 185        |
| Time                    | 6.09e+03   |
| dLoss                   | 0.0637657  |
----------------------------------------
itr #340 | 
Mem: 764.281250
Obtaining samples...
Obtaining samples for iteration 340...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5134, #subsample_inputs: 5134
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.682      |
| AbsLearnSignalNew       | 0.682      |
| AbsLearningOld          | 0.682      |
| AverageDiscountedReturn | 132        |
| AveragePhiLoss          | 14.7804    |
| AveragePolicyStd        | 0.824026   |
| AverageReturn           | 449        |
| Entropy                 | 7.32643    |
| EnvExecTime             | 2.6        |
| ExplainedVariance       | 0.459      |
| Iteration               | 340        |
| ItrTime                 | 17.3       |
| LossAfter               | -0.192049  |
| LossBefore              | -0.138603  |
| MaxReturn               | 636        |
| MeanKL                  | 0.00645502 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 302        |
| NumTrajs                | 22         |
| Perplexity              | 1519.95    |
| PolicyExecTime          | 0.538      |
| ProcessExecTime         | 0.0719     |
| StdReturn               | 85.5       |
| Time                    | 6.11e+03   |
| dLoss                   | 0.0534452  |
----------------------------------------
itr #341 | 
Mem: 764.281250
Obtaining samples...
Obtaining samples for iteration 341...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5215, #subsample_inputs: 5215
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.575      |
| AbsLearnSignalNew       | 0.575      |
| AbsLearningOld          | 0.575      |
| AverageDiscountedReturn | 143        |
| AveragePhiLoss          | 13.9277    |
| AveragePolicyStd        | 0.820519   |
| AverageReturn           | 532        |
| Entropy                 | 7.30175    |
| EnvExecTime             | 2.78       |
| ExplainedVariance       | -0.433     |
| Iteration               | 341        |
| ItrTime                 | 18.5       |
| LossAfter               | 0.137186   |
| LossBefore              | 0.192838   |
| MaxReturn               | 915        |
| MeanKL                  | 0.00641821 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 255        |
| NumTrajs                | 20         |
| Perplexity              | 1482.89    |
| PolicyExecTime          | 0.599      |
| ProcessExecTime         | 0.0782     |
| StdReturn               | 150        |
| Time                    | 6.13e+03   |
| dLoss                   | 0.055652   |
----------------------------------------
itr #342 | 
Mem: 764.281250
Obtaining samples...
Obtaining samples for iteration 342...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5012, #subsample_inputs: 5012
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.74       |
| AbsLearnSignalNew       | 0.74       |
| AbsLearningOld          | 0.74       |
| AverageDiscountedReturn | 134        |
| AveragePhiLoss          | 14.1759    |
| AveragePolicyStd        | 0.819716   |
| AverageReturn           | 458        |
| Entropy                 | 7.29544    |
| EnvExecTime             | 2.58       |
| ExplainedVariance       | 0.572      |
| Iteration               | 342        |
| ItrTime                 | 17.7       |
| LossAfter               | 0.00575031 |
| LossBefore              | 0.0573462  |
| MaxReturn               | 593        |
| MeanKL                  | 0.00641192 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 323        |
| NumTrajs                | 21         |
| Perplexity              | 1473.57    |
| PolicyExecTime          | 0.515      |
| ProcessExecTime         | 0.0681     |
| StdReturn               | 86.1       |
| Time                    | 6.14e+03   |
| dLoss                   | 0.0515959  |
----------------------------------------
itr #343 | 
Mem: 764.281250
Obtaining samples...
Obtaining samples for iteration 343...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5141, #subsample_inputs: 5141
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.607      |
| AbsLearnSignalNew       | 0.607      |
| AbsLearningOld          | 0.607      |
| AverageDiscountedReturn | 131        |
| AveragePhiLoss          | 14.654     |
| AveragePolicyStd        | 0.821176   |
| AverageReturn           | 425        |
| Entropy                 | 7.30601    |
| EnvExecTime             | 2.97       |
| ExplainedVariance       | 0.278      |
| Iteration               | 343        |
| ItrTime                 | 18.3       |
| LossAfter               | -0.779811  |
| LossBefore              | -0.704928  |
| MaxReturn               | 914        |
| MeanKL                  | 0.00992001 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 146        |
| NumTrajs                | 23         |
| Perplexity              | 1489.22    |
| PolicyExecTime          | 0.634      |
| ProcessExecTime         | 0.0852     |
| StdReturn               | 166        |
| Time                    | 6.16e+03   |
| dLoss                   | 0.0748827  |
----------------------------------------
itr #344 | 
Mem: 764.281250
Obtaining samples...
Obtaining samples for iteration 344...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5242, #subsample_inputs: 5242
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.718      |
| AbsLearnSignalNew       | 0.718      |
| AbsLearningOld          | 0.718      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 14.0685    |
| AveragePolicyStd        | 0.822804   |
| AverageReturn           | 446        |
| Entropy                 | 7.31449    |
| EnvExecTime             | 2.68       |
| ExplainedVariance       | 0.419      |
| Iteration               | 344        |
| ItrTime                 | 18.1       |
| LossAfter               | -1.33825   |
| LossBefore              | -1.28271   |
| MaxReturn               | 854        |
| MeanKL                  | 0.00999148 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 68.3       |
| NumTrajs                | 22         |
| Perplexity              | 1501.9     |
| PolicyExecTime          | 0.524      |
| ProcessExecTime         | 0.0694     |
| StdReturn               | 163        |
| Time                    | 6.18e+03   |
| dLoss                   | 0.0555391  |
----------------------------------------
itr #345 | 
Mem: 764.281250
Obtaining samples...
Obtaining samples for iteration 345...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5187, #subsample_inputs: 5187
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.637      |
| AbsLearnSignalNew       | 0.637      |
| AbsLearningOld          | 0.637      |
| AverageDiscountedReturn | 130        |
| AveragePhiLoss          | 15.4054    |
| AveragePolicyStd        | 0.820445   |
| AverageReturn           | 477        |
| Entropy                 | 7.29661    |
| EnvExecTime             | 2.96       |
| ExplainedVariance       | 0.353      |
| Iteration               | 345        |
| ItrTime                 | 18         |
| LossAfter               | -0.557872  |
| LossBefore              | -0.505001  |
| MaxReturn               | 1.18e+03   |
| MeanKL                  | 0.00647081 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 113        |
| NumTrajs                | 21         |
| Perplexity              | 1475.3     |
| PolicyExecTime          | 0.633      |
| ProcessExecTime         | 0.0817     |
| StdReturn               | 212        |
| Time                    | 6.2e+03    |
| dLoss                   | 0.0528708  |
----------------------------------------
itr #346 | 
Mem: 765.687500
Obtaining samples...
Obtaining samples for iteration 346...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5370, #subsample_inputs: 5370
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.712      |
| AbsLearnSignalNew       | 0.712      |
| AbsLearningOld          | 0.712      |
| AverageDiscountedReturn | 129        |
| AveragePhiLoss          | 14.8227    |
| AveragePolicyStd        | 0.818617   |
| AverageReturn           | 487        |
| Entropy                 | 7.2843     |
| EnvExecTime             | 2.99       |
| ExplainedVariance       | 0.41       |
| Iteration               | 346        |
| ItrTime                 | 19.1       |
| LossAfter               | -0.162038  |
| LossBefore              | -0.113811  |
| MaxReturn               | 952        |
| MeanKL                  | 0.00641958 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 121        |
| NumTrajs                | 21         |
| Perplexity              | 1457.24    |
| PolicyExecTime          | 0.618      |
| ProcessExecTime         | 0.0817     |
| StdReturn               | 185        |
| Time                    | 6.22e+03   |
| dLoss                   | 0.048227   |
----------------------------------------
itr #347 | 
Mem: 765.941406
Obtaining samples...
Obtaining samples for iteration 347...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5153, #subsample_inputs: 5153
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.649      |
| AbsLearnSignalNew       | 0.649      |
| AbsLearningOld          | 0.649      |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 14.472     |
| AveragePolicyStd        | 0.817938   |
| AverageReturn           | 434        |
| Entropy                 | 7.27925    |
| EnvExecTime             | 2.41       |
| ExplainedVariance       | 0.415      |
| Iteration               | 347        |
| ItrTime                 | 17.2       |
| LossAfter               | -0.861685  |
| LossBefore              | -0.786232  |
| MaxReturn               | 752        |
| MeanKL                  | 0.00993166 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 178        |
| NumTrajs                | 22         |
| Perplexity              | 1449.9     |
| PolicyExecTime          | 0.47       |
| ProcessExecTime         | 0.0629     |
| StdReturn               | 131        |
| Time                    | 6.23e+03   |
| dLoss                   | 0.075453   |
----------------------------------------
itr #348 | 
Mem: 765.941406
Obtaining samples...
Obtaining samples for iteration 348...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5159, #subsample_inputs: 5159
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.69       |
| AbsLearnSignalNew       | 0.69       |
| AbsLearningOld          | 0.69       |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 14.6761    |
| AveragePolicyStd        | 0.816282   |
| AverageReturn           | 469        |
| Entropy                 | 7.26736    |
| EnvExecTime             | 2.97       |
| ExplainedVariance       | 0.411      |
| Iteration               | 348        |
| ItrTime                 | 18.3       |
| LossAfter               | -1.36622   |
| LossBefore              | -1.30277   |
| MaxReturn               | 811        |
| MeanKL                  | 0.00993498 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 199        |
| NumTrajs                | 20         |
| Perplexity              | 1432.76    |
| PolicyExecTime          | 0.627      |
| ProcessExecTime         | 0.0803     |
| StdReturn               | 129        |
| Time                    | 6.25e+03   |
| dLoss                   | 0.0634527  |
----------------------------------------
itr #349 | 
Mem: 766.183594
Obtaining samples...
Obtaining samples for iteration 349...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5125, #subsample_inputs: 5125
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.727      |
| AbsLearnSignalNew       | 0.727      |
| AbsLearningOld          | 0.727      |
| AverageDiscountedReturn | 131        |
| AveragePhiLoss          | 14.4585    |
| AveragePolicyStd        | 0.815109   |
| AverageReturn           | 459        |
| Entropy                 | 7.26024    |
| EnvExecTime             | 2.57       |
| ExplainedVariance       | 0.472      |
| Iteration               | 349        |
| ItrTime                 | 18         |
| LossAfter               | -1.33834   |
| LossBefore              | -1.27416   |
| MaxReturn               | 784        |
| MeanKL                  | 0.00988345 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 270        |
| NumTrajs                | 21         |
| Perplexity              | 1422.59    |
| PolicyExecTime          | 0.49       |
| ProcessExecTime         | 0.0647     |
| StdReturn               | 125        |
| Time                    | 6.27e+03   |
| dLoss                   | 0.064185   |
----------------------------------------
itr #350 | 
Mem: 766.183594
Obtaining samples...
Obtaining samples for iteration 350...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5166, #subsample_inputs: 5166
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.628      |
| AbsLearnSignalNew       | 0.628      |
| AbsLearningOld          | 0.628      |
| AverageDiscountedReturn | 131        |
| AveragePhiLoss          | 14.0059    |
| AveragePolicyStd        | 0.817909   |
| AverageReturn           | 423        |
| Entropy                 | 7.28289    |
| EnvExecTime             | 2.91       |
| ExplainedVariance       | 0.495      |
| Iteration               | 350        |
| ItrTime                 | 17.9       |
| LossAfter               | -1.32469   |
| LossBefore              | -1.27662   |
| MaxReturn               | 678        |
| MeanKL                  | 0.00641836 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 217        |
| NumTrajs                | 23         |
| Perplexity              | 1455.18    |
| PolicyExecTime          | 0.62       |
| ProcessExecTime         | 0.0803     |
| StdReturn               | 110        |
| Time                    | 6.29e+03   |
| dLoss                   | 0.0480747  |
----------------------------------------
itr #351 | 
Mem: 766.183594
Obtaining samples...
Obtaining samples for iteration 351...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5029, #subsample_inputs: 5029
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.586      |
| AbsLearnSignalNew       | 0.586      |
| AbsLearningOld          | 0.586      |
| AverageDiscountedReturn | 119        |
| AveragePhiLoss          | 16.4258    |
| AveragePolicyStd        | 0.81501    |
| AverageReturn           | 394        |
| Entropy                 | 7.26214    |
| EnvExecTime             | 2.6        |
| ExplainedVariance       | 0.369      |
| Iteration               | 351        |
| ItrTime                 | 17.7       |
| LossAfter               | -0.827549  |
| LossBefore              | -0.773989  |
| MaxReturn               | 650        |
| MeanKL                  | 0.00643651 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 23.8       |
| NumTrajs                | 22         |
| Perplexity              | 1425.31    |
| PolicyExecTime          | 0.522      |
| ProcessExecTime         | 0.0666     |
| StdReturn               | 162        |
| Time                    | 6.31e+03   |
| dLoss                   | 0.0535605  |
----------------------------------------
itr #352 | 
Mem: 766.183594
Obtaining samples...
Obtaining samples for iteration 352...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5077, #subsample_inputs: 5077
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.701      |
| AbsLearnSignalNew       | 0.701      |
| AbsLearningOld          | 0.701      |
| AverageDiscountedReturn | 130        |
| AveragePhiLoss          | 14.7252    |
| AveragePolicyStd        | 0.815607   |
| AverageReturn           | 434        |
| Entropy                 | 7.26798    |
| EnvExecTime             | 2.6        |
| ExplainedVariance       | 0.44       |
| Iteration               | 352        |
| ItrTime                 | 17.3       |
| LossAfter               | -0.668608  |
| LossBefore              | -0.620094  |
| MaxReturn               | 741        |
| MeanKL                  | 0.00640486 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 62.3       |
| NumTrajs                | 22         |
| Perplexity              | 1433.65    |
| PolicyExecTime          | 0.555      |
| ProcessExecTime         | 0.0735     |
| StdReturn               | 176        |
| Time                    | 6.32e+03   |
| dLoss                   | 0.0485147  |
----------------------------------------
itr #353 | 
Mem: 766.183594
Obtaining samples...
Obtaining samples for iteration 353...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5213, #subsample_inputs: 5213
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.697      |
| AbsLearnSignalNew       | 0.697      |
| AbsLearningOld          | 0.697      |
| AverageDiscountedReturn | 131        |
| AveragePhiLoss          | 14.946     |
| AveragePolicyStd        | 0.812815   |
| AverageReturn           | 528        |
| Entropy                 | 7.24651    |
| EnvExecTime             | 2.55       |
| ExplainedVariance       | 0.464      |
| Iteration               | 353        |
| ItrTime                 | 18.2       |
| LossAfter               | 0.0710555  |
| LossBefore              | 0.134556   |
| MaxReturn               | 907        |
| MeanKL                  | 0.00999153 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 134        |
| NumTrajs                | 19         |
| Perplexity              | 1403.19    |
| PolicyExecTime          | 0.535      |
| ProcessExecTime         | 0.0686     |
| StdReturn               | 188        |
| Time                    | 6.34e+03   |
| dLoss                   | 0.0635002  |
----------------------------------------
itr #354 | 
Mem: 766.183594
Obtaining samples...
Obtaining samples for iteration 354...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5035, #subsample_inputs: 5035
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.688      |
| AbsLearnSignalNew       | 0.688      |
| AbsLearningOld          | 0.688      |
| AverageDiscountedReturn | 132        |
| AveragePhiLoss          | 15.202     |
| AveragePolicyStd        | 0.811977   |
| AverageReturn           | 414        |
| Entropy                 | 7.24147    |
| EnvExecTime             | 2.74       |
| ExplainedVariance       | 0.48       |
| Iteration               | 354        |
| ItrTime                 | 17.6       |
| LossAfter               | -0.346794  |
| LossBefore              | -0.296044  |
| MaxReturn               | 664        |
| MeanKL                  | 0.00642981 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 208        |
| NumTrajs                | 24         |
| Perplexity              | 1396.14    |
| PolicyExecTime          | 0.565      |
| ProcessExecTime         | 0.072      |
| StdReturn               | 137        |
| Time                    | 6.36e+03   |
| dLoss                   | 0.0507495  |
----------------------------------------
itr #355 | 
Mem: 766.183594
Obtaining samples...
Obtaining samples for iteration 355...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5138, #subsample_inputs: 5138
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.646      |
| AbsLearnSignalNew       | 0.646      |
| AbsLearningOld          | 0.646      |
| AverageDiscountedReturn | 121        |
| AveragePhiLoss          | 15.2577    |
| AveragePolicyStd        | 0.81097    |
| AverageReturn           | 475        |
| Entropy                 | 7.23537    |
| EnvExecTime             | 2.77       |
| ExplainedVariance       | 0.27       |
| Iteration               | 355        |
| ItrTime                 | 18.1       |
| LossAfter               | -1.16173   |
| LossBefore              | -1.09605   |
| MaxReturn               | 1.1e+03    |
| MeanKL                  | 0.00993841 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 52.3       |
| NumTrajs                | 20         |
| Perplexity              | 1387.65    |
| PolicyExecTime          | 0.611      |
| ProcessExecTime         | 0.0735     |
| StdReturn               | 240        |
| Time                    | 6.38e+03   |
| dLoss                   | 0.0656813  |
----------------------------------------
itr #356 | 
Mem: 766.183594
Obtaining samples...
Obtaining samples for iteration 356...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5010, #subsample_inputs: 5010
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.707      |
| AbsLearnSignalNew       | 0.707      |
| AbsLearningOld          | 0.707      |
| AverageDiscountedReturn | 139        |
| AveragePhiLoss          | 14.7789    |
| AveragePolicyStd        | 0.810489   |
| AverageReturn           | 517        |
| Entropy                 | 7.23259    |
| EnvExecTime             | 2.28       |
| ExplainedVariance       | 0.27       |
| Iteration               | 356        |
| ItrTime                 | 16.8       |
| LossAfter               | -0.776364  |
| LossBefore              | -0.728244  |
| MaxReturn               | 966        |
| MeanKL                  | 0.00647868 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 164        |
| NumTrajs                | 19         |
| Perplexity              | 1383.81    |
| PolicyExecTime          | 0.455      |
| ProcessExecTime         | 0.0612     |
| StdReturn               | 223        |
| Time                    | 6.4e+03    |
| dLoss                   | 0.0481196  |
----------------------------------------
itr #357 | 
Mem: 766.183594
Obtaining samples...
Obtaining samples for iteration 357...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5237, #subsample_inputs: 5237
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.697      |
| AbsLearnSignalNew       | 0.697      |
| AbsLearningOld          | 0.697      |
| AverageDiscountedReturn | 125        |
| AveragePhiLoss          | 15.2597    |
| AveragePolicyStd        | 0.807672   |
| AverageReturn           | 491        |
| Entropy                 | 7.21091    |
| EnvExecTime             | 2.81       |
| ExplainedVariance       | 0.361      |
| Iteration               | 357        |
| ItrTime                 | 18.6       |
| LossAfter               | -2.10588   |
| LossBefore              | -2.04      |
| MaxReturn               | 853        |
| MeanKL                  | 0.00996851 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 92.5       |
| NumTrajs                | 19         |
| Perplexity              | 1354.12    |
| PolicyExecTime          | 0.598      |
| ProcessExecTime         | 0.0769     |
| StdReturn               | 168        |
| Time                    | 6.41e+03   |
| dLoss                   | 0.0658832  |
----------------------------------------
itr #358 | 
Mem: 766.183594
Obtaining samples...
Obtaining samples for iteration 358...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5075, #subsample_inputs: 5075
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.702      |
| AbsLearnSignalNew       | 0.702      |
| AbsLearningOld          | 0.702      |
| AverageDiscountedReturn | 114        |
| AveragePhiLoss          | 15.7496    |
| AveragePolicyStd        | 0.806982   |
| AverageReturn           | 418        |
| Entropy                 | 7.2052     |
| EnvExecTime             | 2.49       |
| ExplainedVariance       | 0.489      |
| Iteration               | 358        |
| ItrTime                 | 17         |
| LossAfter               | -2.31064   |
| LossBefore              | -2.24293   |
| MaxReturn               | 682        |
| MeanKL                  | 0.00990839 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 47         |
| NumTrajs                | 20         |
| Perplexity              | 1346.42    |
| PolicyExecTime          | 0.469      |
| ProcessExecTime         | 0.063      |
| StdReturn               | 163        |
| Time                    | 6.43e+03   |
| dLoss                   | 0.0677085  |
----------------------------------------
itr #359 | 
Mem: 766.183594
Obtaining samples...
Obtaining samples for iteration 359...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5150, #subsample_inputs: 5150
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.703      |
| AbsLearnSignalNew       | 0.703      |
| AbsLearningOld          | 0.703      |
| AverageDiscountedReturn | 122        |
| AveragePhiLoss          | 15.1714    |
| AveragePolicyStd        | 0.807366   |
| AverageReturn           | 460        |
| Entropy                 | 7.20686    |
| EnvExecTime             | 3.01       |
| ExplainedVariance       | 0.463      |
| Iteration               | 359        |
| ItrTime                 | 18.3       |
| LossAfter               | -1.0818    |
| LossBefore              | -1.03056   |
| MaxReturn               | 793        |
| MeanKL                  | 0.00640402 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 92.6       |
| NumTrajs                | 20         |
| Perplexity              | 1348.65    |
| PolicyExecTime          | 0.645      |
| ProcessExecTime         | 0.0819     |
| StdReturn               | 168        |
| Time                    | 6.45e+03   |
| dLoss                   | 0.0512452  |
----------------------------------------
itr #360 | 
Mem: 766.183594
Obtaining samples...
Obtaining samples for iteration 360...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5049, #subsample_inputs: 5049
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.644      |
| AbsLearnSignalNew       | 0.644      |
| AbsLearningOld          | 0.644      |
| AverageDiscountedReturn | 133        |
| AveragePhiLoss          | 17.1451    |
| AveragePolicyStd        | 0.807034   |
| AverageReturn           | 479        |
| Entropy                 | 7.2037     |
| EnvExecTime             | 2.36       |
| ExplainedVariance       | 0.193      |
| Iteration               | 360        |
| ItrTime                 | 17.4       |
| LossAfter               | -1.48295   |
| LossBefore              | -1.41029   |
| MaxReturn               | 793        |
| MeanKL                  | 0.00999678 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 145        |
| NumTrajs                | 20         |
| Perplexity              | 1344.39    |
| PolicyExecTime          | 0.458      |
| ProcessExecTime         | 0.0605     |
| StdReturn               | 150        |
| Time                    | 6.47e+03   |
| dLoss                   | 0.0726612  |
----------------------------------------
itr #361 | 
Mem: 766.183594
Obtaining samples...
Obtaining samples for iteration 361...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5183, #subsample_inputs: 5183
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.695      |
| AbsLearnSignalNew       | 0.695      |
| AbsLearningOld          | 0.695      |
| AverageDiscountedReturn | 124        |
| AveragePhiLoss          | 15.725     |
| AveragePolicyStd        | 0.806291   |
| AverageReturn           | 447        |
| Entropy                 | 7.19859    |
| EnvExecTime             | 2.98       |
| ExplainedVariance       | 0.387      |
| Iteration               | 361        |
| ItrTime                 | 18.3       |
| LossAfter               | 0.596743   |
| LossBefore              | 0.661814   |
| MaxReturn               | 906        |
| MeanKL                  | 0.00998499 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 133        |
| NumTrajs                | 21         |
| Perplexity              | 1337.54    |
| PolicyExecTime          | 0.65       |
| ProcessExecTime         | 0.0827     |
| StdReturn               | 182        |
| Time                    | 6.49e+03   |
| dLoss                   | 0.0650706  |
----------------------------------------
itr #362 | 
Mem: 766.183594
Obtaining samples...
Obtaining samples for iteration 362...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5219, #subsample_inputs: 5219
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.704      |
| AbsLearnSignalNew       | 0.704      |
| AbsLearningOld          | 0.704      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 15.9796    |
| AveragePolicyStd        | 0.80476    |
| AverageReturn           | 466        |
| Entropy                 | 7.18854    |
| EnvExecTime             | 2.83       |
| ExplainedVariance       | 0.437      |
| Iteration               | 362        |
| ItrTime                 | 18.3       |
| LossAfter               | -0.272679  |
| LossBefore              | -0.223578  |
| MaxReturn               | 874        |
| MeanKL                  | 0.00642084 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 62         |
| NumTrajs                | 21         |
| Perplexity              | 1324.16    |
| PolicyExecTime          | 0.559      |
| ProcessExecTime         | 0.0688     |
| StdReturn               | 222        |
| Time                    | 6.5e+03    |
| dLoss                   | 0.049101   |
----------------------------------------
itr #363 | 
Mem: 766.183594
Obtaining samples...
Obtaining samples for iteration 363...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5033, #subsample_inputs: 5033
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.662     |
| AbsLearnSignalNew       | 0.662     |
| AbsLearningOld          | 0.662     |
| AverageDiscountedReturn | 130       |
| AveragePhiLoss          | 15.3241   |
| AveragePolicyStd        | 0.802798  |
| AverageReturn           | 524       |
| Entropy                 | 7.17359   |
| EnvExecTime             | 2.78      |
| ExplainedVariance       | 0.414     |
| Iteration               | 363       |
| ItrTime                 | 17.7      |
| LossAfter               | -0.955973 |
| LossBefore              | -0.882208 |
| MaxReturn               | 897       |
| MeanKL                  | 0.009871  |
| MeanKLBefore            | 0.0       |
| MinReturn               | 78.4      |
| NumTrajs                | 19        |
| Perplexity              | 1304.52   |
| PolicyExecTime          | 0.565     |
| ProcessExecTime         | 0.0741    |
| StdReturn               | 219       |
| Time                    | 6.52e+03  |
| dLoss                   | 0.0737649 |
---------------------------------------
itr #364 | 
Mem: 766.183594
Obtaining samples...
Obtaining samples for iteration 364...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5041, #subsample_inputs: 5041
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.719      |
| AbsLearnSignalNew       | 0.719      |
| AbsLearningOld          | 0.719      |
| AverageDiscountedReturn | 132        |
| AveragePhiLoss          | 14.8393    |
| AveragePolicyStd        | 0.800701   |
| AverageReturn           | 495        |
| Entropy                 | 7.15997    |
| EnvExecTime             | 2.78       |
| ExplainedVariance       | 0.412      |
| Iteration               | 364        |
| ItrTime                 | 17.9       |
| LossAfter               | -1.72719   |
| LossBefore              | -1.67431   |
| MaxReturn               | 920        |
| MeanKL                  | 0.00644606 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 81.3       |
| NumTrajs                | 20         |
| Perplexity              | 1286.88    |
| PolicyExecTime          | 0.592      |
| ProcessExecTime         | 0.0764     |
| StdReturn               | 202        |
| Time                    | 6.54e+03   |
| dLoss                   | 0.0528811  |
----------------------------------------
itr #365 | 
Mem: 766.183594
Obtaining samples...
Obtaining samples for iteration 365...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5226, #subsample_inputs: 5226
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.698      |
| AbsLearnSignalNew       | 0.698      |
| AbsLearningOld          | 0.698      |
| AverageDiscountedReturn | 127        |
| AveragePhiLoss          | 15.4266    |
| AveragePolicyStd        | 0.799439   |
| AverageReturn           | 429        |
| Entropy                 | 7.15141    |
| EnvExecTime             | 2.83       |
| ExplainedVariance       | 0.367      |
| Iteration               | 365        |
| ItrTime                 | 18.1       |
| LossAfter               | 0.252429   |
| LossBefore              | 0.316633   |
| MaxReturn               | 812        |
| MeanKL                  | 0.00992286 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 45.6       |
| NumTrajs                | 23         |
| Perplexity              | 1275.91    |
| PolicyExecTime          | 0.577      |
| ProcessExecTime         | 0.0763     |
| StdReturn               | 182        |
| Time                    | 6.56e+03   |
| dLoss                   | 0.0642041  |
----------------------------------------
itr #366 | 
Mem: 766.183594
Obtaining samples...
Obtaining samples for iteration 366...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5159, #subsample_inputs: 5159
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.692      |
| AbsLearnSignalNew       | 0.692      |
| AbsLearningOld          | 0.692      |
| AverageDiscountedReturn | 113        |
| AveragePhiLoss          | 15.122     |
| AveragePolicyStd        | 0.798859   |
| AverageReturn           | 427        |
| Entropy                 | 7.14883    |
| EnvExecTime             | 2.93       |
| ExplainedVariance       | 0.488      |
| Iteration               | 366        |
| ItrTime                 | 18.2       |
| LossAfter               | 1.32432    |
| LossBefore              | 1.38709    |
| MaxReturn               | 996        |
| MeanKL                  | 0.00995688 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 34.4       |
| NumTrajs                | 21         |
| Perplexity              | 1272.62    |
| PolicyExecTime          | 0.613      |
| ProcessExecTime         | 0.08       |
| StdReturn               | 238        |
| Time                    | 6.58e+03   |
| dLoss                   | 0.0627711  |
----------------------------------------
itr #367 | 
Mem: 766.183594
Obtaining samples...
Obtaining samples for iteration 367...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5135, #subsample_inputs: 5135
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.685      |
| AbsLearnSignalNew       | 0.685      |
| AbsLearningOld          | 0.685      |
| AverageDiscountedReturn | 130        |
| AveragePhiLoss          | 15.2972    |
| AveragePolicyStd        | 0.796432   |
| AverageReturn           | 494        |
| Entropy                 | 7.12997    |
| EnvExecTime             | 2.62       |
| ExplainedVariance       | 0.447      |
| Iteration               | 367        |
| ItrTime                 | 17.6       |
| LossAfter               | 1.49835    |
| LossBefore              | 1.56346    |
| MaxReturn               | 970        |
| MeanKL                  | 0.00990263 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 64         |
| NumTrajs                | 20         |
| Perplexity              | 1248.84    |
| PolicyExecTime          | 0.529      |
| ProcessExecTime         | 0.0674     |
| StdReturn               | 175        |
| Time                    | 6.59e+03   |
| dLoss                   | 0.0651066  |
----------------------------------------
itr #368 | 
Mem: 766.183594
Obtaining samples...
Obtaining samples for iteration 368...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5158, #subsample_inputs: 5158
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.679      |
| AbsLearnSignalNew       | 0.679      |
| AbsLearningOld          | 0.679      |
| AverageDiscountedReturn | 139        |
| AveragePhiLoss          | 16.8227    |
| AveragePolicyStd        | 0.795863   |
| AverageReturn           | 574        |
| Entropy                 | 7.12553    |
| EnvExecTime             | 2.73       |
| ExplainedVariance       | 0.324      |
| Iteration               | 368        |
| ItrTime                 | 18         |
| LossAfter               | 0.386904   |
| LossBefore              | 0.456588   |
| MaxReturn               | 1.09e+03   |
| MeanKL                  | 0.00982389 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 341        |
| NumTrajs                | 18         |
| Perplexity              | 1243.31    |
| PolicyExecTime          | 0.596      |
| ProcessExecTime         | 0.0799     |
| StdReturn               | 170        |
| Time                    | 6.61e+03   |
| dLoss                   | 0.0696837  |
----------------------------------------
itr #369 | 
Mem: 766.183594
Obtaining samples...
Obtaining samples for iteration 369...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5136, #subsample_inputs: 5136
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.657      |
| AbsLearnSignalNew       | 0.657      |
| AbsLearningOld          | 0.657      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 16.3167    |
| AveragePolicyStd        | 0.795224   |
| AverageReturn           | 515        |
| Entropy                 | 7.12186    |
| EnvExecTime             | 2.55       |
| ExplainedVariance       | 0.357      |
| Iteration               | 369        |
| ItrTime                 | 17.7       |
| LossAfter               | 1.32437    |
| LossBefore              | 1.37326    |
| MaxReturn               | 1.16e+03   |
| MeanKL                  | 0.00641862 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 13.7       |
| NumTrajs                | 18         |
| Perplexity              | 1238.75    |
| PolicyExecTime          | 0.514      |
| ProcessExecTime         | 0.0666     |
| StdReturn               | 242        |
| Time                    | 6.63e+03   |
| dLoss                   | 0.0488932  |
----------------------------------------
itr #370 | 
Mem: 766.183594
Obtaining samples...
Obtaining samples for iteration 370...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5190, #subsample_inputs: 5190
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
-----------------------------------------
| AbsLearnSignal          | 0.685       |
| AbsLearnSignalNew       | 0.685       |
| AbsLearningOld          | 0.685       |
| AverageDiscountedReturn | 125         |
| AveragePhiLoss          | 16.0723     |
| AveragePolicyStd        | 0.794206    |
| AverageReturn           | 487         |
| Entropy                 | 7.11448     |
| EnvExecTime             | 3.06        |
| ExplainedVariance       | 0.418       |
| Iteration               | 370         |
| ItrTime                 | 17.8        |
| LossAfter               | -0.00187563 |
| LossBefore              | 0.0634583   |
| MaxReturn               | 792         |
| MeanKL                  | 0.00993201  |
| MeanKLBefore            | 0.0         |
| MinReturn               | 98.2        |
| NumTrajs                | 19          |
| Perplexity              | 1229.65     |
| PolicyExecTime          | 0.63        |
| ProcessExecTime         | 0.082       |
| StdReturn               | 170         |
| Time                    | 6.65e+03    |
| dLoss                   | 0.065334    |
-----------------------------------------
itr #371 | 
Mem: 766.183594
Obtaining samples...
Obtaining samples for iteration 371...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5081, #subsample_inputs: 5081
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.722      |
| AbsLearnSignalNew       | 0.722      |
| AbsLearningOld          | 0.722      |
| AverageDiscountedReturn | 131        |
| AveragePhiLoss          | 15.2388    |
| AveragePolicyStd        | 0.791862   |
| AverageReturn           | 493        |
| Entropy                 | 7.09672    |
| EnvExecTime             | 2.94       |
| ExplainedVariance       | 0.392      |
| Iteration               | 371        |
| ItrTime                 | 18.2       |
| LossAfter               | 0.230676   |
| LossBefore              | 0.283009   |
| MaxReturn               | 838        |
| MeanKL                  | 0.00644885 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 245        |
| NumTrajs                | 20         |
| Perplexity              | 1208.0     |
| PolicyExecTime          | 0.622      |
| ProcessExecTime         | 0.0793     |
| StdReturn               | 177        |
| Time                    | 6.67e+03   |
| dLoss                   | 0.0523332  |
----------------------------------------
itr #372 | 
Mem: 766.183594
Obtaining samples...
Obtaining samples for iteration 372...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5048, #subsample_inputs: 5048
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.623      |
| AbsLearnSignalNew       | 0.623      |
| AbsLearningOld          | 0.623      |
| AverageDiscountedReturn | 127        |
| AveragePhiLoss          | 16.5967    |
| AveragePolicyStd        | 0.791694   |
| AverageReturn           | 498        |
| Entropy                 | 7.09468    |
| EnvExecTime             | 2.59       |
| ExplainedVariance       | 0.118      |
| Iteration               | 372        |
| ItrTime                 | 17.4       |
| LossAfter               | -0.895109  |
| LossBefore              | -0.839842  |
| MaxReturn               | 1.11e+03   |
| MeanKL                  | 0.00646375 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 69.2       |
| NumTrajs                | 19         |
| Perplexity              | 1205.54    |
| PolicyExecTime          | 0.512      |
| ProcessExecTime         | 0.0663     |
| StdReturn               | 265        |
| Time                    | 6.68e+03   |
| dLoss                   | 0.055267   |
----------------------------------------
itr #373 | 
Mem: 766.183594
Obtaining samples...
Obtaining samples for iteration 373...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5215, #subsample_inputs: 5215
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.674      |
| AbsLearnSignalNew       | 0.674      |
| AbsLearningOld          | 0.674      |
| AverageDiscountedReturn | 135        |
| AveragePhiLoss          | 16.2818    |
| AveragePolicyStd        | 0.789906   |
| AverageReturn           | 577        |
| Entropy                 | 7.08122    |
| EnvExecTime             | 3.07       |
| ExplainedVariance       | 0.381      |
| Iteration               | 373        |
| ItrTime                 | 18.9       |
| LossAfter               | 0.0827323  |
| LossBefore              | 0.143045   |
| MaxReturn               | 1.03e+03   |
| MeanKL                  | 0.00993059 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 93.5       |
| NumTrajs                | 18         |
| Perplexity              | 1189.42    |
| PolicyExecTime          | 0.632      |
| ProcessExecTime         | 0.0856     |
| StdReturn               | 211        |
| Time                    | 6.7e+03    |
| dLoss                   | 0.0603129  |
----------------------------------------
itr #374 | 
Mem: 766.183594
Obtaining samples...
Obtaining samples for iteration 374...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5121, #subsample_inputs: 5121
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.66       |
| AbsLearnSignalNew       | 0.66       |
| AbsLearningOld          | 0.66       |
| AverageDiscountedReturn | 131        |
| AveragePhiLoss          | 17.0575    |
| AveragePolicyStd        | 0.788966   |
| AverageReturn           | 542        |
| Entropy                 | 7.07525    |
| EnvExecTime             | 2.68       |
| ExplainedVariance       | 0.0703     |
| Iteration               | 374        |
| ItrTime                 | 18.1       |
| LossAfter               | -0.734345  |
| LossBefore              | -0.667969  |
| MaxReturn               | 1.32e+03   |
| MeanKL                  | 0.00984778 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 143        |
| NumTrajs                | 18         |
| Perplexity              | 1182.34    |
| PolicyExecTime          | 0.563      |
| ProcessExecTime         | 0.0692     |
| StdReturn               | 283        |
| Time                    | 6.72e+03   |
| dLoss                   | 0.0663762  |
----------------------------------------
itr #375 | 
Mem: 766.183594
Obtaining samples...
Obtaining samples for iteration 375...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5076, #subsample_inputs: 5076
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.713      |
| AbsLearnSignalNew       | 0.713      |
| AbsLearningOld          | 0.713      |
| AverageDiscountedReturn | 129        |
| AveragePhiLoss          | 16.105     |
| AveragePolicyStd        | 0.790626   |
| AverageReturn           | 497        |
| Entropy                 | 7.08834    |
| EnvExecTime             | 2.99       |
| ExplainedVariance       | 0.436      |
| Iteration               | 375        |
| ItrTime                 | 17.4       |
| LossAfter               | 0.250883   |
| LossBefore              | 0.300637   |
| MaxReturn               | 1.09e+03   |
| MeanKL                  | 0.00642143 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 114        |
| NumTrajs                | 19         |
| Perplexity              | 1197.92    |
| PolicyExecTime          | 0.631      |
| ProcessExecTime         | 0.0793     |
| StdReturn               | 209        |
| Time                    | 6.74e+03   |
| dLoss                   | 0.0497534  |
----------------------------------------
itr #376 | 
Mem: 766.183594
Obtaining samples...
Obtaining samples for iteration 376...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5241, #subsample_inputs: 5241
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.638      |
| AbsLearnSignalNew       | 0.638      |
| AbsLearningOld          | 0.638      |
| AverageDiscountedReturn | 129        |
| AveragePhiLoss          | 16.3565    |
| AveragePolicyStd        | 0.79064    |
| AverageReturn           | 474        |
| Entropy                 | 7.08742    |
| EnvExecTime             | 2.55       |
| ExplainedVariance       | 0.406      |
| Iteration               | 376        |
| ItrTime                 | 18.3       |
| LossAfter               | 0.303807   |
| LossBefore              | 0.358638   |
| MaxReturn               | 923        |
| MeanKL                  | 0.00641587 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 91.1       |
| NumTrajs                | 20         |
| Perplexity              | 1196.81    |
| PolicyExecTime          | 0.538      |
| ProcessExecTime         | 0.0698     |
| StdReturn               | 208        |
| Time                    | 6.76e+03   |
| dLoss                   | 0.0548314  |
----------------------------------------
itr #377 | 
Mem: 766.183594
Obtaining samples...
Obtaining samples for iteration 377...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5124, #subsample_inputs: 5124
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.699      |
| AbsLearnSignalNew       | 0.699      |
| AbsLearningOld          | 0.699      |
| AverageDiscountedReturn | 133        |
| AveragePhiLoss          | 18.4422    |
| AveragePolicyStd        | 0.789397   |
| AverageReturn           | 478        |
| Entropy                 | 7.07655    |
| EnvExecTime             | 2.66       |
| ExplainedVariance       | 0.381      |
| Iteration               | 377        |
| ItrTime                 | 17.7       |
| LossAfter               | -0.0233191 |
| LossBefore              | 0.026561   |
| MaxReturn               | 971        |
| MeanKL                  | 0.00654708 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 240        |
| NumTrajs                | 21         |
| Perplexity              | 1183.88    |
| PolicyExecTime          | 0.555      |
| ProcessExecTime         | 0.0735     |
| StdReturn               | 174        |
| Time                    | 6.77e+03   |
| dLoss                   | 0.0498801  |
----------------------------------------
itr #378 | 
Mem: 766.183594
Obtaining samples...
Obtaining samples for iteration 378...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5285, #subsample_inputs: 5285
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.668      |
| AbsLearnSignalNew       | 0.668      |
| AbsLearningOld          | 0.667      |
| AverageDiscountedReturn | 138        |
| AveragePhiLoss          | 15.8042    |
| AveragePolicyStd        | 0.788242   |
| AverageReturn           | 518        |
| Entropy                 | 7.06436    |
| EnvExecTime             | 3          |
| ExplainedVariance       | 0.498      |
| Iteration               | 378        |
| ItrTime                 | 18.9       |
| LossAfter               | -0.80187   |
| LossBefore              | -0.741756  |
| MaxReturn               | 1.38e+03   |
| MeanKL                  | 0.00647971 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 48.2       |
| NumTrajs                | 21         |
| Perplexity              | 1169.54    |
| PolicyExecTime          | 0.655      |
| ProcessExecTime         | 0.0869     |
| StdReturn               | 270        |
| Time                    | 6.79e+03   |
| dLoss                   | 0.0601138  |
----------------------------------------
itr #379 | 
Mem: 766.183594
Obtaining samples...
Obtaining samples for iteration 379...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5180, #subsample_inputs: 5180
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
---------------------------------------
| AbsLearnSignal          | 0.682     |
| AbsLearnSignalNew       | 0.682     |
| AbsLearningOld          | 0.682     |
| AverageDiscountedReturn | 126       |
| AveragePhiLoss          | 16.4994   |
| AveragePolicyStd        | 0.786151  |
| AverageReturn           | 468       |
| Entropy                 | 7.04867   |
| EnvExecTime             | 2.74      |
| ExplainedVariance       | 0.507     |
| Iteration               | 379       |
| ItrTime                 | 17.6      |
| LossAfter               | -1.16967  |
| LossBefore              | -1.09847  |
| MaxReturn               | 824       |
| MeanKL                  | 0.009864  |
| MeanKLBefore            | 0.0       |
| MinReturn               | 13.9      |
| NumTrajs                | 21        |
| Perplexity              | 1151.32   |
| PolicyExecTime          | 0.561     |
| ProcessExecTime         | 0.07      |
| StdReturn               | 173       |
| Time                    | 6.81e+03  |
| dLoss                   | 0.0712045 |
---------------------------------------
itr #380 | 
Mem: 766.183594
Obtaining samples...
Obtaining samples for iteration 380...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5048, #subsample_inputs: 5048
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.368      |
| AbsLearnSignalNew       | 0.368      |
| AbsLearningOld          | 0.368      |
| AverageDiscountedReturn | 137        |
| AveragePhiLoss          | 17.9338    |
| AveragePolicyStd        | 0.786653   |
| AverageReturn           | 584        |
| Entropy                 | 7.05109    |
| EnvExecTime             | 2.87       |
| ExplainedVariance       | -10.2      |
| Iteration               | 380        |
| ItrTime                 | 18.3       |
| LossAfter               | 0.438118   |
| LossBefore              | 0.564088   |
| MaxReturn               | 1.56e+03   |
| MeanKL                  | 0.00985219 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 70.9       |
| NumTrajs                | 18         |
| Perplexity              | 1154.11    |
| PolicyExecTime          | 0.621      |
| ProcessExecTime         | 0.0789     |
| StdReturn               | 344        |
| Time                    | 6.83e+03   |
| dLoss                   | 0.12597    |
----------------------------------------
itr #381 | 
Mem: 766.183594
Obtaining samples...
Obtaining samples for iteration 381...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5045, #subsample_inputs: 5045
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.733      |
| AbsLearnSignalNew       | 0.733      |
| AbsLearningOld          | 0.734      |
| AverageDiscountedReturn | 127        |
| AveragePhiLoss          | 16.0806    |
| AveragePolicyStd        | 0.788313   |
| AverageReturn           | 472        |
| Entropy                 | 7.06428    |
| EnvExecTime             | 2.3        |
| ExplainedVariance       | 0.49       |
| Iteration               | 381        |
| ItrTime                 | 17         |
| LossAfter               | -2.17221   |
| LossBefore              | -2.11346   |
| MaxReturn               | 988        |
| MeanKL                  | 0.00988435 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 81.2       |
| NumTrajs                | 20         |
| Perplexity              | 1169.44    |
| PolicyExecTime          | 0.444      |
| ProcessExecTime         | 0.0604     |
| StdReturn               | 247        |
| Time                    | 6.85e+03   |
| dLoss                   | 0.0587509  |
----------------------------------------
itr #382 | 
Mem: 766.183594
Obtaining samples...
Obtaining samples for iteration 382...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5184, #subsample_inputs: 5184
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.72       |
| AbsLearnSignalNew       | 0.72       |
| AbsLearningOld          | 0.72       |
| AverageDiscountedReturn | 119        |
| AveragePhiLoss          | 15.7535    |
| AveragePolicyStd        | 0.790271   |
| AverageReturn           | 421        |
| Entropy                 | 7.08056    |
| EnvExecTime             | 3          |
| ExplainedVariance       | 0.366      |
| Iteration               | 382        |
| ItrTime                 | 18.7       |
| LossAfter               | -0.280515  |
| LossBefore              | -0.217334  |
| MaxReturn               | 755        |
| MeanKL                  | 0.00996427 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 63.2       |
| NumTrajs                | 21         |
| Perplexity              | 1188.63    |
| PolicyExecTime          | 0.644      |
| ProcessExecTime         | 0.0833     |
| StdReturn               | 182        |
| Time                    | 6.87e+03   |
| dLoss                   | 0.0631816  |
----------------------------------------
itr #383 | 
Mem: 766.183594
Obtaining samples...
Obtaining samples for iteration 383...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5305, #subsample_inputs: 5305
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.675      |
| AbsLearnSignalNew       | 0.675      |
| AbsLearningOld          | 0.675      |
| AverageDiscountedReturn | 128        |
| AveragePhiLoss          | 15.9335    |
| AveragePolicyStd        | 0.792124   |
| AverageReturn           | 535        |
| Entropy                 | 7.09349    |
| EnvExecTime             | 2.78       |
| ExplainedVariance       | 0.181      |
| Iteration               | 383        |
| ItrTime                 | 18.7       |
| LossAfter               | 0.504256   |
| LossBefore              | 0.55289    |
| MaxReturn               | 1.1e+03    |
| MeanKL                  | 0.00641191 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 63.5       |
| NumTrajs                | 18         |
| Perplexity              | 1204.1     |
| PolicyExecTime          | 0.576      |
| ProcessExecTime         | 0.0702     |
| StdReturn               | 278        |
| Time                    | 6.88e+03   |
| dLoss                   | 0.0486342  |
----------------------------------------
itr #384 | 
Mem: 766.183594
Obtaining samples...
Obtaining samples for iteration 384...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5235, #subsample_inputs: 5235
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.682      |
| AbsLearnSignalNew       | 0.682      |
| AbsLearningOld          | 0.682      |
| AverageDiscountedReturn | 133        |
| AveragePhiLoss          | 15.772     |
| AveragePolicyStd        | 0.792984   |
| AverageReturn           | 495        |
| Entropy                 | 7.09929    |
| EnvExecTime             | 2.68       |
| ExplainedVariance       | 0.356      |
| Iteration               | 384        |
| ItrTime                 | 17.9       |
| LossAfter               | 0.777029   |
| LossBefore              | 0.832111   |
| MaxReturn               | 766        |
| MeanKL                  | 0.00644531 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 215        |
| NumTrajs                | 20         |
| Perplexity              | 1211.1     |
| PolicyExecTime          | 0.539      |
| ProcessExecTime         | 0.0696     |
| StdReturn               | 131        |
| Time                    | 6.9e+03    |
| dLoss                   | 0.0550817  |
----------------------------------------
itr #385 | 
Mem: 767.929688
Obtaining samples...
Obtaining samples for iteration 385...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5066, #subsample_inputs: 5066
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 0
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.698      |
| AbsLearnSignalNew       | 0.698      |
| AbsLearningOld          | 0.698      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 15.6346    |
| AveragePolicyStd        | 0.793786   |
| AverageReturn           | 500        |
| Entropy                 | 7.10539    |
| EnvExecTime             | 2.7        |
| ExplainedVariance       | 0.37       |
| Iteration               | 385        |
| ItrTime                 | 17.9       |
| LossAfter               | 0.342117   |
| LossBefore              | 0.410361   |
| MaxReturn               | 897        |
| MeanKL                  | 0.00978362 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 54.1       |
| NumTrajs                | 19         |
| Perplexity              | 1218.51    |
| PolicyExecTime          | 0.569      |
| ProcessExecTime         | 0.0734     |
| StdReturn               | 182        |
| Time                    | 6.92e+03   |
| dLoss                   | 0.0682441  |
----------------------------------------
itr #386 | 
Mem: 767.929688
Obtaining samples...
Obtaining samples for iteration 386...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
Optimizing policy...
Using Stein CV optimizer
Computing loss before
Computing KL before
Optimizing
Start CG optimization: #parameters: 8287, #inputs: 5133, #subsample_inputs: 5133
computing loss before
performing update
computing gradient
gradient computed
computing descent direction
descent direction computed
backtrack iters: 1
computing loss after
optimization finished
Computing KL after
Computing loss after
Saved
----------------------------------------
| AbsLearnSignal          | 0.588      |
| AbsLearnSignalNew       | 0.588      |
| AbsLearningOld          | 0.588      |
| AverageDiscountedReturn | 126        |
| AveragePhiLoss          | 13.996     |
| AveragePolicyStd        | 0.79389    |
| AverageReturn           | 552        |
| Entropy                 | 7.1057     |
| EnvExecTime             | 2.52       |
| ExplainedVariance       | 0.328      |
| Iteration               | 386        |
| ItrTime                 | 17.7       |
| LossAfter               | 0.603101   |
| LossBefore              | 0.657695   |
| MaxReturn               | 980        |
| MeanKL                  | 0.00641977 |
| MeanKLBefore            | 0.0        |
| MinReturn               | 48.8       |
| NumTrajs                | 18         |
| Perplexity              | 1218.89    |
| PolicyExecTime          | 0.494      |
| ProcessExecTime         | 0.0624     |
| StdReturn               | 258        |
| Time                    | 6.94e+03   |
| dLoss                   | 0.0545934  |
----------------------------------------
itr #387 | 
Mem: 767.929688
Obtaining samples...
Obtaining samples for iteration 387...
Processing samples...
Stein Variance Reduction, subtracting functions
fitting baseline...
fitted
Logging diagnostics...
Optimizing phi to reduce variance before policy...
Optimizing phi function for 800 iterations
